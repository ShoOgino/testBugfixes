{"path":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean,ValueHolder[Boolean]).mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean,ValueHolder[Boolean]).mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean,ValueHolder[Boolean]).mjava","sourceNew":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex, ValueHolder<Boolean> usedIdvBasedImpl) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers));\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<Collection<SearchGroup<BytesRef>>>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<AbstractFirstPassGroupingCollector<?>>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[shardIDX].getIndexReader().getClass())) {\n        canUseIDV = false;\n      } else {\n        canUseIDV = !preFlex;\n      }\n\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(\"group\", groupSort, groupOffset + topNGroups, canUseIDV);\n        if (DVFirstPassGroupingCollector.class.isAssignableFrom(firstPassCollector.getClass())) {\n          usedIdvBasedImpl.value = true;\n        }\n      } else {\n        firstPassCollector = createFirstPassCollector(\"group\", groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            \"group\", mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex, ValueHolder<Boolean> usedIdvBasedImpl) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers));\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<Collection<SearchGroup<BytesRef>>>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<AbstractFirstPassGroupingCollector<?>>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[shardIDX].getIndexReader().getClass())) {\n        canUseIDV = false;\n      } else {\n        canUseIDV = !preFlex;\n      }\n\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(\"group\", groupSort, groupOffset + topNGroups, canUseIDV);\n        if (DVFirstPassGroupingCollector.class.isAssignableFrom(firstPassCollector.getClass())) {\n          usedIdvBasedImpl.value = true;\n        }\n      } else {\n        firstPassCollector = createFirstPassCollector(\"group\", groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            \"group\", mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"85d41890f2bad879e6a04c6dd7d2cf276f973994","date":1338488367,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean,ValueHolder[Boolean]).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean,ValueHolder[Boolean]).mjava","sourceNew":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex, ValueHolder<Boolean> usedIdvBasedImpl) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers));\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<Collection<SearchGroup<BytesRef>>>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<AbstractFirstPassGroupingCollector<?>>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[shardIDX].getIndexReader().getClass())) {\n        canUseIDV = false;\n      } else {\n        canUseIDV = !preFlex;\n      }\n\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(\"group\", groupSort, groupOffset + topNGroups, canUseIDV);\n        if (DVFirstPassGroupingCollector.class.isAssignableFrom(firstPassCollector.getClass())) {\n          usedIdvBasedImpl.value = true;\n        }\n      } else {\n        firstPassCollector = createFirstPassCollector(\"group\", groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            \"group\", mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex, ValueHolder<Boolean> usedIdvBasedImpl) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers));\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<Collection<SearchGroup<BytesRef>>>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<AbstractFirstPassGroupingCollector<?>>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[shardIDX].getIndexReader().getClass())) {\n        canUseIDV = false;\n      } else {\n        canUseIDV = !preFlex;\n      }\n\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(\"group\", groupSort, groupOffset + topNGroups, canUseIDV);\n        if (DVFirstPassGroupingCollector.class.isAssignableFrom(firstPassCollector.getClass())) {\n          usedIdvBasedImpl.value = true;\n        }\n      } else {\n        firstPassCollector = createFirstPassCollector(\"group\", groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            \"group\", mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":["4739c84c362b9673ab5ed3e038ff760c718c30c8"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"854f97cd3613b9579fba83755c80b697e2f3993f","date":1353527621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean,ValueHolder[Boolean]).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean,ValueHolder[Boolean]).mjava","sourceNew":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex, ValueHolder<Boolean> usedIdvBasedImpl) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<Collection<SearchGroup<BytesRef>>>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<AbstractFirstPassGroupingCollector<?>>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[shardIDX].getIndexReader().getClass())) {\n        canUseIDV = false;\n      } else {\n        canUseIDV = !preFlex;\n      }\n\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(\"group\", groupSort, groupOffset + topNGroups, canUseIDV);\n        if (DVFirstPassGroupingCollector.class.isAssignableFrom(firstPassCollector.getClass())) {\n          usedIdvBasedImpl.value = true;\n        }\n      } else {\n        firstPassCollector = createFirstPassCollector(\"group\", groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            \"group\", mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex, ValueHolder<Boolean> usedIdvBasedImpl) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers));\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<Collection<SearchGroup<BytesRef>>>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<AbstractFirstPassGroupingCollector<?>>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[shardIDX].getIndexReader().getClass())) {\n        canUseIDV = false;\n      } else {\n        canUseIDV = !preFlex;\n      }\n\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(\"group\", groupSort, groupOffset + topNGroups, canUseIDV);\n        if (DVFirstPassGroupingCollector.class.isAssignableFrom(firstPassCollector.getClass())) {\n          usedIdvBasedImpl.value = true;\n        }\n      } else {\n        firstPassCollector = createFirstPassCollector(\"group\", groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            \"group\", mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e13078ebcbc41380853f4612578b706f40699cf5","date":1358203044,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean,ValueHolder[Boolean]).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean,ValueHolder[Boolean]).mjava","sourceNew":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex, ValueHolder<Boolean> usedIdvBasedImpl) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<Collection<SearchGroup<BytesRef>>>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<AbstractFirstPassGroupingCollector<?>>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[shardIDX].getIndexReader().getClass())) {\n        canUseIDV = false;\n      } else {\n        canUseIDV = !preFlex;\n      }\n\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(\"group\", groupSort, groupOffset + topNGroups, canUseIDV);\n        if (DVFirstPassGroupingCollector.class.isAssignableFrom(firstPassCollector.getClass())) {\n          usedIdvBasedImpl.value = true;\n        }\n      } else {\n        firstPassCollector = createFirstPassCollector(\"group\", groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            \"group\", mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex, ValueHolder<Boolean> usedIdvBasedImpl) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<Collection<SearchGroup<BytesRef>>>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<AbstractFirstPassGroupingCollector<?>>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[shardIDX].getIndexReader().getClass())) {\n        canUseIDV = false;\n      } else {\n        canUseIDV = !preFlex;\n      }\n\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(\"group\", groupSort, groupOffset + topNGroups, canUseIDV);\n        if (DVFirstPassGroupingCollector.class.isAssignableFrom(firstPassCollector.getClass())) {\n          usedIdvBasedImpl.value = true;\n        }\n      } else {\n        firstPassCollector = createFirstPassCollector(\"group\", groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            \"group\", mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0837ab0472feecb3a54260729d845f839e1cbd72","date":1358283639,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean,ValueHolder[Boolean]).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean,ValueHolder[Boolean]).mjava","sourceNew":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex, ValueHolder<Boolean> usedIdvBasedImpl) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<Collection<SearchGroup<BytesRef>>>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<AbstractFirstPassGroupingCollector<?>>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[shardIDX].getIndexReader().getClass())) {\n        canUseIDV = false;\n      } else {\n        canUseIDV = !preFlex;\n      }\n\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(\"group\", groupSort, groupOffset + topNGroups, canUseIDV);\n      } else {\n        firstPassCollector = createFirstPassCollector(\"group\", groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            \"group\", mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex, ValueHolder<Boolean> usedIdvBasedImpl) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<Collection<SearchGroup<BytesRef>>>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<AbstractFirstPassGroupingCollector<?>>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[shardIDX].getIndexReader().getClass())) {\n        canUseIDV = false;\n      } else {\n        canUseIDV = !preFlex;\n      }\n\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(\"group\", groupSort, groupOffset + topNGroups, canUseIDV);\n        if (DVFirstPassGroupingCollector.class.isAssignableFrom(firstPassCollector.getClass())) {\n          usedIdvBasedImpl.value = true;\n        }\n      } else {\n        firstPassCollector = createFirstPassCollector(\"group\", groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            \"group\", mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e3eb88edd735aec1f42cbe41c478fb4f8d41f0ec","date":1358544193,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean,ValueHolder[Boolean]).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean,ValueHolder[Boolean]).mjava","sourceNew":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex, ValueHolder<Boolean> usedIdvBasedImpl) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<Collection<SearchGroup<BytesRef>>>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<AbstractFirstPassGroupingCollector<?>>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV;\n    if (canUseIDV) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[0].getIndexReader().getClass())) {\n        shardsCanUseIDV = false;\n      } else {\n        shardsCanUseIDV = !preFlex;\n      }\n    } else {\n      shardsCanUseIDV = false;\n    }\n\n    String groupField = \"group\";\n    if (shardsCanUseIDV && random().nextBoolean()) {\n      groupField += \"_dv\";\n      usedIdvBasedImpl.value = true;\n    }\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex, ValueHolder<Boolean> usedIdvBasedImpl) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<Collection<SearchGroup<BytesRef>>>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<AbstractFirstPassGroupingCollector<?>>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[shardIDX].getIndexReader().getClass())) {\n        canUseIDV = false;\n      } else {\n        canUseIDV = !preFlex;\n      }\n\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(\"group\", groupSort, groupOffset + topNGroups, canUseIDV);\n      } else {\n        firstPassCollector = createFirstPassCollector(\"group\", groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            \"group\", mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1","0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1","0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d4d69c535930b5cce125cff868d40f6373dc27d4","date":1360270101,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean,ValueHolder[Boolean]).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean,ValueHolder[Boolean]).mjava","sourceNew":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex, ValueHolder<Boolean> usedIdvBasedImpl) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<Collection<SearchGroup<BytesRef>>>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<AbstractFirstPassGroupingCollector<?>>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV;\n    if (canUseIDV) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[0].getIndexReader().getClass())) {\n        shardsCanUseIDV = false;\n      } else {\n        shardsCanUseIDV = !preFlex;\n      }\n    } else {\n      shardsCanUseIDV = false;\n    }\n\n    String groupField = \"group\";\n    if (shardsCanUseIDV && random().nextBoolean()) {\n      groupField += \"_dv\";\n      usedIdvBasedImpl.value = true;\n    }\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex, ValueHolder<Boolean> usedIdvBasedImpl) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers));\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<Collection<SearchGroup<BytesRef>>>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<AbstractFirstPassGroupingCollector<?>>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[shardIDX].getIndexReader().getClass())) {\n        canUseIDV = false;\n      } else {\n        canUseIDV = !preFlex;\n      }\n\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(\"group\", groupSort, groupOffset + topNGroups, canUseIDV);\n        if (DVFirstPassGroupingCollector.class.isAssignableFrom(firstPassCollector.getClass())) {\n          usedIdvBasedImpl.value = true;\n        }\n      } else {\n        firstPassCollector = createFirstPassCollector(\"group\", groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            \"group\", mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":["7528ec8c6e88061e2e6af98c4ae1f72a30f180b2","4739c84c362b9673ab5ed3e038ff760c718c30c8"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"97d4692d0c601ff773f0a2231967312428a904e4","date":1366026608,"type":3,"author":"Martijn van Groningen","isMerge":false,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean,ValueHolder[Boolean]).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean,ValueHolder[Boolean]).mjava","sourceNew":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex, ValueHolder<Boolean> usedIdvBasedImpl) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV;\n    if (canUseIDV) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[0].getIndexReader().getClass())) {\n        shardsCanUseIDV = false;\n      } else {\n        shardsCanUseIDV = !preFlex;\n      }\n    } else {\n      shardsCanUseIDV = false;\n    }\n\n    String groupField = \"group\";\n    if (shardsCanUseIDV && random().nextBoolean()) {\n      groupField += \"_dv\";\n      usedIdvBasedImpl.value = true;\n    }\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex, ValueHolder<Boolean> usedIdvBasedImpl) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<Collection<SearchGroup<BytesRef>>>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<AbstractFirstPassGroupingCollector<?>>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV;\n    if (canUseIDV) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[0].getIndexReader().getClass())) {\n        shardsCanUseIDV = false;\n      } else {\n        shardsCanUseIDV = !preFlex;\n      }\n    } else {\n      shardsCanUseIDV = false;\n    }\n\n    String groupField = \"group\";\n    if (shardsCanUseIDV && random().nextBoolean()) {\n      groupField += \"_dv\";\n      usedIdvBasedImpl.value = true;\n    }\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b36581872266f87caefe066d71f76c81cf1b636e","date":1399817565,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean,ValueHolder[Boolean]).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean,ValueHolder[Boolean]).mjava","sourceNew":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex, ValueHolder<Boolean> usedIdvBasedImpl) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV;\n    if (canUseIDV) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[0].getIndexReader().getClass())) {\n        shardsCanUseIDV = false;\n      } else {\n        shardsCanUseIDV = !preFlex;\n      }\n    } else {\n      shardsCanUseIDV = false;\n    }\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex, ValueHolder<Boolean> usedIdvBasedImpl) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV;\n    if (canUseIDV) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[0].getIndexReader().getClass())) {\n        shardsCanUseIDV = false;\n      } else {\n        shardsCanUseIDV = !preFlex;\n      }\n    } else {\n      shardsCanUseIDV = false;\n    }\n\n    String groupField = \"group\";\n    if (shardsCanUseIDV && random().nextBoolean()) {\n      groupField += \"_dv\";\n      usedIdvBasedImpl.value = true;\n    }\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c9f72b4e0953a7ed14ab0430053c1bb65f2ef529","date":1399818681,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean,ValueHolder[Boolean]).mjava","sourceNew":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV;\n    if (canUseIDV) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[0].getIndexReader().getClass())) {\n        shardsCanUseIDV = false;\n      } else {\n        shardsCanUseIDV = !preFlex;\n      }\n    } else {\n      shardsCanUseIDV = false;\n    }\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex, ValueHolder<Boolean> usedIdvBasedImpl) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV;\n    if (canUseIDV) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[0].getIndexReader().getClass())) {\n        shardsCanUseIDV = false;\n      } else {\n        shardsCanUseIDV = !preFlex;\n      }\n    } else {\n      shardsCanUseIDV = false;\n    }\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"93dd449115a9247533e44bab47e8429e5dccbc6d","date":1400258396,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean,ValueHolder[Boolean]).mjava","sourceNew":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV;\n    if (canUseIDV) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[0].getIndexReader().getClass())) {\n        shardsCanUseIDV = false;\n      } else {\n        shardsCanUseIDV = !preFlex;\n      }\n    } else {\n      shardsCanUseIDV = false;\n    }\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex, ValueHolder<Boolean> usedIdvBasedImpl) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV;\n    if (canUseIDV) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[0].getIndexReader().getClass())) {\n        shardsCanUseIDV = false;\n      } else {\n        shardsCanUseIDV = !preFlex;\n      }\n    } else {\n      shardsCanUseIDV = false;\n    }\n\n    String groupField = \"group\";\n    if (shardsCanUseIDV && random().nextBoolean()) {\n      groupField += \"_dv\";\n      usedIdvBasedImpl.value = true;\n    }\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"56572ec06f1407c066d6b7399413178b33176cd8","date":1400495675,"type":5,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean,ValueHolder[Boolean]).mjava","sourceNew":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV;\n    if (canUseIDV) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[0].getIndexReader().getClass())) {\n        shardsCanUseIDV = false;\n      } else {\n        shardsCanUseIDV = !preFlex;\n      }\n    } else {\n      shardsCanUseIDV = false;\n    }\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex, ValueHolder<Boolean> usedIdvBasedImpl) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV;\n    if (canUseIDV) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[0].getIndexReader().getClass())) {\n        shardsCanUseIDV = false;\n      } else {\n        shardsCanUseIDV = !preFlex;\n      }\n    } else {\n      shardsCanUseIDV = false;\n    }\n\n    String groupField = \"group\";\n    if (shardsCanUseIDV && random().nextBoolean()) {\n      groupField += \"_dv\";\n      usedIdvBasedImpl.value = true;\n    }\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b36581872266f87caefe066d71f76c81cf1b636e":["97d4692d0c601ff773f0a2231967312428a904e4"],"56572ec06f1407c066d6b7399413178b33176cd8":["97d4692d0c601ff773f0a2231967312428a904e4","93dd449115a9247533e44bab47e8429e5dccbc6d"],"e3eb88edd735aec1f42cbe41c478fb4f8d41f0ec":["0837ab0472feecb3a54260729d845f839e1cbd72"],"85d41890f2bad879e6a04c6dd7d2cf276f973994":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["85d41890f2bad879e6a04c6dd7d2cf276f973994","e3eb88edd735aec1f42cbe41c478fb4f8d41f0ec"],"93dd449115a9247533e44bab47e8429e5dccbc6d":["97d4692d0c601ff773f0a2231967312428a904e4","c9f72b4e0953a7ed14ab0430053c1bb65f2ef529"],"c9f72b4e0953a7ed14ab0430053c1bb65f2ef529":["b36581872266f87caefe066d71f76c81cf1b636e"],"97d4692d0c601ff773f0a2231967312428a904e4":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0837ab0472feecb3a54260729d845f839e1cbd72":["e13078ebcbc41380853f4612578b706f40699cf5"],"e13078ebcbc41380853f4612578b706f40699cf5":["854f97cd3613b9579fba83755c80b697e2f3993f"],"854f97cd3613b9579fba83755c80b697e2f3993f":["85d41890f2bad879e6a04c6dd7d2cf276f973994"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["93dd449115a9247533e44bab47e8429e5dccbc6d"]},"commit2Childs":{"b36581872266f87caefe066d71f76c81cf1b636e":["c9f72b4e0953a7ed14ab0430053c1bb65f2ef529"],"56572ec06f1407c066d6b7399413178b33176cd8":[],"e3eb88edd735aec1f42cbe41c478fb4f8d41f0ec":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"85d41890f2bad879e6a04c6dd7d2cf276f973994":["d4d69c535930b5cce125cff868d40f6373dc27d4","854f97cd3613b9579fba83755c80b697e2f3993f"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["85d41890f2bad879e6a04c6dd7d2cf276f973994"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["97d4692d0c601ff773f0a2231967312428a904e4"],"93dd449115a9247533e44bab47e8429e5dccbc6d":["56572ec06f1407c066d6b7399413178b33176cd8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c9f72b4e0953a7ed14ab0430053c1bb65f2ef529":["93dd449115a9247533e44bab47e8429e5dccbc6d"],"97d4692d0c601ff773f0a2231967312428a904e4":["b36581872266f87caefe066d71f76c81cf1b636e","56572ec06f1407c066d6b7399413178b33176cd8","93dd449115a9247533e44bab47e8429e5dccbc6d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"0837ab0472feecb3a54260729d845f839e1cbd72":["e3eb88edd735aec1f42cbe41c478fb4f8d41f0ec"],"e13078ebcbc41380853f4612578b706f40699cf5":["0837ab0472feecb3a54260729d845f839e1cbd72"],"854f97cd3613b9579fba83755c80b697e2f3993f":["e13078ebcbc41380853f4612578b706f40699cf5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["56572ec06f1407c066d6b7399413178b33176cd8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}