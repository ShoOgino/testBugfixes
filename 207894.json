{"path":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/morphline/MorphlineMapRunner#getRecord(PathParts).mjava","commits":[{"id":"70f91c8322fbffe3a3a897ef20ea19119cac10cd","date":1386170124,"type":1,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/morphline/MorphlineMapRunner#getRecord(PathParts).mjava","pathOld":"solr/contrib/solr-mr/src/java/org/apache/solr/hadoop/morphline/MorphlineMapRunner#getRecord(PathParts).mjava","sourceNew":"  protected Record getRecord(PathParts parts) {\n    FileStatus stats;\n    try {\n      stats = parts.getFileStatus();\n    } catch (IOException e) {\n      stats = null;\n    }\n    if (stats == null) {\n      LOG.warn(\"Ignoring file that somehow has become unavailable since the job was submitted: {}\",\n          parts.getUploadURL());\n      return null;\n    }\n    \n    Record headers = new Record();\n    //headers.put(getSchema().getUniqueKeyField().getName(), parts.getId()); // use HDFS file path as docId if no docId is specified\n    headers.put(Fields.BASE_ID, parts.getId()); // with sanitizeUniqueKey command, use HDFS file path as docId if no docId is specified\n    headers.put(Fields.ATTACHMENT_NAME, parts.getName()); // Tika can use the file name in guessing the right MIME type\n    \n    // enable indexing and storing of file meta data in Solr\n    headers.put(HdfsFileFieldNames.FILE_UPLOAD_URL, parts.getUploadURL());\n    headers.put(HdfsFileFieldNames.FILE_DOWNLOAD_URL, parts.getDownloadURL());\n    headers.put(HdfsFileFieldNames.FILE_SCHEME, parts.getScheme()); \n    headers.put(HdfsFileFieldNames.FILE_HOST, parts.getHost()); \n    headers.put(HdfsFileFieldNames.FILE_PORT, String.valueOf(parts.getPort())); \n    headers.put(HdfsFileFieldNames.FILE_PATH, parts.getURIPath()); \n    headers.put(HdfsFileFieldNames.FILE_NAME, parts.getName());     \n    headers.put(HdfsFileFieldNames.FILE_LAST_MODIFIED, String.valueOf(stats.getModificationTime())); // FIXME also add in SpoolDirectorySource\n    headers.put(HdfsFileFieldNames.FILE_LENGTH, String.valueOf(stats.getLen())); // FIXME also add in SpoolDirectorySource\n    headers.put(HdfsFileFieldNames.FILE_OWNER, stats.getOwner());\n    headers.put(HdfsFileFieldNames.FILE_GROUP, stats.getGroup());\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_USER, stats.getPermission().getUserAction().SYMBOL);\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_GROUP, stats.getPermission().getGroupAction().SYMBOL);\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_OTHER, stats.getPermission().getOtherAction().SYMBOL);\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_STICKYBIT, String.valueOf(stats.getPermission().getStickyBit()));\n    // TODO: consider to add stats.getAccessTime(), stats.getReplication(), stats.isSymlink(), stats.getBlockSize()\n    \n    return headers;\n  }\n\n","sourceOld":"  protected Record getRecord(PathParts parts) {\n    FileStatus stats;\n    try {\n      stats = parts.getFileStatus();\n    } catch (IOException e) {\n      stats = null;\n    }\n    if (stats == null) {\n      LOG.warn(\"Ignoring file that somehow has become unavailable since the job was submitted: {}\",\n          parts.getUploadURL());\n      return null;\n    }\n    \n    Record headers = new Record();\n    //headers.put(getSchema().getUniqueKeyField().getName(), parts.getId()); // use HDFS file path as docId if no docId is specified\n    headers.put(Fields.BASE_ID, parts.getId()); // with sanitizeUniqueKey command, use HDFS file path as docId if no docId is specified\n    headers.put(Fields.ATTACHMENT_NAME, parts.getName()); // Tika can use the file name in guessing the right MIME type\n    \n    // enable indexing and storing of file meta data in Solr\n    headers.put(HdfsFileFieldNames.FILE_UPLOAD_URL, parts.getUploadURL());\n    headers.put(HdfsFileFieldNames.FILE_DOWNLOAD_URL, parts.getDownloadURL());\n    headers.put(HdfsFileFieldNames.FILE_SCHEME, parts.getScheme()); \n    headers.put(HdfsFileFieldNames.FILE_HOST, parts.getHost()); \n    headers.put(HdfsFileFieldNames.FILE_PORT, String.valueOf(parts.getPort())); \n    headers.put(HdfsFileFieldNames.FILE_PATH, parts.getURIPath()); \n    headers.put(HdfsFileFieldNames.FILE_NAME, parts.getName());     \n    headers.put(HdfsFileFieldNames.FILE_LAST_MODIFIED, String.valueOf(stats.getModificationTime())); // FIXME also add in SpoolDirectorySource\n    headers.put(HdfsFileFieldNames.FILE_LENGTH, String.valueOf(stats.getLen())); // FIXME also add in SpoolDirectorySource\n    headers.put(HdfsFileFieldNames.FILE_OWNER, stats.getOwner());\n    headers.put(HdfsFileFieldNames.FILE_GROUP, stats.getGroup());\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_USER, stats.getPermission().getUserAction().SYMBOL);\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_GROUP, stats.getPermission().getGroupAction().SYMBOL);\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_OTHER, stats.getPermission().getOtherAction().SYMBOL);\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_STICKYBIT, String.valueOf(stats.getPermission().getStickyBit()));\n    // TODO: consider to add stats.getAccessTime(), stats.getReplication(), stats.isSymlink(), stats.getBlockSize()\n    \n    return headers;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"74f45af4339b0daf7a95c820ab88c1aea74fbce0","date":1387475327,"type":0,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/morphline/MorphlineMapRunner#getRecord(PathParts).mjava","pathOld":"/dev/null","sourceNew":"  protected Record getRecord(PathParts parts) {\n    FileStatus stats;\n    try {\n      stats = parts.getFileStatus();\n    } catch (IOException e) {\n      stats = null;\n    }\n    if (stats == null) {\n      LOG.warn(\"Ignoring file that somehow has become unavailable since the job was submitted: {}\",\n          parts.getUploadURL());\n      return null;\n    }\n    \n    Record headers = new Record();\n    //headers.put(getSchema().getUniqueKeyField().getName(), parts.getId()); // use HDFS file path as docId if no docId is specified\n    headers.put(Fields.BASE_ID, parts.getId()); // with sanitizeUniqueKey command, use HDFS file path as docId if no docId is specified\n    headers.put(Fields.ATTACHMENT_NAME, parts.getName()); // Tika can use the file name in guessing the right MIME type\n    \n    // enable indexing and storing of file meta data in Solr\n    headers.put(HdfsFileFieldNames.FILE_UPLOAD_URL, parts.getUploadURL());\n    headers.put(HdfsFileFieldNames.FILE_DOWNLOAD_URL, parts.getDownloadURL());\n    headers.put(HdfsFileFieldNames.FILE_SCHEME, parts.getScheme()); \n    headers.put(HdfsFileFieldNames.FILE_HOST, parts.getHost()); \n    headers.put(HdfsFileFieldNames.FILE_PORT, String.valueOf(parts.getPort())); \n    headers.put(HdfsFileFieldNames.FILE_PATH, parts.getURIPath()); \n    headers.put(HdfsFileFieldNames.FILE_NAME, parts.getName());     \n    headers.put(HdfsFileFieldNames.FILE_LAST_MODIFIED, String.valueOf(stats.getModificationTime())); // FIXME also add in SpoolDirectorySource\n    headers.put(HdfsFileFieldNames.FILE_LENGTH, String.valueOf(stats.getLen())); // FIXME also add in SpoolDirectorySource\n    headers.put(HdfsFileFieldNames.FILE_OWNER, stats.getOwner());\n    headers.put(HdfsFileFieldNames.FILE_GROUP, stats.getGroup());\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_USER, stats.getPermission().getUserAction().SYMBOL);\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_GROUP, stats.getPermission().getGroupAction().SYMBOL);\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_OTHER, stats.getPermission().getOtherAction().SYMBOL);\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_STICKYBIT, String.valueOf(stats.getPermission().getStickyBit()));\n    // TODO: consider to add stats.getAccessTime(), stats.getReplication(), stats.isSymlink(), stats.getBlockSize()\n    \n    return headers;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"12109b652e9210b8d58fca47f6c4a725d058a58e","date":1490373076,"type":4,"author":"Steve Rowe","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/morphline/MorphlineMapRunner#getRecord(PathParts).mjava","sourceNew":null,"sourceOld":"  protected Record getRecord(PathParts parts) {\n    FileStatus stats;\n    try {\n      stats = parts.getFileStatus();\n    } catch (IOException e) {\n      stats = null;\n    }\n    if (stats == null) {\n      LOG.warn(\"Ignoring file that somehow has become unavailable since the job was submitted: {}\",\n          parts.getUploadURL());\n      return null;\n    }\n    \n    Record headers = new Record();\n    //headers.put(getSchema().getUniqueKeyField().getName(), parts.getId()); // use HDFS file path as docId if no docId is specified\n    headers.put(Fields.BASE_ID, parts.getId()); // with sanitizeUniqueKey command, use HDFS file path as docId if no docId is specified\n    headers.put(Fields.ATTACHMENT_NAME, parts.getName()); // Tika can use the file name in guessing the right MIME type\n    \n    // enable indexing and storing of file meta data in Solr\n    headers.put(HdfsFileFieldNames.FILE_UPLOAD_URL, parts.getUploadURL());\n    headers.put(HdfsFileFieldNames.FILE_DOWNLOAD_URL, parts.getDownloadURL());\n    headers.put(HdfsFileFieldNames.FILE_SCHEME, parts.getScheme()); \n    headers.put(HdfsFileFieldNames.FILE_HOST, parts.getHost()); \n    headers.put(HdfsFileFieldNames.FILE_PORT, String.valueOf(parts.getPort())); \n    headers.put(HdfsFileFieldNames.FILE_PATH, parts.getURIPath()); \n    headers.put(HdfsFileFieldNames.FILE_NAME, parts.getName());     \n    headers.put(HdfsFileFieldNames.FILE_LAST_MODIFIED, String.valueOf(stats.getModificationTime())); // FIXME also add in SpoolDirectorySource\n    headers.put(HdfsFileFieldNames.FILE_LENGTH, String.valueOf(stats.getLen())); // FIXME also add in SpoolDirectorySource\n    headers.put(HdfsFileFieldNames.FILE_OWNER, stats.getOwner());\n    headers.put(HdfsFileFieldNames.FILE_GROUP, stats.getGroup());\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_USER, stats.getPermission().getUserAction().SYMBOL);\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_GROUP, stats.getPermission().getGroupAction().SYMBOL);\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_OTHER, stats.getPermission().getOtherAction().SYMBOL);\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_STICKYBIT, String.valueOf(stats.getPermission().getStickyBit()));\n    // TODO: consider to add stats.getAccessTime(), stats.getReplication(), stats.isSymlink(), stats.getBlockSize()\n    \n    return headers;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe1c4aa9af769a38e878f608070f672efbeac27f","date":1490594650,"type":4,"author":"Steve Rowe","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/morphline/MorphlineMapRunner#getRecord(PathParts).mjava","sourceNew":null,"sourceOld":"  protected Record getRecord(PathParts parts) {\n    FileStatus stats;\n    try {\n      stats = parts.getFileStatus();\n    } catch (IOException e) {\n      stats = null;\n    }\n    if (stats == null) {\n      LOG.warn(\"Ignoring file that somehow has become unavailable since the job was submitted: {}\",\n          parts.getUploadURL());\n      return null;\n    }\n    \n    Record headers = new Record();\n    //headers.put(getSchema().getUniqueKeyField().getName(), parts.getId()); // use HDFS file path as docId if no docId is specified\n    headers.put(Fields.BASE_ID, parts.getId()); // with sanitizeUniqueKey command, use HDFS file path as docId if no docId is specified\n    headers.put(Fields.ATTACHMENT_NAME, parts.getName()); // Tika can use the file name in guessing the right MIME type\n    \n    // enable indexing and storing of file meta data in Solr\n    headers.put(HdfsFileFieldNames.FILE_UPLOAD_URL, parts.getUploadURL());\n    headers.put(HdfsFileFieldNames.FILE_DOWNLOAD_URL, parts.getDownloadURL());\n    headers.put(HdfsFileFieldNames.FILE_SCHEME, parts.getScheme()); \n    headers.put(HdfsFileFieldNames.FILE_HOST, parts.getHost()); \n    headers.put(HdfsFileFieldNames.FILE_PORT, String.valueOf(parts.getPort())); \n    headers.put(HdfsFileFieldNames.FILE_PATH, parts.getURIPath()); \n    headers.put(HdfsFileFieldNames.FILE_NAME, parts.getName());     \n    headers.put(HdfsFileFieldNames.FILE_LAST_MODIFIED, String.valueOf(stats.getModificationTime())); // FIXME also add in SpoolDirectorySource\n    headers.put(HdfsFileFieldNames.FILE_LENGTH, String.valueOf(stats.getLen())); // FIXME also add in SpoolDirectorySource\n    headers.put(HdfsFileFieldNames.FILE_OWNER, stats.getOwner());\n    headers.put(HdfsFileFieldNames.FILE_GROUP, stats.getGroup());\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_USER, stats.getPermission().getUserAction().SYMBOL);\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_GROUP, stats.getPermission().getGroupAction().SYMBOL);\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_OTHER, stats.getPermission().getOtherAction().SYMBOL);\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_STICKYBIT, String.valueOf(stats.getPermission().getStickyBit()));\n    // TODO: consider to add stats.getAccessTime(), stats.getReplication(), stats.isSymlink(), stats.getBlockSize()\n    \n    return headers;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"70f91c8322fbffe3a3a897ef20ea19119cac10cd":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"12109b652e9210b8d58fca47f6c4a725d058a58e":["70f91c8322fbffe3a3a897ef20ea19119cac10cd"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","70f91c8322fbffe3a3a897ef20ea19119cac10cd"],"fe1c4aa9af769a38e878f608070f672efbeac27f":["70f91c8322fbffe3a3a897ef20ea19119cac10cd"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["12109b652e9210b8d58fca47f6c4a725d058a58e"]},"commit2Childs":{"70f91c8322fbffe3a3a897ef20ea19119cac10cd":["12109b652e9210b8d58fca47f6c4a725d058a58e","74f45af4339b0daf7a95c820ab88c1aea74fbce0","fe1c4aa9af769a38e878f608070f672efbeac27f"],"12109b652e9210b8d58fca47f6c4a725d058a58e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["70f91c8322fbffe3a3a897ef20ea19119cac10cd","74f45af4339b0daf7a95c820ab88c1aea74fbce0"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":[],"fe1c4aa9af769a38e878f608070f672efbeac27f":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["74f45af4339b0daf7a95c820ab88c1aea74fbce0","fe1c4aa9af769a38e878f608070f672efbeac27f","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}