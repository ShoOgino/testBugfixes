{"path":"lucene/core/src/java/org/apache/lucene/index/Sorter#sort(int,IndexSorter.DocComparator).mjava","commits":[{"id":"773bf150032d3ef6c95997a154fb914b82875cb8","date":1590150786,"type":1,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/Sorter#sort(int,IndexSorter.DocComparator).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/Sorter#sort(int,DocComparator).mjava","sourceNew":"  /** Computes the old-to-new permutation over the given comparator. */\n  private static Sorter.DocMap sort(final int maxDoc, IndexSorter.DocComparator comparator) {\n    // check if the index is sorted\n    boolean sorted = true;\n    for (int i = 1; i < maxDoc; ++i) {\n      if (comparator.compare(i-1, i) > 0) {\n        sorted = false;\n        break;\n      }\n    }\n    if (sorted) {\n      return null;\n    }\n\n    // sort doc IDs\n    final int[] docs = new int[maxDoc];\n    for (int i = 0; i < maxDoc; i++) {\n      docs[i] = i;\n    }\n    \n    DocValueSorter sorter = new DocValueSorter(docs, comparator);\n    // It can be common to sort a reader, add docs, sort it again, ... and in\n    // that case timSort can save a lot of time\n    sorter.sort(0, docs.length); // docs is now the newToOld mapping\n\n    // The reason why we use MonotonicAppendingLongBuffer here is that it\n    // wastes very little memory if the index is in random order but can save\n    // a lot of memory if the index is already \"almost\" sorted\n    final PackedLongValues.Builder newToOldBuilder = PackedLongValues.monotonicBuilder(PackedInts.COMPACT);\n    for (int i = 0; i < maxDoc; ++i) {\n      newToOldBuilder.add(docs[i]);\n    }\n    final PackedLongValues newToOld = newToOldBuilder.build();\n\n    // invert the docs mapping:\n    for (int i = 0; i < maxDoc; ++i) {\n      docs[(int) newToOld.get(i)] = i;\n    } // docs is now the oldToNew mapping\n\n    final PackedLongValues.Builder oldToNewBuilder = PackedLongValues.monotonicBuilder(PackedInts.COMPACT);\n    for (int i = 0; i < maxDoc; ++i) {\n      oldToNewBuilder.add(docs[i]);\n    }\n    final PackedLongValues oldToNew = oldToNewBuilder.build();\n    \n    return new Sorter.DocMap() {\n\n      @Override\n      public int oldToNew(int docID) {\n        return (int) oldToNew.get(docID);\n      }\n\n      @Override\n      public int newToOld(int docID) {\n        return (int) newToOld.get(docID);\n      }\n\n      @Override\n      public int size() {\n        return maxDoc;\n      }\n    };\n  }\n\n","sourceOld":"  /** Computes the old-to-new permutation over the given comparator. */\n  private static Sorter.DocMap sort(final int maxDoc, DocComparator comparator) {\n    // check if the index is sorted\n    boolean sorted = true;\n    for (int i = 1; i < maxDoc; ++i) {\n      if (comparator.compare(i-1, i) > 0) {\n        sorted = false;\n        break;\n      }\n    }\n    if (sorted) {\n      return null;\n    }\n\n    // sort doc IDs\n    final int[] docs = new int[maxDoc];\n    for (int i = 0; i < maxDoc; i++) {\n      docs[i] = i;\n    }\n    \n    DocValueSorter sorter = new DocValueSorter(docs, comparator);\n    // It can be common to sort a reader, add docs, sort it again, ... and in\n    // that case timSort can save a lot of time\n    sorter.sort(0, docs.length); // docs is now the newToOld mapping\n\n    // The reason why we use MonotonicAppendingLongBuffer here is that it\n    // wastes very little memory if the index is in random order but can save\n    // a lot of memory if the index is already \"almost\" sorted\n    final PackedLongValues.Builder newToOldBuilder = PackedLongValues.monotonicBuilder(PackedInts.COMPACT);\n    for (int i = 0; i < maxDoc; ++i) {\n      newToOldBuilder.add(docs[i]);\n    }\n    final PackedLongValues newToOld = newToOldBuilder.build();\n\n    // invert the docs mapping:\n    for (int i = 0; i < maxDoc; ++i) {\n      docs[(int) newToOld.get(i)] = i;\n    } // docs is now the oldToNew mapping\n\n    final PackedLongValues.Builder oldToNewBuilder = PackedLongValues.monotonicBuilder(PackedInts.COMPACT);\n    for (int i = 0; i < maxDoc; ++i) {\n      oldToNewBuilder.add(docs[i]);\n    }\n    final PackedLongValues oldToNew = oldToNewBuilder.build();\n    \n    return new Sorter.DocMap() {\n\n      @Override\n      public int oldToNew(int docID) {\n        return (int) oldToNew.get(docID);\n      }\n\n      @Override\n      public int newToOld(int docID) {\n        return (int) newToOld.get(docID);\n      }\n\n      @Override\n      public int size() {\n        return maxDoc;\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"773bf150032d3ef6c95997a154fb914b82875cb8":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["773bf150032d3ef6c95997a154fb914b82875cb8"]},"commit2Childs":{"773bf150032d3ef6c95997a154fb914b82875cb8":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["773bf150032d3ef6c95997a154fb914b82875cb8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}