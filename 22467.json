{"path":"lucene/core/src/java/org/apache/lucene/codecs/block/BlockPostingsWriter#BlockPostingsWriter(SegmentWriteState,float).mjava","commits":[{"id":"e6b41208259e8566cba0ecac7da6a331ea9732dd","date":1344551376,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/block/BlockPostingsWriter#BlockPostingsWriter(SegmentWriteState,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/blockpacked/BlockPackedPostingsWriter#BlockPackedPostingsWriter(SegmentWriteState,float).mjava","sourceNew":"  public BlockPostingsWriter(SegmentWriteState state, float acceptableOverheadRatio) throws IOException {\n    super();\n\n    docOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPostingsFormat.DOC_EXTENSION),\n                                          state.context);\n    IndexOutput posOut = null;\n    IndexOutput payOut = null;\n    boolean success = false;\n    try {\n      CodecUtil.writeHeader(docOut, DOC_CODEC, VERSION_CURRENT);\n      forUtil = new ForUtil(acceptableOverheadRatio, docOut);\n      if (state.fieldInfos.hasProx()) {\n        posDeltaBuffer = new int[MAX_DATA_SIZE];\n        posOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPostingsFormat.POS_EXTENSION),\n                                              state.context);\n        CodecUtil.writeHeader(posOut, POS_CODEC, VERSION_CURRENT);\n\n        if (state.fieldInfos.hasPayloads()) {\n          payloadBytes = new byte[128];\n          payloadLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          payloadBytes = null;\n          payloadLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasOffsets()) {\n          offsetStartDeltaBuffer = new int[MAX_DATA_SIZE];\n          offsetLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          offsetStartDeltaBuffer = null;\n          offsetLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasPayloads() || state.fieldInfos.hasOffsets()) {\n          payOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPostingsFormat.PAY_EXTENSION),\n                                                state.context);\n          CodecUtil.writeHeader(payOut, PAY_CODEC, VERSION_CURRENT);\n        }\n      } else {\n        posDeltaBuffer = null;\n        payloadLengthBuffer = null;\n        offsetStartDeltaBuffer = null;\n        offsetLengthBuffer = null;\n        payloadBytes = null;\n      }\n      this.payOut = payOut;\n      this.posOut = posOut;\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(docOut, posOut, payOut);\n      }\n    }\n\n    docDeltaBuffer = new int[MAX_DATA_SIZE];\n    freqBuffer = new int[MAX_DATA_SIZE];\n\n    // nocommit should we try skipping every 2/4 blocks...?\n    skipWriter = new BlockSkipWriter(maxSkipLevels,\n                                     BLOCK_SIZE, \n                                     state.segmentInfo.getDocCount(),\n                                     docOut,\n                                     posOut,\n                                     payOut);\n\n    encoded = new byte[MAX_ENCODED_SIZE];\n  }\n\n","sourceOld":"  public BlockPackedPostingsWriter(SegmentWriteState state, float acceptableOverheadRatio) throws IOException {\n    super();\n\n    docOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPackedPostingsFormat.DOC_EXTENSION),\n                                          state.context);\n    IndexOutput posOut = null;\n    IndexOutput payOut = null;\n    boolean success = false;\n    try {\n      CodecUtil.writeHeader(docOut, DOC_CODEC, VERSION_CURRENT);\n      forUtil = new ForUtil(acceptableOverheadRatio, docOut);\n      if (state.fieldInfos.hasProx()) {\n        posDeltaBuffer = new int[MAX_DATA_SIZE];\n        posOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPackedPostingsFormat.POS_EXTENSION),\n                                              state.context);\n        CodecUtil.writeHeader(posOut, POS_CODEC, VERSION_CURRENT);\n\n        if (state.fieldInfos.hasPayloads()) {\n          payloadBytes = new byte[128];\n          payloadLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          payloadBytes = null;\n          payloadLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasOffsets()) {\n          offsetStartDeltaBuffer = new int[MAX_DATA_SIZE];\n          offsetLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          offsetStartDeltaBuffer = null;\n          offsetLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasPayloads() || state.fieldInfos.hasOffsets()) {\n          payOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPackedPostingsFormat.PAY_EXTENSION),\n                                                state.context);\n          CodecUtil.writeHeader(payOut, PAY_CODEC, VERSION_CURRENT);\n        }\n      } else {\n        posDeltaBuffer = null;\n        payloadLengthBuffer = null;\n        offsetStartDeltaBuffer = null;\n        offsetLengthBuffer = null;\n        payloadBytes = null;\n      }\n      this.payOut = payOut;\n      this.posOut = posOut;\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(docOut, posOut, payOut);\n      }\n    }\n\n    docDeltaBuffer = new int[MAX_DATA_SIZE];\n    freqBuffer = new int[MAX_DATA_SIZE];\n\n    // nocommit should we try skipping every 2/4 blocks...?\n    skipWriter = new BlockPackedSkipWriter(maxSkipLevels,\n                                     BlockPackedPostingsFormat.BLOCK_SIZE, \n                                     state.segmentInfo.getDocCount(),\n                                     docOut,\n                                     posOut,\n                                     payOut);\n\n    encoded = new byte[MAX_ENCODED_SIZE];\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"007463e97416788017c563017736002c3f72ea73","date":1344616184,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/block/BlockPostingsWriter#BlockPostingsWriter(SegmentWriteState,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/block/BlockPostingsWriter#BlockPostingsWriter(SegmentWriteState,float).mjava","sourceNew":"  public BlockPostingsWriter(SegmentWriteState state, float acceptableOverheadRatio) throws IOException {\n    super();\n\n    docOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPostingsFormat.DOC_EXTENSION),\n                                          state.context);\n    IndexOutput posOut = null;\n    IndexOutput payOut = null;\n    boolean success = false;\n    try {\n      CodecUtil.writeHeader(docOut, DOC_CODEC, VERSION_CURRENT);\n      forUtil = new ForUtil(acceptableOverheadRatio, docOut);\n      if (state.fieldInfos.hasProx()) {\n        posDeltaBuffer = new int[MAX_DATA_SIZE];\n        posOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPostingsFormat.POS_EXTENSION),\n                                              state.context);\n        CodecUtil.writeHeader(posOut, POS_CODEC, VERSION_CURRENT);\n\n        if (state.fieldInfos.hasPayloads()) {\n          payloadBytes = new byte[128];\n          payloadLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          payloadBytes = null;\n          payloadLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasOffsets()) {\n          offsetStartDeltaBuffer = new int[MAX_DATA_SIZE];\n          offsetLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          offsetStartDeltaBuffer = null;\n          offsetLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasPayloads() || state.fieldInfos.hasOffsets()) {\n          payOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPostingsFormat.PAY_EXTENSION),\n                                                state.context);\n          CodecUtil.writeHeader(payOut, PAY_CODEC, VERSION_CURRENT);\n        }\n      } else {\n        posDeltaBuffer = null;\n        payloadLengthBuffer = null;\n        offsetStartDeltaBuffer = null;\n        offsetLengthBuffer = null;\n        payloadBytes = null;\n      }\n      this.payOut = payOut;\n      this.posOut = posOut;\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(docOut, posOut, payOut);\n      }\n    }\n\n    docDeltaBuffer = new int[MAX_DATA_SIZE];\n    freqBuffer = new int[MAX_DATA_SIZE];\n\n    // TODO: should we try skipping every 2/4 blocks...?\n    skipWriter = new BlockSkipWriter(maxSkipLevels,\n                                     BLOCK_SIZE, \n                                     state.segmentInfo.getDocCount(),\n                                     docOut,\n                                     posOut,\n                                     payOut);\n\n    encoded = new byte[MAX_ENCODED_SIZE];\n  }\n\n","sourceOld":"  public BlockPostingsWriter(SegmentWriteState state, float acceptableOverheadRatio) throws IOException {\n    super();\n\n    docOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPostingsFormat.DOC_EXTENSION),\n                                          state.context);\n    IndexOutput posOut = null;\n    IndexOutput payOut = null;\n    boolean success = false;\n    try {\n      CodecUtil.writeHeader(docOut, DOC_CODEC, VERSION_CURRENT);\n      forUtil = new ForUtil(acceptableOverheadRatio, docOut);\n      if (state.fieldInfos.hasProx()) {\n        posDeltaBuffer = new int[MAX_DATA_SIZE];\n        posOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPostingsFormat.POS_EXTENSION),\n                                              state.context);\n        CodecUtil.writeHeader(posOut, POS_CODEC, VERSION_CURRENT);\n\n        if (state.fieldInfos.hasPayloads()) {\n          payloadBytes = new byte[128];\n          payloadLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          payloadBytes = null;\n          payloadLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasOffsets()) {\n          offsetStartDeltaBuffer = new int[MAX_DATA_SIZE];\n          offsetLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          offsetStartDeltaBuffer = null;\n          offsetLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasPayloads() || state.fieldInfos.hasOffsets()) {\n          payOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPostingsFormat.PAY_EXTENSION),\n                                                state.context);\n          CodecUtil.writeHeader(payOut, PAY_CODEC, VERSION_CURRENT);\n        }\n      } else {\n        posDeltaBuffer = null;\n        payloadLengthBuffer = null;\n        offsetStartDeltaBuffer = null;\n        offsetLengthBuffer = null;\n        payloadBytes = null;\n      }\n      this.payOut = payOut;\n      this.posOut = posOut;\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(docOut, posOut, payOut);\n      }\n    }\n\n    docDeltaBuffer = new int[MAX_DATA_SIZE];\n    freqBuffer = new int[MAX_DATA_SIZE];\n\n    // nocommit should we try skipping every 2/4 blocks...?\n    skipWriter = new BlockSkipWriter(maxSkipLevels,\n                                     BLOCK_SIZE, \n                                     state.segmentInfo.getDocCount(),\n                                     docOut,\n                                     posOut,\n                                     payOut);\n\n    encoded = new byte[MAX_ENCODED_SIZE];\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8615860cb50aefb8eebca1d1b3893dbe21cf126","date":1345550448,"type":0,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/block/BlockPostingsWriter#BlockPostingsWriter(SegmentWriteState,float).mjava","pathOld":"/dev/null","sourceNew":"  public BlockPostingsWriter(SegmentWriteState state, float acceptableOverheadRatio) throws IOException {\n    super();\n\n    docOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPostingsFormat.DOC_EXTENSION),\n                                          state.context);\n    IndexOutput posOut = null;\n    IndexOutput payOut = null;\n    boolean success = false;\n    try {\n      CodecUtil.writeHeader(docOut, DOC_CODEC, VERSION_CURRENT);\n      forUtil = new ForUtil(acceptableOverheadRatio, docOut);\n      if (state.fieldInfos.hasProx()) {\n        posDeltaBuffer = new int[MAX_DATA_SIZE];\n        posOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPostingsFormat.POS_EXTENSION),\n                                              state.context);\n        CodecUtil.writeHeader(posOut, POS_CODEC, VERSION_CURRENT);\n\n        if (state.fieldInfos.hasPayloads()) {\n          payloadBytes = new byte[128];\n          payloadLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          payloadBytes = null;\n          payloadLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasOffsets()) {\n          offsetStartDeltaBuffer = new int[MAX_DATA_SIZE];\n          offsetLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          offsetStartDeltaBuffer = null;\n          offsetLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasPayloads() || state.fieldInfos.hasOffsets()) {\n          payOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPostingsFormat.PAY_EXTENSION),\n                                                state.context);\n          CodecUtil.writeHeader(payOut, PAY_CODEC, VERSION_CURRENT);\n        }\n      } else {\n        posDeltaBuffer = null;\n        payloadLengthBuffer = null;\n        offsetStartDeltaBuffer = null;\n        offsetLengthBuffer = null;\n        payloadBytes = null;\n      }\n      this.payOut = payOut;\n      this.posOut = posOut;\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(docOut, posOut, payOut);\n      }\n    }\n\n    docDeltaBuffer = new int[MAX_DATA_SIZE];\n    freqBuffer = new int[MAX_DATA_SIZE];\n\n    // TODO: should we try skipping every 2/4 blocks...?\n    skipWriter = new BlockSkipWriter(maxSkipLevels,\n                                     BLOCK_SIZE, \n                                     state.segmentInfo.getDocCount(),\n                                     docOut,\n                                     posOut,\n                                     payOut);\n\n    encoded = new byte[MAX_ENCODED_SIZE];\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"001b25b42373b22a52f399dbf072f1224632e8e6","date":1345889167,"type":0,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/block/BlockPostingsWriter#BlockPostingsWriter(SegmentWriteState,float).mjava","pathOld":"/dev/null","sourceNew":"  public BlockPostingsWriter(SegmentWriteState state, float acceptableOverheadRatio) throws IOException {\n    super();\n\n    docOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPostingsFormat.DOC_EXTENSION),\n                                          state.context);\n    IndexOutput posOut = null;\n    IndexOutput payOut = null;\n    boolean success = false;\n    try {\n      CodecUtil.writeHeader(docOut, DOC_CODEC, VERSION_CURRENT);\n      forUtil = new ForUtil(acceptableOverheadRatio, docOut);\n      if (state.fieldInfos.hasProx()) {\n        posDeltaBuffer = new int[MAX_DATA_SIZE];\n        posOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPostingsFormat.POS_EXTENSION),\n                                              state.context);\n        CodecUtil.writeHeader(posOut, POS_CODEC, VERSION_CURRENT);\n\n        if (state.fieldInfos.hasPayloads()) {\n          payloadBytes = new byte[128];\n          payloadLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          payloadBytes = null;\n          payloadLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasOffsets()) {\n          offsetStartDeltaBuffer = new int[MAX_DATA_SIZE];\n          offsetLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          offsetStartDeltaBuffer = null;\n          offsetLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasPayloads() || state.fieldInfos.hasOffsets()) {\n          payOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPostingsFormat.PAY_EXTENSION),\n                                                state.context);\n          CodecUtil.writeHeader(payOut, PAY_CODEC, VERSION_CURRENT);\n        }\n      } else {\n        posDeltaBuffer = null;\n        payloadLengthBuffer = null;\n        offsetStartDeltaBuffer = null;\n        offsetLengthBuffer = null;\n        payloadBytes = null;\n      }\n      this.payOut = payOut;\n      this.posOut = posOut;\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(docOut, posOut, payOut);\n      }\n    }\n\n    docDeltaBuffer = new int[MAX_DATA_SIZE];\n    freqBuffer = new int[MAX_DATA_SIZE];\n\n    // TODO: should we try skipping every 2/4 blocks...?\n    skipWriter = new BlockSkipWriter(maxSkipLevels,\n                                     BLOCK_SIZE, \n                                     state.segmentInfo.getDocCount(),\n                                     docOut,\n                                     posOut,\n                                     payOut);\n\n    encoded = new byte[MAX_ENCODED_SIZE];\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3e45d45bc3730ddd1341f4eb6025f33b8482e6e2","date":1346834651,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/block/BlockPostingsWriter#BlockPostingsWriter(SegmentWriteState,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/block/BlockPostingsWriter#BlockPostingsWriter(SegmentWriteState,float).mjava","sourceNew":"  public BlockPostingsWriter(SegmentWriteState state, float acceptableOverheadRatio) throws IOException {\n    super();\n\n    docOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPostingsFormat.DOC_EXTENSION),\n                                          state.context);\n    IndexOutput posOut = null;\n    IndexOutput payOut = null;\n    boolean success = false;\n    try {\n      CodecUtil.writeHeader(docOut, DOC_CODEC, VERSION_CURRENT);\n      forUtil = new ForUtil(acceptableOverheadRatio, docOut);\n      if (state.fieldInfos.hasProx()) {\n        posDeltaBuffer = new int[MAX_DATA_SIZE];\n        posOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPostingsFormat.POS_EXTENSION),\n                                              state.context);\n        CodecUtil.writeHeader(posOut, POS_CODEC, VERSION_CURRENT);\n\n        if (state.fieldInfos.hasPayloads()) {\n          payloadBytes = new byte[128];\n          payloadLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          payloadBytes = null;\n          payloadLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasOffsets()) {\n          offsetStartDeltaBuffer = new int[MAX_DATA_SIZE];\n          offsetLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          offsetStartDeltaBuffer = null;\n          offsetLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasPayloads() || state.fieldInfos.hasOffsets()) {\n          payOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPostingsFormat.PAY_EXTENSION),\n                                                state.context);\n          CodecUtil.writeHeader(payOut, PAY_CODEC, VERSION_CURRENT);\n        }\n      } else {\n        posDeltaBuffer = null;\n        payloadLengthBuffer = null;\n        offsetStartDeltaBuffer = null;\n        offsetLengthBuffer = null;\n        payloadBytes = null;\n      }\n      this.payOut = payOut;\n      this.posOut = posOut;\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(docOut, posOut, payOut);\n      }\n    }\n\n    docDeltaBuffer = new int[MAX_DATA_SIZE];\n    freqBuffer = new int[MAX_DATA_SIZE];\n\n    // TODO: should we try skipping every 2/4 blocks...?\n    skipWriter = new BlockSkipWriter(maxSkipLevels,\n                                     BLOCK_SIZE, \n                                     state.segmentInfo.getDocCount(),\n                                     docOut,\n                                     posOut,\n                                     payOut);\n\n    encoded = new byte[MAX_ENCODED_SIZE];\n  }\n\n","sourceOld":"  public BlockPostingsWriter(SegmentWriteState state, float acceptableOverheadRatio) throws IOException {\n    super();\n\n    docOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPostingsFormat.DOC_EXTENSION),\n                                          state.context);\n    IndexOutput posOut = null;\n    IndexOutput payOut = null;\n    boolean success = false;\n    try {\n      CodecUtil.writeHeader(docOut, DOC_CODEC, VERSION_CURRENT);\n      forUtil = new ForUtil(acceptableOverheadRatio, docOut);\n      if (state.fieldInfos.hasProx()) {\n        posDeltaBuffer = new int[MAX_DATA_SIZE];\n        posOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPostingsFormat.POS_EXTENSION),\n                                              state.context);\n        CodecUtil.writeHeader(posOut, POS_CODEC, VERSION_CURRENT);\n\n        if (state.fieldInfos.hasPayloads()) {\n          payloadBytes = new byte[128];\n          payloadLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          payloadBytes = null;\n          payloadLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasOffsets()) {\n          offsetStartDeltaBuffer = new int[MAX_DATA_SIZE];\n          offsetLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          offsetStartDeltaBuffer = null;\n          offsetLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasPayloads() || state.fieldInfos.hasOffsets()) {\n          payOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPostingsFormat.PAY_EXTENSION),\n                                                state.context);\n          CodecUtil.writeHeader(payOut, PAY_CODEC, VERSION_CURRENT);\n        }\n      } else {\n        posDeltaBuffer = null;\n        payloadLengthBuffer = null;\n        offsetStartDeltaBuffer = null;\n        offsetLengthBuffer = null;\n        payloadBytes = null;\n      }\n      this.payOut = payOut;\n      this.posOut = posOut;\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(docOut, posOut, payOut);\n      }\n    }\n\n    docDeltaBuffer = new int[MAX_DATA_SIZE];\n    freqBuffer = new int[MAX_DATA_SIZE];\n\n    // TODO: should we try skipping every 2/4 blocks...?\n    skipWriter = new BlockSkipWriter(maxSkipLevels,\n                                     BLOCK_SIZE, \n                                     state.segmentInfo.getDocCount(),\n                                     docOut,\n                                     posOut,\n                                     payOut);\n\n    encoded = new byte[MAX_ENCODED_SIZE];\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"007463e97416788017c563017736002c3f72ea73":["e6b41208259e8566cba0ecac7da6a331ea9732dd"],"001b25b42373b22a52f399dbf072f1224632e8e6":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","f8615860cb50aefb8eebca1d1b3893dbe21cf126"],"3e45d45bc3730ddd1341f4eb6025f33b8482e6e2":["f8615860cb50aefb8eebca1d1b3893dbe21cf126"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"f8615860cb50aefb8eebca1d1b3893dbe21cf126":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","007463e97416788017c563017736002c3f72ea73"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3e45d45bc3730ddd1341f4eb6025f33b8482e6e2"],"e6b41208259e8566cba0ecac7da6a331ea9732dd":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"007463e97416788017c563017736002c3f72ea73":["f8615860cb50aefb8eebca1d1b3893dbe21cf126"],"001b25b42373b22a52f399dbf072f1224632e8e6":[],"3e45d45bc3730ddd1341f4eb6025f33b8482e6e2":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["001b25b42373b22a52f399dbf072f1224632e8e6","f8615860cb50aefb8eebca1d1b3893dbe21cf126","e6b41208259e8566cba0ecac7da6a331ea9732dd"],"f8615860cb50aefb8eebca1d1b3893dbe21cf126":["001b25b42373b22a52f399dbf072f1224632e8e6","3e45d45bc3730ddd1341f4eb6025f33b8482e6e2"],"e6b41208259e8566cba0ecac7da6a331ea9732dd":["007463e97416788017c563017736002c3f72ea73"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["001b25b42373b22a52f399dbf072f1224632e8e6","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}