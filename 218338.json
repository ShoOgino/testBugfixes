{"path":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadTermQuery#testMultipleMatchesPerDoc().mjava","commits":[{"id":"eeab49258a6aca6c7e96aaf189f1794fe6ddebe4","date":1442407411,"type":1,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadTermQuery#testMultipleMatchesPerDoc().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testMultipleMatchesPerDoc().mjava","sourceNew":"  public void testMultipleMatchesPerDoc() throws Exception {\n    SpanQuery query = new PayloadScoreQuery(new SpanTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\")),\n            new MaxPayloadFunction());\n    TopDocs hits = searcher.search(query, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = MultiSpansWrapper.wrap(searcher.getIndexReader(), query);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n      while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n        count++;\n      }\n    }\n    assertTrue(count + \" does not equal: \" + 200, count == 200);\n  }\n\n","sourceOld":"  public void testMultipleMatchesPerDoc() throws Exception {\n    SpanQuery query = new PayloadScoreQuery(new SpanTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\")),\n            new MaxPayloadFunction());\n    TopDocs hits = searcher.search(query, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = MultiSpansWrapper.wrap(searcher.getIndexReader(), query);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n      while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n        count++;\n      }\n    }\n    assertTrue(count + \" does not equal: \" + 200, count == 200);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1","date":1457644139,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadTermQuery#testMultipleMatchesPerDoc().mjava","pathOld":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadTermQuery#testMultipleMatchesPerDoc().mjava","sourceNew":"  public void testMultipleMatchesPerDoc() throws Exception {\n    SpanQuery query = new PayloadScoreQuery(new SpanTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\")),\n            new MaxPayloadFunction());\n    TopDocs hits = searcher.search(query, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.createWeight(searcher, false).getSpans(searcher.getIndexReader().leaves().get(0), SpanWeight.Postings.POSITIONS);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n      while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n        count++;\n      }\n    }\n    assertTrue(count + \" does not equal: \" + 200, count == 200);\n  }\n\n","sourceOld":"  public void testMultipleMatchesPerDoc() throws Exception {\n    SpanQuery query = new PayloadScoreQuery(new SpanTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\")),\n            new MaxPayloadFunction());\n    TopDocs hits = searcher.search(query, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = MultiSpansWrapper.wrap(searcher.getIndexReader(), query);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n      while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n        count++;\n      }\n    }\n    assertTrue(count + \" does not equal: \" + 200, count == 200);\n  }\n\n","bugFix":["30de45e50bdc1a79a6797f34dca6271c8866cb6e"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"02e175abd2c4c1611c5a9647486ae8ba249a94c1","date":1468327116,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadTermQuery#testMultipleMatchesPerDoc().mjava","pathOld":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadTermQuery#testMultipleMatchesPerDoc().mjava","sourceNew":"  public void testMultipleMatchesPerDoc() throws Exception {\n    SpanQuery query = new PayloadScoreQuery(new SpanTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\")),\n            new MaxPayloadFunction());\n    TopDocs hits = searcher.search(query, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.createWeight(searcher, false, 1f).getSpans(searcher.getIndexReader().leaves().get(0), SpanWeight.Postings.POSITIONS);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n      while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n        count++;\n      }\n    }\n    assertTrue(count + \" does not equal: \" + 200, count == 200);\n  }\n\n","sourceOld":"  public void testMultipleMatchesPerDoc() throws Exception {\n    SpanQuery query = new PayloadScoreQuery(new SpanTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\")),\n            new MaxPayloadFunction());\n    TopDocs hits = searcher.search(query, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.createWeight(searcher, false).getSpans(searcher.getIndexReader().leaves().get(0), SpanWeight.Postings.POSITIONS);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n      while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n        count++;\n      }\n    }\n    assertTrue(count + \" does not equal: \" + 200, count == 200);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadTermQuery#testMultipleMatchesPerDoc().mjava","pathOld":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadTermQuery#testMultipleMatchesPerDoc().mjava","sourceNew":"  public void testMultipleMatchesPerDoc() throws Exception {\n    SpanQuery query = new PayloadScoreQuery(new SpanTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\")),\n            new MaxPayloadFunction());\n    TopDocs hits = searcher.search(query, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.createWeight(searcher, false, 1f).getSpans(searcher.getIndexReader().leaves().get(0), SpanWeight.Postings.POSITIONS);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n      while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n        count++;\n      }\n    }\n    assertTrue(count + \" does not equal: \" + 200, count == 200);\n  }\n\n","sourceOld":"  public void testMultipleMatchesPerDoc() throws Exception {\n    SpanQuery query = new PayloadScoreQuery(new SpanTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\")),\n            new MaxPayloadFunction());\n    TopDocs hits = searcher.search(query, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.createWeight(searcher, false).getSpans(searcher.getIndexReader().leaves().get(0), SpanWeight.Postings.POSITIONS);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n      while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n        count++;\n      }\n    }\n    assertTrue(count + \" does not equal: \" + 200, count == 200);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4d9b8e4987e93a0ea580f91defdc31ce5dd572e2","date":1510236334,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadTermQuery#testMultipleMatchesPerDoc().mjava","pathOld":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadTermQuery#testMultipleMatchesPerDoc().mjava","sourceNew":"  public void testMultipleMatchesPerDoc() throws Exception {\n    SpanQuery query = new PayloadScoreQuery(new SpanTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\")),\n            new MaxPayloadFunction(), PayloadDecoder.FLOAT_DECODER);\n    TopDocs hits = searcher.search(query, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.createWeight(searcher, false, 1f).getSpans(searcher.getIndexReader().leaves().get(0), SpanWeight.Postings.POSITIONS);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n      while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n        count++;\n      }\n    }\n    assertTrue(count + \" does not equal: \" + 200, count == 200);\n  }\n\n","sourceOld":"  public void testMultipleMatchesPerDoc() throws Exception {\n    SpanQuery query = new PayloadScoreQuery(new SpanTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\")),\n            new MaxPayloadFunction());\n    TopDocs hits = searcher.search(query, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.createWeight(searcher, false, 1f).getSpans(searcher.getIndexReader().leaves().get(0), SpanWeight.Postings.POSITIONS);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n      while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n        count++;\n      }\n    }\n    assertTrue(count + \" does not equal: \" + 200, count == 200);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9fc47cb7b4346802411bb432f501ed0673d7119e","date":1512640179,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadTermQuery#testMultipleMatchesPerDoc().mjava","pathOld":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadTermQuery#testMultipleMatchesPerDoc().mjava","sourceNew":"  public void testMultipleMatchesPerDoc() throws Exception {\n    SpanQuery query = new PayloadScoreQuery(new SpanTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\")),\n            new MaxPayloadFunction(), PayloadDecoder.FLOAT_DECODER);\n    TopDocs hits = searcher.search(query, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.createWeight(searcher, ScoreMode.COMPLETE_NO_SCORES, 1f).getSpans(searcher.getIndexReader().leaves().get(0), SpanWeight.Postings.POSITIONS);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n      while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n        count++;\n      }\n    }\n    assertTrue(count + \" does not equal: \" + 200, count == 200);\n  }\n\n","sourceOld":"  public void testMultipleMatchesPerDoc() throws Exception {\n    SpanQuery query = new PayloadScoreQuery(new SpanTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\")),\n            new MaxPayloadFunction(), PayloadDecoder.FLOAT_DECODER);\n    TopDocs hits = searcher.search(query, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.createWeight(searcher, false, 1f).getSpans(searcher.getIndexReader().leaves().get(0), SpanWeight.Postings.POSITIONS);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n      while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n        count++;\n      }\n    }\n    assertTrue(count + \" does not equal: \" + 200, count == 200);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"417142ff08fda9cf0b72d5133e63097a166c6458","date":1512729693,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadTermQuery#testMultipleMatchesPerDoc().mjava","pathOld":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadTermQuery#testMultipleMatchesPerDoc().mjava","sourceNew":"  public void testMultipleMatchesPerDoc() throws Exception {\n    SpanQuery query = new PayloadScoreQuery(new SpanTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\")),\n            new MaxPayloadFunction(), PayloadDecoder.FLOAT_DECODER);\n    TopDocs hits = searcher.search(query, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.createWeight(searcher, ScoreMode.COMPLETE_NO_SCORES, 1f).getSpans(searcher.getIndexReader().leaves().get(0), SpanWeight.Postings.POSITIONS);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n      while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n        count++;\n      }\n    }\n    assertTrue(count + \" does not equal: \" + 200, count == 200);\n  }\n\n","sourceOld":"  public void testMultipleMatchesPerDoc() throws Exception {\n    SpanQuery query = new PayloadScoreQuery(new SpanTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\")),\n            new MaxPayloadFunction(), PayloadDecoder.FLOAT_DECODER);\n    TopDocs hits = searcher.search(query, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.createWeight(searcher, false, 1f).getSpans(searcher.getIndexReader().leaves().get(0), SpanWeight.Postings.POSITIONS);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n      while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n        count++;\n      }\n    }\n    assertTrue(count + \" does not equal: \" + 200, count == 200);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"81fff83bdb893c1471efd78f6a9a3ce4f98120b9","date":1531895937,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadTermQuery#testMultipleMatchesPerDoc().mjava","pathOld":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadTermQuery#testMultipleMatchesPerDoc().mjava","sourceNew":"  public void testMultipleMatchesPerDoc() throws Exception {\n    SpanQuery query = new PayloadScoreQuery(new SpanTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\")),\n            new MaxPayloadFunction(), PayloadDecoder.FLOAT_DECODER);\n    TopDocs hits = searcher.search(query, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.createWeight(searcher, ScoreMode.COMPLETE_NO_SCORES, 1f).getSpans(searcher.getIndexReader().leaves().get(0), SpanWeight.Postings.POSITIONS);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n      while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n        count++;\n      }\n    }\n    assertTrue(count + \" does not equal: \" + 200, count == 200);\n  }\n\n","sourceOld":"  public void testMultipleMatchesPerDoc() throws Exception {\n    SpanQuery query = new PayloadScoreQuery(new SpanTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\")),\n            new MaxPayloadFunction(), PayloadDecoder.FLOAT_DECODER);\n    TopDocs hits = searcher.search(query, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.createWeight(searcher, ScoreMode.COMPLETE_NO_SCORES, 1f).getSpans(searcher.getIndexReader().leaves().get(0), SpanWeight.Postings.POSITIONS);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n      while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n        count++;\n      }\n    }\n    assertTrue(count + \" does not equal: \" + 200, count == 200);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadTermQuery#testMultipleMatchesPerDoc().mjava","pathOld":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadTermQuery#testMultipleMatchesPerDoc().mjava","sourceNew":"  public void testMultipleMatchesPerDoc() throws Exception {\n    SpanQuery query = new PayloadScoreQuery(new SpanTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\")),\n            new MaxPayloadFunction(), PayloadDecoder.FLOAT_DECODER);\n    TopDocs hits = searcher.search(query, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.createWeight(searcher, ScoreMode.COMPLETE_NO_SCORES, 1f).getSpans(searcher.getIndexReader().leaves().get(0), SpanWeight.Postings.POSITIONS);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n      while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n        count++;\n      }\n    }\n    assertTrue(count + \" does not equal: \" + 200, count == 200);\n  }\n\n","sourceOld":"  public void testMultipleMatchesPerDoc() throws Exception {\n    SpanQuery query = new PayloadScoreQuery(new SpanTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\")),\n            new MaxPayloadFunction(), PayloadDecoder.FLOAT_DECODER);\n    TopDocs hits = searcher.search(query, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.createWeight(searcher, ScoreMode.COMPLETE_NO_SCORES, 1f).getSpans(searcher.getIndexReader().leaves().get(0), SpanWeight.Postings.POSITIONS);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n      while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n        count++;\n      }\n    }\n    assertTrue(count + \" does not equal: \" + 200, count == 200);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"83788ad129a5154d5c6562c4e8ce3db48793aada","date":1532961485,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadTermQuery#testMultipleMatchesPerDoc().mjava","pathOld":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadTermQuery#testMultipleMatchesPerDoc().mjava","sourceNew":"  public void testMultipleMatchesPerDoc() throws Exception {\n    SpanQuery query = new PayloadScoreQuery(new SpanTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\")),\n            new MaxPayloadFunction(), PayloadDecoder.FLOAT_DECODER);\n    TopDocs hits = searcher.search(query, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits.value + \" is not: \" + 100, hits.totalHits.value == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.createWeight(searcher, ScoreMode.COMPLETE_NO_SCORES, 1f).getSpans(searcher.getIndexReader().leaves().get(0), SpanWeight.Postings.POSITIONS);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n      while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n        count++;\n      }\n    }\n    assertTrue(count + \" does not equal: \" + 200, count == 200);\n  }\n\n","sourceOld":"  public void testMultipleMatchesPerDoc() throws Exception {\n    SpanQuery query = new PayloadScoreQuery(new SpanTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\")),\n            new MaxPayloadFunction(), PayloadDecoder.FLOAT_DECODER);\n    TopDocs hits = searcher.search(query, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.createWeight(searcher, ScoreMode.COMPLETE_NO_SCORES, 1f).getSpans(searcher.getIndexReader().leaves().get(0), SpanWeight.Postings.POSITIONS);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n      while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n        count++;\n      }\n    }\n    assertTrue(count + \" does not equal: \" + 200, count == 200);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1":["eeab49258a6aca6c7e96aaf189f1794fe6ddebe4"],"eeab49258a6aca6c7e96aaf189f1794fe6ddebe4":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["417142ff08fda9cf0b72d5133e63097a166c6458","81fff83bdb893c1471efd78f6a9a3ce4f98120b9"],"4d9b8e4987e93a0ea580f91defdc31ce5dd572e2":["02e175abd2c4c1611c5a9647486ae8ba249a94c1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"02e175abd2c4c1611c5a9647486ae8ba249a94c1":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["81fff83bdb893c1471efd78f6a9a3ce4f98120b9"],"81fff83bdb893c1471efd78f6a9a3ce4f98120b9":["417142ff08fda9cf0b72d5133e63097a166c6458"],"9fc47cb7b4346802411bb432f501ed0673d7119e":["4d9b8e4987e93a0ea580f91defdc31ce5dd572e2"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1","02e175abd2c4c1611c5a9647486ae8ba249a94c1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["83788ad129a5154d5c6562c4e8ce3db48793aada"],"417142ff08fda9cf0b72d5133e63097a166c6458":["4d9b8e4987e93a0ea580f91defdc31ce5dd572e2","9fc47cb7b4346802411bb432f501ed0673d7119e"]},"commit2Childs":{"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1":["02e175abd2c4c1611c5a9647486ae8ba249a94c1","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"eeab49258a6aca6c7e96aaf189f1794fe6ddebe4":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"4d9b8e4987e93a0ea580f91defdc31ce5dd572e2":["9fc47cb7b4346802411bb432f501ed0673d7119e","417142ff08fda9cf0b72d5133e63097a166c6458"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["eeab49258a6aca6c7e96aaf189f1794fe6ddebe4"],"02e175abd2c4c1611c5a9647486ae8ba249a94c1":["4d9b8e4987e93a0ea580f91defdc31ce5dd572e2","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"81fff83bdb893c1471efd78f6a9a3ce4f98120b9":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","83788ad129a5154d5c6562c4e8ce3db48793aada"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"9fc47cb7b4346802411bb432f501ed0673d7119e":["417142ff08fda9cf0b72d5133e63097a166c6458"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"417142ff08fda9cf0b72d5133e63097a166c6458":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","81fff83bdb893c1471efd78f6a9a3ce4f98120b9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}