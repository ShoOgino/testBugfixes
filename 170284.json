{"path":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","commits":[{"id":"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","date":1281646583,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","pathOld":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(PrintWriter,boolean).mjava","sourceNew":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory(random);\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(random, TEST_VERSION_CURRENT, analyzer);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundFiles);\n      lmp.setUseCompoundDocStore(useCompoundFiles);\n      IndexWriter writer = new IndexWriter(directory, conf);\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(new Field(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n\n        // NOTE: this ID_FIELD produces no tokens since\n        // MockAnalyzer discards numbers\n        d.add(new Field(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      Searcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","sourceOld":"  private void doTest(PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = new MockRAMDirectory();\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundFiles);\n      lmp.setUseCompoundDocStore(useCompoundFiles);\n      IndexWriter writer = new IndexWriter(directory, conf);\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(new Field(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n\n        // NOTE: this ID_FIELD produces no tokens since\n        // MockAnalyzer discards numbers\n        d.add(new Field(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      Searcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f653cfcf159baeaafe5d01682a911e95bba4012","date":1284122058,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","pathOld":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","sourceNew":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundFiles);\n      lmp.setUseCompoundDocStore(useCompoundFiles);\n      IndexWriter writer = new IndexWriter(directory, conf);\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(new Field(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n\n        // NOTE: this ID_FIELD produces no tokens since\n        // MockAnalyzer discards numbers\n        d.add(new Field(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      Searcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","sourceOld":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory(random);\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(random, TEST_VERSION_CURRENT, analyzer);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundFiles);\n      lmp.setUseCompoundDocStore(useCompoundFiles);\n      IndexWriter writer = new IndexWriter(directory, conf);\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(new Field(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n\n        // NOTE: this ID_FIELD produces no tokens since\n        // MockAnalyzer discards numbers\n        d.add(new Field(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      Searcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"132903c28af3aa6f67284b78de91c0f0a99488c2","date":1284282129,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","pathOld":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","sourceNew":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundFiles);\n      lmp.setUseCompoundDocStore(useCompoundFiles);\n      IndexWriter writer = new IndexWriter(directory, conf);\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n\n        // NOTE: this ID_FIELD produces no tokens since\n        // MockAnalyzer discards numbers\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      Searcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","sourceOld":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundFiles);\n      lmp.setUseCompoundDocStore(useCompoundFiles);\n      IndexWriter writer = new IndexWriter(directory, conf);\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(new Field(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n\n        // NOTE: this ID_FIELD produces no tokens since\n        // MockAnalyzer discards numbers\n        d.add(new Field(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      Searcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"44fcbde6fb2ac44ee3b45e013e54a42911e689ff","date":1292065621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","pathOld":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","sourceNew":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundFiles);\n      lmp.setUseCompoundDocStore(useCompoundFiles);\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n\n        // NOTE: this ID_FIELD produces no tokens since\n        // MockAnalyzer discards numbers\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      Searcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","sourceOld":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundFiles);\n      lmp.setUseCompoundDocStore(useCompoundFiles);\n      IndexWriter writer = new IndexWriter(directory, conf);\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n\n        // NOTE: this ID_FIELD produces no tokens since\n        // MockAnalyzer discards numbers\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      Searcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5","date":1292695408,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","pathOld":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","sourceNew":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundFiles);\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n\n        // NOTE: this ID_FIELD produces no tokens since\n        // MockAnalyzer discards numbers\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      Searcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","sourceOld":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundFiles);\n      lmp.setUseCompoundDocStore(useCompoundFiles);\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n\n        // NOTE: this ID_FIELD produces no tokens since\n        // MockAnalyzer discards numbers\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      Searcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab5cb6a74aefb78aa0569857970b9151dfe2e787","date":1292842407,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","pathOld":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","sourceNew":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundFiles);\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n\n        // NOTE: this ID_FIELD produces no tokens since\n        // MockAnalyzer discards numbers\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      Searcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","sourceOld":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundFiles);\n      lmp.setUseCompoundDocStore(useCompoundFiles);\n      IndexWriter writer = new IndexWriter(directory, conf);\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n\n        // NOTE: this ID_FIELD produces no tokens since\n        // MockAnalyzer discards numbers\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      Searcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":0,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","pathOld":"/dev/null","sourceNew":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundFiles);\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n\n        // NOTE: this ID_FIELD produces no tokens since\n        // MockAnalyzer discards numbers\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      Searcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8b241ea5e635d896cc0af83cd96ffd0322e0aba7","date":1294226200,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","pathOld":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","sourceNew":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundFiles);\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n\n        // NOTE: this ID_FIELD produces no tokens since\n        // MockAnalyzer discards numbers\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      IndexSearcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","sourceOld":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundFiles);\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n\n        // NOTE: this ID_FIELD produces no tokens since\n        // MockAnalyzer discards numbers\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      Searcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70ad682703b8585f5d0a637efec044d57ec05efb","date":1294259117,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","pathOld":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","sourceNew":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundFiles);\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n\n        // NOTE: this ID_FIELD produces no tokens since\n        // MockAnalyzer discards numbers\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      IndexSearcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","sourceOld":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundFiles);\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n\n        // NOTE: this ID_FIELD produces no tokens since\n        // MockAnalyzer discards numbers\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      Searcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","pathOld":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","sourceNew":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundFiles);\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n\n        // NOTE: this ID_FIELD produces no tokens since\n        // MockAnalyzer discards numbers\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      IndexSearcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","sourceOld":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundFiles);\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n\n        // NOTE: this ID_FIELD produces no tokens since\n        // MockAnalyzer discards numbers\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      Searcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b1add9ddc0005b07550d4350720aac22dc9886b3","date":1295549635,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","pathOld":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","sourceNew":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundFiles);\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n\n        // NOTE: this ID_FIELD produces no tokens since\n        // MockAnalyzer discards numbers\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      IndexSearcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n      if (VERBOSE) {\n        System.out.println(\"TEST: search query=\" + query);\n      }\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","sourceOld":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundFiles);\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n\n        // NOTE: this ID_FIELD produces no tokens since\n        // MockAnalyzer discards numbers\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      IndexSearcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e79a6d080bdd5b2a8f56342cf571b5476de04180","date":1295638686,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","pathOld":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","sourceNew":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundFiles);\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n\n        // NOTE: this ID_FIELD produces no tokens since\n        // MockAnalyzer discards numbers\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      IndexSearcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n      if (VERBOSE) {\n        System.out.println(\"TEST: search query=\" + query);\n      }\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","sourceOld":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundFiles);\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n\n        // NOTE: this ID_FIELD produces no tokens since\n        // MockAnalyzer discards numbers\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      IndexSearcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c19f985e36a65cc969e8e564fe337a0d41512075","date":1296330536,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","pathOld":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","sourceNew":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      final MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setUseCompoundFile(useCompoundFiles);\n      }\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      IndexSearcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n      if (VERBOSE) {\n        System.out.println(\"TEST: search query=\" + query);\n      }\n\n      final Sort sort = new Sort(new SortField[] {\n          SortField.FIELD_SCORE,\n          new SortField(ID_FIELD, SortField.INT)});\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","sourceOld":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundFiles);\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n\n        // NOTE: this ID_FIELD produces no tokens since\n        // MockAnalyzer discards numbers\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      IndexSearcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n      if (VERBOSE) {\n        System.out.println(\"TEST: search query=\" + query);\n      }\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","pathOld":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","sourceNew":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      final MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setUseCompoundFile(useCompoundFiles);\n      }\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      IndexSearcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n      if (VERBOSE) {\n        System.out.println(\"TEST: search query=\" + query);\n      }\n\n      final Sort sort = new Sort(new SortField[] {\n          SortField.FIELD_SCORE,\n          new SortField(ID_FIELD, SortField.INT)});\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","sourceOld":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundFiles);\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n\n        // NOTE: this ID_FIELD produces no tokens since\n        // MockAnalyzer discards numbers\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      IndexSearcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","pathOld":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","sourceNew":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      final MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setUseCompoundFile(useCompoundFiles);\n      }\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      IndexSearcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n      if (VERBOSE) {\n        System.out.println(\"TEST: search query=\" + query);\n      }\n\n      final Sort sort = new Sort(new SortField[] {\n          SortField.FIELD_SCORE,\n          new SortField(ID_FIELD, SortField.INT)});\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","sourceOld":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundFiles);\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n\n        // NOTE: this ID_FIELD produces no tokens since\n        // MockAnalyzer discards numbers\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      IndexSearcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n      if (VERBOSE) {\n        System.out.println(\"TEST: search query=\" + query);\n      }\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2c5f0cb44df114db4228c8f77861714b5cabaea","date":1302542431,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","pathOld":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","sourceNew":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer(random);\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      final MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setUseCompoundFile(useCompoundFiles);\n      }\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      IndexSearcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n      if (VERBOSE) {\n        System.out.println(\"TEST: search query=\" + query);\n      }\n\n      final Sort sort = new Sort(new SortField[] {\n          SortField.FIELD_SCORE,\n          new SortField(ID_FIELD, SortField.INT)});\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","sourceOld":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      final MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setUseCompoundFile(useCompoundFiles);\n      }\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      IndexSearcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n      if (VERBOSE) {\n        System.out.println(\"TEST: search query=\" + query);\n      }\n\n      final Sort sort = new Sort(new SortField[] {\n          SortField.FIELD_SCORE,\n          new SortField(ID_FIELD, SortField.INT)});\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"962d04139994fce5193143ef35615499a9a96d78","date":1302693744,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","pathOld":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","sourceNew":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer(random);\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      final MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setUseCompoundFile(useCompoundFiles);\n      }\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      IndexSearcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n      if (VERBOSE) {\n        System.out.println(\"TEST: search query=\" + query);\n      }\n\n      final Sort sort = new Sort(new SortField[] {\n          SortField.FIELD_SCORE,\n          new SortField(ID_FIELD, SortField.INT)});\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","sourceOld":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      final MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setUseCompoundFile(useCompoundFiles);\n      }\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      IndexSearcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n      if (VERBOSE) {\n        System.out.println(\"TEST: search query=\" + query);\n      }\n\n      final Sort sort = new Sort(new SortField[] {\n          SortField.FIELD_SCORE,\n          new SortField(ID_FIELD, SortField.INT)});\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","pathOld":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","sourceNew":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer(random);\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      final MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setUseCompoundFile(useCompoundFiles);\n      }\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      IndexSearcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n      if (VERBOSE) {\n        System.out.println(\"TEST: search query=\" + query);\n      }\n\n      final Sort sort = new Sort(new SortField[] {\n          SortField.FIELD_SCORE,\n          new SortField(ID_FIELD, SortField.INT)});\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","sourceOld":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      final MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setUseCompoundFile(useCompoundFiles);\n      }\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      IndexSearcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n      if (VERBOSE) {\n        System.out.println(\"TEST: search query=\" + query);\n      }\n\n      final Sort sort = new Sort(new SortField[] {\n          SortField.FIELD_SCORE,\n          new SortField(ID_FIELD, SortField.INT)});\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","pathOld":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","sourceNew":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer(random);\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      final MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setUseCompoundFile(useCompoundFiles);\n      }\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      IndexSearcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n      if (VERBOSE) {\n        System.out.println(\"TEST: search query=\" + query);\n      }\n\n      final Sort sort = new Sort(new SortField[] {\n          SortField.FIELD_SCORE,\n          new SortField(ID_FIELD, SortField.INT)});\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","sourceOld":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      final MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setUseCompoundFile(useCompoundFiles);\n      }\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      IndexSearcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n      if (VERBOSE) {\n        System.out.println(\"TEST: search query=\" + query);\n      }\n\n      final Sort sort = new Sort(new SortField[] {\n          SortField.FIELD_SCORE,\n          new SortField(ID_FIELD, SortField.INT)});\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0762b640e0d0d12b6edb96db68986e13145c3484","date":1307575932,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean,int).mjava","pathOld":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","sourceNew":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles, int MAX_DOCS) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer(random);\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      final MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setUseCompoundFile(useCompoundFiles);\n      }\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      IndexSearcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n      if (VERBOSE) {\n        System.out.println(\"TEST: search query=\" + query);\n      }\n\n      final Sort sort = new Sort(new SortField[] {\n          SortField.FIELD_SCORE,\n          new SortField(ID_FIELD, SortField.INT)});\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","sourceOld":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer(random);\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      final MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setUseCompoundFile(useCompoundFiles);\n      }\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      IndexSearcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n      if (VERBOSE) {\n        System.out.println(\"TEST: search query=\" + query);\n      }\n\n      final Sort sort = new Sort(new SortField[] {\n          SortField.FIELD_SCORE,\n          new SortField(ID_FIELD, SortField.INT)});\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"77cf4379b2824f6ea34b091c495d6e95c38ff9e2","date":1307610475,"type":5,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean,int).mjava","pathOld":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","sourceNew":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles, int MAX_DOCS) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer(random);\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      final MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setUseCompoundFile(useCompoundFiles);\n      }\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      IndexSearcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n      if (VERBOSE) {\n        System.out.println(\"TEST: search query=\" + query);\n      }\n\n      final Sort sort = new Sort(new SortField[] {\n          SortField.FIELD_SCORE,\n          new SortField(ID_FIELD, SortField.INT)});\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","sourceOld":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer(random);\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      final MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setUseCompoundFile(useCompoundFiles);\n      }\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      IndexSearcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n      if (VERBOSE) {\n        System.out.println(\"TEST: search query=\" + query);\n      }\n\n      final Sort sort = new Sort(new SortField[] {\n          SortField.FIELD_SCORE,\n          new SortField(ID_FIELD, SortField.INT)});\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","date":1307729864,"type":4,"author":"Steven Rowe","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/test/org/apache/lucene/TestSearchForDuplicates#doTest(Random,PrintWriter,boolean).mjava","sourceNew":null,"sourceOld":"  private void doTest(Random random, PrintWriter out, boolean useCompoundFiles) throws Exception {\n      Directory directory = newDirectory();\n      Analyzer analyzer = new MockAnalyzer(random);\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n      final MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setUseCompoundFile(useCompoundFiles);\n      }\n      IndexWriter writer = new IndexWriter(directory, conf);\n      if (VERBOSE) {\n        System.out.println(\"TEST: now build index\");\n        writer.setInfoStream(System.out);\n      }\n\n      final int MAX_DOCS = 225;\n\n      for (int j = 0; j < MAX_DOCS; j++) {\n        Document d = new Document();\n        d.add(newField(PRIORITY_FIELD, HIGH_PRIORITY, Field.Store.YES, Field.Index.ANALYZED));\n        d.add(newField(ID_FIELD, Integer.toString(j), Field.Store.YES, Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      // try a search without OR\n      IndexSearcher searcher = new IndexSearcher(directory, true);\n\n      QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      Query query = parser.parse(HIGH_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n      if (VERBOSE) {\n        System.out.println(\"TEST: search query=\" + query);\n      }\n\n      final Sort sort = new Sort(new SortField[] {\n          SortField.FIELD_SCORE,\n          new SortField(ID_FIELD, SortField.INT)});\n\n      ScoreDoc[] hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n\n      // try a new search with OR\n      searcher = new IndexSearcher(directory, true);\n      hits = null;\n\n      parser = new QueryParser(TEST_VERSION_CURRENT, PRIORITY_FIELD, analyzer);\n\n      query = parser.parse(HIGH_PRIORITY + \" OR \" + MED_PRIORITY);\n      out.println(\"Query: \" + query.toString(PRIORITY_FIELD));\n\n      hits = searcher.search(query, null, MAX_DOCS, sort).scoreDocs;\n      printHits(out, hits, searcher);\n      checkHits(hits, MAX_DOCS, searcher);\n\n      searcher.close();\n      directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":["a3776dccca01c11e7046323cfad46a3b4a471233","0762b640e0d0d12b6edb96db68986e13145c3484"],"70ad682703b8585f5d0a637efec044d57ec05efb":["ab5cb6a74aefb78aa0569857970b9151dfe2e787","8b241ea5e635d896cc0af83cd96ffd0322e0aba7"],"44fcbde6fb2ac44ee3b45e013e54a42911e689ff":["132903c28af3aa6f67284b78de91c0f0a99488c2"],"0762b640e0d0d12b6edb96db68986e13145c3484":["f2c5f0cb44df114db4228c8f77861714b5cabaea"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["29ef99d61cda9641b6250bf9567329a6e65f901d","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["132903c28af3aa6f67284b78de91c0f0a99488c2","4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"132903c28af3aa6f67284b78de91c0f0a99488c2":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"962d04139994fce5193143ef35615499a9a96d78":["bde51b089eb7f86171eb3406e38a274743f9b7ac","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"b1add9ddc0005b07550d4350720aac22dc9886b3":["8b241ea5e635d896cc0af83cd96ffd0322e0aba7"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"e79a6d080bdd5b2a8f56342cf571b5476de04180":["868da859b43505d9d2a023bfeae6dd0c795f5295","b1add9ddc0005b07550d4350720aac22dc9886b3"],"c19f985e36a65cc969e8e564fe337a0d41512075":["b1add9ddc0005b07550d4350720aac22dc9886b3"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["c19f985e36a65cc969e8e564fe337a0d41512075"],"8b241ea5e635d896cc0af83cd96ffd0322e0aba7":["4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"a3776dccca01c11e7046323cfad46a3b4a471233":["c19f985e36a65cc969e8e564fe337a0d41512075","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["70ad682703b8585f5d0a637efec044d57ec05efb","c19f985e36a65cc969e8e564fe337a0d41512075"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":["135621f3a0670a9394eb563224a3b76cc4dddc0f","0762b640e0d0d12b6edb96db68986e13145c3484"],"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5":["44fcbde6fb2ac44ee3b45e013e54a42911e689ff"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","8b241ea5e635d896cc0af83cd96ffd0322e0aba7"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["e79a6d080bdd5b2a8f56342cf571b5476de04180","c19f985e36a65cc969e8e564fe337a0d41512075"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["0762b640e0d0d12b6edb96db68986e13145c3484"]},"commit2Childs":{"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":[],"70ad682703b8585f5d0a637efec044d57ec05efb":["29ef99d61cda9641b6250bf9567329a6e65f901d"],"44fcbde6fb2ac44ee3b45e013e54a42911e689ff":["4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"0762b640e0d0d12b6edb96db68986e13145c3484":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","77cf4379b2824f6ea34b091c495d6e95c38ff9e2","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["77cf4379b2824f6ea34b091c495d6e95c38ff9e2"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["70ad682703b8585f5d0a637efec044d57ec05efb"],"132903c28af3aa6f67284b78de91c0f0a99488c2":["44fcbde6fb2ac44ee3b45e013e54a42911e689ff","ab5cb6a74aefb78aa0569857970b9151dfe2e787"],"962d04139994fce5193143ef35615499a9a96d78":[],"b1add9ddc0005b07550d4350720aac22dc9886b3":["e79a6d080bdd5b2a8f56342cf571b5476de04180","c19f985e36a65cc969e8e564fe337a0d41512075"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["868da859b43505d9d2a023bfeae6dd0c795f5295"],"e79a6d080bdd5b2a8f56342cf571b5476de04180":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"c19f985e36a65cc969e8e564fe337a0d41512075":["f2c5f0cb44df114db4228c8f77861714b5cabaea","a3776dccca01c11e7046323cfad46a3b4a471233","29ef99d61cda9641b6250bf9567329a6e65f901d","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"8b241ea5e635d896cc0af83cd96ffd0322e0aba7":["70ad682703b8585f5d0a637efec044d57ec05efb","b1add9ddc0005b07550d4350720aac22dc9886b3","868da859b43505d9d2a023bfeae6dd0c795f5295"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["0762b640e0d0d12b6edb96db68986e13145c3484","135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","a3776dccca01c11e7046323cfad46a3b4a471233"],"a3776dccca01c11e7046323cfad46a3b4a471233":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["132903c28af3aa6f67284b78de91c0f0a99488c2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":[],"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5":["ab5cb6a74aefb78aa0569857970b9151dfe2e787","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","8b241ea5e635d896cc0af83cd96ffd0322e0aba7"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["e79a6d080bdd5b2a8f56342cf571b5476de04180"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["962d04139994fce5193143ef35615499a9a96d78"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","962d04139994fce5193143ef35615499a9a96d78","77cf4379b2824f6ea34b091c495d6e95c38ff9e2","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}