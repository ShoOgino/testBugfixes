{"path":"lucene/facet/src/test/org/apache/lucene/facet/search/TestDemoFacets#test().mjava","commits":[{"id":"9aec76e44cc718c8a51f11f0a498e1a34efffb42","date":1355323760,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/TestDemoFacets#test().mjava","pathOld":"/dev/null","sourceNew":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    writer = new RandomIndexWriter(random(), dir);\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    docBuilder = new CategoryDocumentBuilder(taxoWriter);\n\n    add(\"Author/Bob\", \"Publish Date/2010/10/15\");\n    add(\"Author/Lisa\", \"Publish Date/2010/10/20\");\n    add(\"Author/Lisa\", \"Publish Date/2012/1/1\");\n    add(\"Author/Susan\", \"Publish Date/2012/1/7\");\n    add(\"Author/Frank\", \"Publish Date/1999/5/5\");\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Holds all configuration for a facet request:\n    FacetSearchParams fsp = new FacetSearchParams();\n\n    // Count both \"Publish Date\" and \"Author\" dimensions:\n    fsp.addFacetRequest(new CountFacetRequest(new CategoryPath(\"Publish Date\"), 10));\n    fsp.addFacetRequest(new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n\n    // Aggregatses the facet counts:\n    FacetsCollector c = new FacetsCollector(fsp, searcher.getIndexReader(), taxoReader);\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    // Retrieve & verify results:\n    List<FacetResult> results = c.getFacetResults();\n    assertEquals(2, results.size());\n    assertEquals(\"Publish Date (5)\\n  2012 (2)\\n  2010 (2)\\n  1999 (1)\\n\",\n                 toSimpleString(results.get(0)));\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Frank (1)\\n  Susan (1)\\n  Bob (1)\\n\",\n                 toSimpleString(results.get(1)));\n\n    \n    // Now user drills down on Publish Date/2010:\n    fsp = new FacetSearchParams();\n    Query q2 = DrillDown.query(fsp, new MatchAllDocsQuery(), new CategoryPath(\"Publish Date/2010\", '/'));\n    fsp.addFacetRequest(new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n    c = new FacetsCollector(fsp, searcher.getIndexReader(), taxoReader);\n    searcher.search(q2, c);\n    results = c.getFacetResults();\n    assertEquals(1, results.size());\n    assertEquals(\"Author (2)\\n  Lisa (1)\\n  Bob (1)\\n\",\n                 toSimpleString(results.get(0)));\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d4c6c7f3cda7a0595cabd16e5e9107ca29852708","date":1355402234,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/TestDemoFacets#test().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/TestDemoFacets#test().mjava","sourceNew":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    writer = new RandomIndexWriter(random(), dir);\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    docBuilder = new CategoryDocumentBuilder(taxoWriter);\n\n    add(\"Author/Bob\", \"Publish Date/2010/10/15\");\n    add(\"Author/Lisa\", \"Publish Date/2010/10/20\");\n    add(\"Author/Lisa\", \"Publish Date/2012/1/1\");\n    add(\"Author/Susan\", \"Publish Date/2012/1/7\");\n    add(\"Author/Frank\", \"Publish Date/1999/5/5\");\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Count both \"Publish Date\" and \"Author\" dimensions:\n    FacetSearchParams fsp = new FacetSearchParams(\n        new CountFacetRequest(new CategoryPath(\"Publish Date\"), 10), \n        new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n\n    // Aggregatses the facet counts:\n    FacetsCollector c = new FacetsCollector(fsp, searcher.getIndexReader(), taxoReader);\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    // Retrieve & verify results:\n    List<FacetResult> results = c.getFacetResults();\n    assertEquals(2, results.size());\n    assertEquals(\"Publish Date (5)\\n  2012 (2)\\n  2010 (2)\\n  1999 (1)\\n\",\n                 toSimpleString(results.get(0)));\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Frank (1)\\n  Susan (1)\\n  Bob (1)\\n\",\n                 toSimpleString(results.get(1)));\n\n    \n    // Now user drills down on Publish Date/2010:\n    fsp = new FacetSearchParams(new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n    Query q2 = DrillDown.query(fsp, new MatchAllDocsQuery(), new CategoryPath(\"Publish Date/2010\", '/'));\n    c = new FacetsCollector(fsp, searcher.getIndexReader(), taxoReader);\n    searcher.search(q2, c);\n    results = c.getFacetResults();\n    assertEquals(1, results.size());\n    assertEquals(\"Author (2)\\n  Lisa (1)\\n  Bob (1)\\n\",\n                 toSimpleString(results.get(0)));\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    writer = new RandomIndexWriter(random(), dir);\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    docBuilder = new CategoryDocumentBuilder(taxoWriter);\n\n    add(\"Author/Bob\", \"Publish Date/2010/10/15\");\n    add(\"Author/Lisa\", \"Publish Date/2010/10/20\");\n    add(\"Author/Lisa\", \"Publish Date/2012/1/1\");\n    add(\"Author/Susan\", \"Publish Date/2012/1/7\");\n    add(\"Author/Frank\", \"Publish Date/1999/5/5\");\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Holds all configuration for a facet request:\n    FacetSearchParams fsp = new FacetSearchParams();\n\n    // Count both \"Publish Date\" and \"Author\" dimensions:\n    fsp.addFacetRequest(new CountFacetRequest(new CategoryPath(\"Publish Date\"), 10));\n    fsp.addFacetRequest(new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n\n    // Aggregatses the facet counts:\n    FacetsCollector c = new FacetsCollector(fsp, searcher.getIndexReader(), taxoReader);\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    // Retrieve & verify results:\n    List<FacetResult> results = c.getFacetResults();\n    assertEquals(2, results.size());\n    assertEquals(\"Publish Date (5)\\n  2012 (2)\\n  2010 (2)\\n  1999 (1)\\n\",\n                 toSimpleString(results.get(0)));\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Frank (1)\\n  Susan (1)\\n  Bob (1)\\n\",\n                 toSimpleString(results.get(1)));\n\n    \n    // Now user drills down on Publish Date/2010:\n    fsp = new FacetSearchParams();\n    Query q2 = DrillDown.query(fsp, new MatchAllDocsQuery(), new CategoryPath(\"Publish Date/2010\", '/'));\n    fsp.addFacetRequest(new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n    c = new FacetsCollector(fsp, searcher.getIndexReader(), taxoReader);\n    searcher.search(q2, c);\n    results = c.getFacetResults();\n    assertEquals(1, results.size());\n    assertEquals(\"Author (2)\\n  Lisa (1)\\n  Bob (1)\\n\",\n                 toSimpleString(results.get(0)));\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7a1037d9031f9702ee6912f8751ef1d5320da6d9","date":1357217787,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/TestDemoFacets#test().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/TestDemoFacets#test().mjava","sourceNew":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    writer = new RandomIndexWriter(random(), dir);\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    docBuilder = new FacetFields(taxoWriter);\n\n    add(\"Author/Bob\", \"Publish Date/2010/10/15\");\n    add(\"Author/Lisa\", \"Publish Date/2010/10/20\");\n    add(\"Author/Lisa\", \"Publish Date/2012/1/1\");\n    add(\"Author/Susan\", \"Publish Date/2012/1/7\");\n    add(\"Author/Frank\", \"Publish Date/1999/5/5\");\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Count both \"Publish Date\" and \"Author\" dimensions:\n    FacetSearchParams fsp = new FacetSearchParams(\n        new CountFacetRequest(new CategoryPath(\"Publish Date\"), 10), \n        new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n\n    // Aggregatses the facet counts:\n    FacetsCollector c = new FacetsCollector(fsp, searcher.getIndexReader(), taxoReader);\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    // Retrieve & verify results:\n    List<FacetResult> results = c.getFacetResults();\n    assertEquals(2, results.size());\n    assertEquals(\"Publish Date (5)\\n  2012 (2)\\n  2010 (2)\\n  1999 (1)\\n\",\n                 toSimpleString(results.get(0)));\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Frank (1)\\n  Susan (1)\\n  Bob (1)\\n\",\n                 toSimpleString(results.get(1)));\n\n    \n    // Now user drills down on Publish Date/2010:\n    fsp = new FacetSearchParams(new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n    Query q2 = DrillDown.query(fsp, new MatchAllDocsQuery(), new CategoryPath(\"Publish Date/2010\", '/'));\n    c = new FacetsCollector(fsp, searcher.getIndexReader(), taxoReader);\n    searcher.search(q2, c);\n    results = c.getFacetResults();\n    assertEquals(1, results.size());\n    assertEquals(\"Author (2)\\n  Lisa (1)\\n  Bob (1)\\n\",\n                 toSimpleString(results.get(0)));\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    writer = new RandomIndexWriter(random(), dir);\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    docBuilder = new CategoryDocumentBuilder(taxoWriter);\n\n    add(\"Author/Bob\", \"Publish Date/2010/10/15\");\n    add(\"Author/Lisa\", \"Publish Date/2010/10/20\");\n    add(\"Author/Lisa\", \"Publish Date/2012/1/1\");\n    add(\"Author/Susan\", \"Publish Date/2012/1/7\");\n    add(\"Author/Frank\", \"Publish Date/1999/5/5\");\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Count both \"Publish Date\" and \"Author\" dimensions:\n    FacetSearchParams fsp = new FacetSearchParams(\n        new CountFacetRequest(new CategoryPath(\"Publish Date\"), 10), \n        new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n\n    // Aggregatses the facet counts:\n    FacetsCollector c = new FacetsCollector(fsp, searcher.getIndexReader(), taxoReader);\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    // Retrieve & verify results:\n    List<FacetResult> results = c.getFacetResults();\n    assertEquals(2, results.size());\n    assertEquals(\"Publish Date (5)\\n  2012 (2)\\n  2010 (2)\\n  1999 (1)\\n\",\n                 toSimpleString(results.get(0)));\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Frank (1)\\n  Susan (1)\\n  Bob (1)\\n\",\n                 toSimpleString(results.get(1)));\n\n    \n    // Now user drills down on Publish Date/2010:\n    fsp = new FacetSearchParams(new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n    Query q2 = DrillDown.query(fsp, new MatchAllDocsQuery(), new CategoryPath(\"Publish Date/2010\", '/'));\n    c = new FacetsCollector(fsp, searcher.getIndexReader(), taxoReader);\n    searcher.search(q2, c);\n    results = c.getFacetResults();\n    assertEquals(1, results.size());\n    assertEquals(\"Author (2)\\n  Lisa (1)\\n  Bob (1)\\n\",\n                 toSimpleString(results.get(0)));\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/TestDemoFacets#test().mjava","pathOld":"/dev/null","sourceNew":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    writer = new RandomIndexWriter(random(), dir);\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    docBuilder = new FacetFields(taxoWriter);\n\n    add(\"Author/Bob\", \"Publish Date/2010/10/15\");\n    add(\"Author/Lisa\", \"Publish Date/2010/10/20\");\n    add(\"Author/Lisa\", \"Publish Date/2012/1/1\");\n    add(\"Author/Susan\", \"Publish Date/2012/1/7\");\n    add(\"Author/Frank\", \"Publish Date/1999/5/5\");\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Count both \"Publish Date\" and \"Author\" dimensions:\n    FacetSearchParams fsp = new FacetSearchParams(\n        new CountFacetRequest(new CategoryPath(\"Publish Date\"), 10), \n        new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n\n    // Aggregatses the facet counts:\n    FacetsCollector c = new FacetsCollector(fsp, searcher.getIndexReader(), taxoReader);\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    // Retrieve & verify results:\n    List<FacetResult> results = c.getFacetResults();\n    assertEquals(2, results.size());\n    assertEquals(\"Publish Date (5)\\n  2012 (2)\\n  2010 (2)\\n  1999 (1)\\n\",\n                 toSimpleString(results.get(0)));\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Frank (1)\\n  Susan (1)\\n  Bob (1)\\n\",\n                 toSimpleString(results.get(1)));\n\n    \n    // Now user drills down on Publish Date/2010:\n    fsp = new FacetSearchParams(new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n    Query q2 = DrillDown.query(fsp, new MatchAllDocsQuery(), new CategoryPath(\"Publish Date/2010\", '/'));\n    c = new FacetsCollector(fsp, searcher.getIndexReader(), taxoReader);\n    searcher.search(q2, c);\n    results = c.getFacetResults();\n    assertEquals(1, results.size());\n    assertEquals(\"Author (2)\\n  Lisa (1)\\n  Bob (1)\\n\",\n                 toSimpleString(results.get(0)));\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f96e4a056f7ee1bafbfb8a06c5bd93f7708e560d","date":1358784296,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/TestDemoFacets#test().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/TestDemoFacets#test().mjava","sourceNew":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    writer = new RandomIndexWriter(random(), dir);\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    docBuilder = new FacetFields(taxoWriter);\n\n    add(\"Author/Bob\", \"Publish Date/2010/10/15\");\n    add(\"Author/Lisa\", \"Publish Date/2010/10/20\");\n    add(\"Author/Lisa\", \"Publish Date/2012/1/1\");\n    add(\"Author/Susan\", \"Publish Date/2012/1/7\");\n    add(\"Author/Frank\", \"Publish Date/1999/5/5\");\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Count both \"Publish Date\" and \"Author\" dimensions:\n    FacetSearchParams fsp = new FacetSearchParams(\n        new CountFacetRequest(new CategoryPath(\"Publish Date\"), 10), \n        new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n\n    // Aggregatses the facet counts:\n    FacetsCollector c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    // Retrieve & verify results:\n    List<FacetResult> results = c.getFacetResults();\n    assertEquals(2, results.size());\n    assertEquals(\"Publish Date (5)\\n  2012 (2)\\n  2010 (2)\\n  1999 (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Frank (1)\\n  Susan (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(1)));\n\n    \n    // Now user drills down on Publish Date/2010:\n    fsp = new FacetSearchParams(new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n    Query q2 = DrillDown.query(fsp, new MatchAllDocsQuery(), new CategoryPath(\"Publish Date/2010\", '/'));\n    c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n    searcher.search(q2, c);\n    results = c.getFacetResults();\n    assertEquals(1, results.size());\n    assertEquals(\"Author (2)\\n  Lisa (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    writer = new RandomIndexWriter(random(), dir);\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    docBuilder = new FacetFields(taxoWriter);\n\n    add(\"Author/Bob\", \"Publish Date/2010/10/15\");\n    add(\"Author/Lisa\", \"Publish Date/2010/10/20\");\n    add(\"Author/Lisa\", \"Publish Date/2012/1/1\");\n    add(\"Author/Susan\", \"Publish Date/2012/1/7\");\n    add(\"Author/Frank\", \"Publish Date/1999/5/5\");\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Count both \"Publish Date\" and \"Author\" dimensions:\n    FacetSearchParams fsp = new FacetSearchParams(\n        new CountFacetRequest(new CategoryPath(\"Publish Date\"), 10), \n        new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n\n    // Aggregatses the facet counts:\n    FacetsCollector c = new FacetsCollector(fsp, searcher.getIndexReader(), taxoReader);\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    // Retrieve & verify results:\n    List<FacetResult> results = c.getFacetResults();\n    assertEquals(2, results.size());\n    assertEquals(\"Publish Date (5)\\n  2012 (2)\\n  2010 (2)\\n  1999 (1)\\n\",\n                 toSimpleString(results.get(0)));\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Frank (1)\\n  Susan (1)\\n  Bob (1)\\n\",\n                 toSimpleString(results.get(1)));\n\n    \n    // Now user drills down on Publish Date/2010:\n    fsp = new FacetSearchParams(new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n    Query q2 = DrillDown.query(fsp, new MatchAllDocsQuery(), new CategoryPath(\"Publish Date/2010\", '/'));\n    c = new FacetsCollector(fsp, searcher.getIndexReader(), taxoReader);\n    searcher.search(q2, c);\n    results = c.getFacetResults();\n    assertEquals(1, results.size());\n    assertEquals(\"Author (2)\\n  Lisa (1)\\n  Bob (1)\\n\",\n                 toSimpleString(results.get(0)));\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"224d71a68a47e867c96b8134405615e90f815f84","date":1358787040,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/TestDemoFacets#test().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/TestDemoFacets#test().mjava","sourceNew":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    writer = new RandomIndexWriter(random(), dir);\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    docBuilder = new FacetFields(taxoWriter);\n\n    add(\"Author/Bob\", \"Publish Date/2010/10/15\");\n    add(\"Author/Lisa\", \"Publish Date/2010/10/20\");\n    add(\"Author/Lisa\", \"Publish Date/2012/1/1\");\n    add(\"Author/Susan\", \"Publish Date/2012/1/7\");\n    add(\"Author/Frank\", \"Publish Date/1999/5/5\");\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Count both \"Publish Date\" and \"Author\" dimensions:\n    FacetSearchParams fsp = new FacetSearchParams(\n        new CountFacetRequest(new CategoryPath(\"Publish Date\"), 10), \n        new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n\n    // Aggregatses the facet counts:\n    FacetsCollector c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    // Retrieve & verify results:\n    List<FacetResult> results = c.getFacetResults();\n    assertEquals(2, results.size());\n    assertEquals(\"Publish Date (5)\\n  2012 (2)\\n  2010 (2)\\n  1999 (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Frank (1)\\n  Susan (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(1)));\n\n    \n    // Now user drills down on Publish Date/2010:\n    fsp = new FacetSearchParams(new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n    Query q2 = DrillDown.query(fsp, new MatchAllDocsQuery(), new CategoryPath(\"Publish Date/2010\", '/'));\n    c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n    searcher.search(q2, c);\n    results = c.getFacetResults();\n    assertEquals(1, results.size());\n    assertEquals(\"Author (2)\\n  Lisa (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    writer = new RandomIndexWriter(random(), dir);\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    docBuilder = new FacetFields(taxoWriter);\n\n    add(\"Author/Bob\", \"Publish Date/2010/10/15\");\n    add(\"Author/Lisa\", \"Publish Date/2010/10/20\");\n    add(\"Author/Lisa\", \"Publish Date/2012/1/1\");\n    add(\"Author/Susan\", \"Publish Date/2012/1/7\");\n    add(\"Author/Frank\", \"Publish Date/1999/5/5\");\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Count both \"Publish Date\" and \"Author\" dimensions:\n    FacetSearchParams fsp = new FacetSearchParams(\n        new CountFacetRequest(new CategoryPath(\"Publish Date\"), 10), \n        new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n\n    // Aggregatses the facet counts:\n    FacetsCollector c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    // Retrieve & verify results:\n    List<FacetResult> results = c.getFacetResults();\n    assertEquals(2, results.size());\n    assertEquals(\"Publish Date (5)\\n  2012 (2)\\n  2010 (2)\\n  1999 (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Frank (1)\\n  Susan (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(1)));\n\n    \n    // Now user drills down on Publish Date/2010:\n    fsp = new FacetSearchParams(new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n    Query q2 = DrillDown.query(fsp, new MatchAllDocsQuery(), new CategoryPath(\"Publish Date/2010\", '/'));\n    c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n    searcher.search(q2, c);\n    results = c.getFacetResults();\n    assertEquals(1, results.size());\n    assertEquals(\"Author (2)\\n  Lisa (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"07155cdd910937cdf6877e48884d5782845c8b8b","date":1358796205,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/TestDemoFacets#test().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/TestDemoFacets#test().mjava","sourceNew":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    writer = new RandomIndexWriter(random(), dir);\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    docBuilder = new FacetFields(taxoWriter);\n\n    add(\"Author/Bob\", \"Publish Date/2010/10/15\");\n    add(\"Author/Lisa\", \"Publish Date/2010/10/20\");\n    add(\"Author/Lisa\", \"Publish Date/2012/1/1\");\n    add(\"Author/Susan\", \"Publish Date/2012/1/7\");\n    add(\"Author/Frank\", \"Publish Date/1999/5/5\");\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Count both \"Publish Date\" and \"Author\" dimensions:\n    FacetSearchParams fsp = new FacetSearchParams(\n        new CountFacetRequest(new CategoryPath(\"Publish Date\"), 10), \n        new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n\n    // Aggregatses the facet counts:\n    FacetsCollector c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    // Retrieve & verify results:\n    List<FacetResult> results = c.getFacetResults();\n    assertEquals(2, results.size());\n    assertEquals(\"Publish Date (5)\\n  2012 (2)\\n  2010 (2)\\n  1999 (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Frank (1)\\n  Susan (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(1)));\n\n    \n    // Now user drills down on Publish Date/2010:\n    fsp = new FacetSearchParams(new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n    Query q2 = DrillDown.query(fsp, new MatchAllDocsQuery(), new CategoryPath(\"Publish Date/2010\", '/'));\n    c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n    searcher.search(q2, c);\n    results = c.getFacetResults();\n    assertEquals(1, results.size());\n    assertEquals(\"Author (2)\\n  Lisa (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    writer = new RandomIndexWriter(random(), dir);\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    docBuilder = new FacetFields(taxoWriter);\n\n    add(\"Author/Bob\", \"Publish Date/2010/10/15\");\n    add(\"Author/Lisa\", \"Publish Date/2010/10/20\");\n    add(\"Author/Lisa\", \"Publish Date/2012/1/1\");\n    add(\"Author/Susan\", \"Publish Date/2012/1/7\");\n    add(\"Author/Frank\", \"Publish Date/1999/5/5\");\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Count both \"Publish Date\" and \"Author\" dimensions:\n    FacetSearchParams fsp = new FacetSearchParams(\n        new CountFacetRequest(new CategoryPath(\"Publish Date\"), 10), \n        new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n\n    // Aggregatses the facet counts:\n    FacetsCollector c = new FacetsCollector(fsp, searcher.getIndexReader(), taxoReader);\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    // Retrieve & verify results:\n    List<FacetResult> results = c.getFacetResults();\n    assertEquals(2, results.size());\n    assertEquals(\"Publish Date (5)\\n  2012 (2)\\n  2010 (2)\\n  1999 (1)\\n\",\n                 toSimpleString(results.get(0)));\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Frank (1)\\n  Susan (1)\\n  Bob (1)\\n\",\n                 toSimpleString(results.get(1)));\n\n    \n    // Now user drills down on Publish Date/2010:\n    fsp = new FacetSearchParams(new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n    Query q2 = DrillDown.query(fsp, new MatchAllDocsQuery(), new CategoryPath(\"Publish Date/2010\", '/'));\n    c = new FacetsCollector(fsp, searcher.getIndexReader(), taxoReader);\n    searcher.search(q2, c);\n    results = c.getFacetResults();\n    assertEquals(1, results.size());\n    assertEquals(\"Author (2)\\n  Lisa (1)\\n  Bob (1)\\n\",\n                 toSimpleString(results.get(0)));\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"90213788e5007cc5e2b3d88200a8265de9d4e6d4","date":1359060940,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/TestDemoFacets#test().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/TestDemoFacets#test().mjava","sourceNew":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    writer = new RandomIndexWriter(random(), dir);\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    facetFields = new FacetFields(taxoWriter);\n\n    add(\"Author/Bob\", \"Publish Date/2010/10/15\");\n    add(\"Author/Lisa\", \"Publish Date/2010/10/20\");\n    add(\"Author/Lisa\", \"Publish Date/2012/1/1\");\n    add(\"Author/Susan\", \"Publish Date/2012/1/7\");\n    add(\"Author/Frank\", \"Publish Date/1999/5/5\");\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Count both \"Publish Date\" and \"Author\" dimensions:\n    FacetSearchParams fsp = new FacetSearchParams(\n        new CountFacetRequest(new CategoryPath(\"Publish Date\"), 10), \n        new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n\n    // Aggregatses the facet counts:\n    FacetsCollector c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    // Retrieve & verify results:\n    List<FacetResult> results = c.getFacetResults();\n    assertEquals(2, results.size());\n    assertEquals(\"Publish Date (5)\\n  2012 (2)\\n  2010 (2)\\n  1999 (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Frank (1)\\n  Susan (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(1)));\n\n    \n    // Now user drills down on Publish Date/2010:\n    fsp = new FacetSearchParams(new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n    Query q2 = DrillDown.query(fsp, new MatchAllDocsQuery(), new CategoryPath(\"Publish Date/2010\", '/'));\n    c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n    searcher.search(q2, c);\n    results = c.getFacetResults();\n    assertEquals(1, results.size());\n    assertEquals(\"Author (2)\\n  Lisa (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    writer = new RandomIndexWriter(random(), dir);\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    docBuilder = new FacetFields(taxoWriter);\n\n    add(\"Author/Bob\", \"Publish Date/2010/10/15\");\n    add(\"Author/Lisa\", \"Publish Date/2010/10/20\");\n    add(\"Author/Lisa\", \"Publish Date/2012/1/1\");\n    add(\"Author/Susan\", \"Publish Date/2012/1/7\");\n    add(\"Author/Frank\", \"Publish Date/1999/5/5\");\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Count both \"Publish Date\" and \"Author\" dimensions:\n    FacetSearchParams fsp = new FacetSearchParams(\n        new CountFacetRequest(new CategoryPath(\"Publish Date\"), 10), \n        new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n\n    // Aggregatses the facet counts:\n    FacetsCollector c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    // Retrieve & verify results:\n    List<FacetResult> results = c.getFacetResults();\n    assertEquals(2, results.size());\n    assertEquals(\"Publish Date (5)\\n  2012 (2)\\n  2010 (2)\\n  1999 (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Frank (1)\\n  Susan (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(1)));\n\n    \n    // Now user drills down on Publish Date/2010:\n    fsp = new FacetSearchParams(new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n    Query q2 = DrillDown.query(fsp, new MatchAllDocsQuery(), new CategoryPath(\"Publish Date/2010\", '/'));\n    c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n    searcher.search(q2, c);\n    results = c.getFacetResults();\n    assertEquals(1, results.size());\n    assertEquals(\"Author (2)\\n  Lisa (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9fa7a3db4fa6c77f454964f515841c097ca09212","date":1359119468,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/TestDemoFacets#test().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/TestDemoFacets#test().mjava","sourceNew":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    writer = new RandomIndexWriter(random(), dir);\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    facetFields = new FacetFields(taxoWriter);\n\n    add(\"Author/Bob\", \"Publish Date/2010/10/15\");\n    add(\"Author/Lisa\", \"Publish Date/2010/10/20\");\n    add(\"Author/Lisa\", \"Publish Date/2012/1/1\");\n    add(\"Author/Susan\", \"Publish Date/2012/1/7\");\n    add(\"Author/Frank\", \"Publish Date/1999/5/5\");\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Count both \"Publish Date\" and \"Author\" dimensions:\n    FacetSearchParams fsp = new FacetSearchParams(\n        new CountFacetRequest(new CategoryPath(\"Publish Date\"), 10), \n        new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n\n    // Aggregatses the facet counts:\n    FacetsCollector c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    // Retrieve & verify results:\n    List<FacetResult> results = c.getFacetResults();\n    assertEquals(2, results.size());\n    assertEquals(\"Publish Date (5)\\n  2012 (2)\\n  2010 (2)\\n  1999 (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Frank (1)\\n  Susan (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(1)));\n\n    \n    // Now user drills down on Publish Date/2010:\n    fsp = new FacetSearchParams(new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n    Query q2 = DrillDown.query(fsp, new MatchAllDocsQuery(), Occur.MUST, new CategoryPath(\"Publish Date/2010\", '/'));\n    c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n    searcher.search(q2, c);\n    results = c.getFacetResults();\n    assertEquals(1, results.size());\n    assertEquals(\"Author (2)\\n  Lisa (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    writer = new RandomIndexWriter(random(), dir);\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    facetFields = new FacetFields(taxoWriter);\n\n    add(\"Author/Bob\", \"Publish Date/2010/10/15\");\n    add(\"Author/Lisa\", \"Publish Date/2010/10/20\");\n    add(\"Author/Lisa\", \"Publish Date/2012/1/1\");\n    add(\"Author/Susan\", \"Publish Date/2012/1/7\");\n    add(\"Author/Frank\", \"Publish Date/1999/5/5\");\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Count both \"Publish Date\" and \"Author\" dimensions:\n    FacetSearchParams fsp = new FacetSearchParams(\n        new CountFacetRequest(new CategoryPath(\"Publish Date\"), 10), \n        new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n\n    // Aggregatses the facet counts:\n    FacetsCollector c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    // Retrieve & verify results:\n    List<FacetResult> results = c.getFacetResults();\n    assertEquals(2, results.size());\n    assertEquals(\"Publish Date (5)\\n  2012 (2)\\n  2010 (2)\\n  1999 (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Frank (1)\\n  Susan (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(1)));\n\n    \n    // Now user drills down on Publish Date/2010:\n    fsp = new FacetSearchParams(new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n    Query q2 = DrillDown.query(fsp, new MatchAllDocsQuery(), new CategoryPath(\"Publish Date/2010\", '/'));\n    c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n    searcher.search(q2, c);\n    results = c.getFacetResults();\n    assertEquals(1, results.size());\n    assertEquals(\"Author (2)\\n  Lisa (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"dd45d4a2ee01a1932d33eec42f5272c2402da679","date":1359316912,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/TestDemoFacets#test().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/TestDemoFacets#test().mjava","sourceNew":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    writer = new RandomIndexWriter(random(), dir);\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    facetFields = new FacetFields(taxoWriter);\n\n    add(\"Author/Bob\", \"Publish Date/2010/10/15\");\n    add(\"Author/Lisa\", \"Publish Date/2010/10/20\");\n    add(\"Author/Lisa\", \"Publish Date/2012/1/1\");\n    add(\"Author/Susan\", \"Publish Date/2012/1/7\");\n    add(\"Author/Frank\", \"Publish Date/1999/5/5\");\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Count both \"Publish Date\" and \"Author\" dimensions:\n    FacetSearchParams fsp = new FacetSearchParams(\n        new CountFacetRequest(new CategoryPath(\"Publish Date\"), 10), \n        new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n\n    // Aggregatses the facet counts:\n    FacetsCollector c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    // Retrieve & verify results:\n    List<FacetResult> results = c.getFacetResults();\n    assertEquals(2, results.size());\n    assertEquals(\"Publish Date (5)\\n  2012 (2)\\n  2010 (2)\\n  1999 (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Frank (1)\\n  Susan (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(1)));\n\n    \n    // Now user drills down on Publish Date/2010:\n    fsp = new FacetSearchParams(new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n    Query q2 = DrillDown.query(fsp, new MatchAllDocsQuery(), Occur.MUST, new CategoryPath(\"Publish Date/2010\", '/'));\n    c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n    searcher.search(q2, c);\n    results = c.getFacetResults();\n    assertEquals(1, results.size());\n    assertEquals(\"Author (2)\\n  Lisa (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    writer = new RandomIndexWriter(random(), dir);\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    docBuilder = new FacetFields(taxoWriter);\n\n    add(\"Author/Bob\", \"Publish Date/2010/10/15\");\n    add(\"Author/Lisa\", \"Publish Date/2010/10/20\");\n    add(\"Author/Lisa\", \"Publish Date/2012/1/1\");\n    add(\"Author/Susan\", \"Publish Date/2012/1/7\");\n    add(\"Author/Frank\", \"Publish Date/1999/5/5\");\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Count both \"Publish Date\" and \"Author\" dimensions:\n    FacetSearchParams fsp = new FacetSearchParams(\n        new CountFacetRequest(new CategoryPath(\"Publish Date\"), 10), \n        new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n\n    // Aggregatses the facet counts:\n    FacetsCollector c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    // Retrieve & verify results:\n    List<FacetResult> results = c.getFacetResults();\n    assertEquals(2, results.size());\n    assertEquals(\"Publish Date (5)\\n  2012 (2)\\n  2010 (2)\\n  1999 (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Frank (1)\\n  Susan (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(1)));\n\n    \n    // Now user drills down on Publish Date/2010:\n    fsp = new FacetSearchParams(new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n    Query q2 = DrillDown.query(fsp, new MatchAllDocsQuery(), new CategoryPath(\"Publish Date/2010\", '/'));\n    c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n    searcher.search(q2, c);\n    results = c.getFacetResults();\n    assertEquals(1, results.size());\n    assertEquals(\"Author (2)\\n  Lisa (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"239f79ed06f0979cfe1911ec5fba32b94fda43c1","date":1359553898,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/TestDemoFacets#test().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/TestDemoFacets#test().mjava","sourceNew":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    writer = new RandomIndexWriter(random(), dir);\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    facetFields = new FacetFields(taxoWriter);\n\n    add(\"Author/Bob\", \"Publish Date/2010/10/15\");\n    add(\"Author/Lisa\", \"Publish Date/2010/10/20\");\n    add(\"Author/Lisa\", \"Publish Date/2012/1/1\");\n    add(\"Author/Susan\", \"Publish Date/2012/1/7\");\n    add(\"Author/Frank\", \"Publish Date/1999/5/5\");\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Count both \"Publish Date\" and \"Author\" dimensions:\n    FacetSearchParams fsp = new FacetSearchParams(\n        new CountFacetRequest(new CategoryPath(\"Publish Date\"), 10), \n        new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n\n    // Aggregatses the facet counts:\n    FacetsCollector c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    // Retrieve & verify results:\n    List<FacetResult> results = c.getFacetResults();\n    assertEquals(2, results.size());\n    assertEquals(\"Publish Date (0)\\n  2012 (2)\\n  2010 (2)\\n  1999 (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n    assertEquals(\"Author (0)\\n  Lisa (2)\\n  Frank (1)\\n  Susan (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(1)));\n\n    \n    // Now user drills down on Publish Date/2010:\n    fsp = new FacetSearchParams(new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n    Query q2 = DrillDown.query(fsp, new MatchAllDocsQuery(), Occur.MUST, new CategoryPath(\"Publish Date/2010\", '/'));\n    c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n    searcher.search(q2, c);\n    results = c.getFacetResults();\n    assertEquals(1, results.size());\n    assertEquals(\"Author (0)\\n  Lisa (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    writer = new RandomIndexWriter(random(), dir);\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    facetFields = new FacetFields(taxoWriter);\n\n    add(\"Author/Bob\", \"Publish Date/2010/10/15\");\n    add(\"Author/Lisa\", \"Publish Date/2010/10/20\");\n    add(\"Author/Lisa\", \"Publish Date/2012/1/1\");\n    add(\"Author/Susan\", \"Publish Date/2012/1/7\");\n    add(\"Author/Frank\", \"Publish Date/1999/5/5\");\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Count both \"Publish Date\" and \"Author\" dimensions:\n    FacetSearchParams fsp = new FacetSearchParams(\n        new CountFacetRequest(new CategoryPath(\"Publish Date\"), 10), \n        new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n\n    // Aggregatses the facet counts:\n    FacetsCollector c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    // Retrieve & verify results:\n    List<FacetResult> results = c.getFacetResults();\n    assertEquals(2, results.size());\n    assertEquals(\"Publish Date (5)\\n  2012 (2)\\n  2010 (2)\\n  1999 (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Frank (1)\\n  Susan (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(1)));\n\n    \n    // Now user drills down on Publish Date/2010:\n    fsp = new FacetSearchParams(new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n    Query q2 = DrillDown.query(fsp, new MatchAllDocsQuery(), Occur.MUST, new CategoryPath(\"Publish Date/2010\", '/'));\n    c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n    searcher.search(q2, c);\n    results = c.getFacetResults();\n    assertEquals(1, results.size());\n    assertEquals(\"Author (2)\\n  Lisa (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"61d5f95d14e5b9b046998c51e16709a398c15226","date":1359603451,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/TestDemoFacets#test().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/TestDemoFacets#test().mjava","sourceNew":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    writer = new RandomIndexWriter(random(), dir);\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    facetFields = new FacetFields(taxoWriter);\n\n    add(\"Author/Bob\", \"Publish Date/2010/10/15\");\n    add(\"Author/Lisa\", \"Publish Date/2010/10/20\");\n    add(\"Author/Lisa\", \"Publish Date/2012/1/1\");\n    add(\"Author/Susan\", \"Publish Date/2012/1/7\");\n    add(\"Author/Frank\", \"Publish Date/1999/5/5\");\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Count both \"Publish Date\" and \"Author\" dimensions:\n    FacetSearchParams fsp = new FacetSearchParams(\n        new CountFacetRequest(new CategoryPath(\"Publish Date\"), 10), \n        new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n\n    // Aggregatses the facet counts:\n    FacetsCollector c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    // Retrieve & verify results:\n    List<FacetResult> results = c.getFacetResults();\n    assertEquals(2, results.size());\n    assertEquals(\"Publish Date (0)\\n  2012 (2)\\n  2010 (2)\\n  1999 (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n    assertEquals(\"Author (0)\\n  Lisa (2)\\n  Frank (1)\\n  Susan (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(1)));\n\n    \n    // Now user drills down on Publish Date/2010:\n    fsp = new FacetSearchParams(new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n    Query q2 = DrillDown.query(fsp, new MatchAllDocsQuery(), Occur.MUST, new CategoryPath(\"Publish Date/2010\", '/'));\n    c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n    searcher.search(q2, c);\n    results = c.getFacetResults();\n    assertEquals(1, results.size());\n    assertEquals(\"Author (0)\\n  Lisa (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    writer = new RandomIndexWriter(random(), dir);\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    facetFields = new FacetFields(taxoWriter);\n\n    add(\"Author/Bob\", \"Publish Date/2010/10/15\");\n    add(\"Author/Lisa\", \"Publish Date/2010/10/20\");\n    add(\"Author/Lisa\", \"Publish Date/2012/1/1\");\n    add(\"Author/Susan\", \"Publish Date/2012/1/7\");\n    add(\"Author/Frank\", \"Publish Date/1999/5/5\");\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Count both \"Publish Date\" and \"Author\" dimensions:\n    FacetSearchParams fsp = new FacetSearchParams(\n        new CountFacetRequest(new CategoryPath(\"Publish Date\"), 10), \n        new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n\n    // Aggregatses the facet counts:\n    FacetsCollector c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    // Retrieve & verify results:\n    List<FacetResult> results = c.getFacetResults();\n    assertEquals(2, results.size());\n    assertEquals(\"Publish Date (5)\\n  2012 (2)\\n  2010 (2)\\n  1999 (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n    assertEquals(\"Author (5)\\n  Lisa (2)\\n  Frank (1)\\n  Susan (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(1)));\n\n    \n    // Now user drills down on Publish Date/2010:\n    fsp = new FacetSearchParams(new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n    Query q2 = DrillDown.query(fsp, new MatchAllDocsQuery(), Occur.MUST, new CategoryPath(\"Publish Date/2010\", '/'));\n    c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n    searcher.search(q2, c);\n    results = c.getFacetResults();\n    assertEquals(1, results.size());\n    assertEquals(\"Author (2)\\n  Lisa (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f793470bad5ce8422502e33eaae65fc6a3271bd2","date":1360479442,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/TestDemoFacets#test().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/TestDemoFacets#test().mjava","sourceNew":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    writer = new RandomIndexWriter(random(), dir);\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    facetFields = new FacetFields(taxoWriter);\n\n    add(\"Author/Bob\", \"Publish Date/2010/10/15\");\n    add(\"Author/Lisa\", \"Publish Date/2010/10/20\");\n    add(\"Author/Lisa\", \"Publish Date/2012/1/1\");\n    add(\"Author/Susan\", \"Publish Date/2012/1/7\");\n    add(\"Author/Frank\", \"Publish Date/1999/5/5\");\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Count both \"Publish Date\" and \"Author\" dimensions:\n    FacetSearchParams fsp = new FacetSearchParams(\n        new CountFacetRequest(new CategoryPath(\"Publish Date\"), 10), \n        new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n\n    // Aggregatses the facet counts:\n    FacetsCollector c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    // Retrieve & verify results:\n    List<FacetResult> results = c.getFacetResults();\n    assertEquals(2, results.size());\n    assertEquals(\"Publish Date (0)\\n  2012 (2)\\n  2010 (2)\\n  1999 (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n    assertEquals(\"Author (0)\\n  Lisa (2)\\n  Frank (1)\\n  Susan (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(1)));\n\n    \n    // Now user drills down on Publish Date/2010:\n    fsp = new FacetSearchParams(new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n    DrillDownQuery q2 = new DrillDownQuery(fsp.indexingParams, new MatchAllDocsQuery());\n    q2.add(new CategoryPath(\"Publish Date/2010\", '/'));\n    c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n    searcher.search(q2, c);\n    results = c.getFacetResults();\n    assertEquals(1, results.size());\n    assertEquals(\"Author (0)\\n  Lisa (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    writer = new RandomIndexWriter(random(), dir);\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    facetFields = new FacetFields(taxoWriter);\n\n    add(\"Author/Bob\", \"Publish Date/2010/10/15\");\n    add(\"Author/Lisa\", \"Publish Date/2010/10/20\");\n    add(\"Author/Lisa\", \"Publish Date/2012/1/1\");\n    add(\"Author/Susan\", \"Publish Date/2012/1/7\");\n    add(\"Author/Frank\", \"Publish Date/1999/5/5\");\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Count both \"Publish Date\" and \"Author\" dimensions:\n    FacetSearchParams fsp = new FacetSearchParams(\n        new CountFacetRequest(new CategoryPath(\"Publish Date\"), 10), \n        new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n\n    // Aggregatses the facet counts:\n    FacetsCollector c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    // Retrieve & verify results:\n    List<FacetResult> results = c.getFacetResults();\n    assertEquals(2, results.size());\n    assertEquals(\"Publish Date (0)\\n  2012 (2)\\n  2010 (2)\\n  1999 (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n    assertEquals(\"Author (0)\\n  Lisa (2)\\n  Frank (1)\\n  Susan (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(1)));\n\n    \n    // Now user drills down on Publish Date/2010:\n    fsp = new FacetSearchParams(new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n    Query q2 = DrillDown.query(fsp, new MatchAllDocsQuery(), Occur.MUST, new CategoryPath(\"Publish Date/2010\", '/'));\n    c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n    searcher.search(q2, c);\n    results = c.getFacetResults();\n    assertEquals(1, results.size());\n    assertEquals(\"Author (0)\\n  Lisa (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7258ce0dc97438594beb9d50d0d5db4f26da424a","date":1383851496,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/TestDemoFacets#test().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/TestDemoFacets#test().mjava","sourceNew":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    writer = new RandomIndexWriter(random(), dir);\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    facetFields = new FacetFields(taxoWriter);\n\n    add(\"Author/Bob\", \"Publish Date/2010/10/15\");\n    add(\"Author/Lisa\", \"Publish Date/2010/10/20\");\n    add(\"Author/Lisa\", \"Publish Date/2012/1/1\");\n    add(\"Author/Susan\", \"Publish Date/2012/1/7\");\n    add(\"Author/Frank\", \"Publish Date/1999/5/5\");\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Count both \"Publish Date\" and \"Author\" dimensions:\n    FacetSearchParams fsp = new FacetSearchParams(\n        new CountFacetRequest(new CategoryPath(\"Publish Date\"), 10), \n        new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n\n    // Aggregate the facet counts:\n    FacetsCollector c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    // Retrieve & verify results:\n    List<FacetResult> results = c.getFacetResults();\n    assertEquals(2, results.size());\n    assertEquals(\"Publish Date (0)\\n  2012 (2)\\n  2010 (2)\\n  1999 (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n    assertEquals(\"Author (0)\\n  Lisa (2)\\n  Frank (1)\\n  Susan (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(1)));\n\n    \n    // Now user drills down on Publish Date/2010:\n    fsp = new FacetSearchParams(new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n    DrillDownQuery q2 = new DrillDownQuery(fsp.indexingParams, new MatchAllDocsQuery());\n    q2.add(new CategoryPath(\"Publish Date/2010\", '/'));\n    c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n    searcher.search(q2, c);\n    results = c.getFacetResults();\n    assertEquals(1, results.size());\n    assertEquals(\"Author (0)\\n  Lisa (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    writer = new RandomIndexWriter(random(), dir);\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    facetFields = new FacetFields(taxoWriter);\n\n    add(\"Author/Bob\", \"Publish Date/2010/10/15\");\n    add(\"Author/Lisa\", \"Publish Date/2010/10/20\");\n    add(\"Author/Lisa\", \"Publish Date/2012/1/1\");\n    add(\"Author/Susan\", \"Publish Date/2012/1/7\");\n    add(\"Author/Frank\", \"Publish Date/1999/5/5\");\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Count both \"Publish Date\" and \"Author\" dimensions:\n    FacetSearchParams fsp = new FacetSearchParams(\n        new CountFacetRequest(new CategoryPath(\"Publish Date\"), 10), \n        new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n\n    // Aggregatses the facet counts:\n    FacetsCollector c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    // Retrieve & verify results:\n    List<FacetResult> results = c.getFacetResults();\n    assertEquals(2, results.size());\n    assertEquals(\"Publish Date (0)\\n  2012 (2)\\n  2010 (2)\\n  1999 (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n    assertEquals(\"Author (0)\\n  Lisa (2)\\n  Frank (1)\\n  Susan (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(1)));\n\n    \n    // Now user drills down on Publish Date/2010:\n    fsp = new FacetSearchParams(new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n    DrillDownQuery q2 = new DrillDownQuery(fsp.indexingParams, new MatchAllDocsQuery());\n    q2.add(new CategoryPath(\"Publish Date/2010\", '/'));\n    c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n    searcher.search(q2, c);\n    results = c.getFacetResults();\n    assertEquals(1, results.size());\n    assertEquals(\"Author (0)\\n  Lisa (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c190847801a50f4dd20fd639bdc29b54ea3b288b","date":1384461522,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/TestDemoFacets#test().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/TestDemoFacets#test().mjava","sourceNew":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    writer = new RandomIndexWriter(random(), dir);\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    facetFields = new FacetFields(taxoWriter);\n\n    add(\"Author/Bob\", \"Publish Date/2010/10/15\");\n    add(\"Author/Lisa\", \"Publish Date/2010/10/20\");\n    add(\"Author/Lisa\", \"Publish Date/2012/1/1\");\n    add(\"Author/Susan\", \"Publish Date/2012/1/7\");\n    add(\"Author/Frank\", \"Publish Date/1999/5/5\");\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Count both \"Publish Date\" and \"Author\" dimensions:\n    FacetSearchParams fsp = new FacetSearchParams(\n        new CountFacetRequest(new FacetLabel(\"Publish Date\"), 10), \n        new CountFacetRequest(new FacetLabel(\"Author\"), 10));\n\n    // Aggregate the facet counts:\n    FacetsCollector c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    // Retrieve & verify results:\n    List<FacetResult> results = c.getFacetResults();\n    assertEquals(2, results.size());\n    assertEquals(\"Publish Date (0)\\n  2012 (2)\\n  2010 (2)\\n  1999 (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n    assertEquals(\"Author (0)\\n  Lisa (2)\\n  Frank (1)\\n  Susan (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(1)));\n\n    \n    // Now user drills down on Publish Date/2010:\n    fsp = new FacetSearchParams(new CountFacetRequest(new FacetLabel(\"Author\"), 10));\n    DrillDownQuery q2 = new DrillDownQuery(fsp.indexingParams, new MatchAllDocsQuery());\n    q2.add(new FacetLabel(\"Publish Date/2010\", '/'));\n    c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n    searcher.search(q2, c);\n    results = c.getFacetResults();\n    assertEquals(1, results.size());\n    assertEquals(\"Author (0)\\n  Lisa (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    writer = new RandomIndexWriter(random(), dir);\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    facetFields = new FacetFields(taxoWriter);\n\n    add(\"Author/Bob\", \"Publish Date/2010/10/15\");\n    add(\"Author/Lisa\", \"Publish Date/2010/10/20\");\n    add(\"Author/Lisa\", \"Publish Date/2012/1/1\");\n    add(\"Author/Susan\", \"Publish Date/2012/1/7\");\n    add(\"Author/Frank\", \"Publish Date/1999/5/5\");\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Count both \"Publish Date\" and \"Author\" dimensions:\n    FacetSearchParams fsp = new FacetSearchParams(\n        new CountFacetRequest(new CategoryPath(\"Publish Date\"), 10), \n        new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n\n    // Aggregate the facet counts:\n    FacetsCollector c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    // Retrieve & verify results:\n    List<FacetResult> results = c.getFacetResults();\n    assertEquals(2, results.size());\n    assertEquals(\"Publish Date (0)\\n  2012 (2)\\n  2010 (2)\\n  1999 (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n    assertEquals(\"Author (0)\\n  Lisa (2)\\n  Frank (1)\\n  Susan (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(1)));\n\n    \n    // Now user drills down on Publish Date/2010:\n    fsp = new FacetSearchParams(new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n    DrillDownQuery q2 = new DrillDownQuery(fsp.indexingParams, new MatchAllDocsQuery());\n    q2.add(new CategoryPath(\"Publish Date/2010\", '/'));\n    c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n    searcher.search(q2, c);\n    results = c.getFacetResults();\n    assertEquals(1, results.size());\n    assertEquals(\"Author (0)\\n  Lisa (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"19f5022544a8fc895776356d1b35a4b46d05945c","date":1385063323,"type":4,"author":"Michael McCandless","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/TestDemoFacets#test().mjava","sourceNew":null,"sourceOld":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    writer = new RandomIndexWriter(random(), dir);\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    facetFields = new FacetFields(taxoWriter);\n\n    add(\"Author/Bob\", \"Publish Date/2010/10/15\");\n    add(\"Author/Lisa\", \"Publish Date/2010/10/20\");\n    add(\"Author/Lisa\", \"Publish Date/2012/1/1\");\n    add(\"Author/Susan\", \"Publish Date/2012/1/7\");\n    add(\"Author/Frank\", \"Publish Date/1999/5/5\");\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Count both \"Publish Date\" and \"Author\" dimensions:\n    FacetSearchParams fsp = new FacetSearchParams(\n        new CountFacetRequest(new FacetLabel(\"Publish Date\"), 10), \n        new CountFacetRequest(new FacetLabel(\"Author\"), 10));\n\n    // Aggregate the facet counts:\n    FacetsCollector c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    // Retrieve & verify results:\n    List<FacetResult> results = c.getFacetResults();\n    assertEquals(2, results.size());\n    assertEquals(\"Publish Date (0)\\n  2012 (2)\\n  2010 (2)\\n  1999 (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n    assertEquals(\"Author (0)\\n  Lisa (2)\\n  Frank (1)\\n  Susan (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(1)));\n\n    \n    // Now user drills down on Publish Date/2010:\n    fsp = new FacetSearchParams(new CountFacetRequest(new FacetLabel(\"Author\"), 10));\n    DrillDownQuery q2 = new DrillDownQuery(fsp.indexingParams, new MatchAllDocsQuery());\n    q2.add(new FacetLabel(\"Publish Date/2010\", '/'));\n    c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n    searcher.search(q2, c);\n    results = c.getFacetResults();\n    assertEquals(1, results.size());\n    assertEquals(\"Author (0)\\n  Lisa (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3cc728b07df73b197e6d940d27f9b08b63918f13","date":1388834348,"type":4,"author":"Michael McCandless","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/TestDemoFacets#test().mjava","sourceNew":null,"sourceOld":"  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    writer = new RandomIndexWriter(random(), dir);\n\n    // Writes facet ords to a separate directory from the\n    // main index:\n    taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    // Reused across documents, to add the necessary facet\n    // fields:\n    facetFields = new FacetFields(taxoWriter);\n\n    add(\"Author/Bob\", \"Publish Date/2010/10/15\");\n    add(\"Author/Lisa\", \"Publish Date/2010/10/20\");\n    add(\"Author/Lisa\", \"Publish Date/2012/1/1\");\n    add(\"Author/Susan\", \"Publish Date/2012/1/7\");\n    add(\"Author/Frank\", \"Publish Date/1999/5/5\");\n\n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    writer.close();\n\n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    taxoWriter.close();\n\n    // Count both \"Publish Date\" and \"Author\" dimensions:\n    FacetSearchParams fsp = new FacetSearchParams(\n        new CountFacetRequest(new CategoryPath(\"Publish Date\"), 10), \n        new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n\n    // Aggregate the facet counts:\n    FacetsCollector c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n\n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n\n    // Retrieve & verify results:\n    List<FacetResult> results = c.getFacetResults();\n    assertEquals(2, results.size());\n    assertEquals(\"Publish Date (0)\\n  2012 (2)\\n  2010 (2)\\n  1999 (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n    assertEquals(\"Author (0)\\n  Lisa (2)\\n  Frank (1)\\n  Susan (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(1)));\n\n    \n    // Now user drills down on Publish Date/2010:\n    fsp = new FacetSearchParams(new CountFacetRequest(new CategoryPath(\"Author\"), 10));\n    DrillDownQuery q2 = new DrillDownQuery(fsp.indexingParams, new MatchAllDocsQuery());\n    q2.add(new CategoryPath(\"Publish Date/2010\", '/'));\n    c = FacetsCollector.create(fsp, searcher.getIndexReader(), taxoReader);\n    searcher.search(q2, c);\n    results = c.getFacetResults();\n    assertEquals(1, results.size());\n    assertEquals(\"Author (0)\\n  Lisa (1)\\n  Bob (1)\\n\",\n        FacetTestUtils.toSimpleString(results.get(0)));\n\n    // Smoke test PrintTaxonomyStats:\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    PrintTaxonomyStats.printStats(taxoReader, new PrintStream(bos, false, \"UTF-8\"), true);\n    String result = bos.toString(\"UTF-8\");\n    assertTrue(result.indexOf(\"/Author: 4 immediate children; 5 total categories\") != -1);\n    assertTrue(result.indexOf(\"/Publish Date: 3 immediate children; 12 total categories\") != -1);\n    // Make sure at least a few nodes of the tree came out:\n    assertTrue(result.indexOf(\"  /1999\") != -1);\n    assertTrue(result.indexOf(\"  /2012\") != -1);\n    assertTrue(result.indexOf(\"      /20\") != -1);\n\n    taxoReader.close();\n    searcher.getIndexReader().close();\n    dir.close();\n    taxoDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","7a1037d9031f9702ee6912f8751ef1d5320da6d9"],"f96e4a056f7ee1bafbfb8a06c5bd93f7708e560d":["7a1037d9031f9702ee6912f8751ef1d5320da6d9"],"9fa7a3db4fa6c77f454964f515841c097ca09212":["90213788e5007cc5e2b3d88200a8265de9d4e6d4"],"7a1037d9031f9702ee6912f8751ef1d5320da6d9":["d4c6c7f3cda7a0595cabd16e5e9107ca29852708"],"9aec76e44cc718c8a51f11f0a498e1a34efffb42":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"19f5022544a8fc895776356d1b35a4b46d05945c":["c190847801a50f4dd20fd639bdc29b54ea3b288b"],"dd45d4a2ee01a1932d33eec42f5272c2402da679":["07155cdd910937cdf6877e48884d5782845c8b8b","9fa7a3db4fa6c77f454964f515841c097ca09212"],"07155cdd910937cdf6877e48884d5782845c8b8b":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","224d71a68a47e867c96b8134405615e90f815f84"],"7258ce0dc97438594beb9d50d0d5db4f26da424a":["f793470bad5ce8422502e33eaae65fc6a3271bd2"],"f793470bad5ce8422502e33eaae65fc6a3271bd2":["239f79ed06f0979cfe1911ec5fba32b94fda43c1"],"c190847801a50f4dd20fd639bdc29b54ea3b288b":["7258ce0dc97438594beb9d50d0d5db4f26da424a"],"90213788e5007cc5e2b3d88200a8265de9d4e6d4":["224d71a68a47e867c96b8134405615e90f815f84"],"61d5f95d14e5b9b046998c51e16709a398c15226":["dd45d4a2ee01a1932d33eec42f5272c2402da679","239f79ed06f0979cfe1911ec5fba32b94fda43c1"],"d4c6c7f3cda7a0595cabd16e5e9107ca29852708":["9aec76e44cc718c8a51f11f0a498e1a34efffb42"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"239f79ed06f0979cfe1911ec5fba32b94fda43c1":["9fa7a3db4fa6c77f454964f515841c097ca09212"],"3cc728b07df73b197e6d940d27f9b08b63918f13":["7258ce0dc97438594beb9d50d0d5db4f26da424a","19f5022544a8fc895776356d1b35a4b46d05945c"],"224d71a68a47e867c96b8134405615e90f815f84":["f96e4a056f7ee1bafbfb8a06c5bd93f7708e560d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3cc728b07df73b197e6d940d27f9b08b63918f13"]},"commit2Childs":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["07155cdd910937cdf6877e48884d5782845c8b8b"],"f96e4a056f7ee1bafbfb8a06c5bd93f7708e560d":["224d71a68a47e867c96b8134405615e90f815f84"],"7a1037d9031f9702ee6912f8751ef1d5320da6d9":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","f96e4a056f7ee1bafbfb8a06c5bd93f7708e560d"],"9fa7a3db4fa6c77f454964f515841c097ca09212":["dd45d4a2ee01a1932d33eec42f5272c2402da679","239f79ed06f0979cfe1911ec5fba32b94fda43c1"],"9aec76e44cc718c8a51f11f0a498e1a34efffb42":["d4c6c7f3cda7a0595cabd16e5e9107ca29852708"],"19f5022544a8fc895776356d1b35a4b46d05945c":["3cc728b07df73b197e6d940d27f9b08b63918f13"],"dd45d4a2ee01a1932d33eec42f5272c2402da679":["61d5f95d14e5b9b046998c51e16709a398c15226"],"07155cdd910937cdf6877e48884d5782845c8b8b":["dd45d4a2ee01a1932d33eec42f5272c2402da679"],"7258ce0dc97438594beb9d50d0d5db4f26da424a":["c190847801a50f4dd20fd639bdc29b54ea3b288b","3cc728b07df73b197e6d940d27f9b08b63918f13"],"f793470bad5ce8422502e33eaae65fc6a3271bd2":["7258ce0dc97438594beb9d50d0d5db4f26da424a"],"c190847801a50f4dd20fd639bdc29b54ea3b288b":["19f5022544a8fc895776356d1b35a4b46d05945c"],"90213788e5007cc5e2b3d88200a8265de9d4e6d4":["9fa7a3db4fa6c77f454964f515841c097ca09212"],"61d5f95d14e5b9b046998c51e16709a398c15226":[],"d4c6c7f3cda7a0595cabd16e5e9107ca29852708":["7a1037d9031f9702ee6912f8751ef1d5320da6d9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","9aec76e44cc718c8a51f11f0a498e1a34efffb42"],"239f79ed06f0979cfe1911ec5fba32b94fda43c1":["f793470bad5ce8422502e33eaae65fc6a3271bd2","61d5f95d14e5b9b046998c51e16709a398c15226"],"3cc728b07df73b197e6d940d27f9b08b63918f13":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"224d71a68a47e867c96b8134405615e90f815f84":["07155cdd910937cdf6877e48884d5782845c8b8b","90213788e5007cc5e2b3d88200a8265de9d4e6d4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["61d5f95d14e5b9b046998c51e16709a398c15226","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}