{"path":"src/java/org/apache/lucene/analysis/CharTokenizer#next().mjava","commits":[{"id":"ba388d9c5138e103816965577c37f8466bacce4b","date":1011898972,"type":1,"author":"Doug Cutting","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/CharTokenizer#next().mjava","pathOld":"src/java/org/apache/lucene/analysis/LetterTokenizer#next().mjava","sourceNew":"  /** Returns the next token in the stream, or null at EOS. */\n  public final Token next() throws java.io.IOException {\n    int length = 0;\n    int start = offset;\n    while (true) {\n      final char c;\n\n      offset++;\n      if (bufferIndex >= dataLen) {\n        dataLen = input.read(ioBuffer);\n        bufferIndex = 0;\n      };\n      if (dataLen == -1) {\n\tif (length > 0)\n\t  break;\n\telse\n\t  return null;\n      }\n      else\n        c = (char) ioBuffer[bufferIndex++];\n      \n      if (isTokenChar(c)) {                       // if it's a token char\n\n\tif (length == 0)\t\t\t  // start of token\n\t  start = offset-1;\n\n\tbuffer[length++] = normalize(c);          // buffer it, normalized\n\n\tif (length == MAX_WORD_LEN)\t\t  // buffer overflow!\n\t  break;\n\n      } else if (length > 0)\t\t\t  // at non-Letter w/ chars\n\tbreak;\t\t\t\t\t  // return 'em\n\n    }\n\n    return new Token(new String(buffer, 0, length), start, start+length);\n  }\n\n","sourceOld":"  public final Token next() throws java.io.IOException {\n    int length = 0;\n    int start = offset;\n    while (true) {\n      final char c;\n\n      offset++;\n      if (bufferIndex >= dataLen) {\n        dataLen = input.read(ioBuffer);\n        bufferIndex = 0;\n      };\n      if (dataLen == -1) {\n\tif (length > 0)\n\t  break;\n\telse\n\t  return null;\n      }\n      else\n        c = (char) ioBuffer[bufferIndex++];\n      \n      if (Character.isLetter(c)) {\t\t  // if it's a letter\n\n\tif (length == 0)\t\t\t  // start of token\n\t  start = offset-1;\n\n\tbuffer[length++] = c;\t\t\t  // buffer it\n\n\tif (length == MAX_WORD_LEN)\t\t  // buffer overflow!\n\t  break;\n\n      } else if (length > 0)\t\t\t  // at non-Letter w/ chars\n\tbreak;\t\t\t\t\t  // return 'em\n\n    }\n\n    return new Token(new String(buffer, 0, length), start, start+length);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"57ccb7a1556d155f11fe658338607c75cd919eb1","date":1068598850,"type":3,"author":"Erik Hatcher","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/CharTokenizer#next().mjava","pathOld":"src/java/org/apache/lucene/analysis/CharTokenizer#next().mjava","sourceNew":"  /** Returns the next token in the stream, or null at EOS. */\n  public final Token next() throws java.io.IOException {\n    int length = 0;\n    int start = offset;\n    while (true) {\n      final char c;\n\n      offset++;\n      if (bufferIndex >= dataLen) {\n        dataLen = input.read(ioBuffer);\n        bufferIndex = 0;\n      }\n      ;\n      if (dataLen == -1) {\n        if (length > 0)\n          break;\n        else\n          return null;\n      } else\n        c = ioBuffer[bufferIndex++];\n\n      if (isTokenChar(c)) {               // if it's a token char\n\n        if (length == 0)\t\t\t           // start of token\n          start = offset - 1;\n\n        buffer[length++] = normalize(c); // buffer it, normalized\n\n        if (length == MAX_WORD_LEN)\t\t   // buffer overflow!\n          break;\n\n      } else if (length > 0)             // at non-Letter w/ chars\n        break;                           // return 'em\n\n    }\n\n    return new Token(new String(buffer, 0, length), start, start + length);\n  }\n\n","sourceOld":"  /** Returns the next token in the stream, or null at EOS. */\n  public final Token next() throws java.io.IOException {\n    int length = 0;\n    int start = offset;\n    while (true) {\n      final char c;\n\n      offset++;\n      if (bufferIndex >= dataLen) {\n        dataLen = input.read(ioBuffer);\n        bufferIndex = 0;\n      };\n      if (dataLen == -1) {\n\tif (length > 0)\n\t  break;\n\telse\n\t  return null;\n      }\n      else\n        c = (char) ioBuffer[bufferIndex++];\n      \n      if (isTokenChar(c)) {                       // if it's a token char\n\n\tif (length == 0)\t\t\t  // start of token\n\t  start = offset-1;\n\n\tbuffer[length++] = normalize(c);          // buffer it, normalized\n\n\tif (length == MAX_WORD_LEN)\t\t  // buffer overflow!\n\t  break;\n\n      } else if (length > 0)\t\t\t  // at non-Letter w/ chars\n\tbreak;\t\t\t\t\t  // return 'em\n\n    }\n\n    return new Token(new String(buffer, 0, length), start, start+length);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"130bb5646654c8ba311d3fe3cc0ff363d93240be","date":1100013136,"type":3,"author":"Erik Hatcher","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/CharTokenizer#next().mjava","pathOld":"src/java/org/apache/lucene/analysis/CharTokenizer#next().mjava","sourceNew":"  /** Returns the next token in the stream, or null at EOS. */\n  public final Token next() throws IOException {\n    int length = 0;\n    int start = offset;\n    while (true) {\n      final char c;\n\n      offset++;\n      if (bufferIndex >= dataLen) {\n        dataLen = input.read(ioBuffer);\n        bufferIndex = 0;\n      }\n      ;\n      if (dataLen == -1) {\n        if (length > 0)\n          break;\n        else\n          return null;\n      } else\n        c = ioBuffer[bufferIndex++];\n\n      if (isTokenChar(c)) {               // if it's a token char\n\n        if (length == 0)\t\t\t           // start of token\n          start = offset - 1;\n\n        buffer[length++] = normalize(c); // buffer it, normalized\n\n        if (length == MAX_WORD_LEN)\t\t   // buffer overflow!\n          break;\n\n      } else if (length > 0)             // at non-Letter w/ chars\n        break;                           // return 'em\n\n    }\n\n    return new Token(new String(buffer, 0, length), start, start + length);\n  }\n\n","sourceOld":"  /** Returns the next token in the stream, or null at EOS. */\n  public final Token next() throws java.io.IOException {\n    int length = 0;\n    int start = offset;\n    while (true) {\n      final char c;\n\n      offset++;\n      if (bufferIndex >= dataLen) {\n        dataLen = input.read(ioBuffer);\n        bufferIndex = 0;\n      }\n      ;\n      if (dataLen == -1) {\n        if (length > 0)\n          break;\n        else\n          return null;\n      } else\n        c = ioBuffer[bufferIndex++];\n\n      if (isTokenChar(c)) {               // if it's a token char\n\n        if (length == 0)\t\t\t           // start of token\n          start = offset - 1;\n\n        buffer[length++] = normalize(c); // buffer it, normalized\n\n        if (length == MAX_WORD_LEN)\t\t   // buffer overflow!\n          break;\n\n      } else if (length > 0)             // at non-Letter w/ chars\n        break;                           // return 'em\n\n    }\n\n    return new Token(new String(buffer, 0, length), start, start + length);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6864413dbc0c12104c978c05456f3da1d45adb03","date":1186770873,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/CharTokenizer#next(Token).mjava","pathOld":"src/java/org/apache/lucene/analysis/CharTokenizer#next().mjava","sourceNew":"  public final Token next(Token token) throws IOException {\n    int length = 0;\n    int start = bufferIndex;\n    char[] buffer = token.termBuffer();\n    while (true) {\n\n      if (bufferIndex >= dataLen) {\n        offset += dataLen;\n        dataLen = input.read(ioBuffer);\n        if (dataLen == -1) {\n          if (length > 0)\n            break;\n          else\n            return null;\n        }\n        bufferIndex = 0;\n      }\n\n      final char c = ioBuffer[bufferIndex++];\n\n      if (isTokenChar(c)) {               // if it's a token char\n\n        if (length == 0)\t\t\t           // start of token\n          start = offset + bufferIndex - 1;\n        else if (length == buffer.length)\n          buffer = token.resizeTermBuffer(1+length);\n\n        buffer[length++] = normalize(c); // buffer it, normalized\n\n        if (length == MAX_WORD_LEN)\t\t   // buffer overflow!\n          break;\n\n      } else if (length > 0)             // at non-Letter w/ chars\n        break;                           // return 'em\n    }\n\n    token.termLength = length;\n    token.startOffset = start;\n    token.endOffset = start+length;\n    return token;\n  }\n\n","sourceOld":"  /** Returns the next token in the stream, or null at EOS. */\n  public final Token next() throws IOException {\n    int length = 0;\n    int start = offset;\n    while (true) {\n      final char c;\n\n      offset++;\n      if (bufferIndex >= dataLen) {\n        dataLen = input.read(ioBuffer);\n        bufferIndex = 0;\n      }\n      ;\n      if (dataLen == -1) {\n        if (length > 0)\n          break;\n        else\n          return null;\n      } else\n        c = ioBuffer[bufferIndex++];\n\n      if (isTokenChar(c)) {               // if it's a token char\n\n        if (length == 0)\t\t\t           // start of token\n          start = offset - 1;\n\n        buffer[length++] = normalize(c); // buffer it, normalized\n\n        if (length == MAX_WORD_LEN)\t\t   // buffer overflow!\n          break;\n\n      } else if (length > 0)             // at non-Letter w/ chars\n        break;                           // return 'em\n\n    }\n\n    return new Token(new String(buffer, 0, length), start, start + length);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ec8b5a20a12931b8d7e616c79c5248ae06cc5568","date":1248471948,"type":0,"author":"Michael Busch","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/CharTokenizer#next().mjava","pathOld":"/dev/null","sourceNew":"  /** @deprecated Will be removed in Lucene 3.0. This method is final, as it should\n   * not be overridden. Delegates to the backwards compatibility layer. */\n  public final Token next() throws IOException {\n    return super.next();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"439b0fe2f799d1c722151e88e32bdefad8d34ebe","date":1255282509,"type":4,"author":"Uwe Schindler","isMerge":false,"pathNew":"/dev/null","pathOld":"src/java/org/apache/lucene/analysis/CharTokenizer#next().mjava","sourceNew":null,"sourceOld":"  /** @deprecated Will be removed in Lucene 3.0. This method is final, as it should\n   * not be overridden. Delegates to the backwards compatibility layer. */\n  public final Token next() throws IOException {\n    return super.next();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"130bb5646654c8ba311d3fe3cc0ff363d93240be":["57ccb7a1556d155f11fe658338607c75cd919eb1"],"6864413dbc0c12104c978c05456f3da1d45adb03":["130bb5646654c8ba311d3fe3cc0ff363d93240be"],"57ccb7a1556d155f11fe658338607c75cd919eb1":["ba388d9c5138e103816965577c37f8466bacce4b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"439b0fe2f799d1c722151e88e32bdefad8d34ebe":["ec8b5a20a12931b8d7e616c79c5248ae06cc5568"],"ba388d9c5138e103816965577c37f8466bacce4b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["439b0fe2f799d1c722151e88e32bdefad8d34ebe"],"ec8b5a20a12931b8d7e616c79c5248ae06cc5568":["6864413dbc0c12104c978c05456f3da1d45adb03"]},"commit2Childs":{"130bb5646654c8ba311d3fe3cc0ff363d93240be":["6864413dbc0c12104c978c05456f3da1d45adb03"],"6864413dbc0c12104c978c05456f3da1d45adb03":["ec8b5a20a12931b8d7e616c79c5248ae06cc5568"],"57ccb7a1556d155f11fe658338607c75cd919eb1":["130bb5646654c8ba311d3fe3cc0ff363d93240be"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ba388d9c5138e103816965577c37f8466bacce4b"],"439b0fe2f799d1c722151e88e32bdefad8d34ebe":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ba388d9c5138e103816965577c37f8466bacce4b":["57ccb7a1556d155f11fe658338607c75cd919eb1"],"ec8b5a20a12931b8d7e616c79c5248ae06cc5568":["439b0fe2f799d1c722151e88e32bdefad8d34ebe"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}