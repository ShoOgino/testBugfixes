{"path":"solr/core/src/test/org/apache/solr/cloud/ShardRoutingTest#doHashingTest().mjava","commits":[{"id":"70cbbf09b1986180fc73b08b8ded592b3465806b","date":1355001417,"type":0,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardRoutingTest#doHashingTest().mjava","pathOld":"/dev/null","sourceNew":"  private void doHashingTest() throws Exception {\n    assertEquals(4, cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION).getSlices().size());\n    String shardKeys = ShardParams.SHARD_KEYS;\n    // for now,  we know how ranges will be distributed to shards.\n    // may have to look it up in clusterstate if that assumption changes.\n\n    String bucket1 = \"shard1\";      // shard1: top bits:10  80000000:bfffffff\n    String bucket2 = \"shard2\";      // shard2: top bits:11  c0000000:ffffffff\n    String bucket3 = \"shard3\";      // shard3: top bits:00  00000000:3fffffff\n    String bucket4 = \"shard4\";      // shard4: top bits:01  40000000:7fffffff\n\n    doAddDoc(\"b!doc1\");\n    doAddDoc(\"c!doc2\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n    commit();\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", \"shards\",\"shard1,shard2,shard3,shard4\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,c!,d!,e!\");\n    doQuery(\"b!doc1\", \"q\",\"*:*\", shardKeys,\"b!\");\n    doQuery(\"b!doc1\", \"q\",\"*:*\", \"shards\",bucket1);\n    doQuery(\"c!doc2\", \"q\",\"*:*\", shardKeys,\"c!\");\n    doQuery(\"d!doc3\", \"q\",\"*:*\", shardKeys,\"d!\");\n    doQuery(\"e!doc4\", \"q\",\"*:*\", shardKeys,\"e!\");\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n    doQuery(\"b!doc1,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,e!\");\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b,c\");     // query shards that would contain *documents* \"b\" and \"c\" (i.e. not prefixes).  The upper bits are the same, so the shards should be the same.\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b/1!\");   // top bit of hash(b)==1, so shard1 and shard2\n    doQuery(\"d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"d/1!\");   // top bit of hash(b)==0, so shard3 and shard4\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"foo/0!\");\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f5950eb64b8186de9916cbfc47470784523079a","date":1355004015,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardRoutingTest#doHashingTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardRoutingTest#doHashingTest().mjava","sourceNew":"  private void doHashingTest() throws Exception {\n    assertEquals(4, cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION).getSlices().size());\n    String shardKeys = ShardParams.SHARD_KEYS;\n    // for now,  we know how ranges will be distributed to shards.\n    // may have to look it up in clusterstate if that assumption changes.\n\n    String bucket1 = \"shard1\";      // shard1: top bits:10  80000000:bfffffff\n    String bucket2 = \"shard2\";      // shard2: top bits:11  c0000000:ffffffff\n    String bucket3 = \"shard3\";      // shard3: top bits:00  00000000:3fffffff\n    String bucket4 = \"shard4\";      // shard4: top bits:01  40000000:7fffffff\n\n    doAddDoc(\"b!doc1\");\n    doAddDoc(\"c!doc2\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n\n    doRTG(\"b!doc1\");\n    doRTG(\"c!doc2\");\n    doRTG(\"d!doc3\");\n    doRTG(\"e!doc4\");\n    doRTG(\"b!doc1,c!doc2\");\n    doRTG(\"d!doc3,e!doc4\");\n\n    commit();\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", \"shards\",\"shard1,shard2,shard3,shard4\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,c!,d!,e!\");\n    doQuery(\"b!doc1\", \"q\",\"*:*\", shardKeys,\"b!\");\n    doQuery(\"b!doc1\", \"q\",\"*:*\", \"shards\",bucket1);\n    doQuery(\"c!doc2\", \"q\",\"*:*\", shardKeys,\"c!\");\n    doQuery(\"d!doc3\", \"q\",\"*:*\", shardKeys,\"d!\");\n    doQuery(\"e!doc4\", \"q\",\"*:*\", shardKeys,\"e!\");\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n    doQuery(\"b!doc1,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,e!\");\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b,c\");     // query shards that would contain *documents* \"b\" and \"c\" (i.e. not prefixes).  The upper bits are the same, so the shards should be the same.\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b/1!\");   // top bit of hash(b)==1, so shard1 and shard2\n    doQuery(\"d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"d/1!\");   // top bit of hash(b)==0, so shard3 and shard4\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"foo/0!\");\n  }\n\n","sourceOld":"  private void doHashingTest() throws Exception {\n    assertEquals(4, cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION).getSlices().size());\n    String shardKeys = ShardParams.SHARD_KEYS;\n    // for now,  we know how ranges will be distributed to shards.\n    // may have to look it up in clusterstate if that assumption changes.\n\n    String bucket1 = \"shard1\";      // shard1: top bits:10  80000000:bfffffff\n    String bucket2 = \"shard2\";      // shard2: top bits:11  c0000000:ffffffff\n    String bucket3 = \"shard3\";      // shard3: top bits:00  00000000:3fffffff\n    String bucket4 = \"shard4\";      // shard4: top bits:01  40000000:7fffffff\n\n    doAddDoc(\"b!doc1\");\n    doAddDoc(\"c!doc2\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n    commit();\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", \"shards\",\"shard1,shard2,shard3,shard4\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,c!,d!,e!\");\n    doQuery(\"b!doc1\", \"q\",\"*:*\", shardKeys,\"b!\");\n    doQuery(\"b!doc1\", \"q\",\"*:*\", \"shards\",bucket1);\n    doQuery(\"c!doc2\", \"q\",\"*:*\", shardKeys,\"c!\");\n    doQuery(\"d!doc3\", \"q\",\"*:*\", shardKeys,\"d!\");\n    doQuery(\"e!doc4\", \"q\",\"*:*\", shardKeys,\"e!\");\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n    doQuery(\"b!doc1,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,e!\");\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b,c\");     // query shards that would contain *documents* \"b\" and \"c\" (i.e. not prefixes).  The upper bits are the same, so the shards should be the same.\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b/1!\");   // top bit of hash(b)==1, so shard1 and shard2\n    doQuery(\"d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"d/1!\");   // top bit of hash(b)==0, so shard3 and shard4\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"foo/0!\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eec5368fa415ebab044b7ae01de50d5b49519b7e","date":1355029764,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardRoutingTest#doHashingTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardRoutingTest#doHashingTest().mjava","sourceNew":"  private void doHashingTest() throws Exception {\n    assertEquals(4, cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION).getSlices().size());\n    String shardKeys = ShardParams.SHARD_KEYS;\n    // for now,  we know how ranges will be distributed to shards.\n    // may have to look it up in clusterstate if that assumption changes.\n\n    String bucket1 = \"shard1\";      // shard1: top bits:10  80000000:bfffffff\n    String bucket2 = \"shard2\";      // shard2: top bits:11  c0000000:ffffffff\n    String bucket3 = \"shard3\";      // shard3: top bits:00  00000000:3fffffff\n    String bucket4 = \"shard4\";      // shard4: top bits:01  40000000:7fffffff\n\n    doAddDoc(\"b!doc1\");\n    doAddDoc(\"c!doc2\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n\n    doRTG(\"b!doc1\");\n    doRTG(\"c!doc2\");\n    doRTG(\"d!doc3\");\n    doRTG(\"e!doc4\");\n    doRTG(\"b!doc1,c!doc2\");\n    doRTG(\"d!doc3,e!doc4\");\n\n    commit();\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", \"shards\",\"shard1,shard2,shard3,shard4\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,c!,d!,e!\");\n    doQuery(\"b!doc1\", \"q\",\"*:*\", shardKeys,\"b!\");\n    doQuery(\"b!doc1\", \"q\",\"*:*\", \"shards\",bucket1);\n    doQuery(\"c!doc2\", \"q\",\"*:*\", shardKeys,\"c!\");\n    doQuery(\"d!doc3\", \"q\",\"*:*\", shardKeys,\"d!\");\n    doQuery(\"e!doc4\", \"q\",\"*:*\", shardKeys,\"e!\");\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n    doQuery(\"b!doc1,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,e!\");\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b,c\");     // query shards that would contain *documents* \"b\" and \"c\" (i.e. not prefixes).  The upper bits are the same, so the shards should be the same.\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b/1!\");   // top bit of hash(b)==1, so shard1 and shard2\n    doQuery(\"d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"d/1!\");   // top bit of hash(b)==0, so shard3 and shard4\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"foo/0!\");\n\n    doDBQ(\"*:*\", shardKeys,\"b!\");\n    commit();\n    doQuery(\"c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"b!doc1\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"d!,e!\");\n    commit();\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n  }\n\n","sourceOld":"  private void doHashingTest() throws Exception {\n    assertEquals(4, cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION).getSlices().size());\n    String shardKeys = ShardParams.SHARD_KEYS;\n    // for now,  we know how ranges will be distributed to shards.\n    // may have to look it up in clusterstate if that assumption changes.\n\n    String bucket1 = \"shard1\";      // shard1: top bits:10  80000000:bfffffff\n    String bucket2 = \"shard2\";      // shard2: top bits:11  c0000000:ffffffff\n    String bucket3 = \"shard3\";      // shard3: top bits:00  00000000:3fffffff\n    String bucket4 = \"shard4\";      // shard4: top bits:01  40000000:7fffffff\n\n    doAddDoc(\"b!doc1\");\n    doAddDoc(\"c!doc2\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n\n    doRTG(\"b!doc1\");\n    doRTG(\"c!doc2\");\n    doRTG(\"d!doc3\");\n    doRTG(\"e!doc4\");\n    doRTG(\"b!doc1,c!doc2\");\n    doRTG(\"d!doc3,e!doc4\");\n\n    commit();\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", \"shards\",\"shard1,shard2,shard3,shard4\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,c!,d!,e!\");\n    doQuery(\"b!doc1\", \"q\",\"*:*\", shardKeys,\"b!\");\n    doQuery(\"b!doc1\", \"q\",\"*:*\", \"shards\",bucket1);\n    doQuery(\"c!doc2\", \"q\",\"*:*\", shardKeys,\"c!\");\n    doQuery(\"d!doc3\", \"q\",\"*:*\", shardKeys,\"d!\");\n    doQuery(\"e!doc4\", \"q\",\"*:*\", shardKeys,\"e!\");\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n    doQuery(\"b!doc1,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,e!\");\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b,c\");     // query shards that would contain *documents* \"b\" and \"c\" (i.e. not prefixes).  The upper bits are the same, so the shards should be the same.\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b/1!\");   // top bit of hash(b)==1, so shard1 and shard2\n    doQuery(\"d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"d/1!\");   // top bit of hash(b)==0, so shard3 and shard4\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"foo/0!\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"919e6b4fea3dbc81ee31eff28b2b74b057f5361f","date":1355072041,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardRoutingTest#doHashingTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardRoutingTest#doHashingTest().mjava","sourceNew":"  private void doHashingTest() throws Exception {\n    assertEquals(4, cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION).getSlices().size());\n    String shardKeys = ShardParams.SHARD_KEYS;\n    // for now,  we know how ranges will be distributed to shards.\n    // may have to look it up in clusterstate if that assumption changes.\n\n    String bucket1 = \"shard1\";      // shard1: top bits:10  80000000:bfffffff\n    String bucket2 = \"shard2\";      // shard2: top bits:11  c0000000:ffffffff\n    String bucket3 = \"shard3\";      // shard3: top bits:00  00000000:3fffffff\n    String bucket4 = \"shard4\";      // shard4: top bits:01  40000000:7fffffff\n\n    doAddDoc(\"b!doc1\");\n    doAddDoc(\"c!doc2\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n\n    doRTG(\"b!doc1\");\n    doRTG(\"c!doc2\");\n    doRTG(\"d!doc3\");\n    doRTG(\"e!doc4\");\n    doRTG(\"b!doc1,c!doc2\");\n    doRTG(\"d!doc3,e!doc4\");\n\n    commit();\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", \"shards\",\"shard1,shard2,shard3,shard4\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,c!,d!,e!\");\n    doQuery(\"b!doc1\", \"q\",\"*:*\", shardKeys,\"b!\");\n    doQuery(\"c!doc2\", \"q\",\"*:*\", shardKeys,\"c!\");\n    doQuery(\"d!doc3\", \"q\",\"*:*\", shardKeys,\"d!\");\n    doQuery(\"e!doc4\", \"q\",\"*:*\", shardKeys,\"e!\");\n\n    // try using shards parameter\n    doQuery(\"b!doc1\", \"q\",\"*:*\", \"shards\",bucket1);\n    doQuery(\"c!doc2\", \"q\",\"*:*\", \"shards\",bucket2);\n    doQuery(\"d!doc3\", \"q\",\"*:*\", \"shards\",bucket3);\n    doQuery(\"e!doc4\", \"q\",\"*:*\", \"shards\",bucket4);\n\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n    doQuery(\"b!doc1,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,e!\");\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b,c\");     // query shards that would contain *documents* \"b\" and \"c\" (i.e. not prefixes).  The upper bits are the same, so the shards should be the same.\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b/1!\");   // top bit of hash(b)==1, so shard1 and shard2\n    doQuery(\"d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"d/1!\");   // top bit of hash(b)==0, so shard3 and shard4\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"foo/0!\");\n\n    // test targeting deleteByQuery at only certain shards\n    doDBQ(\"*:*\", shardKeys,\"b!\");\n    commit();\n    doQuery(\"c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"b!doc1\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"d!,e!\");\n    commit();\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n\n    commit();\n\n\n  }\n\n","sourceOld":"  private void doHashingTest() throws Exception {\n    assertEquals(4, cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION).getSlices().size());\n    String shardKeys = ShardParams.SHARD_KEYS;\n    // for now,  we know how ranges will be distributed to shards.\n    // may have to look it up in clusterstate if that assumption changes.\n\n    String bucket1 = \"shard1\";      // shard1: top bits:10  80000000:bfffffff\n    String bucket2 = \"shard2\";      // shard2: top bits:11  c0000000:ffffffff\n    String bucket3 = \"shard3\";      // shard3: top bits:00  00000000:3fffffff\n    String bucket4 = \"shard4\";      // shard4: top bits:01  40000000:7fffffff\n\n    doAddDoc(\"b!doc1\");\n    doAddDoc(\"c!doc2\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n\n    doRTG(\"b!doc1\");\n    doRTG(\"c!doc2\");\n    doRTG(\"d!doc3\");\n    doRTG(\"e!doc4\");\n    doRTG(\"b!doc1,c!doc2\");\n    doRTG(\"d!doc3,e!doc4\");\n\n    commit();\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", \"shards\",\"shard1,shard2,shard3,shard4\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,c!,d!,e!\");\n    doQuery(\"b!doc1\", \"q\",\"*:*\", shardKeys,\"b!\");\n    doQuery(\"b!doc1\", \"q\",\"*:*\", \"shards\",bucket1);\n    doQuery(\"c!doc2\", \"q\",\"*:*\", shardKeys,\"c!\");\n    doQuery(\"d!doc3\", \"q\",\"*:*\", shardKeys,\"d!\");\n    doQuery(\"e!doc4\", \"q\",\"*:*\", shardKeys,\"e!\");\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n    doQuery(\"b!doc1,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,e!\");\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b,c\");     // query shards that would contain *documents* \"b\" and \"c\" (i.e. not prefixes).  The upper bits are the same, so the shards should be the same.\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b/1!\");   // top bit of hash(b)==1, so shard1 and shard2\n    doQuery(\"d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"d/1!\");   // top bit of hash(b)==0, so shard3 and shard4\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"foo/0!\");\n\n    doDBQ(\"*:*\", shardKeys,\"b!\");\n    commit();\n    doQuery(\"c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"b!doc1\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"d!,e!\");\n    commit();\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"407687e67faf6e1f02a211ca078d8e3eed631027","date":1355157407,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardRoutingTest#doHashingTest().mjava","pathOld":"/dev/null","sourceNew":"  private void doHashingTest() throws Exception {\n    assertEquals(4, cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION).getSlices().size());\n    String shardKeys = ShardParams.SHARD_KEYS;\n    // for now,  we know how ranges will be distributed to shards.\n    // may have to look it up in clusterstate if that assumption changes.\n\n    String bucket1 = \"shard1\";      // shard1: top bits:10  80000000:bfffffff\n    String bucket2 = \"shard2\";      // shard2: top bits:11  c0000000:ffffffff\n    String bucket3 = \"shard3\";      // shard3: top bits:00  00000000:3fffffff\n    String bucket4 = \"shard4\";      // shard4: top bits:01  40000000:7fffffff\n\n    doAddDoc(\"b!doc1\");\n    doAddDoc(\"c!doc2\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n\n    doRTG(\"b!doc1\");\n    doRTG(\"c!doc2\");\n    doRTG(\"d!doc3\");\n    doRTG(\"e!doc4\");\n    doRTG(\"b!doc1,c!doc2\");\n    doRTG(\"d!doc3,e!doc4\");\n\n    commit();\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", \"shards\",\"shard1,shard2,shard3,shard4\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,c!,d!,e!\");\n    doQuery(\"b!doc1\", \"q\",\"*:*\", shardKeys,\"b!\");\n    doQuery(\"c!doc2\", \"q\",\"*:*\", shardKeys,\"c!\");\n    doQuery(\"d!doc3\", \"q\",\"*:*\", shardKeys,\"d!\");\n    doQuery(\"e!doc4\", \"q\",\"*:*\", shardKeys,\"e!\");\n\n    // try using shards parameter\n    doQuery(\"b!doc1\", \"q\",\"*:*\", \"shards\",bucket1);\n    doQuery(\"c!doc2\", \"q\",\"*:*\", \"shards\",bucket2);\n    doQuery(\"d!doc3\", \"q\",\"*:*\", \"shards\",bucket3);\n    doQuery(\"e!doc4\", \"q\",\"*:*\", \"shards\",bucket4);\n\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n    doQuery(\"b!doc1,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,e!\");\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b,c\");     // query shards that would contain *documents* \"b\" and \"c\" (i.e. not prefixes).  The upper bits are the same, so the shards should be the same.\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b/1!\");   // top bit of hash(b)==1, so shard1 and shard2\n    doQuery(\"d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"d/1!\");   // top bit of hash(b)==0, so shard3 and shard4\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"foo/0!\");\n\n    // test targeting deleteByQuery at only certain shards\n    doDBQ(\"*:*\", shardKeys,\"b!\");\n    commit();\n    doQuery(\"c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"b!doc1\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"d!,e!\");\n    commit();\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n\n    commit();\n\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c33aa37f7cb15bff94880004576bd9347e871dbc","date":1355453481,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardRoutingTest#doHashingTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardRoutingTest#doHashingTest().mjava","sourceNew":"  private void doHashingTest() throws Exception {\n    assertEquals(4, cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION).getSlices().size());\n    String shardKeys = ShardParams.SHARD_KEYS;\n    // for now,  we know how ranges will be distributed to shards.\n    // may have to look it up in clusterstate if that assumption changes.\n\n\n    doAddDoc(\"b!doc1\");\n    doAddDoc(\"c!doc2\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n\n    doRTG(\"b!doc1\");\n    doRTG(\"c!doc2\");\n    doRTG(\"d!doc3\");\n    doRTG(\"e!doc4\");\n    doRTG(\"b!doc1,c!doc2\");\n    doRTG(\"d!doc3,e!doc4\");\n\n    commit();\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", \"shards\",\"shard1,shard2,shard3,shard4\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,c!,d!,e!\");\n    doQuery(\"b!doc1\", \"q\",\"*:*\", shardKeys,\"b!\");\n    doQuery(\"c!doc2\", \"q\",\"*:*\", shardKeys,\"c!\");\n    doQuery(\"d!doc3\", \"q\",\"*:*\", shardKeys,\"d!\");\n    doQuery(\"e!doc4\", \"q\",\"*:*\", shardKeys,\"e!\");\n\n    // try using shards parameter\n    doQuery(\"b!doc1\", \"q\",\"*:*\", \"shards\",bucket1);\n    doQuery(\"c!doc2\", \"q\",\"*:*\", \"shards\",bucket2);\n    doQuery(\"d!doc3\", \"q\",\"*:*\", \"shards\",bucket3);\n    doQuery(\"e!doc4\", \"q\",\"*:*\", \"shards\",bucket4);\n\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n    doQuery(\"b!doc1,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,e!\");\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b,c\");     // query shards that would contain *documents* \"b\" and \"c\" (i.e. not prefixes).  The upper bits are the same, so the shards should be the same.\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b/1!\");   // top bit of hash(b)==1, so shard1 and shard2\n    doQuery(\"d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"d/1!\");   // top bit of hash(b)==0, so shard3 and shard4\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"foo/0!\");\n\n    // test targeting deleteByQuery at only certain shards\n    doDBQ(\"*:*\", shardKeys,\"b!\");\n    commit();\n    doQuery(\"c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"b!doc1\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"d!,e!\");\n    commit();\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n\n    commit();\n  }\n\n","sourceOld":"  private void doHashingTest() throws Exception {\n    assertEquals(4, cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION).getSlices().size());\n    String shardKeys = ShardParams.SHARD_KEYS;\n    // for now,  we know how ranges will be distributed to shards.\n    // may have to look it up in clusterstate if that assumption changes.\n\n    String bucket1 = \"shard1\";      // shard1: top bits:10  80000000:bfffffff\n    String bucket2 = \"shard2\";      // shard2: top bits:11  c0000000:ffffffff\n    String bucket3 = \"shard3\";      // shard3: top bits:00  00000000:3fffffff\n    String bucket4 = \"shard4\";      // shard4: top bits:01  40000000:7fffffff\n\n    doAddDoc(\"b!doc1\");\n    doAddDoc(\"c!doc2\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n\n    doRTG(\"b!doc1\");\n    doRTG(\"c!doc2\");\n    doRTG(\"d!doc3\");\n    doRTG(\"e!doc4\");\n    doRTG(\"b!doc1,c!doc2\");\n    doRTG(\"d!doc3,e!doc4\");\n\n    commit();\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", \"shards\",\"shard1,shard2,shard3,shard4\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,c!,d!,e!\");\n    doQuery(\"b!doc1\", \"q\",\"*:*\", shardKeys,\"b!\");\n    doQuery(\"c!doc2\", \"q\",\"*:*\", shardKeys,\"c!\");\n    doQuery(\"d!doc3\", \"q\",\"*:*\", shardKeys,\"d!\");\n    doQuery(\"e!doc4\", \"q\",\"*:*\", shardKeys,\"e!\");\n\n    // try using shards parameter\n    doQuery(\"b!doc1\", \"q\",\"*:*\", \"shards\",bucket1);\n    doQuery(\"c!doc2\", \"q\",\"*:*\", \"shards\",bucket2);\n    doQuery(\"d!doc3\", \"q\",\"*:*\", \"shards\",bucket3);\n    doQuery(\"e!doc4\", \"q\",\"*:*\", \"shards\",bucket4);\n\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n    doQuery(\"b!doc1,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,e!\");\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b,c\");     // query shards that would contain *documents* \"b\" and \"c\" (i.e. not prefixes).  The upper bits are the same, so the shards should be the same.\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b/1!\");   // top bit of hash(b)==1, so shard1 and shard2\n    doQuery(\"d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"d/1!\");   // top bit of hash(b)==0, so shard3 and shard4\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"foo/0!\");\n\n    // test targeting deleteByQuery at only certain shards\n    doDBQ(\"*:*\", shardKeys,\"b!\");\n    commit();\n    doQuery(\"c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"b!doc1\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"d!,e!\");\n    commit();\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n\n    commit();\n\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e0920dbf6195ede2c071dfb0b0c939297dc1a0c8","date":1356657569,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardRoutingTest#doHashingTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardRoutingTest#doHashingTest().mjava","sourceNew":"  private void doHashingTest() throws Exception {\n    log.info(\"### STARTING doHashingTest\");\n    assertEquals(4, cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION).getSlices().size());\n    String shardKeys = ShardParams.SHARD_KEYS;\n    // for now,  we know how ranges will be distributed to shards.\n    // may have to look it up in clusterstate if that assumption changes.\n\n\n    doAddDoc(\"b!doc1\");\n    doAddDoc(\"c!doc2\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n\n    doRTG(\"b!doc1\");\n    doRTG(\"c!doc2\");\n    doRTG(\"d!doc3\");\n    doRTG(\"e!doc4\");\n    doRTG(\"b!doc1,c!doc2\");\n    doRTG(\"d!doc3,e!doc4\");\n\n    commit();\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", \"shards\",\"shard1,shard2,shard3,shard4\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,c!,d!,e!\");\n    doQuery(\"b!doc1\", \"q\",\"*:*\", shardKeys,\"b!\");\n    doQuery(\"c!doc2\", \"q\",\"*:*\", shardKeys,\"c!\");\n    doQuery(\"d!doc3\", \"q\",\"*:*\", shardKeys,\"d!\");\n    doQuery(\"e!doc4\", \"q\",\"*:*\", shardKeys,\"e!\");\n\n    // try using shards parameter\n    doQuery(\"b!doc1\", \"q\",\"*:*\", \"shards\",bucket1);\n    doQuery(\"c!doc2\", \"q\",\"*:*\", \"shards\",bucket2);\n    doQuery(\"d!doc3\", \"q\",\"*:*\", \"shards\",bucket3);\n    doQuery(\"e!doc4\", \"q\",\"*:*\", \"shards\",bucket4);\n\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n    doQuery(\"b!doc1,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,e!\");\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b,c\");     // query shards that would contain *documents* \"b\" and \"c\" (i.e. not prefixes).  The upper bits are the same, so the shards should be the same.\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b/1!\");   // top bit of hash(b)==1, so shard1 and shard2\n    doQuery(\"d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"d/1!\");   // top bit of hash(b)==0, so shard3 and shard4\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"foo/0!\");\n\n    // test targeting deleteByQuery at only certain shards\n    doDBQ(\"*:*\", shardKeys,\"b!\");\n    commit();\n    doQuery(\"c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"b!doc1\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"d!,e!\");\n    commit();\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n\n    commit();\n  }\n\n","sourceOld":"  private void doHashingTest() throws Exception {\n    assertEquals(4, cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION).getSlices().size());\n    String shardKeys = ShardParams.SHARD_KEYS;\n    // for now,  we know how ranges will be distributed to shards.\n    // may have to look it up in clusterstate if that assumption changes.\n\n\n    doAddDoc(\"b!doc1\");\n    doAddDoc(\"c!doc2\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n\n    doRTG(\"b!doc1\");\n    doRTG(\"c!doc2\");\n    doRTG(\"d!doc3\");\n    doRTG(\"e!doc4\");\n    doRTG(\"b!doc1,c!doc2\");\n    doRTG(\"d!doc3,e!doc4\");\n\n    commit();\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", \"shards\",\"shard1,shard2,shard3,shard4\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,c!,d!,e!\");\n    doQuery(\"b!doc1\", \"q\",\"*:*\", shardKeys,\"b!\");\n    doQuery(\"c!doc2\", \"q\",\"*:*\", shardKeys,\"c!\");\n    doQuery(\"d!doc3\", \"q\",\"*:*\", shardKeys,\"d!\");\n    doQuery(\"e!doc4\", \"q\",\"*:*\", shardKeys,\"e!\");\n\n    // try using shards parameter\n    doQuery(\"b!doc1\", \"q\",\"*:*\", \"shards\",bucket1);\n    doQuery(\"c!doc2\", \"q\",\"*:*\", \"shards\",bucket2);\n    doQuery(\"d!doc3\", \"q\",\"*:*\", \"shards\",bucket3);\n    doQuery(\"e!doc4\", \"q\",\"*:*\", \"shards\",bucket4);\n\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n    doQuery(\"b!doc1,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,e!\");\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b,c\");     // query shards that would contain *documents* \"b\" and \"c\" (i.e. not prefixes).  The upper bits are the same, so the shards should be the same.\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b/1!\");   // top bit of hash(b)==1, so shard1 and shard2\n    doQuery(\"d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"d/1!\");   // top bit of hash(b)==0, so shard3 and shard4\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"foo/0!\");\n\n    // test targeting deleteByQuery at only certain shards\n    doDBQ(\"*:*\", shardKeys,\"b!\");\n    commit();\n    doQuery(\"c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"b!doc1\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"d!,e!\");\n    commit();\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n\n    commit();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardRoutingTest#doHashingTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardRoutingTest#doHashingTest().mjava","sourceNew":"  private void doHashingTest() throws Exception {\n    log.info(\"### STARTING doHashingTest\");\n    assertEquals(4, cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION).getSlices().size());\n    String shardKeys = ShardParams.SHARD_KEYS;\n    // for now,  we know how ranges will be distributed to shards.\n    // may have to look it up in clusterstate if that assumption changes.\n\n\n    doAddDoc(\"b!doc1\");\n    doAddDoc(\"c!doc2\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n\n    doRTG(\"b!doc1\");\n    doRTG(\"c!doc2\");\n    doRTG(\"d!doc3\");\n    doRTG(\"e!doc4\");\n    doRTG(\"b!doc1,c!doc2\");\n    doRTG(\"d!doc3,e!doc4\");\n\n    commit();\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", \"shards\",\"shard1,shard2,shard3,shard4\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,c!,d!,e!\");\n    doQuery(\"b!doc1\", \"q\",\"*:*\", shardKeys,\"b!\");\n    doQuery(\"c!doc2\", \"q\",\"*:*\", shardKeys,\"c!\");\n    doQuery(\"d!doc3\", \"q\",\"*:*\", shardKeys,\"d!\");\n    doQuery(\"e!doc4\", \"q\",\"*:*\", shardKeys,\"e!\");\n\n    // try using shards parameter\n    doQuery(\"b!doc1\", \"q\",\"*:*\", \"shards\",bucket1);\n    doQuery(\"c!doc2\", \"q\",\"*:*\", \"shards\",bucket2);\n    doQuery(\"d!doc3\", \"q\",\"*:*\", \"shards\",bucket3);\n    doQuery(\"e!doc4\", \"q\",\"*:*\", \"shards\",bucket4);\n\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n    doQuery(\"b!doc1,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,e!\");\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b,c\");     // query shards that would contain *documents* \"b\" and \"c\" (i.e. not prefixes).  The upper bits are the same, so the shards should be the same.\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b/1!\");   // top bit of hash(b)==1, so shard1 and shard2\n    doQuery(\"d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"d/1!\");   // top bit of hash(b)==0, so shard3 and shard4\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"foo/0!\");\n\n    // test targeting deleteByQuery at only certain shards\n    doDBQ(\"*:*\", shardKeys,\"b!\");\n    commit();\n    doQuery(\"c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"b!doc1\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"d!,e!\");\n    commit();\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n\n    commit();\n  }\n\n","sourceOld":"  private void doHashingTest() throws Exception {\n    assertEquals(4, cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION).getSlices().size());\n    String shardKeys = ShardParams.SHARD_KEYS;\n    // for now,  we know how ranges will be distributed to shards.\n    // may have to look it up in clusterstate if that assumption changes.\n\n    String bucket1 = \"shard1\";      // shard1: top bits:10  80000000:bfffffff\n    String bucket2 = \"shard2\";      // shard2: top bits:11  c0000000:ffffffff\n    String bucket3 = \"shard3\";      // shard3: top bits:00  00000000:3fffffff\n    String bucket4 = \"shard4\";      // shard4: top bits:01  40000000:7fffffff\n\n    doAddDoc(\"b!doc1\");\n    doAddDoc(\"c!doc2\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n\n    doRTG(\"b!doc1\");\n    doRTG(\"c!doc2\");\n    doRTG(\"d!doc3\");\n    doRTG(\"e!doc4\");\n    doRTG(\"b!doc1,c!doc2\");\n    doRTG(\"d!doc3,e!doc4\");\n\n    commit();\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", \"shards\",\"shard1,shard2,shard3,shard4\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,c!,d!,e!\");\n    doQuery(\"b!doc1\", \"q\",\"*:*\", shardKeys,\"b!\");\n    doQuery(\"c!doc2\", \"q\",\"*:*\", shardKeys,\"c!\");\n    doQuery(\"d!doc3\", \"q\",\"*:*\", shardKeys,\"d!\");\n    doQuery(\"e!doc4\", \"q\",\"*:*\", shardKeys,\"e!\");\n\n    // try using shards parameter\n    doQuery(\"b!doc1\", \"q\",\"*:*\", \"shards\",bucket1);\n    doQuery(\"c!doc2\", \"q\",\"*:*\", \"shards\",bucket2);\n    doQuery(\"d!doc3\", \"q\",\"*:*\", \"shards\",bucket3);\n    doQuery(\"e!doc4\", \"q\",\"*:*\", \"shards\",bucket4);\n\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n    doQuery(\"b!doc1,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,e!\");\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b,c\");     // query shards that would contain *documents* \"b\" and \"c\" (i.e. not prefixes).  The upper bits are the same, so the shards should be the same.\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b/1!\");   // top bit of hash(b)==1, so shard1 and shard2\n    doQuery(\"d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"d/1!\");   // top bit of hash(b)==0, so shard3 and shard4\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"foo/0!\");\n\n    // test targeting deleteByQuery at only certain shards\n    doDBQ(\"*:*\", shardKeys,\"b!\");\n    commit();\n    doQuery(\"c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"b!doc1\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"d!,e!\");\n    commit();\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n\n    commit();\n\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f7623716022a9a68898e329e8ffe6c36d168fba7","date":1384524101,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardRoutingTest#doHashingTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardRoutingTest#doHashingTest().mjava","sourceNew":"  private void doHashingTest() throws Exception {\n    log.info(\"### STARTING doHashingTest\");\n    assertEquals(4, cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION).getSlices().size());\n    String shardKeys = ShardParams.SHARD_KEYS;\n    // for now,  we know how ranges will be distributed to shards.\n    // may have to look it up in clusterstate if that assumption changes.\n\n\n    doAddDoc(\"b!doc1\");\n    doAddDoc(\"c!doc2\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n    doAddDoc(\"f1!f2!doc5\");\n\n    doRTG(\"b!doc1\");\n    doRTG(\"c!doc2\");\n    doRTG(\"d!doc3\");\n    doRTG(\"e!doc4\");\n    doRTG(\"f1!f2!doc5\");\n    doRTG(\"b!doc1,c!doc2\");\n    doRTG(\"d!doc3,e!doc4\");\n\n    commit();\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4,f1!f2!doc5\", \"q\",\"*:*\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4,f1!f2!doc5\", \"q\",\"*:*\", \"shards\",\"shard1,shard2,shard3,shard4\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4,f1!f2!doc5\", \"q\",\"*:*\", shardKeys,\"b!,c!,d!,e!,f1!f2!\");\n    doQuery(\"b!doc1\", \"q\",\"*:*\", shardKeys,\"b!\");\n    doQuery(\"c!doc2\", \"q\",\"*:*\", shardKeys,\"c!\");\n    doQuery(\"d!doc3,f1!f2!doc5\", \"q\",\"*:*\", shardKeys,\"d!\");\n    doQuery(\"e!doc4\", \"q\",\"*:*\", shardKeys,\"e!\");\n    doQuery(\"f1!f2!doc5,d!doc3\", \"q\",\"*:*\", shardKeys,\"f1/8!\");\n\n    // try using shards parameter\n    doQuery(\"b!doc1\", \"q\",\"*:*\", \"shards\",bucket1);\n    doQuery(\"c!doc2\", \"q\",\"*:*\", \"shards\",bucket2);\n    doQuery(\"d!doc3,f1!f2!doc5\", \"q\",\"*:*\", \"shards\",bucket3);\n    doQuery(\"e!doc4\", \"q\",\"*:*\", \"shards\",bucket4);\n\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n    doQuery(\"b!doc1,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,e!\");\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b,c\");     // query shards that would contain *documents* \"b\" and \"c\" (i.e. not prefixes).  The upper bits are the same, so the shards should be the same.\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b/1!\");   // top bit of hash(b)==1, so shard1 and shard2\n    doQuery(\"d!doc3,e!doc4,f1!f2!doc5\", \"q\",\"*:*\", shardKeys,\"d/1!\");   // top bit of hash(b)==0, so shard3 and shard4\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n\n    doQuery(\"b!doc1,f1!f2!doc5,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"foo/0!\");\n\n    // test targeting deleteByQuery at only certain shards\n    doDBQ(\"*:*\", shardKeys,\"b!\");\n    commit();\n    doQuery(\"c!doc2,d!doc3,e!doc4,f1!f2!doc5\", \"q\",\"*:*\");\n    doAddDoc(\"b!doc1\");\n\n    doDBQ(\"*:*\", shardKeys,\"f1!\");\n    commit();\n    doQuery(\"b!doc1,c!doc2,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"f1!f2!doc5\");\n    doAddDoc(\"d!doc3\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,f1!f2!doc5,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"d!,e!\");\n    commit();\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n    doAddDoc(\"f1!f2!doc5\");\n\n    commit();\n  }\n\n","sourceOld":"  private void doHashingTest() throws Exception {\n    log.info(\"### STARTING doHashingTest\");\n    assertEquals(4, cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION).getSlices().size());\n    String shardKeys = ShardParams.SHARD_KEYS;\n    // for now,  we know how ranges will be distributed to shards.\n    // may have to look it up in clusterstate if that assumption changes.\n\n\n    doAddDoc(\"b!doc1\");\n    doAddDoc(\"c!doc2\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n\n    doRTG(\"b!doc1\");\n    doRTG(\"c!doc2\");\n    doRTG(\"d!doc3\");\n    doRTG(\"e!doc4\");\n    doRTG(\"b!doc1,c!doc2\");\n    doRTG(\"d!doc3,e!doc4\");\n\n    commit();\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", \"shards\",\"shard1,shard2,shard3,shard4\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,c!,d!,e!\");\n    doQuery(\"b!doc1\", \"q\",\"*:*\", shardKeys,\"b!\");\n    doQuery(\"c!doc2\", \"q\",\"*:*\", shardKeys,\"c!\");\n    doQuery(\"d!doc3\", \"q\",\"*:*\", shardKeys,\"d!\");\n    doQuery(\"e!doc4\", \"q\",\"*:*\", shardKeys,\"e!\");\n\n    // try using shards parameter\n    doQuery(\"b!doc1\", \"q\",\"*:*\", \"shards\",bucket1);\n    doQuery(\"c!doc2\", \"q\",\"*:*\", \"shards\",bucket2);\n    doQuery(\"d!doc3\", \"q\",\"*:*\", \"shards\",bucket3);\n    doQuery(\"e!doc4\", \"q\",\"*:*\", \"shards\",bucket4);\n\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n    doQuery(\"b!doc1,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,e!\");\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b,c\");     // query shards that would contain *documents* \"b\" and \"c\" (i.e. not prefixes).  The upper bits are the same, so the shards should be the same.\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b/1!\");   // top bit of hash(b)==1, so shard1 and shard2\n    doQuery(\"d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"d/1!\");   // top bit of hash(b)==0, so shard3 and shard4\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"foo/0!\");\n\n    // test targeting deleteByQuery at only certain shards\n    doDBQ(\"*:*\", shardKeys,\"b!\");\n    commit();\n    doQuery(\"c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"b!doc1\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"d!,e!\");\n    commit();\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n\n    commit();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"180464626ce8630fd4ec3bc3dafafdd02316e6f2","date":1386087058,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardRoutingTest#doHashingTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardRoutingTest#doHashingTest().mjava","sourceNew":"  private void doHashingTest() throws Exception {\n    log.info(\"### STARTING doHashingTest\");\n    assertEquals(4, cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION).getSlices().size());\n    String shardKeys = ShardParams.SHARD_KEYS;\n    // for now,  we know how ranges will be distributed to shards.\n    // may have to look it up in clusterstate if that assumption changes.\n\n\n    doAddDoc(\"b!doc1\");\n    doAddDoc(\"c!doc2\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n    doAddDoc(\"f1!f2!doc5\");\n    // Check successful addition of a document with a '/' in the id part.\n    doAddDoc(\"f1!f2!doc5/5\");\n\n    doRTG(\"b!doc1\");\n    doRTG(\"c!doc2\");\n    doRTG(\"d!doc3\");\n    doRTG(\"e!doc4\");\n    doRTG(\"f1!f2!doc5\");\n    doRTG(\"f1!f2!doc5/5\");\n    doRTG(\"b!doc1,c!doc2\");\n    doRTG(\"d!doc3,e!doc4\");\n\n    commit();\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\", \"shards\",\"shard1,shard2,shard3,shard4\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\", shardKeys,\"b!,c!,d!,e!,f1!f2!\");\n    doQuery(\"b!doc1\", \"q\",\"*:*\", shardKeys,\"b!\");\n    doQuery(\"c!doc2\", \"q\",\"*:*\", shardKeys,\"c!\");\n    doQuery(\"d!doc3,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\", shardKeys,\"d!\");\n    doQuery(\"e!doc4\", \"q\",\"*:*\", shardKeys,\"e!\");\n    doQuery(\"f1!f2!doc5,d!doc3,f1!f2!doc5/5\", \"q\",\"*:*\", shardKeys,\"f1/8!\");\n\n    // try using shards parameter\n    doQuery(\"b!doc1\", \"q\",\"*:*\", \"shards\",bucket1);\n    doQuery(\"c!doc2\", \"q\",\"*:*\", \"shards\",bucket2);\n    doQuery(\"d!doc3,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\", \"shards\",bucket3);\n    doQuery(\"e!doc4\", \"q\",\"*:*\", \"shards\",bucket4);\n\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n    doQuery(\"b!doc1,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,e!\");\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b,c\");     // query shards that would contain *documents* \"b\" and \"c\" (i.e. not prefixes).  The upper bits are the same, so the shards should be the same.\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b/1!\");   // top bit of hash(b)==1, so shard1 and shard2\n    doQuery(\"d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\", shardKeys,\"d/1!\");   // top bit of hash(b)==0, so shard3 and shard4\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n\n    doQuery(\"b!doc1,f1!f2!doc5,c!doc2,d!doc3,e!doc4,f1!f2!doc5/5\", \"q\",\"*:*\", shardKeys,\"foo/0!\");\n\n    // test targeting deleteByQuery at only certain shards\n    doDBQ(\"*:*\", shardKeys,\"b!\");\n    commit();\n    doQuery(\"c!doc2,d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\");\n    doAddDoc(\"b!doc1\");\n\n    doDBQ(\"*:*\", shardKeys,\"f1!\");\n    commit();\n    doQuery(\"b!doc1,c!doc2,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"f1!f2!doc5\");\n    doAddDoc(\"d!doc3\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,f1!f2!doc5,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"d!,e!\");\n    commit();\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n    doAddDoc(\"f1!f2!doc5\");\n\n    commit();\n  }\n\n","sourceOld":"  private void doHashingTest() throws Exception {\n    log.info(\"### STARTING doHashingTest\");\n    assertEquals(4, cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION).getSlices().size());\n    String shardKeys = ShardParams.SHARD_KEYS;\n    // for now,  we know how ranges will be distributed to shards.\n    // may have to look it up in clusterstate if that assumption changes.\n\n\n    doAddDoc(\"b!doc1\");\n    doAddDoc(\"c!doc2\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n    doAddDoc(\"f1!f2!doc5\");\n\n    doRTG(\"b!doc1\");\n    doRTG(\"c!doc2\");\n    doRTG(\"d!doc3\");\n    doRTG(\"e!doc4\");\n    doRTG(\"f1!f2!doc5\");\n    doRTG(\"b!doc1,c!doc2\");\n    doRTG(\"d!doc3,e!doc4\");\n\n    commit();\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4,f1!f2!doc5\", \"q\",\"*:*\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4,f1!f2!doc5\", \"q\",\"*:*\", \"shards\",\"shard1,shard2,shard3,shard4\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4,f1!f2!doc5\", \"q\",\"*:*\", shardKeys,\"b!,c!,d!,e!,f1!f2!\");\n    doQuery(\"b!doc1\", \"q\",\"*:*\", shardKeys,\"b!\");\n    doQuery(\"c!doc2\", \"q\",\"*:*\", shardKeys,\"c!\");\n    doQuery(\"d!doc3,f1!f2!doc5\", \"q\",\"*:*\", shardKeys,\"d!\");\n    doQuery(\"e!doc4\", \"q\",\"*:*\", shardKeys,\"e!\");\n    doQuery(\"f1!f2!doc5,d!doc3\", \"q\",\"*:*\", shardKeys,\"f1/8!\");\n\n    // try using shards parameter\n    doQuery(\"b!doc1\", \"q\",\"*:*\", \"shards\",bucket1);\n    doQuery(\"c!doc2\", \"q\",\"*:*\", \"shards\",bucket2);\n    doQuery(\"d!doc3,f1!f2!doc5\", \"q\",\"*:*\", \"shards\",bucket3);\n    doQuery(\"e!doc4\", \"q\",\"*:*\", \"shards\",bucket4);\n\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n    doQuery(\"b!doc1,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,e!\");\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b,c\");     // query shards that would contain *documents* \"b\" and \"c\" (i.e. not prefixes).  The upper bits are the same, so the shards should be the same.\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b/1!\");   // top bit of hash(b)==1, so shard1 and shard2\n    doQuery(\"d!doc3,e!doc4,f1!f2!doc5\", \"q\",\"*:*\", shardKeys,\"d/1!\");   // top bit of hash(b)==0, so shard3 and shard4\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n\n    doQuery(\"b!doc1,f1!f2!doc5,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"foo/0!\");\n\n    // test targeting deleteByQuery at only certain shards\n    doDBQ(\"*:*\", shardKeys,\"b!\");\n    commit();\n    doQuery(\"c!doc2,d!doc3,e!doc4,f1!f2!doc5\", \"q\",\"*:*\");\n    doAddDoc(\"b!doc1\");\n\n    doDBQ(\"*:*\", shardKeys,\"f1!\");\n    commit();\n    doQuery(\"b!doc1,c!doc2,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"f1!f2!doc5\");\n    doAddDoc(\"d!doc3\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,f1!f2!doc5,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"d!,e!\");\n    commit();\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n    doAddDoc(\"f1!f2!doc5\");\n\n    commit();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"74f45af4339b0daf7a95c820ab88c1aea74fbce0","date":1387475327,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardRoutingTest#doHashingTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardRoutingTest#doHashingTest().mjava","sourceNew":"  private void doHashingTest() throws Exception {\n    log.info(\"### STARTING doHashingTest\");\n    assertEquals(4, cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION).getSlices().size());\n    String shardKeys = ShardParams.SHARD_KEYS;\n    // for now,  we know how ranges will be distributed to shards.\n    // may have to look it up in clusterstate if that assumption changes.\n\n\n    doAddDoc(\"b!doc1\");\n    doAddDoc(\"c!doc2\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n    doAddDoc(\"f1!f2!doc5\");\n    // Check successful addition of a document with a '/' in the id part.\n    doAddDoc(\"f1!f2!doc5/5\");\n\n    doRTG(\"b!doc1\");\n    doRTG(\"c!doc2\");\n    doRTG(\"d!doc3\");\n    doRTG(\"e!doc4\");\n    doRTG(\"f1!f2!doc5\");\n    doRTG(\"f1!f2!doc5/5\");\n    doRTG(\"b!doc1,c!doc2\");\n    doRTG(\"d!doc3,e!doc4\");\n\n    commit();\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\", \"shards\",\"shard1,shard2,shard3,shard4\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\", shardKeys,\"b!,c!,d!,e!,f1!f2!\");\n    doQuery(\"b!doc1\", \"q\",\"*:*\", shardKeys,\"b!\");\n    doQuery(\"c!doc2\", \"q\",\"*:*\", shardKeys,\"c!\");\n    doQuery(\"d!doc3,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\", shardKeys,\"d!\");\n    doQuery(\"e!doc4\", \"q\",\"*:*\", shardKeys,\"e!\");\n    doQuery(\"f1!f2!doc5,d!doc3,f1!f2!doc5/5\", \"q\",\"*:*\", shardKeys,\"f1/8!\");\n\n    // try using shards parameter\n    doQuery(\"b!doc1\", \"q\",\"*:*\", \"shards\",bucket1);\n    doQuery(\"c!doc2\", \"q\",\"*:*\", \"shards\",bucket2);\n    doQuery(\"d!doc3,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\", \"shards\",bucket3);\n    doQuery(\"e!doc4\", \"q\",\"*:*\", \"shards\",bucket4);\n\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n    doQuery(\"b!doc1,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,e!\");\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b,c\");     // query shards that would contain *documents* \"b\" and \"c\" (i.e. not prefixes).  The upper bits are the same, so the shards should be the same.\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b/1!\");   // top bit of hash(b)==1, so shard1 and shard2\n    doQuery(\"d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\", shardKeys,\"d/1!\");   // top bit of hash(b)==0, so shard3 and shard4\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n\n    doQuery(\"b!doc1,f1!f2!doc5,c!doc2,d!doc3,e!doc4,f1!f2!doc5/5\", \"q\",\"*:*\", shardKeys,\"foo/0!\");\n\n    // test targeting deleteByQuery at only certain shards\n    doDBQ(\"*:*\", shardKeys,\"b!\");\n    commit();\n    doQuery(\"c!doc2,d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\");\n    doAddDoc(\"b!doc1\");\n\n    doDBQ(\"*:*\", shardKeys,\"f1!\");\n    commit();\n    doQuery(\"b!doc1,c!doc2,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"f1!f2!doc5\");\n    doAddDoc(\"d!doc3\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,f1!f2!doc5,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"d!,e!\");\n    commit();\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n    doAddDoc(\"f1!f2!doc5\");\n\n    commit();\n  }\n\n","sourceOld":"  private void doHashingTest() throws Exception {\n    log.info(\"### STARTING doHashingTest\");\n    assertEquals(4, cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION).getSlices().size());\n    String shardKeys = ShardParams.SHARD_KEYS;\n    // for now,  we know how ranges will be distributed to shards.\n    // may have to look it up in clusterstate if that assumption changes.\n\n\n    doAddDoc(\"b!doc1\");\n    doAddDoc(\"c!doc2\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n\n    doRTG(\"b!doc1\");\n    doRTG(\"c!doc2\");\n    doRTG(\"d!doc3\");\n    doRTG(\"e!doc4\");\n    doRTG(\"b!doc1,c!doc2\");\n    doRTG(\"d!doc3,e!doc4\");\n\n    commit();\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", \"shards\",\"shard1,shard2,shard3,shard4\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,c!,d!,e!\");\n    doQuery(\"b!doc1\", \"q\",\"*:*\", shardKeys,\"b!\");\n    doQuery(\"c!doc2\", \"q\",\"*:*\", shardKeys,\"c!\");\n    doQuery(\"d!doc3\", \"q\",\"*:*\", shardKeys,\"d!\");\n    doQuery(\"e!doc4\", \"q\",\"*:*\", shardKeys,\"e!\");\n\n    // try using shards parameter\n    doQuery(\"b!doc1\", \"q\",\"*:*\", \"shards\",bucket1);\n    doQuery(\"c!doc2\", \"q\",\"*:*\", \"shards\",bucket2);\n    doQuery(\"d!doc3\", \"q\",\"*:*\", \"shards\",bucket3);\n    doQuery(\"e!doc4\", \"q\",\"*:*\", \"shards\",bucket4);\n\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n    doQuery(\"b!doc1,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,e!\");\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b,c\");     // query shards that would contain *documents* \"b\" and \"c\" (i.e. not prefixes).  The upper bits are the same, so the shards should be the same.\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b/1!\");   // top bit of hash(b)==1, so shard1 and shard2\n    doQuery(\"d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"d/1!\");   // top bit of hash(b)==0, so shard3 and shard4\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\", shardKeys,\"foo/0!\");\n\n    // test targeting deleteByQuery at only certain shards\n    doDBQ(\"*:*\", shardKeys,\"b!\");\n    commit();\n    doQuery(\"c!doc2,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"b!doc1\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"d!,e!\");\n    commit();\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n\n    commit();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f9a6292fc3940c131b3e108d897f0c2ee2063db9","date":1391760827,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardRoutingTest#doHashingTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardRoutingTest#doHashingTest().mjava","sourceNew":"  private void doHashingTest() throws Exception {\n    log.info(\"### STARTING doHashingTest\");\n    assertEquals(4, cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION).getSlices().size());\n    String shardKeys = ShardParams.SHARD_KEYS;\n    // for now,  we know how ranges will be distributed to shards.\n    // may have to look it up in clusterstate if that assumption changes.\n\n\n    doAddDoc(\"b!doc1\");\n    doAddDoc(\"c!doc2\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n    doAddDoc(\"f1!f2!doc5\");\n    // Check successful addition of a document with a '/' in the id part.\n    doAddDoc(\"f1!f2!doc5/5\");\n\n    doRTG(\"b!doc1\");\n    doRTG(\"c!doc2\");\n    doRTG(\"d!doc3\");\n    doRTG(\"e!doc4\");\n    doRTG(\"f1!f2!doc5\");\n    doRTG(\"f1!f2!doc5/5\");\n    doRTG(\"b!doc1,c!doc2\");\n    doRTG(\"d!doc3,e!doc4\");\n\n    commit();\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\", \"shards\",\"shard1,shard2,shard3,shard4\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\", shardKeys,\"b!,c!,d!,e!,f1!f2!\");\n    doQuery(\"b!doc1\", \"q\",\"*:*\", shardKeys,\"b!\");\n    doQuery(\"c!doc2\", \"q\",\"*:*\", shardKeys,\"c!\");\n    doQuery(\"d!doc3,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\", shardKeys,\"d!\");\n    doQuery(\"e!doc4\", \"q\",\"*:*\", shardKeys,\"e!\");\n    doQuery(\"f1!f2!doc5,d!doc3,f1!f2!doc5/5\", \"q\",\"*:*\", shardKeys,\"f1/8!\");\n\n    // try using shards parameter\n    doQuery(\"b!doc1\", \"q\",\"*:*\", \"shards\",bucket1);\n    doQuery(\"c!doc2\", \"q\",\"*:*\", \"shards\",bucket2);\n    doQuery(\"d!doc3,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\", \"shards\",bucket3);\n    doQuery(\"e!doc4\", \"q\",\"*:*\", \"shards\",bucket4);\n\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n    doQuery(\"b!doc1,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,e!\");\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b,c\");     // query shards that would contain *documents* \"b\" and \"c\" (i.e. not prefixes).  The upper bits are the same, so the shards should be the same.\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b/1!\");   // top bit of hash(b)==1, so shard1 and shard2\n    doQuery(\"d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\", shardKeys,\"d/1!\");   // top bit of hash(b)==0, so shard3 and shard4\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n\n    doQuery(\"b!doc1,f1!f2!doc5,c!doc2,d!doc3,e!doc4,f1!f2!doc5/5\", \"q\",\"*:*\", shardKeys,\"foo/0!\");\n\n    // test targeting deleteByQuery at only certain shards\n    doDBQ(\"*:*\", shardKeys,\"b!\");\n    commit();\n    doQuery(\"c!doc2,d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\");\n    doAddDoc(\"b!doc1\");\n\n    doDBQ(\"*:*\", shardKeys,\"f1!\");\n    commit();\n    doQuery(\"b!doc1,c!doc2,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"f1!f2!doc5\");\n    doAddDoc(\"d!doc3\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,f1!f2!doc5,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"d!,e!\");\n    commit();\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n    doAddDoc(\"f1!f2!doc5\");\n\n    commit();\n\n    doDBQ(\"*:*\");\n    commit();\n\n    doAddDoc(\"b!\");\n    doAddDoc(\"c!doc1\");\n    commit();\n    doQuery(\"b!,c!doc1\", \"q\",\"*:*\");\n    UpdateRequest req = new UpdateRequest();\n    req.deleteById(\"b!\");\n    req.process(cloudClient);\n    commit();\n    doQuery(\"c!doc1\", \"q\",\"*:*\");\n\n    doDBQ(\"id:b!\");\n    commit();\n    doQuery(\"c!doc1\", \"q\",\"*:*\");\n\n    doDBQ(\"*:*\");\n    commit();\n\n    doAddDoc(\"a!b!\");\n    doAddDoc(\"b!doc1\");\n    doAddDoc(\"c!doc2\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n    doAddDoc(\"f1!f2!doc5\");\n    doAddDoc(\"f1!f2!doc5/5\");\n    commit();\n    doQuery(\"a!b!,b!doc1,c!doc2,d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\");\n  }\n\n","sourceOld":"  private void doHashingTest() throws Exception {\n    log.info(\"### STARTING doHashingTest\");\n    assertEquals(4, cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION).getSlices().size());\n    String shardKeys = ShardParams.SHARD_KEYS;\n    // for now,  we know how ranges will be distributed to shards.\n    // may have to look it up in clusterstate if that assumption changes.\n\n\n    doAddDoc(\"b!doc1\");\n    doAddDoc(\"c!doc2\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n    doAddDoc(\"f1!f2!doc5\");\n    // Check successful addition of a document with a '/' in the id part.\n    doAddDoc(\"f1!f2!doc5/5\");\n\n    doRTG(\"b!doc1\");\n    doRTG(\"c!doc2\");\n    doRTG(\"d!doc3\");\n    doRTG(\"e!doc4\");\n    doRTG(\"f1!f2!doc5\");\n    doRTG(\"f1!f2!doc5/5\");\n    doRTG(\"b!doc1,c!doc2\");\n    doRTG(\"d!doc3,e!doc4\");\n\n    commit();\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\", \"shards\",\"shard1,shard2,shard3,shard4\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\", shardKeys,\"b!,c!,d!,e!,f1!f2!\");\n    doQuery(\"b!doc1\", \"q\",\"*:*\", shardKeys,\"b!\");\n    doQuery(\"c!doc2\", \"q\",\"*:*\", shardKeys,\"c!\");\n    doQuery(\"d!doc3,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\", shardKeys,\"d!\");\n    doQuery(\"e!doc4\", \"q\",\"*:*\", shardKeys,\"e!\");\n    doQuery(\"f1!f2!doc5,d!doc3,f1!f2!doc5/5\", \"q\",\"*:*\", shardKeys,\"f1/8!\");\n\n    // try using shards parameter\n    doQuery(\"b!doc1\", \"q\",\"*:*\", \"shards\",bucket1);\n    doQuery(\"c!doc2\", \"q\",\"*:*\", \"shards\",bucket2);\n    doQuery(\"d!doc3,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\", \"shards\",bucket3);\n    doQuery(\"e!doc4\", \"q\",\"*:*\", \"shards\",bucket4);\n\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n    doQuery(\"b!doc1,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,e!\");\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b,c\");     // query shards that would contain *documents* \"b\" and \"c\" (i.e. not prefixes).  The upper bits are the same, so the shards should be the same.\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b/1!\");   // top bit of hash(b)==1, so shard1 and shard2\n    doQuery(\"d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\", shardKeys,\"d/1!\");   // top bit of hash(b)==0, so shard3 and shard4\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n\n    doQuery(\"b!doc1,f1!f2!doc5,c!doc2,d!doc3,e!doc4,f1!f2!doc5/5\", \"q\",\"*:*\", shardKeys,\"foo/0!\");\n\n    // test targeting deleteByQuery at only certain shards\n    doDBQ(\"*:*\", shardKeys,\"b!\");\n    commit();\n    doQuery(\"c!doc2,d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\");\n    doAddDoc(\"b!doc1\");\n\n    doDBQ(\"*:*\", shardKeys,\"f1!\");\n    commit();\n    doQuery(\"b!doc1,c!doc2,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"f1!f2!doc5\");\n    doAddDoc(\"d!doc3\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,f1!f2!doc5,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"d!,e!\");\n    commit();\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n    doAddDoc(\"f1!f2!doc5\");\n\n    commit();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2fc9f4a33c8fefeb1260aea04273a36b0d32378e","date":1421852764,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardRoutingTest#doHashingTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardRoutingTest#doHashingTest().mjava","sourceNew":"  private void doHashingTest() throws Exception {\n    log.info(\"### STARTING doHashingTest\");\n    assertEquals(4, cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION).getSlices().size());\n    String shardKeys = ShardParams._ROUTE_;\n    // for now,  we know how ranges will be distributed to shards.\n    // may have to look it up in clusterstate if that assumption changes.\n\n\n    doAddDoc(\"b!doc1\");\n    doAddDoc(\"c!doc2\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n    doAddDoc(\"f1!f2!doc5\");\n    // Check successful addition of a document with a '/' in the id part.\n    doAddDoc(\"f1!f2!doc5/5\");\n\n    doRTG(\"b!doc1\");\n    doRTG(\"c!doc2\");\n    doRTG(\"d!doc3\");\n    doRTG(\"e!doc4\");\n    doRTG(\"f1!f2!doc5\");\n    doRTG(\"f1!f2!doc5/5\");\n    doRTG(\"b!doc1,c!doc2\");\n    doRTG(\"d!doc3,e!doc4\");\n\n    commit();\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\", \"shards\",\"shard1,shard2,shard3,shard4\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\", shardKeys,\"b!,c!,d!,e!,f1!f2!\");\n    doQuery(\"b!doc1\", \"q\",\"*:*\", shardKeys,\"b!\");\n    doQuery(\"c!doc2\", \"q\",\"*:*\", shardKeys,\"c!\");\n    doQuery(\"d!doc3,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\", shardKeys,\"d!\");\n    doQuery(\"e!doc4\", \"q\",\"*:*\", shardKeys,\"e!\");\n    doQuery(\"f1!f2!doc5,d!doc3,f1!f2!doc5/5\", \"q\",\"*:*\", shardKeys,\"f1/8!\");\n\n    // try using shards parameter\n    doQuery(\"b!doc1\", \"q\",\"*:*\", \"shards\",bucket1);\n    doQuery(\"c!doc2\", \"q\",\"*:*\", \"shards\",bucket2);\n    doQuery(\"d!doc3,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\", \"shards\",bucket3);\n    doQuery(\"e!doc4\", \"q\",\"*:*\", \"shards\",bucket4);\n\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n    doQuery(\"b!doc1,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,e!\");\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b,c\");     // query shards that would contain *documents* \"b\" and \"c\" (i.e. not prefixes).  The upper bits are the same, so the shards should be the same.\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b/1!\");   // top bit of hash(b)==1, so shard1 and shard2\n    doQuery(\"d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\", shardKeys,\"d/1!\");   // top bit of hash(b)==0, so shard3 and shard4\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n\n    doQuery(\"b!doc1,f1!f2!doc5,c!doc2,d!doc3,e!doc4,f1!f2!doc5/5\", \"q\",\"*:*\", shardKeys,\"foo/0!\");\n\n    // test targeting deleteByQuery at only certain shards\n    doDBQ(\"*:*\", shardKeys,\"b!\");\n    commit();\n    doQuery(\"c!doc2,d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\");\n    doAddDoc(\"b!doc1\");\n\n    doDBQ(\"*:*\", shardKeys,\"f1!\");\n    commit();\n    doQuery(\"b!doc1,c!doc2,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"f1!f2!doc5\");\n    doAddDoc(\"d!doc3\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,f1!f2!doc5,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"d!,e!\");\n    commit();\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n    doAddDoc(\"f1!f2!doc5\");\n\n    commit();\n\n    doDBQ(\"*:*\");\n    commit();\n\n    doAddDoc(\"b!\");\n    doAddDoc(\"c!doc1\");\n    commit();\n    doQuery(\"b!,c!doc1\", \"q\",\"*:*\");\n    UpdateRequest req = new UpdateRequest();\n    req.deleteById(\"b!\");\n    req.process(cloudClient);\n    commit();\n    doQuery(\"c!doc1\", \"q\",\"*:*\");\n\n    doDBQ(\"id:b!\");\n    commit();\n    doQuery(\"c!doc1\", \"q\",\"*:*\");\n\n    doDBQ(\"*:*\");\n    commit();\n\n    doAddDoc(\"a!b!\");\n    doAddDoc(\"b!doc1\");\n    doAddDoc(\"c!doc2\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n    doAddDoc(\"f1!f2!doc5\");\n    doAddDoc(\"f1!f2!doc5/5\");\n    commit();\n    doQuery(\"a!b!,b!doc1,c!doc2,d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\");\n  }\n\n","sourceOld":"  private void doHashingTest() throws Exception {\n    log.info(\"### STARTING doHashingTest\");\n    assertEquals(4, cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION).getSlices().size());\n    String shardKeys = ShardParams.SHARD_KEYS;\n    // for now,  we know how ranges will be distributed to shards.\n    // may have to look it up in clusterstate if that assumption changes.\n\n\n    doAddDoc(\"b!doc1\");\n    doAddDoc(\"c!doc2\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n    doAddDoc(\"f1!f2!doc5\");\n    // Check successful addition of a document with a '/' in the id part.\n    doAddDoc(\"f1!f2!doc5/5\");\n\n    doRTG(\"b!doc1\");\n    doRTG(\"c!doc2\");\n    doRTG(\"d!doc3\");\n    doRTG(\"e!doc4\");\n    doRTG(\"f1!f2!doc5\");\n    doRTG(\"f1!f2!doc5/5\");\n    doRTG(\"b!doc1,c!doc2\");\n    doRTG(\"d!doc3,e!doc4\");\n\n    commit();\n\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\", \"shards\",\"shard1,shard2,shard3,shard4\");\n    doQuery(\"b!doc1,c!doc2,d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\", shardKeys,\"b!,c!,d!,e!,f1!f2!\");\n    doQuery(\"b!doc1\", \"q\",\"*:*\", shardKeys,\"b!\");\n    doQuery(\"c!doc2\", \"q\",\"*:*\", shardKeys,\"c!\");\n    doQuery(\"d!doc3,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\", shardKeys,\"d!\");\n    doQuery(\"e!doc4\", \"q\",\"*:*\", shardKeys,\"e!\");\n    doQuery(\"f1!f2!doc5,d!doc3,f1!f2!doc5/5\", \"q\",\"*:*\", shardKeys,\"f1/8!\");\n\n    // try using shards parameter\n    doQuery(\"b!doc1\", \"q\",\"*:*\", \"shards\",bucket1);\n    doQuery(\"c!doc2\", \"q\",\"*:*\", \"shards\",bucket2);\n    doQuery(\"d!doc3,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\", \"shards\",bucket3);\n    doQuery(\"e!doc4\", \"q\",\"*:*\", \"shards\",bucket4);\n\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n    doQuery(\"b!doc1,e!doc4\", \"q\",\"*:*\", shardKeys,\"b!,e!\");\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b,c\");     // query shards that would contain *documents* \"b\" and \"c\" (i.e. not prefixes).  The upper bits are the same, so the shards should be the same.\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b/1!\");   // top bit of hash(b)==1, so shard1 and shard2\n    doQuery(\"d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\", shardKeys,\"d/1!\");   // top bit of hash(b)==0, so shard3 and shard4\n\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\", shardKeys,\"b!,c!\");\n\n    doQuery(\"b!doc1,f1!f2!doc5,c!doc2,d!doc3,e!doc4,f1!f2!doc5/5\", \"q\",\"*:*\", shardKeys,\"foo/0!\");\n\n    // test targeting deleteByQuery at only certain shards\n    doDBQ(\"*:*\", shardKeys,\"b!\");\n    commit();\n    doQuery(\"c!doc2,d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\");\n    doAddDoc(\"b!doc1\");\n\n    doDBQ(\"*:*\", shardKeys,\"f1!\");\n    commit();\n    doQuery(\"b!doc1,c!doc2,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"f1!f2!doc5\");\n    doAddDoc(\"d!doc3\");\n\n    doDBQ(\"*:*\", shardKeys,\"c!\");\n    commit();\n    doQuery(\"b!doc1,f1!f2!doc5,d!doc3,e!doc4\", \"q\",\"*:*\");\n    doAddDoc(\"c!doc2\");\n\n    doDBQ(\"*:*\", shardKeys,\"d!,e!\");\n    commit();\n    doQuery(\"b!doc1,c!doc2\", \"q\",\"*:*\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n    doAddDoc(\"f1!f2!doc5\");\n\n    commit();\n\n    doDBQ(\"*:*\");\n    commit();\n\n    doAddDoc(\"b!\");\n    doAddDoc(\"c!doc1\");\n    commit();\n    doQuery(\"b!,c!doc1\", \"q\",\"*:*\");\n    UpdateRequest req = new UpdateRequest();\n    req.deleteById(\"b!\");\n    req.process(cloudClient);\n    commit();\n    doQuery(\"c!doc1\", \"q\",\"*:*\");\n\n    doDBQ(\"id:b!\");\n    commit();\n    doQuery(\"c!doc1\", \"q\",\"*:*\");\n\n    doDBQ(\"*:*\");\n    commit();\n\n    doAddDoc(\"a!b!\");\n    doAddDoc(\"b!doc1\");\n    doAddDoc(\"c!doc2\");\n    doAddDoc(\"d!doc3\");\n    doAddDoc(\"e!doc4\");\n    doAddDoc(\"f1!f2!doc5\");\n    doAddDoc(\"f1!f2!doc5/5\");\n    commit();\n    doQuery(\"a!b!,b!doc1,c!doc2,d!doc3,e!doc4,f1!f2!doc5,f1!f2!doc5/5\", \"q\",\"*:*\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["407687e67faf6e1f02a211ca078d8e3eed631027","e0920dbf6195ede2c071dfb0b0c939297dc1a0c8"],"eec5368fa415ebab044b7ae01de50d5b49519b7e":["0f5950eb64b8186de9916cbfc47470784523079a"],"407687e67faf6e1f02a211ca078d8e3eed631027":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","919e6b4fea3dbc81ee31eff28b2b74b057f5361f"],"f9a6292fc3940c131b3e108d897f0c2ee2063db9":["180464626ce8630fd4ec3bc3dafafdd02316e6f2"],"0f5950eb64b8186de9916cbfc47470784523079a":["70cbbf09b1986180fc73b08b8ded592b3465806b"],"919e6b4fea3dbc81ee31eff28b2b74b057f5361f":["eec5368fa415ebab044b7ae01de50d5b49519b7e"],"70cbbf09b1986180fc73b08b8ded592b3465806b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"2fc9f4a33c8fefeb1260aea04273a36b0d32378e":["f9a6292fc3940c131b3e108d897f0c2ee2063db9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":["e0920dbf6195ede2c071dfb0b0c939297dc1a0c8","180464626ce8630fd4ec3bc3dafafdd02316e6f2"],"f7623716022a9a68898e329e8ffe6c36d168fba7":["e0920dbf6195ede2c071dfb0b0c939297dc1a0c8"],"e0920dbf6195ede2c071dfb0b0c939297dc1a0c8":["c33aa37f7cb15bff94880004576bd9347e871dbc"],"180464626ce8630fd4ec3bc3dafafdd02316e6f2":["f7623716022a9a68898e329e8ffe6c36d168fba7"],"c33aa37f7cb15bff94880004576bd9347e871dbc":["919e6b4fea3dbc81ee31eff28b2b74b057f5361f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["2fc9f4a33c8fefeb1260aea04273a36b0d32378e"]},"commit2Childs":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"eec5368fa415ebab044b7ae01de50d5b49519b7e":["919e6b4fea3dbc81ee31eff28b2b74b057f5361f"],"407687e67faf6e1f02a211ca078d8e3eed631027":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064"],"f9a6292fc3940c131b3e108d897f0c2ee2063db9":["2fc9f4a33c8fefeb1260aea04273a36b0d32378e"],"0f5950eb64b8186de9916cbfc47470784523079a":["eec5368fa415ebab044b7ae01de50d5b49519b7e"],"919e6b4fea3dbc81ee31eff28b2b74b057f5361f":["407687e67faf6e1f02a211ca078d8e3eed631027","c33aa37f7cb15bff94880004576bd9347e871dbc"],"70cbbf09b1986180fc73b08b8ded592b3465806b":["0f5950eb64b8186de9916cbfc47470784523079a"],"2fc9f4a33c8fefeb1260aea04273a36b0d32378e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["407687e67faf6e1f02a211ca078d8e3eed631027","70cbbf09b1986180fc73b08b8ded592b3465806b"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":[],"e0920dbf6195ede2c071dfb0b0c939297dc1a0c8":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","74f45af4339b0daf7a95c820ab88c1aea74fbce0","f7623716022a9a68898e329e8ffe6c36d168fba7"],"f7623716022a9a68898e329e8ffe6c36d168fba7":["180464626ce8630fd4ec3bc3dafafdd02316e6f2"],"180464626ce8630fd4ec3bc3dafafdd02316e6f2":["f9a6292fc3940c131b3e108d897f0c2ee2063db9","74f45af4339b0daf7a95c820ab88c1aea74fbce0"],"c33aa37f7cb15bff94880004576bd9347e871dbc":["e0920dbf6195ede2c071dfb0b0c939297dc1a0c8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","74f45af4339b0daf7a95c820ab88c1aea74fbce0","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}