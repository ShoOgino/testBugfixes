{"path":"lucene/core/src/java/org/apache/lucene/index/BufferedUpdates#addNumericUpdate(NumericUpdate,int).mjava","commits":[{"id":"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0","date":1383367127,"type":1,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/BufferedUpdates#addNumericUpdate(NumericUpdate,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/BufferedDeletes#addNumericUpdate(NumericUpdate,int).mjava","sourceNew":"  public void addNumericUpdate(NumericUpdate update, int docIDUpto) {\n    LinkedHashMap<Term,NumericUpdate> fieldUpdates = numericUpdates.get(update.field);\n    if (fieldUpdates == null) {\n      fieldUpdates = new LinkedHashMap<Term,NumericUpdate>();\n      numericUpdates.put(update.field, fieldUpdates);\n      bytesUsed.addAndGet(BYTES_PER_NUMERIC_FIELD_ENTRY);\n    }\n    final NumericUpdate current = fieldUpdates.get(update.term);\n    if (current != null && docIDUpto < current.docIDUpto) {\n      // Only record the new number if it's greater than or equal to the current\n      // one. This is important because if multiple threads are replacing the\n      // same doc at nearly the same time, it's possible that one thread that\n      // got a higher docID is scheduled before the other threads.\n      return;\n    }\n\n    update.docIDUpto = docIDUpto;\n    // since it's a LinkedHashMap, we must first remove the Term entry so that\n    // it's added last (we're interested in insertion-order).\n    if (current != null) {\n      fieldUpdates.remove(update.term);\n    }\n    fieldUpdates.put(update.term, update);\n    numNumericUpdates.incrementAndGet();\n    if (current == null) {\n      bytesUsed.addAndGet(BYTES_PER_NUMERIC_UPDATE_ENTRY + update.sizeInBytes());\n    }\n  }\n\n","sourceOld":"  public void addNumericUpdate(NumericUpdate update, int docIDUpto) {\n    LinkedHashMap<Term,NumericUpdate> fieldUpdates = numericUpdates.get(update.field);\n    if (fieldUpdates == null) {\n      fieldUpdates = new LinkedHashMap<Term,NumericUpdate>();\n      numericUpdates.put(update.field, fieldUpdates);\n      bytesUsed.addAndGet(BYTES_PER_NUMERIC_FIELD_ENTRY);\n    }\n    final NumericUpdate current = fieldUpdates.get(update.term);\n    if (current != null && docIDUpto < current.docIDUpto) {\n      // Only record the new number if it's greater than or equal to the current\n      // one. This is important because if multiple threads are replacing the\n      // same doc at nearly the same time, it's possible that one thread that\n      // got a higher docID is scheduled before the other threads.\n      return;\n    }\n\n    update.docIDUpto = docIDUpto;\n    // since it's a LinkedHashMap, we must first remove the Term entry so that\n    // it's added last (we're interested in insertion-order).\n    if (current != null) {\n      fieldUpdates.remove(update.term);\n    }\n    fieldUpdates.put(update.term, update);\n    numNumericUpdates.incrementAndGet();\n    if (current == null) {\n      bytesUsed.addAndGet(BYTES_PER_NUMERIC_UPDATE_ENTRY + update.sizeInBytes());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/BufferedUpdates#addNumericUpdate(NumericUpdate,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/BufferedUpdates#addNumericUpdate(NumericUpdate,int).mjava","sourceNew":"  public void addNumericUpdate(NumericUpdate update, int docIDUpto) {\n    LinkedHashMap<Term,NumericUpdate> fieldUpdates = numericUpdates.get(update.field);\n    if (fieldUpdates == null) {\n      fieldUpdates = new LinkedHashMap<>();\n      numericUpdates.put(update.field, fieldUpdates);\n      bytesUsed.addAndGet(BYTES_PER_NUMERIC_FIELD_ENTRY);\n    }\n    final NumericUpdate current = fieldUpdates.get(update.term);\n    if (current != null && docIDUpto < current.docIDUpto) {\n      // Only record the new number if it's greater than or equal to the current\n      // one. This is important because if multiple threads are replacing the\n      // same doc at nearly the same time, it's possible that one thread that\n      // got a higher docID is scheduled before the other threads.\n      return;\n    }\n\n    update.docIDUpto = docIDUpto;\n    // since it's a LinkedHashMap, we must first remove the Term entry so that\n    // it's added last (we're interested in insertion-order).\n    if (current != null) {\n      fieldUpdates.remove(update.term);\n    }\n    fieldUpdates.put(update.term, update);\n    numNumericUpdates.incrementAndGet();\n    if (current == null) {\n      bytesUsed.addAndGet(BYTES_PER_NUMERIC_UPDATE_ENTRY + update.sizeInBytes());\n    }\n  }\n\n","sourceOld":"  public void addNumericUpdate(NumericUpdate update, int docIDUpto) {\n    LinkedHashMap<Term,NumericUpdate> fieldUpdates = numericUpdates.get(update.field);\n    if (fieldUpdates == null) {\n      fieldUpdates = new LinkedHashMap<Term,NumericUpdate>();\n      numericUpdates.put(update.field, fieldUpdates);\n      bytesUsed.addAndGet(BYTES_PER_NUMERIC_FIELD_ENTRY);\n    }\n    final NumericUpdate current = fieldUpdates.get(update.term);\n    if (current != null && docIDUpto < current.docIDUpto) {\n      // Only record the new number if it's greater than or equal to the current\n      // one. This is important because if multiple threads are replacing the\n      // same doc at nearly the same time, it's possible that one thread that\n      // got a higher docID is scheduled before the other threads.\n      return;\n    }\n\n    update.docIDUpto = docIDUpto;\n    // since it's a LinkedHashMap, we must first remove the Term entry so that\n    // it's added last (we're interested in insertion-order).\n    if (current != null) {\n      fieldUpdates.remove(update.term);\n    }\n    fieldUpdates.put(update.term, update);\n    numNumericUpdates.incrementAndGet();\n    if (current == null) {\n      bytesUsed.addAndGet(BYTES_PER_NUMERIC_UPDATE_ENTRY + update.sizeInBytes());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"06805da26538ed636bd89b10c2699cc3834032ae","date":1395132972,"type":6,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/BufferedUpdates#addBinaryUpdate(BinaryDocValuesUpdate,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/BufferedUpdates#addNumericUpdate(NumericUpdate,int).mjava","sourceNew":"  public void addBinaryUpdate(BinaryDocValuesUpdate update, int docIDUpto) {\n    LinkedHashMap<Term,BinaryDocValuesUpdate> fieldUpdates = binaryUpdates.get(update.field);\n    if (fieldUpdates == null) {\n      fieldUpdates = new LinkedHashMap<>();\n      binaryUpdates.put(update.field, fieldUpdates);\n      bytesUsed.addAndGet(BYTES_PER_BINARY_FIELD_ENTRY);\n    }\n    final BinaryDocValuesUpdate current = fieldUpdates.get(update.term);\n    if (current != null && docIDUpto < current.docIDUpto) {\n      // Only record the new number if it's greater than or equal to the current\n      // one. This is important because if multiple threads are replacing the\n      // same doc at nearly the same time, it's possible that one thread that\n      // got a higher docID is scheduled before the other threads.\n      return;\n    }\n    \n    update.docIDUpto = docIDUpto;\n    // since it's a LinkedHashMap, we must first remove the Term entry so that\n    // it's added last (we're interested in insertion-order).\n    if (current != null) {\n      fieldUpdates.remove(update.term);\n    }\n    fieldUpdates.put(update.term, update);\n    numBinaryUpdates.incrementAndGet();\n    if (current == null) {\n      bytesUsed.addAndGet(BYTES_PER_BINARY_UPDATE_ENTRY + update.sizeInBytes());\n    }\n  }\n\n","sourceOld":"  public void addNumericUpdate(NumericUpdate update, int docIDUpto) {\n    LinkedHashMap<Term,NumericUpdate> fieldUpdates = numericUpdates.get(update.field);\n    if (fieldUpdates == null) {\n      fieldUpdates = new LinkedHashMap<>();\n      numericUpdates.put(update.field, fieldUpdates);\n      bytesUsed.addAndGet(BYTES_PER_NUMERIC_FIELD_ENTRY);\n    }\n    final NumericUpdate current = fieldUpdates.get(update.term);\n    if (current != null && docIDUpto < current.docIDUpto) {\n      // Only record the new number if it's greater than or equal to the current\n      // one. This is important because if multiple threads are replacing the\n      // same doc at nearly the same time, it's possible that one thread that\n      // got a higher docID is scheduled before the other threads.\n      return;\n    }\n\n    update.docIDUpto = docIDUpto;\n    // since it's a LinkedHashMap, we must first remove the Term entry so that\n    // it's added last (we're interested in insertion-order).\n    if (current != null) {\n      fieldUpdates.remove(update.term);\n    }\n    fieldUpdates.put(update.term, update);\n    numNumericUpdates.incrementAndGet();\n    if (current == null) {\n      bytesUsed.addAndGet(BYTES_PER_NUMERIC_UPDATE_ENTRY + update.sizeInBytes());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"06805da26538ed636bd89b10c2699cc3834032ae","date":1395132972,"type":5,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/BufferedUpdates#addNumericUpdate(NumericDocValuesUpdate,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/BufferedUpdates#addNumericUpdate(NumericUpdate,int).mjava","sourceNew":"  public void addNumericUpdate(NumericDocValuesUpdate update, int docIDUpto) {\n    LinkedHashMap<Term,NumericDocValuesUpdate> fieldUpdates = numericUpdates.get(update.field);\n    if (fieldUpdates == null) {\n      fieldUpdates = new LinkedHashMap<>();\n      numericUpdates.put(update.field, fieldUpdates);\n      bytesUsed.addAndGet(BYTES_PER_NUMERIC_FIELD_ENTRY);\n    }\n    final NumericDocValuesUpdate current = fieldUpdates.get(update.term);\n    if (current != null && docIDUpto < current.docIDUpto) {\n      // Only record the new number if it's greater than or equal to the current\n      // one. This is important because if multiple threads are replacing the\n      // same doc at nearly the same time, it's possible that one thread that\n      // got a higher docID is scheduled before the other threads.\n      return;\n    }\n\n    update.docIDUpto = docIDUpto;\n    // since it's a LinkedHashMap, we must first remove the Term entry so that\n    // it's added last (we're interested in insertion-order).\n    if (current != null) {\n      fieldUpdates.remove(update.term);\n    }\n    fieldUpdates.put(update.term, update);\n    numNumericUpdates.incrementAndGet();\n    if (current == null) {\n      bytesUsed.addAndGet(BYTES_PER_NUMERIC_UPDATE_ENTRY + update.sizeInBytes());\n    }\n  }\n\n","sourceOld":"  public void addNumericUpdate(NumericUpdate update, int docIDUpto) {\n    LinkedHashMap<Term,NumericUpdate> fieldUpdates = numericUpdates.get(update.field);\n    if (fieldUpdates == null) {\n      fieldUpdates = new LinkedHashMap<>();\n      numericUpdates.put(update.field, fieldUpdates);\n      bytesUsed.addAndGet(BYTES_PER_NUMERIC_FIELD_ENTRY);\n    }\n    final NumericUpdate current = fieldUpdates.get(update.term);\n    if (current != null && docIDUpto < current.docIDUpto) {\n      // Only record the new number if it's greater than or equal to the current\n      // one. This is important because if multiple threads are replacing the\n      // same doc at nearly the same time, it's possible that one thread that\n      // got a higher docID is scheduled before the other threads.\n      return;\n    }\n\n    update.docIDUpto = docIDUpto;\n    // since it's a LinkedHashMap, we must first remove the Term entry so that\n    // it's added last (we're interested in insertion-order).\n    if (current != null) {\n      fieldUpdates.remove(update.term);\n    }\n    fieldUpdates.put(update.term, update);\n    numNumericUpdates.incrementAndGet();\n    if (current == null) {\n      bytesUsed.addAndGet(BYTES_PER_NUMERIC_UPDATE_ENTRY + update.sizeInBytes());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"06805da26538ed636bd89b10c2699cc3834032ae":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["06805da26538ed636bd89b10c2699cc3834032ae"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["06805da26538ed636bd89b10c2699cc3834032ae"],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"],"06805da26538ed636bd89b10c2699cc3834032ae":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}