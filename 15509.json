{"path":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","commits":[{"id":"955c32f886db6f6356c9fcdea6b1f1cb4effda24","date":1270581567,"type":0,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"/dev/null","sourceNew":"  public void testRandomPostings() throws Throwable {\n\n    RANDOM = this.newRandom();\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = new MockRAMDirectory();\n\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, CodecProvider.getDefault().getWriter(null));\n\n    final FieldsProducer terms = si.getCodec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6267e1ce56c2eec111425690cd04e251b6f14952","date":1275222352,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n\n    RANDOM = this.newRandom();\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = new MockRAMDirectory();\n\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, CodecProvider.getDefault().getWriter(null));\n\n    final FieldsProducer terms = si.getCodec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n\n    RANDOM = this.newRandom();\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = new MockRAMDirectory();\n\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, CodecProvider.getDefault().getWriter(null));\n\n    final FieldsProducer terms = si.getCodec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"833a7987bc1c94455fde83e3311f72bddedcfb93","date":1279951470,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n\n    RANDOM = this.newRandom();\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = new MockRAMDirectory();\n\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, CodecProvider.getDefault().getWriter(null));\n\n    final FieldsProducer terms = si.getCodec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n\n    RANDOM = this.newRandom();\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = new MockRAMDirectory();\n\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, CodecProvider.getDefault().getWriter(null));\n\n    final FieldsProducer terms = si.getCodec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","date":1281646583,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n\n    RANDOM = this.newRandom();\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory(RANDOM);\n\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, CodecProvider.getDefault().getWriter(null));\n\n    final FieldsProducer terms = si.getCodec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n\n    RANDOM = this.newRandom();\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = new MockRAMDirectory();\n\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, CodecProvider.getDefault().getWriter(null));\n\n    final FieldsProducer terms = si.getCodec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f653cfcf159baeaafe5d01682a911e95bba4012","date":1284122058,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, CodecProvider.getDefault().getWriter(null));\n\n    final FieldsProducer terms = si.getCodec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n\n    RANDOM = this.newRandom();\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory(RANDOM);\n\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, CodecProvider.getDefault().getWriter(null));\n\n    final FieldsProducer terms = si.getCodec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a493e6d0c3ad86bd55c0a1360d110142e948f2bd","date":1289406991,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()));\n\n    final FieldsProducer terms = si.getCodecInfo().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, CodecProvider.getDefault().getWriter(null));\n\n    final FieldsProducer terms = si.getCodec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"85a883878c0af761245ab048babc63d099f835f3","date":1289553330,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()));\n\n    final FieldsProducer terms = si.getCodecInfo().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, CodecProvider.getDefault().getWriter(null));\n\n    final FieldsProducer terms = si.getCodec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8bc084aae57b2027dcd1e8786dabc47987dce76b","date":1289596643,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()));\n\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()));\n\n    final FieldsProducer terms = si.getCodecInfo().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c498d3f8d75170b121f5eda2c6210ac5beb5d411","date":1289726298,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()));\n\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()));\n\n    final FieldsProducer terms = si.getCodecInfo().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e1cbd7e289dc1243c7a59e1a83d078163a147fe","date":1292268032,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()));\n\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5","date":1292695408,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab5cb6a74aefb78aa0569857970b9151dfe2e787","date":1292842407,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()));\n\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n\n    RANDOM = this.newRandom();\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = new MockRAMDirectory();\n\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, CodecProvider.getDefault().getWriter(null));\n\n    final FieldsProducer terms = si.getCodec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"56da903869515527852ee21ea7ef7bfe414cd40d","date":1294224724,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70ad682703b8585f5d0a637efec044d57ec05efb","date":1294259117,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b0c7a8f7304b75b1528814c5820fa23a96816c27","date":1298314239,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, SegmentCodecs.build(clonedFieldInfos, CodecProvider.getDefault()), clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, SegmentCodecs.build(clonedFieldInfos, CodecProvider.getDefault()), clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"14ec33385f6fbb6ce172882d14605790418a5d31","date":1298910796,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, SegmentCodecs.build(clonedFieldInfos, CodecProvider.getDefault()), clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1224a4027481acce15495b03bce9b48b93b42722","date":1300792329,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(clonedFieldInfos, CodecProvider.getDefault()), clonedFieldInfos.hasVectors(), clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e92442af786151ee55bc283eb472f629e3c7b52b","date":1301070252,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true,  clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos.hasVectors(), clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(clonedFieldInfos, CodecProvider.getDefault()), clonedFieldInfos.hasVectors(), clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d619839baa8ce5503e496b94a9e42ad6f079293f","date":1301309428,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true,  clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos.hasVectors(), clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c0ef0193974807e4bddf5432a6b0287fe4d6c9df","date":1301476645,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true,  clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos.hasVectors(), clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, SegmentCodecs.build(clonedFieldInfos, CodecProvider.getDefault()), clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3fe2fc74577855eadfb5eae3153c2fffdaaf791","date":1305237079,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true,  clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos.hasVectors(), clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c700f8d0842d3e52bb2bdfbfdc046a137e836edb","date":1305285499,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true,  clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos.hasVectors(), clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true,  clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos.hasVectors(), clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"639c36565ce03aed5b0fce7c9e4448e53a1f7efd","date":1308580104,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, IOContext.READ, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b6f9be74ca7baaef11857ad002cad40419979516","date":1309449808,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, IOContext.READ, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ddc4c914be86e34b54f70023f45a60fa7f04e929","date":1310115160,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5d004d0e0b3f65bb40da76d476d659d7888270e8","date":1310158940,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7b91922b55d15444d554721b352861d028eb8278","date":1320421415,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3cc749c053615f5871f3b95715fe292f34e70a53","date":1321470575,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868186558eb3a854ce7e720a52bb445795d54910","date":1327853682,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5cab9a86bd67202d20b6adc463008c8e982b070a","date":1327966443,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d3fe2fc74577855eadfb5eae3153c2fffdaaf791":["e92442af786151ee55bc283eb472f629e3c7b52b"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"a493e6d0c3ad86bd55c0a1360d110142e948f2bd":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["d3fe2fc74577855eadfb5eae3153c2fffdaaf791"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["833a7987bc1c94455fde83e3311f72bddedcfb93","4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"e92442af786151ee55bc283eb472f629e3c7b52b":["1224a4027481acce15495b03bce9b48b93b42722"],"c0ef0193974807e4bddf5432a6b0287fe4d6c9df":["bde51b089eb7f86171eb3406e38a274743f9b7ac","e92442af786151ee55bc283eb472f629e3c7b52b"],"14ec33385f6fbb6ce172882d14605790418a5d31":["b0c7a8f7304b75b1528814c5820fa23a96816c27"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b6f9be74ca7baaef11857ad002cad40419979516":["639c36565ce03aed5b0fce7c9e4448e53a1f7efd"],"5d004d0e0b3f65bb40da76d476d659d7888270e8":["a3776dccca01c11e7046323cfad46a3b4a471233","ddc4c914be86e34b54f70023f45a60fa7f04e929"],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":["d619839baa8ce5503e496b94a9e42ad6f079293f","d3fe2fc74577855eadfb5eae3153c2fffdaaf791"],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["d3fe2fc74577855eadfb5eae3153c2fffdaaf791","b6f9be74ca7baaef11857ad002cad40419979516"],"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5":["7e1cbd7e289dc1243c7a59e1a83d078163a147fe"],"7e1cbd7e289dc1243c7a59e1a83d078163a147fe":["8bc084aae57b2027dcd1e8786dabc47987dce76b"],"868186558eb3a854ce7e720a52bb445795d54910":["3cc749c053615f5871f3b95715fe292f34e70a53"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["868da859b43505d9d2a023bfeae6dd0c795f5295","b0c7a8f7304b75b1528814c5820fa23a96816c27"],"1224a4027481acce15495b03bce9b48b93b42722":["14ec33385f6fbb6ce172882d14605790418a5d31"],"833a7987bc1c94455fde83e3311f72bddedcfb93":["6267e1ce56c2eec111425690cd04e251b6f14952"],"70ad682703b8585f5d0a637efec044d57ec05efb":["ab5cb6a74aefb78aa0569857970b9151dfe2e787","56da903869515527852ee21ea7ef7bfe414cd40d"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["6267e1ce56c2eec111425690cd04e251b6f14952"],"c498d3f8d75170b121f5eda2c6210ac5beb5d411":["85a883878c0af761245ab048babc63d099f835f3","8bc084aae57b2027dcd1e8786dabc47987dce76b"],"85a883878c0af761245ab048babc63d099f835f3":["1f653cfcf159baeaafe5d01682a911e95bba4012","a493e6d0c3ad86bd55c0a1360d110142e948f2bd"],"3cc749c053615f5871f3b95715fe292f34e70a53":["7b91922b55d15444d554721b352861d028eb8278"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["c498d3f8d75170b121f5eda2c6210ac5beb5d411","4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["3cc749c053615f5871f3b95715fe292f34e70a53","868186558eb3a854ce7e720a52bb445795d54910"],"7b91922b55d15444d554721b352861d028eb8278":["ddc4c914be86e34b54f70023f45a60fa7f04e929"],"8bc084aae57b2027dcd1e8786dabc47987dce76b":["a493e6d0c3ad86bd55c0a1360d110142e948f2bd"],"6267e1ce56c2eec111425690cd04e251b6f14952":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["70ad682703b8585f5d0a637efec044d57ec05efb","e92442af786151ee55bc283eb472f629e3c7b52b"],"b0c7a8f7304b75b1528814c5820fa23a96816c27":["56da903869515527852ee21ea7ef7bfe414cd40d"],"56da903869515527852ee21ea7ef7bfe414cd40d":["4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"a3776dccca01c11e7046323cfad46a3b4a471233":["e92442af786151ee55bc283eb472f629e3c7b52b","d3fe2fc74577855eadfb5eae3153c2fffdaaf791"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","56da903869515527852ee21ea7ef7bfe414cd40d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"d3fe2fc74577855eadfb5eae3153c2fffdaaf791":["639c36565ce03aed5b0fce7c9e4448e53a1f7efd","c700f8d0842d3e52bb2bdfbfdc046a137e836edb","ddc4c914be86e34b54f70023f45a60fa7f04e929","a3776dccca01c11e7046323cfad46a3b4a471233"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a493e6d0c3ad86bd55c0a1360d110142e948f2bd":["85a883878c0af761245ab048babc63d099f835f3","8bc084aae57b2027dcd1e8786dabc47987dce76b"],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["6267e1ce56c2eec111425690cd04e251b6f14952"],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["b6f9be74ca7baaef11857ad002cad40419979516"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["868da859b43505d9d2a023bfeae6dd0c795f5295"],"e92442af786151ee55bc283eb472f629e3c7b52b":["d3fe2fc74577855eadfb5eae3153c2fffdaaf791","c0ef0193974807e4bddf5432a6b0287fe4d6c9df","d619839baa8ce5503e496b94a9e42ad6f079293f","a3776dccca01c11e7046323cfad46a3b4a471233"],"c0ef0193974807e4bddf5432a6b0287fe4d6c9df":[],"14ec33385f6fbb6ce172882d14605790418a5d31":["1224a4027481acce15495b03bce9b48b93b42722"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["a493e6d0c3ad86bd55c0a1360d110142e948f2bd","85a883878c0af761245ab048babc63d099f835f3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"b6f9be74ca7baaef11857ad002cad40419979516":["ddc4c914be86e34b54f70023f45a60fa7f04e929"],"5d004d0e0b3f65bb40da76d476d659d7888270e8":[],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":[],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["5d004d0e0b3f65bb40da76d476d659d7888270e8","7b91922b55d15444d554721b352861d028eb8278"],"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","ab5cb6a74aefb78aa0569857970b9151dfe2e787","56da903869515527852ee21ea7ef7bfe414cd40d"],"7e1cbd7e289dc1243c7a59e1a83d078163a147fe":["4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["c0ef0193974807e4bddf5432a6b0287fe4d6c9df"],"868186558eb3a854ce7e720a52bb445795d54910":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"833a7987bc1c94455fde83e3311f72bddedcfb93":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"1224a4027481acce15495b03bce9b48b93b42722":["e92442af786151ee55bc283eb472f629e3c7b52b"],"70ad682703b8585f5d0a637efec044d57ec05efb":["d619839baa8ce5503e496b94a9e42ad6f079293f"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"c498d3f8d75170b121f5eda2c6210ac5beb5d411":["ab5cb6a74aefb78aa0569857970b9151dfe2e787"],"85a883878c0af761245ab048babc63d099f835f3":["c498d3f8d75170b121f5eda2c6210ac5beb5d411"],"3cc749c053615f5871f3b95715fe292f34e70a53":["868186558eb3a854ce7e720a52bb445795d54910","5cab9a86bd67202d20b6adc463008c8e982b070a"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["70ad682703b8585f5d0a637efec044d57ec05efb"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"8bc084aae57b2027dcd1e8786dabc47987dce76b":["7e1cbd7e289dc1243c7a59e1a83d078163a147fe","c498d3f8d75170b121f5eda2c6210ac5beb5d411"],"6267e1ce56c2eec111425690cd04e251b6f14952":["833a7987bc1c94455fde83e3311f72bddedcfb93","ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"7b91922b55d15444d554721b352861d028eb8278":["3cc749c053615f5871f3b95715fe292f34e70a53"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["c700f8d0842d3e52bb2bdfbfdc046a137e836edb"],"b0c7a8f7304b75b1528814c5820fa23a96816c27":["14ec33385f6fbb6ce172882d14605790418a5d31","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"a3776dccca01c11e7046323cfad46a3b4a471233":["5d004d0e0b3f65bb40da76d476d659d7888270e8"],"56da903869515527852ee21ea7ef7bfe414cd40d":["70ad682703b8585f5d0a637efec044d57ec05efb","b0c7a8f7304b75b1528814c5820fa23a96816c27","868da859b43505d9d2a023bfeae6dd0c795f5295"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c0ef0193974807e4bddf5432a6b0287fe4d6c9df","5d004d0e0b3f65bb40da76d476d659d7888270e8","c700f8d0842d3e52bb2bdfbfdc046a137e836edb","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}