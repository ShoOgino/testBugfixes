{"path":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,boolean,float).mjava","commits":[{"id":"5a412a7808b2815566cb17117ebe6638112b9a31","date":1484916151,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,boolean,float).mjava","pathOld":"lucene/sandbox/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,boolean,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, needsScores, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, needsScores, boost);\n    return new Weight(this) {\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        indexWeight.extractTerms(terms);\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.explain(context, doc);\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        // Bulk scorers need to consume the entire set of docs, so using an\n        // index structure should perform better\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context);\n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(boolean randomAccess) throws IOException {\n            return (randomAccess ? dvScorerSupplier : indexScorerSupplier).get(randomAccess);\n          }\n\n          @Override\n          public long cost() {\n            return Math.min(indexScorerSupplier.cost(), dvScorerSupplier.cost());\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(false);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, needsScores, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, needsScores, boost);\n    return new ConstantScoreWeight(this, boost) {\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context); \n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(boolean randomAccess) throws IOException {\n            return (randomAccess ? dvScorerSupplier : indexScorerSupplier).get(randomAccess);\n          }\n\n          @Override\n          public long cost() {\n            return Math.min(indexScorerSupplier.cost(), dvScorerSupplier.cost());\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(false);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"90a682dc1bfd188ef61cc28373c7f5d700b4ac75","date":1485186128,"type":1,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,boolean,float).mjava","pathOld":"lucene/sandbox/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,boolean,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, needsScores, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, needsScores, boost);\n    return new Weight(this) {\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        indexWeight.extractTerms(terms);\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.explain(context, doc);\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        // Bulk scorers need to consume the entire set of docs, so using an\n        // index structure should perform better\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context);\n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(boolean randomAccess) throws IOException {\n            return (randomAccess ? dvScorerSupplier : indexScorerSupplier).get(randomAccess);\n          }\n\n          @Override\n          public long cost() {\n            return Math.min(indexScorerSupplier.cost(), dvScorerSupplier.cost());\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(false);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, needsScores, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, needsScores, boost);\n    return new ConstantScoreWeight(this, boost) {\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context); \n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(boolean randomAccess) throws IOException {\n            return (randomAccess ? dvScorerSupplier : indexScorerSupplier).get(randomAccess);\n          }\n\n          @Override\n          public long cost() {\n            return Math.min(indexScorerSupplier.cost(), dvScorerSupplier.cost());\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(false);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"24f3e9c0fc20b3107388ec853a6fbad9f891b461","date":1502359844,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,boolean,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,boolean,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, needsScores, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, needsScores, boost);\n    return new Weight(this) {\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        indexWeight.extractTerms(terms);\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.explain(context, doc);\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        // Bulk scorers need to consume the entire set of docs, so using an\n        // index structure should perform better\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context);\n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(long leadCost) throws IOException {\n            // At equal costs, doc values tend to be worse than points since they\n            // still need to perform one comparison per document while points can\n            // do much better than that given how values are organized. So we give\n            // an arbitrary 8x penalty to doc values.\n            final long threshold = cost() >>> 3;\n            if (threshold <= leadCost) {\n              return indexScorerSupplier.get(leadCost);\n            } else {\n              return dvScorerSupplier.get(leadCost);\n            }\n          }\n\n          @Override\n          public long cost() {\n            return indexScorerSupplier.cost();\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(Long.MAX_VALUE);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, needsScores, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, needsScores, boost);\n    return new Weight(this) {\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        indexWeight.extractTerms(terms);\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.explain(context, doc);\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        // Bulk scorers need to consume the entire set of docs, so using an\n        // index structure should perform better\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context);\n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(boolean randomAccess) throws IOException {\n            return (randomAccess ? dvScorerSupplier : indexScorerSupplier).get(randomAccess);\n          }\n\n          @Override\n          public long cost() {\n            return Math.min(indexScorerSupplier.cost(), dvScorerSupplier.cost());\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(false);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7d6ba405c7c8192661bdf7ce782181d12f3162a6","date":1502361392,"type":3,"author":"Cao Manh Dat","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,boolean,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,boolean,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, needsScores, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, needsScores, boost);\n    return new Weight(this) {\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        indexWeight.extractTerms(terms);\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.explain(context, doc);\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        // Bulk scorers need to consume the entire set of docs, so using an\n        // index structure should perform better\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context);\n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(long leadCost) throws IOException {\n            // At equal costs, doc values tend to be worse than points since they\n            // still need to perform one comparison per document while points can\n            // do much better than that given how values are organized. So we give\n            // an arbitrary 8x penalty to doc values.\n            final long threshold = cost() >>> 3;\n            if (threshold <= leadCost) {\n              return indexScorerSupplier.get(leadCost);\n            } else {\n              return dvScorerSupplier.get(leadCost);\n            }\n          }\n\n          @Override\n          public long cost() {\n            return indexScorerSupplier.cost();\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(Long.MAX_VALUE);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, needsScores, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, needsScores, boost);\n    return new Weight(this) {\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        indexWeight.extractTerms(terms);\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.explain(context, doc);\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        // Bulk scorers need to consume the entire set of docs, so using an\n        // index structure should perform better\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context);\n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(boolean randomAccess) throws IOException {\n            return (randomAccess ? dvScorerSupplier : indexScorerSupplier).get(randomAccess);\n          }\n\n          @Override\n          public long cost() {\n            return Math.min(indexScorerSupplier.cost(), dvScorerSupplier.cost());\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(false);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"58884af1f68e9d61c217c753fbd6266d86a63b14","date":1502363401,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,boolean,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,boolean,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, needsScores, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, needsScores, boost);\n    return new Weight(this) {\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        indexWeight.extractTerms(terms);\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.explain(context, doc);\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        // Bulk scorers need to consume the entire set of docs, so using an\n        // index structure should perform better\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context);\n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(long leadCost) throws IOException {\n            // At equal costs, doc values tend to be worse than points since they\n            // still need to perform one comparison per document while points can\n            // do much better than that given how values are organized. So we give\n            // an arbitrary 8x penalty to doc values.\n            final long threshold = cost() >>> 3;\n            if (threshold <= leadCost) {\n              return indexScorerSupplier.get(leadCost);\n            } else {\n              return dvScorerSupplier.get(leadCost);\n            }\n          }\n\n          @Override\n          public long cost() {\n            return indexScorerSupplier.cost();\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(Long.MAX_VALUE);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, needsScores, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, needsScores, boost);\n    return new Weight(this) {\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        indexWeight.extractTerms(terms);\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.explain(context, doc);\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        // Bulk scorers need to consume the entire set of docs, so using an\n        // index structure should perform better\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context);\n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(boolean randomAccess) throws IOException {\n            return (randomAccess ? dvScorerSupplier : indexScorerSupplier).get(randomAccess);\n          }\n\n          @Override\n          public long cost() {\n            return Math.min(indexScorerSupplier.cost(), dvScorerSupplier.cost());\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(false);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"93d40a0287bd8a5b69a8df49a797dcd4a8b1a7be","date":1502692251,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,boolean,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,boolean,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, needsScores, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, needsScores, boost);\n    return new Weight(this) {\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        indexWeight.extractTerms(terms);\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.explain(context, doc);\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        // Bulk scorers need to consume the entire set of docs, so using an\n        // index structure should perform better\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context);\n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(long leadCost) throws IOException {\n            // At equal costs, doc values tend to be worse than points since they\n            // still need to perform one comparison per document while points can\n            // do much better than that given how values are organized. So we give\n            // an arbitrary 8x penalty to doc values.\n            final long threshold = cost() >>> 3;\n            if (threshold <= leadCost) {\n              return indexScorerSupplier.get(leadCost);\n            } else {\n              return dvScorerSupplier.get(leadCost);\n            }\n          }\n\n          @Override\n          public long cost() {\n            return indexScorerSupplier.cost();\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(Long.MAX_VALUE);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, needsScores, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, needsScores, boost);\n    return new Weight(this) {\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        indexWeight.extractTerms(terms);\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.explain(context, doc);\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        // Bulk scorers need to consume the entire set of docs, so using an\n        // index structure should perform better\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context);\n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(boolean randomAccess) throws IOException {\n            return (randomAccess ? dvScorerSupplier : indexScorerSupplier).get(randomAccess);\n          }\n\n          @Override\n          public long cost() {\n            return Math.min(indexScorerSupplier.cost(), dvScorerSupplier.cost());\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(false);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"706a7a3396c030cc66dda92a0492eb492131c4c0","date":1509705614,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,boolean,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,boolean,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, needsScores, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, needsScores, boost);\n    return new Weight(this) {\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        indexWeight.extractTerms(terms);\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.explain(context, doc);\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        // Bulk scorers need to consume the entire set of docs, so using an\n        // index structure should perform better\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context);\n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(long leadCost) throws IOException {\n            // At equal costs, doc values tend to be worse than points since they\n            // still need to perform one comparison per document while points can\n            // do much better than that given how values are organized. So we give\n            // an arbitrary 8x penalty to doc values.\n            final long threshold = cost() >>> 3;\n            if (threshold <= leadCost) {\n              return indexScorerSupplier.get(leadCost);\n            } else {\n              return dvScorerSupplier.get(leadCost);\n            }\n          }\n\n          @Override\n          public long cost() {\n            return indexScorerSupplier.cost();\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(Long.MAX_VALUE);\n      }\n\n      @Override\n      public IndexReader.CacheHelper getCacheHelper(LeafReaderContext context) {\n        // Both index and dv query should return the same values, so we can use\n        // the index query's cachehelper here\n        return indexWeight.getCacheHelper(context);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, needsScores, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, needsScores, boost);\n    return new Weight(this) {\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        indexWeight.extractTerms(terms);\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.explain(context, doc);\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        // Bulk scorers need to consume the entire set of docs, so using an\n        // index structure should perform better\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context);\n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(long leadCost) throws IOException {\n            // At equal costs, doc values tend to be worse than points since they\n            // still need to perform one comparison per document while points can\n            // do much better than that given how values are organized. So we give\n            // an arbitrary 8x penalty to doc values.\n            final long threshold = cost() >>> 3;\n            if (threshold <= leadCost) {\n              return indexScorerSupplier.get(leadCost);\n            } else {\n              return dvScorerSupplier.get(leadCost);\n            }\n          }\n\n          @Override\n          public long cost() {\n            return indexScorerSupplier.cost();\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(Long.MAX_VALUE);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d523b8189b211dd1630166aa77b8c88bb48b3fcc","date":1510144168,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,boolean,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,boolean,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, needsScores, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, needsScores, boost);\n    return new Weight(this) {\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        indexWeight.extractTerms(terms);\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.explain(context, doc);\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        // Bulk scorers need to consume the entire set of docs, so using an\n        // index structure should perform better\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context);\n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(long leadCost) throws IOException {\n            // At equal costs, doc values tend to be worse than points since they\n            // still need to perform one comparison per document while points can\n            // do much better than that given how values are organized. So we give\n            // an arbitrary 8x penalty to doc values.\n            final long threshold = cost() >>> 3;\n            if (threshold <= leadCost) {\n              return indexScorerSupplier.get(leadCost);\n            } else {\n              return dvScorerSupplier.get(leadCost);\n            }\n          }\n\n          @Override\n          public long cost() {\n            return indexScorerSupplier.cost();\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(Long.MAX_VALUE);\n      }\n\n      @Override\n      public IndexReader.CacheHelper getCacheHelper(LeafReaderContext context) {\n        // Both index and dv query should return the same values, so we can use\n        // the index query's cachehelper here\n        return indexWeight.getCacheHelper(context);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, needsScores, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, needsScores, boost);\n    return new Weight(this) {\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        indexWeight.extractTerms(terms);\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.explain(context, doc);\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        // Bulk scorers need to consume the entire set of docs, so using an\n        // index structure should perform better\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context);\n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(long leadCost) throws IOException {\n            // At equal costs, doc values tend to be worse than points since they\n            // still need to perform one comparison per document while points can\n            // do much better than that given how values are organized. So we give\n            // an arbitrary 8x penalty to doc values.\n            final long threshold = cost() >>> 3;\n            if (threshold <= leadCost) {\n              return indexScorerSupplier.get(leadCost);\n            } else {\n              return dvScorerSupplier.get(leadCost);\n            }\n          }\n\n          @Override\n          public long cost() {\n            return indexScorerSupplier.cost();\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(Long.MAX_VALUE);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"da1460d7a5dea2658e7b8e4f6e632e53ade440ac","date":1510316270,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,boolean,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,boolean,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, needsScores, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, needsScores, boost);\n    return new Weight(this) {\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        indexWeight.extractTerms(terms);\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.explain(context, doc);\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        // Bulk scorers need to consume the entire set of docs, so using an\n        // index structure should perform better\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context);\n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(long leadCost) throws IOException {\n            // At equal costs, doc values tend to be worse than points since they\n            // still need to perform one comparison per document while points can\n            // do much better than that given how values are organized. So we give\n            // an arbitrary 8x penalty to doc values.\n            final long threshold = cost() >>> 3;\n            if (threshold <= leadCost) {\n              return indexScorerSupplier.get(leadCost);\n            } else {\n              return dvScorerSupplier.get(leadCost);\n            }\n          }\n\n          @Override\n          public long cost() {\n            return indexScorerSupplier.cost();\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(Long.MAX_VALUE);\n      }\n\n      @Override\n      public boolean isCacheable(LeafReaderContext ctx) {\n        // Both index and dv query should return the same values, so we can use\n        // the index query's cachehelper here\n        return indexWeight.isCacheable(ctx);\n      }\n\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, needsScores, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, needsScores, boost);\n    return new Weight(this) {\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        indexWeight.extractTerms(terms);\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.explain(context, doc);\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        // Bulk scorers need to consume the entire set of docs, so using an\n        // index structure should perform better\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context);\n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(long leadCost) throws IOException {\n            // At equal costs, doc values tend to be worse than points since they\n            // still need to perform one comparison per document while points can\n            // do much better than that given how values are organized. So we give\n            // an arbitrary 8x penalty to doc values.\n            final long threshold = cost() >>> 3;\n            if (threshold <= leadCost) {\n              return indexScorerSupplier.get(leadCost);\n            } else {\n              return dvScorerSupplier.get(leadCost);\n            }\n          }\n\n          @Override\n          public long cost() {\n            return indexScorerSupplier.cost();\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(Long.MAX_VALUE);\n      }\n\n      @Override\n      public IndexReader.CacheHelper getCacheHelper(LeafReaderContext context) {\n        // Both index and dv query should return the same values, so we can use\n        // the index query's cachehelper here\n        return indexWeight.getCacheHelper(context);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9fc47cb7b4346802411bb432f501ed0673d7119e","date":1512640179,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,boolean,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, scoreMode, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, scoreMode, boost);\n    return new Weight(this) {\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        indexWeight.extractTerms(terms);\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.explain(context, doc);\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        // Bulk scorers need to consume the entire set of docs, so using an\n        // index structure should perform better\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context);\n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(long leadCost) throws IOException {\n            // At equal costs, doc values tend to be worse than points since they\n            // still need to perform one comparison per document while points can\n            // do much better than that given how values are organized. So we give\n            // an arbitrary 8x penalty to doc values.\n            final long threshold = cost() >>> 3;\n            if (threshold <= leadCost) {\n              return indexScorerSupplier.get(leadCost);\n            } else {\n              return dvScorerSupplier.get(leadCost);\n            }\n          }\n\n          @Override\n          public long cost() {\n            return indexScorerSupplier.cost();\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(Long.MAX_VALUE);\n      }\n\n      @Override\n      public boolean isCacheable(LeafReaderContext ctx) {\n        // Both index and dv query should return the same values, so we can use\n        // the index query's cachehelper here\n        return indexWeight.isCacheable(ctx);\n      }\n\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, needsScores, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, needsScores, boost);\n    return new Weight(this) {\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        indexWeight.extractTerms(terms);\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.explain(context, doc);\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        // Bulk scorers need to consume the entire set of docs, so using an\n        // index structure should perform better\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context);\n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(long leadCost) throws IOException {\n            // At equal costs, doc values tend to be worse than points since they\n            // still need to perform one comparison per document while points can\n            // do much better than that given how values are organized. So we give\n            // an arbitrary 8x penalty to doc values.\n            final long threshold = cost() >>> 3;\n            if (threshold <= leadCost) {\n              return indexScorerSupplier.get(leadCost);\n            } else {\n              return dvScorerSupplier.get(leadCost);\n            }\n          }\n\n          @Override\n          public long cost() {\n            return indexScorerSupplier.cost();\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(Long.MAX_VALUE);\n      }\n\n      @Override\n      public boolean isCacheable(LeafReaderContext ctx) {\n        // Both index and dv query should return the same values, so we can use\n        // the index query's cachehelper here\n        return indexWeight.isCacheable(ctx);\n      }\n\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"417142ff08fda9cf0b72d5133e63097a166c6458","date":1512729693,"type":5,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,boolean,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, scoreMode, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, scoreMode, boost);\n    return new Weight(this) {\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        indexWeight.extractTerms(terms);\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.explain(context, doc);\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        // Bulk scorers need to consume the entire set of docs, so using an\n        // index structure should perform better\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context);\n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(long leadCost) throws IOException {\n            // At equal costs, doc values tend to be worse than points since they\n            // still need to perform one comparison per document while points can\n            // do much better than that given how values are organized. So we give\n            // an arbitrary 8x penalty to doc values.\n            final long threshold = cost() >>> 3;\n            if (threshold <= leadCost) {\n              return indexScorerSupplier.get(leadCost);\n            } else {\n              return dvScorerSupplier.get(leadCost);\n            }\n          }\n\n          @Override\n          public long cost() {\n            return indexScorerSupplier.cost();\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(Long.MAX_VALUE);\n      }\n\n      @Override\n      public boolean isCacheable(LeafReaderContext ctx) {\n        // Both index and dv query should return the same values, so we can use\n        // the index query's cachehelper here\n        return indexWeight.isCacheable(ctx);\n      }\n\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, needsScores, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, needsScores, boost);\n    return new Weight(this) {\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        indexWeight.extractTerms(terms);\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.explain(context, doc);\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        // Bulk scorers need to consume the entire set of docs, so using an\n        // index structure should perform better\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context);\n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(long leadCost) throws IOException {\n            // At equal costs, doc values tend to be worse than points since they\n            // still need to perform one comparison per document while points can\n            // do much better than that given how values are organized. So we give\n            // an arbitrary 8x penalty to doc values.\n            final long threshold = cost() >>> 3;\n            if (threshold <= leadCost) {\n              return indexScorerSupplier.get(leadCost);\n            } else {\n              return dvScorerSupplier.get(leadCost);\n            }\n          }\n\n          @Override\n          public long cost() {\n            return indexScorerSupplier.cost();\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(Long.MAX_VALUE);\n      }\n\n      @Override\n      public boolean isCacheable(LeafReaderContext ctx) {\n        // Both index and dv query should return the same values, so we can use\n        // the index query's cachehelper here\n        return indexWeight.isCacheable(ctx);\n      }\n\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"706a7a3396c030cc66dda92a0492eb492131c4c0":["7d6ba405c7c8192661bdf7ce782181d12f3162a6"],"24f3e9c0fc20b3107388ec853a6fbad9f891b461":["5a412a7808b2815566cb17117ebe6638112b9a31"],"da1460d7a5dea2658e7b8e4f6e632e53ade440ac":["d523b8189b211dd1630166aa77b8c88bb48b3fcc"],"d523b8189b211dd1630166aa77b8c88bb48b3fcc":["7d6ba405c7c8192661bdf7ce782181d12f3162a6","706a7a3396c030cc66dda92a0492eb492131c4c0"],"90a682dc1bfd188ef61cc28373c7f5d700b4ac75":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","5a412a7808b2815566cb17117ebe6638112b9a31"],"417142ff08fda9cf0b72d5133e63097a166c6458":["da1460d7a5dea2658e7b8e4f6e632e53ade440ac","9fc47cb7b4346802411bb432f501ed0673d7119e"],"7d6ba405c7c8192661bdf7ce782181d12f3162a6":["5a412a7808b2815566cb17117ebe6638112b9a31","24f3e9c0fc20b3107388ec853a6fbad9f891b461"],"58884af1f68e9d61c217c753fbd6266d86a63b14":["5a412a7808b2815566cb17117ebe6638112b9a31","7d6ba405c7c8192661bdf7ce782181d12f3162a6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"93d40a0287bd8a5b69a8df49a797dcd4a8b1a7be":["5a412a7808b2815566cb17117ebe6638112b9a31","7d6ba405c7c8192661bdf7ce782181d12f3162a6"],"5a412a7808b2815566cb17117ebe6638112b9a31":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"9fc47cb7b4346802411bb432f501ed0673d7119e":["da1460d7a5dea2658e7b8e4f6e632e53ade440ac"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["417142ff08fda9cf0b72d5133e63097a166c6458"]},"commit2Childs":{"706a7a3396c030cc66dda92a0492eb492131c4c0":["d523b8189b211dd1630166aa77b8c88bb48b3fcc"],"24f3e9c0fc20b3107388ec853a6fbad9f891b461":["7d6ba405c7c8192661bdf7ce782181d12f3162a6"],"da1460d7a5dea2658e7b8e4f6e632e53ade440ac":["417142ff08fda9cf0b72d5133e63097a166c6458","9fc47cb7b4346802411bb432f501ed0673d7119e"],"d523b8189b211dd1630166aa77b8c88bb48b3fcc":["da1460d7a5dea2658e7b8e4f6e632e53ade440ac"],"90a682dc1bfd188ef61cc28373c7f5d700b4ac75":[],"417142ff08fda9cf0b72d5133e63097a166c6458":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"7d6ba405c7c8192661bdf7ce782181d12f3162a6":["706a7a3396c030cc66dda92a0492eb492131c4c0","d523b8189b211dd1630166aa77b8c88bb48b3fcc","58884af1f68e9d61c217c753fbd6266d86a63b14","93d40a0287bd8a5b69a8df49a797dcd4a8b1a7be"],"58884af1f68e9d61c217c753fbd6266d86a63b14":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["90a682dc1bfd188ef61cc28373c7f5d700b4ac75","5a412a7808b2815566cb17117ebe6638112b9a31"],"93d40a0287bd8a5b69a8df49a797dcd4a8b1a7be":[],"5a412a7808b2815566cb17117ebe6638112b9a31":["24f3e9c0fc20b3107388ec853a6fbad9f891b461","90a682dc1bfd188ef61cc28373c7f5d700b4ac75","7d6ba405c7c8192661bdf7ce782181d12f3162a6","58884af1f68e9d61c217c753fbd6266d86a63b14","93d40a0287bd8a5b69a8df49a797dcd4a8b1a7be"],"9fc47cb7b4346802411bb432f501ed0673d7119e":["417142ff08fda9cf0b72d5133e63097a166c6458"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["90a682dc1bfd188ef61cc28373c7f5d700b4ac75","58884af1f68e9d61c217c753fbd6266d86a63b14","93d40a0287bd8a5b69a8df49a797dcd4a8b1a7be","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}