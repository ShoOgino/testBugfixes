{"path":"solr/contrib/solr-mr/src/java/org/apache/solr/hadoop/morphline/MorphlineMapRunner#getRecord(PathParts).mjava","commits":[{"id":"d6e604e9030fb0cabf0c5a85ae6039921a81419c","date":1386009743,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/contrib/solr-mr/src/java/org/apache/solr/hadoop/morphline/MorphlineMapRunner#getRecord(PathParts).mjava","pathOld":"/dev/null","sourceNew":"  protected Record getRecord(PathParts parts) {\n    FileStatus stats;\n    try {\n      stats = parts.getFileStatus();\n    } catch (IOException e) {\n      stats = null;\n    }\n    if (stats == null) {\n      LOG.warn(\"Ignoring file that somehow has become unavailable since the job was submitted: {}\",\n          parts.getUploadURL());\n      return null;\n    }\n    \n    Record headers = new Record();\n    //headers.put(getSchema().getUniqueKeyField().getName(), parts.getId()); // use HDFS file path as docId if no docId is specified\n    headers.put(Fields.BASE_ID, parts.getId()); // with sanitizeUniqueKey command, use HDFS file path as docId if no docId is specified\n    headers.put(Fields.ATTACHMENT_NAME, parts.getName()); // Tika can use the file name in guessing the right MIME type\n    \n    // enable indexing and storing of file meta data in Solr\n    headers.put(HdfsFileFieldNames.FILE_UPLOAD_URL, parts.getUploadURL());\n    headers.put(HdfsFileFieldNames.FILE_DOWNLOAD_URL, parts.getDownloadURL());\n    headers.put(HdfsFileFieldNames.FILE_SCHEME, parts.getScheme()); \n    headers.put(HdfsFileFieldNames.FILE_HOST, parts.getHost()); \n    headers.put(HdfsFileFieldNames.FILE_PORT, String.valueOf(parts.getPort())); \n    headers.put(HdfsFileFieldNames.FILE_PATH, parts.getURIPath()); \n    headers.put(HdfsFileFieldNames.FILE_NAME, parts.getName());     \n    headers.put(HdfsFileFieldNames.FILE_LAST_MODIFIED, String.valueOf(stats.getModificationTime())); // FIXME also add in SpoolDirectorySource\n    headers.put(HdfsFileFieldNames.FILE_LENGTH, String.valueOf(stats.getLen())); // FIXME also add in SpoolDirectorySource\n    headers.put(HdfsFileFieldNames.FILE_OWNER, stats.getOwner());\n    headers.put(HdfsFileFieldNames.FILE_GROUP, stats.getGroup());\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_USER, stats.getPermission().getUserAction().SYMBOL);\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_GROUP, stats.getPermission().getGroupAction().SYMBOL);\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_OTHER, stats.getPermission().getOtherAction().SYMBOL);\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_STICKYBIT, String.valueOf(stats.getPermission().getStickyBit()));\n    // TODO: consider to add stats.getAccessTime(), stats.getReplication(), stats.isSymlink(), stats.getBlockSize()\n    \n    return headers;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70f91c8322fbffe3a3a897ef20ea19119cac10cd","date":1386170124,"type":5,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/morphline/MorphlineMapRunner#getRecord(PathParts).mjava","pathOld":"solr/contrib/solr-mr/src/java/org/apache/solr/hadoop/morphline/MorphlineMapRunner#getRecord(PathParts).mjava","sourceNew":"  protected Record getRecord(PathParts parts) {\n    FileStatus stats;\n    try {\n      stats = parts.getFileStatus();\n    } catch (IOException e) {\n      stats = null;\n    }\n    if (stats == null) {\n      LOG.warn(\"Ignoring file that somehow has become unavailable since the job was submitted: {}\",\n          parts.getUploadURL());\n      return null;\n    }\n    \n    Record headers = new Record();\n    //headers.put(getSchema().getUniqueKeyField().getName(), parts.getId()); // use HDFS file path as docId if no docId is specified\n    headers.put(Fields.BASE_ID, parts.getId()); // with sanitizeUniqueKey command, use HDFS file path as docId if no docId is specified\n    headers.put(Fields.ATTACHMENT_NAME, parts.getName()); // Tika can use the file name in guessing the right MIME type\n    \n    // enable indexing and storing of file meta data in Solr\n    headers.put(HdfsFileFieldNames.FILE_UPLOAD_URL, parts.getUploadURL());\n    headers.put(HdfsFileFieldNames.FILE_DOWNLOAD_URL, parts.getDownloadURL());\n    headers.put(HdfsFileFieldNames.FILE_SCHEME, parts.getScheme()); \n    headers.put(HdfsFileFieldNames.FILE_HOST, parts.getHost()); \n    headers.put(HdfsFileFieldNames.FILE_PORT, String.valueOf(parts.getPort())); \n    headers.put(HdfsFileFieldNames.FILE_PATH, parts.getURIPath()); \n    headers.put(HdfsFileFieldNames.FILE_NAME, parts.getName());     \n    headers.put(HdfsFileFieldNames.FILE_LAST_MODIFIED, String.valueOf(stats.getModificationTime())); // FIXME also add in SpoolDirectorySource\n    headers.put(HdfsFileFieldNames.FILE_LENGTH, String.valueOf(stats.getLen())); // FIXME also add in SpoolDirectorySource\n    headers.put(HdfsFileFieldNames.FILE_OWNER, stats.getOwner());\n    headers.put(HdfsFileFieldNames.FILE_GROUP, stats.getGroup());\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_USER, stats.getPermission().getUserAction().SYMBOL);\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_GROUP, stats.getPermission().getGroupAction().SYMBOL);\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_OTHER, stats.getPermission().getOtherAction().SYMBOL);\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_STICKYBIT, String.valueOf(stats.getPermission().getStickyBit()));\n    // TODO: consider to add stats.getAccessTime(), stats.getReplication(), stats.isSymlink(), stats.getBlockSize()\n    \n    return headers;\n  }\n\n","sourceOld":"  protected Record getRecord(PathParts parts) {\n    FileStatus stats;\n    try {\n      stats = parts.getFileStatus();\n    } catch (IOException e) {\n      stats = null;\n    }\n    if (stats == null) {\n      LOG.warn(\"Ignoring file that somehow has become unavailable since the job was submitted: {}\",\n          parts.getUploadURL());\n      return null;\n    }\n    \n    Record headers = new Record();\n    //headers.put(getSchema().getUniqueKeyField().getName(), parts.getId()); // use HDFS file path as docId if no docId is specified\n    headers.put(Fields.BASE_ID, parts.getId()); // with sanitizeUniqueKey command, use HDFS file path as docId if no docId is specified\n    headers.put(Fields.ATTACHMENT_NAME, parts.getName()); // Tika can use the file name in guessing the right MIME type\n    \n    // enable indexing and storing of file meta data in Solr\n    headers.put(HdfsFileFieldNames.FILE_UPLOAD_URL, parts.getUploadURL());\n    headers.put(HdfsFileFieldNames.FILE_DOWNLOAD_URL, parts.getDownloadURL());\n    headers.put(HdfsFileFieldNames.FILE_SCHEME, parts.getScheme()); \n    headers.put(HdfsFileFieldNames.FILE_HOST, parts.getHost()); \n    headers.put(HdfsFileFieldNames.FILE_PORT, String.valueOf(parts.getPort())); \n    headers.put(HdfsFileFieldNames.FILE_PATH, parts.getURIPath()); \n    headers.put(HdfsFileFieldNames.FILE_NAME, parts.getName());     \n    headers.put(HdfsFileFieldNames.FILE_LAST_MODIFIED, String.valueOf(stats.getModificationTime())); // FIXME also add in SpoolDirectorySource\n    headers.put(HdfsFileFieldNames.FILE_LENGTH, String.valueOf(stats.getLen())); // FIXME also add in SpoolDirectorySource\n    headers.put(HdfsFileFieldNames.FILE_OWNER, stats.getOwner());\n    headers.put(HdfsFileFieldNames.FILE_GROUP, stats.getGroup());\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_USER, stats.getPermission().getUserAction().SYMBOL);\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_GROUP, stats.getPermission().getGroupAction().SYMBOL);\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_OTHER, stats.getPermission().getOtherAction().SYMBOL);\n    headers.put(HdfsFileFieldNames.FILE_PERMISSIONS_STICKYBIT, String.valueOf(stats.getPermission().getStickyBit()));\n    // TODO: consider to add stats.getAccessTime(), stats.getReplication(), stats.isSymlink(), stats.getBlockSize()\n    \n    return headers;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"70f91c8322fbffe3a3a897ef20ea19119cac10cd":["d6e604e9030fb0cabf0c5a85ae6039921a81419c"],"d6e604e9030fb0cabf0c5a85ae6039921a81419c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["70f91c8322fbffe3a3a897ef20ea19119cac10cd"]},"commit2Childs":{"70f91c8322fbffe3a3a897ef20ea19119cac10cd":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d6e604e9030fb0cabf0c5a85ae6039921a81419c":["70f91c8322fbffe3a3a897ef20ea19119cac10cd"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d6e604e9030fb0cabf0c5a85ae6039921a81419c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}