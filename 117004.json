{"path":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","commits":[{"id":"30e0912f3a3069b115cfea44ff612c44d6906386","date":1365631344,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","pathOld":"/dev/null","sourceNew":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(_TestUtil.getTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    IndexReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes IR[]\");\n            }\n            w.addIndexes(new IndexReader[] {r});\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        w.close();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(_TestUtil.getTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<String>();\n        for (String file : dir.listAll()) {\n          dir.copy(dirCopy, file, file, IOContext.DEFAULT);\n          files.add(file);\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["0fa3fa46c67543546ab45142cc8ee7cf34fc9aaa","11c6df42fb3eba174c3ca0d9a5194eaecd893b77"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","sourceNew":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(TestUtil.getTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    IndexReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes IR[]\");\n            }\n            w.addIndexes(new IndexReader[] {r});\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        w.close();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(TestUtil.getTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<String>();\n        for (String file : dir.listAll()) {\n          dir.copy(dirCopy, file, file, IOContext.DEFAULT);\n          files.add(file);\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(_TestUtil.getTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    IndexReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes IR[]\");\n            }\n            w.addIndexes(new IndexReader[] {r});\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        w.close();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(_TestUtil.getTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<String>();\n        for (String file : dir.listAll()) {\n          dir.copy(dirCopy, file, file, IOContext.DEFAULT);\n          files.add(file);\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e1151ecb4798f5c31137aec032c241638018ed20","date":1394284367,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","sourceNew":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(TestUtil.getTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    IndexReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes IR[]\");\n            }\n            w.addIndexes(new IndexReader[] {r});\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        w.close();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(TestUtil.getTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<String>();\n        for (String file : dir.listAll()) {\n          dir.copy(dirCopy, file, file, IOContext.DEFAULT);\n          files.add(file);\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(TestUtil.getTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    IndexReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes IR[]\");\n            }\n            w.addIndexes(new IndexReader[] {r});\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        w.close();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(TestUtil.getTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<String>();\n        for (String file : dir.listAll()) {\n          dir.copy(dirCopy, file, file, IOContext.DEFAULT);\n          files.add(file);\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a58bbbe1c866963764d3f15d3a26a6a85f6c6af4","date":1394564625,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","sourceNew":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(TestUtil.getTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    IndexReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes IR[]\");\n            }\n            w.addIndexes(new IndexReader[] {r});\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        w.close();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(TestUtil.getTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<String>();\n        for (String file : dir.listAll()) {\n          dir.copy(dirCopy, file, file, IOContext.DEFAULT);\n          files.add(file);\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(TestUtil.getTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    IndexReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes IR[]\");\n            }\n            w.addIndexes(new IndexReader[] {r});\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        w.close();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(TestUtil.getTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<String>();\n        for (String file : dir.listAll()) {\n          dir.copy(dirCopy, file, file, IOContext.DEFAULT);\n          files.add(file);\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","sourceNew":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(TestUtil.getTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    IndexReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes IR[]\");\n            }\n            w.addIndexes(new IndexReader[] {r});\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        w.close();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(TestUtil.getTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          dir.copy(dirCopy, file, file, IOContext.DEFAULT);\n          files.add(file);\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(TestUtil.getTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    IndexReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes IR[]\");\n            }\n            w.addIndexes(new IndexReader[] {r});\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        w.close();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(TestUtil.getTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<String>();\n        for (String file : dir.listAll()) {\n          dir.copy(dirCopy, file, file, IOContext.DEFAULT);\n          files.add(file);\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cd4e13d997cf4fb810398a20a299c2c5a9f6b796","date":1395594336,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","sourceNew":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(TestUtil.getTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    IndexReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes IR[]\");\n            }\n            w.addIndexes(new IndexReader[] {r});\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        w.close();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(TestUtil.getTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          dir.copy(dirCopy, file, file, IOContext.DEFAULT);\n          files.add(file);\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(TestUtil.getTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    IndexReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes IR[]\");\n            }\n            w.addIndexes(new IndexReader[] {r});\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        w.close();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(TestUtil.getTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          dir.copy(dirCopy, file, file, IOContext.DEFAULT);\n          files.add(file);\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d0d579490a72f2e6297eaa648940611234c57cf1","date":1395917140,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","sourceNew":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(TestUtil.createTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    IndexReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes IR[]\");\n            }\n            w.addIndexes(new IndexReader[] {r});\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        w.close();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(TestUtil.createTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          dir.copy(dirCopy, file, file, IOContext.DEFAULT);\n          files.add(file);\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(TestUtil.getTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    IndexReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes IR[]\");\n            }\n            w.addIndexes(new IndexReader[] {r});\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        w.close();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(TestUtil.getTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          dir.copy(dirCopy, file, file, IOContext.DEFAULT);\n          files.add(file);\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a9a24bae1e63c3bb5ff2fb47b0119240d840ee7c","date":1396633078,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","sourceNew":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    IndexReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes IR[]\");\n            }\n            w.addIndexes(new IndexReader[] {r});\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        w.close();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          dir.copy(dirCopy, file, file, IOContext.DEFAULT);\n          files.add(file);\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(TestUtil.createTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    IndexReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes IR[]\");\n            }\n            w.addIndexes(new IndexReader[] {r});\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        w.close();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(TestUtil.createTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          dir.copy(dirCopy, file, file, IOContext.DEFAULT);\n          files.add(file);\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2a0f5bb79c600763ffe7b8141df59a3169d31e48","date":1396689440,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","sourceNew":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    IndexReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes IR[]\");\n            }\n            w.addIndexes(new IndexReader[] {r});\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        w.close();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          dir.copy(dirCopy, file, file, IOContext.DEFAULT);\n          files.add(file);\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(TestUtil.getTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    IndexReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes IR[]\");\n            }\n            w.addIndexes(new IndexReader[] {r});\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        w.close();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(TestUtil.getTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          dir.copy(dirCopy, file, file, IOContext.DEFAULT);\n          files.add(file);\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","sourceNew":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    IndexReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes IR[]\");\n            }\n            w.addIndexes(new IndexReader[] {r});\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        w.shutdown();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          dir.copy(dirCopy, file, file, IOContext.DEFAULT);\n          files.add(file);\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))).shutdown();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    IndexReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes IR[]\");\n            }\n            w.addIndexes(new IndexReader[] {r});\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        w.close();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          dir.copy(dirCopy, file, file, IOContext.DEFAULT);\n          files.add(file);\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","sourceNew":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    IndexReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes IR[]\");\n            }\n            w.addIndexes(new IndexReader[] {r});\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        w.shutdown();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          dir.copy(dirCopy, file, file, IOContext.DEFAULT);\n          files.add(file);\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(new MockAnalyzer(random()))).shutdown();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    IndexReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes IR[]\");\n            }\n            w.addIndexes(new IndexReader[] {r});\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        w.shutdown();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          dir.copy(dirCopy, file, file, IOContext.DEFAULT);\n          files.add(file);\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))).shutdown();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","sourceNew":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    IndexReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes IR[]\");\n            }\n            w.addIndexes(new IndexReader[] {r});\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        w.close();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          dir.copy(dirCopy, file, file, IOContext.DEFAULT);\n          files.add(file);\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    IndexReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes IR[]\");\n            }\n            w.addIndexes(new IndexReader[] {r});\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        w.shutdown();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          dir.copy(dirCopy, file, file, IOContext.DEFAULT);\n          files.add(file);\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(new MockAnalyzer(random()))).shutdown();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["72bb5f6dcfb4fcb6cf7f7bb97ec181faf7484c52"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"52d4cfb22484037a9b8e9080e03aeaff60954880","date":1420125313,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","sourceNew":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    IndexReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes IR[]\");\n            }\n            w.addIndexes(new IndexReader[] {r});\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        w.close();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          dirCopy.copyFrom(dir, file, file, IOContext.DEFAULT);\n          files.add(file);\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    IndexReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes IR[]\");\n            }\n            w.addIndexes(new IndexReader[] {r});\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        w.close();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          dir.copy(dirCopy, file, file, IOContext.DEFAULT);\n          files.add(file);\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0fa3fa46c67543546ab45142cc8ee7cf34fc9aaa","date":1420599177,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","sourceNew":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    DirectoryReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes LR[]\");\n            }\n            TestUtil.addIndexesSlowly(w, r);\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        w.close();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          dirCopy.copyFrom(dir, file, file, IOContext.DEFAULT);\n          files.add(file);\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    IndexReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes IR[]\");\n            }\n            w.addIndexes(new IndexReader[] {r});\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        w.close();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          dirCopy.copyFrom(dir, file, file, IOContext.DEFAULT);\n          files.add(file);\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","bugFix":["30e0912f3a3069b115cfea44ff612c44d6906386"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b36736553cfe38460cf236e855aeb30730073855","date":1424496993,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","sourceNew":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    DirectoryReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes LR[]\");\n            }\n            TestUtil.addIndexesSlowly(w, r);\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        w.close();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          if (file.startsWith(IndexFileNames.SEGMENTS) || IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n            dirCopy.copyFrom(dir, file, file, IOContext.DEFAULT);\n            files.add(file);\n          }\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    DirectoryReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes LR[]\");\n            }\n            TestUtil.addIndexesSlowly(w, r);\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        w.close();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          dirCopy.copyFrom(dir, file, file, IOContext.DEFAULT);\n          files.add(file);\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a6b82a3644db30161c3cbd3e23aeefe19cb88113","date":1435478870,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","sourceNew":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    DirectoryReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes LR[]\");\n            }\n            TestUtil.addIndexesSlowly(w, r);\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        w.close();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (AssertionError | IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          if (file.startsWith(IndexFileNames.SEGMENTS) || IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n            dirCopy.copyFrom(dir, file, file, IOContext.DEFAULT);\n            files.add(file);\n          }\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    DirectoryReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes LR[]\");\n            }\n            TestUtil.addIndexesSlowly(w, r);\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        w.close();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          if (file.startsWith(IndexFileNames.SEGMENTS) || IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n            dirCopy.copyFrom(dir, file, file, IOContext.DEFAULT);\n            files.add(file);\n          }\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"72bb5f6dcfb4fcb6cf7f7bb97ec181faf7484c52","date":1442279960,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","sourceNew":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    DirectoryReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes LR[]\");\n            }\n            TestUtil.addIndexesSlowly(w, r);\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).sync();\n        }\n        // If exc hit CMS then writer will be tragically closed:\n        if (w.getTragicException() == null) {\n          w.close();\n        }\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (AssertionError | IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          if (file.startsWith(IndexFileNames.SEGMENTS) || IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n            dirCopy.copyFrom(dir, file, file, IOContext.DEFAULT);\n            files.add(file);\n          }\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    DirectoryReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes LR[]\");\n            }\n            TestUtil.addIndexesSlowly(w, r);\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        w.close();\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (AssertionError | IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          if (file.startsWith(IndexFileNames.SEGMENTS) || IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n            dirCopy.copyFrom(dir, file, file, IOContext.DEFAULT);\n            files.add(file);\n          }\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","bugFix":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"11c6df42fb3eba174c3ca0d9a5194eaecd893b77","date":1465931757,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","sourceNew":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    DirectoryReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes LR[]\");\n            }\n            TestUtil.addIndexesSlowly(w, r);\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).sync();\n        }\n        // If exc hit CMS then writer will be tragically closed:\n        if (w.getTragicException() == null) {\n          w.close();\n        }\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (AssertionError | IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          if (file.startsWith(IndexFileNames.SEGMENTS) || IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n            dirCopy.copyFrom(dir, file, file, IOContext.DEFAULT);\n            files.add(file);\n          }\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    DirectoryReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes LR[]\");\n            }\n            TestUtil.addIndexesSlowly(w, r);\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).sync();\n        }\n        // If exc hit CMS then writer will be tragically closed:\n        if (w.getTragicException() == null) {\n          w.close();\n        }\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (AssertionError | IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          if (file.startsWith(IndexFileNames.SEGMENTS) || IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n            dirCopy.copyFrom(dir, file, file, IOContext.DEFAULT);\n            files.add(file);\n          }\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","bugFix":["30e0912f3a3069b115cfea44ff612c44d6906386"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","sourceNew":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    DirectoryReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes LR[]\");\n            }\n            TestUtil.addIndexesSlowly(w, r);\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).sync();\n        }\n        // If exc hit CMS then writer will be tragically closed:\n        if (w.getTragicException() == null) {\n          w.close();\n        }\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (AssertionError | IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          if (file.startsWith(IndexFileNames.SEGMENTS) || IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n            dirCopy.copyFrom(dir, file, file, IOContext.DEFAULT);\n            files.add(file);\n          }\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    dir.setPreventDoubleWrite(false);\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    DirectoryReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes LR[]\");\n            }\n            TestUtil.addIndexesSlowly(w, r);\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).sync();\n        }\n        // If exc hit CMS then writer will be tragically closed:\n        if (w.getTragicException() == null) {\n          w.close();\n        }\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (AssertionError | IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          if (file.startsWith(IndexFileNames.SEGMENTS) || IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n            dirCopy.copyFrom(dir, file, file, IOContext.DEFAULT);\n            files.add(file);\n          }\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c4636d93693f8d76e3d5f6940b31bde2540d7354","date":1524737410,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","sourceNew":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    DirectoryReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        if (Constants.WINDOWS && dir.checkPendingDeletions()) {\n          // if we are on windows and we have pending deletions we can't execute this test\n          break;\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes LR[]\");\n            }\n            TestUtil.addIndexesSlowly(w, r);\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).sync();\n        }\n        // If exc hit CMS then writer will be tragically closed:\n        if (w.getTragicException() == null) {\n          w.close();\n        }\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (AssertionError | IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          if (file.startsWith(IndexFileNames.SEGMENTS) || IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n            dirCopy.copyFrom(dir, file, file, IOContext.DEFAULT);\n            files.add(file);\n          }\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    DirectoryReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes LR[]\");\n            }\n            TestUtil.addIndexesSlowly(w, r);\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).sync();\n        }\n        // If exc hit CMS then writer will be tragically closed:\n        if (w.getTragicException() == null) {\n          w.close();\n        }\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (AssertionError | IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          if (file.startsWith(IndexFileNames.SEGMENTS) || IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n            dirCopy.copyFrom(dir, file, file, IOContext.DEFAULT);\n            files.add(file);\n          }\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c5e84aa7f651de6493590da495bcbe46d32cf038","date":1526462263,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfFileDescriptors#test().mjava","sourceNew":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    DirectoryReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes LR[]\");\n            }\n            TestUtil.addIndexesSlowly(w, r);\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).sync();\n        }\n        // If exc hit CMS then writer will be tragically closed:\n        if (w.getTragicException() == null) {\n          w.close();\n        }\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (AssertionError | IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          if (file.startsWith(IndexFileNames.SEGMENTS) || IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n            dirCopy.copyFrom(dir, file, file, IOContext.DEFAULT);\n            files.add(file);\n          }\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    MockDirectoryWrapper dir = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors\"));\n    double rate = random().nextDouble()*0.01;\n    //System.out.println(\"rate=\" + rate);\n    dir.setRandomIOExceptionRateOnOpen(rate);\n    int iters = atLeast(20);\n    LineFileDocs docs = new LineFileDocs(random());\n    DirectoryReader r = null;\n    DirectoryReader r2 = null;\n    boolean any = false;\n    MockDirectoryWrapper dirCopy = null;\n    int lastNumDocs = 0;\n    for(int iter=0;iter<iters;iter++) {\n\n      IndexWriter w = null;\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      try {\n        MockAnalyzer analyzer = new MockAnalyzer(random());\n        analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n        IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n\n        if (VERBOSE) {\n          // Do this ourselves instead of relying on LTC so\n          // we see incrementing messageID:\n          iwc.setInfoStream(new PrintStreamInfoStream(System.out));\n        }\n        MergeScheduler ms = iwc.getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n        if (Constants.WINDOWS && dir.checkPendingDeletions()) {\n          // if we are on windows and we have pending deletions we can't execute this test\n          break;\n        }\n        w = new IndexWriter(dir, iwc);\n        if (r != null && random().nextInt(5) == 3) {\n          if (random().nextBoolean()) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes LR[]\");\n            }\n            TestUtil.addIndexesSlowly(w, r);\n          } else {\n            if (VERBOSE) {\n              System.out.println(\"TEST: addIndexes Directory[]\");\n            }\n            w.addIndexes(new Directory[] {dirCopy});\n          }\n        } else {\n          if (VERBOSE) {\n            System.out.println(\"TEST: addDocument\");\n          }\n          w.addDocument(docs.nextDoc());\n        }\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        if (ms instanceof ConcurrentMergeScheduler) {\n          ((ConcurrentMergeScheduler) ms).sync();\n        }\n        // If exc hit CMS then writer will be tragically closed:\n        if (w.getTragicException() == null) {\n          w.close();\n        }\n        w = null;\n\n        // NOTE: This is O(N^2)!  Only enable for temporary debugging:\n        //dir.setRandomIOExceptionRateOnOpen(0.0);\n        //_TestUtil.checkIndex(dir);\n        //dir.setRandomIOExceptionRateOnOpen(rate);\n\n        // Verify numDocs only increases, to catch IndexWriter\n        // accidentally deleting the index:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        assertTrue(DirectoryReader.indexExists(dir));\n        if (r2 == null) {\n          r2 = DirectoryReader.open(dir);\n        } else {\n          DirectoryReader r3 = DirectoryReader.openIfChanged(r2);\n          if (r3 != null) {\n            r2.close();\n            r2 = r3;\n          }\n        }\n        assertTrue(\"before=\" + lastNumDocs + \" after=\" + r2.numDocs(), r2.numDocs() >= lastNumDocs);\n        lastNumDocs = r2.numDocs();\n        //System.out.println(\"numDocs=\" + lastNumDocs);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n\n        any = true;\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": success\");\n        }\n      } catch (AssertionError | IOException ioe) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: iter=\" + iter + \": exception\");\n          ioe.printStackTrace();\n        }\n        if (w != null) {\n          // NOTE: leave random IO exceptions enabled here,\n          // to verify that rollback does not try to write\n          // anything:\n          w.rollback();\n        }\n      }\n\n      if (any && r == null && random().nextBoolean()) {\n        // Make a copy of a non-empty index so we can use\n        // it to addIndexes later:\n        dir.setRandomIOExceptionRateOnOpen(0.0);\n        r = DirectoryReader.open(dir);\n        dirCopy = newMockFSDirectory(createTempDir(\"TestIndexWriterOutOfFileDescriptors.copy\"));\n        Set<String> files = new HashSet<>();\n        for (String file : dir.listAll()) {\n          if (file.startsWith(IndexFileNames.SEGMENTS) || IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n            dirCopy.copyFrom(dir, file, file, IOContext.DEFAULT);\n            files.add(file);\n          }\n        }\n        dirCopy.sync(files);\n        // Have IW kiss the dir so we remove any leftover\n        // files ... we can easily have leftover files at\n        // the time we take a copy because we are holding\n        // open a reader:\n        new IndexWriter(dirCopy, newIndexWriterConfig(new MockAnalyzer(random()))).close();\n        dirCopy.setRandomIOExceptionRate(rate);\n        dir.setRandomIOExceptionRateOnOpen(rate);\n      }\n    }\n\n    if (r2 != null) {\n      r2.close();\n    }\n    if (r != null) {\n      r.close();\n      dirCopy.close();\n    }\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["e1151ecb4798f5c31137aec032c241638018ed20"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"2a0f5bb79c600763ffe7b8141df59a3169d31e48":["cd4e13d997cf4fb810398a20a299c2c5a9f6b796","a9a24bae1e63c3bb5ff2fb47b0119240d840ee7c"],"cd4e13d997cf4fb810398a20a299c2c5a9f6b796":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"a58bbbe1c866963764d3f15d3a26a6a85f6c6af4":["6613659748fe4411a7dcf85266e55db1f95f7315","e1151ecb4798f5c31137aec032c241638018ed20"],"6613659748fe4411a7dcf85266e55db1f95f7315":["30e0912f3a3069b115cfea44ff612c44d6906386"],"0fa3fa46c67543546ab45142cc8ee7cf34fc9aaa":["52d4cfb22484037a9b8e9080e03aeaff60954880"],"11c6df42fb3eba174c3ca0d9a5194eaecd893b77":["72bb5f6dcfb4fcb6cf7f7bb97ec181faf7484c52"],"d0d579490a72f2e6297eaa648940611234c57cf1":["cd4e13d997cf4fb810398a20a299c2c5a9f6b796"],"72bb5f6dcfb4fcb6cf7f7bb97ec181faf7484c52":["a6b82a3644db30161c3cbd3e23aeefe19cb88113"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["72bb5f6dcfb4fcb6cf7f7bb97ec181faf7484c52","11c6df42fb3eba174c3ca0d9a5194eaecd893b77"],"e1151ecb4798f5c31137aec032c241638018ed20":["6613659748fe4411a7dcf85266e55db1f95f7315"],"b36736553cfe38460cf236e855aeb30730073855":["0fa3fa46c67543546ab45142cc8ee7cf34fc9aaa"],"a9a24bae1e63c3bb5ff2fb47b0119240d840ee7c":["d0d579490a72f2e6297eaa648940611234c57cf1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"52d4cfb22484037a9b8e9080e03aeaff60954880":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"a6b82a3644db30161c3cbd3e23aeefe19cb88113":["b36736553cfe38460cf236e855aeb30730073855"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["2a0f5bb79c600763ffe7b8141df59a3169d31e48"],"30e0912f3a3069b115cfea44ff612c44d6906386":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c4636d93693f8d76e3d5f6940b31bde2540d7354":["11c6df42fb3eba174c3ca0d9a5194eaecd893b77"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c5e84aa7f651de6493590da495bcbe46d32cf038"],"c5e84aa7f651de6493590da495bcbe46d32cf038":["c4636d93693f8d76e3d5f6940b31bde2540d7354"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["cd4e13d997cf4fb810398a20a299c2c5a9f6b796"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"2a0f5bb79c600763ffe7b8141df59a3169d31e48":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"cd4e13d997cf4fb810398a20a299c2c5a9f6b796":["2a0f5bb79c600763ffe7b8141df59a3169d31e48","d0d579490a72f2e6297eaa648940611234c57cf1"],"a58bbbe1c866963764d3f15d3a26a6a85f6c6af4":[],"6613659748fe4411a7dcf85266e55db1f95f7315":["a58bbbe1c866963764d3f15d3a26a6a85f6c6af4","e1151ecb4798f5c31137aec032c241638018ed20"],"0fa3fa46c67543546ab45142cc8ee7cf34fc9aaa":["b36736553cfe38460cf236e855aeb30730073855"],"11c6df42fb3eba174c3ca0d9a5194eaecd893b77":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","c4636d93693f8d76e3d5f6940b31bde2540d7354"],"d0d579490a72f2e6297eaa648940611234c57cf1":["a9a24bae1e63c3bb5ff2fb47b0119240d840ee7c"],"72bb5f6dcfb4fcb6cf7f7bb97ec181faf7484c52":["11c6df42fb3eba174c3ca0d9a5194eaecd893b77","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"e1151ecb4798f5c31137aec032c241638018ed20":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","a58bbbe1c866963764d3f15d3a26a6a85f6c6af4"],"b36736553cfe38460cf236e855aeb30730073855":["a6b82a3644db30161c3cbd3e23aeefe19cb88113"],"a9a24bae1e63c3bb5ff2fb47b0119240d840ee7c":["2a0f5bb79c600763ffe7b8141df59a3169d31e48"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["30e0912f3a3069b115cfea44ff612c44d6906386"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["52d4cfb22484037a9b8e9080e03aeaff60954880"],"52d4cfb22484037a9b8e9080e03aeaff60954880":["0fa3fa46c67543546ab45142cc8ee7cf34fc9aaa"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"30e0912f3a3069b115cfea44ff612c44d6906386":["6613659748fe4411a7dcf85266e55db1f95f7315"],"a6b82a3644db30161c3cbd3e23aeefe19cb88113":["72bb5f6dcfb4fcb6cf7f7bb97ec181faf7484c52"],"c4636d93693f8d76e3d5f6940b31bde2540d7354":["c5e84aa7f651de6493590da495bcbe46d32cf038"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"c5e84aa7f651de6493590da495bcbe46d32cf038":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["a58bbbe1c866963764d3f15d3a26a6a85f6c6af4","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}