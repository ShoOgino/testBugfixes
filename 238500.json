{"path":"contrib/analyzers/src/java/org/apache/lucene/analysis/ar/ArabicNormalizer#normalize(char[],int).mjava","commits":[{"id":"4507f887015ed704dfc72ce14e0b23ce086865e0","date":1224523169,"type":0,"author":"Grant Ingersoll","isMerge":false,"pathNew":"contrib/analyzers/src/java/org/apache/lucene/analysis/ar/ArabicNormalizer#normalize(char[],int).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Normalize an input buffer of Arabic text\n   * \n   * @param s input buffer\n   * @param len length of input buffer\n   * @return length of input buffer after normalization\n   */\n  public int normalize(char s[], int len) {\n \n    for (int i = 0; i < len; i++) {\n      if (s[i] == ALEF_MADDA || s[i] == ALEF_HAMZA_ABOVE || s[i] == ALEF_HAMZA_BELOW)\n        s[i] = ALEF;\n\n      if (s[i] == DOTLESS_YEH)\n        s[i] = YEH;\n\n      if (s[i] == TEH_MARBUTA)\n        s[i] = HEH;\n\n      if (s[i] == TATWEEL || s[i] == KASRATAN || s[i] == DAMMATAN || s[i] == FATHATAN ||\n          s[i] == FATHA || s[i] == DAMMA || s[i] == KASRA || s[i] == SHADDA || s[i] == SUKUN) {\n        len = delete(s, i, len);\n        i--;\n      }\n    }\n\n    return len;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"dd745d580729e528151b58aeda87ef82f1b95c9b","date":1248369082,"type":5,"author":"Simon Willnauer","isMerge":false,"pathNew":"contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicNormalizer#normalize(char[],int).mjava","pathOld":"contrib/analyzers/src/java/org/apache/lucene/analysis/ar/ArabicNormalizer#normalize(char[],int).mjava","sourceNew":"  /**\n   * Normalize an input buffer of Arabic text\n   * \n   * @param s input buffer\n   * @param len length of input buffer\n   * @return length of input buffer after normalization\n   */\n  public int normalize(char s[], int len) {\n \n    for (int i = 0; i < len; i++) {\n      if (s[i] == ALEF_MADDA || s[i] == ALEF_HAMZA_ABOVE || s[i] == ALEF_HAMZA_BELOW)\n        s[i] = ALEF;\n\n      if (s[i] == DOTLESS_YEH)\n        s[i] = YEH;\n\n      if (s[i] == TEH_MARBUTA)\n        s[i] = HEH;\n\n      if (s[i] == TATWEEL || s[i] == KASRATAN || s[i] == DAMMATAN || s[i] == FATHATAN ||\n          s[i] == FATHA || s[i] == DAMMA || s[i] == KASRA || s[i] == SHADDA || s[i] == SUKUN) {\n        len = delete(s, i, len);\n        i--;\n      }\n    }\n\n    return len;\n  }\n\n","sourceOld":"  /**\n   * Normalize an input buffer of Arabic text\n   * \n   * @param s input buffer\n   * @param len length of input buffer\n   * @return length of input buffer after normalization\n   */\n  public int normalize(char s[], int len) {\n \n    for (int i = 0; i < len; i++) {\n      if (s[i] == ALEF_MADDA || s[i] == ALEF_HAMZA_ABOVE || s[i] == ALEF_HAMZA_BELOW)\n        s[i] = ALEF;\n\n      if (s[i] == DOTLESS_YEH)\n        s[i] = YEH;\n\n      if (s[i] == TEH_MARBUTA)\n        s[i] = HEH;\n\n      if (s[i] == TATWEEL || s[i] == KASRATAN || s[i] == DAMMATAN || s[i] == FATHATAN ||\n          s[i] == FATHA || s[i] == DAMMA || s[i] == KASRA || s[i] == SHADDA || s[i] == SUKUN) {\n        len = delete(s, i, len);\n        i--;\n      }\n    }\n\n    return len;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"dd745d580729e528151b58aeda87ef82f1b95c9b":["4507f887015ed704dfc72ce14e0b23ce086865e0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4507f887015ed704dfc72ce14e0b23ce086865e0":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["dd745d580729e528151b58aeda87ef82f1b95c9b"]},"commit2Childs":{"dd745d580729e528151b58aeda87ef82f1b95c9b":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4507f887015ed704dfc72ce14e0b23ce086865e0"],"4507f887015ed704dfc72ce14e0b23ce086865e0":["dd745d580729e528151b58aeda87ef82f1b95c9b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}