{"path":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new Collector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) throws IOException {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        public void setNextReader(AtomicReaderContext context)\n            throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer)\n            throws IOException {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD), false);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new Collector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) throws IOException {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        public void setNextReader(AtomicReaderContext context)\n            throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer)\n            throws IOException {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD), false);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f","date":1338430031,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new Collector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) throws IOException {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        public void setNextReader(AtomicReaderContext context)\n            throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer)\n            throws IOException {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD), false);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new Collector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) throws IOException {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        public void setNextReader(AtomicReaderContext context)\n            throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer)\n            throws IOException {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD), false);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"04f07771a2a7dd3a395700665ed839c3dae2def2","date":1339350139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new Collector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) throws IOException {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        public void setNextReader(AtomicReaderContext context)\n            throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer)\n            throws IOException {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD), false);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new Collector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) throws IOException {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        public void setNextReader(AtomicReaderContext context)\n            throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer)\n            throws IOException {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD), false);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4d3e8520fd031bab31fd0e4d480e55958bc45efe","date":1340901565,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new Collector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        public void setNextReader(AtomicReaderContext context) {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer) {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD), false);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new Collector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) throws IOException {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        public void setNextReader(AtomicReaderContext context)\n            throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer)\n            throws IOException {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD), false);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":["0e7c2454a6a8237bfd0e953f5b940838408c9055","fafd002a407d38098f1f0edf4365f971102ae0ef"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new Collector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        public void setNextReader(AtomicReaderContext context) {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer) {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD), false);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new Collector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) throws IOException {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        public void setNextReader(AtomicReaderContext context)\n            throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer)\n            throws IOException {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD), false);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae73da626f97850c922c42736f808d0378e165f0","date":1396625460,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new SimpleCollector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        protected void doSetNextReader(AtomicReaderContext context) throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer) {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD), false);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new Collector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        public void setNextReader(AtomicReaderContext context) {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer) {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD), false);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"15e323346eac5e4685c0a9f2df85eb96b4239bbb","date":1396688577,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new SimpleCollector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        protected void doSetNextReader(AtomicReaderContext context) throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer) {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD), false);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new Collector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        public void setNextReader(AtomicReaderContext context) {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer) {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD), false);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.shutdown();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new SimpleCollector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        protected void doSetNextReader(AtomicReaderContext context) throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer) {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD), false);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new SimpleCollector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        protected void doSetNextReader(AtomicReaderContext context) throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer) {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD), false);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.shutdown();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new SimpleCollector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        protected void doSetNextReader(AtomicReaderContext context) throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer) {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD), false);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.shutdown();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new SimpleCollector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        protected void doSetNextReader(AtomicReaderContext context) throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer) {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD), false);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new SimpleCollector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        protected void doSetNextReader(AtomicReaderContext context) throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer) {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD), false);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.shutdown();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new SimpleCollector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        protected void doSetNextReader(AtomicReaderContext context) throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer) {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD), false);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new SimpleCollector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        protected void doSetNextReader(LeafReaderContext context) throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer) {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD), false);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new SimpleCollector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        protected void doSetNextReader(AtomicReaderContext context) throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer) {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD), false);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0abcec02c9851c46c70a75bd42fb6e4d5348ac9e","date":1414135939,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new SimpleCollector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        protected void doSetNextReader(LeafReaderContext context) throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer) {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD), false);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new SimpleCollector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        protected void doSetNextReader(LeafReaderContext context) throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer) {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD), false);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"08a32c8b6fbb299bd14b2e45490c9554c794a85e","date":1417322051,"type":3,"author":"David Wayne Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new SimpleCollector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        protected void doSetNextReader(LeafReaderContext context) throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer) {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD));\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new SimpleCollector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        protected void doSetNextReader(LeafReaderContext context) throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer) {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD), false);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f582f18c13d4852b01d4fe0a0196432c5c6f2b7f","date":1421314520,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new SimpleCollector() {\n        private int baseDoc;\n\n        @Override\n        public void collect(int i) {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        protected void doSetNextReader(LeafReaderContext context) throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer) {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD));\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new SimpleCollector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        protected void doSetNextReader(LeafReaderContext context) throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer) {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD));\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"781239fc84d36be12b84e4d3e2618f5f07a182e3","date":1423139668,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new SimpleCollector() {\n        private int baseDoc;\n\n        @Override\n        public void collect(int i) {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        protected void doSetNextReader(LeafReaderContext context) throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer) {\n          // Do Nothing\n        }\n\n        @Override\n        public boolean needsScores() {\n          return false;\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD));\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new SimpleCollector() {\n        private int baseDoc;\n\n        @Override\n        public void collect(int i) {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        protected void doSetNextReader(LeafReaderContext context) throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer) {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD));\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5d62e4938659e263e96ae8188e11aea8a940aea5","date":1430230314,"type":3,"author":"David Wayne Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new SimpleCollector() {\n        private int baseDoc;\n\n        @Override\n        public void collect(int i) {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        protected void doSetNextReader(LeafReaderContext context) throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer) {\n          // Do Nothing\n        }\n\n        @Override\n        public boolean needsScores() {\n          return false;\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream =\n            TokenSources.getTermVectorTokenStreamOrNull(FIELD, indexReader.getTermVectors(position), -1);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new SimpleCollector() {\n        private int baseDoc;\n\n        @Override\n        public void collect(int i) {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        protected void doSetNextReader(LeafReaderContext context) throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer) {\n          // Do Nothing\n        }\n\n        @Override\n        public boolean needsScores() {\n          return false;\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD));\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9fc47cb7b4346802411bb432f501ed0673d7119e","date":1512640179,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new SimpleCollector() {\n        private int baseDoc;\n\n        @Override\n        public void collect(int i) {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        protected void doSetNextReader(LeafReaderContext context) throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer) {\n          // Do Nothing\n        }\n\n        @Override\n        public ScoreMode scoreMode() {\n          return ScoreMode.COMPLETE_NO_SCORES;\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream =\n            TokenSources.getTermVectorTokenStreamOrNull(FIELD, indexReader.getTermVectors(position), -1);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new SimpleCollector() {\n        private int baseDoc;\n\n        @Override\n        public void collect(int i) {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        protected void doSetNextReader(LeafReaderContext context) throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer) {\n          // Do Nothing\n        }\n\n        @Override\n        public boolean needsScores() {\n          return false;\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream =\n            TokenSources.getTermVectorTokenStreamOrNull(FIELD, indexReader.getTermVectors(position), -1);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"417142ff08fda9cf0b72d5133e63097a166c6458","date":1512729693,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new SimpleCollector() {\n        private int baseDoc;\n\n        @Override\n        public void collect(int i) {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        protected void doSetNextReader(LeafReaderContext context) throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer) {\n          // Do Nothing\n        }\n\n        @Override\n        public ScoreMode scoreMode() {\n          return ScoreMode.COMPLETE_NO_SCORES;\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream =\n            TokenSources.getTermVectorTokenStreamOrNull(FIELD, indexReader.getTermVectors(position), -1);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new SimpleCollector() {\n        private int baseDoc;\n\n        @Override\n        public void collect(int i) {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        protected void doSetNextReader(LeafReaderContext context) throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer) {\n          // Do Nothing\n        }\n\n        @Override\n        public boolean needsScores() {\n          return false;\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream =\n            TokenSources.getTermVectorTokenStreamOrNull(FIELD, indexReader.getTermVectors(position), -1);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"285244982ce6aa163d1e60a707f0e6e121736ce5","date":1536055304,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new SimpleCollector() {\n        private int baseDoc;\n\n        @Override\n        public void collect(int i) {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        protected void doSetNextReader(LeafReaderContext context) throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(Scorable scorer) {\n          // Do Nothing\n        }\n\n        @Override\n        public ScoreMode scoreMode() {\n          return ScoreMode.COMPLETE_NO_SCORES;\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream =\n            TokenSources.getTermVectorTokenStreamOrNull(FIELD, indexReader.getTermVectors(position), -1);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = DirectoryReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new SimpleCollector() {\n        private int baseDoc;\n\n        @Override\n        public void collect(int i) {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        protected void doSetNextReader(LeafReaderContext context) throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer) {\n          // Do Nothing\n        }\n\n        @Override\n        public ScoreMode scoreMode() {\n          return ScoreMode.COMPLETE_NO_SCORES;\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream =\n            TokenSources.getTermVectorTokenStreamOrNull(FIELD, indexReader.getTermVectors(position), -1);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"08a32c8b6fbb299bd14b2e45490c9554c794a85e":["0abcec02c9851c46c70a75bd42fb6e4d5348ac9e"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"781239fc84d36be12b84e4d3e2618f5f07a182e3":["f582f18c13d4852b01d4fe0a0196432c5c6f2b7f"],"5d62e4938659e263e96ae8188e11aea8a940aea5":["781239fc84d36be12b84e4d3e2618f5f07a182e3"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"417142ff08fda9cf0b72d5133e63097a166c6458":["5d62e4938659e263e96ae8188e11aea8a940aea5","9fc47cb7b4346802411bb432f501ed0673d7119e"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"285244982ce6aa163d1e60a707f0e6e121736ce5":["417142ff08fda9cf0b72d5133e63097a166c6458"],"f582f18c13d4852b01d4fe0a0196432c5c6f2b7f":["08a32c8b6fbb299bd14b2e45490c9554c794a85e"],"15e323346eac5e4685c0a9f2df85eb96b4239bbb":["4d3e8520fd031bab31fd0e4d480e55958bc45efe","ae73da626f97850c922c42736f808d0378e165f0"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["04f07771a2a7dd3a395700665ed839c3dae2def2","4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ae73da626f97850c922c42736f808d0378e165f0":["4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["ae73da626f97850c922c42736f808d0378e165f0"],"4d3e8520fd031bab31fd0e4d480e55958bc45efe":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"9fc47cb7b4346802411bb432f501ed0673d7119e":["5d62e4938659e263e96ae8188e11aea8a940aea5"],"0abcec02c9851c46c70a75bd42fb6e4d5348ac9e":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["285244982ce6aa163d1e60a707f0e6e121736ce5"]},"commit2Childs":{"08a32c8b6fbb299bd14b2e45490c9554c794a85e":["f582f18c13d4852b01d4fe0a0196432c5c6f2b7f"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"781239fc84d36be12b84e4d3e2618f5f07a182e3":["5d62e4938659e263e96ae8188e11aea8a940aea5"],"5d62e4938659e263e96ae8188e11aea8a940aea5":["417142ff08fda9cf0b72d5133e63097a166c6458","9fc47cb7b4346802411bb432f501ed0673d7119e"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["0abcec02c9851c46c70a75bd42fb6e4d5348ac9e"],"417142ff08fda9cf0b72d5133e63097a166c6458":["285244982ce6aa163d1e60a707f0e6e121736ce5"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["fe33227f6805edab2036cbb80645cc4e2d1fa424","4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"f582f18c13d4852b01d4fe0a0196432c5c6f2b7f":["781239fc84d36be12b84e4d3e2618f5f07a182e3"],"285244982ce6aa163d1e60a707f0e6e121736ce5":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"15e323346eac5e4685c0a9f2df85eb96b4239bbb":[],"fe33227f6805edab2036cbb80645cc4e2d1fa424":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"ae73da626f97850c922c42736f808d0378e165f0":["15e323346eac5e4685c0a9f2df85eb96b4239bbb","ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"9fc47cb7b4346802411bb432f501ed0673d7119e":["417142ff08fda9cf0b72d5133e63097a166c6458"],"4d3e8520fd031bab31fd0e4d480e55958bc45efe":["15e323346eac5e4685c0a9f2df85eb96b4239bbb","fe33227f6805edab2036cbb80645cc4e2d1fa424","ae73da626f97850c922c42736f808d0378e165f0"],"0abcec02c9851c46c70a75bd42fb6e4d5348ac9e":["08a32c8b6fbb299bd14b2e45490c9554c794a85e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["15e323346eac5e4685c0a9f2df85eb96b4239bbb","fe33227f6805edab2036cbb80645cc4e2d1fa424","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}