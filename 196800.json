{"path":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int).mjava","pathOld":"src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int).mjava","sourceNew":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n\n    if (!readOnly) {\n      // We assume that this segments_N was previously\n      // properly sync'd:\n      synced.addAll(sis.files(directory, true));\n    }\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor);\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","sourceOld":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n\n    if (!readOnly) {\n      // We assume that this segments_N was previously\n      // properly sync'd:\n      synced.addAll(sis.files(directory, true));\n    }\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor);\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e4b4e97a5e8ab5b96cc56c561131d720c756756b","date":1269362401,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int).mjava","sourceNew":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor);\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","sourceOld":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n\n    if (!readOnly) {\n      // We assume that this segments_N was previously\n      // properly sync'd:\n      synced.addAll(sis.files(directory, true));\n    }\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor);\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"955c32f886db6f6356c9fcdea6b1f1cb4effda24","date":1270581567,"type":4,"author":"Uwe Schindler","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int).mjava","sourceNew":null,"sourceOld":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor);\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7b91922b55d15444d554721b352861d028eb8278","date":1320421415,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int,CodecProvider).mjava","sourceNew":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    readerFinishedListeners = new MapBackedSet<ReaderFinishedListener>(new ConcurrentHashMap<ReaderFinishedListener,Boolean>());\n    applyAllDeletes = false;\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor, IOContext.READ);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","sourceOld":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor, CodecProvider codecs) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = new MapBackedSet<ReaderFinishedListener>(new ConcurrentHashMap<ReaderFinishedListener,Boolean>());\n    applyAllDeletes = false;\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor, IOContext.READ);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e1f693ce507c40f77e3a92acd16c6b79cdd730e4","date":1323036169,"type":5,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,boolean,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int).mjava","sourceNew":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, boolean readOnly, int termInfosIndexDivisor) throws IOException {\n    this.directory = directory;\n    this.readOnly = true; // nocommit: remove readOnly at all\n    this.segmentInfos = sis;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    readerFinishedListeners = new MapBackedSet<ReaderFinishedListener>(new ConcurrentHashMap<ReaderFinishedListener,Boolean>());\n    applyAllDeletes = false;\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor, IOContext.READ);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","sourceOld":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    readerFinishedListeners = new MapBackedSet<ReaderFinishedListener>(new ConcurrentHashMap<ReaderFinishedListener,Boolean>());\n    applyAllDeletes = false;\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor, IOContext.READ);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3615ce4a1f785ae1b779244de52c6a7d99227e60","date":1323422019,"type":5,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int).mjava","sourceNew":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, int termInfosIndexDivisor) throws IOException {\n    this.directory = directory;\n    this.segmentInfos = sis;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    readerFinishedListeners = new MapBackedSet<ReaderFinishedListener>(new ConcurrentHashMap<ReaderFinishedListener,Boolean>());\n    applyAllDeletes = false;\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(sis.info(i), termInfosIndexDivisor, IOContext.READ);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","sourceOld":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    readerFinishedListeners = new MapBackedSet<ReaderFinishedListener>(new ConcurrentHashMap<ReaderFinishedListener,Boolean>());\n    applyAllDeletes = false;\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor, IOContext.READ);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","date":1323437438,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int).mjava","sourceNew":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, int termInfosIndexDivisor) throws IOException {\n    this.directory = directory;\n    this.segmentInfos = sis;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    readerFinishedListeners = new MapBackedSet<ReaderFinishedListener>(new ConcurrentHashMap<ReaderFinishedListener,Boolean>());\n    applyAllDeletes = false;\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(sis.info(i), termInfosIndexDivisor, IOContext.READ);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","sourceOld":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    readerFinishedListeners = new MapBackedSet<ReaderFinishedListener>(new ConcurrentHashMap<ReaderFinishedListener,Boolean>());\n    applyAllDeletes = false;\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor, IOContext.READ);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7b91922b55d15444d554721b352861d028eb8278":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"e1f693ce507c40f77e3a92acd16c6b79cdd730e4":["7b91922b55d15444d554721b352861d028eb8278"],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":["7b91922b55d15444d554721b352861d028eb8278","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["e4b4e97a5e8ab5b96cc56c561131d720c756756b"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["7b91922b55d15444d554721b352861d028eb8278","e1f693ce507c40f77e3a92acd16c6b79cdd730e4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"e4b4e97a5e8ab5b96cc56c561131d720c756756b":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"7b91922b55d15444d554721b352861d028eb8278":["e1f693ce507c40f77e3a92acd16c6b79cdd730e4","ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"e1f693ce507c40f77e3a92acd16c6b79cdd730e4":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["7b91922b55d15444d554721b352861d028eb8278"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"e4b4e97a5e8ab5b96cc56c561131d720c756756b":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["e4b4e97a5e8ab5b96cc56c561131d720c756756b"]},"heads":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}