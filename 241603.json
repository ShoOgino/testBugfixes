{"path":"lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testParallelExhausted().mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testParallelExhausted().mjava","pathOld":"modules/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testParallelExhausted().mjava","sourceNew":"  /**\n   * Test that \" {[AddDoc(4000)]: 4} : * \" works corrcetly (for LUCENE-941)\n   */\n  public void testParallelExhausted() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"task.max.depth.log=1\",\n        \"# ----- alg \",\n        \"CreateIndex\",\n        \"{ [ AddDoc]: 4} : * \",\n        \"ResetInputs \",\n        \"{ [ AddDoc]: 4} : * \",\n        \"WaitForMerges\",\n        \"CloseIndex\",\n    };\n    \n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n\n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory());\n    int ndocsExpected = 2 * 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that \" {[AddDoc(4000)]: 4} : * \" works corrcetly (for LUCENE-941)\n   */\n  public void testParallelExhausted() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"task.max.depth.log=1\",\n        \"# ----- alg \",\n        \"CreateIndex\",\n        \"{ [ AddDoc]: 4} : * \",\n        \"ResetInputs \",\n        \"{ [ AddDoc]: 4} : * \",\n        \"WaitForMerges\",\n        \"CloseIndex\",\n    };\n    \n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n\n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory());\n    int ndocsExpected = 2 * 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f","date":1338430031,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testParallelExhausted().mjava","pathOld":"lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testParallelExhausted().mjava","sourceNew":"  /**\n   * Test that \" {[AddDoc(4000)]: 4} : * \" works corrcetly (for LUCENE-941)\n   */\n  public void testParallelExhausted() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"task.max.depth.log=1\",\n        \"# ----- alg \",\n        \"CreateIndex\",\n        \"{ [ AddDoc]: 4} : * \",\n        \"ResetInputs \",\n        \"{ [ AddDoc]: 4} : * \",\n        \"WaitForMerges\",\n        \"CloseIndex\",\n    };\n    \n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n\n    // 3. test number of docs in the index\n    IndexReader ir = DirectoryReader.open(benchmark.getRunData().getDirectory());\n    int ndocsExpected = 2 * 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that \" {[AddDoc(4000)]: 4} : * \" works corrcetly (for LUCENE-941)\n   */\n  public void testParallelExhausted() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"task.max.depth.log=1\",\n        \"# ----- alg \",\n        \"CreateIndex\",\n        \"{ [ AddDoc]: 4} : * \",\n        \"ResetInputs \",\n        \"{ [ AddDoc]: 4} : * \",\n        \"WaitForMerges\",\n        \"CloseIndex\",\n    };\n    \n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n\n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory());\n    int ndocsExpected = 2 * 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"19275ba31e621f6da1b83bf13af75233876fd3d4","date":1374846698,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testParallelExhausted().mjava","pathOld":"lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testParallelExhausted().mjava","sourceNew":"  /**\n   * Test that \" {[AddDoc(4000)]: 4} : * \" works corrcetly (for LUCENE-941)\n   */\n  public void testParallelExhausted() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"task.max.depth.log=1\",\n        \"# ----- alg \",\n        \"CreateIndex\",\n        \"{ [ AddDoc]: 4} : * \",\n        \"ResetInputs \",\n        \"{ [ AddDoc]: 4} : * \",\n        \"WaitForMerges\",\n        \"CloseIndex\",\n    };\n    \n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n\n    // 3. test number of docs in the index\n    IndexReader ir = DirectoryReader.open(benchmark.getRunData().getDirectory());\n    int ndocsExpected = 2 * 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that \" {[AddDoc(4000)]: 4} : * \" works corrcetly (for LUCENE-941)\n   */\n  public void testParallelExhausted() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"task.max.depth.log=1\",\n        \"# ----- alg \",\n        \"CreateIndex\",\n        \"{ [ AddDoc]: 4} : * \",\n        \"ResetInputs \",\n        \"{ [ AddDoc]: 4} : * \",\n        \"WaitForMerges\",\n        \"CloseIndex\",\n    };\n    \n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n\n    // 3. test number of docs in the index\n    IndexReader ir = DirectoryReader.open(benchmark.getRunData().getDirectory());\n    int ndocsExpected = 2 * 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testParallelExhausted().mjava","pathOld":"lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testParallelExhausted().mjava","sourceNew":"  /**\n   * Test that \" {[AddDoc(4000)]: 4} : * \" works corrcetly (for LUCENE-941)\n   */\n  public void testParallelExhausted() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"task.max.depth.log=1\",\n        \"# ----- alg \",\n        \"CreateIndex\",\n        \"{ [ AddDoc]: 4} : * \",\n        \"ResetInputs \",\n        \"{ [ AddDoc]: 4} : * \",\n        \"WaitForMerges\",\n        \"CloseIndex\",\n    };\n    \n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n\n    // 3. test number of docs in the index\n    IndexReader ir = DirectoryReader.open(benchmark.getRunData().getDirectory());\n    int ndocsExpected = 2 * 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that \" {[AddDoc(4000)]: 4} : * \" works corrcetly (for LUCENE-941)\n   */\n  public void testParallelExhausted() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"task.max.depth.log=1\",\n        \"# ----- alg \",\n        \"CreateIndex\",\n        \"{ [ AddDoc]: 4} : * \",\n        \"ResetInputs \",\n        \"{ [ AddDoc]: 4} : * \",\n        \"WaitForMerges\",\n        \"CloseIndex\",\n    };\n    \n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n\n    // 3. test number of docs in the index\n    IndexReader ir = DirectoryReader.open(benchmark.getRunData().getDirectory());\n    int ndocsExpected = 2 * 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"15fbe8579d34349a8c79cbc5c933530dd5b6742a","date":1418066328,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testParallelExhausted().mjava","pathOld":"lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testParallelExhausted().mjava","sourceNew":"  /**\n   * Test that \" {[AddDoc(4000)]: 4} : * \" works corrcetly (for LUCENE-941)\n   */\n  public void testParallelExhausted() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"task.max.depth.log=1\",\n        \"# ----- alg \",\n        \"CreateIndex\",\n        \"{ [ AddDoc]: 4} : * \",\n        \"ResetInputs \",\n        \"{ [ AddDoc]: 4} : * \",\n        \"CloseIndex\",\n    };\n    \n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n\n    // 3. test number of docs in the index\n    IndexReader ir = DirectoryReader.open(benchmark.getRunData().getDirectory());\n    int ndocsExpected = 2 * 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that \" {[AddDoc(4000)]: 4} : * \" works corrcetly (for LUCENE-941)\n   */\n  public void testParallelExhausted() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"task.max.depth.log=1\",\n        \"# ----- alg \",\n        \"CreateIndex\",\n        \"{ [ AddDoc]: 4} : * \",\n        \"ResetInputs \",\n        \"{ [ AddDoc]: 4} : * \",\n        \"WaitForMerges\",\n        \"CloseIndex\",\n    };\n    \n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n\n    // 3. test number of docs in the index\n    IndexReader ir = DirectoryReader.open(benchmark.getRunData().getDirectory());\n    int ndocsExpected = 2 * 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","bugFix":["18bef4a19690afd674183385b5bf3c27bba9274b"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d77dafd89756a5161d244985903e3487ca109182","date":1548679743,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testParallelExhausted().mjava","pathOld":"lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testParallelExhausted().mjava","sourceNew":"  /**\n   * Test that \" {[AddDoc(4000)]: 4} : * \" works corrcetly (for LUCENE-941)\n   */\n  public void testParallelExhausted() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=ByteBuffersDirectory\",\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"task.max.depth.log=1\",\n        \"# ----- alg \",\n        \"CreateIndex\",\n        \"{ [ AddDoc]: 4} : * \",\n        \"ResetInputs \",\n        \"{ [ AddDoc]: 4} : * \",\n        \"CloseIndex\",\n    };\n    \n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n\n    // 3. test number of docs in the index\n    IndexReader ir = DirectoryReader.open(benchmark.getRunData().getDirectory());\n    int ndocsExpected = 2 * 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that \" {[AddDoc(4000)]: 4} : * \" works corrcetly (for LUCENE-941)\n   */\n  public void testParallelExhausted() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"task.max.depth.log=1\",\n        \"# ----- alg \",\n        \"CreateIndex\",\n        \"{ [ AddDoc]: 4} : * \",\n        \"ResetInputs \",\n        \"{ [ AddDoc]: 4} : * \",\n        \"CloseIndex\",\n    };\n    \n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n\n    // 3. test number of docs in the index\n    IndexReader ir = DirectoryReader.open(benchmark.getRunData().getDirectory());\n    int ndocsExpected = 2 * 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"d77dafd89756a5161d244985903e3487ca109182":["15fbe8579d34349a8c79cbc5c933530dd5b6742a"],"19275ba31e621f6da1b83bf13af75233876fd3d4":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"15fbe8579d34349a8c79cbc5c933530dd5b6742a":["19275ba31e621f6da1b83bf13af75233876fd3d4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d77dafd89756a5161d244985903e3487ca109182"]},"commit2Childs":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","19275ba31e621f6da1b83bf13af75233876fd3d4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"d77dafd89756a5161d244985903e3487ca109182":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"19275ba31e621f6da1b83bf13af75233876fd3d4":["15fbe8579d34349a8c79cbc5c933530dd5b6742a"],"15fbe8579d34349a8c79cbc5c933530dd5b6742a":["d77dafd89756a5161d244985903e3487ca109182"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}