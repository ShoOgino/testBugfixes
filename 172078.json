{"path":"lucene/core/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader().maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","sourceOld":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader().maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d08eba3d52b63561ebf936481ce73e6b6a14aa03","date":1333879759,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final InvertedFields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader().maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","sourceOld":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader().maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf","date":1333892281,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader().maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","sourceOld":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final InvertedFields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader().maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"02331260bb246364779cb6f04919ca47900d01bb","date":1343749884,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader().maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, 0);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","sourceOld":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader().maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","bugFix":["872cff1d3a554e0cd64014cd97f88d3002b0f491"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","date":1343768312,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader().maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, 0);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","sourceOld":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader().maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader().maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, 0);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","sourceOld":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader().maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"15250ca94ba8ab3bcdd476daf6bf3f3febb92640","date":1355200097,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader().maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, DocsEnum.FLAG_NONE);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","sourceOld":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader().maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, 0);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader().maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, DocsEnum.FLAG_NONE);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","sourceOld":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader().maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, 0);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"dc06632ede7e48a5ddc6917badec25c8336feedc","date":1366983006,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return null;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return null;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader().maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, DocsEnum.FLAG_NONE);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader().maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, DocsEnum.FLAG_NONE);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return DocIdSet.EMPTY_DOCIDSET;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0cf15d89c400585df630cb62449fb4d6cb58434f","date":1397643074,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return null;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return null;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader().maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        rewriteTermCount++;\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, DocsEnum.FLAG_NONE);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return null;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return null;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader().maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, DocsEnum.FLAG_NONE);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"158bf4b301557fdddcd1f665fa0700b7f19678d0","date":1397643258,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return null;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return null;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader().maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, DocsEnum.FLAG_NONE);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return null;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return null;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader().maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        rewriteTermCount++;\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, DocsEnum.FLAG_NONE);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":4,"author":"Ryan Ernst","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/search/MultiTermQueryWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":null,"sourceOld":"  /**\n   * Returns a DocIdSet with documents that should be permitted in search\n   * results.\n   */\n  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    final Fields fields = reader.fields();\n    if (fields == null) {\n      // reader has no fields\n      return null;\n    }\n\n    final Terms terms = fields.terms(query.field);\n    if (terms == null) {\n      // field does not exist\n      return null;\n    }\n\n    final TermsEnum termsEnum = query.getTermsEnum(terms);\n    assert termsEnum != null;\n    if (termsEnum.next() != null) {\n      // fill into a FixedBitSet\n      final FixedBitSet bitSet = new FixedBitSet(context.reader().maxDoc());\n      DocsEnum docsEnum = null;\n      do {\n        // System.out.println(\"  iter termCount=\" + termCount + \" term=\" +\n        // enumerator.term().toBytesString());\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, DocsEnum.FLAG_NONE);\n        int docid;\n        while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          bitSet.set(docid);\n        }\n      } while (termsEnum.next() != null);\n      // System.out.println(\"  done termCount=\" + termCount);\n\n      return bitSet;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"dc06632ede7e48a5ddc6917badec25c8336feedc":["15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["02331260bb246364779cb6f04919ca47900d01bb","15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"158bf4b301557fdddcd1f665fa0700b7f19678d0":["0cf15d89c400585df630cb62449fb4d6cb58434f"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"d08eba3d52b63561ebf936481ce73e6b6a14aa03":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["158bf4b301557fdddcd1f665fa0700b7f19678d0"],"0cf15d89c400585df630cb62449fb4d6cb58434f":["dc06632ede7e48a5ddc6917badec25c8336feedc"],"15250ca94ba8ab3bcdd476daf6bf3f3febb92640":["02331260bb246364779cb6f04919ca47900d01bb"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf","02331260bb246364779cb6f04919ca47900d01bb"],"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf":["d08eba3d52b63561ebf936481ce73e6b6a14aa03"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf","02331260bb246364779cb6f04919ca47900d01bb"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"02331260bb246364779cb6f04919ca47900d01bb":["e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf"]},"commit2Childs":{"dc06632ede7e48a5ddc6917badec25c8336feedc":["0cf15d89c400585df630cb62449fb4d6cb58434f"],"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"158bf4b301557fdddcd1f665fa0700b7f19678d0":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["d08eba3d52b63561ebf936481ce73e6b6a14aa03"],"d08eba3d52b63561ebf936481ce73e6b6a14aa03":["e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"0cf15d89c400585df630cb62449fb4d6cb58434f":["158bf4b301557fdddcd1f665fa0700b7f19678d0"],"15250ca94ba8ab3bcdd476daf6bf3f3febb92640":["dc06632ede7e48a5ddc6917badec25c8336feedc","d3fcb70cf561547c7bb1506e0cf32ca7b1287064"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":[],"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b","02331260bb246364779cb6f04919ca47900d01bb"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":[],"02331260bb246364779cb6f04919ca47900d01bb":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","15250ca94ba8ab3bcdd476daf6bf3f3febb92640","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}