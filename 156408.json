{"path":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/FuzzyCompletionQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","commits":[{"id":"9fc47cb7b4346802411bb432f501ed0673d7119e","date":1512640179,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/FuzzyCompletionQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/FuzzyCompletionQuery#createWeight(IndexSearcher,boolean,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    CompletionTokenStream stream = (CompletionTokenStream) analyzer.tokenStream(getField(), getTerm().text());\n    Set<IntsRef> refs = new HashSet<>();\n    Automaton automaton = toLevenshteinAutomata(stream.toAutomaton(unicodeAware), refs);\n    if (unicodeAware) {\n      Automaton utf8automaton = new UTF32ToUTF8().convert(automaton);\n      utf8automaton = Operations.determinize(utf8automaton, maxDeterminizedStates);\n      automaton = utf8automaton;\n    }\n    // TODO Accumulating all refs is bad, because the resulting set may be very big.\n    // TODO Better iterate over automaton again inside FuzzyCompletionWeight?\n    return new FuzzyCompletionWeight(this, automaton, refs);\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores, float boost) throws IOException {\n    CompletionTokenStream stream = (CompletionTokenStream) analyzer.tokenStream(getField(), getTerm().text());\n    Set<IntsRef> refs = new HashSet<>();\n    Automaton automaton = toLevenshteinAutomata(stream.toAutomaton(unicodeAware), refs);\n    if (unicodeAware) {\n      Automaton utf8automaton = new UTF32ToUTF8().convert(automaton);\n      utf8automaton = Operations.determinize(utf8automaton, maxDeterminizedStates);\n      automaton = utf8automaton;\n    }\n    // TODO Accumulating all refs is bad, because the resulting set may be very big.\n    // TODO Better iterate over automaton again inside FuzzyCompletionWeight?\n    return new FuzzyCompletionWeight(this, automaton, refs);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"417142ff08fda9cf0b72d5133e63097a166c6458","date":1512729693,"type":1,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/FuzzyCompletionQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/FuzzyCompletionQuery#createWeight(IndexSearcher,boolean,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    CompletionTokenStream stream = (CompletionTokenStream) analyzer.tokenStream(getField(), getTerm().text());\n    Set<IntsRef> refs = new HashSet<>();\n    Automaton automaton = toLevenshteinAutomata(stream.toAutomaton(unicodeAware), refs);\n    if (unicodeAware) {\n      Automaton utf8automaton = new UTF32ToUTF8().convert(automaton);\n      utf8automaton = Operations.determinize(utf8automaton, maxDeterminizedStates);\n      automaton = utf8automaton;\n    }\n    // TODO Accumulating all refs is bad, because the resulting set may be very big.\n    // TODO Better iterate over automaton again inside FuzzyCompletionWeight?\n    return new FuzzyCompletionWeight(this, automaton, refs);\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores, float boost) throws IOException {\n    CompletionTokenStream stream = (CompletionTokenStream) analyzer.tokenStream(getField(), getTerm().text());\n    Set<IntsRef> refs = new HashSet<>();\n    Automaton automaton = toLevenshteinAutomata(stream.toAutomaton(unicodeAware), refs);\n    if (unicodeAware) {\n      Automaton utf8automaton = new UTF32ToUTF8().convert(automaton);\n      utf8automaton = Operations.determinize(utf8automaton, maxDeterminizedStates);\n      automaton = utf8automaton;\n    }\n    // TODO Accumulating all refs is bad, because the resulting set may be very big.\n    // TODO Better iterate over automaton again inside FuzzyCompletionWeight?\n    return new FuzzyCompletionWeight(this, automaton, refs);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a","date":1528168051,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/FuzzyCompletionQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/FuzzyCompletionQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    final Automaton originalAutomata;\n    try (CompletionTokenStream stream = (CompletionTokenStream) analyzer.tokenStream(getField(), getTerm().text()) ) {\n      originalAutomata = stream.toAutomaton(unicodeAware);\n    }\n    Set<IntsRef> refs = new HashSet<>();\n    Automaton automaton = toLevenshteinAutomata(originalAutomata, refs);\n    if (unicodeAware) {\n      Automaton utf8automaton = new UTF32ToUTF8().convert(automaton);\n      utf8automaton = Operations.determinize(utf8automaton, maxDeterminizedStates);\n      automaton = utf8automaton;\n    }\n    // TODO Accumulating all refs is bad, because the resulting set may be very big.\n    // TODO Better iterate over automaton again inside FuzzyCompletionWeight?\n    return new FuzzyCompletionWeight(this, automaton, refs);\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    CompletionTokenStream stream = (CompletionTokenStream) analyzer.tokenStream(getField(), getTerm().text());\n    Set<IntsRef> refs = new HashSet<>();\n    Automaton automaton = toLevenshteinAutomata(stream.toAutomaton(unicodeAware), refs);\n    if (unicodeAware) {\n      Automaton utf8automaton = new UTF32ToUTF8().convert(automaton);\n      utf8automaton = Operations.determinize(utf8automaton, maxDeterminizedStates);\n      automaton = utf8automaton;\n    }\n    // TODO Accumulating all refs is bad, because the resulting set may be very big.\n    // TODO Better iterate over automaton again inside FuzzyCompletionWeight?\n    return new FuzzyCompletionWeight(this, automaton, refs);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f592209545c71895260367152601e9200399776d","date":1528238935,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/FuzzyCompletionQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/FuzzyCompletionQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    final Automaton originalAutomata;\n    try (CompletionTokenStream stream = (CompletionTokenStream) analyzer.tokenStream(getField(), getTerm().text()) ) {\n      originalAutomata = stream.toAutomaton(unicodeAware);\n    }\n    Set<IntsRef> refs = new HashSet<>();\n    Automaton automaton = toLevenshteinAutomata(originalAutomata, refs);\n    if (unicodeAware) {\n      Automaton utf8automaton = new UTF32ToUTF8().convert(automaton);\n      utf8automaton = Operations.determinize(utf8automaton, maxDeterminizedStates);\n      automaton = utf8automaton;\n    }\n    // TODO Accumulating all refs is bad, because the resulting set may be very big.\n    // TODO Better iterate over automaton again inside FuzzyCompletionWeight?\n    return new FuzzyCompletionWeight(this, automaton, refs);\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    CompletionTokenStream stream = (CompletionTokenStream) analyzer.tokenStream(getField(), getTerm().text());\n    Set<IntsRef> refs = new HashSet<>();\n    Automaton automaton = toLevenshteinAutomata(stream.toAutomaton(unicodeAware), refs);\n    if (unicodeAware) {\n      Automaton utf8automaton = new UTF32ToUTF8().convert(automaton);\n      utf8automaton = Operations.determinize(utf8automaton, maxDeterminizedStates);\n      automaton = utf8automaton;\n    }\n    // TODO Accumulating all refs is bad, because the resulting set may be very big.\n    // TODO Better iterate over automaton again inside FuzzyCompletionWeight?\n    return new FuzzyCompletionWeight(this, automaton, refs);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b70042a8a492f7054d480ccdd2be9796510d4327","date":1528386658,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/FuzzyCompletionQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/FuzzyCompletionQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    final Automaton originalAutomata;\n    try (CompletionTokenStream stream = (CompletionTokenStream) analyzer.tokenStream(getField(), getTerm().text()) ) {\n      originalAutomata = stream.toAutomaton(unicodeAware);\n    }\n    Set<IntsRef> refs = new HashSet<>();\n    Automaton automaton = toLevenshteinAutomata(originalAutomata, refs);\n    if (unicodeAware) {\n      Automaton utf8automaton = new UTF32ToUTF8().convert(automaton);\n      utf8automaton = Operations.determinize(utf8automaton, maxDeterminizedStates);\n      automaton = utf8automaton;\n    }\n    // TODO Accumulating all refs is bad, because the resulting set may be very big.\n    // TODO Better iterate over automaton again inside FuzzyCompletionWeight?\n    return new FuzzyCompletionWeight(this, automaton, refs);\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    CompletionTokenStream stream = (CompletionTokenStream) analyzer.tokenStream(getField(), getTerm().text());\n    Set<IntsRef> refs = new HashSet<>();\n    Automaton automaton = toLevenshteinAutomata(stream.toAutomaton(unicodeAware), refs);\n    if (unicodeAware) {\n      Automaton utf8automaton = new UTF32ToUTF8().convert(automaton);\n      utf8automaton = Operations.determinize(utf8automaton, maxDeterminizedStates);\n      automaton = utf8automaton;\n    }\n    // TODO Accumulating all refs is bad, because the resulting set may be very big.\n    // TODO Better iterate over automaton again inside FuzzyCompletionWeight?\n    return new FuzzyCompletionWeight(this, automaton, refs);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b70042a8a492f7054d480ccdd2be9796510d4327":["417142ff08fda9cf0b72d5133e63097a166c6458","9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a"],"9fc47cb7b4346802411bb432f501ed0673d7119e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a":["417142ff08fda9cf0b72d5133e63097a166c6458"],"f592209545c71895260367152601e9200399776d":["417142ff08fda9cf0b72d5133e63097a166c6458","9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a"],"417142ff08fda9cf0b72d5133e63097a166c6458":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","9fc47cb7b4346802411bb432f501ed0673d7119e"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9fc47cb7b4346802411bb432f501ed0673d7119e","417142ff08fda9cf0b72d5133e63097a166c6458"],"b70042a8a492f7054d480ccdd2be9796510d4327":[],"9fc47cb7b4346802411bb432f501ed0673d7119e":["417142ff08fda9cf0b72d5133e63097a166c6458"],"9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a":["b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f592209545c71895260367152601e9200399776d":[],"417142ff08fda9cf0b72d5133e63097a166c6458":["b70042a8a492f7054d480ccdd2be9796510d4327","9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a","f592209545c71895260367152601e9200399776d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}