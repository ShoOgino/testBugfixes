{"path":"lucene/backward-codecs/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testDocValuesUpdatesWithNewField().mjava","commits":[{"id":"9135dfa8824df4c6f7619bd2ac9507d821c61239","date":1544123763,"type":0,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testDocValuesUpdatesWithNewField().mjava","pathOld":"/dev/null","sourceNew":"  public void testDocValuesUpdatesWithNewField() throws Exception {\n    Path oldIndexDir = createTempDir(\"dvupdates\");\n    TestUtil.unzip(getDataInputStream(dvUpdatesIndex), oldIndexDir);\n    Directory dir = newFSDirectory(oldIndexDir);\n    verifyUsesDefaultCodec(dir, dvUpdatesIndex);\n\n    // update fields and verify index\n    IndexWriterConfig conf = new IndexWriterConfig(new MockAnalyzer(random()));\n    IndexWriter writer = new IndexWriter(dir, conf);\n    // introduce a new field that we later update\n    writer.addDocument(Arrays.asList(new StringField(\"id\", \"\" + Integer.MAX_VALUE, Field.Store.NO),\n        new NumericDocValuesField(\"new_numeric\", 1),\n        new BinaryDocValuesField(\"new_binary\", toBytes(1))));\n    writer.updateNumericDocValue(new Term(\"id\", \"1\"), \"new_numeric\", 1);\n    writer.updateBinaryDocValue(new Term(\"id\", \"1\"), \"new_binary\", toBytes(1));\n\n    writer.commit();\n    Runnable assertDV = () -> {\n      boolean found = false;\n      try (DirectoryReader reader = DirectoryReader.open(dir)) {\n        for (LeafReaderContext ctx : reader.leaves()) {\n          LeafReader leafReader = ctx.reader();\n          TermsEnum id = leafReader.terms(\"id\").iterator();\n          if (id.seekExact(new BytesRef(\"1\"))) {\n            PostingsEnum postings = id.postings(null, PostingsEnum.NONE);\n            NumericDocValues numericDocValues = leafReader.getNumericDocValues(\"new_numeric\");\n            BinaryDocValues binaryDocValues = leafReader.getBinaryDocValues(\"new_binary\");\n            int doc;\n            while ((doc = postings.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n              found = true;\n              assertTrue(binaryDocValues.advanceExact(doc));\n              assertTrue(numericDocValues.advanceExact(doc));\n              assertEquals(1, numericDocValues.longValue());\n              assertEquals(toBytes(1), binaryDocValues.binaryValue());\n            }\n          }\n        }\n      } catch (IOException e) {\n        throw new AssertionError(e);\n      }\n      assertTrue(found);\n    };\n    assertDV.run();\n    // merge all segments\n    writer.forceMerge(1);\n    writer.commit();\n    assertDV.run();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d722b735bc69d2234e957cb69cf96ad28ea7e1c3","date":1546867201,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testDocValuesUpdatesWithNewField().mjava","pathOld":"lucene/backward-codecs/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testDocValuesUpdatesWithNewField().mjava","sourceNew":"  public void testDocValuesUpdatesWithNewField() throws Exception {\n    assumeTrue(\"Reenable when 8.0 is released\", false);\n    Path oldIndexDir = createTempDir(\"dvupdates\");\n    TestUtil.unzip(getDataInputStream(dvUpdatesIndex), oldIndexDir);\n    Directory dir = newFSDirectory(oldIndexDir);\n    verifyUsesDefaultCodec(dir, dvUpdatesIndex);\n\n    // update fields and verify index\n    IndexWriterConfig conf = new IndexWriterConfig(new MockAnalyzer(random()));\n    IndexWriter writer = new IndexWriter(dir, conf);\n    // introduce a new field that we later update\n    writer.addDocument(Arrays.asList(new StringField(\"id\", \"\" + Integer.MAX_VALUE, Field.Store.NO),\n        new NumericDocValuesField(\"new_numeric\", 1),\n        new BinaryDocValuesField(\"new_binary\", toBytes(1))));\n    writer.updateNumericDocValue(new Term(\"id\", \"1\"), \"new_numeric\", 1);\n    writer.updateBinaryDocValue(new Term(\"id\", \"1\"), \"new_binary\", toBytes(1));\n\n    writer.commit();\n    Runnable assertDV = () -> {\n      boolean found = false;\n      try (DirectoryReader reader = DirectoryReader.open(dir)) {\n        for (LeafReaderContext ctx : reader.leaves()) {\n          LeafReader leafReader = ctx.reader();\n          TermsEnum id = leafReader.terms(\"id\").iterator();\n          if (id.seekExact(new BytesRef(\"1\"))) {\n            PostingsEnum postings = id.postings(null, PostingsEnum.NONE);\n            NumericDocValues numericDocValues = leafReader.getNumericDocValues(\"new_numeric\");\n            BinaryDocValues binaryDocValues = leafReader.getBinaryDocValues(\"new_binary\");\n            int doc;\n            while ((doc = postings.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n              found = true;\n              assertTrue(binaryDocValues.advanceExact(doc));\n              assertTrue(numericDocValues.advanceExact(doc));\n              assertEquals(1, numericDocValues.longValue());\n              assertEquals(toBytes(1), binaryDocValues.binaryValue());\n            }\n          }\n        }\n      } catch (IOException e) {\n        throw new AssertionError(e);\n      }\n      assertTrue(found);\n    };\n    assertDV.run();\n    // merge all segments\n    writer.forceMerge(1);\n    writer.commit();\n    assertDV.run();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocValuesUpdatesWithNewField() throws Exception {\n    Path oldIndexDir = createTempDir(\"dvupdates\");\n    TestUtil.unzip(getDataInputStream(dvUpdatesIndex), oldIndexDir);\n    Directory dir = newFSDirectory(oldIndexDir);\n    verifyUsesDefaultCodec(dir, dvUpdatesIndex);\n\n    // update fields and verify index\n    IndexWriterConfig conf = new IndexWriterConfig(new MockAnalyzer(random()));\n    IndexWriter writer = new IndexWriter(dir, conf);\n    // introduce a new field that we later update\n    writer.addDocument(Arrays.asList(new StringField(\"id\", \"\" + Integer.MAX_VALUE, Field.Store.NO),\n        new NumericDocValuesField(\"new_numeric\", 1),\n        new BinaryDocValuesField(\"new_binary\", toBytes(1))));\n    writer.updateNumericDocValue(new Term(\"id\", \"1\"), \"new_numeric\", 1);\n    writer.updateBinaryDocValue(new Term(\"id\", \"1\"), \"new_binary\", toBytes(1));\n\n    writer.commit();\n    Runnable assertDV = () -> {\n      boolean found = false;\n      try (DirectoryReader reader = DirectoryReader.open(dir)) {\n        for (LeafReaderContext ctx : reader.leaves()) {\n          LeafReader leafReader = ctx.reader();\n          TermsEnum id = leafReader.terms(\"id\").iterator();\n          if (id.seekExact(new BytesRef(\"1\"))) {\n            PostingsEnum postings = id.postings(null, PostingsEnum.NONE);\n            NumericDocValues numericDocValues = leafReader.getNumericDocValues(\"new_numeric\");\n            BinaryDocValues binaryDocValues = leafReader.getBinaryDocValues(\"new_binary\");\n            int doc;\n            while ((doc = postings.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n              found = true;\n              assertTrue(binaryDocValues.advanceExact(doc));\n              assertTrue(numericDocValues.advanceExact(doc));\n              assertEquals(1, numericDocValues.longValue());\n              assertEquals(toBytes(1), binaryDocValues.binaryValue());\n            }\n          }\n        }\n      } catch (IOException e) {\n        throw new AssertionError(e);\n      }\n      assertTrue(found);\n    };\n    assertDV.run();\n    // merge all segments\n    writer.forceMerge(1);\n    writer.commit();\n    assertDV.run();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3c167f43985b3d924e6402ded39beada51a81b6b","date":1552568413,"type":3,"author":"jimczi","isMerge":false,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testDocValuesUpdatesWithNewField().mjava","pathOld":"lucene/backward-codecs/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testDocValuesUpdatesWithNewField().mjava","sourceNew":"  public void testDocValuesUpdatesWithNewField() throws Exception {\n    Path oldIndexDir = createTempDir(\"dvupdates\");\n    TestUtil.unzip(getDataInputStream(dvUpdatesIndex), oldIndexDir);\n    Directory dir = newFSDirectory(oldIndexDir);\n    verifyUsesDefaultCodec(dir, dvUpdatesIndex);\n\n    // update fields and verify index\n    IndexWriterConfig conf = new IndexWriterConfig(new MockAnalyzer(random()));\n    IndexWriter writer = new IndexWriter(dir, conf);\n    // introduce a new field that we later update\n    writer.addDocument(Arrays.asList(new StringField(\"id\", \"\" + Integer.MAX_VALUE, Field.Store.NO),\n        new NumericDocValuesField(\"new_numeric\", 1),\n        new BinaryDocValuesField(\"new_binary\", toBytes(1))));\n    writer.updateNumericDocValue(new Term(\"id\", \"1\"), \"new_numeric\", 1);\n    writer.updateBinaryDocValue(new Term(\"id\", \"1\"), \"new_binary\", toBytes(1));\n\n    writer.commit();\n    Runnable assertDV = () -> {\n      boolean found = false;\n      try (DirectoryReader reader = DirectoryReader.open(dir)) {\n        for (LeafReaderContext ctx : reader.leaves()) {\n          LeafReader leafReader = ctx.reader();\n          TermsEnum id = leafReader.terms(\"id\").iterator();\n          if (id.seekExact(new BytesRef(\"1\"))) {\n            PostingsEnum postings = id.postings(null, PostingsEnum.NONE);\n            NumericDocValues numericDocValues = leafReader.getNumericDocValues(\"new_numeric\");\n            BinaryDocValues binaryDocValues = leafReader.getBinaryDocValues(\"new_binary\");\n            int doc;\n            while ((doc = postings.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n              found = true;\n              assertTrue(binaryDocValues.advanceExact(doc));\n              assertTrue(numericDocValues.advanceExact(doc));\n              assertEquals(1, numericDocValues.longValue());\n              assertEquals(toBytes(1), binaryDocValues.binaryValue());\n            }\n          }\n        }\n      } catch (IOException e) {\n        throw new AssertionError(e);\n      }\n      assertTrue(found);\n    };\n    assertDV.run();\n    // merge all segments\n    writer.forceMerge(1);\n    writer.commit();\n    assertDV.run();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocValuesUpdatesWithNewField() throws Exception {\n    assumeTrue(\"Reenable when 8.0 is released\", false);\n    Path oldIndexDir = createTempDir(\"dvupdates\");\n    TestUtil.unzip(getDataInputStream(dvUpdatesIndex), oldIndexDir);\n    Directory dir = newFSDirectory(oldIndexDir);\n    verifyUsesDefaultCodec(dir, dvUpdatesIndex);\n\n    // update fields and verify index\n    IndexWriterConfig conf = new IndexWriterConfig(new MockAnalyzer(random()));\n    IndexWriter writer = new IndexWriter(dir, conf);\n    // introduce a new field that we later update\n    writer.addDocument(Arrays.asList(new StringField(\"id\", \"\" + Integer.MAX_VALUE, Field.Store.NO),\n        new NumericDocValuesField(\"new_numeric\", 1),\n        new BinaryDocValuesField(\"new_binary\", toBytes(1))));\n    writer.updateNumericDocValue(new Term(\"id\", \"1\"), \"new_numeric\", 1);\n    writer.updateBinaryDocValue(new Term(\"id\", \"1\"), \"new_binary\", toBytes(1));\n\n    writer.commit();\n    Runnable assertDV = () -> {\n      boolean found = false;\n      try (DirectoryReader reader = DirectoryReader.open(dir)) {\n        for (LeafReaderContext ctx : reader.leaves()) {\n          LeafReader leafReader = ctx.reader();\n          TermsEnum id = leafReader.terms(\"id\").iterator();\n          if (id.seekExact(new BytesRef(\"1\"))) {\n            PostingsEnum postings = id.postings(null, PostingsEnum.NONE);\n            NumericDocValues numericDocValues = leafReader.getNumericDocValues(\"new_numeric\");\n            BinaryDocValues binaryDocValues = leafReader.getBinaryDocValues(\"new_binary\");\n            int doc;\n            while ((doc = postings.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n              found = true;\n              assertTrue(binaryDocValues.advanceExact(doc));\n              assertTrue(numericDocValues.advanceExact(doc));\n              assertEquals(1, numericDocValues.longValue());\n              assertEquals(toBytes(1), binaryDocValues.binaryValue());\n            }\n          }\n        }\n      } catch (IOException e) {\n        throw new AssertionError(e);\n      }\n      assertTrue(found);\n    };\n    assertDV.run();\n    // merge all segments\n    writer.forceMerge(1);\n    writer.commit();\n    assertDV.run();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"9135dfa8824df4c6f7619bd2ac9507d821c61239":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3c167f43985b3d924e6402ded39beada51a81b6b":["d722b735bc69d2234e957cb69cf96ad28ea7e1c3"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3c167f43985b3d924e6402ded39beada51a81b6b"],"d722b735bc69d2234e957cb69cf96ad28ea7e1c3":["9135dfa8824df4c6f7619bd2ac9507d821c61239"]},"commit2Childs":{"9135dfa8824df4c6f7619bd2ac9507d821c61239":["d722b735bc69d2234e957cb69cf96ad28ea7e1c3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9135dfa8824df4c6f7619bd2ac9507d821c61239"],"3c167f43985b3d924e6402ded39beada51a81b6b":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d722b735bc69d2234e957cb69cf96ad28ea7e1c3":["3c167f43985b3d924e6402ded39beada51a81b6b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}