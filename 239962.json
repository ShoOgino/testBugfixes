{"path":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","commits":[{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"solr/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2,2}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4,4}, null, false));\n  }\n\n","sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2,2}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4,4}, null, false));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"solr/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2,2}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4,4}, null, false));\n  }\n\n","sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2,2}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4,4}, null, false));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"solr/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2,2}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4,4}, null, false));\n  }\n\n","sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2,2}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4,4}, null, false));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"77d924c3b8deab5881ed0d996d597a4ea5bbc40a","date":1316977817,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expecting the 'MockTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2,2}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4,4}, null, false));\n  }\n\n","sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2,2}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4,4}, null, false));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"08970e5b8411182a29412c177eff67ec1110095b","date":1366640815,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getLatestSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expecting the 'MockTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2,2}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4,4}, null, false));\n  }\n\n","sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expecting the 'MockTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2,2}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4,4}, null, false));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"eafa8c5eabc3dacd34680054e6a33bda024080ac","date":1367691488,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getLatestSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expecting the 'MockTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3,3}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6,6}, null, false));\n  }\n\n","sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getLatestSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expecting the 'MockTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2,2}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4,4}, null, false));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b266fe0ac2172d4ad87cff12bd9bf9f8c8247345","date":1465936684,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getLatestSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expecting the 'MockTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3,3}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6,6}, null, false));\n  }\n\n","sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getLatestSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expecting the 'MockTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3,3}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6,6}, null, false));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"128099577578723971decd2fd3c3b0a043ff9855","date":1473703890,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getLatestSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expecting the 'MockTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3,3}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6,6}, null, false));\n  }\n\n","sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getLatestSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expecting the 'MockTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3,3}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6,6}, null, false));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"89424def13674ea17829b41c5883c54ecc31a132","date":1473767373,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getLatestSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expecting the 'MockTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3,3}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6,6}, null, false));\n  }\n\n","sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getLatestSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expecting the 'MockTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3,3}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6,6}, null, false));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"17e5da53e4e5bd659e22add9bba1cfa222e7e30d","date":1475435902,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getLatestSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expecting the 'MockTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3,3}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6,6}, null, false));\n  }\n\n","sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getLatestSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expecting the 'MockTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3,3}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6,6}, null, false));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fb1921ba901ad34c1b448d0b8c98a563dfea7dd9","date":1501254464,"type":3,"author":"Steve Rowe","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n    document.addField(\"number_l_p\", 88L);\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getLatestSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n    String name;\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n    queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = idResult.get(\"index\");\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n\n    // the number_l_p field\n    NamedList<NamedList<Object>> number_l_p_Result = documentResult.get(\"number_l_p\");\n    assertNotNull(\"an analysis for the 'number_l_p' field should be returned\", number_l_p_Result);\n    indexResult = number_l_p_Result.get(\"index\");\n    assertEquals(\"The number_l_p field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"88\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'number_l_p' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"88\", null, \"word\", 0, 2, 1, new int[]{1}, null, false));\n\n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expecting the 'MockTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3,3}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6,6}, null, false));\n  }\n\n","sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getLatestSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expecting the 'MockTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3,3}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6,6}, null, false));\n  }\n\n","bugFix":["78da6990f140a712adfb145ea6faa99db270e1bc","68df8db3f6c0c0ebbd1e40ba638115a748fb6a2a"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","date":1502192746,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n    document.addField(\"number_l_p\", 88L);\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getLatestSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n    String name;\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n    queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = idResult.get(\"index\");\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n\n    // the number_l_p field\n    NamedList<NamedList<Object>> number_l_p_Result = documentResult.get(\"number_l_p\");\n    assertNotNull(\"an analysis for the 'number_l_p' field should be returned\", number_l_p_Result);\n    indexResult = number_l_p_Result.get(\"index\");\n    assertEquals(\"The number_l_p field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"88\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'number_l_p' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"88\", null, \"word\", 0, 2, 1, new int[]{1}, null, false));\n\n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expecting the 'MockTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3,3}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6,6}, null, false));\n  }\n\n","sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getLatestSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expecting the 'MockTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3,3}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6,6}, null, false));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"205f0e81aafd8115e4cd61788ef9e7a6476aa175","date":1530097523,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n    document.addField(\"number_l_p\", 88L);\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getLatestSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n    String name;\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n    queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = idResult.get(\"index\");\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n\n    // the number_l_p field\n    NamedList<NamedList<Object>> number_l_p_Result = documentResult.get(\"number_l_p\");\n    assertNotNull(\"an analysis for the 'number_l_p' field should be returned\", number_l_p_Result);\n    indexResult = number_l_p_Result.get(\"index\");\n    assertEquals(\"The number_l_p field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"88\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'number_l_p' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"88\", null, \"word\", 0, 2, 1, new int[]{1}, null, false));\n\n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expecting the 'MockTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6}, null, false));\n  }\n\n","sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n    document.addField(\"number_l_p\", 88L);\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getLatestSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n    String name;\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n    queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = idResult.get(\"index\");\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n\n    // the number_l_p field\n    NamedList<NamedList<Object>> number_l_p_Result = documentResult.get(\"number_l_p\");\n    assertNotNull(\"an analysis for the 'number_l_p' field should be returned\", number_l_p_Result);\n    indexResult = number_l_p_Result.get(\"index\");\n    assertEquals(\"The number_l_p field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"88\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'number_l_p' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"88\", null, \"word\", 0, 2, 1, new int[]{1}, null, false));\n\n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expecting the 'MockTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3,3}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6,6}, null, false));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n    document.addField(\"number_l_p\", 88L);\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getLatestSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n    String name;\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n    queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = idResult.get(\"index\");\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n\n    // the number_l_p field\n    NamedList<NamedList<Object>> number_l_p_Result = documentResult.get(\"number_l_p\");\n    assertNotNull(\"an analysis for the 'number_l_p' field should be returned\", number_l_p_Result);\n    indexResult = number_l_p_Result.get(\"index\");\n    assertEquals(\"The number_l_p field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"88\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'number_l_p' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"88\", null, \"word\", 0, 2, 1, new int[]{1}, null, false));\n\n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expecting the 'MockTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6}, null, false));\n  }\n\n","sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n    document.addField(\"number_l_p\", 88L);\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getLatestSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n    String name;\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n    queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = idResult.get(\"index\");\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n\n    // the number_l_p field\n    NamedList<NamedList<Object>> number_l_p_Result = documentResult.get(\"number_l_p\");\n    assertNotNull(\"an analysis for the 'number_l_p' field should be returned\", number_l_p_Result);\n    indexResult = number_l_p_Result.get(\"index\");\n    assertEquals(\"The number_l_p field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"88\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'number_l_p' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"88\", null, \"word\", 0, 2, 1, new int[]{1}, null, false));\n\n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expecting the 'MockTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3,3}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6,6}, null, false));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n    document.addField(\"number_l_p\", 88L);\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getLatestSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n    String name;\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n    queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = idResult.get(\"index\");\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n\n    // the number_l_p field\n    NamedList<NamedList<Object>> number_l_p_Result = documentResult.get(\"number_l_p\");\n    assertNotNull(\"an analysis for the 'number_l_p' field should be returned\", number_l_p_Result);\n    indexResult = number_l_p_Result.get(\"index\");\n    assertEquals(\"The number_l_p field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"88\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'number_l_p' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"88\", null, \"word\", 0, 2, 1, new int[]{1}, null, false));\n\n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expecting the 'MockTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6}, null, false));\n  }\n\n","sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n    document.addField(\"number_l_p\", 88L);\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getLatestSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n    String name;\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n    queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = idResult.get(\"index\");\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n\n    // the number_l_p field\n    NamedList<NamedList<Object>> number_l_p_Result = documentResult.get(\"number_l_p\");\n    assertNotNull(\"an analysis for the 'number_l_p' field should be returned\", number_l_p_Result);\n    indexResult = number_l_p_Result.get(\"index\");\n    assertEquals(\"The number_l_p field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"88\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'number_l_p' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"88\", null, \"word\", 0, 2, 1, new int[]{1}, null, false));\n\n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expecting the 'MockTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3,3}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6,6}, null, false));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e98520789adb1d5ad05afb4956eca0944a929688","date":1592430701,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n    document.addField(\"number_l_p\", 88L);\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getLatestSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n    String name;\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n    queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = idResult.get(\"index\");\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n\n    // the number_l_p field\n    NamedList<NamedList<Object>> number_l_p_Result = documentResult.get(\"number_l_p\");\n    assertNotNull(\"an analysis for the 'number_l_p' field should be returned\", number_l_p_Result);\n    indexResult = number_l_p_Result.get(\"index\");\n    assertEquals(\"The number_l_p field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"88\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'number_l_p' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"88\", null, \"word\", 0, 2, 1, new int[]{1}, null, false));\n\n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expecting the 'MockTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6}, null, false));\n  }\n\n","sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n    document.addField(\"number_l_p\", 88L);\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getLatestSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n    String name;\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n    queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = idResult.get(\"index\");\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n\n    // the number_l_p field\n    NamedList<NamedList<Object>> number_l_p_Result = documentResult.get(\"number_l_p\");\n    assertNotNull(\"an analysis for the 'number_l_p' field should be returned\", number_l_p_Result);\n    indexResult = number_l_p_Result.get(\"index\");\n    assertEquals(\"The number_l_p field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"88\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'number_l_p' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"88\", null, \"word\", 0, 2, 1, new int[]{1}, null, false));\n\n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(MockTokenizer.class.getName());\n    assertNotNull(\"Expecting the 'MockTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2,2}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3,3}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4,4}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6,6}, null, false));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c26f00b574427b55127e869b935845554afde1fa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"77d924c3b8deab5881ed0d996d597a4ea5bbc40a":["c26f00b574427b55127e869b935845554afde1fa"],"eafa8c5eabc3dacd34680054e6a33bda024080ac":["08970e5b8411182a29412c177eff67ec1110095b"],"fb1921ba901ad34c1b448d0b8c98a563dfea7dd9":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"b266fe0ac2172d4ad87cff12bd9bf9f8c8247345":["eafa8c5eabc3dacd34680054e6a33bda024080ac"],"e98520789adb1d5ad05afb4956eca0944a929688":["205f0e81aafd8115e4cd61788ef9e7a6476aa175"],"08970e5b8411182a29412c177eff67ec1110095b":["77d924c3b8deab5881ed0d996d597a4ea5bbc40a"],"89424def13674ea17829b41c5883c54ecc31a132":["b266fe0ac2172d4ad87cff12bd9bf9f8c8247345","128099577578723971decd2fd3c3b0a043ff9855"],"205f0e81aafd8115e4cd61788ef9e7a6476aa175":["fb1921ba901ad34c1b448d0b8c98a563dfea7dd9"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["fb1921ba901ad34c1b448d0b8c98a563dfea7dd9","205f0e81aafd8115e4cd61788ef9e7a6476aa175"],"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d","fb1921ba901ad34c1b448d0b8c98a563dfea7dd9"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["b266fe0ac2172d4ad87cff12bd9bf9f8c8247345","89424def13674ea17829b41c5883c54ecc31a132"],"128099577578723971decd2fd3c3b0a043ff9855":["b266fe0ac2172d4ad87cff12bd9bf9f8c8247345"],"a258fbb26824fd104ed795e5d9033d2d040049ee":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e98520789adb1d5ad05afb4956eca0944a929688"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["fb1921ba901ad34c1b448d0b8c98a563dfea7dd9","205f0e81aafd8115e4cd61788ef9e7a6476aa175"]},"commit2Childs":{"c26f00b574427b55127e869b935845554afde1fa":["77d924c3b8deab5881ed0d996d597a4ea5bbc40a"],"77d924c3b8deab5881ed0d996d597a4ea5bbc40a":["08970e5b8411182a29412c177eff67ec1110095b"],"eafa8c5eabc3dacd34680054e6a33bda024080ac":["b266fe0ac2172d4ad87cff12bd9bf9f8c8247345"],"fb1921ba901ad34c1b448d0b8c98a563dfea7dd9":["205f0e81aafd8115e4cd61788ef9e7a6476aa175","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"b266fe0ac2172d4ad87cff12bd9bf9f8c8247345":["89424def13674ea17829b41c5883c54ecc31a132","17e5da53e4e5bd659e22add9bba1cfa222e7e30d","128099577578723971decd2fd3c3b0a043ff9855"],"08970e5b8411182a29412c177eff67ec1110095b":["eafa8c5eabc3dacd34680054e6a33bda024080ac"],"e98520789adb1d5ad05afb4956eca0944a929688":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"89424def13674ea17829b41c5883c54ecc31a132":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"205f0e81aafd8115e4cd61788ef9e7a6476aa175":["e98520789adb1d5ad05afb4956eca0944a929688","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":[],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c26f00b574427b55127e869b935845554afde1fa","c903c3d15906a3da96b8c0c2fb704491005fdbdb","a258fbb26824fd104ed795e5d9033d2d040049ee"],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["fb1921ba901ad34c1b448d0b8c98a563dfea7dd9","7a23cf16c8fa265dc0a564adcabb55e3f054e0ac"],"128099577578723971decd2fd3c3b0a043ff9855":["89424def13674ea17829b41c5883c54ecc31a132"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[]},"heads":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}