{"path":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","commits":[{"id":"7afb64ff3a701f68b2689cafff6c5bdeb4f67f63","date":1398957288,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testSimple().mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    Directory dir = newDirectory();\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = new CrankyTokenFilter(tokenizer, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    Codec codec = new CrankyCodec(Codec.getDefault(), new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n    \n    // TODO: too much?\n    int numDocs = RANDOM_MULTIPLIER * 1000;\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // TODO: sometimes update dv\n        try {\n          iw.addDocument(doc);\n        } catch (Exception e) {\n          if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n            exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n            e.printStackTrace(exceptionStream);\n          } else {\n            Rethrow.rethrow(e);\n          }\n        }\n        if (random().nextInt(10) == 0) {\n          // trigger flush: TODO: sometimes reopen\n          try {\n            iw.commit();\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.shutdown();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          System.out.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testSimple() throws Exception {\n    Directory dir = newDirectory();\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = new CrankyTokenFilter(tokenizer, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    Codec codec = new CrankyCodec(Codec.getDefault(), new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n    \n    // TODO: too much?\n    int numDocs = RANDOM_MULTIPLIER * 1000;\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // TODO: sometimes update dv\n        try {\n          iw.addDocument(doc);\n        } catch (Exception e) {\n          if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n            System.out.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n            e.printStackTrace(exceptionStream);\n          } else {\n            Rethrow.rethrow(e);\n          }\n        }\n        if (random().nextInt(10) == 0) {\n          // trigger flush: TODO: sometimes reopen\n          try {\n            iw.commit();\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              System.out.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.shutdown();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          System.out.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c11c451a6e72282b9f57f81fb1e0878be67edcfd","date":1398963015,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    Directory dir = newDirectory();\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = new CrankyTokenFilter(tokenizer, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    Codec codec = new CrankyCodec(Codec.getDefault(), new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n    \n    // TODO: too much?\n    int numDocs = RANDOM_MULTIPLIER * 1000;\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // TODO: sometimes update dv\n        try {\n          iw.addDocument(doc);\n          // we made it, sometimes delete our doc\n          if (random().nextInt(4) == 0) {\n            iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n          }\n        } catch (Exception e) {\n          if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n            exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n            e.printStackTrace(exceptionStream);\n          } else {\n            Rethrow.rethrow(e);\n          }\n        }\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.shutdown();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    Directory dir = newDirectory();\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = new CrankyTokenFilter(tokenizer, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    Codec codec = new CrankyCodec(Codec.getDefault(), new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n    \n    // TODO: too much?\n    int numDocs = RANDOM_MULTIPLIER * 1000;\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // TODO: sometimes update dv\n        try {\n          iw.addDocument(doc);\n        } catch (Exception e) {\n          if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n            exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n            e.printStackTrace(exceptionStream);\n          } else {\n            Rethrow.rethrow(e);\n          }\n        }\n        if (random().nextInt(10) == 0) {\n          // trigger flush: TODO: sometimes reopen\n          try {\n            iw.commit();\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.shutdown();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          System.out.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"12320451a8cf581593c5eca6d2db98d299d693c7","date":1398969355,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = new CrankyTokenFilter(tokenizer, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n    \n    int numDocs = atLeast(2500);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // TODO: sometimes update dv\n        try {\n          iw.addDocument(doc);\n          // we made it, sometimes delete our doc\n          if (random().nextInt(4) == 0) {\n            iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n          }\n        } catch (Exception e) {\n          if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n            exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n            e.printStackTrace(exceptionStream);\n          } else {\n            Rethrow.rethrow(e);\n          }\n        }\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.shutdown();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    Directory dir = newDirectory();\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = new CrankyTokenFilter(tokenizer, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    Codec codec = new CrankyCodec(Codec.getDefault(), new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n    \n    // TODO: too much?\n    int numDocs = RANDOM_MULTIPLIER * 1000;\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // TODO: sometimes update dv\n        try {\n          iw.addDocument(doc);\n          // we made it, sometimes delete our doc\n          if (random().nextInt(4) == 0) {\n            iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n          }\n        } catch (Exception e) {\n          if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n            exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n            e.printStackTrace(exceptionStream);\n          } else {\n            Rethrow.rethrow(e);\n          }\n        }\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.shutdown();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":["0e80cc3f88baf8f24df62207787944c7df9b75b9"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fdc81126b07d75058a8395541b107b36f02ca9ac","date":1398970178,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = new CrankyTokenFilter(tokenizer, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n    \n    int numDocs = atLeast(2500);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        try {\n          iw.addDocument(doc);\n          // we made it, sometimes delete our doc, or update a dv\n          int thingToDo = random().nextInt(4);\n          if (thingToDo == 0) {\n            iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n          } else if (thingToDo == 1 && defaultCodecSupportsFieldUpdates()){\n            iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n          }\n        } catch (Exception e) {\n          if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n            exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n            e.printStackTrace(exceptionStream);\n          } else {\n            Rethrow.rethrow(e);\n          }\n        }\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.shutdown();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = new CrankyTokenFilter(tokenizer, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n    \n    int numDocs = atLeast(2500);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // TODO: sometimes update dv\n        try {\n          iw.addDocument(doc);\n          // we made it, sometimes delete our doc\n          if (random().nextInt(4) == 0) {\n            iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n          }\n        } catch (Exception e) {\n          if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n            exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n            e.printStackTrace(exceptionStream);\n          } else {\n            Rethrow.rethrow(e);\n          }\n        }\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.shutdown();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":["0e80cc3f88baf8f24df62207787944c7df9b75b9"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0e80cc3f88baf8f24df62207787944c7df9b75b9","date":1398972512,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n    \n    int numDocs = atLeast(2000);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        if (defaultCodecSupportsSortedSet()) {\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        }\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        \n        try {\n          iw.addDocument(doc);\n          // we made it, sometimes delete our doc, or update a dv\n          int thingToDo = random().nextInt(4);\n          if (thingToDo == 0) {\n            iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n          } else if (thingToDo == 1 && defaultCodecSupportsFieldUpdates()) {\n            iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n          } else if (thingToDo == 2 && defaultCodecSupportsFieldUpdates()) {\n            iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n          }\n        } catch (Exception e) {\n          if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n            exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n            e.printStackTrace(exceptionStream);\n          } else {\n            Rethrow.rethrow(e);\n          }\n        }\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.shutdown();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = new CrankyTokenFilter(tokenizer, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n    \n    int numDocs = atLeast(2500);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        try {\n          iw.addDocument(doc);\n          // we made it, sometimes delete our doc, or update a dv\n          int thingToDo = random().nextInt(4);\n          if (thingToDo == 0) {\n            iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n          } else if (thingToDo == 1 && defaultCodecSupportsFieldUpdates()){\n            iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n          }\n        } catch (Exception e) {\n          if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n            exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n            e.printStackTrace(exceptionStream);\n          } else {\n            Rethrow.rethrow(e);\n          }\n        }\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.shutdown();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":["4e8947bb335882c059bedf21cdadc06a26c922b0","fdc81126b07d75058a8395541b107b36f02ca9ac","12320451a8cf581593c5eca6d2db98d299d693c7"],"bugIntro":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7f72557fc48bb36e35802ffb52580e40de88d40d","date":1398996736,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n    \n    int numDocs = atLeast(2000);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        if (defaultCodecSupportsSortedSet()) {\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        }\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1 && defaultCodecSupportsFieldUpdates()) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2 && defaultCodecSupportsFieldUpdates()) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.shutdown();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n    \n    int numDocs = atLeast(2000);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        if (defaultCodecSupportsSortedSet()) {\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        }\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        \n        try {\n          iw.addDocument(doc);\n          // we made it, sometimes delete our doc, or update a dv\n          int thingToDo = random().nextInt(4);\n          if (thingToDo == 0) {\n            iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n          } else if (thingToDo == 1 && defaultCodecSupportsFieldUpdates()) {\n            iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n          } else if (thingToDo == 2 && defaultCodecSupportsFieldUpdates()) {\n            iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n          }\n        } catch (Exception e) {\n          if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n            exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n            e.printStackTrace(exceptionStream);\n          } else {\n            Rethrow.rethrow(e);\n          }\n        }\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.shutdown();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d14ffaac9c4a4a2c750bf0cd956506802561e062","date":1402602036,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n    \n    int numDocs = atLeast(2000);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        if (defaultCodecSupportsSortedSet()) {\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        }\n        if (defaultCodecSupportsSortedNumeric()) {\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        }\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1 && defaultCodecSupportsFieldUpdates()) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2 && defaultCodecSupportsFieldUpdates()) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.shutdown();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n    \n    int numDocs = atLeast(2000);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        if (defaultCodecSupportsSortedSet()) {\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        }\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1 && defaultCodecSupportsFieldUpdates()) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2 && defaultCodecSupportsFieldUpdates()) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.shutdown();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c6f080a2ab37c464dd98db173f6cbf10dc74f211","date":1402946779,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n    \n    int numDocs = atLeast(2000);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        if (defaultCodecSupportsSortedSet()) {\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        }\n        if (defaultCodecSupportsSortedNumeric()) {\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        }\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1 && defaultCodecSupportsFieldUpdates()) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2 && defaultCodecSupportsFieldUpdates()) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.shutdown();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n    \n    int numDocs = atLeast(2000);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        if (defaultCodecSupportsSortedSet()) {\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        }\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1 && defaultCodecSupportsFieldUpdates()) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2 && defaultCodecSupportsFieldUpdates()) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.shutdown();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n    \n    int numDocs = atLeast(2000);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        if (defaultCodecSupportsSortedSet()) {\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        }\n        if (defaultCodecSupportsSortedNumeric()) {\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        }\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1 && defaultCodecSupportsFieldUpdates()) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2 && defaultCodecSupportsFieldUpdates()) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.shutdown();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n    \n    int numDocs = atLeast(2000);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        if (defaultCodecSupportsSortedSet()) {\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        }\n        if (defaultCodecSupportsSortedNumeric()) {\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        }\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1 && defaultCodecSupportsFieldUpdates()) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2 && defaultCodecSupportsFieldUpdates()) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.shutdown();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n    \n    int numDocs = atLeast(2000);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        if (defaultCodecSupportsSortedSet()) {\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        }\n        if (defaultCodecSupportsSortedNumeric()) {\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        }\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1 && defaultCodecSupportsFieldUpdates()) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2 && defaultCodecSupportsFieldUpdates()) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.close();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n    \n    int numDocs = atLeast(2000);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        if (defaultCodecSupportsSortedSet()) {\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        }\n        if (defaultCodecSupportsSortedNumeric()) {\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        }\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1 && defaultCodecSupportsFieldUpdates()) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2 && defaultCodecSupportsFieldUpdates()) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.shutdown();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ad2a673349939e48652bf304cccf673c3412198f","date":1409585169,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n    \n    int numDocs = atLeast(2000);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.close();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n    \n    int numDocs = atLeast(2000);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        if (defaultCodecSupportsSortedSet()) {\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        }\n        if (defaultCodecSupportsSortedNumeric()) {\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        }\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1 && defaultCodecSupportsFieldUpdates()) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2 && defaultCodecSupportsFieldUpdates()) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.close();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"402ad3ddc9da7b70da1b167667a60ece6a1381fb","date":1409656478,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n    \n    int numDocs = atLeast(2000);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.close();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n    \n    int numDocs = atLeast(2000);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        if (defaultCodecSupportsSortedSet()) {\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        }\n        if (defaultCodecSupportsSortedNumeric()) {\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        }\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1 && defaultCodecSupportsFieldUpdates()) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2 && defaultCodecSupportsFieldUpdates()) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.close();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":["7f72557fc48bb36e35802ffb52580e40de88d40d","d14ffaac9c4a4a2c750bf0cd956506802561e062","0e80cc3f88baf8f24df62207787944c7df9b75b9"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a87ce200bba7d88024e2f1c4012212072ce8a5ae","date":1417031281,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n    \n    int numDocs = atLeast(500);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.close();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n    \n    int numDocs = atLeast(2000);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.close();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9299079153fd7895bf3cf6835cf7019af2ba89b3","date":1417813477,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n      ((MockDirectoryWrapper)dir).setPreventDoubleWrite(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n\n    int numDocs = atLeast(500);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      boolean allowAlreadyClosed = false;\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.close();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n    \n    int numDocs = atLeast(500);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.close();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":["11c6df42fb3eba174c3ca0d9a5194eaecd893b77"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0d49a158012a8ff48f328a4558e4bfcffbaed16f","date":1453677440,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n      ((MockDirectoryWrapper)dir).setPreventDoubleWrite(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n\n    int numDocs = atLeast(500);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      boolean allowAlreadyClosed = false;\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean(), false);\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.close();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n      ((MockDirectoryWrapper)dir).setPreventDoubleWrite(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n\n    int numDocs = atLeast(500);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      boolean allowAlreadyClosed = false;\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.close();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"85ca0e073c286ebb2c89364ada6dd2740fc18880","date":1453996944,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n      ((MockDirectoryWrapper)dir).setPreventDoubleWrite(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n\n    int numDocs = atLeast(500);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      boolean allowAlreadyClosed = false;\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        doc.add(new IntPoint(\"point\", random().nextInt()));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.close();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n      ((MockDirectoryWrapper)dir).setPreventDoubleWrite(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n\n    int numDocs = atLeast(500);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      boolean allowAlreadyClosed = false;\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.close();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8de18786ea000fc5fbc7214d571cc7f41d597ee3","date":1454085819,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n      ((MockDirectoryWrapper)dir).setPreventDoubleWrite(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n\n    int numDocs = atLeast(500);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      boolean allowAlreadyClosed = false;\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        doc.add(new IntPoint(\"point\", random().nextInt()));\n        doc.add(new IntPoint(\"point2d\", random().nextInt(), random().nextInt()));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.close();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n      ((MockDirectoryWrapper)dir).setPreventDoubleWrite(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n\n    int numDocs = atLeast(500);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      boolean allowAlreadyClosed = false;\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        doc.add(new IntPoint(\"point\", random().nextInt()));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.close();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8d15e34266d75e4e8b95da046cd0afc812367b38","date":1454246129,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n      ((MockDirectoryWrapper)dir).setPreventDoubleWrite(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n\n    int numDocs = atLeast(500);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      boolean allowAlreadyClosed = false;\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        doc.add(new IntPoint(\"point\", random().nextInt()));\n        doc.add(new IntPoint(\"point2d\", random().nextInt(), random().nextInt()));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.close();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n      ((MockDirectoryWrapper)dir).setPreventDoubleWrite(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n\n    int numDocs = atLeast(500);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      boolean allowAlreadyClosed = false;\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.close();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1e6acbaae7af722f17204ceccf0f7db5753eccf3","date":1454775255,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n      ((MockDirectoryWrapper)dir).setPreventDoubleWrite(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n\n    int numDocs = atLeast(500);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      boolean allowAlreadyClosed = false;\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        doc.add(new IntPoint(\"point\", random().nextInt()));\n        doc.add(new IntPoint(\"point2d\", random().nextInt(), random().nextInt()));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean(), false);\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.close();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n      ((MockDirectoryWrapper)dir).setPreventDoubleWrite(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n\n    int numDocs = atLeast(500);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      boolean allowAlreadyClosed = false;\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean(), false);\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.close();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"68496c2200e559fb7802f7575427b7a482659afb","date":1455207618,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n      ((MockDirectoryWrapper)dir).setPreventDoubleWrite(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n\n    int numDocs = atLeast(500);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      boolean allowAlreadyClosed = false;\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        doc.add(new IntPoint(\"point\", random().nextInt()));\n        doc.add(new IntPoint(\"point2d\", random().nextInt(), random().nextInt()));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean(), false);\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.close();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n      ((MockDirectoryWrapper)dir).setPreventDoubleWrite(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n\n    int numDocs = atLeast(500);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      boolean allowAlreadyClosed = false;\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        doc.add(new IntPoint(\"point\", random().nextInt()));\n        doc.add(new IntPoint(\"point2d\", random().nextInt(), random().nextInt()));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean());\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.close();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"11c6df42fb3eba174c3ca0d9a5194eaecd893b77","date":1465931757,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n\n    int numDocs = atLeast(500);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      boolean allowAlreadyClosed = false;\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        doc.add(new IntPoint(\"point\", random().nextInt()));\n        doc.add(new IntPoint(\"point2d\", random().nextInt(), random().nextInt()));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean(), false);\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.close();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n      ((MockDirectoryWrapper)dir).setPreventDoubleWrite(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n\n    int numDocs = atLeast(500);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      boolean allowAlreadyClosed = false;\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        doc.add(new IntPoint(\"point\", random().nextInt()));\n        doc.add(new IntPoint(\"point2d\", random().nextInt(), random().nextInt()));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean(), false);\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.close();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":["9299079153fd7895bf3cf6835cf7019af2ba89b3"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n\n    int numDocs = atLeast(500);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      boolean allowAlreadyClosed = false;\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        doc.add(new IntPoint(\"point\", random().nextInt()));\n        doc.add(new IntPoint(\"point2d\", random().nextInt(), random().nextInt()));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean(), false);\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.close();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n      ((MockDirectoryWrapper)dir).setPreventDoubleWrite(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n\n    int numDocs = atLeast(500);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      boolean allowAlreadyClosed = false;\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        doc.add(new IntPoint(\"point\", random().nextInt()));\n        doc.add(new IntPoint(\"point2d\", random().nextInt(), random().nextInt()));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean(), false);\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.close();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f","date":1579652839,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n\n    int numDocs = atLeast(100);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      boolean allowAlreadyClosed = false;\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        doc.add(new IntPoint(\"point\", random().nextInt()));\n        doc.add(new IntPoint(\"point2d\", random().nextInt(), random().nextInt()));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean(), false);\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.close();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n\n    int numDocs = atLeast(500);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      boolean allowAlreadyClosed = false;\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        doc.add(new IntPoint(\"point\", random().nextInt()));\n        doc.add(new IntPoint(\"point2d\", random().nextInt(), random().nextInt()));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean(), false);\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.close();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8a428f5314daaabf8eab7c50bdc3bc14e6cd1aa2","date":1588002560,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions2#testBasics().mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n\n    int numDocs = atLeast(100);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      boolean allowAlreadyClosed = false;\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        doc.add(new IntPoint(\"point\", random().nextInt()));\n        doc.add(new IntPoint(\"point2d\", random().nextInt(), random().nextInt()));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.isDeleterClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.isDeleterClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean(), false);\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.isDeleterClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.close();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {\n    // disable slow things: we don't rely upon sleeps here.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n      ((MockDirectoryWrapper)dir).setUseSlowOpenClosers(false);\n    }\n    \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    // create lots of non-aborting exceptions with a broken analyzer\n    final long analyzerSeed = random().nextLong();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, false);\n        tokenizer.setEnableChecks(false); // TODO: can we turn this on? our filter is probably too evil\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        stream = new CrankyTokenFilter(stream, new Random(analyzerSeed));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    // create lots of aborting exceptions with a broken codec\n    // we don't need a random codec, as we aren't trying to find bugs in the codec here.\n    Codec inner = RANDOM_MULTIPLIER > 1 ? Codec.getDefault() : new AssertingCodec();\n    Codec codec = new CrankyCodec(inner, new Random(random().nextLong()));\n    \n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    // just for now, try to keep this test reproducible\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    conf.setCodec(codec);\n\n    int numDocs = atLeast(100);\n    \n    IndexWriter iw = new IndexWriter(dir, conf);\n    try {\n      boolean allowAlreadyClosed = false;\n      for (int i = 0; i < numDocs; i++) {\n        // TODO: add crankyDocValuesFields, etc\n        Document doc = new Document();\n        doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n        doc.add(new NumericDocValuesField(\"dv\", i));\n        doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n        doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n        doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n        doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n        // ensure we store something\n        doc.add(new StoredField(\"stored1\", \"foo\"));\n        doc.add(new StoredField(\"stored1\", \"bar\"));    \n        // ensure we get some payloads\n        doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n        // ensure we get some vectors\n        FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n        ft.setStoreTermVectors(true);\n        doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n        doc.add(new IntPoint(\"point\", random().nextInt()));\n        doc.add(new IntPoint(\"point2d\", random().nextInt(), random().nextInt()));\n        \n        if (random().nextInt(10) > 0) {\n          // single doc\n          try {\n            iw.addDocument(doc);\n            // we made it, sometimes delete our doc, or update a dv\n            int thingToDo = random().nextInt(4);\n            if (thingToDo == 0) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n            } else if (thingToDo == 1) {\n              iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n            } else if (thingToDo == 2) {\n              iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        } else {\n          // block docs\n          Document doc2 = new Document();\n          doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n          doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          doc2.add(new StoredField(\"stored1\", \"foo\"));\n          doc2.add(new StoredField(\"stored1\", \"bar\"));\n          doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          try {\n            iw.addDocuments(Arrays.asList(doc, doc2));\n            // we made it, sometimes delete our docs\n            if (random().nextBoolean()) {\n              iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n\n        if (random().nextInt(10) == 0) {\n          // trigger flush:\n          try {\n            if (random().nextBoolean()) {\n              DirectoryReader ir = null;\n              try {\n                ir = DirectoryReader.open(iw, random().nextBoolean(), false);\n                TestUtil.checkReader(ir);\n              } finally {\n                IOUtils.closeWhileHandlingException(ir);\n              }\n            } else {\n              iw.commit();\n            }\n            if (DirectoryReader.indexExists(dir)) {\n              TestUtil.checkIndex(dir);\n            }\n          } catch (AlreadyClosedException ace) {\n            // OK: writer was closed by abort; we just reopen now:\n            assertTrue(iw.deleter.isClosed());\n            assertTrue(allowAlreadyClosed);\n            allowAlreadyClosed = false;\n            conf = newIndexWriterConfig(analyzer);\n            // just for now, try to keep this test reproducible\n            conf.setMergeScheduler(new SerialMergeScheduler());\n            conf.setCodec(codec);\n            iw = new IndexWriter(dir, conf);            \n          } catch (Exception e) {\n            if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n              exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n              e.printStackTrace(exceptionStream);\n              allowAlreadyClosed = true;\n            } else {\n              Rethrow.rethrow(e);\n            }\n          }\n        }\n      }\n      \n      try {\n        iw.close();\n      } catch (Exception e) {\n        if (e.getMessage() != null && e.getMessage().startsWith(\"Fake IOException\")) {\n          exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n          e.printStackTrace(exceptionStream);\n          try {\n            iw.rollback();\n          } catch (Throwable t) {}\n        } else {\n          Rethrow.rethrow(e);\n        }\n      }\n      dir.close();\n    } catch (Throwable t) {\n      System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n      exceptionStream.flush();\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n      System.out.flush();\n      Rethrow.rethrow(t);\n    }\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"11c6df42fb3eba174c3ca0d9a5194eaecd893b77":["68496c2200e559fb7802f7575427b7a482659afb"],"0e80cc3f88baf8f24df62207787944c7df9b75b9":["fdc81126b07d75058a8395541b107b36f02ca9ac"],"7afb64ff3a701f68b2689cafff6c5bdeb4f67f63":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"7f72557fc48bb36e35802ffb52580e40de88d40d":["0e80cc3f88baf8f24df62207787944c7df9b75b9"],"8de18786ea000fc5fbc7214d571cc7f41d597ee3":["85ca0e073c286ebb2c89364ada6dd2740fc18880"],"a87ce200bba7d88024e2f1c4012212072ce8a5ae":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"68496c2200e559fb7802f7575427b7a482659afb":["8d15e34266d75e4e8b95da046cd0afc812367b38","1e6acbaae7af722f17204ceccf0f7db5753eccf3"],"85ca0e073c286ebb2c89364ada6dd2740fc18880":["9299079153fd7895bf3cf6835cf7019af2ba89b3"],"8d15e34266d75e4e8b95da046cd0afc812367b38":["9299079153fd7895bf3cf6835cf7019af2ba89b3","8de18786ea000fc5fbc7214d571cc7f41d597ee3"],"fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f":["11c6df42fb3eba174c3ca0d9a5194eaecd893b77"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d14ffaac9c4a4a2c750bf0cd956506802561e062"],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":["0d49a158012a8ff48f328a4558e4bfcffbaed16f","8d15e34266d75e4e8b95da046cd0afc812367b38"],"fdc81126b07d75058a8395541b107b36f02ca9ac":["12320451a8cf581593c5eca6d2db98d299d693c7"],"c6f080a2ab37c464dd98db173f6cbf10dc74f211":["7f72557fc48bb36e35802ffb52580e40de88d40d","d14ffaac9c4a4a2c750bf0cd956506802561e062"],"c11c451a6e72282b9f57f81fb1e0878be67edcfd":["7afb64ff3a701f68b2689cafff6c5bdeb4f67f63"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["68496c2200e559fb7802f7575427b7a482659afb","11c6df42fb3eba174c3ca0d9a5194eaecd893b77"],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["d0ef034a4f10871667ae75181537775ddcf8ade4","ad2a673349939e48652bf304cccf673c3412198f"],"12320451a8cf581593c5eca6d2db98d299d693c7":["c11c451a6e72282b9f57f81fb1e0878be67edcfd"],"8a428f5314daaabf8eab7c50bdc3bc14e6cd1aa2":["fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"9299079153fd7895bf3cf6835cf7019af2ba89b3":["a87ce200bba7d88024e2f1c4012212072ce8a5ae"],"ad2a673349939e48652bf304cccf673c3412198f":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["8a428f5314daaabf8eab7c50bdc3bc14e6cd1aa2"],"d14ffaac9c4a4a2c750bf0cd956506802561e062":["7f72557fc48bb36e35802ffb52580e40de88d40d"],"0d49a158012a8ff48f328a4558e4bfcffbaed16f":["9299079153fd7895bf3cf6835cf7019af2ba89b3"]},"commit2Childs":{"11c6df42fb3eba174c3ca0d9a5194eaecd893b77":["fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"0e80cc3f88baf8f24df62207787944c7df9b75b9":["7f72557fc48bb36e35802ffb52580e40de88d40d"],"7afb64ff3a701f68b2689cafff6c5bdeb4f67f63":["c11c451a6e72282b9f57f81fb1e0878be67edcfd"],"7f72557fc48bb36e35802ffb52580e40de88d40d":["c6f080a2ab37c464dd98db173f6cbf10dc74f211","d14ffaac9c4a4a2c750bf0cd956506802561e062"],"8de18786ea000fc5fbc7214d571cc7f41d597ee3":["8d15e34266d75e4e8b95da046cd0afc812367b38"],"a87ce200bba7d88024e2f1c4012212072ce8a5ae":["9299079153fd7895bf3cf6835cf7019af2ba89b3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["7afb64ff3a701f68b2689cafff6c5bdeb4f67f63"],"68496c2200e559fb7802f7575427b7a482659afb":["11c6df42fb3eba174c3ca0d9a5194eaecd893b77","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"85ca0e073c286ebb2c89364ada6dd2740fc18880":["8de18786ea000fc5fbc7214d571cc7f41d597ee3"],"8d15e34266d75e4e8b95da046cd0afc812367b38":["68496c2200e559fb7802f7575427b7a482659afb","1e6acbaae7af722f17204ceccf0f7db5753eccf3"],"fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f":["8a428f5314daaabf8eab7c50bdc3bc14e6cd1aa2"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":["68496c2200e559fb7802f7575427b7a482659afb"],"fdc81126b07d75058a8395541b107b36f02ca9ac":["0e80cc3f88baf8f24df62207787944c7df9b75b9"],"c6f080a2ab37c464dd98db173f6cbf10dc74f211":[],"c11c451a6e72282b9f57f81fb1e0878be67edcfd":["12320451a8cf581593c5eca6d2db98d299d693c7"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["a87ce200bba7d88024e2f1c4012212072ce8a5ae"],"12320451a8cf581593c5eca6d2db98d299d693c7":["fdc81126b07d75058a8395541b107b36f02ca9ac"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["402ad3ddc9da7b70da1b167667a60ece6a1381fb","ad2a673349939e48652bf304cccf673c3412198f"],"8a428f5314daaabf8eab7c50bdc3bc14e6cd1aa2":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"9299079153fd7895bf3cf6835cf7019af2ba89b3":["85ca0e073c286ebb2c89364ada6dd2740fc18880","8d15e34266d75e4e8b95da046cd0afc812367b38","0d49a158012a8ff48f328a4558e4bfcffbaed16f"],"ad2a673349939e48652bf304cccf673c3412198f":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"d14ffaac9c4a4a2c750bf0cd956506802561e062":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","c6f080a2ab37c464dd98db173f6cbf10dc74f211"],"0d49a158012a8ff48f328a4558e4bfcffbaed16f":["1e6acbaae7af722f17204ceccf0f7db5753eccf3"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c6f080a2ab37c464dd98db173f6cbf10dc74f211","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}