{"path":"solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest#doRandomSortsOnLargeIndex().mjava","commits":[{"id":"d5bc8e25f59990525f5beb14afe9c96240dcf4a2","date":1389042945,"type":0,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest#doRandomSortsOnLargeIndex().mjava","pathOld":"/dev/null","sourceNew":"  /** randomized testing of a non-trivial number of docs using assertFullWalkNoDups \n   */\n  public void doRandomSortsOnLargeIndex() throws Exception {\n    final Collection<String> allFieldNames = getAllFieldNames();\n\n    final int initialDocs = _TestUtil.nextInt(random(),100,200);\n    final int totalDocs = atLeast(5000);\n\n    // start with a smallish number of documents, and test that we can do a full walk using a \n    // sort on *every* field in the schema...\n\n    for (int i = 1; i <= initialDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      indexDoc(doc);\n    }\n    commit();\n\n    for (String f : allFieldNames) {\n      for (String order : new String[] {\" asc\", \" desc\"}) {\n        String sort = f + order + (\"id\".equals(f) ? \"\" : \", id\" + order);\n        String rows = \"\" + _TestUtil.nextInt(random(),13,50);\n        SentinelIntSet ids = assertFullWalkNoDups(initialDocs, \n                                                  params(\"q\", \"*:*\",\n                                                         \"fl\",\"id\",\n                                                         \"rows\",rows,\n                                                         \"sort\",sort));\n        assertEquals(initialDocs, ids.size());\n      }\n    }\n\n    // now add a lot more docs, and test a handful of randomized multi-level sorts\n    for (int i = initialDocs+1; i <= totalDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      indexDoc(doc);\n    }\n    commit();\n\n    final int numRandomSorts = atLeast(5);\n    for (int i = 0; i < numRandomSorts; i++) {\n      final String sort = CursorPagingTest.buildRandomSort(allFieldNames);\n      final String rows = \"\" + _TestUtil.nextInt(random(),63,113);\n      final String fl = random().nextBoolean() ? \"id\" : \"id,score\";\n      final boolean matchAll = random().nextBoolean();\n      final String q = matchAll ? \"*:*\" : CursorPagingTest.buildRandomQuery();\n\n      SentinelIntSet ids = assertFullWalkNoDups(totalDocs, \n                                                params(\"q\", q,\n                                                       \"fl\",fl,\n                                                       \"rows\",rows,\n                                                       \"sort\",sort));\n      if (matchAll) {\n        assertEquals(totalDocs, ids.size());\n      }\n\n    }\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["c8257d69ecbfc2c790df7fa8b18953b9eb18b706"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cbd6d2ce12ab9b3bef6559744b54e95242cf5747","date":1390347163,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest#doRandomSortsOnLargeIndex().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest#doRandomSortsOnLargeIndex().mjava","sourceNew":"  /** randomized testing of a non-trivial number of docs using assertFullWalkNoDups \n   */\n  public void doRandomSortsOnLargeIndex() throws Exception {\n    final Collection<String> allFieldNames = getAllFieldNames();\n\n    final int initialDocs = _TestUtil.nextInt(random(),100,200);\n    final int totalDocs = atLeast(5000);\n\n    // start with a smallish number of documents, and test that we can do a full walk using a \n    // sort on *every* field in the schema...\n\n    for (int i = 1; i <= initialDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      indexDoc(doc);\n    }\n    commit();\n\n    log.info(\"SOLR-5652: Begining Loop over smallish num of docs\");\n    final boolean SOLR_5652 = true;\n\n    for (String f : allFieldNames) {\n      for (String order : new String[] {\" asc\", \" desc\"}) {\n        String sort = f + order + (\"id\".equals(f) ? \"\" : \", id\" + order);\n        String rows = \"\" + _TestUtil.nextInt(random(),13,50);\n        SentinelIntSet ids = assertFullWalkNoDups(SOLR_5652,\n                                                  initialDocs, \n                                                  params(\"q\", \"*:*\",\n                                                         \"fl\",\"id,\"+f,\n                                                         \"rows\",rows,\n                                                         \"sort\",sort));\n        assertEquals(initialDocs, ids.size());\n      }\n    }\n\n    log.info(\"SOLR-5652: Ending Loop over smallish num of docs\");\n\n    // now add a lot more docs, and test a handful of randomized multi-level sorts\n    for (int i = initialDocs+1; i <= totalDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      indexDoc(doc);\n    }\n    commit();\n\n    final int numRandomSorts = atLeast(5);\n    for (int i = 0; i < numRandomSorts; i++) {\n      final String sort = CursorPagingTest.buildRandomSort(allFieldNames);\n      final String rows = \"\" + _TestUtil.nextInt(random(),63,113);\n      final String fl = random().nextBoolean() ? \"id\" : \"id,score\";\n      final boolean matchAll = random().nextBoolean();\n      final String q = matchAll ? \"*:*\" : CursorPagingTest.buildRandomQuery();\n\n      SentinelIntSet ids = assertFullWalkNoDups(totalDocs, \n                                                params(\"q\", q,\n                                                       \"fl\",fl,\n                                                       \"rows\",rows,\n                                                       \"sort\",sort));\n      if (matchAll) {\n        assertEquals(totalDocs, ids.size());\n      }\n\n    }\n\n  }\n\n","sourceOld":"  /** randomized testing of a non-trivial number of docs using assertFullWalkNoDups \n   */\n  public void doRandomSortsOnLargeIndex() throws Exception {\n    final Collection<String> allFieldNames = getAllFieldNames();\n\n    final int initialDocs = _TestUtil.nextInt(random(),100,200);\n    final int totalDocs = atLeast(5000);\n\n    // start with a smallish number of documents, and test that we can do a full walk using a \n    // sort on *every* field in the schema...\n\n    for (int i = 1; i <= initialDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      indexDoc(doc);\n    }\n    commit();\n\n    for (String f : allFieldNames) {\n      for (String order : new String[] {\" asc\", \" desc\"}) {\n        String sort = f + order + (\"id\".equals(f) ? \"\" : \", id\" + order);\n        String rows = \"\" + _TestUtil.nextInt(random(),13,50);\n        SentinelIntSet ids = assertFullWalkNoDups(initialDocs, \n                                                  params(\"q\", \"*:*\",\n                                                         \"fl\",\"id\",\n                                                         \"rows\",rows,\n                                                         \"sort\",sort));\n        assertEquals(initialDocs, ids.size());\n      }\n    }\n\n    // now add a lot more docs, and test a handful of randomized multi-level sorts\n    for (int i = initialDocs+1; i <= totalDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      indexDoc(doc);\n    }\n    commit();\n\n    final int numRandomSorts = atLeast(5);\n    for (int i = 0; i < numRandomSorts; i++) {\n      final String sort = CursorPagingTest.buildRandomSort(allFieldNames);\n      final String rows = \"\" + _TestUtil.nextInt(random(),63,113);\n      final String fl = random().nextBoolean() ? \"id\" : \"id,score\";\n      final boolean matchAll = random().nextBoolean();\n      final String q = matchAll ? \"*:*\" : CursorPagingTest.buildRandomQuery();\n\n      SentinelIntSet ids = assertFullWalkNoDups(totalDocs, \n                                                params(\"q\", q,\n                                                       \"fl\",fl,\n                                                       \"rows\",rows,\n                                                       \"sort\",sort));\n      if (matchAll) {\n        assertEquals(totalDocs, ids.size());\n      }\n\n    }\n\n  }\n\n","bugFix":null,"bugIntro":["c8257d69ecbfc2c790df7fa8b18953b9eb18b706","df168f752ac3120a6e38cebfc8fc77722d6b2d20"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c8257d69ecbfc2c790df7fa8b18953b9eb18b706","date":1390836101,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest#doRandomSortsOnLargeIndex().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest#doRandomSortsOnLargeIndex().mjava","sourceNew":"  /** randomized testing of a non-trivial number of docs using assertFullWalkNoDups \n   */\n  public void doRandomSortsOnLargeIndex() throws Exception {\n    final Collection<String> allFieldNames = getAllFieldNames();\n\n    final int numInitialDocs = _TestUtil.nextInt(random(),100,200);\n    final int totalDocs = atLeast(5000);\n\n    // start with a smallish number of documents, and test that we can do a full walk using a \n    // sort on *every* field in the schema...\n\n    List<SolrInputDocument> initialDocs = new ArrayList<SolrInputDocument>();\n    for (int i = 1; i <= numInitialDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      initialDocs.add(doc);\n      indexDoc(doc);\n    }\n    commit();\n\n    log.info(\"SOLR-5652: Begining Loop over smallish num of docs\");\n    final boolean SOLR_5652 = true;\n\n    for (String f : allFieldNames) {\n      for (String order : new String[] {\" asc\", \" desc\"}) {\n        String sort = f + order + (\"id\".equals(f) ? \"\" : \", id\" + order);\n        String rows = \"\" + _TestUtil.nextInt(random(),13,50);\n        SentinelIntSet ids = assertFullWalkNoDups(SOLR_5652,\n                                                  numInitialDocs,\n                                                  params(\"q\", \"*:*\",\n                                                         \"fl\",\"id,\"+f,\n                                                         \"rows\",rows,\n                                                         \"sort\",sort));\n        if (numInitialDocs != ids.size()) {\n          StringBuilder message = new StringBuilder\n              (\"Expected \" + numInitialDocs + \" docs but got \" + ids.size() + \". \");\n          message.append(\"sort=\");\n          message.append(sort);\n          message.append(\". \");\n          if (ids.size() < numInitialDocs) {\n            message.append(\"Missing doc(s): \");\n            for (SolrInputDocument doc : initialDocs) {\n              int id = ((Integer)doc.get(\"id\").getValue()).intValue();\n              if ( ! ids.exists(id)) {\n                QueryResponse rsp = cloudClient.query(params(\"q\", \"id:\" + id,\n                                                             \"rows\", \"1\"));\n                if (0 == rsp.getResults().size()) {\n                  message.append(\"<NOT RETRIEVABLE>:\");\n                  message.append(doc.values());\n                } else {\n                  message.append(rsp.getResults().get(0).getFieldValueMap().toString());\n                }\n                message.append(\"; \");\n              }\n            }\n          }\n          fail(message.toString());\n        }\n      }\n    }\n\n    log.info(\"SOLR-5652: Ending Loop over smallish num of docs\");\n\n    // now add a lot more docs, and test a handful of randomized multi-level sorts\n    for (int i = numInitialDocs+1; i <= totalDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      indexDoc(doc);\n    }\n    commit();\n\n    final int numRandomSorts = atLeast(5);\n    for (int i = 0; i < numRandomSorts; i++) {\n      final String sort = CursorPagingTest.buildRandomSort(allFieldNames);\n      final String rows = \"\" + _TestUtil.nextInt(random(),63,113);\n      final String fl = random().nextBoolean() ? \"id\" : \"id,score\";\n      final boolean matchAll = random().nextBoolean();\n      final String q = matchAll ? \"*:*\" : CursorPagingTest.buildRandomQuery();\n\n      SentinelIntSet ids = assertFullWalkNoDups(totalDocs,\n                                                params(\"q\", q,\n                                                       \"fl\",fl,\n                                                       \"rows\",rows,\n                                                       \"sort\",sort));\n      if (matchAll) {\n        assertEquals(totalDocs, ids.size());\n      }\n\n    }\n\n  }\n\n","sourceOld":"  /** randomized testing of a non-trivial number of docs using assertFullWalkNoDups \n   */\n  public void doRandomSortsOnLargeIndex() throws Exception {\n    final Collection<String> allFieldNames = getAllFieldNames();\n\n    final int initialDocs = _TestUtil.nextInt(random(),100,200);\n    final int totalDocs = atLeast(5000);\n\n    // start with a smallish number of documents, and test that we can do a full walk using a \n    // sort on *every* field in the schema...\n\n    for (int i = 1; i <= initialDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      indexDoc(doc);\n    }\n    commit();\n\n    log.info(\"SOLR-5652: Begining Loop over smallish num of docs\");\n    final boolean SOLR_5652 = true;\n\n    for (String f : allFieldNames) {\n      for (String order : new String[] {\" asc\", \" desc\"}) {\n        String sort = f + order + (\"id\".equals(f) ? \"\" : \", id\" + order);\n        String rows = \"\" + _TestUtil.nextInt(random(),13,50);\n        SentinelIntSet ids = assertFullWalkNoDups(SOLR_5652,\n                                                  initialDocs, \n                                                  params(\"q\", \"*:*\",\n                                                         \"fl\",\"id,\"+f,\n                                                         \"rows\",rows,\n                                                         \"sort\",sort));\n        assertEquals(initialDocs, ids.size());\n      }\n    }\n\n    log.info(\"SOLR-5652: Ending Loop over smallish num of docs\");\n\n    // now add a lot more docs, and test a handful of randomized multi-level sorts\n    for (int i = initialDocs+1; i <= totalDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      indexDoc(doc);\n    }\n    commit();\n\n    final int numRandomSorts = atLeast(5);\n    for (int i = 0; i < numRandomSorts; i++) {\n      final String sort = CursorPagingTest.buildRandomSort(allFieldNames);\n      final String rows = \"\" + _TestUtil.nextInt(random(),63,113);\n      final String fl = random().nextBoolean() ? \"id\" : \"id,score\";\n      final boolean matchAll = random().nextBoolean();\n      final String q = matchAll ? \"*:*\" : CursorPagingTest.buildRandomQuery();\n\n      SentinelIntSet ids = assertFullWalkNoDups(totalDocs, \n                                                params(\"q\", q,\n                                                       \"fl\",fl,\n                                                       \"rows\",rows,\n                                                       \"sort\",sort));\n      if (matchAll) {\n        assertEquals(totalDocs, ids.size());\n      }\n\n    }\n\n  }\n\n","bugFix":["cbd6d2ce12ab9b3bef6559744b54e95242cf5747","d5bc8e25f59990525f5beb14afe9c96240dcf4a2"],"bugIntro":["df168f752ac3120a6e38cebfc8fc77722d6b2d20"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6a0f9b793b360e5f5863eef2d4b02a2ddd8b47b4","date":1390935815,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest#doRandomSortsOnLargeIndex().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest#doRandomSortsOnLargeIndex().mjava","sourceNew":"  /** randomized testing of a non-trivial number of docs using assertFullWalkNoDups \n   */\n  public void doRandomSortsOnLargeIndex() throws Exception {\n    final Collection<String> allFieldNames = getAllSortFieldNames();\n\n    final int numInitialDocs = _TestUtil.nextInt(random(),100,200);\n    final int totalDocs = atLeast(5000);\n\n    // start with a smallish number of documents, and test that we can do a full walk using a \n    // sort on *every* field in the schema...\n\n    List<SolrInputDocument> initialDocs = new ArrayList<SolrInputDocument>();\n    for (int i = 1; i <= numInitialDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      initialDocs.add(doc);\n      indexDoc(doc);\n    }\n    commit();\n\n    log.info(\"SOLR-5652: Begining Loop over smallish num of docs\");\n    final boolean SOLR_5652 = true;\n\n    for (String f : allFieldNames) {\n      for (String order : new String[] {\" asc\", \" desc\"}) {\n        String sort = f + order + (\"id\".equals(f) ? \"\" : \", id\" + order);\n        String rows = \"\" + _TestUtil.nextInt(random(),13,50);\n        SentinelIntSet ids = assertFullWalkNoDups(SOLR_5652,\n                                                  numInitialDocs,\n                                                  params(\"q\", \"*:*\",\n                                                         \"fl\",\"id,\"+f,\n                                                         \"rows\",rows,\n                                                         \"sort\",sort));\n        if (numInitialDocs != ids.size()) {\n          StringBuilder message = new StringBuilder\n              (\"Expected \" + numInitialDocs + \" docs but got \" + ids.size() + \". \");\n          message.append(\"sort=\");\n          message.append(sort);\n          message.append(\". \");\n          if (ids.size() < numInitialDocs) {\n            message.append(\"Missing doc(s): \");\n            for (SolrInputDocument doc : initialDocs) {\n              int id = ((Integer)doc.get(\"id\").getValue()).intValue();\n              if ( ! ids.exists(id)) {\n                QueryResponse rsp = cloudClient.query(params(\"q\", \"id:\" + id,\n                                                             \"rows\", \"1\"));\n                if (0 == rsp.getResults().size()) {\n                  message.append(\"<NOT RETRIEVABLE>:\");\n                  message.append(doc.values());\n                } else {\n                  message.append(rsp.getResults().get(0).getFieldValueMap().toString());\n                }\n                message.append(\"; \");\n              }\n            }\n          }\n          fail(message.toString());\n        }\n      }\n    }\n\n    log.info(\"SOLR-5652: Ending Loop over smallish num of docs\");\n\n    // now add a lot more docs, and test a handful of randomized multi-level sorts\n    for (int i = numInitialDocs+1; i <= totalDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      indexDoc(doc);\n    }\n    commit();\n\n    final int numRandomSorts = atLeast(5);\n    for (int i = 0; i < numRandomSorts; i++) {\n      final String sort = CursorPagingTest.buildRandomSort(allFieldNames);\n      final String rows = \"\" + _TestUtil.nextInt(random(),63,113);\n      final String fl = random().nextBoolean() ? \"id\" : \"id,score\";\n      final boolean matchAll = random().nextBoolean();\n      final String q = matchAll ? \"*:*\" : CursorPagingTest.buildRandomQuery();\n\n      SentinelIntSet ids = assertFullWalkNoDups(totalDocs,\n                                                params(\"q\", q,\n                                                       \"fl\",fl,\n                                                       \"rows\",rows,\n                                                       \"sort\",sort));\n      if (matchAll) {\n        assertEquals(totalDocs, ids.size());\n      }\n\n    }\n\n  }\n\n","sourceOld":"  /** randomized testing of a non-trivial number of docs using assertFullWalkNoDups \n   */\n  public void doRandomSortsOnLargeIndex() throws Exception {\n    final Collection<String> allFieldNames = getAllFieldNames();\n\n    final int numInitialDocs = _TestUtil.nextInt(random(),100,200);\n    final int totalDocs = atLeast(5000);\n\n    // start with a smallish number of documents, and test that we can do a full walk using a \n    // sort on *every* field in the schema...\n\n    List<SolrInputDocument> initialDocs = new ArrayList<SolrInputDocument>();\n    for (int i = 1; i <= numInitialDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      initialDocs.add(doc);\n      indexDoc(doc);\n    }\n    commit();\n\n    log.info(\"SOLR-5652: Begining Loop over smallish num of docs\");\n    final boolean SOLR_5652 = true;\n\n    for (String f : allFieldNames) {\n      for (String order : new String[] {\" asc\", \" desc\"}) {\n        String sort = f + order + (\"id\".equals(f) ? \"\" : \", id\" + order);\n        String rows = \"\" + _TestUtil.nextInt(random(),13,50);\n        SentinelIntSet ids = assertFullWalkNoDups(SOLR_5652,\n                                                  numInitialDocs,\n                                                  params(\"q\", \"*:*\",\n                                                         \"fl\",\"id,\"+f,\n                                                         \"rows\",rows,\n                                                         \"sort\",sort));\n        if (numInitialDocs != ids.size()) {\n          StringBuilder message = new StringBuilder\n              (\"Expected \" + numInitialDocs + \" docs but got \" + ids.size() + \". \");\n          message.append(\"sort=\");\n          message.append(sort);\n          message.append(\". \");\n          if (ids.size() < numInitialDocs) {\n            message.append(\"Missing doc(s): \");\n            for (SolrInputDocument doc : initialDocs) {\n              int id = ((Integer)doc.get(\"id\").getValue()).intValue();\n              if ( ! ids.exists(id)) {\n                QueryResponse rsp = cloudClient.query(params(\"q\", \"id:\" + id,\n                                                             \"rows\", \"1\"));\n                if (0 == rsp.getResults().size()) {\n                  message.append(\"<NOT RETRIEVABLE>:\");\n                  message.append(doc.values());\n                } else {\n                  message.append(rsp.getResults().get(0).getFieldValueMap().toString());\n                }\n                message.append(\"; \");\n              }\n            }\n          }\n          fail(message.toString());\n        }\n      }\n    }\n\n    log.info(\"SOLR-5652: Ending Loop over smallish num of docs\");\n\n    // now add a lot more docs, and test a handful of randomized multi-level sorts\n    for (int i = numInitialDocs+1; i <= totalDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      indexDoc(doc);\n    }\n    commit();\n\n    final int numRandomSorts = atLeast(5);\n    for (int i = 0; i < numRandomSorts; i++) {\n      final String sort = CursorPagingTest.buildRandomSort(allFieldNames);\n      final String rows = \"\" + _TestUtil.nextInt(random(),63,113);\n      final String fl = random().nextBoolean() ? \"id\" : \"id,score\";\n      final boolean matchAll = random().nextBoolean();\n      final String q = matchAll ? \"*:*\" : CursorPagingTest.buildRandomQuery();\n\n      SentinelIntSet ids = assertFullWalkNoDups(totalDocs,\n                                                params(\"q\", q,\n                                                       \"fl\",fl,\n                                                       \"rows\",rows,\n                                                       \"sort\",sort));\n      if (matchAll) {\n        assertEquals(totalDocs, ids.size());\n      }\n\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"df168f752ac3120a6e38cebfc8fc77722d6b2d20","date":1392501538,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest#doRandomSortsOnLargeIndex().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest#doRandomSortsOnLargeIndex().mjava","sourceNew":"  /** randomized testing of a non-trivial number of docs using assertFullWalkNoDups \n   */\n  public void doRandomSortsOnLargeIndex() throws Exception {\n    final Collection<String> allFieldNames = getAllSortFieldNames();\n\n    final int numInitialDocs = _TestUtil.nextInt(random(),100,200);\n    final int totalDocs = atLeast(5000);\n\n    // start with a smallish number of documents, and test that we can do a full walk using a \n    // sort on *every* field in the schema...\n\n    List<SolrInputDocument> initialDocs = new ArrayList<SolrInputDocument>();\n    for (int i = 1; i <= numInitialDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      initialDocs.add(doc);\n      indexDoc(doc);\n    }\n    commit();\n\n    for (String f : allFieldNames) {\n      for (String order : new String[] {\" asc\", \" desc\"}) {\n        String sort = f + order + (\"id\".equals(f) ? \"\" : \", id\" + order);\n        String rows = \"\" + _TestUtil.nextInt(random(),13,50);\n        SentinelIntSet ids = assertFullWalkNoDups(numInitialDocs,\n                                                  params(\"q\", \"*:*\",\n                                                         \"fl\",\"id,\"+f,\n                                                         \"rows\",rows,\n                                                         \"sort\",sort));\n        if (numInitialDocs != ids.size()) {\n          StringBuilder message = new StringBuilder\n              (\"Expected \" + numInitialDocs + \" docs but got \" + ids.size() + \". \");\n          message.append(\"sort=\");\n          message.append(sort);\n          message.append(\". \");\n          if (ids.size() < numInitialDocs) {\n            message.append(\"Missing doc(s): \");\n            for (SolrInputDocument doc : initialDocs) {\n              int id = ((Integer)doc.get(\"id\").getValue()).intValue();\n              if ( ! ids.exists(id)) {\n                QueryResponse rsp = cloudClient.query(params(\"q\", \"id:\" + id,\n                                                             \"rows\", \"1\"));\n                if (0 == rsp.getResults().size()) {\n                  message.append(\"<NOT RETRIEVABLE>:\");\n                  message.append(doc.values());\n                } else {\n                  message.append(rsp.getResults().get(0).getFieldValueMap().toString());\n                }\n                message.append(\"; \");\n              }\n            }\n          }\n          fail(message.toString());\n        }\n      }\n    }\n\n    // now add a lot more docs, and test a handful of randomized multi-level sorts\n    for (int i = numInitialDocs+1; i <= totalDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      indexDoc(doc);\n    }\n    commit();\n\n    final int numRandomSorts = atLeast(5);\n    for (int i = 0; i < numRandomSorts; i++) {\n      final String sort = CursorPagingTest.buildRandomSort(allFieldNames);\n      final String rows = \"\" + _TestUtil.nextInt(random(),63,113);\n      final String fl = random().nextBoolean() ? \"id\" : \"id,score\";\n      final boolean matchAll = random().nextBoolean();\n      final String q = matchAll ? \"*:*\" : CursorPagingTest.buildRandomQuery();\n\n      SentinelIntSet ids = assertFullWalkNoDups(totalDocs,\n                                                params(\"q\", q,\n                                                       \"fl\",fl,\n                                                       \"rows\",rows,\n                                                       \"sort\",sort));\n      if (matchAll) {\n        assertEquals(totalDocs, ids.size());\n      }\n\n    }\n\n  }\n\n","sourceOld":"  /** randomized testing of a non-trivial number of docs using assertFullWalkNoDups \n   */\n  public void doRandomSortsOnLargeIndex() throws Exception {\n    final Collection<String> allFieldNames = getAllSortFieldNames();\n\n    final int numInitialDocs = _TestUtil.nextInt(random(),100,200);\n    final int totalDocs = atLeast(5000);\n\n    // start with a smallish number of documents, and test that we can do a full walk using a \n    // sort on *every* field in the schema...\n\n    List<SolrInputDocument> initialDocs = new ArrayList<SolrInputDocument>();\n    for (int i = 1; i <= numInitialDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      initialDocs.add(doc);\n      indexDoc(doc);\n    }\n    commit();\n\n    log.info(\"SOLR-5652: Begining Loop over smallish num of docs\");\n    final boolean SOLR_5652 = true;\n\n    for (String f : allFieldNames) {\n      for (String order : new String[] {\" asc\", \" desc\"}) {\n        String sort = f + order + (\"id\".equals(f) ? \"\" : \", id\" + order);\n        String rows = \"\" + _TestUtil.nextInt(random(),13,50);\n        SentinelIntSet ids = assertFullWalkNoDups(SOLR_5652,\n                                                  numInitialDocs,\n                                                  params(\"q\", \"*:*\",\n                                                         \"fl\",\"id,\"+f,\n                                                         \"rows\",rows,\n                                                         \"sort\",sort));\n        if (numInitialDocs != ids.size()) {\n          StringBuilder message = new StringBuilder\n              (\"Expected \" + numInitialDocs + \" docs but got \" + ids.size() + \". \");\n          message.append(\"sort=\");\n          message.append(sort);\n          message.append(\". \");\n          if (ids.size() < numInitialDocs) {\n            message.append(\"Missing doc(s): \");\n            for (SolrInputDocument doc : initialDocs) {\n              int id = ((Integer)doc.get(\"id\").getValue()).intValue();\n              if ( ! ids.exists(id)) {\n                QueryResponse rsp = cloudClient.query(params(\"q\", \"id:\" + id,\n                                                             \"rows\", \"1\"));\n                if (0 == rsp.getResults().size()) {\n                  message.append(\"<NOT RETRIEVABLE>:\");\n                  message.append(doc.values());\n                } else {\n                  message.append(rsp.getResults().get(0).getFieldValueMap().toString());\n                }\n                message.append(\"; \");\n              }\n            }\n          }\n          fail(message.toString());\n        }\n      }\n    }\n\n    log.info(\"SOLR-5652: Ending Loop over smallish num of docs\");\n\n    // now add a lot more docs, and test a handful of randomized multi-level sorts\n    for (int i = numInitialDocs+1; i <= totalDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      indexDoc(doc);\n    }\n    commit();\n\n    final int numRandomSorts = atLeast(5);\n    for (int i = 0; i < numRandomSorts; i++) {\n      final String sort = CursorPagingTest.buildRandomSort(allFieldNames);\n      final String rows = \"\" + _TestUtil.nextInt(random(),63,113);\n      final String fl = random().nextBoolean() ? \"id\" : \"id,score\";\n      final boolean matchAll = random().nextBoolean();\n      final String q = matchAll ? \"*:*\" : CursorPagingTest.buildRandomQuery();\n\n      SentinelIntSet ids = assertFullWalkNoDups(totalDocs,\n                                                params(\"q\", q,\n                                                       \"fl\",fl,\n                                                       \"rows\",rows,\n                                                       \"sort\",sort));\n      if (matchAll) {\n        assertEquals(totalDocs, ids.size());\n      }\n\n    }\n\n  }\n\n","bugFix":["cbd6d2ce12ab9b3bef6559744b54e95242cf5747","c8257d69ecbfc2c790df7fa8b18953b9eb18b706"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest#doRandomSortsOnLargeIndex().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest#doRandomSortsOnLargeIndex().mjava","sourceNew":"  /** randomized testing of a non-trivial number of docs using assertFullWalkNoDups \n   */\n  public void doRandomSortsOnLargeIndex() throws Exception {\n    final Collection<String> allFieldNames = getAllSortFieldNames();\n\n    final int numInitialDocs = TestUtil.nextInt(random(), 100, 200);\n    final int totalDocs = atLeast(5000);\n\n    // start with a smallish number of documents, and test that we can do a full walk using a \n    // sort on *every* field in the schema...\n\n    List<SolrInputDocument> initialDocs = new ArrayList<SolrInputDocument>();\n    for (int i = 1; i <= numInitialDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      initialDocs.add(doc);\n      indexDoc(doc);\n    }\n    commit();\n\n    for (String f : allFieldNames) {\n      for (String order : new String[] {\" asc\", \" desc\"}) {\n        String sort = f + order + (\"id\".equals(f) ? \"\" : \", id\" + order);\n        String rows = \"\" + TestUtil.nextInt(random(), 13, 50);\n        SentinelIntSet ids = assertFullWalkNoDups(numInitialDocs,\n                                                  params(\"q\", \"*:*\",\n                                                         \"fl\",\"id,\"+f,\n                                                         \"rows\",rows,\n                                                         \"sort\",sort));\n        if (numInitialDocs != ids.size()) {\n          StringBuilder message = new StringBuilder\n              (\"Expected \" + numInitialDocs + \" docs but got \" + ids.size() + \". \");\n          message.append(\"sort=\");\n          message.append(sort);\n          message.append(\". \");\n          if (ids.size() < numInitialDocs) {\n            message.append(\"Missing doc(s): \");\n            for (SolrInputDocument doc : initialDocs) {\n              int id = ((Integer)doc.get(\"id\").getValue()).intValue();\n              if ( ! ids.exists(id)) {\n                QueryResponse rsp = cloudClient.query(params(\"q\", \"id:\" + id,\n                                                             \"rows\", \"1\"));\n                if (0 == rsp.getResults().size()) {\n                  message.append(\"<NOT RETRIEVABLE>:\");\n                  message.append(doc.values());\n                } else {\n                  message.append(rsp.getResults().get(0).getFieldValueMap().toString());\n                }\n                message.append(\"; \");\n              }\n            }\n          }\n          fail(message.toString());\n        }\n      }\n    }\n\n    // now add a lot more docs, and test a handful of randomized multi-level sorts\n    for (int i = numInitialDocs+1; i <= totalDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      indexDoc(doc);\n    }\n    commit();\n\n    final int numRandomSorts = atLeast(5);\n    for (int i = 0; i < numRandomSorts; i++) {\n      final String sort = CursorPagingTest.buildRandomSort(allFieldNames);\n      final String rows = \"\" + TestUtil.nextInt(random(), 63, 113);\n      final String fl = random().nextBoolean() ? \"id\" : \"id,score\";\n      final boolean matchAll = random().nextBoolean();\n      final String q = matchAll ? \"*:*\" : CursorPagingTest.buildRandomQuery();\n\n      SentinelIntSet ids = assertFullWalkNoDups(totalDocs,\n                                                params(\"q\", q,\n                                                       \"fl\",fl,\n                                                       \"rows\",rows,\n                                                       \"sort\",sort));\n      if (matchAll) {\n        assertEquals(totalDocs, ids.size());\n      }\n\n    }\n\n  }\n\n","sourceOld":"  /** randomized testing of a non-trivial number of docs using assertFullWalkNoDups \n   */\n  public void doRandomSortsOnLargeIndex() throws Exception {\n    final Collection<String> allFieldNames = getAllSortFieldNames();\n\n    final int numInitialDocs = _TestUtil.nextInt(random(),100,200);\n    final int totalDocs = atLeast(5000);\n\n    // start with a smallish number of documents, and test that we can do a full walk using a \n    // sort on *every* field in the schema...\n\n    List<SolrInputDocument> initialDocs = new ArrayList<SolrInputDocument>();\n    for (int i = 1; i <= numInitialDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      initialDocs.add(doc);\n      indexDoc(doc);\n    }\n    commit();\n\n    for (String f : allFieldNames) {\n      for (String order : new String[] {\" asc\", \" desc\"}) {\n        String sort = f + order + (\"id\".equals(f) ? \"\" : \", id\" + order);\n        String rows = \"\" + _TestUtil.nextInt(random(),13,50);\n        SentinelIntSet ids = assertFullWalkNoDups(numInitialDocs,\n                                                  params(\"q\", \"*:*\",\n                                                         \"fl\",\"id,\"+f,\n                                                         \"rows\",rows,\n                                                         \"sort\",sort));\n        if (numInitialDocs != ids.size()) {\n          StringBuilder message = new StringBuilder\n              (\"Expected \" + numInitialDocs + \" docs but got \" + ids.size() + \". \");\n          message.append(\"sort=\");\n          message.append(sort);\n          message.append(\". \");\n          if (ids.size() < numInitialDocs) {\n            message.append(\"Missing doc(s): \");\n            for (SolrInputDocument doc : initialDocs) {\n              int id = ((Integer)doc.get(\"id\").getValue()).intValue();\n              if ( ! ids.exists(id)) {\n                QueryResponse rsp = cloudClient.query(params(\"q\", \"id:\" + id,\n                                                             \"rows\", \"1\"));\n                if (0 == rsp.getResults().size()) {\n                  message.append(\"<NOT RETRIEVABLE>:\");\n                  message.append(doc.values());\n                } else {\n                  message.append(rsp.getResults().get(0).getFieldValueMap().toString());\n                }\n                message.append(\"; \");\n              }\n            }\n          }\n          fail(message.toString());\n        }\n      }\n    }\n\n    // now add a lot more docs, and test a handful of randomized multi-level sorts\n    for (int i = numInitialDocs+1; i <= totalDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      indexDoc(doc);\n    }\n    commit();\n\n    final int numRandomSorts = atLeast(5);\n    for (int i = 0; i < numRandomSorts; i++) {\n      final String sort = CursorPagingTest.buildRandomSort(allFieldNames);\n      final String rows = \"\" + _TestUtil.nextInt(random(),63,113);\n      final String fl = random().nextBoolean() ? \"id\" : \"id,score\";\n      final boolean matchAll = random().nextBoolean();\n      final String q = matchAll ? \"*:*\" : CursorPagingTest.buildRandomQuery();\n\n      SentinelIntSet ids = assertFullWalkNoDups(totalDocs,\n                                                params(\"q\", q,\n                                                       \"fl\",fl,\n                                                       \"rows\",rows,\n                                                       \"sort\",sort));\n      if (matchAll) {\n        assertEquals(totalDocs, ids.size());\n      }\n\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3d0814e12c6e2b86cf23048e6310a3715a8f6ea5","date":1393541825,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest#doRandomSortsOnLargeIndex().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest#doRandomSortsOnLargeIndex().mjava","sourceNew":"  /** randomized testing of a non-trivial number of docs using assertFullWalkNoDups \n   */\n  public void doRandomSortsOnLargeIndex() throws Exception {\n    final Collection<String> allFieldNames = getAllSortFieldNames();\n\n    final int numInitialDocs = TestUtil.nextInt(random(), 100, 200);\n    final int totalDocs = atLeast(500);\n\n    // start with a smallish number of documents, and test that we can do a full walk using a \n    // sort on *every* field in the schema...\n\n    List<SolrInputDocument> initialDocs = new ArrayList<SolrInputDocument>();\n    for (int i = 1; i <= numInitialDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      initialDocs.add(doc);\n      indexDoc(doc);\n    }\n    commit();\n\n    for (String f : allFieldNames) {\n      for (String order : new String[] {\" asc\", \" desc\"}) {\n        String sort = f + order + (\"id\".equals(f) ? \"\" : \", id\" + order);\n        String rows = \"\" + TestUtil.nextInt(random(), 13, 50);\n        SentinelIntSet ids = assertFullWalkNoDups(numInitialDocs,\n                                                  params(\"q\", \"*:*\",\n                                                         \"fl\",\"id,\"+f,\n                                                         \"rows\",rows,\n                                                         \"sort\",sort));\n        if (numInitialDocs != ids.size()) {\n          StringBuilder message = new StringBuilder\n              (\"Expected \" + numInitialDocs + \" docs but got \" + ids.size() + \". \");\n          message.append(\"sort=\");\n          message.append(sort);\n          message.append(\". \");\n          if (ids.size() < numInitialDocs) {\n            message.append(\"Missing doc(s): \");\n            for (SolrInputDocument doc : initialDocs) {\n              int id = ((Integer)doc.get(\"id\").getValue()).intValue();\n              if ( ! ids.exists(id)) {\n                QueryResponse rsp = cloudClient.query(params(\"q\", \"id:\" + id,\n                                                             \"rows\", \"1\"));\n                if (0 == rsp.getResults().size()) {\n                  message.append(\"<NOT RETRIEVABLE>:\");\n                  message.append(doc.values());\n                } else {\n                  message.append(rsp.getResults().get(0).getFieldValueMap().toString());\n                }\n                message.append(\"; \");\n              }\n            }\n          }\n          fail(message.toString());\n        }\n      }\n    }\n\n    // now add a lot more docs, and test a handful of randomized multi-level sorts\n    for (int i = numInitialDocs+1; i <= totalDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      indexDoc(doc);\n    }\n    commit();\n\n    final int numRandomSorts = atLeast(3);\n    for (int i = 0; i < numRandomSorts; i++) {\n      final String sort = CursorPagingTest.buildRandomSort(allFieldNames);\n      final String rows = \"\" + TestUtil.nextInt(random(), 63, 113);\n      final String fl = random().nextBoolean() ? \"id\" : \"id,score\";\n      final boolean matchAll = random().nextBoolean();\n      final String q = matchAll ? \"*:*\" : CursorPagingTest.buildRandomQuery();\n\n      SentinelIntSet ids = assertFullWalkNoDups(totalDocs,\n                                                params(\"q\", q,\n                                                       \"fl\",fl,\n                                                       \"rows\",rows,\n                                                       \"sort\",sort));\n      if (matchAll) {\n        assertEquals(totalDocs, ids.size());\n      }\n\n    }\n\n  }\n\n","sourceOld":"  /** randomized testing of a non-trivial number of docs using assertFullWalkNoDups \n   */\n  public void doRandomSortsOnLargeIndex() throws Exception {\n    final Collection<String> allFieldNames = getAllSortFieldNames();\n\n    final int numInitialDocs = TestUtil.nextInt(random(), 100, 200);\n    final int totalDocs = atLeast(5000);\n\n    // start with a smallish number of documents, and test that we can do a full walk using a \n    // sort on *every* field in the schema...\n\n    List<SolrInputDocument> initialDocs = new ArrayList<SolrInputDocument>();\n    for (int i = 1; i <= numInitialDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      initialDocs.add(doc);\n      indexDoc(doc);\n    }\n    commit();\n\n    for (String f : allFieldNames) {\n      for (String order : new String[] {\" asc\", \" desc\"}) {\n        String sort = f + order + (\"id\".equals(f) ? \"\" : \", id\" + order);\n        String rows = \"\" + TestUtil.nextInt(random(), 13, 50);\n        SentinelIntSet ids = assertFullWalkNoDups(numInitialDocs,\n                                                  params(\"q\", \"*:*\",\n                                                         \"fl\",\"id,\"+f,\n                                                         \"rows\",rows,\n                                                         \"sort\",sort));\n        if (numInitialDocs != ids.size()) {\n          StringBuilder message = new StringBuilder\n              (\"Expected \" + numInitialDocs + \" docs but got \" + ids.size() + \". \");\n          message.append(\"sort=\");\n          message.append(sort);\n          message.append(\". \");\n          if (ids.size() < numInitialDocs) {\n            message.append(\"Missing doc(s): \");\n            for (SolrInputDocument doc : initialDocs) {\n              int id = ((Integer)doc.get(\"id\").getValue()).intValue();\n              if ( ! ids.exists(id)) {\n                QueryResponse rsp = cloudClient.query(params(\"q\", \"id:\" + id,\n                                                             \"rows\", \"1\"));\n                if (0 == rsp.getResults().size()) {\n                  message.append(\"<NOT RETRIEVABLE>:\");\n                  message.append(doc.values());\n                } else {\n                  message.append(rsp.getResults().get(0).getFieldValueMap().toString());\n                }\n                message.append(\"; \");\n              }\n            }\n          }\n          fail(message.toString());\n        }\n      }\n    }\n\n    // now add a lot more docs, and test a handful of randomized multi-level sorts\n    for (int i = numInitialDocs+1; i <= totalDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      indexDoc(doc);\n    }\n    commit();\n\n    final int numRandomSorts = atLeast(5);\n    for (int i = 0; i < numRandomSorts; i++) {\n      final String sort = CursorPagingTest.buildRandomSort(allFieldNames);\n      final String rows = \"\" + TestUtil.nextInt(random(), 63, 113);\n      final String fl = random().nextBoolean() ? \"id\" : \"id,score\";\n      final boolean matchAll = random().nextBoolean();\n      final String q = matchAll ? \"*:*\" : CursorPagingTest.buildRandomQuery();\n\n      SentinelIntSet ids = assertFullWalkNoDups(totalDocs,\n                                                params(\"q\", q,\n                                                       \"fl\",fl,\n                                                       \"rows\",rows,\n                                                       \"sort\",sort));\n      if (matchAll) {\n        assertEquals(totalDocs, ids.size());\n      }\n\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest#doRandomSortsOnLargeIndex().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest#doRandomSortsOnLargeIndex().mjava","sourceNew":"  /** randomized testing of a non-trivial number of docs using assertFullWalkNoDups \n   */\n  public void doRandomSortsOnLargeIndex() throws Exception {\n    final Collection<String> allFieldNames = getAllSortFieldNames();\n\n    final int numInitialDocs = TestUtil.nextInt(random(), 100, 200);\n    final int totalDocs = atLeast(500);\n\n    // start with a smallish number of documents, and test that we can do a full walk using a \n    // sort on *every* field in the schema...\n\n    List<SolrInputDocument> initialDocs = new ArrayList<>();\n    for (int i = 1; i <= numInitialDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      initialDocs.add(doc);\n      indexDoc(doc);\n    }\n    commit();\n\n    for (String f : allFieldNames) {\n      for (String order : new String[] {\" asc\", \" desc\"}) {\n        String sort = f + order + (\"id\".equals(f) ? \"\" : \", id\" + order);\n        String rows = \"\" + TestUtil.nextInt(random(), 13, 50);\n        SentinelIntSet ids = assertFullWalkNoDups(numInitialDocs,\n                                                  params(\"q\", \"*:*\",\n                                                         \"fl\",\"id,\"+f,\n                                                         \"rows\",rows,\n                                                         \"sort\",sort));\n        if (numInitialDocs != ids.size()) {\n          StringBuilder message = new StringBuilder\n              (\"Expected \" + numInitialDocs + \" docs but got \" + ids.size() + \". \");\n          message.append(\"sort=\");\n          message.append(sort);\n          message.append(\". \");\n          if (ids.size() < numInitialDocs) {\n            message.append(\"Missing doc(s): \");\n            for (SolrInputDocument doc : initialDocs) {\n              int id = ((Integer)doc.get(\"id\").getValue()).intValue();\n              if ( ! ids.exists(id)) {\n                QueryResponse rsp = cloudClient.query(params(\"q\", \"id:\" + id,\n                                                             \"rows\", \"1\"));\n                if (0 == rsp.getResults().size()) {\n                  message.append(\"<NOT RETRIEVABLE>:\");\n                  message.append(doc.values());\n                } else {\n                  message.append(rsp.getResults().get(0).getFieldValueMap().toString());\n                }\n                message.append(\"; \");\n              }\n            }\n          }\n          fail(message.toString());\n        }\n      }\n    }\n\n    // now add a lot more docs, and test a handful of randomized multi-level sorts\n    for (int i = numInitialDocs+1; i <= totalDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      indexDoc(doc);\n    }\n    commit();\n\n    final int numRandomSorts = atLeast(3);\n    for (int i = 0; i < numRandomSorts; i++) {\n      final String sort = CursorPagingTest.buildRandomSort(allFieldNames);\n      final String rows = \"\" + TestUtil.nextInt(random(), 63, 113);\n      final String fl = random().nextBoolean() ? \"id\" : \"id,score\";\n      final boolean matchAll = random().nextBoolean();\n      final String q = matchAll ? \"*:*\" : CursorPagingTest.buildRandomQuery();\n\n      SentinelIntSet ids = assertFullWalkNoDups(totalDocs,\n                                                params(\"q\", q,\n                                                       \"fl\",fl,\n                                                       \"rows\",rows,\n                                                       \"sort\",sort));\n      if (matchAll) {\n        assertEquals(totalDocs, ids.size());\n      }\n\n    }\n\n  }\n\n","sourceOld":"  /** randomized testing of a non-trivial number of docs using assertFullWalkNoDups \n   */\n  public void doRandomSortsOnLargeIndex() throws Exception {\n    final Collection<String> allFieldNames = getAllSortFieldNames();\n\n    final int numInitialDocs = TestUtil.nextInt(random(), 100, 200);\n    final int totalDocs = atLeast(500);\n\n    // start with a smallish number of documents, and test that we can do a full walk using a \n    // sort on *every* field in the schema...\n\n    List<SolrInputDocument> initialDocs = new ArrayList<SolrInputDocument>();\n    for (int i = 1; i <= numInitialDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      initialDocs.add(doc);\n      indexDoc(doc);\n    }\n    commit();\n\n    for (String f : allFieldNames) {\n      for (String order : new String[] {\" asc\", \" desc\"}) {\n        String sort = f + order + (\"id\".equals(f) ? \"\" : \", id\" + order);\n        String rows = \"\" + TestUtil.nextInt(random(), 13, 50);\n        SentinelIntSet ids = assertFullWalkNoDups(numInitialDocs,\n                                                  params(\"q\", \"*:*\",\n                                                         \"fl\",\"id,\"+f,\n                                                         \"rows\",rows,\n                                                         \"sort\",sort));\n        if (numInitialDocs != ids.size()) {\n          StringBuilder message = new StringBuilder\n              (\"Expected \" + numInitialDocs + \" docs but got \" + ids.size() + \". \");\n          message.append(\"sort=\");\n          message.append(sort);\n          message.append(\". \");\n          if (ids.size() < numInitialDocs) {\n            message.append(\"Missing doc(s): \");\n            for (SolrInputDocument doc : initialDocs) {\n              int id = ((Integer)doc.get(\"id\").getValue()).intValue();\n              if ( ! ids.exists(id)) {\n                QueryResponse rsp = cloudClient.query(params(\"q\", \"id:\" + id,\n                                                             \"rows\", \"1\"));\n                if (0 == rsp.getResults().size()) {\n                  message.append(\"<NOT RETRIEVABLE>:\");\n                  message.append(doc.values());\n                } else {\n                  message.append(rsp.getResults().get(0).getFieldValueMap().toString());\n                }\n                message.append(\"; \");\n              }\n            }\n          }\n          fail(message.toString());\n        }\n      }\n    }\n\n    // now add a lot more docs, and test a handful of randomized multi-level sorts\n    for (int i = numInitialDocs+1; i <= totalDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      indexDoc(doc);\n    }\n    commit();\n\n    final int numRandomSorts = atLeast(3);\n    for (int i = 0; i < numRandomSorts; i++) {\n      final String sort = CursorPagingTest.buildRandomSort(allFieldNames);\n      final String rows = \"\" + TestUtil.nextInt(random(), 63, 113);\n      final String fl = random().nextBoolean() ? \"id\" : \"id,score\";\n      final boolean matchAll = random().nextBoolean();\n      final String q = matchAll ? \"*:*\" : CursorPagingTest.buildRandomQuery();\n\n      SentinelIntSet ids = assertFullWalkNoDups(totalDocs,\n                                                params(\"q\", q,\n                                                       \"fl\",fl,\n                                                       \"rows\",rows,\n                                                       \"sort\",sort));\n      if (matchAll) {\n        assertEquals(totalDocs, ids.size());\n      }\n\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a71f63026529f3c1f03cfdd664910873ab2369ae","date":1497543264,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest#doRandomSortsOnLargeIndex().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest#doRandomSortsOnLargeIndex().mjava","sourceNew":"  /** randomized testing of a non-trivial number of docs using assertFullWalkNoDups \n   */\n  public void doRandomSortsOnLargeIndex() throws Exception {\n    final Collection<String> allFieldNames = getAllSortFieldNames();\n\n    final int numInitialDocs = TestUtil.nextInt(random(), 100, 200);\n    final int totalDocs = atLeast(500);\n\n    // start with a smallish number of documents, and test that we can do a full walk using a \n    // sort on *every* field in the schema...\n\n    List<SolrInputDocument> initialDocs = new ArrayList<>();\n    for (int i = 1; i <= numInitialDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      initialDocs.add(doc);\n      indexDoc(doc);\n    }\n    commit();\n\n    for (String f : allFieldNames) {\n      for (String order : new String[] {\" asc\", \" desc\"}) {\n        String sort = f + order + (\"id\".equals(f) ? \"\" : \", id\" + order);\n        String rows = \"\" + TestUtil.nextInt(random(), 13, 50);\n        SentinelIntSet ids = assertFullWalkNoDups(numInitialDocs,\n                                                  params(\"q\", \"*:*\",\n                                                         \"fl\",\"id,\"+f,\n                                                         \"rows\",rows,\n                                                         \"sort\",sort));\n        if (numInitialDocs != ids.size()) {\n          StringBuilder message = new StringBuilder\n              (\"Expected \" + numInitialDocs + \" docs but got \" + ids.size() + \". \");\n          message.append(\"sort=\");\n          message.append(sort);\n          message.append(\". \");\n          if (ids.size() < numInitialDocs) {\n            message.append(\"Missing doc(s): \");\n            for (SolrInputDocument doc : initialDocs) {\n              int id = Integer.parseInt(doc.getFieldValue(\"id\").toString());\n              if ( ! ids.exists(id)) {\n                QueryResponse rsp = cloudClient.query(params(\"q\", \"id:\" + id,\n                                                             \"rows\", \"1\"));\n                if (0 == rsp.getResults().size()) {\n                  message.append(\"<NOT RETRIEVABLE>:\");\n                  message.append(doc.values());\n                } else {\n                  message.append(rsp.getResults().get(0).getFieldValueMap().toString());\n                }\n                message.append(\"; \");\n              }\n            }\n          }\n          fail(message.toString());\n        }\n      }\n    }\n\n    // now add a lot more docs, and test a handful of randomized multi-level sorts\n    for (int i = numInitialDocs+1; i <= totalDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      indexDoc(doc);\n    }\n    commit();\n\n    final int numRandomSorts = atLeast(3);\n    for (int i = 0; i < numRandomSorts; i++) {\n      final String sort = CursorPagingTest.buildRandomSort(allFieldNames);\n      final String rows = \"\" + TestUtil.nextInt(random(), 63, 113);\n      final String fl = random().nextBoolean() ? \"id\" : \"id,score\";\n      final boolean matchAll = random().nextBoolean();\n      final String q = matchAll ? \"*:*\" : CursorPagingTest.buildRandomQuery();\n\n      SentinelIntSet ids = assertFullWalkNoDups(totalDocs,\n                                                params(\"q\", q,\n                                                       \"fl\",fl,\n                                                       \"rows\",rows,\n                                                       \"sort\",sort));\n      if (matchAll) {\n        assertEquals(totalDocs, ids.size());\n      }\n\n    }\n\n  }\n\n","sourceOld":"  /** randomized testing of a non-trivial number of docs using assertFullWalkNoDups \n   */\n  public void doRandomSortsOnLargeIndex() throws Exception {\n    final Collection<String> allFieldNames = getAllSortFieldNames();\n\n    final int numInitialDocs = TestUtil.nextInt(random(), 100, 200);\n    final int totalDocs = atLeast(500);\n\n    // start with a smallish number of documents, and test that we can do a full walk using a \n    // sort on *every* field in the schema...\n\n    List<SolrInputDocument> initialDocs = new ArrayList<>();\n    for (int i = 1; i <= numInitialDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      initialDocs.add(doc);\n      indexDoc(doc);\n    }\n    commit();\n\n    for (String f : allFieldNames) {\n      for (String order : new String[] {\" asc\", \" desc\"}) {\n        String sort = f + order + (\"id\".equals(f) ? \"\" : \", id\" + order);\n        String rows = \"\" + TestUtil.nextInt(random(), 13, 50);\n        SentinelIntSet ids = assertFullWalkNoDups(numInitialDocs,\n                                                  params(\"q\", \"*:*\",\n                                                         \"fl\",\"id,\"+f,\n                                                         \"rows\",rows,\n                                                         \"sort\",sort));\n        if (numInitialDocs != ids.size()) {\n          StringBuilder message = new StringBuilder\n              (\"Expected \" + numInitialDocs + \" docs but got \" + ids.size() + \". \");\n          message.append(\"sort=\");\n          message.append(sort);\n          message.append(\". \");\n          if (ids.size() < numInitialDocs) {\n            message.append(\"Missing doc(s): \");\n            for (SolrInputDocument doc : initialDocs) {\n              int id = ((Integer)doc.get(\"id\").getValue()).intValue();\n              if ( ! ids.exists(id)) {\n                QueryResponse rsp = cloudClient.query(params(\"q\", \"id:\" + id,\n                                                             \"rows\", \"1\"));\n                if (0 == rsp.getResults().size()) {\n                  message.append(\"<NOT RETRIEVABLE>:\");\n                  message.append(doc.values());\n                } else {\n                  message.append(rsp.getResults().get(0).getFieldValueMap().toString());\n                }\n                message.append(\"; \");\n              }\n            }\n          }\n          fail(message.toString());\n        }\n      }\n    }\n\n    // now add a lot more docs, and test a handful of randomized multi-level sorts\n    for (int i = numInitialDocs+1; i <= totalDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      indexDoc(doc);\n    }\n    commit();\n\n    final int numRandomSorts = atLeast(3);\n    for (int i = 0; i < numRandomSorts; i++) {\n      final String sort = CursorPagingTest.buildRandomSort(allFieldNames);\n      final String rows = \"\" + TestUtil.nextInt(random(), 63, 113);\n      final String fl = random().nextBoolean() ? \"id\" : \"id,score\";\n      final boolean matchAll = random().nextBoolean();\n      final String q = matchAll ? \"*:*\" : CursorPagingTest.buildRandomQuery();\n\n      SentinelIntSet ids = assertFullWalkNoDups(totalDocs,\n                                                params(\"q\", q,\n                                                       \"fl\",fl,\n                                                       \"rows\",rows,\n                                                       \"sort\",sort));\n      if (matchAll) {\n        assertEquals(totalDocs, ids.size());\n      }\n\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9","date":1498028748,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest#doRandomSortsOnLargeIndex().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest#doRandomSortsOnLargeIndex().mjava","sourceNew":"  /** randomized testing of a non-trivial number of docs using assertFullWalkNoDups \n   */\n  public void doRandomSortsOnLargeIndex() throws Exception {\n    final Collection<String> allFieldNames = getAllSortFieldNames();\n\n    final int numInitialDocs = TestUtil.nextInt(random(), 100, 200);\n    final int totalDocs = atLeast(500);\n\n    // start with a smallish number of documents, and test that we can do a full walk using a \n    // sort on *every* field in the schema...\n\n    List<SolrInputDocument> initialDocs = new ArrayList<>();\n    for (int i = 1; i <= numInitialDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      initialDocs.add(doc);\n      indexDoc(doc);\n    }\n    commit();\n\n    for (String f : allFieldNames) {\n      for (String order : new String[] {\" asc\", \" desc\"}) {\n        String sort = f + order + (\"id\".equals(f) ? \"\" : \", id\" + order);\n        String rows = \"\" + TestUtil.nextInt(random(), 13, 50);\n        SentinelIntSet ids = assertFullWalkNoDups(numInitialDocs,\n                                                  params(\"q\", \"*:*\",\n                                                         \"fl\",\"id,\"+f,\n                                                         \"rows\",rows,\n                                                         \"sort\",sort));\n        if (numInitialDocs != ids.size()) {\n          StringBuilder message = new StringBuilder\n              (\"Expected \" + numInitialDocs + \" docs but got \" + ids.size() + \". \");\n          message.append(\"sort=\");\n          message.append(sort);\n          message.append(\". \");\n          if (ids.size() < numInitialDocs) {\n            message.append(\"Missing doc(s): \");\n            for (SolrInputDocument doc : initialDocs) {\n              int id = Integer.parseInt(doc.getFieldValue(\"id\").toString());\n              if ( ! ids.exists(id)) {\n                QueryResponse rsp = cloudClient.query(params(\"q\", \"id:\" + id,\n                                                             \"rows\", \"1\"));\n                if (0 == rsp.getResults().size()) {\n                  message.append(\"<NOT RETRIEVABLE>:\");\n                  message.append(doc.values());\n                } else {\n                  message.append(rsp.getResults().get(0).getFieldValueMap().toString());\n                }\n                message.append(\"; \");\n              }\n            }\n          }\n          fail(message.toString());\n        }\n      }\n    }\n\n    // now add a lot more docs, and test a handful of randomized multi-level sorts\n    for (int i = numInitialDocs+1; i <= totalDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      indexDoc(doc);\n    }\n    commit();\n\n    final int numRandomSorts = atLeast(3);\n    for (int i = 0; i < numRandomSorts; i++) {\n      final String sort = CursorPagingTest.buildRandomSort(allFieldNames);\n      final String rows = \"\" + TestUtil.nextInt(random(), 63, 113);\n      final String fl = random().nextBoolean() ? \"id\" : \"id,score\";\n      final boolean matchAll = random().nextBoolean();\n      final String q = matchAll ? \"*:*\" : CursorPagingTest.buildRandomQuery();\n\n      SentinelIntSet ids = assertFullWalkNoDups(totalDocs,\n                                                params(\"q\", q,\n                                                       \"fl\",fl,\n                                                       \"rows\",rows,\n                                                       \"sort\",sort));\n      if (matchAll) {\n        assertEquals(totalDocs, ids.size());\n      }\n\n    }\n\n  }\n\n","sourceOld":"  /** randomized testing of a non-trivial number of docs using assertFullWalkNoDups \n   */\n  public void doRandomSortsOnLargeIndex() throws Exception {\n    final Collection<String> allFieldNames = getAllSortFieldNames();\n\n    final int numInitialDocs = TestUtil.nextInt(random(), 100, 200);\n    final int totalDocs = atLeast(500);\n\n    // start with a smallish number of documents, and test that we can do a full walk using a \n    // sort on *every* field in the schema...\n\n    List<SolrInputDocument> initialDocs = new ArrayList<>();\n    for (int i = 1; i <= numInitialDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      initialDocs.add(doc);\n      indexDoc(doc);\n    }\n    commit();\n\n    for (String f : allFieldNames) {\n      for (String order : new String[] {\" asc\", \" desc\"}) {\n        String sort = f + order + (\"id\".equals(f) ? \"\" : \", id\" + order);\n        String rows = \"\" + TestUtil.nextInt(random(), 13, 50);\n        SentinelIntSet ids = assertFullWalkNoDups(numInitialDocs,\n                                                  params(\"q\", \"*:*\",\n                                                         \"fl\",\"id,\"+f,\n                                                         \"rows\",rows,\n                                                         \"sort\",sort));\n        if (numInitialDocs != ids.size()) {\n          StringBuilder message = new StringBuilder\n              (\"Expected \" + numInitialDocs + \" docs but got \" + ids.size() + \". \");\n          message.append(\"sort=\");\n          message.append(sort);\n          message.append(\". \");\n          if (ids.size() < numInitialDocs) {\n            message.append(\"Missing doc(s): \");\n            for (SolrInputDocument doc : initialDocs) {\n              int id = ((Integer)doc.get(\"id\").getValue()).intValue();\n              if ( ! ids.exists(id)) {\n                QueryResponse rsp = cloudClient.query(params(\"q\", \"id:\" + id,\n                                                             \"rows\", \"1\"));\n                if (0 == rsp.getResults().size()) {\n                  message.append(\"<NOT RETRIEVABLE>:\");\n                  message.append(doc.values());\n                } else {\n                  message.append(rsp.getResults().get(0).getFieldValueMap().toString());\n                }\n                message.append(\"; \");\n              }\n            }\n          }\n          fail(message.toString());\n        }\n      }\n    }\n\n    // now add a lot more docs, and test a handful of randomized multi-level sorts\n    for (int i = numInitialDocs+1; i <= totalDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      indexDoc(doc);\n    }\n    commit();\n\n    final int numRandomSorts = atLeast(3);\n    for (int i = 0; i < numRandomSorts; i++) {\n      final String sort = CursorPagingTest.buildRandomSort(allFieldNames);\n      final String rows = \"\" + TestUtil.nextInt(random(), 63, 113);\n      final String fl = random().nextBoolean() ? \"id\" : \"id,score\";\n      final boolean matchAll = random().nextBoolean();\n      final String q = matchAll ? \"*:*\" : CursorPagingTest.buildRandomQuery();\n\n      SentinelIntSet ids = assertFullWalkNoDups(totalDocs,\n                                                params(\"q\", q,\n                                                       \"fl\",fl,\n                                                       \"rows\",rows,\n                                                       \"sort\",sort));\n      if (matchAll) {\n        assertEquals(totalDocs, ids.size());\n      }\n\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest#doRandomSortsOnLargeIndex().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest#doRandomSortsOnLargeIndex().mjava","sourceNew":"  /** randomized testing of a non-trivial number of docs using assertFullWalkNoDups \n   */\n  public void doRandomSortsOnLargeIndex() throws Exception {\n    final Collection<String> allFieldNames = getAllSortFieldNames();\n\n    final int numInitialDocs = TestUtil.nextInt(random(), 100, 200);\n    final int totalDocs = atLeast(500);\n\n    // start with a smallish number of documents, and test that we can do a full walk using a \n    // sort on *every* field in the schema...\n\n    List<SolrInputDocument> initialDocs = new ArrayList<>();\n    for (int i = 1; i <= numInitialDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      initialDocs.add(doc);\n      indexDoc(doc);\n    }\n    commit();\n\n    for (String f : allFieldNames) {\n      for (String order : new String[] {\" asc\", \" desc\"}) {\n        String sort = f + order + (\"id\".equals(f) ? \"\" : \", id\" + order);\n        String rows = \"\" + TestUtil.nextInt(random(), 13, 50);\n        SentinelIntSet ids = assertFullWalkNoDups(numInitialDocs,\n                                                  params(\"q\", \"*:*\",\n                                                         \"fl\",\"id,\"+f,\n                                                         \"rows\",rows,\n                                                         \"sort\",sort));\n        if (numInitialDocs != ids.size()) {\n          StringBuilder message = new StringBuilder\n              (\"Expected \" + numInitialDocs + \" docs but got \" + ids.size() + \". \");\n          message.append(\"sort=\");\n          message.append(sort);\n          message.append(\". \");\n          if (ids.size() < numInitialDocs) {\n            message.append(\"Missing doc(s): \");\n            for (SolrInputDocument doc : initialDocs) {\n              int id = Integer.parseInt(doc.getFieldValue(\"id\").toString());\n              if ( ! ids.exists(id)) {\n                QueryResponse rsp = cloudClient.query(params(\"q\", \"id:\" + id,\n                                                             \"rows\", \"1\"));\n                if (0 == rsp.getResults().size()) {\n                  message.append(\"<NOT RETRIEVABLE>:\");\n                  message.append(doc.values());\n                } else {\n                  message.append(rsp.getResults().get(0).getFieldValueMap().toString());\n                }\n                message.append(\"; \");\n              }\n            }\n          }\n          fail(message.toString());\n        }\n      }\n    }\n\n    // now add a lot more docs, and test a handful of randomized multi-level sorts\n    for (int i = numInitialDocs+1; i <= totalDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      indexDoc(doc);\n    }\n    commit();\n\n    final int numRandomSorts = atLeast(3);\n    for (int i = 0; i < numRandomSorts; i++) {\n      final String sort = CursorPagingTest.buildRandomSort(allFieldNames);\n      final String rows = \"\" + TestUtil.nextInt(random(), 63, 113);\n      final String fl = random().nextBoolean() ? \"id\" : \"id,score\";\n      final boolean matchAll = random().nextBoolean();\n      final String q = matchAll ? \"*:*\" : CursorPagingTest.buildRandomQuery();\n\n      SentinelIntSet ids = assertFullWalkNoDups(totalDocs,\n                                                params(\"q\", q,\n                                                       \"fl\",fl,\n                                                       \"rows\",rows,\n                                                       \"sort\",sort));\n      if (matchAll) {\n        assertEquals(totalDocs, ids.size());\n      }\n\n    }\n\n  }\n\n","sourceOld":"  /** randomized testing of a non-trivial number of docs using assertFullWalkNoDups \n   */\n  public void doRandomSortsOnLargeIndex() throws Exception {\n    final Collection<String> allFieldNames = getAllSortFieldNames();\n\n    final int numInitialDocs = TestUtil.nextInt(random(), 100, 200);\n    final int totalDocs = atLeast(500);\n\n    // start with a smallish number of documents, and test that we can do a full walk using a \n    // sort on *every* field in the schema...\n\n    List<SolrInputDocument> initialDocs = new ArrayList<>();\n    for (int i = 1; i <= numInitialDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      initialDocs.add(doc);\n      indexDoc(doc);\n    }\n    commit();\n\n    for (String f : allFieldNames) {\n      for (String order : new String[] {\" asc\", \" desc\"}) {\n        String sort = f + order + (\"id\".equals(f) ? \"\" : \", id\" + order);\n        String rows = \"\" + TestUtil.nextInt(random(), 13, 50);\n        SentinelIntSet ids = assertFullWalkNoDups(numInitialDocs,\n                                                  params(\"q\", \"*:*\",\n                                                         \"fl\",\"id,\"+f,\n                                                         \"rows\",rows,\n                                                         \"sort\",sort));\n        if (numInitialDocs != ids.size()) {\n          StringBuilder message = new StringBuilder\n              (\"Expected \" + numInitialDocs + \" docs but got \" + ids.size() + \". \");\n          message.append(\"sort=\");\n          message.append(sort);\n          message.append(\". \");\n          if (ids.size() < numInitialDocs) {\n            message.append(\"Missing doc(s): \");\n            for (SolrInputDocument doc : initialDocs) {\n              int id = ((Integer)doc.get(\"id\").getValue()).intValue();\n              if ( ! ids.exists(id)) {\n                QueryResponse rsp = cloudClient.query(params(\"q\", \"id:\" + id,\n                                                             \"rows\", \"1\"));\n                if (0 == rsp.getResults().size()) {\n                  message.append(\"<NOT RETRIEVABLE>:\");\n                  message.append(doc.values());\n                } else {\n                  message.append(rsp.getResults().get(0).getFieldValueMap().toString());\n                }\n                message.append(\"; \");\n              }\n            }\n          }\n          fail(message.toString());\n        }\n      }\n    }\n\n    // now add a lot more docs, and test a handful of randomized multi-level sorts\n    for (int i = numInitialDocs+1; i <= totalDocs; i++) {\n      SolrInputDocument doc = CursorPagingTest.buildRandomDocument(i);\n      indexDoc(doc);\n    }\n    commit();\n\n    final int numRandomSorts = atLeast(3);\n    for (int i = 0; i < numRandomSorts; i++) {\n      final String sort = CursorPagingTest.buildRandomSort(allFieldNames);\n      final String rows = \"\" + TestUtil.nextInt(random(), 63, 113);\n      final String fl = random().nextBoolean() ? \"id\" : \"id,score\";\n      final boolean matchAll = random().nextBoolean();\n      final String q = matchAll ? \"*:*\" : CursorPagingTest.buildRandomQuery();\n\n      SentinelIntSet ids = assertFullWalkNoDups(totalDocs,\n                                                params(\"q\", q,\n                                                       \"fl\",fl,\n                                                       \"rows\",rows,\n                                                       \"sort\",sort));\n      if (matchAll) {\n        assertEquals(totalDocs, ids.size());\n      }\n\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3d0814e12c6e2b86cf23048e6310a3715a8f6ea5":["6613659748fe4411a7dcf85266e55db1f95f7315"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["3d0814e12c6e2b86cf23048e6310a3715a8f6ea5"],"6613659748fe4411a7dcf85266e55db1f95f7315":["df168f752ac3120a6e38cebfc8fc77722d6b2d20"],"d5bc8e25f59990525f5beb14afe9c96240dcf4a2":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a71f63026529f3c1f03cfdd664910873ab2369ae":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"c8257d69ecbfc2c790df7fa8b18953b9eb18b706":["cbd6d2ce12ab9b3bef6559744b54e95242cf5747"],"df168f752ac3120a6e38cebfc8fc77722d6b2d20":["6a0f9b793b360e5f5863eef2d4b02a2ddd8b47b4"],"28288370235ed02234a64753cdbf0c6ec096304a":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","a71f63026529f3c1f03cfdd664910873ab2369ae"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"6a0f9b793b360e5f5863eef2d4b02a2ddd8b47b4":["c8257d69ecbfc2c790df7fa8b18953b9eb18b706"],"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","a71f63026529f3c1f03cfdd664910873ab2369ae"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["28288370235ed02234a64753cdbf0c6ec096304a"],"cbd6d2ce12ab9b3bef6559744b54e95242cf5747":["d5bc8e25f59990525f5beb14afe9c96240dcf4a2"]},"commit2Childs":{"3d0814e12c6e2b86cf23048e6310a3715a8f6ea5":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["a71f63026529f3c1f03cfdd664910873ab2369ae","28288370235ed02234a64753cdbf0c6ec096304a","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9"],"6613659748fe4411a7dcf85266e55db1f95f7315":["3d0814e12c6e2b86cf23048e6310a3715a8f6ea5"],"d5bc8e25f59990525f5beb14afe9c96240dcf4a2":["cbd6d2ce12ab9b3bef6559744b54e95242cf5747"],"a71f63026529f3c1f03cfdd664910873ab2369ae":["28288370235ed02234a64753cdbf0c6ec096304a","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9"],"c8257d69ecbfc2c790df7fa8b18953b9eb18b706":["6a0f9b793b360e5f5863eef2d4b02a2ddd8b47b4"],"df168f752ac3120a6e38cebfc8fc77722d6b2d20":["6613659748fe4411a7dcf85266e55db1f95f7315"],"28288370235ed02234a64753cdbf0c6ec096304a":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d5bc8e25f59990525f5beb14afe9c96240dcf4a2"],"6a0f9b793b360e5f5863eef2d4b02a2ddd8b47b4":["df168f752ac3120a6e38cebfc8fc77722d6b2d20"],"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9":[],"cbd6d2ce12ab9b3bef6559744b54e95242cf5747":["c8257d69ecbfc2c790df7fa8b18953b9eb18b706"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}