{"path":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random, termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random, termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f08557cdb6c60ac7b88a9342c983a20cd236e74f","date":1330954480,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random, termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random, termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","date":1331075828,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random, termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random, termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"399d5903979ca52514d2bc7e3a362e1c45885c94","date":1333042474,"type":3,"author":"Ryan McKinley","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random, termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random, termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d08eba3d52b63561ebf936481ce73e6b6a14aa03","date":1333879759,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    final InvertedFieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random, termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random, termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf","date":1333892281,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random, termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    final InvertedFieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random, termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random, termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["02331260bb246364779cb6f04919ca47900d01bb"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f6eee1e5a8555d83dd8f2f2e3c0a4ccec8e7cf9b","date":1337136355,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final MutableFieldInfos fieldInfos = new MutableFieldInfos(new MutableFieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d2dee33619431ada2a7a07f5fe2dbd94bac6a460","date":1337274029,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final MutableFieldInfos fieldInfos = new MutableFieldInfos(new MutableFieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final MutableFieldInfos fieldInfos = new MutableFieldInfos(new MutableFieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"57d2758489b06da76bc6a037793d9ba347ce01fd","date":1337351495,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final MutableFieldInfos builder = new MutableFieldInfos(new MutableFieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final MutableFieldInfos fieldInfos = new MutableFieldInfos(new MutableFieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a851824c09818632c94eba41e60ef5e72e323c8e","date":1337355760,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final MutableFieldInfos builder = new MutableFieldInfos(new MutableFieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b6dce319de558e8b80705326dd04d578f74767d9","date":1337618331,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, -1, SEGMENT, false, null, false,\n                                           0, codec, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9d153abcf92dc5329d98571a8c3035df9bd80648","date":1337702630,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, -1, SEGMENT, false, null, false,\n                                           codec, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, -1, SEGMENT, false, null, false,\n                                           0, codec, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"63caed6eb28209e181e97822c4c8fdf808884c3b","date":1337712793,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, -1, SEGMENT, false, null, false,\n                                           codec, null, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, -1, SEGMENT, false, null, false,\n                                           codec, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6a917aca07a305ab70118a83e84d931503441271","date":1337826487,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, null, false,\n                                           codec, null, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, -1, SEGMENT, false, null, false,\n                                           codec, null, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"764b942fd30efcae6e532c19771f32eeeb0037b2","date":1337868546,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, false, codec, null, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, null, false,\n                                           codec, null, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"615ddbd81799980d0fdd95e0238e1c498b6f47b0","date":1338233290,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, false, codec, null, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"57ae3024996ccdb3c36c42cb890e1efb37df4ce8","date":1338343651,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, false, codec, null, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, false, codec, null, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"02331260bb246364779cb6f04919ca47900d01bb","date":1343749884,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, false, codec, null, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, 0);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, false, codec, null, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","date":1343768312,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, false, codec, null, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, 0);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, false, codec, null, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, false, codec, null, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, 0);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, false, codec, null, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fb07ab105350b80ed9d63ca64b117084ed7391bc","date":1344824719,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, false, codec, null, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, 0);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, false, codec, null, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, 0);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7869f64c874ebf7f317d22c00baf2b6857797a6","date":1344856617,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, false, codec, null, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, 0);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, false, codec, null, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, 0);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9","date":1344867506,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, false, codec, null, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, 0);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, false, codec, null, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, 0);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"15250ca94ba8ab3bcdd476daf6bf3f3febb92640","date":1355200097,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, false, codec, null, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, DocsEnum.FLAG_NONE);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, false, codec, null, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, 0);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, false, codec, null, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, DocsEnum.FLAG_NONE);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, false, codec, null, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, 0);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a45bec74b98f6fc05f52770cfb425739e6563960","date":1375119292,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, false, codec, null, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, DocsEnum.FLAG_NONE);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, false, codec, null, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, DocsEnum.FLAG_NONE);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, false, codec, null, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, DocsEnum.FLAG_NONE);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, false, codec, null, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, DocsEnum.FLAG_NONE);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"77f264c55cbf75404f8601ae7290d69157273a56","date":1380484282,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, false, codec, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, DocsEnum.FLAG_NONE);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, false, codec, null, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, DocsEnum.FLAG_NONE);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, false, codec, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = TestUtil.docs(random(), termsEnum, null, docsEnum, DocsEnum.FLAG_NONE);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, false, codec, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random(), termsEnum, null,  docsEnum, DocsEnum.FLAG_NONE);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"057a1793765d068ea9302f1a29e21734ee58d41e","date":1408130117,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = TestUtil.docs(random(), termsEnum, null, docsEnum, DocsEnum.FLAG_NONE);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, false, codec, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = TestUtil.docs(random(), termsEnum, null, docsEnum, DocsEnum.FLAG_NONE);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["5f6bd27530a2846413fe2d00030493c0e2d3a072"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c65d2864d936ccf22dc7ec14dd48b4dff7bacceb","date":1411653326,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null, StringHelper.randomId());\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = TestUtil.docs(random(), termsEnum, null, docsEnum, DocsEnum.FLAG_NONE);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = TestUtil.docs(random(), termsEnum, null, docsEnum, DocsEnum.FLAG_NONE);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["8521d944f9dfb45692ec28235dbf116d47ef69ba"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5f6bd27530a2846413fe2d00030493c0e2d3a072","date":1411811855,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null, StringHelper.randomId());\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = TestUtil.docs(random(), termsEnum, null, docsEnum, DocsEnum.FLAG_NONE);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = TestUtil.docs(random(), termsEnum, null, docsEnum, DocsEnum.FLAG_NONE);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":["057a1793765d068ea9302f1a29e21734ee58d41e"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f382b2e9f4ca7dbe98e2f15da70983ecfc02b171","date":1412231650,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null, StringHelper.randomId());\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = TestUtil.docs(random(), termsEnum, null, docsEnum, DocsEnum.FLAG_NONE);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null, StringHelper.randomId());\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = TestUtil.docs(random(), termsEnum, null, docsEnum, DocsEnum.FLAG_NONE);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9bb9a29a5e71a90295f175df8919802993142c9a","date":1412517673,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null, StringHelper.randomId());\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = TestUtil.docs(random(), termsEnum, null, docsEnum, DocsEnum.FLAG_NONE);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null, StringHelper.randomId());\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = TestUtil.docs(random(), termsEnum, null, docsEnum, DocsEnum.FLAG_NONE);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8521d944f9dfb45692ec28235dbf116d47ef69ba","date":1417535150,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null, StringHelper.randomId(), new HashMap<>());\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = TestUtil.docs(random(), termsEnum, null, docsEnum, DocsEnum.FLAG_NONE);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null, StringHelper.randomId());\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = TestUtil.docs(random(), termsEnum, null, docsEnum, DocsEnum.FLAG_NONE);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":["c65d2864d936ccf22dc7ec14dd48b4dff7bacceb"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"51f5280f31484820499077f41fcdfe92d527d9dc","date":1423229122,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null, StringHelper.randomId(), new HashMap<>());\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, null, postingsEnum, PostingsEnum.FLAG_NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null, StringHelper.randomId(), new HashMap<>());\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = TestUtil.docs(random(), termsEnum, null, docsEnum, DocsEnum.FLAG_NONE);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e73063b92d958076ef4ae8beb5f493e8ccdcecb4","date":1424177215,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null, StringHelper.randomId(), new HashMap<>());\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, null, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null, StringHelper.randomId(), new HashMap<>());\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, null, postingsEnum, PostingsEnum.FLAG_NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"79700663e164dece87bed4adfd3e28bab6cb1385","date":1425241849,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>());\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, null, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null, StringHelper.randomId(), new HashMap<>());\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, null, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"299a2348fa24151d150182211b6208a38e5e3450","date":1425304608,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>());\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, null, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null, StringHelper.randomId(), new HashMap<>());\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, null, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>());\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, null, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null, StringHelper.randomId(), new HashMap<>());\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, null, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82","date":1428522487,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>());\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator();\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, null, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>());\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, null, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f4464508ee83288c8c4585b533f9faaa93aa314","date":1435240759,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>());\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator();\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>());\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator();\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, null, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ceaef6cfc68c8ab22a684192e469a8280f9e6e70","date":1462354657,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator();\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>());\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator();\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3d33e731a93d4b57e662ff094f64f94a745422d4","date":1463128289,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator();\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>());\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator();\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0ad30c6a479e764150a3316e57263319775f1df2","date":1463395403,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator();\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>());\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator();\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d470c8182e92b264680e34081b75e70a9f2b3c89","date":1463985353,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator();\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>());\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator();\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator();\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>());\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator();\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"31741cf1390044e38a2ec3127cf302ba841bfd75","date":1491292636,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator();\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator();\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"92212fd254551a0b1156aafc3a1a6ed1a43932ad","date":1491296431,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator();\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator();\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7e4ca6dc9612ff741d8713743e2bccfae5eadac","date":1528093718,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder(new FieldInfos.FieldNumbers(null));\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator();\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator();\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f592209545c71895260367152601e9200399776d","date":1528238935,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder(new FieldInfos.FieldNumbers(null));\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator();\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator();\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b70042a8a492f7054d480ccdd2be9796510d4327","date":1528386658,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder(new FieldInfos.FieldNumbers(null));\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator();\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator();\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"790693f23f4e88a59fbb25e47cc25f6d493b03cb","date":1553077690,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder(new FieldInfos.FieldNumbers(null));\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, false, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator();\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder(new FieldInfos.FieldNumbers(null));\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator();\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"763da4a9605e47013078edc323b9d4b608f0f9e0","date":1555353576,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder(new FieldInfos.FieldNumbers(null));\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, false, newIOContext(random()), Collections.emptyMap()));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator();\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder(new FieldInfos.FieldNumbers(null));\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, false, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator();\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a4e83191a3e02851a0b67e5335e6922f3e9ea86d","date":1583489709,"type":3,"author":"Bruno Roustant","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder(new FieldInfos.FieldNumbers(null));\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, false, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator();\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder(new FieldInfos.FieldNumbers(null));\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, false, newIOContext(random()), Collections.emptyMap()));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator();\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bec68e7c41fed133827595747d853cad504e481e","date":1583501052,"type":3,"author":"Bruno Roustant","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder(new FieldInfos.FieldNumbers(null));\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator();\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos.Builder builder = new FieldInfos.Builder(new FieldInfos.FieldNumbers(null));\n\n    final FieldData field = new FieldData(\"field\", builder, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n    final FieldInfos fieldInfos = builder.finish();\n    final Directory dir = newDirectory();\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    \n    this.write(si, fieldInfos, dir, fields);\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, false, newIOContext(random())));\n\n    final Iterator<String> fieldsEnum = reader.iterator();\n    String fieldName = fieldsEnum.next();\n    assertNotNull(fieldName);\n    final Terms terms2 = reader.terms(fieldName);\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator();\n\n    PostingsEnum postingsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        postingsEnum = TestUtil.docs(random(), termsEnum, postingsEnum, PostingsEnum.NONE);\n        assertEquals(terms[i].docs[0], postingsEnum.nextDoc());\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postingsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertFalse(fieldsEnum.hasNext());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["79700663e164dece87bed4adfd3e28bab6cb1385"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"63caed6eb28209e181e97822c4c8fdf808884c3b":["9d153abcf92dc5329d98571a8c3035df9bd80648"],"f6eee1e5a8555d83dd8f2f2e3c0a4ccec8e7cf9b":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"a4e83191a3e02851a0b67e5335e6922f3e9ea86d":["763da4a9605e47013078edc323b9d4b608f0f9e0"],"57ae3024996ccdb3c36c42cb890e1efb37df4ce8":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"b70042a8a492f7054d480ccdd2be9796510d4327":["31741cf1390044e38a2ec3127cf302ba841bfd75","b7e4ca6dc9612ff741d8713743e2bccfae5eadac"],"79700663e164dece87bed4adfd3e28bab6cb1385":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf":["d08eba3d52b63561ebf936481ce73e6b6a14aa03"],"77f264c55cbf75404f8601ae7290d69157273a56":["a45bec74b98f6fc05f52770cfb425739e6563960"],"299a2348fa24151d150182211b6208a38e5e3450":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4","79700663e164dece87bed4adfd3e28bab6cb1385"],"790693f23f4e88a59fbb25e47cc25f6d493b03cb":["b7e4ca6dc9612ff741d8713743e2bccfae5eadac"],"f382b2e9f4ca7dbe98e2f15da70983ecfc02b171":["c65d2864d936ccf22dc7ec14dd48b4dff7bacceb"],"a45bec74b98f6fc05f52770cfb425739e6563960":["15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"fb07ab105350b80ed9d63ca64b117084ed7391bc":["02331260bb246364779cb6f04919ca47900d01bb"],"bec68e7c41fed133827595747d853cad504e481e":["a4e83191a3e02851a0b67e5335e6922f3e9ea86d"],"51f5280f31484820499077f41fcdfe92d527d9dc":["8521d944f9dfb45692ec28235dbf116d47ef69ba"],"8521d944f9dfb45692ec28235dbf116d47ef69ba":["9bb9a29a5e71a90295f175df8919802993142c9a"],"d2dee33619431ada2a7a07f5fe2dbd94bac6a460":["f6eee1e5a8555d83dd8f2f2e3c0a4ccec8e7cf9b"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["51f5280f31484820499077f41fcdfe92d527d9dc"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["57ae3024996ccdb3c36c42cb890e1efb37df4ce8","02331260bb246364779cb6f04919ca47900d01bb"],"f592209545c71895260367152601e9200399776d":["31741cf1390044e38a2ec3127cf302ba841bfd75","b7e4ca6dc9612ff741d8713743e2bccfae5eadac"],"02331260bb246364779cb6f04919ca47900d01bb":["57ae3024996ccdb3c36c42cb890e1efb37df4ce8"],"c65d2864d936ccf22dc7ec14dd48b4dff7bacceb":["057a1793765d068ea9302f1a29e21734ee58d41e"],"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["fb07ab105350b80ed9d63ca64b117084ed7391bc","15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"6a917aca07a305ab70118a83e84d931503441271":["63caed6eb28209e181e97822c4c8fdf808884c3b"],"763da4a9605e47013078edc323b9d4b608f0f9e0":["790693f23f4e88a59fbb25e47cc25f6d493b03cb"],"764b942fd30efcae6e532c19771f32eeeb0037b2":["6a917aca07a305ab70118a83e84d931503441271"],"5f6bd27530a2846413fe2d00030493c0e2d3a072":["057a1793765d068ea9302f1a29e21734ee58d41e","c65d2864d936ccf22dc7ec14dd48b4dff7bacceb"],"a851824c09818632c94eba41e60ef5e72e323c8e":["57d2758489b06da76bc6a037793d9ba347ce01fd"],"0ad30c6a479e764150a3316e57263319775f1df2":["0f4464508ee83288c8c4585b533f9faaa93aa314","3d33e731a93d4b57e662ff094f64f94a745422d4"],"057a1793765d068ea9302f1a29e21734ee58d41e":["6613659748fe4411a7dcf85266e55db1f95f7315"],"31741cf1390044e38a2ec3127cf302ba841bfd75":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"d470c8182e92b264680e34081b75e70a9f2b3c89":["0f4464508ee83288c8c4585b533f9faaa93aa314","0ad30c6a479e764150a3316e57263319775f1df2"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4","79700663e164dece87bed4adfd3e28bab6cb1385"],"c7869f64c874ebf7f317d22c00baf2b6857797a6":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","fb07ab105350b80ed9d63ca64b117084ed7391bc"],"9bb9a29a5e71a90295f175df8919802993142c9a":["5f6bd27530a2846413fe2d00030493c0e2d3a072","f382b2e9f4ca7dbe98e2f15da70983ecfc02b171"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b7e4ca6dc9612ff741d8713743e2bccfae5eadac":["31741cf1390044e38a2ec3127cf302ba841bfd75"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"92212fd254551a0b1156aafc3a1a6ed1a43932ad":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9":["d6f074e73200c07d54f242d3880a8da5a35ff97b","fb07ab105350b80ed9d63ca64b117084ed7391bc"],"6613659748fe4411a7dcf85266e55db1f95f7315":["77f264c55cbf75404f8601ae7290d69157273a56"],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"9d153abcf92dc5329d98571a8c3035df9bd80648":["b6dce319de558e8b80705326dd04d578f74767d9"],"399d5903979ca52514d2bc7e3a362e1c45885c94":["f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"57d2758489b06da76bc6a037793d9ba347ce01fd":["d2dee33619431ada2a7a07f5fe2dbd94bac6a460"],"d08eba3d52b63561ebf936481ce73e6b6a14aa03":["399d5903979ca52514d2bc7e3a362e1c45885c94"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["0f4464508ee83288c8c4585b533f9faaa93aa314","d470c8182e92b264680e34081b75e70a9f2b3c89"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["629c38c4ae4e303d0617e05fbfe508140b32f0a3","764b942fd30efcae6e532c19771f32eeeb0037b2"],"ceaef6cfc68c8ab22a684192e469a8280f9e6e70":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"15250ca94ba8ab3bcdd476daf6bf3f3febb92640":["fb07ab105350b80ed9d63ca64b117084ed7391bc"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["57ae3024996ccdb3c36c42cb890e1efb37df4ce8","02331260bb246364779cb6f04919ca47900d01bb"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf"],"b6dce319de558e8b80705326dd04d578f74767d9":["a851824c09818632c94eba41e60ef5e72e323c8e"],"3d33e731a93d4b57e662ff094f64f94a745422d4":["0f4464508ee83288c8c4585b533f9faaa93aa314","ceaef6cfc68c8ab22a684192e469a8280f9e6e70"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["bec68e7c41fed133827595747d853cad504e481e"]},"commit2Childs":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"63caed6eb28209e181e97822c4c8fdf808884c3b":["6a917aca07a305ab70118a83e84d931503441271"],"f6eee1e5a8555d83dd8f2f2e3c0a4ccec8e7cf9b":["d2dee33619431ada2a7a07f5fe2dbd94bac6a460"],"a4e83191a3e02851a0b67e5335e6922f3e9ea86d":["bec68e7c41fed133827595747d853cad504e481e"],"57ae3024996ccdb3c36c42cb890e1efb37df4ce8":["d6f074e73200c07d54f242d3880a8da5a35ff97b","02331260bb246364779cb6f04919ca47900d01bb","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f"],"b70042a8a492f7054d480ccdd2be9796510d4327":[],"79700663e164dece87bed4adfd3e28bab6cb1385":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82","299a2348fa24151d150182211b6208a38e5e3450","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"77f264c55cbf75404f8601ae7290d69157273a56":["6613659748fe4411a7dcf85266e55db1f95f7315"],"299a2348fa24151d150182211b6208a38e5e3450":[],"790693f23f4e88a59fbb25e47cc25f6d493b03cb":["763da4a9605e47013078edc323b9d4b608f0f9e0"],"f382b2e9f4ca7dbe98e2f15da70983ecfc02b171":["9bb9a29a5e71a90295f175df8919802993142c9a"],"a45bec74b98f6fc05f52770cfb425739e6563960":["77f264c55cbf75404f8601ae7290d69157273a56"],"fb07ab105350b80ed9d63ca64b117084ed7391bc":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","c7869f64c874ebf7f317d22c00baf2b6857797a6","d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9","15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"bec68e7c41fed133827595747d853cad504e481e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"51f5280f31484820499077f41fcdfe92d527d9dc":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"8521d944f9dfb45692ec28235dbf116d47ef69ba":["51f5280f31484820499077f41fcdfe92d527d9dc"],"d2dee33619431ada2a7a07f5fe2dbd94bac6a460":["57d2758489b06da76bc6a037793d9ba347ce01fd"],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["79700663e164dece87bed4adfd3e28bab6cb1385","299a2348fa24151d150182211b6208a38e5e3450","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["0ad30c6a479e764150a3316e57263319775f1df2","d470c8182e92b264680e34081b75e70a9f2b3c89","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","ceaef6cfc68c8ab22a684192e469a8280f9e6e70","3d33e731a93d4b57e662ff094f64f94a745422d4"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9"],"f592209545c71895260367152601e9200399776d":[],"c65d2864d936ccf22dc7ec14dd48b4dff7bacceb":["f382b2e9f4ca7dbe98e2f15da70983ecfc02b171","5f6bd27530a2846413fe2d00030493c0e2d3a072"],"02331260bb246364779cb6f04919ca47900d01bb":["fb07ab105350b80ed9d63ca64b117084ed7391bc","d6f074e73200c07d54f242d3880a8da5a35ff97b","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f"],"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"6a917aca07a305ab70118a83e84d931503441271":["764b942fd30efcae6e532c19771f32eeeb0037b2"],"763da4a9605e47013078edc323b9d4b608f0f9e0":["a4e83191a3e02851a0b67e5335e6922f3e9ea86d"],"764b942fd30efcae6e532c19771f32eeeb0037b2":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"5f6bd27530a2846413fe2d00030493c0e2d3a072":["9bb9a29a5e71a90295f175df8919802993142c9a"],"a851824c09818632c94eba41e60ef5e72e323c8e":["b6dce319de558e8b80705326dd04d578f74767d9"],"0ad30c6a479e764150a3316e57263319775f1df2":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"057a1793765d068ea9302f1a29e21734ee58d41e":["c65d2864d936ccf22dc7ec14dd48b4dff7bacceb","5f6bd27530a2846413fe2d00030493c0e2d3a072"],"31741cf1390044e38a2ec3127cf302ba841bfd75":["b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","b7e4ca6dc9612ff741d8713743e2bccfae5eadac"],"d470c8182e92b264680e34081b75e70a9f2b3c89":["31741cf1390044e38a2ec3127cf302ba841bfd75","92212fd254551a0b1156aafc3a1a6ed1a43932ad","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"c7869f64c874ebf7f317d22c00baf2b6857797a6":[],"9bb9a29a5e71a90295f175df8919802993142c9a":["8521d944f9dfb45692ec28235dbf116d47ef69ba"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"b7e4ca6dc9612ff741d8713743e2bccfae5eadac":["b70042a8a492f7054d480ccdd2be9796510d4327","790693f23f4e88a59fbb25e47cc25f6d493b03cb","f592209545c71895260367152601e9200399776d"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"92212fd254551a0b1156aafc3a1a6ed1a43932ad":[],"d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9":[],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","399d5903979ca52514d2bc7e3a362e1c45885c94"],"6613659748fe4411a7dcf85266e55db1f95f7315":["057a1793765d068ea9302f1a29e21734ee58d41e"],"9d153abcf92dc5329d98571a8c3035df9bd80648":["63caed6eb28209e181e97822c4c8fdf808884c3b"],"57d2758489b06da76bc6a037793d9ba347ce01fd":["a851824c09818632c94eba41e60ef5e72e323c8e"],"399d5903979ca52514d2bc7e3a362e1c45885c94":["d08eba3d52b63561ebf936481ce73e6b6a14aa03"],"d08eba3d52b63561ebf936481ce73e6b6a14aa03":["e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["57ae3024996ccdb3c36c42cb890e1efb37df4ce8"],"ceaef6cfc68c8ab22a684192e469a8280f9e6e70":["3d33e731a93d4b57e662ff094f64f94a745422d4"],"15250ca94ba8ab3bcdd476daf6bf3f3febb92640":["a45bec74b98f6fc05f52770cfb425739e6563960","d3fcb70cf561547c7bb1506e0cf32ca7b1287064","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["c7869f64c874ebf7f317d22c00baf2b6857797a6"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["f6eee1e5a8555d83dd8f2f2e3c0a4ccec8e7cf9b","615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"3d33e731a93d4b57e662ff094f64f94a745422d4":["0ad30c6a479e764150a3316e57263319775f1df2"],"b6dce319de558e8b80705326dd04d578f74767d9":["9d153abcf92dc5329d98571a8c3035df9bd80648"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","b70042a8a492f7054d480ccdd2be9796510d4327","299a2348fa24151d150182211b6208a38e5e3450","f592209545c71895260367152601e9200399776d","d3fcb70cf561547c7bb1506e0cf32ca7b1287064","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","c7869f64c874ebf7f317d22c00baf2b6857797a6","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","92212fd254551a0b1156aafc3a1a6ed1a43932ad","d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}