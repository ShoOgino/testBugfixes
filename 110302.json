{"path":"src/test/org/apache/solr/analysis/TestMappingCharFilter#testTokenStream().mjava","commits":[{"id":"00c1e7284eb0e728903446dd05972acc9905dd53","date":1226627781,"type":0,"author":"Koji Sekiguchi","isMerge":false,"pathNew":"src/test/org/apache/solr/analysis/TestMappingCharFilter#testTokenStream().mjava","pathOld":"/dev/null","sourceNew":"  //\n  //                1111111111222\n  //      01234567890123456789012\n  //(in)  h i j k ll cccc bbb aa\n  //\n  //                1111111111222\n  //      01234567890123456789012\n  //(out) i i jj kkk llll cc b a\n  //\n  //    h, 0, 1 =>    i, 0, 1\n  //    i, 2, 3 =>    i, 2, 3\n  //    j, 4, 5 =>   jj, 4, 5\n  //    k, 6, 7 =>  kkk, 6, 7\n  //   ll, 8,10 => llll, 8,10\n  // cccc,11,15 =>   cc,11,15\n  //  bbb,16,19 =>    b,16,19\n  //   aa,20,22 =>    a,20,22\n  //\n  public void testTokenStream() throws Exception {\n    CharStream cs = new MappingCharFilter( normMap, new CharReader( new StringReader( \"h i j k ll cccc bbb aa\" ) ) );\n    TokenStream ts = new CharStreamAwareWhitespaceTokenizer( cs );\n    List<Token> real = getTokens( ts );\n    List<Token> expect = tokens( \"i,1,0,1 i,1,2,3 jj,1,4,5 kkk,1,6,7 llll,1,8,10 cc,1,11,15 b,1,16,19 a,1,20,22\" );\n    assertTokEqualOff( expect, real );\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28c0138f618eb6728ba8fd2428b4f978fc379780","date":1237964337,"type":3,"author":"Koji Sekiguchi","isMerge":false,"pathNew":"src/test/org/apache/solr/analysis/TestMappingCharFilter#testTokenStream().mjava","pathOld":"src/test/org/apache/solr/analysis/TestMappingCharFilter#testTokenStream().mjava","sourceNew":"  //\n  //                1111111111222\n  //      01234567890123456789012\n  //(in)  h i j k ll cccc bbb aa\n  //\n  //                1111111111222\n  //      01234567890123456789012\n  //(out) i i jj kkk llll cc b a\n  //\n  //    h, 0, 1 =>    i, 0, 1\n  //    i, 2, 3 =>    i, 2, 3\n  //    j, 4, 5 =>   jj, 4, 5\n  //    k, 6, 7 =>  kkk, 6, 7\n  //   ll, 8,10 => llll, 8,10\n  // cccc,11,15 =>   cc,11,15\n  //  bbb,16,19 =>    b,16,19\n  //   aa,20,22 =>    a,20,22\n  //\n  public void testTokenStream() throws Exception {\n    CharStream cs = new MappingCharFilter( normMap, CharReader.get( new StringReader( \"h i j k ll cccc bbb aa\" ) ) );\n    TokenStream ts = new CharStreamAwareWhitespaceTokenizer( cs );\n    List<Token> real = getTokens( ts );\n    List<Token> expect = tokens( \"i,1,0,1 i,1,2,3 jj,1,4,5 kkk,1,6,7 llll,1,8,10 cc,1,11,15 b,1,16,19 a,1,20,22\" );\n    assertTokEqualOff( expect, real );\n  }\n\n","sourceOld":"  //\n  //                1111111111222\n  //      01234567890123456789012\n  //(in)  h i j k ll cccc bbb aa\n  //\n  //                1111111111222\n  //      01234567890123456789012\n  //(out) i i jj kkk llll cc b a\n  //\n  //    h, 0, 1 =>    i, 0, 1\n  //    i, 2, 3 =>    i, 2, 3\n  //    j, 4, 5 =>   jj, 4, 5\n  //    k, 6, 7 =>  kkk, 6, 7\n  //   ll, 8,10 => llll, 8,10\n  // cccc,11,15 =>   cc,11,15\n  //  bbb,16,19 =>    b,16,19\n  //   aa,20,22 =>    a,20,22\n  //\n  public void testTokenStream() throws Exception {\n    CharStream cs = new MappingCharFilter( normMap, new CharReader( new StringReader( \"h i j k ll cccc bbb aa\" ) ) );\n    TokenStream ts = new CharStreamAwareWhitespaceTokenizer( cs );\n    List<Token> real = getTokens( ts );\n    List<Token> expect = tokens( \"i,1,0,1 i,1,2,3 jj,1,4,5 kkk,1,6,7 llll,1,8,10 cc,1,11,15 b,1,16,19 a,1,20,22\" );\n    assertTokEqualOff( expect, real );\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1e77721aaf23393f6ea7926045ae6f8efea0ce8e","date":1247678464,"type":4,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"/dev/null","pathOld":"src/test/org/apache/solr/analysis/TestMappingCharFilter#testTokenStream().mjava","sourceNew":null,"sourceOld":"  //\n  //                1111111111222\n  //      01234567890123456789012\n  //(in)  h i j k ll cccc bbb aa\n  //\n  //                1111111111222\n  //      01234567890123456789012\n  //(out) i i jj kkk llll cc b a\n  //\n  //    h, 0, 1 =>    i, 0, 1\n  //    i, 2, 3 =>    i, 2, 3\n  //    j, 4, 5 =>   jj, 4, 5\n  //    k, 6, 7 =>  kkk, 6, 7\n  //   ll, 8,10 => llll, 8,10\n  // cccc,11,15 =>   cc,11,15\n  //  bbb,16,19 =>    b,16,19\n  //   aa,20,22 =>    a,20,22\n  //\n  public void testTokenStream() throws Exception {\n    CharStream cs = new MappingCharFilter( normMap, CharReader.get( new StringReader( \"h i j k ll cccc bbb aa\" ) ) );\n    TokenStream ts = new CharStreamAwareWhitespaceTokenizer( cs );\n    List<Token> real = getTokens( ts );\n    List<Token> expect = tokens( \"i,1,0,1 i,1,2,3 jj,1,4,5 kkk,1,6,7 llll,1,8,10 cc,1,11,15 b,1,16,19 a,1,20,22\" );\n    assertTokEqualOff( expect, real );\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"1e77721aaf23393f6ea7926045ae6f8efea0ce8e":["28c0138f618eb6728ba8fd2428b4f978fc379780"],"28c0138f618eb6728ba8fd2428b4f978fc379780":["00c1e7284eb0e728903446dd05972acc9905dd53"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"00c1e7284eb0e728903446dd05972acc9905dd53":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"1e77721aaf23393f6ea7926045ae6f8efea0ce8e":[],"28c0138f618eb6728ba8fd2428b4f978fc379780":["1e77721aaf23393f6ea7926045ae6f8efea0ce8e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["00c1e7284eb0e728903446dd05972acc9905dd53"],"00c1e7284eb0e728903446dd05972acc9905dd53":["28c0138f618eb6728ba8fd2428b4f978fc379780"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["1e77721aaf23393f6ea7926045ae6f8efea0ce8e","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"pathCommit":null}