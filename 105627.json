{"path":"lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestUAX29URLEmailTokenizer#testLongEMAILatomText().mjava","commits":[{"id":"3c00ffa555aa637d932f7d491038cf9992403994","date":1408702746,"type":0,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestUAX29URLEmailTokenizer#testLongEMAILatomText().mjava","pathOld":"/dev/null","sourceNew":"  // LUCENE-5440: extremely slow tokenization of text matching email <local-part> (before the '@')\n  public void testLongEMAILatomText() throws Exception {\n    // EMAILatomText = [A-Za-z0-9!#$%&'*+-/=?\\^_`{|}~]\n    char[] emailAtomChars\n        = \"!#$%&'*+,-./0123456789=?ABCDEFGHIJKLMNOPQRSTUVWXYZ^_`abcdefghijklmnopqrstuvwxyz{|}~\".toCharArray();\n    StringBuilder builder = new StringBuilder();\n    int numChars = TestUtil.nextInt(random(), 100 * 1024, 3 * 1024 * 1024);\n    for (int i = 0 ; i < numChars ; ++i) {\n      builder.append(emailAtomChars[random().nextInt(emailAtomChars.length)]);\n    }\n    int tokenCount = 0;\n    UAX29URLEmailTokenizer ts = new UAX29URLEmailTokenizer();\n    String text = builder.toString();\n    ts.setReader(new StringReader(text));\n    ts.reset();\n    while (ts.incrementToken()) {\n      tokenCount++;\n    }\n    ts.end();\n    ts.close();\n    assertTrue(tokenCount > 0);\n\n    tokenCount = 0;\n    int newBufferSize = TestUtil.nextInt(random(), 200, 8192);\n    ts.setMaxTokenLength(newBufferSize);\n    ts.setReader(new StringReader(text));\n    ts.reset();\n    while (ts.incrementToken()) {\n      tokenCount++;\n    }\n    ts.end();\n    ts.close();\n    assertTrue(tokenCount > 0);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"91a5e37a1dee5ad8d3fe6d55228839d5d0412999","date":1412798723,"type":5,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/TestUAX29URLEmailTokenizer#testLongEMAILatomText().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestUAX29URLEmailTokenizer#testLongEMAILatomText().mjava","sourceNew":"  // LUCENE-5440: extremely slow tokenization of text matching email <local-part> (before the '@')\n  public void testLongEMAILatomText() throws Exception {\n    // EMAILatomText = [A-Za-z0-9!#$%&'*+-/=?\\^_`{|}~]\n    char[] emailAtomChars\n        = \"!#$%&'*+,-./0123456789=?ABCDEFGHIJKLMNOPQRSTUVWXYZ^_`abcdefghijklmnopqrstuvwxyz{|}~\".toCharArray();\n    StringBuilder builder = new StringBuilder();\n    int numChars = TestUtil.nextInt(random(), 100 * 1024, 3 * 1024 * 1024);\n    for (int i = 0 ; i < numChars ; ++i) {\n      builder.append(emailAtomChars[random().nextInt(emailAtomChars.length)]);\n    }\n    int tokenCount = 0;\n    UAX29URLEmailTokenizer ts = new UAX29URLEmailTokenizer();\n    String text = builder.toString();\n    ts.setReader(new StringReader(text));\n    ts.reset();\n    while (ts.incrementToken()) {\n      tokenCount++;\n    }\n    ts.end();\n    ts.close();\n    assertTrue(tokenCount > 0);\n\n    tokenCount = 0;\n    int newBufferSize = TestUtil.nextInt(random(), 200, 8192);\n    ts.setMaxTokenLength(newBufferSize);\n    ts.setReader(new StringReader(text));\n    ts.reset();\n    while (ts.incrementToken()) {\n      tokenCount++;\n    }\n    ts.end();\n    ts.close();\n    assertTrue(tokenCount > 0);\n  }\n\n","sourceOld":"  // LUCENE-5440: extremely slow tokenization of text matching email <local-part> (before the '@')\n  public void testLongEMAILatomText() throws Exception {\n    // EMAILatomText = [A-Za-z0-9!#$%&'*+-/=?\\^_`{|}~]\n    char[] emailAtomChars\n        = \"!#$%&'*+,-./0123456789=?ABCDEFGHIJKLMNOPQRSTUVWXYZ^_`abcdefghijklmnopqrstuvwxyz{|}~\".toCharArray();\n    StringBuilder builder = new StringBuilder();\n    int numChars = TestUtil.nextInt(random(), 100 * 1024, 3 * 1024 * 1024);\n    for (int i = 0 ; i < numChars ; ++i) {\n      builder.append(emailAtomChars[random().nextInt(emailAtomChars.length)]);\n    }\n    int tokenCount = 0;\n    UAX29URLEmailTokenizer ts = new UAX29URLEmailTokenizer();\n    String text = builder.toString();\n    ts.setReader(new StringReader(text));\n    ts.reset();\n    while (ts.incrementToken()) {\n      tokenCount++;\n    }\n    ts.end();\n    ts.close();\n    assertTrue(tokenCount > 0);\n\n    tokenCount = 0;\n    int newBufferSize = TestUtil.nextInt(random(), 200, 8192);\n    ts.setMaxTokenLength(newBufferSize);\n    ts.setReader(new StringReader(text));\n    ts.reset();\n    while (ts.incrementToken()) {\n      tokenCount++;\n    }\n    ts.end();\n    ts.close();\n    assertTrue(tokenCount > 0);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"55980207f1977bd1463465de1659b821347e2fa8","date":1413336386,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/TestUAX29URLEmailTokenizer#testLongEMAILatomText().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestUAX29URLEmailTokenizer#testLongEMAILatomText().mjava","sourceNew":"  // LUCENE-5440: extremely slow tokenization of text matching email <local-part> (before the '@')\n  public void testLongEMAILatomText() throws Exception {\n    // EMAILatomText = [A-Za-z0-9!#$%&'*+-/=?\\^_`{|}~]\n    char[] emailAtomChars\n        = \"!#$%&'*+,-./0123456789=?ABCDEFGHIJKLMNOPQRSTUVWXYZ^_`abcdefghijklmnopqrstuvwxyz{|}~\".toCharArray();\n    StringBuilder builder = new StringBuilder();\n    int numChars = TestUtil.nextInt(random(), 100 * 1024, 3 * 1024 * 1024);\n    for (int i = 0 ; i < numChars ; ++i) {\n      builder.append(emailAtomChars[random().nextInt(emailAtomChars.length)]);\n    }\n    int tokenCount = 0;\n    UAX29URLEmailTokenizer ts = new UAX29URLEmailTokenizer();\n    String text = builder.toString();\n    ts.setReader(new StringReader(text));\n    ts.reset();\n    while (ts.incrementToken()) {\n      tokenCount++;\n    }\n    ts.end();\n    ts.close();\n    assertTrue(tokenCount > 0);\n\n    tokenCount = 0;\n    int newBufferSize = TestUtil.nextInt(random(), 200, 8192);\n    ts.setMaxTokenLength(newBufferSize);\n    ts.setReader(new StringReader(text));\n    ts.reset();\n    while (ts.incrementToken()) {\n      tokenCount++;\n    }\n    ts.end();\n    ts.close();\n    assertTrue(tokenCount > 0);\n  }\n\n","sourceOld":"  // LUCENE-5440: extremely slow tokenization of text matching email <local-part> (before the '@')\n  public void testLongEMAILatomText() throws Exception {\n    // EMAILatomText = [A-Za-z0-9!#$%&'*+-/=?\\^_`{|}~]\n    char[] emailAtomChars\n        = \"!#$%&'*+,-./0123456789=?ABCDEFGHIJKLMNOPQRSTUVWXYZ^_`abcdefghijklmnopqrstuvwxyz{|}~\".toCharArray();\n    StringBuilder builder = new StringBuilder();\n    int numChars = TestUtil.nextInt(random(), 100 * 1024, 3 * 1024 * 1024);\n    for (int i = 0 ; i < numChars ; ++i) {\n      builder.append(emailAtomChars[random().nextInt(emailAtomChars.length)]);\n    }\n    int tokenCount = 0;\n    UAX29URLEmailTokenizer ts = new UAX29URLEmailTokenizer();\n    String text = builder.toString();\n    ts.setReader(new StringReader(text));\n    ts.reset();\n    while (ts.incrementToken()) {\n      tokenCount++;\n    }\n    ts.end();\n    ts.close();\n    assertTrue(tokenCount > 0);\n\n    tokenCount = 0;\n    int newBufferSize = TestUtil.nextInt(random(), 200, 8192);\n    ts.setMaxTokenLength(newBufferSize);\n    ts.setReader(new StringReader(text));\n    ts.reset();\n    while (ts.incrementToken()) {\n      tokenCount++;\n    }\n    ts.end();\n    ts.close();\n    assertTrue(tokenCount > 0);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"55980207f1977bd1463465de1659b821347e2fa8":["3c00ffa555aa637d932f7d491038cf9992403994","91a5e37a1dee5ad8d3fe6d55228839d5d0412999"],"91a5e37a1dee5ad8d3fe6d55228839d5d0412999":["3c00ffa555aa637d932f7d491038cf9992403994"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3c00ffa555aa637d932f7d491038cf9992403994":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["91a5e37a1dee5ad8d3fe6d55228839d5d0412999"]},"commit2Childs":{"55980207f1977bd1463465de1659b821347e2fa8":[],"91a5e37a1dee5ad8d3fe6d55228839d5d0412999":["55980207f1977bd1463465de1659b821347e2fa8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3c00ffa555aa637d932f7d491038cf9992403994"],"3c00ffa555aa637d932f7d491038cf9992403994":["55980207f1977bd1463465de1659b821347e2fa8","91a5e37a1dee5ad8d3fe6d55228839d5d0412999"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["55980207f1977bd1463465de1659b821347e2fa8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}