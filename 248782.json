{"path":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#build(int,int,MutablePointsReader,int,int,IndexOutput,byte[],byte[],byte[],long[],int[]).mjava","commits":[{"id":"d561885e9bb6238af1ff8afe8630dcfe49b66ac7","date":1469780634,"type":0,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#build(int,int,MutablePointsReader,int,int,IndexOutput,byte[],byte[],byte[],long[],int[]).mjava","pathOld":"/dev/null","sourceNew":"  /* Recursively reorders the provided reader and writes the bkd-tree on the fly. */\n  private void build(int nodeID, int leafNodeOffset,\n      MutablePointsReader reader, int from, int to,\n      IndexOutput out,\n      byte[] minPackedValue, byte[] maxPackedValue,\n      byte[] splitPackedValues,\n      long[] leafBlockFPs,\n      int[] spareDocIds) throws IOException {\n\n    if (nodeID >= leafNodeOffset) {\n      // leaf node\n      final int count = to - from;\n      assert count <= maxPointsInLeafNode;\n\n      // Compute common prefixes\n      Arrays.fill(commonPrefixLengths, bytesPerDim);\n      reader.getValue(from, scratch1);\n      for (int i = from + 1; i < to; ++i) {\n        reader.getValue(i, scratch2);\n        for (int dim=0;dim<numDims;dim++) {\n          final int offset = dim * bytesPerDim;\n          for(int j=0;j<commonPrefixLengths[dim];j++) {\n            if (scratch1[offset+j] != scratch2[offset+j]) {\n              commonPrefixLengths[dim] = j;\n              break;\n            }\n          }\n        }\n      }\n\n      // Find the dimension that has the least number of unique bytes at commonPrefixLengths[dim]\n      FixedBitSet[] usedBytes = new FixedBitSet[numDims];\n      for (int dim = 0; dim < numDims; ++dim) {\n        if (commonPrefixLengths[dim] < bytesPerDim) {\n          usedBytes[dim] = new FixedBitSet(256);\n        }\n      }\n      for (int i = from + 1; i < to; ++i) {\n        for (int dim=0;dim<numDims;dim++) {\n          if (usedBytes[dim] != null) {\n            byte b = reader.getByteAt(i, dim * bytesPerDim + commonPrefixLengths[dim]);\n            usedBytes[dim].set(Byte.toUnsignedInt(b));\n          }\n        }\n      }\n      int sortedDim = 0;\n      int sortedDimCardinality = Integer.MAX_VALUE;\n      for (int dim = 0; dim < numDims; ++dim) {\n        if (usedBytes[dim] != null) {\n          final int cardinality = usedBytes[dim].cardinality();\n          if (cardinality < sortedDimCardinality) {\n            sortedDim = dim;\n            sortedDimCardinality = cardinality;\n          }\n        }\n      }\n\n      // sort by sortedDim\n      MutablePointsReaderUtils.sortByDim(sortedDim, bytesPerDim, commonPrefixLengths,\n          reader, from, to, scratch1, scratch2);\n\n      // Save the block file pointer:\n      leafBlockFPs[nodeID - leafNodeOffset] = out.getFilePointer();\n\n      // Write doc IDs\n      int[] docIDs = spareDocIds;\n      for (int i = from; i < to; ++i) {\n        docIDs[i - from] = reader.getDocID(i);\n      }\n      writeLeafBlockDocs(out, docIDs, 0, count);\n\n      // Write the common prefixes:\n      reader.getValue(from, scratch1);\n      writeCommonPrefixes(out, commonPrefixLengths, scratch1);\n\n      // Write the full values:\n      IntFunction<BytesRef> packedValues = new IntFunction<BytesRef>() {\n        final BytesRef scratch = new BytesRef(packedBytesLength);\n\n        {\n          scratch.offset = 0;\n          scratch.length = packedBytesLength;\n        }\n\n        @Override\n        public BytesRef apply(int i) {\n          reader.getValue(from + i, scratch.bytes);\n          return scratch;\n        }\n      };\n      assert valuesInOrderAndBounds(count, sortedDim, minPackedValue, maxPackedValue, packedValues,\n          docIDs, 0);\n      writeLeafBlockPackedValues(out, commonPrefixLengths, count, sortedDim, packedValues);\n\n    } else {\n      // inner node\n\n      // compute the split dimension and partition around it\n      final int splitDim = split(minPackedValue, maxPackedValue);\n      final int mid = (from + to + 1) >>> 1;\n\n      int commonPrefixLen = bytesPerDim;\n      for (int i = 0; i < bytesPerDim; ++i) {\n        if (minPackedValue[splitDim * bytesPerDim + i] != maxPackedValue[splitDim * bytesPerDim + i]) {\n          commonPrefixLen = i;\n          break;\n        }\n      }\n      MutablePointsReaderUtils.partition(maxDoc, splitDim, bytesPerDim, commonPrefixLen,\n          reader, from, to, mid, scratch1, scratch2);\n\n      // set the split value\n      final int address = nodeID * (1+bytesPerDim);\n      splitPackedValues[address] = (byte) splitDim;\n      reader.getValue(mid, scratch1);\n      System.arraycopy(scratch1, splitDim * bytesPerDim, splitPackedValues, address + 1, bytesPerDim);\n\n      byte[] minSplitPackedValue = Arrays.copyOf(minPackedValue, packedBytesLength);\n      byte[] maxSplitPackedValue = Arrays.copyOf(maxPackedValue, packedBytesLength);\n      System.arraycopy(scratch1, splitDim * bytesPerDim, minSplitPackedValue, splitDim * bytesPerDim, bytesPerDim);\n      System.arraycopy(scratch1, splitDim * bytesPerDim, maxSplitPackedValue, splitDim * bytesPerDim, bytesPerDim);\n\n      // recurse\n      build(nodeID * 2, leafNodeOffset, reader, from, mid, out,\n          minPackedValue, maxSplitPackedValue, splitPackedValues, leafBlockFPs, spareDocIds);\n      build(nodeID * 2 + 1, leafNodeOffset, reader, mid, to, out,\n          minSplitPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs, spareDocIds);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a20457919db052812998f60294d17daa883ff972","date":1470227748,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#build(int,int,MutablePointsReader,int,int,IndexOutput,byte[],byte[],byte[],long[],int[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#build(int,int,MutablePointsReader,int,int,IndexOutput,byte[],byte[],byte[],long[],int[]).mjava","sourceNew":"  /* Recursively reorders the provided reader and writes the bkd-tree on the fly. */\n  private void build(int nodeID, int leafNodeOffset,\n      MutablePointsReader reader, int from, int to,\n      IndexOutput out,\n      byte[] minPackedValue, byte[] maxPackedValue,\n      byte[] splitPackedValues,\n      long[] leafBlockFPs,\n      int[] spareDocIds) throws IOException {\n\n    if (nodeID >= leafNodeOffset) {\n      // leaf node\n      final int count = to - from;\n      assert count <= maxPointsInLeafNode;\n\n      // Compute common prefixes\n      Arrays.fill(commonPrefixLengths, bytesPerDim);\n      reader.getValue(from, scratchBytesRef1);\n      for (int i = from + 1; i < to; ++i) {\n        reader.getValue(i, scratchBytesRef2);\n        for (int dim=0;dim<numDims;dim++) {\n          final int offset = dim * bytesPerDim;\n          for(int j=0;j<commonPrefixLengths[dim];j++) {\n            if (scratchBytesRef1.bytes[scratchBytesRef1.offset+offset+j] != scratchBytesRef2.bytes[scratchBytesRef2.offset+offset+j]) {\n              commonPrefixLengths[dim] = j;\n              break;\n            }\n          }\n        }\n      }\n\n      // Find the dimension that has the least number of unique bytes at commonPrefixLengths[dim]\n      FixedBitSet[] usedBytes = new FixedBitSet[numDims];\n      for (int dim = 0; dim < numDims; ++dim) {\n        if (commonPrefixLengths[dim] < bytesPerDim) {\n          usedBytes[dim] = new FixedBitSet(256);\n        }\n      }\n      for (int i = from + 1; i < to; ++i) {\n        for (int dim=0;dim<numDims;dim++) {\n          if (usedBytes[dim] != null) {\n            byte b = reader.getByteAt(i, dim * bytesPerDim + commonPrefixLengths[dim]);\n            usedBytes[dim].set(Byte.toUnsignedInt(b));\n          }\n        }\n      }\n      int sortedDim = 0;\n      int sortedDimCardinality = Integer.MAX_VALUE;\n      for (int dim = 0; dim < numDims; ++dim) {\n        if (usedBytes[dim] != null) {\n          final int cardinality = usedBytes[dim].cardinality();\n          if (cardinality < sortedDimCardinality) {\n            sortedDim = dim;\n            sortedDimCardinality = cardinality;\n          }\n        }\n      }\n\n      // sort by sortedDim\n      MutablePointsReaderUtils.sortByDim(sortedDim, bytesPerDim, commonPrefixLengths,\n          reader, from, to, scratchBytesRef1, scratchBytesRef2);\n\n      // Save the block file pointer:\n      leafBlockFPs[nodeID - leafNodeOffset] = out.getFilePointer();\n\n      // Write doc IDs\n      int[] docIDs = spareDocIds;\n      for (int i = from; i < to; ++i) {\n        docIDs[i - from] = reader.getDocID(i);\n      }\n      writeLeafBlockDocs(out, docIDs, 0, count);\n\n      // Write the common prefixes:\n      reader.getValue(from, scratchBytesRef1);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset, scratch1, 0, packedBytesLength);\n      writeCommonPrefixes(out, commonPrefixLengths, scratch1);\n\n      // Write the full values:\n      IntFunction<BytesRef> packedValues = new IntFunction<BytesRef>() {\n        @Override\n        public BytesRef apply(int i) {\n          reader.getValue(from + i, scratchBytesRef1);\n          return scratchBytesRef1;\n        }\n      };\n      assert valuesInOrderAndBounds(count, sortedDim, minPackedValue, maxPackedValue, packedValues,\n          docIDs, 0);\n      writeLeafBlockPackedValues(out, commonPrefixLengths, count, sortedDim, packedValues);\n\n    } else {\n      // inner node\n\n      // compute the split dimension and partition around it\n      final int splitDim = split(minPackedValue, maxPackedValue);\n      final int mid = (from + to + 1) >>> 1;\n\n      int commonPrefixLen = bytesPerDim;\n      for (int i = 0; i < bytesPerDim; ++i) {\n        if (minPackedValue[splitDim * bytesPerDim + i] != maxPackedValue[splitDim * bytesPerDim + i]) {\n          commonPrefixLen = i;\n          break;\n        }\n      }\n      MutablePointsReaderUtils.partition(maxDoc, splitDim, bytesPerDim, commonPrefixLen,\n          reader, from, to, mid, scratchBytesRef1, scratchBytesRef2);\n\n      // set the split value\n      final int address = nodeID * (1+bytesPerDim);\n      splitPackedValues[address] = (byte) splitDim;\n      reader.getValue(mid, scratchBytesRef1);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + splitDim * bytesPerDim, splitPackedValues, address + 1, bytesPerDim);\n\n      byte[] minSplitPackedValue = Arrays.copyOf(minPackedValue, packedBytesLength);\n      byte[] maxSplitPackedValue = Arrays.copyOf(maxPackedValue, packedBytesLength);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + splitDim * bytesPerDim,\n          minSplitPackedValue, splitDim * bytesPerDim, bytesPerDim);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + splitDim * bytesPerDim,\n          maxSplitPackedValue, splitDim * bytesPerDim, bytesPerDim);\n\n      // recurse\n      build(nodeID * 2, leafNodeOffset, reader, from, mid, out,\n          minPackedValue, maxSplitPackedValue, splitPackedValues, leafBlockFPs, spareDocIds);\n      build(nodeID * 2 + 1, leafNodeOffset, reader, mid, to, out,\n          minSplitPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs, spareDocIds);\n    }\n  }\n\n","sourceOld":"  /* Recursively reorders the provided reader and writes the bkd-tree on the fly. */\n  private void build(int nodeID, int leafNodeOffset,\n      MutablePointsReader reader, int from, int to,\n      IndexOutput out,\n      byte[] minPackedValue, byte[] maxPackedValue,\n      byte[] splitPackedValues,\n      long[] leafBlockFPs,\n      int[] spareDocIds) throws IOException {\n\n    if (nodeID >= leafNodeOffset) {\n      // leaf node\n      final int count = to - from;\n      assert count <= maxPointsInLeafNode;\n\n      // Compute common prefixes\n      Arrays.fill(commonPrefixLengths, bytesPerDim);\n      reader.getValue(from, scratch1);\n      for (int i = from + 1; i < to; ++i) {\n        reader.getValue(i, scratch2);\n        for (int dim=0;dim<numDims;dim++) {\n          final int offset = dim * bytesPerDim;\n          for(int j=0;j<commonPrefixLengths[dim];j++) {\n            if (scratch1[offset+j] != scratch2[offset+j]) {\n              commonPrefixLengths[dim] = j;\n              break;\n            }\n          }\n        }\n      }\n\n      // Find the dimension that has the least number of unique bytes at commonPrefixLengths[dim]\n      FixedBitSet[] usedBytes = new FixedBitSet[numDims];\n      for (int dim = 0; dim < numDims; ++dim) {\n        if (commonPrefixLengths[dim] < bytesPerDim) {\n          usedBytes[dim] = new FixedBitSet(256);\n        }\n      }\n      for (int i = from + 1; i < to; ++i) {\n        for (int dim=0;dim<numDims;dim++) {\n          if (usedBytes[dim] != null) {\n            byte b = reader.getByteAt(i, dim * bytesPerDim + commonPrefixLengths[dim]);\n            usedBytes[dim].set(Byte.toUnsignedInt(b));\n          }\n        }\n      }\n      int sortedDim = 0;\n      int sortedDimCardinality = Integer.MAX_VALUE;\n      for (int dim = 0; dim < numDims; ++dim) {\n        if (usedBytes[dim] != null) {\n          final int cardinality = usedBytes[dim].cardinality();\n          if (cardinality < sortedDimCardinality) {\n            sortedDim = dim;\n            sortedDimCardinality = cardinality;\n          }\n        }\n      }\n\n      // sort by sortedDim\n      MutablePointsReaderUtils.sortByDim(sortedDim, bytesPerDim, commonPrefixLengths,\n          reader, from, to, scratch1, scratch2);\n\n      // Save the block file pointer:\n      leafBlockFPs[nodeID - leafNodeOffset] = out.getFilePointer();\n\n      // Write doc IDs\n      int[] docIDs = spareDocIds;\n      for (int i = from; i < to; ++i) {\n        docIDs[i - from] = reader.getDocID(i);\n      }\n      writeLeafBlockDocs(out, docIDs, 0, count);\n\n      // Write the common prefixes:\n      reader.getValue(from, scratch1);\n      writeCommonPrefixes(out, commonPrefixLengths, scratch1);\n\n      // Write the full values:\n      IntFunction<BytesRef> packedValues = new IntFunction<BytesRef>() {\n        final BytesRef scratch = new BytesRef(packedBytesLength);\n\n        {\n          scratch.offset = 0;\n          scratch.length = packedBytesLength;\n        }\n\n        @Override\n        public BytesRef apply(int i) {\n          reader.getValue(from + i, scratch.bytes);\n          return scratch;\n        }\n      };\n      assert valuesInOrderAndBounds(count, sortedDim, minPackedValue, maxPackedValue, packedValues,\n          docIDs, 0);\n      writeLeafBlockPackedValues(out, commonPrefixLengths, count, sortedDim, packedValues);\n\n    } else {\n      // inner node\n\n      // compute the split dimension and partition around it\n      final int splitDim = split(minPackedValue, maxPackedValue);\n      final int mid = (from + to + 1) >>> 1;\n\n      int commonPrefixLen = bytesPerDim;\n      for (int i = 0; i < bytesPerDim; ++i) {\n        if (minPackedValue[splitDim * bytesPerDim + i] != maxPackedValue[splitDim * bytesPerDim + i]) {\n          commonPrefixLen = i;\n          break;\n        }\n      }\n      MutablePointsReaderUtils.partition(maxDoc, splitDim, bytesPerDim, commonPrefixLen,\n          reader, from, to, mid, scratch1, scratch2);\n\n      // set the split value\n      final int address = nodeID * (1+bytesPerDim);\n      splitPackedValues[address] = (byte) splitDim;\n      reader.getValue(mid, scratch1);\n      System.arraycopy(scratch1, splitDim * bytesPerDim, splitPackedValues, address + 1, bytesPerDim);\n\n      byte[] minSplitPackedValue = Arrays.copyOf(minPackedValue, packedBytesLength);\n      byte[] maxSplitPackedValue = Arrays.copyOf(maxPackedValue, packedBytesLength);\n      System.arraycopy(scratch1, splitDim * bytesPerDim, minSplitPackedValue, splitDim * bytesPerDim, bytesPerDim);\n      System.arraycopy(scratch1, splitDim * bytesPerDim, maxSplitPackedValue, splitDim * bytesPerDim, bytesPerDim);\n\n      // recurse\n      build(nodeID * 2, leafNodeOffset, reader, from, mid, out,\n          minPackedValue, maxSplitPackedValue, splitPackedValues, leafBlockFPs, spareDocIds);\n      build(nodeID * 2 + 1, leafNodeOffset, reader, mid, to, out,\n          minSplitPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs, spareDocIds);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3b013574eedcdbac35dc7e35b0ee616ffc38895d","date":1470897818,"type":0,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#build(int,int,MutablePointsReader,int,int,IndexOutput,byte[],byte[],byte[],long[],int[]).mjava","pathOld":"/dev/null","sourceNew":"  /* Recursively reorders the provided reader and writes the bkd-tree on the fly. */\n  private void build(int nodeID, int leafNodeOffset,\n      MutablePointsReader reader, int from, int to,\n      IndexOutput out,\n      byte[] minPackedValue, byte[] maxPackedValue,\n      byte[] splitPackedValues,\n      long[] leafBlockFPs,\n      int[] spareDocIds) throws IOException {\n\n    if (nodeID >= leafNodeOffset) {\n      // leaf node\n      final int count = to - from;\n      assert count <= maxPointsInLeafNode;\n\n      // Compute common prefixes\n      Arrays.fill(commonPrefixLengths, bytesPerDim);\n      reader.getValue(from, scratchBytesRef1);\n      for (int i = from + 1; i < to; ++i) {\n        reader.getValue(i, scratchBytesRef2);\n        for (int dim=0;dim<numDims;dim++) {\n          final int offset = dim * bytesPerDim;\n          for(int j=0;j<commonPrefixLengths[dim];j++) {\n            if (scratchBytesRef1.bytes[scratchBytesRef1.offset+offset+j] != scratchBytesRef2.bytes[scratchBytesRef2.offset+offset+j]) {\n              commonPrefixLengths[dim] = j;\n              break;\n            }\n          }\n        }\n      }\n\n      // Find the dimension that has the least number of unique bytes at commonPrefixLengths[dim]\n      FixedBitSet[] usedBytes = new FixedBitSet[numDims];\n      for (int dim = 0; dim < numDims; ++dim) {\n        if (commonPrefixLengths[dim] < bytesPerDim) {\n          usedBytes[dim] = new FixedBitSet(256);\n        }\n      }\n      for (int i = from + 1; i < to; ++i) {\n        for (int dim=0;dim<numDims;dim++) {\n          if (usedBytes[dim] != null) {\n            byte b = reader.getByteAt(i, dim * bytesPerDim + commonPrefixLengths[dim]);\n            usedBytes[dim].set(Byte.toUnsignedInt(b));\n          }\n        }\n      }\n      int sortedDim = 0;\n      int sortedDimCardinality = Integer.MAX_VALUE;\n      for (int dim = 0; dim < numDims; ++dim) {\n        if (usedBytes[dim] != null) {\n          final int cardinality = usedBytes[dim].cardinality();\n          if (cardinality < sortedDimCardinality) {\n            sortedDim = dim;\n            sortedDimCardinality = cardinality;\n          }\n        }\n      }\n\n      // sort by sortedDim\n      MutablePointsReaderUtils.sortByDim(sortedDim, bytesPerDim, commonPrefixLengths,\n          reader, from, to, scratchBytesRef1, scratchBytesRef2);\n\n      // Save the block file pointer:\n      leafBlockFPs[nodeID - leafNodeOffset] = out.getFilePointer();\n\n      // Write doc IDs\n      int[] docIDs = spareDocIds;\n      for (int i = from; i < to; ++i) {\n        docIDs[i - from] = reader.getDocID(i);\n      }\n      writeLeafBlockDocs(out, docIDs, 0, count);\n\n      // Write the common prefixes:\n      reader.getValue(from, scratchBytesRef1);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset, scratch1, 0, packedBytesLength);\n      writeCommonPrefixes(out, commonPrefixLengths, scratch1);\n\n      // Write the full values:\n      IntFunction<BytesRef> packedValues = new IntFunction<BytesRef>() {\n        @Override\n        public BytesRef apply(int i) {\n          reader.getValue(from + i, scratchBytesRef1);\n          return scratchBytesRef1;\n        }\n      };\n      assert valuesInOrderAndBounds(count, sortedDim, minPackedValue, maxPackedValue, packedValues,\n          docIDs, 0);\n      writeLeafBlockPackedValues(out, commonPrefixLengths, count, sortedDim, packedValues);\n\n    } else {\n      // inner node\n\n      // compute the split dimension and partition around it\n      final int splitDim = split(minPackedValue, maxPackedValue);\n      final int mid = (from + to + 1) >>> 1;\n\n      int commonPrefixLen = bytesPerDim;\n      for (int i = 0; i < bytesPerDim; ++i) {\n        if (minPackedValue[splitDim * bytesPerDim + i] != maxPackedValue[splitDim * bytesPerDim + i]) {\n          commonPrefixLen = i;\n          break;\n        }\n      }\n      MutablePointsReaderUtils.partition(maxDoc, splitDim, bytesPerDim, commonPrefixLen,\n          reader, from, to, mid, scratchBytesRef1, scratchBytesRef2);\n\n      // set the split value\n      final int address = nodeID * (1+bytesPerDim);\n      splitPackedValues[address] = (byte) splitDim;\n      reader.getValue(mid, scratchBytesRef1);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + splitDim * bytesPerDim, splitPackedValues, address + 1, bytesPerDim);\n\n      byte[] minSplitPackedValue = Arrays.copyOf(minPackedValue, packedBytesLength);\n      byte[] maxSplitPackedValue = Arrays.copyOf(maxPackedValue, packedBytesLength);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + splitDim * bytesPerDim,\n          minSplitPackedValue, splitDim * bytesPerDim, bytesPerDim);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + splitDim * bytesPerDim,\n          maxSplitPackedValue, splitDim * bytesPerDim, bytesPerDim);\n\n      // recurse\n      build(nodeID * 2, leafNodeOffset, reader, from, mid, out,\n          minPackedValue, maxSplitPackedValue, splitPackedValues, leafBlockFPs, spareDocIds);\n      build(nodeID * 2 + 1, leafNodeOffset, reader, mid, to, out,\n          minSplitPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs, spareDocIds);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"367f57e2ee85b7f7e28cfe73370a22cf67624f65","date":1476778467,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#build(int,int,MutablePointValues,int,int,IndexOutput,byte[],byte[],byte[],long[],int[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#build(int,int,MutablePointsReader,int,int,IndexOutput,byte[],byte[],byte[],long[],int[]).mjava","sourceNew":"  /* Recursively reorders the provided reader and writes the bkd-tree on the fly. */\n  private void build(int nodeID, int leafNodeOffset,\n      MutablePointValues reader, int from, int to,\n      IndexOutput out,\n      byte[] minPackedValue, byte[] maxPackedValue,\n      byte[] splitPackedValues,\n      long[] leafBlockFPs,\n      int[] spareDocIds) throws IOException {\n\n    if (nodeID >= leafNodeOffset) {\n      // leaf node\n      final int count = to - from;\n      assert count <= maxPointsInLeafNode;\n\n      // Compute common prefixes\n      Arrays.fill(commonPrefixLengths, bytesPerDim);\n      reader.getValue(from, scratchBytesRef1);\n      for (int i = from + 1; i < to; ++i) {\n        reader.getValue(i, scratchBytesRef2);\n        for (int dim=0;dim<numDims;dim++) {\n          final int offset = dim * bytesPerDim;\n          for(int j=0;j<commonPrefixLengths[dim];j++) {\n            if (scratchBytesRef1.bytes[scratchBytesRef1.offset+offset+j] != scratchBytesRef2.bytes[scratchBytesRef2.offset+offset+j]) {\n              commonPrefixLengths[dim] = j;\n              break;\n            }\n          }\n        }\n      }\n\n      // Find the dimension that has the least number of unique bytes at commonPrefixLengths[dim]\n      FixedBitSet[] usedBytes = new FixedBitSet[numDims];\n      for (int dim = 0; dim < numDims; ++dim) {\n        if (commonPrefixLengths[dim] < bytesPerDim) {\n          usedBytes[dim] = new FixedBitSet(256);\n        }\n      }\n      for (int i = from + 1; i < to; ++i) {\n        for (int dim=0;dim<numDims;dim++) {\n          if (usedBytes[dim] != null) {\n            byte b = reader.getByteAt(i, dim * bytesPerDim + commonPrefixLengths[dim]);\n            usedBytes[dim].set(Byte.toUnsignedInt(b));\n          }\n        }\n      }\n      int sortedDim = 0;\n      int sortedDimCardinality = Integer.MAX_VALUE;\n      for (int dim = 0; dim < numDims; ++dim) {\n        if (usedBytes[dim] != null) {\n          final int cardinality = usedBytes[dim].cardinality();\n          if (cardinality < sortedDimCardinality) {\n            sortedDim = dim;\n            sortedDimCardinality = cardinality;\n          }\n        }\n      }\n\n      // sort by sortedDim\n      MutablePointsReaderUtils.sortByDim(sortedDim, bytesPerDim, commonPrefixLengths,\n          reader, from, to, scratchBytesRef1, scratchBytesRef2);\n\n      // Save the block file pointer:\n      leafBlockFPs[nodeID - leafNodeOffset] = out.getFilePointer();\n\n      // Write doc IDs\n      int[] docIDs = spareDocIds;\n      for (int i = from; i < to; ++i) {\n        docIDs[i - from] = reader.getDocID(i);\n      }\n      writeLeafBlockDocs(out, docIDs, 0, count);\n\n      // Write the common prefixes:\n      reader.getValue(from, scratchBytesRef1);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset, scratch1, 0, packedBytesLength);\n      writeCommonPrefixes(out, commonPrefixLengths, scratch1);\n\n      // Write the full values:\n      IntFunction<BytesRef> packedValues = new IntFunction<BytesRef>() {\n        @Override\n        public BytesRef apply(int i) {\n          reader.getValue(from + i, scratchBytesRef1);\n          return scratchBytesRef1;\n        }\n      };\n      assert valuesInOrderAndBounds(count, sortedDim, minPackedValue, maxPackedValue, packedValues,\n          docIDs, 0);\n      writeLeafBlockPackedValues(out, commonPrefixLengths, count, sortedDim, packedValues);\n\n    } else {\n      // inner node\n\n      // compute the split dimension and partition around it\n      final int splitDim = split(minPackedValue, maxPackedValue);\n      final int mid = (from + to + 1) >>> 1;\n\n      int commonPrefixLen = bytesPerDim;\n      for (int i = 0; i < bytesPerDim; ++i) {\n        if (minPackedValue[splitDim * bytesPerDim + i] != maxPackedValue[splitDim * bytesPerDim + i]) {\n          commonPrefixLen = i;\n          break;\n        }\n      }\n      MutablePointsReaderUtils.partition(maxDoc, splitDim, bytesPerDim, commonPrefixLen,\n          reader, from, to, mid, scratchBytesRef1, scratchBytesRef2);\n\n      // set the split value\n      final int address = nodeID * (1+bytesPerDim);\n      splitPackedValues[address] = (byte) splitDim;\n      reader.getValue(mid, scratchBytesRef1);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + splitDim * bytesPerDim, splitPackedValues, address + 1, bytesPerDim);\n\n      byte[] minSplitPackedValue = Arrays.copyOf(minPackedValue, packedBytesLength);\n      byte[] maxSplitPackedValue = Arrays.copyOf(maxPackedValue, packedBytesLength);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + splitDim * bytesPerDim,\n          minSplitPackedValue, splitDim * bytesPerDim, bytesPerDim);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + splitDim * bytesPerDim,\n          maxSplitPackedValue, splitDim * bytesPerDim, bytesPerDim);\n\n      // recurse\n      build(nodeID * 2, leafNodeOffset, reader, from, mid, out,\n          minPackedValue, maxSplitPackedValue, splitPackedValues, leafBlockFPs, spareDocIds);\n      build(nodeID * 2 + 1, leafNodeOffset, reader, mid, to, out,\n          minSplitPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs, spareDocIds);\n    }\n  }\n\n","sourceOld":"  /* Recursively reorders the provided reader and writes the bkd-tree on the fly. */\n  private void build(int nodeID, int leafNodeOffset,\n      MutablePointsReader reader, int from, int to,\n      IndexOutput out,\n      byte[] minPackedValue, byte[] maxPackedValue,\n      byte[] splitPackedValues,\n      long[] leafBlockFPs,\n      int[] spareDocIds) throws IOException {\n\n    if (nodeID >= leafNodeOffset) {\n      // leaf node\n      final int count = to - from;\n      assert count <= maxPointsInLeafNode;\n\n      // Compute common prefixes\n      Arrays.fill(commonPrefixLengths, bytesPerDim);\n      reader.getValue(from, scratchBytesRef1);\n      for (int i = from + 1; i < to; ++i) {\n        reader.getValue(i, scratchBytesRef2);\n        for (int dim=0;dim<numDims;dim++) {\n          final int offset = dim * bytesPerDim;\n          for(int j=0;j<commonPrefixLengths[dim];j++) {\n            if (scratchBytesRef1.bytes[scratchBytesRef1.offset+offset+j] != scratchBytesRef2.bytes[scratchBytesRef2.offset+offset+j]) {\n              commonPrefixLengths[dim] = j;\n              break;\n            }\n          }\n        }\n      }\n\n      // Find the dimension that has the least number of unique bytes at commonPrefixLengths[dim]\n      FixedBitSet[] usedBytes = new FixedBitSet[numDims];\n      for (int dim = 0; dim < numDims; ++dim) {\n        if (commonPrefixLengths[dim] < bytesPerDim) {\n          usedBytes[dim] = new FixedBitSet(256);\n        }\n      }\n      for (int i = from + 1; i < to; ++i) {\n        for (int dim=0;dim<numDims;dim++) {\n          if (usedBytes[dim] != null) {\n            byte b = reader.getByteAt(i, dim * bytesPerDim + commonPrefixLengths[dim]);\n            usedBytes[dim].set(Byte.toUnsignedInt(b));\n          }\n        }\n      }\n      int sortedDim = 0;\n      int sortedDimCardinality = Integer.MAX_VALUE;\n      for (int dim = 0; dim < numDims; ++dim) {\n        if (usedBytes[dim] != null) {\n          final int cardinality = usedBytes[dim].cardinality();\n          if (cardinality < sortedDimCardinality) {\n            sortedDim = dim;\n            sortedDimCardinality = cardinality;\n          }\n        }\n      }\n\n      // sort by sortedDim\n      MutablePointsReaderUtils.sortByDim(sortedDim, bytesPerDim, commonPrefixLengths,\n          reader, from, to, scratchBytesRef1, scratchBytesRef2);\n\n      // Save the block file pointer:\n      leafBlockFPs[nodeID - leafNodeOffset] = out.getFilePointer();\n\n      // Write doc IDs\n      int[] docIDs = spareDocIds;\n      for (int i = from; i < to; ++i) {\n        docIDs[i - from] = reader.getDocID(i);\n      }\n      writeLeafBlockDocs(out, docIDs, 0, count);\n\n      // Write the common prefixes:\n      reader.getValue(from, scratchBytesRef1);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset, scratch1, 0, packedBytesLength);\n      writeCommonPrefixes(out, commonPrefixLengths, scratch1);\n\n      // Write the full values:\n      IntFunction<BytesRef> packedValues = new IntFunction<BytesRef>() {\n        @Override\n        public BytesRef apply(int i) {\n          reader.getValue(from + i, scratchBytesRef1);\n          return scratchBytesRef1;\n        }\n      };\n      assert valuesInOrderAndBounds(count, sortedDim, minPackedValue, maxPackedValue, packedValues,\n          docIDs, 0);\n      writeLeafBlockPackedValues(out, commonPrefixLengths, count, sortedDim, packedValues);\n\n    } else {\n      // inner node\n\n      // compute the split dimension and partition around it\n      final int splitDim = split(minPackedValue, maxPackedValue);\n      final int mid = (from + to + 1) >>> 1;\n\n      int commonPrefixLen = bytesPerDim;\n      for (int i = 0; i < bytesPerDim; ++i) {\n        if (minPackedValue[splitDim * bytesPerDim + i] != maxPackedValue[splitDim * bytesPerDim + i]) {\n          commonPrefixLen = i;\n          break;\n        }\n      }\n      MutablePointsReaderUtils.partition(maxDoc, splitDim, bytesPerDim, commonPrefixLen,\n          reader, from, to, mid, scratchBytesRef1, scratchBytesRef2);\n\n      // set the split value\n      final int address = nodeID * (1+bytesPerDim);\n      splitPackedValues[address] = (byte) splitDim;\n      reader.getValue(mid, scratchBytesRef1);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + splitDim * bytesPerDim, splitPackedValues, address + 1, bytesPerDim);\n\n      byte[] minSplitPackedValue = Arrays.copyOf(minPackedValue, packedBytesLength);\n      byte[] maxSplitPackedValue = Arrays.copyOf(maxPackedValue, packedBytesLength);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + splitDim * bytesPerDim,\n          minSplitPackedValue, splitDim * bytesPerDim, bytesPerDim);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + splitDim * bytesPerDim,\n          maxSplitPackedValue, splitDim * bytesPerDim, bytesPerDim);\n\n      // recurse\n      build(nodeID * 2, leafNodeOffset, reader, from, mid, out,\n          minPackedValue, maxSplitPackedValue, splitPackedValues, leafBlockFPs, spareDocIds);\n      build(nodeID * 2 + 1, leafNodeOffset, reader, mid, to, out,\n          minSplitPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs, spareDocIds);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a20457919db052812998f60294d17daa883ff972":["d561885e9bb6238af1ff8afe8630dcfe49b66ac7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"367f57e2ee85b7f7e28cfe73370a22cf67624f65":["a20457919db052812998f60294d17daa883ff972"],"d561885e9bb6238af1ff8afe8630dcfe49b66ac7":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","a20457919db052812998f60294d17daa883ff972"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["367f57e2ee85b7f7e28cfe73370a22cf67624f65"]},"commit2Childs":{"a20457919db052812998f60294d17daa883ff972":["367f57e2ee85b7f7e28cfe73370a22cf67624f65","3b013574eedcdbac35dc7e35b0ee616ffc38895d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d561885e9bb6238af1ff8afe8630dcfe49b66ac7","3b013574eedcdbac35dc7e35b0ee616ffc38895d"],"367f57e2ee85b7f7e28cfe73370a22cf67624f65":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d561885e9bb6238af1ff8afe8630dcfe49b66ac7":["a20457919db052812998f60294d17daa883ff972"],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["3b013574eedcdbac35dc7e35b0ee616ffc38895d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}