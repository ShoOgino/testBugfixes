{"path":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testOnlyLeaderIndexes().mjava","commits":[{"id":"61c45e99cf6676da48f19d7511c73712ad39402b","date":1495508331,"type":1,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testOnlyLeaderIndexes().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OnlyLeaderIndexesTest#basicTest().mjava","sourceNew":"  public void testOnlyLeaderIndexes() throws Exception {\n    createAndWaitForCollection(1, 0, 2, 0);\n    \n    CloudSolrClient cloudClient = cluster.getSolrClient();\n    new UpdateRequest()\n        .add(sdoc(\"id\", \"1\"))\n        .add(sdoc(\"id\", \"2\"))\n        .add(sdoc(\"id\", \"3\"))\n        .add(sdoc(\"id\", \"4\"))\n        .process(cloudClient, collectionName);\n\n    {\n      UpdateHandler updateHandler = getSolrCore(true).get(0).getUpdateHandler();\n      RefCounted<IndexWriter> iwRef = updateHandler.getSolrCoreState().getIndexWriter(null);\n      assertTrue(\"IndexWriter at leader must see updates \", iwRef.get().hasUncommittedChanges());\n      iwRef.decref();\n    }\n\n    for (SolrCore solrCore : getSolrCore(false)) {\n      RefCounted<IndexWriter> iwRef = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n      assertFalse(\"IndexWriter at replicas must not see updates \", iwRef.get().hasUncommittedChanges());\n      iwRef.decref();\n    }\n\n    checkRTG(1, 4, cluster.getJettySolrRunners());\n\n    new UpdateRequest()\n        .deleteById(\"1\")\n        .deleteByQuery(\"id:2\")\n        .process(cloudClient, collectionName);\n\n    // The DBQ is not processed at replicas, so we still can get doc2 and other docs by RTG\n    checkRTG(2,4, getSolrRunner(false));\n\n    new UpdateRequest()\n        .commit(cloudClient, collectionName);\n\n    waitForNumDocsInAllActiveReplicas(2);\n\n    // Update log roll over\n    for (SolrCore solrCore : getSolrCore(false)) {\n      UpdateLog updateLog = solrCore.getUpdateHandler().getUpdateLog();\n      assertFalse(updateLog.hasUncommittedChanges());\n    }\n\n    // UpdateLog copy over old updates\n    for (int i = 15; i <= 150; i++) {\n      cloudClient.add(collectionName, sdoc(\"id\",String.valueOf(i)));\n      if (random().nextInt(100) < 15 & i != 150) {\n        cloudClient.commit(collectionName);\n      }\n    }\n    checkRTG(120,150, cluster.getJettySolrRunners());\n    waitForReplicasCatchUp(20);\n  }\n\n","sourceOld":"  public void basicTest() throws Exception {\n    CloudSolrClient cloudClient = cluster.getSolrClient();\n    new UpdateRequest()\n        .add(sdoc(\"id\", \"1\"))\n        .add(sdoc(\"id\", \"2\"))\n        .add(sdoc(\"id\", \"3\"))\n        .add(sdoc(\"id\", \"4\"))\n        .process(cloudClient, COLLECTION);\n\n    {\n      UpdateHandler updateHandler = getSolrCore(true).get(0).getUpdateHandler();\n      RefCounted<IndexWriter> iwRef = updateHandler.getSolrCoreState().getIndexWriter(null);\n      assertTrue(\"IndexWriter at leader must see updates \", iwRef.get().hasUncommittedChanges());\n      iwRef.decref();\n    }\n\n    for (SolrCore solrCore : getSolrCore(false)) {\n      RefCounted<IndexWriter> iwRef = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n      assertFalse(\"IndexWriter at replicas must not see updates \", iwRef.get().hasUncommittedChanges());\n      iwRef.decref();\n    }\n\n    checkRTG(1, 4, cluster.getJettySolrRunners());\n\n    new UpdateRequest()\n        .deleteById(\"1\")\n        .deleteByQuery(\"id:2\")\n        .process(cloudClient, COLLECTION);\n\n    // The DBQ is not processed at replicas, so we still can get doc2 and other docs by RTG\n    checkRTG(2,4, getSolrRunner(false));\n\n    new UpdateRequest()\n        .commit(cloudClient, COLLECTION);\n\n    checkShardConsistency(2, 1);\n\n    // Update log roll over\n    for (SolrCore solrCore : getSolrCore(false)) {\n      UpdateLog updateLog = solrCore.getUpdateHandler().getUpdateLog();\n      assertFalse(updateLog.hasUncommittedChanges());\n    }\n\n    // UpdateLog copy over old updates\n    for (int i = 15; i <= 150; i++) {\n      cloudClient.add(COLLECTION, sdoc(\"id\",String.valueOf(i)));\n      if (random().nextInt(100) < 15 & i != 150) {\n        cloudClient.commit(COLLECTION);\n      }\n    }\n    checkRTG(120,150, cluster.getJettySolrRunners());\n    waitForReplicasCatchUp(20);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e9017cf144952056066919f1ebc7897ff9bd71b1","date":1496757600,"type":0,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testOnlyLeaderIndexes().mjava","pathOld":"/dev/null","sourceNew":"  public void testOnlyLeaderIndexes() throws Exception {\n    createAndWaitForCollection(1, 0, 2, 0);\n    \n    CloudSolrClient cloudClient = cluster.getSolrClient();\n    new UpdateRequest()\n        .add(sdoc(\"id\", \"1\"))\n        .add(sdoc(\"id\", \"2\"))\n        .add(sdoc(\"id\", \"3\"))\n        .add(sdoc(\"id\", \"4\"))\n        .process(cloudClient, collectionName);\n\n    {\n      UpdateHandler updateHandler = getSolrCore(true).get(0).getUpdateHandler();\n      RefCounted<IndexWriter> iwRef = updateHandler.getSolrCoreState().getIndexWriter(null);\n      assertTrue(\"IndexWriter at leader must see updates \", iwRef.get().hasUncommittedChanges());\n      iwRef.decref();\n    }\n\n    for (SolrCore solrCore : getSolrCore(false)) {\n      RefCounted<IndexWriter> iwRef = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n      assertFalse(\"IndexWriter at replicas must not see updates \", iwRef.get().hasUncommittedChanges());\n      iwRef.decref();\n    }\n\n    checkRTG(1, 4, cluster.getJettySolrRunners());\n\n    new UpdateRequest()\n        .deleteById(\"1\")\n        .deleteByQuery(\"id:2\")\n        .process(cloudClient, collectionName);\n\n    // The DBQ is not processed at replicas, so we still can get doc2 and other docs by RTG\n    checkRTG(2,4, getSolrRunner(false));\n\n    new UpdateRequest()\n        .commit(cloudClient, collectionName);\n\n    waitForNumDocsInAllActiveReplicas(2);\n\n    // Update log roll over\n    for (SolrCore solrCore : getSolrCore(false)) {\n      UpdateLog updateLog = solrCore.getUpdateHandler().getUpdateLog();\n      assertFalse(updateLog.hasUncommittedChanges());\n    }\n\n    // UpdateLog copy over old updates\n    for (int i = 15; i <= 150; i++) {\n      cloudClient.add(collectionName, sdoc(\"id\",String.valueOf(i)));\n      if (random().nextInt(100) < 15 & i != 150) {\n        cloudClient.commit(collectionName);\n      }\n    }\n    checkRTG(120,150, cluster.getJettySolrRunners());\n    waitForReplicasCatchUp(20);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"04ecf884544ff74add5faa452748f160c4af904b","date":1506527215,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testOnlyLeaderIndexes().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testOnlyLeaderIndexes().mjava","sourceNew":"  public void testOnlyLeaderIndexes() throws Exception {\n    createAndWaitForCollection(1, 0, 2, 0);\n    \n    CloudSolrClient cloudClient = cluster.getSolrClient();\n    new UpdateRequest()\n        .add(sdoc(\"id\", \"1\"))\n        .add(sdoc(\"id\", \"2\"))\n        .add(sdoc(\"id\", \"3\"))\n        .add(sdoc(\"id\", \"4\"))\n        .process(cloudClient, collectionName);\n\n    {\n      long docsPending = (long) getSolrCore(true).get(0).getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(4, docsPending);\n    }\n\n    for (SolrCore solrCore : getSolrCore(false)) {\n      long docsPending = (long) solrCore.getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(0, docsPending);\n    }\n\n    checkRTG(1, 4, cluster.getJettySolrRunners());\n\n    new UpdateRequest()\n        .deleteById(\"1\")\n        .deleteByQuery(\"id:2\")\n        .process(cloudClient, collectionName);\n\n    // The DBQ is not processed at replicas, so we still can get doc2 and other docs by RTG\n    checkRTG(2,4, getSolrRunner(false));\n\n    Map<SolrCore, Long> timeCopyOverPerCores = getTimesCopyOverOldUpdates(getSolrCore(false));\n    new UpdateRequest()\n        .commit(cloudClient, collectionName);\n\n    waitForNumDocsInAllActiveReplicas(2);\n    assertCopyOverOldUpdates(1, timeCopyOverPerCores);\n\n    // UpdateLog copy over old updates\n    for (int i = 15; i <= 150; i++) {\n      cloudClient.add(collectionName, sdoc(\"id\",String.valueOf(i)));\n      if (random().nextInt(100) < 15 & i != 150) {\n        cloudClient.commit(collectionName);\n      }\n    }\n    checkRTG(120,150, cluster.getJettySolrRunners());\n    waitForReplicasCatchUp(20);\n    assertCopyOverOldUpdates(2, timeCopyOverPerCores);\n  }\n\n","sourceOld":"  public void testOnlyLeaderIndexes() throws Exception {\n    createAndWaitForCollection(1, 0, 2, 0);\n    \n    CloudSolrClient cloudClient = cluster.getSolrClient();\n    new UpdateRequest()\n        .add(sdoc(\"id\", \"1\"))\n        .add(sdoc(\"id\", \"2\"))\n        .add(sdoc(\"id\", \"3\"))\n        .add(sdoc(\"id\", \"4\"))\n        .process(cloudClient, collectionName);\n\n    {\n      UpdateHandler updateHandler = getSolrCore(true).get(0).getUpdateHandler();\n      RefCounted<IndexWriter> iwRef = updateHandler.getSolrCoreState().getIndexWriter(null);\n      assertTrue(\"IndexWriter at leader must see updates \", iwRef.get().hasUncommittedChanges());\n      iwRef.decref();\n    }\n\n    for (SolrCore solrCore : getSolrCore(false)) {\n      RefCounted<IndexWriter> iwRef = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n      assertFalse(\"IndexWriter at replicas must not see updates \", iwRef.get().hasUncommittedChanges());\n      iwRef.decref();\n    }\n\n    checkRTG(1, 4, cluster.getJettySolrRunners());\n\n    new UpdateRequest()\n        .deleteById(\"1\")\n        .deleteByQuery(\"id:2\")\n        .process(cloudClient, collectionName);\n\n    // The DBQ is not processed at replicas, so we still can get doc2 and other docs by RTG\n    checkRTG(2,4, getSolrRunner(false));\n\n    new UpdateRequest()\n        .commit(cloudClient, collectionName);\n\n    waitForNumDocsInAllActiveReplicas(2);\n\n    // Update log roll over\n    for (SolrCore solrCore : getSolrCore(false)) {\n      UpdateLog updateLog = solrCore.getUpdateHandler().getUpdateLog();\n      assertFalse(updateLog.hasUncommittedChanges());\n    }\n\n    // UpdateLog copy over old updates\n    for (int i = 15; i <= 150; i++) {\n      cloudClient.add(collectionName, sdoc(\"id\",String.valueOf(i)));\n      if (random().nextInt(100) < 15 & i != 150) {\n        cloudClient.commit(collectionName);\n      }\n    }\n    checkRTG(120,150, cluster.getJettySolrRunners());\n    waitForReplicasCatchUp(20);\n  }\n\n","bugFix":["be320990bdc77e643388fa801e75017f19289c42"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6240b74b884c5587f2a4062dd27d6c32bf228889","date":1507037235,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testOnlyLeaderIndexes().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testOnlyLeaderIndexes().mjava","sourceNew":"  public void testOnlyLeaderIndexes() throws Exception {\n    createAndWaitForCollection(1, 0, 2, 0);\n    \n    CloudSolrClient cloudClient = cluster.getSolrClient();\n    new UpdateRequest()\n        .add(sdoc(\"id\", \"1\"))\n        .add(sdoc(\"id\", \"2\"))\n        .add(sdoc(\"id\", \"3\"))\n        .add(sdoc(\"id\", \"4\"))\n        .process(cloudClient, collectionName);\n\n    {\n      long docsPending = (long) getSolrCore(true).get(0).getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(4, docsPending);\n    }\n\n    for (SolrCore solrCore : getSolrCore(false)) {\n      long docsPending = (long) solrCore.getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(0, docsPending);\n    }\n\n    checkRTG(1, 4, cluster.getJettySolrRunners());\n\n    new UpdateRequest()\n        .deleteById(\"1\")\n        .deleteByQuery(\"id:2\")\n        .process(cloudClient, collectionName);\n\n    // The DBQ is not processed at replicas, so we still can get doc2 and other docs by RTG\n    checkRTG(2,4, getSolrRunner(false));\n\n    Map<SolrCore, Long> timeCopyOverPerCores = getTimesCopyOverOldUpdates(getSolrCore(false));\n    new UpdateRequest()\n        .commit(cloudClient, collectionName);\n\n    waitForNumDocsInAllActiveReplicas(2);\n    assertCopyOverOldUpdates(1, timeCopyOverPerCores);\n\n    // UpdateLog copy over old updates\n    for (int i = 15; i <= 150; i++) {\n      cloudClient.add(collectionName, sdoc(\"id\",String.valueOf(i)));\n      if (random().nextInt(100) < 15 & i != 150) {\n        cloudClient.commit(collectionName);\n      }\n    }\n    checkRTG(120,150, cluster.getJettySolrRunners());\n    waitForReplicasCatchUp(20);\n    assertCopyOverOldUpdates(2, timeCopyOverPerCores);\n  }\n\n","sourceOld":"  public void testOnlyLeaderIndexes() throws Exception {\n    createAndWaitForCollection(1, 0, 2, 0);\n    \n    CloudSolrClient cloudClient = cluster.getSolrClient();\n    new UpdateRequest()\n        .add(sdoc(\"id\", \"1\"))\n        .add(sdoc(\"id\", \"2\"))\n        .add(sdoc(\"id\", \"3\"))\n        .add(sdoc(\"id\", \"4\"))\n        .process(cloudClient, collectionName);\n\n    {\n      UpdateHandler updateHandler = getSolrCore(true).get(0).getUpdateHandler();\n      RefCounted<IndexWriter> iwRef = updateHandler.getSolrCoreState().getIndexWriter(null);\n      assertTrue(\"IndexWriter at leader must see updates \", iwRef.get().hasUncommittedChanges());\n      iwRef.decref();\n    }\n\n    for (SolrCore solrCore : getSolrCore(false)) {\n      RefCounted<IndexWriter> iwRef = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n      assertFalse(\"IndexWriter at replicas must not see updates \", iwRef.get().hasUncommittedChanges());\n      iwRef.decref();\n    }\n\n    checkRTG(1, 4, cluster.getJettySolrRunners());\n\n    new UpdateRequest()\n        .deleteById(\"1\")\n        .deleteByQuery(\"id:2\")\n        .process(cloudClient, collectionName);\n\n    // The DBQ is not processed at replicas, so we still can get doc2 and other docs by RTG\n    checkRTG(2,4, getSolrRunner(false));\n\n    new UpdateRequest()\n        .commit(cloudClient, collectionName);\n\n    waitForNumDocsInAllActiveReplicas(2);\n\n    // Update log roll over\n    for (SolrCore solrCore : getSolrCore(false)) {\n      UpdateLog updateLog = solrCore.getUpdateHandler().getUpdateLog();\n      assertFalse(updateLog.hasUncommittedChanges());\n    }\n\n    // UpdateLog copy over old updates\n    for (int i = 15; i <= 150; i++) {\n      cloudClient.add(collectionName, sdoc(\"id\",String.valueOf(i)));\n      if (random().nextInt(100) < 15 & i != 150) {\n        cloudClient.commit(collectionName);\n      }\n    }\n    checkRTG(120,150, cluster.getJettySolrRunners());\n    waitForReplicasCatchUp(20);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"820dc7f947c9383eaa2feebcfb3e072799bf11c0","date":1507605119,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testOnlyLeaderIndexes().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testOnlyLeaderIndexes().mjava","sourceNew":"  public void testOnlyLeaderIndexes() throws Exception {\n    createAndWaitForCollection(1, 0, 2, 0);\n    \n    CloudSolrClient cloudClient = cluster.getSolrClient();\n    new UpdateRequest()\n        .add(sdoc(\"id\", \"1\"))\n        .add(sdoc(\"id\", \"2\"))\n        .add(sdoc(\"id\", \"3\"))\n        .add(sdoc(\"id\", \"4\"))\n        .process(cloudClient, collectionName);\n\n    {\n      long docsPending = (long) getSolrCore(true).get(0).getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(4, docsPending);\n    }\n\n    for (SolrCore solrCore : getSolrCore(false)) {\n      long docsPending = (long) solrCore.getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(0, docsPending);\n    }\n\n    checkRTG(1, 4, cluster.getJettySolrRunners());\n\n    new UpdateRequest()\n        .deleteById(\"1\")\n        .deleteByQuery(\"id:2\")\n        .process(cloudClient, collectionName);\n\n    // The DBQ is not processed at replicas, so we still can get doc2 and other docs by RTG\n    checkRTG(2,4, getSolrRunner(false));\n\n    Map<SolrCore, Long> timeCopyOverPerCores = getTimesCopyOverOldUpdates(getSolrCore(false));\n    new UpdateRequest()\n        .commit(cloudClient, collectionName);\n\n    waitForNumDocsInAllActiveReplicas(2);\n    assertCopyOverOldUpdates(1, timeCopyOverPerCores);\n\n    boolean firstCommit = true;\n    // UpdateLog copy over old updates\n    for (int i = 15; i <= 150; i++) {\n      cloudClient.add(collectionName, sdoc(\"id\",String.valueOf(i)));\n      if (random().nextInt(100) < 15 & i != 150) {\n        if (firstCommit) {\n          // because tlog replicas periodically ask leader for new segments,\n          // therefore the copy over old updates action must not be triggered until\n          // tlog replicas actually get new segments\n          assertCopyOverOldUpdates(1, timeCopyOverPerCores);\n          firstCommit = false;\n        }\n        cloudClient.commit(collectionName);\n      }\n    }\n    checkRTG(120,150, cluster.getJettySolrRunners());\n    waitForReplicasCatchUp(20);\n  }\n\n","sourceOld":"  public void testOnlyLeaderIndexes() throws Exception {\n    createAndWaitForCollection(1, 0, 2, 0);\n    \n    CloudSolrClient cloudClient = cluster.getSolrClient();\n    new UpdateRequest()\n        .add(sdoc(\"id\", \"1\"))\n        .add(sdoc(\"id\", \"2\"))\n        .add(sdoc(\"id\", \"3\"))\n        .add(sdoc(\"id\", \"4\"))\n        .process(cloudClient, collectionName);\n\n    {\n      long docsPending = (long) getSolrCore(true).get(0).getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(4, docsPending);\n    }\n\n    for (SolrCore solrCore : getSolrCore(false)) {\n      long docsPending = (long) solrCore.getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(0, docsPending);\n    }\n\n    checkRTG(1, 4, cluster.getJettySolrRunners());\n\n    new UpdateRequest()\n        .deleteById(\"1\")\n        .deleteByQuery(\"id:2\")\n        .process(cloudClient, collectionName);\n\n    // The DBQ is not processed at replicas, so we still can get doc2 and other docs by RTG\n    checkRTG(2,4, getSolrRunner(false));\n\n    Map<SolrCore, Long> timeCopyOverPerCores = getTimesCopyOverOldUpdates(getSolrCore(false));\n    new UpdateRequest()\n        .commit(cloudClient, collectionName);\n\n    waitForNumDocsInAllActiveReplicas(2);\n    assertCopyOverOldUpdates(1, timeCopyOverPerCores);\n\n    // UpdateLog copy over old updates\n    for (int i = 15; i <= 150; i++) {\n      cloudClient.add(collectionName, sdoc(\"id\",String.valueOf(i)));\n      if (random().nextInt(100) < 15 & i != 150) {\n        cloudClient.commit(collectionName);\n      }\n    }\n    checkRTG(120,150, cluster.getJettySolrRunners());\n    waitForReplicasCatchUp(20);\n    assertCopyOverOldUpdates(2, timeCopyOverPerCores);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"065d6b6bd6c614a2b8bb17507341c326573438ae","date":1508497873,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testOnlyLeaderIndexes().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testOnlyLeaderIndexes().mjava","sourceNew":"  public void testOnlyLeaderIndexes() throws Exception {\n    createAndWaitForCollection(1, 0, 2, 0);\n    \n    CloudSolrClient cloudClient = cluster.getSolrClient();\n    new UpdateRequest()\n        .add(sdoc(\"id\", \"1\"))\n        .add(sdoc(\"id\", \"2\"))\n        .add(sdoc(\"id\", \"3\"))\n        .add(sdoc(\"id\", \"4\"))\n        .process(cloudClient, collectionName);\n\n    {\n      long docsPending = (long) getSolrCore(true).get(0).getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(4, docsPending);\n    }\n\n    for (SolrCore solrCore : getSolrCore(false)) {\n      long docsPending = (long) solrCore.getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(0, docsPending);\n    }\n\n    checkRTG(1, 4, cluster.getJettySolrRunners());\n\n    new UpdateRequest()\n        .deleteById(\"1\")\n        .deleteByQuery(\"id:2\")\n        .process(cloudClient, collectionName);\n\n    // The DBQ is not processed at replicas, so we still can get doc2 and other docs by RTG\n    checkRTG(2,4, getSolrRunner(false));\n\n    Map<SolrCore, Long> timeCopyOverPerCores = getTimesCopyOverOldUpdates(getSolrCore(false));\n    new UpdateRequest()\n        .commit(cloudClient, collectionName);\n\n    waitForNumDocsInAllActiveReplicas(2);\n    // There are a small delay between new searcher and copy over old updates operation\n    TimeOut timeOut = new TimeOut(5, TimeUnit.SECONDS);\n    while (!timeOut.hasTimedOut()) {\n      if (assertCopyOverOldUpdates(1, timeCopyOverPerCores)) {\n        break;\n      } else {\n        Thread.sleep(500);\n      }\n    }\n    assertTrue(\"Expect only one copy over updates per cores\", assertCopyOverOldUpdates(1, timeCopyOverPerCores));\n\n    boolean firstCommit = true;\n    // UpdateLog copy over old updates\n    for (int i = 15; i <= 150; i++) {\n      cloudClient.add(collectionName, sdoc(\"id\",String.valueOf(i)));\n      if (random().nextInt(100) < 15 & i != 150) {\n        if (firstCommit) {\n          // because tlog replicas periodically ask leader for new segments,\n          // therefore the copy over old updates action must not be triggered until\n          // tlog replicas actually get new segments\n          assertTrue(\"Expect only one copy over updates per cores\", assertCopyOverOldUpdates(1, timeCopyOverPerCores));\n          firstCommit = false;\n        }\n        cloudClient.commit(collectionName);\n      }\n    }\n    checkRTG(120,150, cluster.getJettySolrRunners());\n    waitForReplicasCatchUp(20);\n  }\n\n","sourceOld":"  public void testOnlyLeaderIndexes() throws Exception {\n    createAndWaitForCollection(1, 0, 2, 0);\n    \n    CloudSolrClient cloudClient = cluster.getSolrClient();\n    new UpdateRequest()\n        .add(sdoc(\"id\", \"1\"))\n        .add(sdoc(\"id\", \"2\"))\n        .add(sdoc(\"id\", \"3\"))\n        .add(sdoc(\"id\", \"4\"))\n        .process(cloudClient, collectionName);\n\n    {\n      long docsPending = (long) getSolrCore(true).get(0).getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(4, docsPending);\n    }\n\n    for (SolrCore solrCore : getSolrCore(false)) {\n      long docsPending = (long) solrCore.getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(0, docsPending);\n    }\n\n    checkRTG(1, 4, cluster.getJettySolrRunners());\n\n    new UpdateRequest()\n        .deleteById(\"1\")\n        .deleteByQuery(\"id:2\")\n        .process(cloudClient, collectionName);\n\n    // The DBQ is not processed at replicas, so we still can get doc2 and other docs by RTG\n    checkRTG(2,4, getSolrRunner(false));\n\n    Map<SolrCore, Long> timeCopyOverPerCores = getTimesCopyOverOldUpdates(getSolrCore(false));\n    new UpdateRequest()\n        .commit(cloudClient, collectionName);\n\n    waitForNumDocsInAllActiveReplicas(2);\n    assertCopyOverOldUpdates(1, timeCopyOverPerCores);\n\n    boolean firstCommit = true;\n    // UpdateLog copy over old updates\n    for (int i = 15; i <= 150; i++) {\n      cloudClient.add(collectionName, sdoc(\"id\",String.valueOf(i)));\n      if (random().nextInt(100) < 15 & i != 150) {\n        if (firstCommit) {\n          // because tlog replicas periodically ask leader for new segments,\n          // therefore the copy over old updates action must not be triggered until\n          // tlog replicas actually get new segments\n          assertCopyOverOldUpdates(1, timeCopyOverPerCores);\n          firstCommit = false;\n        }\n        cloudClient.commit(collectionName);\n      }\n    }\n    checkRTG(120,150, cluster.getJettySolrRunners());\n    waitForReplicasCatchUp(20);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"77c61b53ac917c240593803ca928b383da9a4cd7","date":1508728783,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testOnlyLeaderIndexes().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testOnlyLeaderIndexes().mjava","sourceNew":"  public void testOnlyLeaderIndexes() throws Exception {\n    createAndWaitForCollection(1, 0, 2, 0);\n    \n    CloudSolrClient cloudClient = cluster.getSolrClient();\n    new UpdateRequest()\n        .add(sdoc(\"id\", \"1\"))\n        .add(sdoc(\"id\", \"2\"))\n        .add(sdoc(\"id\", \"3\"))\n        .add(sdoc(\"id\", \"4\"))\n        .process(cloudClient, collectionName);\n\n    {\n      long docsPending = (long) getSolrCore(true).get(0).getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(\"Expected 4 docs are pending in core \" + getSolrCore(true).get(0).getCoreDescriptor(),4, docsPending);\n    }\n\n    for (SolrCore solrCore : getSolrCore(false)) {\n      long docsPending = (long) solrCore.getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(\"Expected non docs are pending in core \" + solrCore.getCoreDescriptor(),0, docsPending);\n    }\n\n    checkRTG(1, 4, cluster.getJettySolrRunners());\n\n    new UpdateRequest()\n        .deleteById(\"1\")\n        .deleteByQuery(\"id:2\")\n        .process(cloudClient, collectionName);\n\n    // The DBQ is not processed at replicas, so we still can get doc2 and other docs by RTG\n    checkRTG(2,4, getSolrRunner(false));\n\n    Map<SolrCore, Long> timeCopyOverPerCores = getTimesCopyOverOldUpdates(getSolrCore(false));\n    new UpdateRequest()\n        .commit(cloudClient, collectionName);\n\n    waitForNumDocsInAllActiveReplicas(2);\n    // There are a small delay between new searcher and copy over old updates operation\n    TimeOut timeOut = new TimeOut(5, TimeUnit.SECONDS);\n    while (!timeOut.hasTimedOut()) {\n      if (assertCopyOverOldUpdates(1, timeCopyOverPerCores)) {\n        break;\n      } else {\n        Thread.sleep(500);\n      }\n    }\n    assertTrue(\"Expect only one copy over updates per cores\", assertCopyOverOldUpdates(1, timeCopyOverPerCores));\n\n    boolean firstCommit = true;\n    // UpdateLog copy over old updates\n    for (int i = 15; i <= 150; i++) {\n      cloudClient.add(collectionName, sdoc(\"id\",String.valueOf(i)));\n      if (random().nextInt(100) < 15 & i != 150) {\n        if (firstCommit) {\n          // because tlog replicas periodically ask leader for new segments,\n          // therefore the copy over old updates action must not be triggered until\n          // tlog replicas actually get new segments\n          assertTrue(\"Expect only one copy over updates per cores\", assertCopyOverOldUpdates(1, timeCopyOverPerCores));\n          firstCommit = false;\n        }\n        cloudClient.commit(collectionName);\n      }\n    }\n    checkRTG(120,150, cluster.getJettySolrRunners());\n    waitForReplicasCatchUp(20);\n  }\n\n","sourceOld":"  public void testOnlyLeaderIndexes() throws Exception {\n    createAndWaitForCollection(1, 0, 2, 0);\n    \n    CloudSolrClient cloudClient = cluster.getSolrClient();\n    new UpdateRequest()\n        .add(sdoc(\"id\", \"1\"))\n        .add(sdoc(\"id\", \"2\"))\n        .add(sdoc(\"id\", \"3\"))\n        .add(sdoc(\"id\", \"4\"))\n        .process(cloudClient, collectionName);\n\n    {\n      long docsPending = (long) getSolrCore(true).get(0).getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(4, docsPending);\n    }\n\n    for (SolrCore solrCore : getSolrCore(false)) {\n      long docsPending = (long) solrCore.getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(0, docsPending);\n    }\n\n    checkRTG(1, 4, cluster.getJettySolrRunners());\n\n    new UpdateRequest()\n        .deleteById(\"1\")\n        .deleteByQuery(\"id:2\")\n        .process(cloudClient, collectionName);\n\n    // The DBQ is not processed at replicas, so we still can get doc2 and other docs by RTG\n    checkRTG(2,4, getSolrRunner(false));\n\n    Map<SolrCore, Long> timeCopyOverPerCores = getTimesCopyOverOldUpdates(getSolrCore(false));\n    new UpdateRequest()\n        .commit(cloudClient, collectionName);\n\n    waitForNumDocsInAllActiveReplicas(2);\n    // There are a small delay between new searcher and copy over old updates operation\n    TimeOut timeOut = new TimeOut(5, TimeUnit.SECONDS);\n    while (!timeOut.hasTimedOut()) {\n      if (assertCopyOverOldUpdates(1, timeCopyOverPerCores)) {\n        break;\n      } else {\n        Thread.sleep(500);\n      }\n    }\n    assertTrue(\"Expect only one copy over updates per cores\", assertCopyOverOldUpdates(1, timeCopyOverPerCores));\n\n    boolean firstCommit = true;\n    // UpdateLog copy over old updates\n    for (int i = 15; i <= 150; i++) {\n      cloudClient.add(collectionName, sdoc(\"id\",String.valueOf(i)));\n      if (random().nextInt(100) < 15 & i != 150) {\n        if (firstCommit) {\n          // because tlog replicas periodically ask leader for new segments,\n          // therefore the copy over old updates action must not be triggered until\n          // tlog replicas actually get new segments\n          assertTrue(\"Expect only one copy over updates per cores\", assertCopyOverOldUpdates(1, timeCopyOverPerCores));\n          firstCommit = false;\n        }\n        cloudClient.commit(collectionName);\n      }\n    }\n    checkRTG(120,150, cluster.getJettySolrRunners());\n    waitForReplicasCatchUp(20);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1","date":1513252583,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testOnlyLeaderIndexes().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testOnlyLeaderIndexes().mjava","sourceNew":"  public void testOnlyLeaderIndexes() throws Exception {\n    createAndWaitForCollection(1, 0, 2, 0);\n    \n    CloudSolrClient cloudClient = cluster.getSolrClient();\n    new UpdateRequest()\n        .add(sdoc(\"id\", \"1\"))\n        .add(sdoc(\"id\", \"2\"))\n        .add(sdoc(\"id\", \"3\"))\n        .add(sdoc(\"id\", \"4\"))\n        .process(cloudClient, collectionName);\n\n    {\n      long docsPending = (long) getSolrCore(true).get(0).getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(\"Expected 4 docs are pending in core \" + getSolrCore(true).get(0).getCoreDescriptor(),4, docsPending);\n    }\n\n    for (SolrCore solrCore : getSolrCore(false)) {\n      long docsPending = (long) solrCore.getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(\"Expected non docs are pending in core \" + solrCore.getCoreDescriptor(),0, docsPending);\n    }\n\n    checkRTG(1, 4, cluster.getJettySolrRunners());\n\n    new UpdateRequest()\n        .deleteById(\"1\")\n        .deleteByQuery(\"id:2\")\n        .process(cloudClient, collectionName);\n\n    // The DBQ is not processed at replicas, so we still can get doc2 and other docs by RTG\n    checkRTG(2,4, getSolrRunner(false));\n\n    Map<SolrCore, Long> timeCopyOverPerCores = getTimesCopyOverOldUpdates(getSolrCore(false));\n    new UpdateRequest()\n        .commit(cloudClient, collectionName);\n\n    waitForNumDocsInAllActiveReplicas(2);\n    // There are a small delay between new searcher and copy over old updates operation\n    TimeOut timeOut = new TimeOut(5, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    while (!timeOut.hasTimedOut()) {\n      if (assertCopyOverOldUpdates(1, timeCopyOverPerCores)) {\n        break;\n      } else {\n        Thread.sleep(500);\n      }\n    }\n    assertTrue(\"Expect only one copy over updates per cores\", assertCopyOverOldUpdates(1, timeCopyOverPerCores));\n\n    boolean firstCommit = true;\n    // UpdateLog copy over old updates\n    for (int i = 15; i <= 150; i++) {\n      cloudClient.add(collectionName, sdoc(\"id\",String.valueOf(i)));\n      if (random().nextInt(100) < 15 & i != 150) {\n        if (firstCommit) {\n          // because tlog replicas periodically ask leader for new segments,\n          // therefore the copy over old updates action must not be triggered until\n          // tlog replicas actually get new segments\n          assertTrue(\"Expect only one copy over updates per cores\", assertCopyOverOldUpdates(1, timeCopyOverPerCores));\n          firstCommit = false;\n        }\n        cloudClient.commit(collectionName);\n      }\n    }\n    checkRTG(120,150, cluster.getJettySolrRunners());\n    waitForReplicasCatchUp(20);\n  }\n\n","sourceOld":"  public void testOnlyLeaderIndexes() throws Exception {\n    createAndWaitForCollection(1, 0, 2, 0);\n    \n    CloudSolrClient cloudClient = cluster.getSolrClient();\n    new UpdateRequest()\n        .add(sdoc(\"id\", \"1\"))\n        .add(sdoc(\"id\", \"2\"))\n        .add(sdoc(\"id\", \"3\"))\n        .add(sdoc(\"id\", \"4\"))\n        .process(cloudClient, collectionName);\n\n    {\n      long docsPending = (long) getSolrCore(true).get(0).getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(\"Expected 4 docs are pending in core \" + getSolrCore(true).get(0).getCoreDescriptor(),4, docsPending);\n    }\n\n    for (SolrCore solrCore : getSolrCore(false)) {\n      long docsPending = (long) solrCore.getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(\"Expected non docs are pending in core \" + solrCore.getCoreDescriptor(),0, docsPending);\n    }\n\n    checkRTG(1, 4, cluster.getJettySolrRunners());\n\n    new UpdateRequest()\n        .deleteById(\"1\")\n        .deleteByQuery(\"id:2\")\n        .process(cloudClient, collectionName);\n\n    // The DBQ is not processed at replicas, so we still can get doc2 and other docs by RTG\n    checkRTG(2,4, getSolrRunner(false));\n\n    Map<SolrCore, Long> timeCopyOverPerCores = getTimesCopyOverOldUpdates(getSolrCore(false));\n    new UpdateRequest()\n        .commit(cloudClient, collectionName);\n\n    waitForNumDocsInAllActiveReplicas(2);\n    // There are a small delay between new searcher and copy over old updates operation\n    TimeOut timeOut = new TimeOut(5, TimeUnit.SECONDS);\n    while (!timeOut.hasTimedOut()) {\n      if (assertCopyOverOldUpdates(1, timeCopyOverPerCores)) {\n        break;\n      } else {\n        Thread.sleep(500);\n      }\n    }\n    assertTrue(\"Expect only one copy over updates per cores\", assertCopyOverOldUpdates(1, timeCopyOverPerCores));\n\n    boolean firstCommit = true;\n    // UpdateLog copy over old updates\n    for (int i = 15; i <= 150; i++) {\n      cloudClient.add(collectionName, sdoc(\"id\",String.valueOf(i)));\n      if (random().nextInt(100) < 15 & i != 150) {\n        if (firstCommit) {\n          // because tlog replicas periodically ask leader for new segments,\n          // therefore the copy over old updates action must not be triggered until\n          // tlog replicas actually get new segments\n          assertTrue(\"Expect only one copy over updates per cores\", assertCopyOverOldUpdates(1, timeCopyOverPerCores));\n          firstCommit = false;\n        }\n        cloudClient.commit(collectionName);\n      }\n    }\n    checkRTG(120,150, cluster.getJettySolrRunners());\n    waitForReplicasCatchUp(20);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bedc8e5595055009e34aaa41f94d3645ba103d98","date":1520708295,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testOnlyLeaderIndexes().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testOnlyLeaderIndexes().mjava","sourceNew":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") //2018-03-10\n  public void testOnlyLeaderIndexes() throws Exception {\n    createAndWaitForCollection(1, 0, 2, 0);\n    \n    CloudSolrClient cloudClient = cluster.getSolrClient();\n    new UpdateRequest()\n        .add(sdoc(\"id\", \"1\"))\n        .add(sdoc(\"id\", \"2\"))\n        .add(sdoc(\"id\", \"3\"))\n        .add(sdoc(\"id\", \"4\"))\n        .process(cloudClient, collectionName);\n\n    {\n      long docsPending = (long) getSolrCore(true).get(0).getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(\"Expected 4 docs are pending in core \" + getSolrCore(true).get(0).getCoreDescriptor(),4, docsPending);\n    }\n\n    for (SolrCore solrCore : getSolrCore(false)) {\n      long docsPending = (long) solrCore.getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(\"Expected non docs are pending in core \" + solrCore.getCoreDescriptor(),0, docsPending);\n    }\n\n    checkRTG(1, 4, cluster.getJettySolrRunners());\n\n    new UpdateRequest()\n        .deleteById(\"1\")\n        .deleteByQuery(\"id:2\")\n        .process(cloudClient, collectionName);\n\n    // The DBQ is not processed at replicas, so we still can get doc2 and other docs by RTG\n    checkRTG(2,4, getSolrRunner(false));\n\n    Map<SolrCore, Long> timeCopyOverPerCores = getTimesCopyOverOldUpdates(getSolrCore(false));\n    new UpdateRequest()\n        .commit(cloudClient, collectionName);\n\n    waitForNumDocsInAllActiveReplicas(2);\n    // There are a small delay between new searcher and copy over old updates operation\n    TimeOut timeOut = new TimeOut(5, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    while (!timeOut.hasTimedOut()) {\n      if (assertCopyOverOldUpdates(1, timeCopyOverPerCores)) {\n        break;\n      } else {\n        Thread.sleep(500);\n      }\n    }\n    assertTrue(\"Expect only one copy over updates per cores\", assertCopyOverOldUpdates(1, timeCopyOverPerCores));\n\n    boolean firstCommit = true;\n    // UpdateLog copy over old updates\n    for (int i = 15; i <= 150; i++) {\n      cloudClient.add(collectionName, sdoc(\"id\",String.valueOf(i)));\n      if (random().nextInt(100) < 15 & i != 150) {\n        if (firstCommit) {\n          // because tlog replicas periodically ask leader for new segments,\n          // therefore the copy over old updates action must not be triggered until\n          // tlog replicas actually get new segments\n          assertTrue(\"Expect only one copy over updates per cores\", assertCopyOverOldUpdates(1, timeCopyOverPerCores));\n          firstCommit = false;\n        }\n        cloudClient.commit(collectionName);\n      }\n    }\n    checkRTG(120,150, cluster.getJettySolrRunners());\n    waitForReplicasCatchUp(20);\n  }\n\n","sourceOld":"  public void testOnlyLeaderIndexes() throws Exception {\n    createAndWaitForCollection(1, 0, 2, 0);\n    \n    CloudSolrClient cloudClient = cluster.getSolrClient();\n    new UpdateRequest()\n        .add(sdoc(\"id\", \"1\"))\n        .add(sdoc(\"id\", \"2\"))\n        .add(sdoc(\"id\", \"3\"))\n        .add(sdoc(\"id\", \"4\"))\n        .process(cloudClient, collectionName);\n\n    {\n      long docsPending = (long) getSolrCore(true).get(0).getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(\"Expected 4 docs are pending in core \" + getSolrCore(true).get(0).getCoreDescriptor(),4, docsPending);\n    }\n\n    for (SolrCore solrCore : getSolrCore(false)) {\n      long docsPending = (long) solrCore.getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(\"Expected non docs are pending in core \" + solrCore.getCoreDescriptor(),0, docsPending);\n    }\n\n    checkRTG(1, 4, cluster.getJettySolrRunners());\n\n    new UpdateRequest()\n        .deleteById(\"1\")\n        .deleteByQuery(\"id:2\")\n        .process(cloudClient, collectionName);\n\n    // The DBQ is not processed at replicas, so we still can get doc2 and other docs by RTG\n    checkRTG(2,4, getSolrRunner(false));\n\n    Map<SolrCore, Long> timeCopyOverPerCores = getTimesCopyOverOldUpdates(getSolrCore(false));\n    new UpdateRequest()\n        .commit(cloudClient, collectionName);\n\n    waitForNumDocsInAllActiveReplicas(2);\n    // There are a small delay between new searcher and copy over old updates operation\n    TimeOut timeOut = new TimeOut(5, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    while (!timeOut.hasTimedOut()) {\n      if (assertCopyOverOldUpdates(1, timeCopyOverPerCores)) {\n        break;\n      } else {\n        Thread.sleep(500);\n      }\n    }\n    assertTrue(\"Expect only one copy over updates per cores\", assertCopyOverOldUpdates(1, timeCopyOverPerCores));\n\n    boolean firstCommit = true;\n    // UpdateLog copy over old updates\n    for (int i = 15; i <= 150; i++) {\n      cloudClient.add(collectionName, sdoc(\"id\",String.valueOf(i)));\n      if (random().nextInt(100) < 15 & i != 150) {\n        if (firstCommit) {\n          // because tlog replicas periodically ask leader for new segments,\n          // therefore the copy over old updates action must not be triggered until\n          // tlog replicas actually get new segments\n          assertTrue(\"Expect only one copy over updates per cores\", assertCopyOverOldUpdates(1, timeCopyOverPerCores));\n          firstCommit = false;\n        }\n        cloudClient.commit(collectionName);\n      }\n    }\n    checkRTG(120,150, cluster.getJettySolrRunners());\n    waitForReplicasCatchUp(20);\n  }\n\n","bugFix":null,"bugIntro":["0484631b41605341d7e71ec7a9ccea076ee90591"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0484631b41605341d7e71ec7a9ccea076ee90591","date":1526889810,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testOnlyLeaderIndexes().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testOnlyLeaderIndexes().mjava","sourceNew":"  @Test\n  // Removed BadApple on 2018-05-21\n  public void testOnlyLeaderIndexes() throws Exception {\n    createAndWaitForCollection(1, 0, 2, 0);\n    \n    CloudSolrClient cloudClient = cluster.getSolrClient();\n    new UpdateRequest()\n        .add(sdoc(\"id\", \"1\"))\n        .add(sdoc(\"id\", \"2\"))\n        .add(sdoc(\"id\", \"3\"))\n        .add(sdoc(\"id\", \"4\"))\n        .process(cloudClient, collectionName);\n\n    {\n      long docsPending = (long) getSolrCore(true).get(0).getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(\"Expected 4 docs are pending in core \" + getSolrCore(true).get(0).getCoreDescriptor(),4, docsPending);\n    }\n\n    for (SolrCore solrCore : getSolrCore(false)) {\n      long docsPending = (long) solrCore.getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(\"Expected non docs are pending in core \" + solrCore.getCoreDescriptor(),0, docsPending);\n    }\n\n    checkRTG(1, 4, cluster.getJettySolrRunners());\n\n    new UpdateRequest()\n        .deleteById(\"1\")\n        .deleteByQuery(\"id:2\")\n        .process(cloudClient, collectionName);\n\n    // The DBQ is not processed at replicas, so we still can get doc2 and other docs by RTG\n    checkRTG(2,4, getSolrRunner(false));\n\n    Map<SolrCore, Long> timeCopyOverPerCores = getTimesCopyOverOldUpdates(getSolrCore(false));\n    new UpdateRequest()\n        .commit(cloudClient, collectionName);\n\n    waitForNumDocsInAllActiveReplicas(2);\n    // There are a small delay between new searcher and copy over old updates operation\n    TimeOut timeOut = new TimeOut(5, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    while (!timeOut.hasTimedOut()) {\n      if (assertCopyOverOldUpdates(1, timeCopyOverPerCores)) {\n        break;\n      } else {\n        Thread.sleep(500);\n      }\n    }\n    assertTrue(\"Expect only one copy over updates per cores\", assertCopyOverOldUpdates(1, timeCopyOverPerCores));\n\n    boolean firstCommit = true;\n    // UpdateLog copy over old updates\n    for (int i = 15; i <= 150; i++) {\n      cloudClient.add(collectionName, sdoc(\"id\",String.valueOf(i)));\n      if (random().nextInt(100) < 15 & i != 150) {\n        if (firstCommit) {\n          // because tlog replicas periodically ask leader for new segments,\n          // therefore the copy over old updates action must not be triggered until\n          // tlog replicas actually get new segments\n          assertTrue(\"Expect only one copy over updates per cores\", assertCopyOverOldUpdates(1, timeCopyOverPerCores));\n          firstCommit = false;\n        }\n        cloudClient.commit(collectionName);\n      }\n    }\n    checkRTG(120,150, cluster.getJettySolrRunners());\n    waitForReplicasCatchUp(20);\n  }\n\n","sourceOld":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") //2018-03-10\n  public void testOnlyLeaderIndexes() throws Exception {\n    createAndWaitForCollection(1, 0, 2, 0);\n    \n    CloudSolrClient cloudClient = cluster.getSolrClient();\n    new UpdateRequest()\n        .add(sdoc(\"id\", \"1\"))\n        .add(sdoc(\"id\", \"2\"))\n        .add(sdoc(\"id\", \"3\"))\n        .add(sdoc(\"id\", \"4\"))\n        .process(cloudClient, collectionName);\n\n    {\n      long docsPending = (long) getSolrCore(true).get(0).getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(\"Expected 4 docs are pending in core \" + getSolrCore(true).get(0).getCoreDescriptor(),4, docsPending);\n    }\n\n    for (SolrCore solrCore : getSolrCore(false)) {\n      long docsPending = (long) solrCore.getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(\"Expected non docs are pending in core \" + solrCore.getCoreDescriptor(),0, docsPending);\n    }\n\n    checkRTG(1, 4, cluster.getJettySolrRunners());\n\n    new UpdateRequest()\n        .deleteById(\"1\")\n        .deleteByQuery(\"id:2\")\n        .process(cloudClient, collectionName);\n\n    // The DBQ is not processed at replicas, so we still can get doc2 and other docs by RTG\n    checkRTG(2,4, getSolrRunner(false));\n\n    Map<SolrCore, Long> timeCopyOverPerCores = getTimesCopyOverOldUpdates(getSolrCore(false));\n    new UpdateRequest()\n        .commit(cloudClient, collectionName);\n\n    waitForNumDocsInAllActiveReplicas(2);\n    // There are a small delay between new searcher and copy over old updates operation\n    TimeOut timeOut = new TimeOut(5, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    while (!timeOut.hasTimedOut()) {\n      if (assertCopyOverOldUpdates(1, timeCopyOverPerCores)) {\n        break;\n      } else {\n        Thread.sleep(500);\n      }\n    }\n    assertTrue(\"Expect only one copy over updates per cores\", assertCopyOverOldUpdates(1, timeCopyOverPerCores));\n\n    boolean firstCommit = true;\n    // UpdateLog copy over old updates\n    for (int i = 15; i <= 150; i++) {\n      cloudClient.add(collectionName, sdoc(\"id\",String.valueOf(i)));\n      if (random().nextInt(100) < 15 & i != 150) {\n        if (firstCommit) {\n          // because tlog replicas periodically ask leader for new segments,\n          // therefore the copy over old updates action must not be triggered until\n          // tlog replicas actually get new segments\n          assertTrue(\"Expect only one copy over updates per cores\", assertCopyOverOldUpdates(1, timeCopyOverPerCores));\n          firstCommit = false;\n        }\n        cloudClient.commit(collectionName);\n      }\n    }\n    checkRTG(120,150, cluster.getJettySolrRunners());\n    waitForReplicasCatchUp(20);\n  }\n\n","bugFix":["bedc8e5595055009e34aaa41f94d3645ba103d98"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0db83f1bb855a4ac824c9a2a8e1ee9b29a039c15","date":1554259533,"type":3,"author":"Gus Heck","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testOnlyLeaderIndexes().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testOnlyLeaderIndexes().mjava","sourceNew":"  @Test\n  // Removed BadApple on 2018-05-21\n  public void testOnlyLeaderIndexes() throws Exception {\n    createAndWaitForCollection(1, 0, 2, 0);\n\n    CloudSolrClient cloudClient = cluster.getSolrClient();\n    new UpdateRequest()\n        .add(sdoc(\"id\", \"1\"))\n        .add(sdoc(\"id\", \"2\"))\n        .add(sdoc(\"id\", \"3\"))\n        .add(sdoc(\"id\", \"4\"))\n        .process(cloudClient, collectionName);\n\n    {\n      long docsPending = (long) getSolrCore(true).get(0).getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(\"Expected 4 docs are pending in core \" + getSolrCore(true).get(0).getCoreDescriptor(),4, docsPending);\n    }\n\n    for (SolrCore solrCore : getSolrCore(false)) {\n      long docsPending = (long) solrCore.getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(\"Expected non docs are pending in core \" + solrCore.getCoreDescriptor(),0, docsPending);\n    }\n\n    checkRTG(1, 4, cluster.getJettySolrRunners());\n\n    new UpdateRequest()\n        .deleteById(\"1\")\n        .deleteByQuery(\"id:2\")\n        .process(cloudClient, collectionName);\n\n    // The DBQ is not processed at replicas, so we still can get doc2 and other docs by RTG\n    checkRTG(2,4, getSolrRunner(false));\n\n    Map<SolrCore, Long> timeCopyOverPerCores = getTimesCopyOverOldUpdates(getSolrCore(false));\n    new UpdateRequest()\n        .commit(cloudClient, collectionName);\n\n    waitForNumDocsInAllActiveReplicas(2);\n    // There are a small delay between new searcher and copy over old updates operation\n    TimeOut timeOut = new TimeOut(5, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    while (!timeOut.hasTimedOut()) {\n      if (assertCopyOverOldUpdates(1, timeCopyOverPerCores)) {\n        break;\n      } else {\n        Thread.sleep(500);\n      }\n    }\n    assertTrue(\"Expect only one copy over updates per cores\", assertCopyOverOldUpdates(1, timeCopyOverPerCores));\n\n    boolean firstCommit = true;\n    // UpdateLog copy over old updates\n    for (int i = 15; i <= 150; i++) {\n      cloudClient.add(collectionName, sdoc(\"id\",String.valueOf(i)));\n      if (random().nextInt(100) < 15 & i != 150) {\n        if (firstCommit) {\n          // because tlog replicas periodically ask leader for new segments,\n          // therefore the copy over old updates action must not be triggered until\n          // tlog replicas actually get new segments\n          assertTrue(\"Expect only one copy over updates per cores\", assertCopyOverOldUpdates(1, timeCopyOverPerCores));\n          firstCommit = false;\n        }\n        cloudClient.commit(collectionName);\n      }\n    }\n    checkRTG(120,150, cluster.getJettySolrRunners());\n    waitForReplicasCatchUp(20);\n  }\n\n","sourceOld":"  @Test\n  // Removed BadApple on 2018-05-21\n  public void testOnlyLeaderIndexes() throws Exception {\n    createAndWaitForCollection(1, 0, 2, 0);\n    \n    CloudSolrClient cloudClient = cluster.getSolrClient();\n    new UpdateRequest()\n        .add(sdoc(\"id\", \"1\"))\n        .add(sdoc(\"id\", \"2\"))\n        .add(sdoc(\"id\", \"3\"))\n        .add(sdoc(\"id\", \"4\"))\n        .process(cloudClient, collectionName);\n\n    {\n      long docsPending = (long) getSolrCore(true).get(0).getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(\"Expected 4 docs are pending in core \" + getSolrCore(true).get(0).getCoreDescriptor(),4, docsPending);\n    }\n\n    for (SolrCore solrCore : getSolrCore(false)) {\n      long docsPending = (long) solrCore.getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(\"Expected non docs are pending in core \" + solrCore.getCoreDescriptor(),0, docsPending);\n    }\n\n    checkRTG(1, 4, cluster.getJettySolrRunners());\n\n    new UpdateRequest()\n        .deleteById(\"1\")\n        .deleteByQuery(\"id:2\")\n        .process(cloudClient, collectionName);\n\n    // The DBQ is not processed at replicas, so we still can get doc2 and other docs by RTG\n    checkRTG(2,4, getSolrRunner(false));\n\n    Map<SolrCore, Long> timeCopyOverPerCores = getTimesCopyOverOldUpdates(getSolrCore(false));\n    new UpdateRequest()\n        .commit(cloudClient, collectionName);\n\n    waitForNumDocsInAllActiveReplicas(2);\n    // There are a small delay between new searcher and copy over old updates operation\n    TimeOut timeOut = new TimeOut(5, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    while (!timeOut.hasTimedOut()) {\n      if (assertCopyOverOldUpdates(1, timeCopyOverPerCores)) {\n        break;\n      } else {\n        Thread.sleep(500);\n      }\n    }\n    assertTrue(\"Expect only one copy over updates per cores\", assertCopyOverOldUpdates(1, timeCopyOverPerCores));\n\n    boolean firstCommit = true;\n    // UpdateLog copy over old updates\n    for (int i = 15; i <= 150; i++) {\n      cloudClient.add(collectionName, sdoc(\"id\",String.valueOf(i)));\n      if (random().nextInt(100) < 15 & i != 150) {\n        if (firstCommit) {\n          // because tlog replicas periodically ask leader for new segments,\n          // therefore the copy over old updates action must not be triggered until\n          // tlog replicas actually get new segments\n          assertTrue(\"Expect only one copy over updates per cores\", assertCopyOverOldUpdates(1, timeCopyOverPerCores));\n          firstCommit = false;\n        }\n        cloudClient.commit(collectionName);\n      }\n    }\n    checkRTG(120,150, cluster.getJettySolrRunners());\n    waitForReplicasCatchUp(20);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bf5b93713fb0adca4f2a88e0a629554bf1ac2866","date":1571852796,"type":3,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testOnlyLeaderIndexes().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testOnlyLeaderIndexes().mjava","sourceNew":"  @Test\n  public void testOnlyLeaderIndexes() throws Exception {\n    createAndWaitForCollection(1, 0, 2, 0);\n\n    CloudSolrClient cloudClient = cluster.getSolrClient();\n    new UpdateRequest()\n        .add(sdoc(\"id\", \"1\"))\n        .add(sdoc(\"id\", \"2\"))\n        .add(sdoc(\"id\", \"3\"))\n        .add(sdoc(\"id\", \"4\"))\n        .process(cloudClient, collectionName);\n\n    {\n      long docsPending = (long) getSolrCore(true).get(0).getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(\"Expected 4 docs are pending in core \" + getSolrCore(true).get(0).getCoreDescriptor(),4, docsPending);\n    }\n\n    for (SolrCore solrCore : getSolrCore(false)) {\n      long docsPending = (long) solrCore.getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(\"Expected non docs are pending in core \" + solrCore.getCoreDescriptor(),0, docsPending);\n    }\n\n    checkRTG(1, 4, cluster.getJettySolrRunners());\n\n    new UpdateRequest()\n        .deleteById(\"1\")\n        .deleteByQuery(\"id:2\")\n        .process(cloudClient, collectionName);\n\n    // The DBQ is not processed at replicas, so we still can get doc2 and other docs by RTG\n    checkRTG(2,4, getSolrRunner(false));\n\n    Map<SolrCore, Long> timeCopyOverPerCores = getTimesCopyOverOldUpdates(getSolrCore(false));\n    new UpdateRequest()\n        .commit(cloudClient, collectionName);\n\n    waitForNumDocsInAllActiveReplicas(2);\n    // There are a small delay between new searcher and copy over old updates operation\n    TimeOut timeOut = new TimeOut(5, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    while (!timeOut.hasTimedOut()) {\n      if (assertCopyOverOldUpdates(1, timeCopyOverPerCores)) {\n        break;\n      } else {\n        Thread.sleep(500);\n      }\n    }\n    assertTrue(\"Expect only one copy over updates per cores\", assertCopyOverOldUpdates(1, timeCopyOverPerCores));\n\n    boolean firstCommit = true;\n    // UpdateLog copy over old updates\n    for (int i = 15; i <= 150; i++) {\n      cloudClient.add(collectionName, sdoc(\"id\",String.valueOf(i)));\n      if (random().nextInt(100) < 15 & i != 150) {\n        if (firstCommit) {\n          // because tlog replicas periodically ask leader for new segments,\n          // therefore the copy over old updates action must not be triggered until\n          // tlog replicas actually get new segments\n          assertTrue(\"Expect only one copy over updates per cores\", assertCopyOverOldUpdates(1, timeCopyOverPerCores));\n          firstCommit = false;\n        }\n        cloudClient.commit(collectionName);\n      }\n    }\n    checkRTG(120,150, cluster.getJettySolrRunners());\n    waitForReplicasCatchUp(4 * REPLICATION_TIMEOUT_SECS);\n  }\n\n","sourceOld":"  @Test\n  // Removed BadApple on 2018-05-21\n  public void testOnlyLeaderIndexes() throws Exception {\n    createAndWaitForCollection(1, 0, 2, 0);\n\n    CloudSolrClient cloudClient = cluster.getSolrClient();\n    new UpdateRequest()\n        .add(sdoc(\"id\", \"1\"))\n        .add(sdoc(\"id\", \"2\"))\n        .add(sdoc(\"id\", \"3\"))\n        .add(sdoc(\"id\", \"4\"))\n        .process(cloudClient, collectionName);\n\n    {\n      long docsPending = (long) getSolrCore(true).get(0).getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(\"Expected 4 docs are pending in core \" + getSolrCore(true).get(0).getCoreDescriptor(),4, docsPending);\n    }\n\n    for (SolrCore solrCore : getSolrCore(false)) {\n      long docsPending = (long) solrCore.getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(\"Expected non docs are pending in core \" + solrCore.getCoreDescriptor(),0, docsPending);\n    }\n\n    checkRTG(1, 4, cluster.getJettySolrRunners());\n\n    new UpdateRequest()\n        .deleteById(\"1\")\n        .deleteByQuery(\"id:2\")\n        .process(cloudClient, collectionName);\n\n    // The DBQ is not processed at replicas, so we still can get doc2 and other docs by RTG\n    checkRTG(2,4, getSolrRunner(false));\n\n    Map<SolrCore, Long> timeCopyOverPerCores = getTimesCopyOverOldUpdates(getSolrCore(false));\n    new UpdateRequest()\n        .commit(cloudClient, collectionName);\n\n    waitForNumDocsInAllActiveReplicas(2);\n    // There are a small delay between new searcher and copy over old updates operation\n    TimeOut timeOut = new TimeOut(5, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    while (!timeOut.hasTimedOut()) {\n      if (assertCopyOverOldUpdates(1, timeCopyOverPerCores)) {\n        break;\n      } else {\n        Thread.sleep(500);\n      }\n    }\n    assertTrue(\"Expect only one copy over updates per cores\", assertCopyOverOldUpdates(1, timeCopyOverPerCores));\n\n    boolean firstCommit = true;\n    // UpdateLog copy over old updates\n    for (int i = 15; i <= 150; i++) {\n      cloudClient.add(collectionName, sdoc(\"id\",String.valueOf(i)));\n      if (random().nextInt(100) < 15 & i != 150) {\n        if (firstCommit) {\n          // because tlog replicas periodically ask leader for new segments,\n          // therefore the copy over old updates action must not be triggered until\n          // tlog replicas actually get new segments\n          assertTrue(\"Expect only one copy over updates per cores\", assertCopyOverOldUpdates(1, timeCopyOverPerCores));\n          firstCommit = false;\n        }\n        cloudClient.commit(collectionName);\n      }\n    }\n    checkRTG(120,150, cluster.getJettySolrRunners());\n    waitForReplicasCatchUp(20);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c2af5a711bd6e2d33e0221ced0f47ac596ed275","date":1572877903,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testOnlyLeaderIndexes().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testOnlyLeaderIndexes().mjava","sourceNew":"  @Test\n  public void testOnlyLeaderIndexes() throws Exception {\n    createAndWaitForCollection(1, 0, 2, 0);\n\n    CloudSolrClient cloudClient = cluster.getSolrClient();\n    new UpdateRequest()\n        .add(sdoc(\"id\", \"1\"))\n        .add(sdoc(\"id\", \"2\"))\n        .add(sdoc(\"id\", \"3\"))\n        .add(sdoc(\"id\", \"4\"))\n        .process(cloudClient, collectionName);\n\n    {\n      long docsPending = (long) getSolrCore(true).get(0).getSolrMetricsContext().getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(\"Expected 4 docs are pending in core \" + getSolrCore(true).get(0).getCoreDescriptor(),4, docsPending);\n    }\n\n    for (SolrCore solrCore : getSolrCore(false)) {\n      long docsPending = (long) solrCore.getSolrMetricsContext().getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(\"Expected non docs are pending in core \" + solrCore.getCoreDescriptor(),0, docsPending);\n    }\n\n    checkRTG(1, 4, cluster.getJettySolrRunners());\n\n    new UpdateRequest()\n        .deleteById(\"1\")\n        .deleteByQuery(\"id:2\")\n        .process(cloudClient, collectionName);\n\n    // The DBQ is not processed at replicas, so we still can get doc2 and other docs by RTG\n    checkRTG(2,4, getSolrRunner(false));\n\n    Map<SolrCore, Long> timeCopyOverPerCores = getTimesCopyOverOldUpdates(getSolrCore(false));\n    new UpdateRequest()\n        .commit(cloudClient, collectionName);\n\n    waitForNumDocsInAllActiveReplicas(2);\n    // There are a small delay between new searcher and copy over old updates operation\n    TimeOut timeOut = new TimeOut(5, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    while (!timeOut.hasTimedOut()) {\n      if (assertCopyOverOldUpdates(1, timeCopyOverPerCores)) {\n        break;\n      } else {\n        Thread.sleep(500);\n      }\n    }\n    assertTrue(\"Expect only one copy over updates per cores\", assertCopyOverOldUpdates(1, timeCopyOverPerCores));\n\n    boolean firstCommit = true;\n    // UpdateLog copy over old updates\n    for (int i = 15; i <= 150; i++) {\n      cloudClient.add(collectionName, sdoc(\"id\",String.valueOf(i)));\n      if (random().nextInt(100) < 15 & i != 150) {\n        if (firstCommit) {\n          // because tlog replicas periodically ask leader for new segments,\n          // therefore the copy over old updates action must not be triggered until\n          // tlog replicas actually get new segments\n          assertTrue(\"Expect only one copy over updates per cores\", assertCopyOverOldUpdates(1, timeCopyOverPerCores));\n          firstCommit = false;\n        }\n        cloudClient.commit(collectionName);\n      }\n    }\n    checkRTG(120,150, cluster.getJettySolrRunners());\n    waitForReplicasCatchUp(4 * REPLICATION_TIMEOUT_SECS);\n  }\n\n","sourceOld":"  @Test\n  public void testOnlyLeaderIndexes() throws Exception {\n    createAndWaitForCollection(1, 0, 2, 0);\n\n    CloudSolrClient cloudClient = cluster.getSolrClient();\n    new UpdateRequest()\n        .add(sdoc(\"id\", \"1\"))\n        .add(sdoc(\"id\", \"2\"))\n        .add(sdoc(\"id\", \"3\"))\n        .add(sdoc(\"id\", \"4\"))\n        .process(cloudClient, collectionName);\n\n    {\n      long docsPending = (long) getSolrCore(true).get(0).getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(\"Expected 4 docs are pending in core \" + getSolrCore(true).get(0).getCoreDescriptor(),4, docsPending);\n    }\n\n    for (SolrCore solrCore : getSolrCore(false)) {\n      long docsPending = (long) solrCore.getMetricRegistry().getGauges().get(\"UPDATE.updateHandler.docsPending\").getValue();\n      assertEquals(\"Expected non docs are pending in core \" + solrCore.getCoreDescriptor(),0, docsPending);\n    }\n\n    checkRTG(1, 4, cluster.getJettySolrRunners());\n\n    new UpdateRequest()\n        .deleteById(\"1\")\n        .deleteByQuery(\"id:2\")\n        .process(cloudClient, collectionName);\n\n    // The DBQ is not processed at replicas, so we still can get doc2 and other docs by RTG\n    checkRTG(2,4, getSolrRunner(false));\n\n    Map<SolrCore, Long> timeCopyOverPerCores = getTimesCopyOverOldUpdates(getSolrCore(false));\n    new UpdateRequest()\n        .commit(cloudClient, collectionName);\n\n    waitForNumDocsInAllActiveReplicas(2);\n    // There are a small delay between new searcher and copy over old updates operation\n    TimeOut timeOut = new TimeOut(5, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    while (!timeOut.hasTimedOut()) {\n      if (assertCopyOverOldUpdates(1, timeCopyOverPerCores)) {\n        break;\n      } else {\n        Thread.sleep(500);\n      }\n    }\n    assertTrue(\"Expect only one copy over updates per cores\", assertCopyOverOldUpdates(1, timeCopyOverPerCores));\n\n    boolean firstCommit = true;\n    // UpdateLog copy over old updates\n    for (int i = 15; i <= 150; i++) {\n      cloudClient.add(collectionName, sdoc(\"id\",String.valueOf(i)));\n      if (random().nextInt(100) < 15 & i != 150) {\n        if (firstCommit) {\n          // because tlog replicas periodically ask leader for new segments,\n          // therefore the copy over old updates action must not be triggered until\n          // tlog replicas actually get new segments\n          assertTrue(\"Expect only one copy over updates per cores\", assertCopyOverOldUpdates(1, timeCopyOverPerCores));\n          firstCommit = false;\n        }\n        cloudClient.commit(collectionName);\n      }\n    }\n    checkRTG(120,150, cluster.getJettySolrRunners());\n    waitForReplicasCatchUp(4 * REPLICATION_TIMEOUT_SECS);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0484631b41605341d7e71ec7a9ccea076ee90591":["bedc8e5595055009e34aaa41f94d3645ba103d98"],"04ecf884544ff74add5faa452748f160c4af904b":["61c45e99cf6676da48f19d7511c73712ad39402b"],"61c45e99cf6676da48f19d7511c73712ad39402b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"bf5b93713fb0adca4f2a88e0a629554bf1ac2866":["0db83f1bb855a4ac824c9a2a8e1ee9b29a039c15"],"bedc8e5595055009e34aaa41f94d3645ba103d98":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","61c45e99cf6676da48f19d7511c73712ad39402b"],"065d6b6bd6c614a2b8bb17507341c326573438ae":["820dc7f947c9383eaa2feebcfb3e072799bf11c0"],"820dc7f947c9383eaa2feebcfb3e072799bf11c0":["04ecf884544ff74add5faa452748f160c4af904b"],"7c2af5a711bd6e2d33e0221ced0f47ac596ed275":["bf5b93713fb0adca4f2a88e0a629554bf1ac2866"],"6240b74b884c5587f2a4062dd27d6c32bf228889":["e9017cf144952056066919f1ebc7897ff9bd71b1","04ecf884544ff74add5faa452748f160c4af904b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"77c61b53ac917c240593803ca928b383da9a4cd7":["065d6b6bd6c614a2b8bb17507341c326573438ae"],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["77c61b53ac917c240593803ca928b383da9a4cd7"],"0db83f1bb855a4ac824c9a2a8e1ee9b29a039c15":["0484631b41605341d7e71ec7a9ccea076ee90591"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["7c2af5a711bd6e2d33e0221ced0f47ac596ed275"]},"commit2Childs":{"0484631b41605341d7e71ec7a9ccea076ee90591":["0db83f1bb855a4ac824c9a2a8e1ee9b29a039c15"],"04ecf884544ff74add5faa452748f160c4af904b":["820dc7f947c9383eaa2feebcfb3e072799bf11c0","6240b74b884c5587f2a4062dd27d6c32bf228889"],"61c45e99cf6676da48f19d7511c73712ad39402b":["04ecf884544ff74add5faa452748f160c4af904b","e9017cf144952056066919f1ebc7897ff9bd71b1"],"bf5b93713fb0adca4f2a88e0a629554bf1ac2866":["7c2af5a711bd6e2d33e0221ced0f47ac596ed275"],"bedc8e5595055009e34aaa41f94d3645ba103d98":["0484631b41605341d7e71ec7a9ccea076ee90591"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["6240b74b884c5587f2a4062dd27d6c32bf228889"],"065d6b6bd6c614a2b8bb17507341c326573438ae":["77c61b53ac917c240593803ca928b383da9a4cd7"],"820dc7f947c9383eaa2feebcfb3e072799bf11c0":["065d6b6bd6c614a2b8bb17507341c326573438ae"],"7c2af5a711bd6e2d33e0221ced0f47ac596ed275":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"6240b74b884c5587f2a4062dd27d6c32bf228889":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["61c45e99cf6676da48f19d7511c73712ad39402b","e9017cf144952056066919f1ebc7897ff9bd71b1"],"77c61b53ac917c240593803ca928b383da9a4cd7":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["bedc8e5595055009e34aaa41f94d3645ba103d98"],"0db83f1bb855a4ac824c9a2a8e1ee9b29a039c15":["bf5b93713fb0adca4f2a88e0a629554bf1ac2866"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["6240b74b884c5587f2a4062dd27d6c32bf228889","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}