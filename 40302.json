{"path":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getFilter(DocSet,List[Query]).mjava","commits":[{"id":"b785b1f61f30f94f0708b16d7f2eee3ee23194ef","date":1285384789,"type":0,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getFilter(DocSet,List[Query]).mjava","pathOld":"/dev/null","sourceNew":"  Filter getFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    Filter answer = setFilter == null ? null : setFilter.getTopFilter();\n\n    if (queries == null || queries.size() == 0) {\n      return answer;\n    }\n\n    if (answer == null && queries.size() == 1) {\n      return getFilter(queries.get(0));  \n    }\n\n\n    DocSet finalSet=null;\n\n    int nDocSets =0;\n    boolean[] neg = new boolean[queries.size()];\n    DocSet[] sets = new DocSet[queries.size()];\n    Query[] nocache = new Query[queries.size()];\n\n    int smallestIndex = -1;\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      // if (q instanceof)\n\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[nDocSets] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[nDocSets] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[nDocSets].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=nDocSets;\n          finalSet = sets[nDocSets];\n        }\n      } else {\n        neg[nDocSets] = true;\n      }\n\n      nDocSets++;\n    }\n\n    // if no positive queries, start off with all docs\n    if (finalSet==null) finalSet = getPositiveDocSet(matchAllDocsQuery);\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<sets.length; i++) {\n      if (neg[i]) finalSet = finalSet.andNot(sets[i]);\n    }\n\n    for (int i=0; i<sets.length; i++) {\n      if (!neg[i] && i!=smallestIndex) finalSet = finalSet.intersection(sets[i]);\n    }\n\n    return finalSet.getTopFilter();\n\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":0,"author":"Michael Busch","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getFilter(DocSet,List[Query]).mjava","pathOld":"/dev/null","sourceNew":"  Filter getFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    Filter answer = setFilter == null ? null : setFilter.getTopFilter();\n\n    if (queries == null || queries.size() == 0) {\n      return answer;\n    }\n\n    if (answer == null && queries.size() == 1) {\n      return getFilter(queries.get(0));  \n    }\n\n\n    DocSet finalSet=null;\n\n    int nDocSets =0;\n    boolean[] neg = new boolean[queries.size()];\n    DocSet[] sets = new DocSet[queries.size()];\n    Query[] nocache = new Query[queries.size()];\n\n    int smallestIndex = -1;\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      // if (q instanceof)\n\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[nDocSets] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[nDocSets] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[nDocSets].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=nDocSets;\n          finalSet = sets[nDocSets];\n        }\n      } else {\n        neg[nDocSets] = true;\n      }\n\n      nDocSets++;\n    }\n\n    // if no positive queries, start off with all docs\n    if (finalSet==null) finalSet = getPositiveDocSet(matchAllDocsQuery);\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<sets.length; i++) {\n      if (neg[i]) finalSet = finalSet.andNot(sets[i]);\n    }\n\n    for (int i=0; i<sets.length; i++) {\n      if (!neg[i] && i!=smallestIndex) finalSet = finalSet.intersection(sets[i]);\n    }\n\n    return finalSet.getTopFilter();\n\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8bf47b67b38083a0c4d9d2e3f53b59a48e8db34","date":1309197122,"type":4,"author":"Yonik Seeley","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getFilter(DocSet,List[Query]).mjava","sourceNew":null,"sourceOld":"  Filter getFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    Filter answer = setFilter == null ? null : setFilter.getTopFilter();\n\n    if (queries == null || queries.size() == 0) {\n      return answer;\n    }\n\n    if (answer == null && queries.size() == 1) {\n      return getFilter(queries.get(0));  \n    }\n\n\n    DocSet finalSet=null;\n\n    int nDocSets =0;\n    boolean[] neg = new boolean[queries.size()];\n    DocSet[] sets = new DocSet[queries.size()];\n    Query[] nocache = new Query[queries.size()];\n\n    int smallestIndex = -1;\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      // if (q instanceof)\n\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[nDocSets] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[nDocSets] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[nDocSets].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=nDocSets;\n          finalSet = sets[nDocSets];\n        }\n      } else {\n        neg[nDocSets] = true;\n      }\n\n      nDocSets++;\n    }\n\n    // if no positive queries, start off with all docs\n    if (finalSet==null) finalSet = getPositiveDocSet(matchAllDocsQuery);\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<sets.length; i++) {\n      if (neg[i]) finalSet = finalSet.andNot(sets[i]);\n    }\n\n    for (int i=0; i<sets.length; i++) {\n      if (!neg[i] && i!=smallestIndex) finalSet = finalSet.intersection(sets[i]);\n    }\n\n    return finalSet.getTopFilter();\n\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2553b00f699380c64959ccb27991289aae87be2e","date":1309290151,"type":4,"author":"Steven Rowe","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getFilter(DocSet,List[Query]).mjava","sourceNew":null,"sourceOld":"  Filter getFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    Filter answer = setFilter == null ? null : setFilter.getTopFilter();\n\n    if (queries == null || queries.size() == 0) {\n      return answer;\n    }\n\n    if (answer == null && queries.size() == 1) {\n      return getFilter(queries.get(0));  \n    }\n\n\n    DocSet finalSet=null;\n\n    int nDocSets =0;\n    boolean[] neg = new boolean[queries.size()];\n    DocSet[] sets = new DocSet[queries.size()];\n    Query[] nocache = new Query[queries.size()];\n\n    int smallestIndex = -1;\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      // if (q instanceof)\n\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[nDocSets] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[nDocSets] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[nDocSets].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=nDocSets;\n          finalSet = sets[nDocSets];\n        }\n      } else {\n        neg[nDocSets] = true;\n      }\n\n      nDocSets++;\n    }\n\n    // if no positive queries, start off with all docs\n    if (finalSet==null) finalSet = getPositiveDocSet(matchAllDocsQuery);\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<sets.length; i++) {\n      if (neg[i]) finalSet = finalSet.andNot(sets[i]);\n    }\n\n    for (int i=0; i<sets.length; i++) {\n      if (!neg[i] && i!=smallestIndex) finalSet = finalSet.intersection(sets[i]);\n    }\n\n    return finalSet.getTopFilter();\n\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":4,"author":"Simon Willnauer","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getFilter(DocSet,List[Query]).mjava","sourceNew":null,"sourceOld":"  Filter getFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    Filter answer = setFilter == null ? null : setFilter.getTopFilter();\n\n    if (queries == null || queries.size() == 0) {\n      return answer;\n    }\n\n    if (answer == null && queries.size() == 1) {\n      return getFilter(queries.get(0));  \n    }\n\n\n    DocSet finalSet=null;\n\n    int nDocSets =0;\n    boolean[] neg = new boolean[queries.size()];\n    DocSet[] sets = new DocSet[queries.size()];\n    Query[] nocache = new Query[queries.size()];\n\n    int smallestIndex = -1;\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      // if (q instanceof)\n\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[nDocSets] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[nDocSets] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[nDocSets].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=nDocSets;\n          finalSet = sets[nDocSets];\n        }\n      } else {\n        neg[nDocSets] = true;\n      }\n\n      nDocSets++;\n    }\n\n    // if no positive queries, start off with all docs\n    if (finalSet==null) finalSet = getPositiveDocSet(matchAllDocsQuery);\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<sets.length; i++) {\n      if (neg[i]) finalSet = finalSet.andNot(sets[i]);\n    }\n\n    for (int i=0; i<sets.length; i++) {\n      if (!neg[i] && i!=smallestIndex) finalSet = finalSet.intersection(sets[i]);\n    }\n\n    return finalSet.getTopFilter();\n\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"f8bf47b67b38083a0c4d9d2e3f53b59a48e8db34":["b785b1f61f30f94f0708b16d7f2eee3ee23194ef"],"b785b1f61f30f94f0708b16d7f2eee3ee23194ef":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"2553b00f699380c64959ccb27991289aae87be2e":["b785b1f61f30f94f0708b16d7f2eee3ee23194ef","f8bf47b67b38083a0c4d9d2e3f53b59a48e8db34"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","b785b1f61f30f94f0708b16d7f2eee3ee23194ef"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["b785b1f61f30f94f0708b16d7f2eee3ee23194ef","f8bf47b67b38083a0c4d9d2e3f53b59a48e8db34"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["f8bf47b67b38083a0c4d9d2e3f53b59a48e8db34"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b785b1f61f30f94f0708b16d7f2eee3ee23194ef","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"f8bf47b67b38083a0c4d9d2e3f53b59a48e8db34":["2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"b785b1f61f30f94f0708b16d7f2eee3ee23194ef":["f8bf47b67b38083a0c4d9d2e3f53b59a48e8db34","2553b00f699380c64959ccb27991289aae87be2e","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","d083e83f225b11e5fdd900e83d26ddb385b6955c"],"2553b00f699380c64959ccb27991289aae87be2e":[],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":[],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["2553b00f699380c64959ccb27991289aae87be2e","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","d083e83f225b11e5fdd900e83d26ddb385b6955c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}