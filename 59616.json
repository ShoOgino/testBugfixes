{"path":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],FacetResultNode,int).mjava","commits":[{"id":"571abba77e55fea386a38c0024f72ffa5b37a9ad","date":1360272747,"type":1,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],FacetResultNode,int).mjava","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],FacetResultNode,FacetArrays,int).mjava","sourceNew":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq, FacetResultNode parentResultNode, \n      int offset) throws IOException {\n    int partitionSize = facetArrays.arrayLength;\n    int endOffset = offset + partitionSize;\n    ParallelTaxonomyArrays childrenArray = taxonomyReader.getParallelTaxonomyArrays();\n    int[] children = childrenArray.children();\n    int[] siblings = childrenArray.siblings();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = children[ordinal];\n    while (yc >= endOffset) {\n      yc = siblings[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = siblings[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = facetRequest.getValueOf(facetArrays, relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new FacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            reusable.ordinal = tosOrdinal;\n            reusable.value = value;\n            reusable.subResults.clear();\n            reusable.label = null;\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = children[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = siblings[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","sourceOld":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq, FacetResultNode parentResultNode, \n      FacetArrays facetArrays, int offset) throws IOException {\n    int partitionSize = facetArrays.arrayLength;\n    int endOffset = offset + partitionSize;\n    ParallelTaxonomyArrays childrenArray = taxonomyReader.getParallelTaxonomyArrays();\n    int[] children = childrenArray.children();\n    int[] siblings = childrenArray.siblings();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = children[ordinal];\n    while (yc >= endOffset) {\n      yc = siblings[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = siblings[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = facetRequest.getValueOf(facetArrays, relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new FacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            reusable.ordinal = tosOrdinal;\n            reusable.value = value;\n            reusable.subResults.clear();\n            reusable.label = null;\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = children[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = siblings[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3b1c67b5eba853532b31132bf5aef70a3b2be63f","date":1375351298,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],FacetResultNode,int).mjava","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],FacetResultNode,int).mjava","sourceNew":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq, FacetResultNode parentResultNode, \n      int offset) throws IOException {\n    int partitionSize = facetArrays.arrayLength;\n    int endOffset = offset + partitionSize;\n    ParallelTaxonomyArrays childrenArray = taxonomyReader.getParallelTaxonomyArrays();\n    int[] children = childrenArray.children();\n    int[] siblings = childrenArray.siblings();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = children[ordinal];\n    while (yc >= endOffset) {\n      yc = siblings[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = siblings[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = resolver.valueOf(relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new FacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            reusable.ordinal = tosOrdinal;\n            reusable.value = value;\n            reusable.subResults.clear();\n            reusable.label = null;\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = children[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = siblings[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","sourceOld":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq, FacetResultNode parentResultNode, \n      int offset) throws IOException {\n    int partitionSize = facetArrays.arrayLength;\n    int endOffset = offset + partitionSize;\n    ParallelTaxonomyArrays childrenArray = taxonomyReader.getParallelTaxonomyArrays();\n    int[] children = childrenArray.children();\n    int[] siblings = childrenArray.siblings();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = children[ordinal];\n    while (yc >= endOffset) {\n      yc = siblings[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = siblings[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = facetRequest.getValueOf(facetArrays, relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new FacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            reusable.ordinal = tosOrdinal;\n            reusable.value = value;\n            reusable.subResults.clear();\n            reusable.label = null;\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = children[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = siblings[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],FacetResultNode,int).mjava","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],FacetResultNode,int).mjava","sourceNew":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq, FacetResultNode parentResultNode, \n      int offset) throws IOException {\n    int partitionSize = facetArrays.arrayLength;\n    int endOffset = offset + partitionSize;\n    ParallelTaxonomyArrays childrenArray = taxonomyReader.getParallelTaxonomyArrays();\n    int[] children = childrenArray.children();\n    int[] siblings = childrenArray.siblings();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = children[ordinal];\n    while (yc >= endOffset) {\n      yc = siblings[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = siblings[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = resolver.valueOf(relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new FacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            reusable.ordinal = tosOrdinal;\n            reusable.value = value;\n            reusable.subResults.clear();\n            reusable.label = null;\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = children[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = siblings[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","sourceOld":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq, FacetResultNode parentResultNode, \n      int offset) throws IOException {\n    int partitionSize = facetArrays.arrayLength;\n    int endOffset = offset + partitionSize;\n    ParallelTaxonomyArrays childrenArray = taxonomyReader.getParallelTaxonomyArrays();\n    int[] children = childrenArray.children();\n    int[] siblings = childrenArray.siblings();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = children[ordinal];\n    while (yc >= endOffset) {\n      yc = siblings[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = siblings[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = facetRequest.getValueOf(facetArrays, relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new FacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            reusable.ordinal = tosOrdinal;\n            reusable.value = value;\n            reusable.subResults.clear();\n            reusable.label = null;\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = children[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = siblings[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d33e19a97046248623a7591aeaa6547233fd15e2","date":1385424777,"type":4,"author":"Michael McCandless","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],FacetResultNode,int).mjava","sourceNew":null,"sourceOld":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq, FacetResultNode parentResultNode, \n      int offset) throws IOException {\n    int partitionSize = facetArrays.arrayLength;\n    int endOffset = offset + partitionSize;\n    ParallelTaxonomyArrays childrenArray = taxonomyReader.getParallelTaxonomyArrays();\n    int[] children = childrenArray.children();\n    int[] siblings = childrenArray.siblings();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = children[ordinal];\n    while (yc >= endOffset) {\n      yc = siblings[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = siblings[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = resolver.valueOf(relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new FacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            reusable.ordinal = tosOrdinal;\n            reusable.value = value;\n            reusable.subResults.clear();\n            reusable.label = null;\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = children[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = siblings[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3cc728b07df73b197e6d940d27f9b08b63918f13","date":1388834348,"type":4,"author":"Michael McCandless","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/search/TopKFacetResultsHandler#heapDescendants(int,Heap[FacetResultNode],FacetResultNode,int).mjava","sourceNew":null,"sourceOld":"  /**\n   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()\n   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). \n   * Candidates are restricted to current \"counting list\" and current \"partition\",\n   * they join the overall priority queue pq of size K.  \n   * @return total number of descendants considered here by pq, excluding ordinal itself.\n   */\n  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq, FacetResultNode parentResultNode, \n      int offset) throws IOException {\n    int partitionSize = facetArrays.arrayLength;\n    int endOffset = offset + partitionSize;\n    ParallelTaxonomyArrays childrenArray = taxonomyReader.getParallelTaxonomyArrays();\n    int[] children = childrenArray.children();\n    int[] siblings = childrenArray.siblings();\n    FacetResultNode reusable = null;\n    int localDepth = 0;\n    int depth = facetRequest.getDepth();\n    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];\n    int childrenCounter = 0;\n    \n    int tosOrdinal; // top of stack element\n    \n    int yc = children[ordinal];\n    while (yc >= endOffset) {\n      yc = siblings[yc];\n    }\n    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset\n    // and it, too, can stop the loop.\n    ordinalStack[++localDepth] = yc;\n    \n    /*\n     * stack holds input parameter ordinal in position 0.\n     * Other elements are < endoffset.\n     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if\n     * the element below it exhausted all its children: has them all processed.\n     * \n     * stack elements are processed (counted and accumulated) only if they \n     * belong to current partition (between offset and endoffset) and first time\n     * they are on top of stack \n     * \n     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling\n     */\n    while (localDepth > 0) {\n      tosOrdinal = ordinalStack[localDepth];\n      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {\n        // element below tos has all its children, and itself, all processed\n        // need to proceed to its sibling\n        localDepth--;\n        // change element now on top of stack to its sibling.\n        ordinalStack[localDepth] = siblings[ordinalStack[localDepth]];\n        continue;\n      }\n      // top of stack is not invalid, this is the first time we see it on top of stack.\n      // collect it, if belongs to current partition, and then push its kids on itself, if applicable\n      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition\n        int relativeOrdinal = tosOrdinal % partitionSize;\n        double value = resolver.valueOf(relativeOrdinal);\n        if (value != 0 && !Double.isNaN(value)) {\n          // Count current ordinal -- the TOS\n          if (reusable == null) {\n            reusable = new FacetResultNode(tosOrdinal, value);\n          } else {\n            // it is safe to cast since reusable was created here.\n            reusable.ordinal = tosOrdinal;\n            reusable.value = value;\n            reusable.subResults.clear();\n            reusable.label = null;\n          }\n          ++childrenCounter;\n          reusable = pq.insertWithOverflow(reusable);\n        }\n      }\n      if (localDepth < depth) {\n        // push kid of current tos\n        yc = children[tosOrdinal];\n        while (yc >= endOffset) {\n          yc = siblings[yc];\n        }\n        ordinalStack[++localDepth] = yc;\n      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL\n        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;\n      }\n    } // endof while stack is not empty\n    \n    return childrenCounter; // we're done\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3b1c67b5eba853532b31132bf5aef70a3b2be63f":["571abba77e55fea386a38c0024f72ffa5b37a9ad"],"d33e19a97046248623a7591aeaa6547233fd15e2":["3b1c67b5eba853532b31132bf5aef70a3b2be63f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["571abba77e55fea386a38c0024f72ffa5b37a9ad"],"3cc728b07df73b197e6d940d27f9b08b63918f13":["3b1c67b5eba853532b31132bf5aef70a3b2be63f","d33e19a97046248623a7591aeaa6547233fd15e2"],"571abba77e55fea386a38c0024f72ffa5b37a9ad":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3cc728b07df73b197e6d940d27f9b08b63918f13"]},"commit2Childs":{"3b1c67b5eba853532b31132bf5aef70a3b2be63f":["d33e19a97046248623a7591aeaa6547233fd15e2","3cc728b07df73b197e6d940d27f9b08b63918f13"],"d33e19a97046248623a7591aeaa6547233fd15e2":["3cc728b07df73b197e6d940d27f9b08b63918f13"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["571abba77e55fea386a38c0024f72ffa5b37a9ad"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"3cc728b07df73b197e6d940d27f9b08b63918f13":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"571abba77e55fea386a38c0024f72ffa5b37a9ad":["3b1c67b5eba853532b31132bf5aef70a3b2be63f","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}