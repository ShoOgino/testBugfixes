{"path":"src/java/org/apache/lucene/index/DocumentsWriterThreadState#writeDocument().mjava","commits":[{"id":"5a0af3a442be522899177e5e11384a45a6784a3f","date":1205348952,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriterThreadState#writeDocument().mjava","pathOld":"/dev/null","sourceNew":"  /** Move all per-document state that was accumulated in\n   *  the ThreadState into the \"real\" stores. */\n  public void writeDocument() throws IOException, AbortException {\n\n    // If we hit an exception while appending to the\n    // stored fields or term vectors files, we have to\n    // abort all documents since we last flushed because\n    // it means those files are possibly inconsistent.\n    try {\n\n      docWriter.numDocsInStore++;\n\n      // Append stored fields to the real FieldsWriter:\n      docWriter.fieldsWriter.flushDocument(numStoredFields, fdtLocal);\n      fdtLocal.reset();\n\n      // Append term vectors to the real outputs:\n      final IndexOutput tvx = docWriter.tvx;\n      final IndexOutput tvd = docWriter.tvd;\n      final IndexOutput tvf = docWriter.tvf;\n      if (tvx != null) {\n        tvx.writeLong(tvd.getFilePointer());\n        tvx.writeLong(tvf.getFilePointer());\n        tvd.writeVInt(numVectorFields);\n        if (numVectorFields > 0) {\n          for(int i=0;i<numVectorFields;i++)\n            tvd.writeVInt(vectorFieldNumbers[i]);\n          assert 0 == vectorFieldPointers[0];\n          long lastPos = vectorFieldPointers[0];\n          for(int i=1;i<numVectorFields;i++) {\n            long pos = vectorFieldPointers[i];\n            tvd.writeVLong(pos-lastPos);\n            lastPos = pos;\n          }\n          tvfLocal.writeTo(tvf);\n          tvfLocal.reset();\n        }\n      }\n\n      // Append norms for the fields we saw:\n      for(int i=0;i<numFieldData;i++) {\n        DocumentsWriterFieldData fp = fieldDataArray[i];\n        if (fp.doNorms) {\n          BufferedNorms bn = docWriter.norms[fp.fieldInfo.number];\n          assert bn != null;\n          assert bn.upto <= docID;\n          bn.fill(docID);\n          float norm = fp.boost * docWriter.writer.getSimilarity().lengthNorm(fp.fieldInfo.name, fp.length);\n          bn.add(norm);\n        }\n      }\n    } catch (Throwable t) {\n      // Forcefully idle this threadstate -- its state will\n      // be reset by abort()\n      isIdle = true;\n      throw new AbortException(t, docWriter);\n    }\n\n    if (docWriter.bufferIsFull && !docWriter.flushPending) {\n      docWriter.flushPending = true;\n      doFlushAfter = true;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5350389bf83287111f7760b9e3db3af8e3648474","date":1216372812,"type":4,"author":"Michael McCandless","isMerge":false,"pathNew":"/dev/null","pathOld":"src/java/org/apache/lucene/index/DocumentsWriterThreadState#writeDocument().mjava","sourceNew":null,"sourceOld":"  /** Move all per-document state that was accumulated in\n   *  the ThreadState into the \"real\" stores. */\n  public void writeDocument() throws IOException, AbortException {\n\n    // If we hit an exception while appending to the\n    // stored fields or term vectors files, we have to\n    // abort all documents since we last flushed because\n    // it means those files are possibly inconsistent.\n    try {\n\n      docWriter.numDocsInStore++;\n\n      // Append stored fields to the real FieldsWriter:\n      docWriter.fieldsWriter.flushDocument(numStoredFields, fdtLocal);\n      fdtLocal.reset();\n\n      // Append term vectors to the real outputs:\n      final IndexOutput tvx = docWriter.tvx;\n      final IndexOutput tvd = docWriter.tvd;\n      final IndexOutput tvf = docWriter.tvf;\n      if (tvx != null) {\n        tvx.writeLong(tvd.getFilePointer());\n        tvx.writeLong(tvf.getFilePointer());\n        tvd.writeVInt(numVectorFields);\n        if (numVectorFields > 0) {\n          for(int i=0;i<numVectorFields;i++)\n            tvd.writeVInt(vectorFieldNumbers[i]);\n          assert 0 == vectorFieldPointers[0];\n          long lastPos = vectorFieldPointers[0];\n          for(int i=1;i<numVectorFields;i++) {\n            long pos = vectorFieldPointers[i];\n            tvd.writeVLong(pos-lastPos);\n            lastPos = pos;\n          }\n          tvfLocal.writeTo(tvf);\n          tvfLocal.reset();\n        }\n      }\n\n      // Append norms for the fields we saw:\n      for(int i=0;i<numFieldData;i++) {\n        DocumentsWriterFieldData fp = fieldDataArray[i];\n        if (fp.doNorms) {\n          BufferedNorms bn = docWriter.norms[fp.fieldInfo.number];\n          assert bn != null;\n          assert bn.upto <= docID;\n          bn.fill(docID);\n          float norm = fp.boost * docWriter.writer.getSimilarity().lengthNorm(fp.fieldInfo.name, fp.length);\n          bn.add(norm);\n        }\n      }\n    } catch (Throwable t) {\n      // Forcefully idle this threadstate -- its state will\n      // be reset by abort()\n      isIdle = true;\n      throw new AbortException(t, docWriter);\n    }\n\n    if (docWriter.bufferIsFull && !docWriter.flushPending) {\n      docWriter.flushPending = true;\n      doFlushAfter = true;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"5a0af3a442be522899177e5e11384a45a6784a3f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"5350389bf83287111f7760b9e3db3af8e3648474":["5a0af3a442be522899177e5e11384a45a6784a3f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["5350389bf83287111f7760b9e3db3af8e3648474"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["5a0af3a442be522899177e5e11384a45a6784a3f"],"5a0af3a442be522899177e5e11384a45a6784a3f":["5350389bf83287111f7760b9e3db3af8e3648474"],"5350389bf83287111f7760b9e3db3af8e3648474":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}