{"path":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","pathOld":"src/test/org/apache/lucene/TestDemo#testDemo().mjava","sourceNew":"  public void testDemo() throws IOException, ParseException {\n\n    Analyzer analyzer = new StandardAnalyzer(TEST_VERSION_CURRENT);\n\n    // Store the index in memory:\n    Directory directory = new RAMDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    IndexWriter iwriter = new IndexWriter(directory, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, analyzer).setMaxFieldLength(25000));\n    \n    Document doc = new Document();\n    String text = \"This is the text to be indexed.\";\n    doc.add(new Field(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    ScoreDoc[] hits = isearcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    // Iterate through the results:\n    for (int i = 0; i < hits.length; i++) {\n      Document hitDoc = isearcher.doc(hits[i].doc);\n      assertEquals(\"This is the text to be indexed.\", hitDoc.get(\"fieldname\"));\n    }\n    isearcher.close();\n    directory.close();\n    \n  }\n\n","sourceOld":"  public void testDemo() throws IOException, ParseException {\n\n    Analyzer analyzer = new StandardAnalyzer(TEST_VERSION_CURRENT);\n\n    // Store the index in memory:\n    Directory directory = new RAMDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    IndexWriter iwriter = new IndexWriter(directory, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, analyzer).setMaxFieldLength(25000));\n    \n    Document doc = new Document();\n    String text = \"This is the text to be indexed.\";\n    doc.add(new Field(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    ScoreDoc[] hits = isearcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    // Iterate through the results:\n    for (int i = 0; i < hits.length; i++) {\n      Document hitDoc = isearcher.doc(hits[i].doc);\n      assertEquals(\"This is the text to be indexed.\", hitDoc.get(\"fieldname\"));\n    }\n    isearcher.close();\n    directory.close();\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"955c32f886db6f6356c9fcdea6b1f1cb4effda24","date":1270581567,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","pathOld":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","sourceNew":"  public void testDemo() throws IOException, ParseException {\n\n    Analyzer analyzer = new StandardAnalyzer(TEST_VERSION_CURRENT);\n\n    // Store the index in memory:\n    Directory directory = new RAMDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    IndexWriter iwriter = new IndexWriter(directory, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, analyzer).setMaxFieldLength(25000));\n    \n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(new Field(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    ScoreDoc[] hits = isearcher.search(query, null, 1).scoreDocs;\n    assertEquals(1, hits.length);\n    // Iterate through the results:\n    for (int i = 0; i < hits.length; i++) {\n      Document hitDoc = isearcher.doc(hits[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n    isearcher.close();\n    directory.close();\n    \n  }\n\n","sourceOld":"  public void testDemo() throws IOException, ParseException {\n\n    Analyzer analyzer = new StandardAnalyzer(TEST_VERSION_CURRENT);\n\n    // Store the index in memory:\n    Directory directory = new RAMDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    IndexWriter iwriter = new IndexWriter(directory, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, analyzer).setMaxFieldLength(25000));\n    \n    Document doc = new Document();\n    String text = \"This is the text to be indexed.\";\n    doc.add(new Field(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    ScoreDoc[] hits = isearcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    // Iterate through the results:\n    for (int i = 0; i < hits.length; i++) {\n      Document hitDoc = isearcher.doc(hits[i].doc);\n      assertEquals(\"This is the text to be indexed.\", hitDoc.get(\"fieldname\"));\n    }\n    isearcher.close();\n    directory.close();\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d572389229127c297dd1fa5ce4758e1cec41e799","date":1273610938,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","pathOld":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","sourceNew":"  public void testDemo() throws IOException, ParseException {\n\n    Analyzer analyzer = new MockAnalyzer();\n\n    // Store the index in memory:\n    Directory directory = new RAMDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    IndexWriter iwriter = new IndexWriter(directory, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, analyzer).setMaxFieldLength(25000));\n    \n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(new Field(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    ScoreDoc[] hits = isearcher.search(query, null, 1).scoreDocs;\n    assertEquals(1, hits.length);\n    // Iterate through the results:\n    for (int i = 0; i < hits.length; i++) {\n      Document hitDoc = isearcher.doc(hits[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n    isearcher.close();\n    directory.close();\n    \n  }\n\n","sourceOld":"  public void testDemo() throws IOException, ParseException {\n\n    Analyzer analyzer = new StandardAnalyzer(TEST_VERSION_CURRENT);\n\n    // Store the index in memory:\n    Directory directory = new RAMDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    IndexWriter iwriter = new IndexWriter(directory, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, analyzer).setMaxFieldLength(25000));\n    \n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(new Field(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    ScoreDoc[] hits = isearcher.search(query, null, 1).scoreDocs;\n    assertEquals(1, hits.length);\n    // Iterate through the results:\n    for (int i = 0; i < hits.length; i++) {\n      Document hitDoc = isearcher.doc(hits[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n    isearcher.close();\n    directory.close();\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c","date":1281477834,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","pathOld":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","sourceNew":"  public void testDemo() throws IOException, ParseException {\n\n    Analyzer analyzer = new MockAnalyzer();\n\n    // Store the index in memory:\n    Directory directory = new MockRAMDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    IndexWriter iwriter = new IndexWriter(directory, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, analyzer).setMaxFieldLength(25000));\n    \n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(new Field(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    ScoreDoc[] hits = isearcher.search(query, null, 1).scoreDocs;\n    assertEquals(1, hits.length);\n    // Iterate through the results:\n    for (int i = 0; i < hits.length; i++) {\n      Document hitDoc = isearcher.doc(hits[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n    isearcher.close();\n    directory.close();\n    \n  }\n\n","sourceOld":"  public void testDemo() throws IOException, ParseException {\n\n    Analyzer analyzer = new MockAnalyzer();\n\n    // Store the index in memory:\n    Directory directory = new RAMDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    IndexWriter iwriter = new IndexWriter(directory, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, analyzer).setMaxFieldLength(25000));\n    \n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(new Field(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    ScoreDoc[] hits = isearcher.search(query, null, 1).scoreDocs;\n    assertEquals(1, hits.length);\n    // Iterate through the results:\n    for (int i = 0; i < hits.length; i++) {\n      Document hitDoc = isearcher.doc(hits[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n    isearcher.close();\n    directory.close();\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a05409176bd65129d67a785ee70e881e238a9aef","date":1282582843,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","pathOld":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","sourceNew":"  public void testDemo() throws IOException, ParseException {\n\n    Analyzer analyzer = new MockAnalyzer();\n\n    // Store the index in memory:\n    Directory directory = newDirectory(newRandom());\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    IndexWriter iwriter = new IndexWriter(directory, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, analyzer).setMaxFieldLength(25000));\n    \n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(new Field(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    ScoreDoc[] hits = isearcher.search(query, null, 1).scoreDocs;\n    assertEquals(1, hits.length);\n    // Iterate through the results:\n    for (int i = 0; i < hits.length; i++) {\n      Document hitDoc = isearcher.doc(hits[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n    isearcher.close();\n    directory.close();\n    \n  }\n\n","sourceOld":"  public void testDemo() throws IOException, ParseException {\n\n    Analyzer analyzer = new MockAnalyzer();\n\n    // Store the index in memory:\n    Directory directory = new MockRAMDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    IndexWriter iwriter = new IndexWriter(directory, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, analyzer).setMaxFieldLength(25000));\n    \n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(new Field(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    ScoreDoc[] hits = isearcher.search(query, null, 1).scoreDocs;\n    assertEquals(1, hits.length);\n    // Iterate through the results:\n    for (int i = 0; i < hits.length; i++) {\n      Document hitDoc = isearcher.doc(hits[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n    isearcher.close();\n    directory.close();\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1f653cfcf159baeaafe5d01682a911e95bba4012","date":1284122058,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","pathOld":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","sourceNew":"  public void testDemo() throws IOException, ParseException {\n\n    Analyzer analyzer = new MockAnalyzer();\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    IndexWriter iwriter = new IndexWriter(directory, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, analyzer).setMaxFieldLength(25000));\n    \n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(new Field(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    ScoreDoc[] hits = isearcher.search(query, null, 1).scoreDocs;\n    assertEquals(1, hits.length);\n    // Iterate through the results:\n    for (int i = 0; i < hits.length; i++) {\n      Document hitDoc = isearcher.doc(hits[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n    isearcher.close();\n    directory.close();\n    \n  }\n\n","sourceOld":"  public void testDemo() throws IOException, ParseException {\n\n    Analyzer analyzer = new MockAnalyzer();\n\n    // Store the index in memory:\n    Directory directory = newDirectory(newRandom());\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    IndexWriter iwriter = new IndexWriter(directory, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, analyzer).setMaxFieldLength(25000));\n    \n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(new Field(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    ScoreDoc[] hits = isearcher.search(query, null, 1).scoreDocs;\n    assertEquals(1, hits.length);\n    // Iterate through the results:\n    for (int i = 0; i < hits.length; i++) {\n      Document hitDoc = isearcher.doc(hits[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n    isearcher.close();\n    directory.close();\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"132903c28af3aa6f67284b78de91c0f0a99488c2","date":1284282129,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","pathOld":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","sourceNew":"  public void testDemo() throws IOException, ParseException {\n\n    Analyzer analyzer = new MockAnalyzer();\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    IndexWriter iwriter = new IndexWriter(directory, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, analyzer).setMaxFieldLength(25000));\n    \n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    ScoreDoc[] hits = isearcher.search(query, null, 1).scoreDocs;\n    assertEquals(1, hits.length);\n    // Iterate through the results:\n    for (int i = 0; i < hits.length; i++) {\n      Document hitDoc = isearcher.doc(hits[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n    isearcher.close();\n    directory.close();\n    \n  }\n\n","sourceOld":"  public void testDemo() throws IOException, ParseException {\n\n    Analyzer analyzer = new MockAnalyzer();\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    IndexWriter iwriter = new IndexWriter(directory, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, analyzer).setMaxFieldLength(25000));\n    \n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(new Field(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    ScoreDoc[] hits = isearcher.search(query, null, 1).scoreDocs;\n    assertEquals(1, hits.length);\n    // Iterate through the results:\n    for (int i = 0; i < hits.length; i++) {\n      Document hitDoc = isearcher.doc(hits[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n    isearcher.close();\n    directory.close();\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8d47f68d60cbff5718136b945ba8c55982342f38","date":1285583375,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","pathOld":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","sourceNew":"  public void testDemo() throws IOException, ParseException {\n\n    Analyzer analyzer = new MockAnalyzer();\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    query = parser.parse(\"\\\"to be\\\"\");\n    assertEquals(1, isearcher.search(query, null, 1).totalHits);\n\n    isearcher.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testDemo() throws IOException, ParseException {\n\n    Analyzer analyzer = new MockAnalyzer();\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    IndexWriter iwriter = new IndexWriter(directory, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, analyzer).setMaxFieldLength(25000));\n    \n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    ScoreDoc[] hits = isearcher.search(query, null, 1).scoreDocs;\n    assertEquals(1, hits.length);\n    // Iterate through the results:\n    for (int i = 0; i < hits.length; i++) {\n      Document hitDoc = isearcher.doc(hits[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n    isearcher.close();\n    directory.close();\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0c839e28bbf8e26233e9cb58aa45188ae669f2be","date":1287228474,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","pathOld":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","sourceNew":"  public void testDemo() throws IOException, ParseException {\n    fail();\n    Analyzer analyzer = new MockAnalyzer();\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    query = parser.parse(\"\\\"to be\\\"\");\n    assertEquals(1, isearcher.search(query, null, 1).totalHits);\n\n    isearcher.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testDemo() throws IOException, ParseException {\n\n    Analyzer analyzer = new MockAnalyzer();\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    query = parser.parse(\"\\\"to be\\\"\");\n    assertEquals(1, isearcher.search(query, null, 1).totalHits);\n\n    isearcher.close();\n    directory.close();\n  }\n\n","bugFix":["835adbfe7017665e672833c6251cb109d5a1d00c"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"75119b664a58052b6c17ae2d4b57250fbe1e8a7d","date":1287228521,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","pathOld":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","sourceNew":"  public void testDemo() throws IOException, ParseException {\n    Analyzer analyzer = new MockAnalyzer();\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    query = parser.parse(\"\\\"to be\\\"\");\n    assertEquals(1, isearcher.search(query, null, 1).totalHits);\n\n    isearcher.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testDemo() throws IOException, ParseException {\n    fail();\n    Analyzer analyzer = new MockAnalyzer();\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    query = parser.parse(\"\\\"to be\\\"\");\n    assertEquals(1, isearcher.search(query, null, 1).totalHits);\n\n    isearcher.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4ecea1664e8617d82eca3b8055a3c37cb4da8511","date":1287578668,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","pathOld":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","sourceNew":"  public void testDemo() throws IOException, ParseException {\n    Analyzer analyzer = new MockAnalyzer();\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    query = parser.parse(\"\\\"to be\\\"\");\n    assertEquals(1, isearcher.search(query, null, 1).totalHits);\n\n    isearcher.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testDemo() throws IOException, ParseException {\n\n    Analyzer analyzer = new MockAnalyzer();\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    query = parser.parse(\"\\\"to be\\\"\");\n    assertEquals(1, isearcher.search(query, null, 1).totalHits);\n\n    isearcher.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"44fcbde6fb2ac44ee3b45e013e54a42911e689ff","date":1292065621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","pathOld":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","sourceNew":"  public void testDemo() throws IOException, ParseException {\n    Analyzer analyzer = new MockAnalyzer();\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory);\n    iwriter.w.setInfoStream(VERBOSE ? System.out : null);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    query = parser.parse(\"\\\"to be\\\"\");\n    assertEquals(1, isearcher.search(query, null, 1).totalHits);\n\n    isearcher.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testDemo() throws IOException, ParseException {\n    Analyzer analyzer = new MockAnalyzer();\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    query = parser.parse(\"\\\"to be\\\"\");\n    assertEquals(1, isearcher.search(query, null, 1).totalHits);\n\n    isearcher.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab5cb6a74aefb78aa0569857970b9151dfe2e787","date":1292842407,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","pathOld":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","sourceNew":"  public void testDemo() throws IOException, ParseException {\n    Analyzer analyzer = new MockAnalyzer();\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory);\n    iwriter.w.setInfoStream(VERBOSE ? System.out : null);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    query = parser.parse(\"\\\"to be\\\"\");\n    assertEquals(1, isearcher.search(query, null, 1).totalHits);\n\n    isearcher.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testDemo() throws IOException, ParseException {\n    Analyzer analyzer = new MockAnalyzer();\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    query = parser.parse(\"\\\"to be\\\"\");\n    assertEquals(1, isearcher.search(query, null, 1).totalHits);\n\n    isearcher.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","pathOld":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","sourceNew":"  public void testDemo() throws IOException, ParseException {\n    Analyzer analyzer = new MockAnalyzer();\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory);\n    iwriter.w.setInfoStream(VERBOSE ? System.out : null);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    query = parser.parse(\"\\\"to be\\\"\");\n    assertEquals(1, isearcher.search(query, null, 1).totalHits);\n\n    isearcher.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testDemo() throws IOException, ParseException {\n\n    Analyzer analyzer = new MockAnalyzer();\n\n    // Store the index in memory:\n    Directory directory = new RAMDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    IndexWriter iwriter = new IndexWriter(directory, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, analyzer).setMaxFieldLength(25000));\n    \n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(new Field(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    ScoreDoc[] hits = isearcher.search(query, null, 1).scoreDocs;\n    assertEquals(1, hits.length);\n    // Iterate through the results:\n    for (int i = 0; i < hits.length; i++) {\n      Document hitDoc = isearcher.doc(hits[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n    isearcher.close();\n    directory.close();\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2c5f0cb44df114db4228c8f77861714b5cabaea","date":1302542431,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","pathOld":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","sourceNew":"  public void testDemo() throws IOException, ParseException {\n    Analyzer analyzer = new MockAnalyzer(random);\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory, analyzer);\n    iwriter.w.setInfoStream(VERBOSE ? System.out : null);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    query = parser.parse(\"\\\"to be\\\"\");\n    assertEquals(1, isearcher.search(query, null, 1).totalHits);\n\n    isearcher.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testDemo() throws IOException, ParseException {\n    Analyzer analyzer = new MockAnalyzer();\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory);\n    iwriter.w.setInfoStream(VERBOSE ? System.out : null);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    query = parser.parse(\"\\\"to be\\\"\");\n    assertEquals(1, isearcher.search(query, null, 1).totalHits);\n\n    isearcher.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"962d04139994fce5193143ef35615499a9a96d78","date":1302693744,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","pathOld":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","sourceNew":"  public void testDemo() throws IOException, ParseException {\n    Analyzer analyzer = new MockAnalyzer(random);\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory, analyzer);\n    iwriter.w.setInfoStream(VERBOSE ? System.out : null);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    query = parser.parse(\"\\\"to be\\\"\");\n    assertEquals(1, isearcher.search(query, null, 1).totalHits);\n\n    isearcher.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testDemo() throws IOException, ParseException {\n    Analyzer analyzer = new MockAnalyzer();\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory);\n    iwriter.w.setInfoStream(VERBOSE ? System.out : null);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    query = parser.parse(\"\\\"to be\\\"\");\n    assertEquals(1, isearcher.search(query, null, 1).totalHits);\n\n    isearcher.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","pathOld":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","sourceNew":"  public void testDemo() throws IOException, ParseException {\n    Analyzer analyzer = new MockAnalyzer(random);\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory, analyzer);\n    iwriter.w.setInfoStream(VERBOSE ? System.out : null);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    query = parser.parse(\"\\\"to be\\\"\");\n    assertEquals(1, isearcher.search(query, null, 1).totalHits);\n\n    isearcher.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testDemo() throws IOException, ParseException {\n    Analyzer analyzer = new MockAnalyzer();\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory);\n    iwriter.w.setInfoStream(VERBOSE ? System.out : null);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    query = parser.parse(\"\\\"to be\\\"\");\n    assertEquals(1, isearcher.search(query, null, 1).totalHits);\n\n    isearcher.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","pathOld":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","sourceNew":"  public void testDemo() throws IOException, ParseException {\n    Analyzer analyzer = new MockAnalyzer(random);\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory, analyzer);\n    iwriter.w.setInfoStream(VERBOSE ? System.out : null);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    query = parser.parse(\"\\\"to be\\\"\");\n    assertEquals(1, isearcher.search(query, null, 1).totalHits);\n\n    isearcher.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testDemo() throws IOException, ParseException {\n    Analyzer analyzer = new MockAnalyzer();\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory);\n    iwriter.w.setInfoStream(VERBOSE ? System.out : null);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    query = parser.parse(\"\\\"to be\\\"\");\n    assertEquals(1, isearcher.search(query, null, 1).totalHits);\n\n    isearcher.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"112629f1dfd1451722c6047bcf593e6efc96f5f4","date":1309910887,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","pathOld":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","sourceNew":"  public void testDemo() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random);\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory, analyzer);\n    iwriter.w.setInfoStream(VERBOSE ? System.out : null);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    PhraseQuery phraseQuery = new PhraseQuery();\n    phraseQuery.add(new Term(\"fieldname\", \"to\"));\n    phraseQuery.add(new Term(\"fieldname\", \"be\"));\n    assertEquals(1, isearcher.search(phraseQuery, null, 1).totalHits);\n\n    isearcher.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testDemo() throws IOException, ParseException {\n    Analyzer analyzer = new MockAnalyzer(random);\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory, analyzer);\n    iwriter.w.setInfoStream(VERBOSE ? System.out : null);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    query = parser.parse(\"\\\"to be\\\"\");\n    assertEquals(1, isearcher.search(query, null, 1).totalHits);\n\n    isearcher.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"817d8435e9135b756f08ce6710ab0baac51bdf88","date":1309986993,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","pathOld":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","sourceNew":"  public void testDemo() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random);\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory, analyzer);\n    iwriter.w.setInfoStream(VERBOSE ? System.out : null);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    PhraseQuery phraseQuery = new PhraseQuery();\n    phraseQuery.add(new Term(\"fieldname\", \"to\"));\n    phraseQuery.add(new Term(\"fieldname\", \"be\"));\n    assertEquals(1, isearcher.search(phraseQuery, null, 1).totalHits);\n\n    isearcher.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testDemo() throws IOException, ParseException {\n    Analyzer analyzer = new MockAnalyzer(random);\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory, analyzer);\n    iwriter.w.setInfoStream(VERBOSE ? System.out : null);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    query = parser.parse(\"\\\"to be\\\"\");\n    assertEquals(1, isearcher.search(query, null, 1).totalHits);\n\n    isearcher.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","pathOld":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","sourceNew":"  public void testDemo() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random);\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory, analyzer);\n    iwriter.w.setInfoStream(VERBOSE ? System.out : null);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    PhraseQuery phraseQuery = new PhraseQuery();\n    phraseQuery.add(new Term(\"fieldname\", \"to\"));\n    phraseQuery.add(new Term(\"fieldname\", \"be\"));\n    assertEquals(1, isearcher.search(phraseQuery, null, 1).totalHits);\n\n    isearcher.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testDemo() throws IOException, ParseException {\n    Analyzer analyzer = new MockAnalyzer(random);\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory, analyzer);\n    iwriter.w.setInfoStream(VERBOSE ? System.out : null);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    // Parse a simple query that searches for \"text\":\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, \"fieldname\", analyzer);\n    Query query = parser.parse(\"text\");\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    query = parser.parse(\"\\\"to be\\\"\");\n    assertEquals(1, isearcher.search(query, null, 1).totalHits);\n\n    isearcher.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","pathOld":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","sourceNew":"  public void testDemo() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random);\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory, analyzer);\n    iwriter.w.setInfoStream(VERBOSE ? System.out : null);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, TextField.TYPE_STORED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    PhraseQuery phraseQuery = new PhraseQuery();\n    phraseQuery.add(new Term(\"fieldname\", \"to\"));\n    phraseQuery.add(new Term(\"fieldname\", \"be\"));\n    assertEquals(1, isearcher.search(phraseQuery, null, 1).totalHits);\n\n    isearcher.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testDemo() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random);\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory, analyzer);\n    iwriter.w.setInfoStream(VERBOSE ? System.out : null);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, Field.Store.YES,\n        Field.Index.ANALYZED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    PhraseQuery phraseQuery = new PhraseQuery();\n    phraseQuery.add(new Term(\"fieldname\", \"to\"));\n    phraseQuery.add(new Term(\"fieldname\", \"be\"));\n    assertEquals(1, isearcher.search(phraseQuery, null, 1).totalHits);\n\n    isearcher.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"06584e6e98d592b34e1329b384182f368d2025e8","date":1320850353,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","pathOld":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","sourceNew":"  public void testDemo() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random);\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory, analyzer);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, TextField.TYPE_STORED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    PhraseQuery phraseQuery = new PhraseQuery();\n    phraseQuery.add(new Term(\"fieldname\", \"to\"));\n    phraseQuery.add(new Term(\"fieldname\", \"be\"));\n    assertEquals(1, isearcher.search(phraseQuery, null, 1).totalHits);\n\n    isearcher.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testDemo() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random);\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory, analyzer);\n    iwriter.w.setInfoStream(VERBOSE ? System.out : null);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, TextField.TYPE_STORED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    PhraseQuery phraseQuery = new PhraseQuery();\n    phraseQuery.add(new Term(\"fieldname\", \"to\"));\n    phraseQuery.add(new Term(\"fieldname\", \"be\"));\n    assertEquals(1, isearcher.search(phraseQuery, null, 1).totalHits);\n\n    isearcher.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a3a0403b45dfe384fae4a1b6e96c3265d000c498","date":1321445981,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","pathOld":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","sourceNew":"  public void testDemo() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random);\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory, analyzer);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, TextField.TYPE_STORED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = IndexReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    PhraseQuery phraseQuery = new PhraseQuery();\n    phraseQuery.add(new Term(\"fieldname\", \"to\"));\n    phraseQuery.add(new Term(\"fieldname\", \"be\"));\n    assertEquals(1, isearcher.search(phraseQuery, null, 1).totalHits);\n\n    isearcher.close();\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testDemo() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random);\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory, analyzer);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, TextField.TYPE_STORED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexSearcher isearcher = new IndexSearcher(directory, true); // read-only=true\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    PhraseQuery phraseQuery = new PhraseQuery();\n    phraseQuery.add(new Term(\"fieldname\", \"to\"));\n    phraseQuery.add(new Term(\"fieldname\", \"be\"));\n    assertEquals(1, isearcher.search(phraseQuery, null, 1).totalHits);\n\n    isearcher.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0e7c2454a6a8237bfd0e953f5b940838408c9055","date":1323649300,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","pathOld":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","sourceNew":"  public void testDemo() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random);\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory, analyzer);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, TextField.TYPE_STORED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = IndexReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    PhraseQuery phraseQuery = new PhraseQuery();\n    phraseQuery.add(new Term(\"fieldname\", \"to\"));\n    phraseQuery.add(new Term(\"fieldname\", \"be\"));\n    assertEquals(1, isearcher.search(phraseQuery, null, 1).totalHits);\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testDemo() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random);\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory, analyzer);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, TextField.TYPE_STORED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = IndexReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    PhraseQuery phraseQuery = new PhraseQuery();\n    phraseQuery.add(new Term(\"fieldname\", \"to\"));\n    phraseQuery.add(new Term(\"fieldname\", \"be\"));\n    assertEquals(1, isearcher.search(phraseQuery, null, 1).totalHits);\n\n    isearcher.close();\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","date":1323720782,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","pathOld":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","sourceNew":"  public void testDemo() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random);\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory, analyzer);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, TextField.TYPE_STORED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = IndexReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    PhraseQuery phraseQuery = new PhraseQuery();\n    phraseQuery.add(new Term(\"fieldname\", \"to\"));\n    phraseQuery.add(new Term(\"fieldname\", \"be\"));\n    assertEquals(1, isearcher.search(phraseQuery, null, 1).totalHits);\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testDemo() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random);\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory, analyzer);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, TextField.TYPE_STORED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = IndexReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    PhraseQuery phraseQuery = new PhraseQuery();\n    phraseQuery.add(new Term(\"fieldname\", \"to\"));\n    phraseQuery.add(new Term(\"fieldname\", \"be\"));\n    assertEquals(1, isearcher.search(phraseQuery, null, 1).totalHits);\n\n    isearcher.close();\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/TestDemo#testDemo().mjava","pathOld":"lucene/src/test/org/apache/lucene/TestDemo#testDemo().mjava","sourceNew":"  public void testDemo() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random);\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory, analyzer);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, TextField.TYPE_STORED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = IndexReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    PhraseQuery phraseQuery = new PhraseQuery();\n    phraseQuery.add(new Term(\"fieldname\", \"to\"));\n    phraseQuery.add(new Term(\"fieldname\", \"be\"));\n    assertEquals(1, isearcher.search(phraseQuery, null, 1).totalHits);\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testDemo() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random);\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n    RandomIndexWriter iwriter = new RandomIndexWriter(random, directory, analyzer);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newField(\"fieldname\", text, TextField.TYPE_STORED));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = IndexReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n    }\n\n    // Test simple phrase query\n    PhraseQuery phraseQuery = new PhraseQuery();\n    phraseQuery.add(new Term(\"fieldname\", \"to\"));\n    phraseQuery.add(new Term(\"fieldname\", \"be\"));\n    assertEquals(1, isearcher.search(phraseQuery, null, 1).totalHits);\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"44fcbde6fb2ac44ee3b45e013e54a42911e689ff":["75119b664a58052b6c17ae2d4b57250fbe1e8a7d"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["0e7c2454a6a8237bfd0e953f5b940838408c9055"],"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c":["a3a0403b45dfe384fae4a1b6e96c3265d000c498","0e7c2454a6a8237bfd0e953f5b940838408c9055"],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"132903c28af3aa6f67284b78de91c0f0a99488c2":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["d572389229127c297dd1fa5ce4758e1cec41e799","44fcbde6fb2ac44ee3b45e013e54a42911e689ff"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["44fcbde6fb2ac44ee3b45e013e54a42911e689ff"],"0e7c2454a6a8237bfd0e953f5b940838408c9055":["a3a0403b45dfe384fae4a1b6e96c3265d000c498"],"0c839e28bbf8e26233e9cb58aa45188ae669f2be":["8d47f68d60cbff5718136b945ba8c55982342f38"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["a05409176bd65129d67a785ee70e881e238a9aef"],"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c":["d572389229127c297dd1fa5ce4758e1cec41e799"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a05409176bd65129d67a785ee70e881e238a9aef":["1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c"],"a3a0403b45dfe384fae4a1b6e96c3265d000c498":["06584e6e98d592b34e1329b384182f368d2025e8"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["112629f1dfd1451722c6047bcf593e6efc96f5f4"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"75119b664a58052b6c17ae2d4b57250fbe1e8a7d":["0c839e28bbf8e26233e9cb58aa45188ae669f2be"],"06584e6e98d592b34e1329b384182f368d2025e8":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["ab5cb6a74aefb78aa0569857970b9151dfe2e787","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"d572389229127c297dd1fa5ce4758e1cec41e799":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["4ecea1664e8617d82eca3b8055a3c37cb4da8511","44fcbde6fb2ac44ee3b45e013e54a42911e689ff"],"962d04139994fce5193143ef35615499a9a96d78":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"8d47f68d60cbff5718136b945ba8c55982342f38":["132903c28af3aa6f67284b78de91c0f0a99488c2"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["f2c5f0cb44df114db4228c8f77861714b5cabaea","112629f1dfd1451722c6047bcf593e6efc96f5f4"],"817d8435e9135b756f08ce6710ab0baac51bdf88":["a3776dccca01c11e7046323cfad46a3b4a471233","112629f1dfd1451722c6047bcf593e6efc96f5f4"],"a3776dccca01c11e7046323cfad46a3b4a471233":["44fcbde6fb2ac44ee3b45e013e54a42911e689ff","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"112629f1dfd1451722c6047bcf593e6efc96f5f4":["f2c5f0cb44df114db4228c8f77861714b5cabaea"],"4ecea1664e8617d82eca3b8055a3c37cb4da8511":["8d47f68d60cbff5718136b945ba8c55982342f38","75119b664a58052b6c17ae2d4b57250fbe1e8a7d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"44fcbde6fb2ac44ee3b45e013e54a42911e689ff":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","f2c5f0cb44df114db4228c8f77861714b5cabaea","ab5cb6a74aefb78aa0569857970b9151dfe2e787","a3776dccca01c11e7046323cfad46a3b4a471233"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c":[],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["d572389229127c297dd1fa5ce4758e1cec41e799"],"132903c28af3aa6f67284b78de91c0f0a99488c2":["8d47f68d60cbff5718136b945ba8c55982342f38"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["962d04139994fce5193143ef35615499a9a96d78"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","d083e83f225b11e5fdd900e83d26ddb385b6955c","a3776dccca01c11e7046323cfad46a3b4a471233","112629f1dfd1451722c6047bcf593e6efc96f5f4"],"0e7c2454a6a8237bfd0e953f5b940838408c9055":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","93ccd971aca7fb61b7f1b946e44714cfc80bfc7c"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["132903c28af3aa6f67284b78de91c0f0a99488c2"],"0c839e28bbf8e26233e9cb58aa45188ae669f2be":["75119b664a58052b6c17ae2d4b57250fbe1e8a7d"],"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c":["a05409176bd65129d67a785ee70e881e238a9aef"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a05409176bd65129d67a785ee70e881e238a9aef":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"a3a0403b45dfe384fae4a1b6e96c3265d000c498":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","0e7c2454a6a8237bfd0e953f5b940838408c9055"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["06584e6e98d592b34e1329b384182f368d2025e8"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"75119b664a58052b6c17ae2d4b57250fbe1e8a7d":["44fcbde6fb2ac44ee3b45e013e54a42911e689ff","4ecea1664e8617d82eca3b8055a3c37cb4da8511"],"06584e6e98d592b34e1329b384182f368d2025e8":["a3a0403b45dfe384fae4a1b6e96c3265d000c498"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":[],"d572389229127c297dd1fa5ce4758e1cec41e799":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"962d04139994fce5193143ef35615499a9a96d78":[],"8d47f68d60cbff5718136b945ba8c55982342f38":["0c839e28bbf8e26233e9cb58aa45188ae669f2be","4ecea1664e8617d82eca3b8055a3c37cb4da8511"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"817d8435e9135b756f08ce6710ab0baac51bdf88":[],"a3776dccca01c11e7046323cfad46a3b4a471233":["817d8435e9135b756f08ce6710ab0baac51bdf88"],"112629f1dfd1451722c6047bcf593e6efc96f5f4":["1509f151d7692d84fae414b2b799ac06ba60fcb4","d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88"],"4ecea1664e8617d82eca3b8055a3c37cb4da8511":["ab5cb6a74aefb78aa0569857970b9151dfe2e787"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}