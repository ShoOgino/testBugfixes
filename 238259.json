{"path":"contrib/queries/src/java/org/apache/lucene/search/similar/MoreLikeThis#createQueue(Map).mjava","commits":[{"id":"d3c3c2404d1200c39220fa15054fae854db4e1ee","date":1140827958,"type":0,"author":"Mark Harwood","isMerge":false,"pathNew":"contrib/queries/src/java/org/apache/lucene/search/similar/MoreLikeThis#createQueue(Map).mjava","pathOld":"/dev/null","sourceNew":"    /**\r\n     * Create a PriorityQueue from a word->tf map.\r\n     *\r\n     * @param words a map of words keyed on the word(String) with Int objects as the values.\r\n     */\r\n    private PriorityQueue createQueue(Map words) throws IOException {\r\n        // have collected all words in doc and their freqs\r\n        int numDocs = ir.numDocs();\r\n        FreqQ res = new FreqQ(words.size()); // will order words by score\r\n\r\n        Iterator it = words.keySet().iterator();\r\n        while (it.hasNext()) { // for every word\r\n            String word = (String) it.next();\r\n\r\n            int tf = ((Int) words.get(word)).x; // term freq in the source doc\r\n            if (minTermFreq > 0 && tf < minTermFreq) {\r\n                continue; // filter out words that don't occur enough times in the source\r\n            }\r\n\r\n            // go through all the fields and find the largest document frequency\r\n            String topField = fieldNames[0];\r\n            int docFreq = 0;\r\n            for (int i = 0; i < fieldNames.length; i++) {\r\n                int freq = ir.docFreq(new Term(fieldNames[i], word));\r\n                topField = (freq > docFreq) ? fieldNames[i] : topField;\r\n                docFreq = (freq > docFreq) ? freq : docFreq;\r\n            }\r\n\r\n            if (minDocFreq > 0 && docFreq < minDocFreq) {\r\n                continue; // filter out words that don't occur in enough docs\r\n            }\r\n\r\n            if (docFreq == 0) {\r\n                continue; // index update problem?\r\n            }\r\n\r\n            float idf = similarity.idf(docFreq, numDocs);\r\n            float score = tf * idf;\r\n\r\n            // only really need 1st 3 entries, other ones are for troubleshooting\r\n            res.insert(new Object[]{word,                   // the word\r\n                                    topField,               // the top field\r\n                                    new Float(score),       // overall score\r\n                                    new Float(idf),         // idf\r\n                                    new Integer(docFreq),   // freq in all docs\r\n                                    new Integer(tf)\r\n            });\r\n        }\r\n        return res;\r\n    }\r\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6a361a621b184d9b73c9c9a37323a9845b8f8260","date":1226370946,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"contrib/queries/src/java/org/apache/lucene/search/similar/MoreLikeThis#createQueue(Map).mjava","pathOld":"contrib/queries/src/java/org/apache/lucene/search/similar/MoreLikeThis#createQueue(Map).mjava","sourceNew":"    /**\n     * Create a PriorityQueue from a word->tf map.\n     *\n     * @param words a map of words keyed on the word(String) with Int objects as the values.\n     */\n    private PriorityQueue createQueue(Map words) throws IOException {\n        // have collected all words in doc and their freqs\n        int numDocs = ir.numDocs();\n        FreqQ res = new FreqQ(words.size()); // will order words by score\n\n        Iterator it = words.keySet().iterator();\n        while (it.hasNext()) { // for every word\n            String word = (String) it.next();\n\n            int tf = ((Int) words.get(word)).x; // term freq in the source doc\n            if (minTermFreq > 0 && tf < minTermFreq) {\n                continue; // filter out words that don't occur enough times in the source\n            }\n\n            // go through all the fields and find the largest document frequency\n            String topField = fieldNames[0];\n            int docFreq = 0;\n            for (int i = 0; i < fieldNames.length; i++) {\n                int freq = ir.docFreq(new Term(fieldNames[i], word));\n                topField = (freq > docFreq) ? fieldNames[i] : topField;\n                docFreq = (freq > docFreq) ? freq : docFreq;\n            }\n\n            if (minDocFreq > 0 && docFreq < minDocFreq) {\n                continue; // filter out words that don't occur in enough docs\n            }\n\n            if (docFreq == 0) {\n                continue; // index update problem?\n            }\n\n            float idf = similarity.idf(docFreq, numDocs);\n            float score = tf * idf;\n\n            // only really need 1st 3 entries, other ones are for troubleshooting\n            res.insert(new Object[]{word,                   // the word\n                                    topField,               // the top field\n                                    new Float(score),       // overall score\n                                    new Float(idf),         // idf\n                                    new Integer(docFreq),   // freq in all docs\n                                    new Integer(tf)\n            });\n        }\n        return res;\n    }\n\n","sourceOld":"    /**\r\n     * Create a PriorityQueue from a word->tf map.\r\n     *\r\n     * @param words a map of words keyed on the word(String) with Int objects as the values.\r\n     */\r\n    private PriorityQueue createQueue(Map words) throws IOException {\r\n        // have collected all words in doc and their freqs\r\n        int numDocs = ir.numDocs();\r\n        FreqQ res = new FreqQ(words.size()); // will order words by score\r\n\r\n        Iterator it = words.keySet().iterator();\r\n        while (it.hasNext()) { // for every word\r\n            String word = (String) it.next();\r\n\r\n            int tf = ((Int) words.get(word)).x; // term freq in the source doc\r\n            if (minTermFreq > 0 && tf < minTermFreq) {\r\n                continue; // filter out words that don't occur enough times in the source\r\n            }\r\n\r\n            // go through all the fields and find the largest document frequency\r\n            String topField = fieldNames[0];\r\n            int docFreq = 0;\r\n            for (int i = 0; i < fieldNames.length; i++) {\r\n                int freq = ir.docFreq(new Term(fieldNames[i], word));\r\n                topField = (freq > docFreq) ? fieldNames[i] : topField;\r\n                docFreq = (freq > docFreq) ? freq : docFreq;\r\n            }\r\n\r\n            if (minDocFreq > 0 && docFreq < minDocFreq) {\r\n                continue; // filter out words that don't occur in enough docs\r\n            }\r\n\r\n            if (docFreq == 0) {\r\n                continue; // index update problem?\r\n            }\r\n\r\n            float idf = similarity.idf(docFreq, numDocs);\r\n            float score = tf * idf;\r\n\r\n            // only really need 1st 3 entries, other ones are for troubleshooting\r\n            res.insert(new Object[]{word,                   // the word\r\n                                    topField,               // the top field\r\n                                    new Float(score),       // overall score\r\n                                    new Float(idf),         // idf\r\n                                    new Integer(docFreq),   // freq in all docs\r\n                                    new Integer(tf)\r\n            });\r\n        }\r\n        return res;\r\n    }\r\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6bcde5e3f23911110baa101ed062b544162825b5","date":1254521804,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/queries/src/java/org/apache/lucene/search/similar/MoreLikeThis#createQueue(Map).mjava","pathOld":"contrib/queries/src/java/org/apache/lucene/search/similar/MoreLikeThis#createQueue(Map).mjava","sourceNew":"    /**\n     * Create a PriorityQueue from a word->tf map.\n     *\n     * @param words a map of words keyed on the word(String) with Int objects as the values.\n     */\n    private PriorityQueue createQueue(Map words) throws IOException {\n        // have collected all words in doc and their freqs\n        int numDocs = ir.numDocs();\n        FreqQ res = new FreqQ(words.size()); // will order words by score\n\n        Iterator it = words.keySet().iterator();\n        while (it.hasNext()) { // for every word\n            String word = (String) it.next();\n\n            int tf = ((Int) words.get(word)).x; // term freq in the source doc\n            if (minTermFreq > 0 && tf < minTermFreq) {\n                continue; // filter out words that don't occur enough times in the source\n            }\n\n            // go through all the fields and find the largest document frequency\n            String topField = fieldNames[0];\n            int docFreq = 0;\n            for (int i = 0; i < fieldNames.length; i++) {\n                int freq = ir.docFreq(new Term(fieldNames[i], word));\n                topField = (freq > docFreq) ? fieldNames[i] : topField;\n                docFreq = (freq > docFreq) ? freq : docFreq;\n            }\n\n            if (minDocFreq > 0 && docFreq < minDocFreq) {\n                continue; // filter out words that don't occur in enough docs\n            }\n\n            if (docFreq == 0) {\n                continue; // index update problem?\n            }\n\n            float idf = similarity.idf(docFreq, numDocs);\n            float score = tf * idf;\n\n            // only really need 1st 3 entries, other ones are for troubleshooting\n            res.insert(new Object[]{word,                   // the word\n                                    topField,               // the top field\n                                    Float.valueOf(score),       // overall score\n                                    Float.valueOf(idf),         // idf\n                                    Integer.valueOf(docFreq),   // freq in all docs\n                                    Integer.valueOf(tf)\n            });\n        }\n        return res;\n    }\n\n","sourceOld":"    /**\n     * Create a PriorityQueue from a word->tf map.\n     *\n     * @param words a map of words keyed on the word(String) with Int objects as the values.\n     */\n    private PriorityQueue createQueue(Map words) throws IOException {\n        // have collected all words in doc and their freqs\n        int numDocs = ir.numDocs();\n        FreqQ res = new FreqQ(words.size()); // will order words by score\n\n        Iterator it = words.keySet().iterator();\n        while (it.hasNext()) { // for every word\n            String word = (String) it.next();\n\n            int tf = ((Int) words.get(word)).x; // term freq in the source doc\n            if (minTermFreq > 0 && tf < minTermFreq) {\n                continue; // filter out words that don't occur enough times in the source\n            }\n\n            // go through all the fields and find the largest document frequency\n            String topField = fieldNames[0];\n            int docFreq = 0;\n            for (int i = 0; i < fieldNames.length; i++) {\n                int freq = ir.docFreq(new Term(fieldNames[i], word));\n                topField = (freq > docFreq) ? fieldNames[i] : topField;\n                docFreq = (freq > docFreq) ? freq : docFreq;\n            }\n\n            if (minDocFreq > 0 && docFreq < minDocFreq) {\n                continue; // filter out words that don't occur in enough docs\n            }\n\n            if (docFreq == 0) {\n                continue; // index update problem?\n            }\n\n            float idf = similarity.idf(docFreq, numDocs);\n            float score = tf * idf;\n\n            // only really need 1st 3 entries, other ones are for troubleshooting\n            res.insert(new Object[]{word,                   // the word\n                                    topField,               // the top field\n                                    new Float(score),       // overall score\n                                    new Float(idf),         // idf\n                                    new Integer(docFreq),   // freq in all docs\n                                    new Integer(tf)\n            });\n        }\n        return res;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0731e137bcbb58121034de6ddaa67332fbe6e5d1","date":1255233265,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"contrib/queries/src/java/org/apache/lucene/search/similar/MoreLikeThis#createQueue(Map).mjava","pathOld":"contrib/queries/src/java/org/apache/lucene/search/similar/MoreLikeThis#createQueue(Map).mjava","sourceNew":"    /**\n     * Create a PriorityQueue from a word->tf map.\n     *\n     * @param words a map of words keyed on the word(String) with Int objects as the values.\n     */\n    private PriorityQueue createQueue(Map words) throws IOException {\n        // have collected all words in doc and their freqs\n        int numDocs = ir.numDocs();\n        FreqQ res = new FreqQ(words.size()); // will order words by score\n\n        Iterator it = words.keySet().iterator();\n        while (it.hasNext()) { // for every word\n            String word = (String) it.next();\n\n            int tf = ((Int) words.get(word)).x; // term freq in the source doc\n            if (minTermFreq > 0 && tf < minTermFreq) {\n                continue; // filter out words that don't occur enough times in the source\n            }\n\n            // go through all the fields and find the largest document frequency\n            String topField = fieldNames[0];\n            int docFreq = 0;\n            for (int i = 0; i < fieldNames.length; i++) {\n                int freq = ir.docFreq(new Term(fieldNames[i], word));\n                topField = (freq > docFreq) ? fieldNames[i] : topField;\n                docFreq = (freq > docFreq) ? freq : docFreq;\n            }\n\n            if (minDocFreq > 0 && docFreq < minDocFreq) {\n                continue; // filter out words that don't occur in enough docs\n            }\n\n            if (docFreq == 0) {\n                continue; // index update problem?\n            }\n\n            float idf = similarity.idf(docFreq, numDocs);\n            float score = tf * idf;\n\n            // only really need 1st 3 entries, other ones are for troubleshooting\n            res.insertWithOverflow(new Object[]{word,                   // the word\n                                    topField,               // the top field\n                                    Float.valueOf(score),       // overall score\n                                    Float.valueOf(idf),         // idf\n                                    Integer.valueOf(docFreq),   // freq in all docs\n                                    Integer.valueOf(tf)\n            });\n        }\n        return res;\n    }\n\n","sourceOld":"    /**\n     * Create a PriorityQueue from a word->tf map.\n     *\n     * @param words a map of words keyed on the word(String) with Int objects as the values.\n     */\n    private PriorityQueue createQueue(Map words) throws IOException {\n        // have collected all words in doc and their freqs\n        int numDocs = ir.numDocs();\n        FreqQ res = new FreqQ(words.size()); // will order words by score\n\n        Iterator it = words.keySet().iterator();\n        while (it.hasNext()) { // for every word\n            String word = (String) it.next();\n\n            int tf = ((Int) words.get(word)).x; // term freq in the source doc\n            if (minTermFreq > 0 && tf < minTermFreq) {\n                continue; // filter out words that don't occur enough times in the source\n            }\n\n            // go through all the fields and find the largest document frequency\n            String topField = fieldNames[0];\n            int docFreq = 0;\n            for (int i = 0; i < fieldNames.length; i++) {\n                int freq = ir.docFreq(new Term(fieldNames[i], word));\n                topField = (freq > docFreq) ? fieldNames[i] : topField;\n                docFreq = (freq > docFreq) ? freq : docFreq;\n            }\n\n            if (minDocFreq > 0 && docFreq < minDocFreq) {\n                continue; // filter out words that don't occur in enough docs\n            }\n\n            if (docFreq == 0) {\n                continue; // index update problem?\n            }\n\n            float idf = similarity.idf(docFreq, numDocs);\n            float score = tf * idf;\n\n            // only really need 1st 3 entries, other ones are for troubleshooting\n            res.insert(new Object[]{word,                   // the word\n                                    topField,               // the top field\n                                    Float.valueOf(score),       // overall score\n                                    Float.valueOf(idf),         // idf\n                                    Integer.valueOf(docFreq),   // freq in all docs\n                                    Integer.valueOf(tf)\n            });\n        }\n        return res;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db6335e86be96a1cf83ab9ad11be468d79868d2b","date":1256039993,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/queries/src/java/org/apache/lucene/search/similar/MoreLikeThis#createQueue(Map).mjava","pathOld":"contrib/queries/src/java/org/apache/lucene/search/similar/MoreLikeThis#createQueue(Map).mjava","sourceNew":"    /**\n     * Create a PriorityQueue from a word->tf map.\n     *\n     * @param words a map of words keyed on the word(String) with Int objects as the values.\n     */\n    private PriorityQueue createQueue(Map words) throws IOException {\n        // have collected all words in doc and their freqs\n        int numDocs = ir.numDocs();\n        FreqQ res = new FreqQ(words.size()); // will order words by score\n\n        Iterator it = words.keySet().iterator();\n        while (it.hasNext()) { // for every word\n            String word = (String) it.next();\n\n            int tf = ((Int) words.get(word)).x; // term freq in the source doc\n            if (minTermFreq > 0 && tf < minTermFreq) {\n                continue; // filter out words that don't occur enough times in the source\n            }\n\n            // go through all the fields and find the largest document frequency\n            String topField = fieldNames[0];\n            int docFreq = 0;\n            for (int i = 0; i < fieldNames.length; i++) {\n                int freq = ir.docFreq(new Term(fieldNames[i], word));\n                topField = (freq > docFreq) ? fieldNames[i] : topField;\n                docFreq = (freq > docFreq) ? freq : docFreq;\n            }\n\n            if (minDocFreq > 0 && docFreq < minDocFreq) {\n                continue; // filter out words that don't occur in enough docs\n            }\n\n            if (docFreq > maxDocFreq) {\n                continue; // filter out words that occur in too many docs            \t\n            }\n\n            if (docFreq == 0) {\n                continue; // index update problem?\n            }\n\n            float idf = similarity.idf(docFreq, numDocs);\n            float score = tf * idf;\n\n            // only really need 1st 3 entries, other ones are for troubleshooting\n            res.insertWithOverflow(new Object[]{word,                   // the word\n                                    topField,               // the top field\n                                    Float.valueOf(score),       // overall score\n                                    Float.valueOf(idf),         // idf\n                                    Integer.valueOf(docFreq),   // freq in all docs\n                                    Integer.valueOf(tf)\n            });\n        }\n        return res;\n    }\n\n","sourceOld":"    /**\n     * Create a PriorityQueue from a word->tf map.\n     *\n     * @param words a map of words keyed on the word(String) with Int objects as the values.\n     */\n    private PriorityQueue createQueue(Map words) throws IOException {\n        // have collected all words in doc and their freqs\n        int numDocs = ir.numDocs();\n        FreqQ res = new FreqQ(words.size()); // will order words by score\n\n        Iterator it = words.keySet().iterator();\n        while (it.hasNext()) { // for every word\n            String word = (String) it.next();\n\n            int tf = ((Int) words.get(word)).x; // term freq in the source doc\n            if (minTermFreq > 0 && tf < minTermFreq) {\n                continue; // filter out words that don't occur enough times in the source\n            }\n\n            // go through all the fields and find the largest document frequency\n            String topField = fieldNames[0];\n            int docFreq = 0;\n            for (int i = 0; i < fieldNames.length; i++) {\n                int freq = ir.docFreq(new Term(fieldNames[i], word));\n                topField = (freq > docFreq) ? fieldNames[i] : topField;\n                docFreq = (freq > docFreq) ? freq : docFreq;\n            }\n\n            if (minDocFreq > 0 && docFreq < minDocFreq) {\n                continue; // filter out words that don't occur in enough docs\n            }\n\n            if (docFreq == 0) {\n                continue; // index update problem?\n            }\n\n            float idf = similarity.idf(docFreq, numDocs);\n            float score = tf * idf;\n\n            // only really need 1st 3 entries, other ones are for troubleshooting\n            res.insertWithOverflow(new Object[]{word,                   // the word\n                                    topField,               // the top field\n                                    Float.valueOf(score),       // overall score\n                                    Float.valueOf(idf),         // idf\n                                    Integer.valueOf(docFreq),   // freq in all docs\n                                    Integer.valueOf(tf)\n            });\n        }\n        return res;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"60cdc0e643184821eb066795a8791cd82559f46e","date":1257941914,"type":5,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/queries/src/java/org/apache/lucene/search/similar/MoreLikeThis#createQueue(Map[String,Int]).mjava","pathOld":"contrib/queries/src/java/org/apache/lucene/search/similar/MoreLikeThis#createQueue(Map).mjava","sourceNew":"    /**\n     * Create a PriorityQueue from a word->tf map.\n     *\n     * @param words a map of words keyed on the word(String) with Int objects as the values.\n     */\n    private PriorityQueue<Object[]> createQueue(Map<String,Int> words) throws IOException {\n        // have collected all words in doc and their freqs\n        int numDocs = ir.numDocs();\n        FreqQ res = new FreqQ(words.size()); // will order words by score\n\n        Iterator<String> it = words.keySet().iterator();\n        while (it.hasNext()) { // for every word\n            String word = it.next();\n\n            int tf = words.get(word).x; // term freq in the source doc\n            if (minTermFreq > 0 && tf < minTermFreq) {\n                continue; // filter out words that don't occur enough times in the source\n            }\n\n            // go through all the fields and find the largest document frequency\n            String topField = fieldNames[0];\n            int docFreq = 0;\n            for (int i = 0; i < fieldNames.length; i++) {\n                int freq = ir.docFreq(new Term(fieldNames[i], word));\n                topField = (freq > docFreq) ? fieldNames[i] : topField;\n                docFreq = (freq > docFreq) ? freq : docFreq;\n            }\n\n            if (minDocFreq > 0 && docFreq < minDocFreq) {\n                continue; // filter out words that don't occur in enough docs\n            }\n\n            if (docFreq > maxDocFreq) {\n                continue; // filter out words that occur in too many docs            \t\n            }\n\n            if (docFreq == 0) {\n                continue; // index update problem?\n            }\n\n            float idf = similarity.idf(docFreq, numDocs);\n            float score = tf * idf;\n\n            // only really need 1st 3 entries, other ones are for troubleshooting\n            res.insertWithOverflow(new Object[]{word,                   // the word\n                                    topField,               // the top field\n                                    Float.valueOf(score),       // overall score\n                                    Float.valueOf(idf),         // idf\n                                    Integer.valueOf(docFreq),   // freq in all docs\n                                    Integer.valueOf(tf)\n            });\n        }\n        return res;\n    }\n\n","sourceOld":"    /**\n     * Create a PriorityQueue from a word->tf map.\n     *\n     * @param words a map of words keyed on the word(String) with Int objects as the values.\n     */\n    private PriorityQueue createQueue(Map words) throws IOException {\n        // have collected all words in doc and their freqs\n        int numDocs = ir.numDocs();\n        FreqQ res = new FreqQ(words.size()); // will order words by score\n\n        Iterator it = words.keySet().iterator();\n        while (it.hasNext()) { // for every word\n            String word = (String) it.next();\n\n            int tf = ((Int) words.get(word)).x; // term freq in the source doc\n            if (minTermFreq > 0 && tf < minTermFreq) {\n                continue; // filter out words that don't occur enough times in the source\n            }\n\n            // go through all the fields and find the largest document frequency\n            String topField = fieldNames[0];\n            int docFreq = 0;\n            for (int i = 0; i < fieldNames.length; i++) {\n                int freq = ir.docFreq(new Term(fieldNames[i], word));\n                topField = (freq > docFreq) ? fieldNames[i] : topField;\n                docFreq = (freq > docFreq) ? freq : docFreq;\n            }\n\n            if (minDocFreq > 0 && docFreq < minDocFreq) {\n                continue; // filter out words that don't occur in enough docs\n            }\n\n            if (docFreq > maxDocFreq) {\n                continue; // filter out words that occur in too many docs            \t\n            }\n\n            if (docFreq == 0) {\n                continue; // index update problem?\n            }\n\n            float idf = similarity.idf(docFreq, numDocs);\n            float score = tf * idf;\n\n            // only really need 1st 3 entries, other ones are for troubleshooting\n            res.insertWithOverflow(new Object[]{word,                   // the word\n                                    topField,               // the top field\n                                    Float.valueOf(score),       // overall score\n                                    Float.valueOf(idf),         // idf\n                                    Integer.valueOf(docFreq),   // freq in all docs\n                                    Integer.valueOf(tf)\n            });\n        }\n        return res;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"60cdc0e643184821eb066795a8791cd82559f46e":["db6335e86be96a1cf83ab9ad11be468d79868d2b"],"6bcde5e3f23911110baa101ed062b544162825b5":["6a361a621b184d9b73c9c9a37323a9845b8f8260"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0731e137bcbb58121034de6ddaa67332fbe6e5d1":["6bcde5e3f23911110baa101ed062b544162825b5"],"6a361a621b184d9b73c9c9a37323a9845b8f8260":["d3c3c2404d1200c39220fa15054fae854db4e1ee"],"d3c3c2404d1200c39220fa15054fae854db4e1ee":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"db6335e86be96a1cf83ab9ad11be468d79868d2b":["0731e137bcbb58121034de6ddaa67332fbe6e5d1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["60cdc0e643184821eb066795a8791cd82559f46e"]},"commit2Childs":{"60cdc0e643184821eb066795a8791cd82559f46e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"6bcde5e3f23911110baa101ed062b544162825b5":["0731e137bcbb58121034de6ddaa67332fbe6e5d1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d3c3c2404d1200c39220fa15054fae854db4e1ee"],"0731e137bcbb58121034de6ddaa67332fbe6e5d1":["db6335e86be96a1cf83ab9ad11be468d79868d2b"],"6a361a621b184d9b73c9c9a37323a9845b8f8260":["6bcde5e3f23911110baa101ed062b544162825b5"],"d3c3c2404d1200c39220fa15054fae854db4e1ee":["6a361a621b184d9b73c9c9a37323a9845b8f8260"],"db6335e86be96a1cf83ab9ad11be468d79868d2b":["60cdc0e643184821eb066795a8791cd82559f46e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}