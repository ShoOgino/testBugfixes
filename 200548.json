{"path":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","commits":[{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","sourceNew":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        final AtomicReaderContext[] leaves = leafContexts;\n\n        for (int i=0; i<leaves.length; i++) {\n          final AtomicReaderContext leaf = leaves[i];\n          final IndexReader reader = leaf.reader;\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = terms==null ? null : terms.docs(liveDocs, termBytes, null);\n\n          if (docsEnum != null) {\n            DocsEnum.BulkReadResult readResult = docsEnum.getBulkResult();\n            for (;;) {\n              int n = docsEnum.read();\n              if (n==0) break;\n              int[] arr = readResult.docs.ints;\n              int end = readResult.docs.offset + n;\n              for (int j=readResult.docs.offset; j<end; j++) {\n                collector.collect(arr[j]);\n              }\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        final AtomicReaderContext[] leaves = leafContexts;\n\n        for (int i=0; i<leaves.length; i++) {\n          final AtomicReaderContext leaf = leaves[i];\n          final IndexReader reader = leaf.reader;\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = terms==null ? null : terms.docs(liveDocs, termBytes, null);\n\n          if (docsEnum != null) {\n            DocsEnum.BulkReadResult readResult = docsEnum.getBulkResult();\n            for (;;) {\n              int n = docsEnum.read();\n              if (n==0) break;\n              int[] arr = readResult.docs.ints;\n              int end = readResult.docs.offset + n;\n              for (int j=readResult.docs.offset; j<end; j++) {\n                collector.collect(arr[j]);\n              }\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","sourceNew":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        final AtomicReaderContext[] leaves = leafContexts;\n\n        for (int i=0; i<leaves.length; i++) {\n          final AtomicReaderContext leaf = leaves[i];\n          final IndexReader reader = leaf.reader;\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = terms==null ? null : terms.docs(liveDocs, termBytes, null);\n\n          if (docsEnum != null) {\n            DocsEnum.BulkReadResult readResult = docsEnum.getBulkResult();\n            for (;;) {\n              int n = docsEnum.read();\n              if (n==0) break;\n              int[] arr = readResult.docs.ints;\n              int end = readResult.docs.offset + n;\n              for (int j=readResult.docs.offset; j<end; j++) {\n                collector.collect(arr[j]);\n              }\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        final AtomicReaderContext[] leaves = leafContexts;\n\n        for (int i=0; i<leaves.length; i++) {\n          final AtomicReaderContext leaf = leaves[i];\n          final IndexReader reader = leaf.reader;\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = terms==null ? null : terms.docs(liveDocs, termBytes, null);\n\n          if (docsEnum != null) {\n            DocsEnum.BulkReadResult readResult = docsEnum.getBulkResult();\n            for (;;) {\n              int n = docsEnum.read();\n              if (n==0) break;\n              int[] arr = readResult.docs.ints;\n              int end = readResult.docs.offset + n;\n              for (int j=readResult.docs.offset; j<end; j++) {\n                collector.collect(arr[j]);\n              }\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","sourceNew":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        final AtomicReaderContext[] leaves = leafContexts;\n\n        for (int i=0; i<leaves.length; i++) {\n          final AtomicReaderContext leaf = leaves[i];\n          final IndexReader reader = leaf.reader;\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = terms==null ? null : terms.docs(liveDocs, termBytes, null);\n\n          if (docsEnum != null) {\n            DocsEnum.BulkReadResult readResult = docsEnum.getBulkResult();\n            for (;;) {\n              int n = docsEnum.read();\n              if (n==0) break;\n              int[] arr = readResult.docs.ints;\n              int end = readResult.docs.offset + n;\n              for (int j=readResult.docs.offset; j<end; j++) {\n                collector.collect(arr[j]);\n              }\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        final AtomicReaderContext[] leaves = leafContexts;\n\n        for (int i=0; i<leaves.length; i++) {\n          final AtomicReaderContext leaf = leaves[i];\n          final IndexReader reader = leaf.reader;\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = terms==null ? null : terms.docs(liveDocs, termBytes, null);\n\n          if (docsEnum != null) {\n            DocsEnum.BulkReadResult readResult = docsEnum.getBulkResult();\n            for (;;) {\n              int n = docsEnum.read();\n              if (n==0) break;\n              int[] arr = readResult.docs.ints;\n              int end = readResult.docs.offset + n;\n              for (int j=readResult.docs.offset; j<end; j++) {\n                collector.collect(arr[j]);\n              }\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e2297162a22c55456e200caef2cbcb00fe381120","date":1321551342,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","sourceNew":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        final AtomicReaderContext[] leaves = leafContexts;\n\n        for (int i=0; i<leaves.length; i++) {\n          final AtomicReaderContext leaf = leaves[i];\n          final IndexReader reader = leaf.reader;\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = null;\n          if (terms != null) {\n            final TermsEnum termsEnum = terms.iterator(null);\n            if (termsEnum.seekExact(termBytes, false)) {\n              docsEnum = termsEnum.docs(MultiFields.getLiveDocs(reader), null);\n            }\n          }\n\n          if (docsEnum != null) {\n            DocsEnum.BulkReadResult readResult = docsEnum.getBulkResult();\n            for (;;) {\n              int n = docsEnum.read();\n              if (n==0) break;\n              int[] arr = readResult.docs.ints;\n              int end = readResult.docs.offset + n;\n              for (int j=readResult.docs.offset; j<end; j++) {\n                collector.collect(arr[j]);\n              }\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        final AtomicReaderContext[] leaves = leafContexts;\n\n        for (int i=0; i<leaves.length; i++) {\n          final AtomicReaderContext leaf = leaves[i];\n          final IndexReader reader = leaf.reader;\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = terms==null ? null : terms.docs(liveDocs, termBytes, null);\n\n          if (docsEnum != null) {\n            DocsEnum.BulkReadResult readResult = docsEnum.getBulkResult();\n            for (;;) {\n              int n = docsEnum.read();\n              if (n==0) break;\n              int[] arr = readResult.docs.ints;\n              int end = readResult.docs.offset + n;\n              for (int j=readResult.docs.offset; j<end; j++) {\n                collector.collect(arr[j]);\n              }\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","bugFix":null,"bugIntro":["7c236c213a9b74e1ab39bf9e289391bf6c749c17"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0445bcd8433e331f296f5502fc089b336cbac3a6","date":1322630375,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","sourceNew":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        final AtomicReaderContext[] leaves = leafContexts;\n\n        for (int i=0; i<leaves.length; i++) {\n          final AtomicReaderContext leaf = leaves[i];\n          final IndexReader reader = leaf.reader;\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = null;\n          if (terms != null) {\n            final TermsEnum termsEnum = terms.iterator(null);\n            if (termsEnum.seekExact(termBytes, false)) {\n              docsEnum = termsEnum.docs(MultiFields.getLiveDocs(reader), null);\n            }\n          }\n\n          if (docsEnum != null) {\n            int docid;\n            while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n              collector.collect(docid);\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        final AtomicReaderContext[] leaves = leafContexts;\n\n        for (int i=0; i<leaves.length; i++) {\n          final AtomicReaderContext leaf = leaves[i];\n          final IndexReader reader = leaf.reader;\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = null;\n          if (terms != null) {\n            final TermsEnum termsEnum = terms.iterator(null);\n            if (termsEnum.seekExact(termBytes, false)) {\n              docsEnum = termsEnum.docs(MultiFields.getLiveDocs(reader), null);\n            }\n          }\n\n          if (docsEnum != null) {\n            DocsEnum.BulkReadResult readResult = docsEnum.getBulkResult();\n            for (;;) {\n              int n = docsEnum.read();\n              if (n==0) break;\n              int[] arr = readResult.docs.ints;\n              int end = readResult.docs.offset + n;\n              for (int j=readResult.docs.offset; j<end; j++) {\n                collector.collect(arr[j]);\n              }\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","bugFix":null,"bugIntro":["7c236c213a9b74e1ab39bf9e289391bf6c749c17"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"872cff1d3a554e0cd64014cd97f88d3002b0f491","date":1323024658,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","sourceNew":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        final AtomicReaderContext[] leaves = leafContexts;\n\n        for (int i=0; i<leaves.length; i++) {\n          final AtomicReaderContext leaf = leaves[i];\n          final IndexReader reader = leaf.reader;\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = null;\n          if (terms != null) {\n            final TermsEnum termsEnum = terms.iterator(null);\n            if (termsEnum.seekExact(termBytes, false)) {\n              docsEnum = termsEnum.docs(MultiFields.getLiveDocs(reader), null, false);\n            }\n          }\n\n          if (docsEnum != null) {\n            int docid;\n            while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n              collector.collect(docid);\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        final AtomicReaderContext[] leaves = leafContexts;\n\n        for (int i=0; i<leaves.length; i++) {\n          final AtomicReaderContext leaf = leaves[i];\n          final IndexReader reader = leaf.reader;\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = null;\n          if (terms != null) {\n            final TermsEnum termsEnum = terms.iterator(null);\n            if (termsEnum.seekExact(termBytes, false)) {\n              docsEnum = termsEnum.docs(MultiFields.getLiveDocs(reader), null);\n            }\n          }\n\n          if (docsEnum != null) {\n            int docid;\n            while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n              collector.collect(docid);\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b65b350ca9588f9fc76ce7d6804160d06c45ff42","date":1323026297,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","sourceNew":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        final AtomicReaderContext[] leaves = leafContexts;\n\n        for (int i=0; i<leaves.length; i++) {\n          final AtomicReaderContext leaf = leaves[i];\n          final IndexReader reader = leaf.reader;\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = null;\n          if (terms != null) {\n            final TermsEnum termsEnum = terms.iterator(null);\n            if (termsEnum.seekExact(termBytes, false)) {\n              docsEnum = termsEnum.docs(MultiFields.getLiveDocs(reader), null, false);\n            }\n          }\n\n          if (docsEnum != null) {\n            int docid;\n            while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n              collector.collect(docid);\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        final AtomicReaderContext[] leaves = leafContexts;\n\n        for (int i=0; i<leaves.length; i++) {\n          final AtomicReaderContext leaf = leaves[i];\n          final IndexReader reader = leaf.reader;\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = null;\n          if (terms != null) {\n            final TermsEnum termsEnum = terms.iterator(null);\n            if (termsEnum.seekExact(termBytes, false)) {\n              docsEnum = termsEnum.docs(MultiFields.getLiveDocs(reader), null);\n            }\n          }\n\n          if (docsEnum != null) {\n            int docid;\n            while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n              collector.collect(docid);\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"96d207426bd26fa5c1014e26d21d87603aea68b7","date":1327944562,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","sourceNew":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        final AtomicReaderContext[] leaves = leafContexts;\n\n        for (int i=0; i<leaves.length; i++) {\n          final AtomicReaderContext leaf = leaves[i];\n          final AtomicReader reader = leaf.reader();\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = null;\n          if (terms != null) {\n            final TermsEnum termsEnum = terms.iterator(null);\n            if (termsEnum.seekExact(termBytes, false)) {\n              docsEnum = termsEnum.docs(liveDocs, null, false);\n            }\n          }\n\n          if (docsEnum != null) {\n            int docid;\n            while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n              collector.collect(docid);\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        final AtomicReaderContext[] leaves = leafContexts;\n\n        for (int i=0; i<leaves.length; i++) {\n          final AtomicReaderContext leaf = leaves[i];\n          final IndexReader reader = leaf.reader;\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = null;\n          if (terms != null) {\n            final TermsEnum termsEnum = terms.iterator(null);\n            if (termsEnum.seekExact(termBytes, false)) {\n              docsEnum = termsEnum.docs(MultiFields.getLiveDocs(reader), null, false);\n            }\n          }\n\n          if (docsEnum != null) {\n            int docid;\n            while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n              collector.collect(docid);\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","bugFix":null,"bugIntro":["7c236c213a9b74e1ab39bf9e289391bf6c749c17","02331260bb246364779cb6f04919ca47900d01bb"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5cab9a86bd67202d20b6adc463008c8e982b070a","date":1327966443,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","sourceNew":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        final AtomicReaderContext[] leaves = leafContexts;\n\n        for (int i=0; i<leaves.length; i++) {\n          final AtomicReaderContext leaf = leaves[i];\n          final AtomicReader reader = leaf.reader();\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = null;\n          if (terms != null) {\n            final TermsEnum termsEnum = terms.iterator(null);\n            if (termsEnum.seekExact(termBytes, false)) {\n              docsEnum = termsEnum.docs(liveDocs, null, false);\n            }\n          }\n\n          if (docsEnum != null) {\n            int docid;\n            while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n              collector.collect(docid);\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        final AtomicReaderContext[] leaves = leafContexts;\n\n        for (int i=0; i<leaves.length; i++) {\n          final AtomicReaderContext leaf = leaves[i];\n          final IndexReader reader = leaf.reader;\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = null;\n          if (terms != null) {\n            final TermsEnum termsEnum = terms.iterator(null);\n            if (termsEnum.seekExact(termBytes, false)) {\n              docsEnum = termsEnum.docs(MultiFields.getLiveDocs(reader), null, false);\n            }\n          }\n\n          if (docsEnum != null) {\n            int docid;\n            while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n              collector.collect(docid);\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d08eba3d52b63561ebf936481ce73e6b6a14aa03","date":1333879759,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","sourceNew":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        final AtomicReaderContext[] leaves = leafContexts;\n\n        for (int i=0; i<leaves.length; i++) {\n          final AtomicReaderContext leaf = leaves[i];\n          final AtomicReader reader = leaf.reader();\n          collector.setNextReader(leaf);\n          InvertedFields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = null;\n          if (terms != null) {\n            final TermsEnum termsEnum = terms.iterator(null);\n            if (termsEnum.seekExact(termBytes, false)) {\n              docsEnum = termsEnum.docs(liveDocs, null, false);\n            }\n          }\n\n          if (docsEnum != null) {\n            int docid;\n            while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n              collector.collect(docid);\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        final AtomicReaderContext[] leaves = leafContexts;\n\n        for (int i=0; i<leaves.length; i++) {\n          final AtomicReaderContext leaf = leaves[i];\n          final AtomicReader reader = leaf.reader();\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = null;\n          if (terms != null) {\n            final TermsEnum termsEnum = terms.iterator(null);\n            if (termsEnum.seekExact(termBytes, false)) {\n              docsEnum = termsEnum.docs(liveDocs, null, false);\n            }\n          }\n\n          if (docsEnum != null) {\n            int docid;\n            while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n              collector.collect(docid);\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf","date":1333892281,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","sourceNew":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        final AtomicReaderContext[] leaves = leafContexts;\n\n        for (int i=0; i<leaves.length; i++) {\n          final AtomicReaderContext leaf = leaves[i];\n          final AtomicReader reader = leaf.reader();\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = null;\n          if (terms != null) {\n            final TermsEnum termsEnum = terms.iterator(null);\n            if (termsEnum.seekExact(termBytes, false)) {\n              docsEnum = termsEnum.docs(liveDocs, null, false);\n            }\n          }\n\n          if (docsEnum != null) {\n            int docid;\n            while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n              collector.collect(docid);\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        final AtomicReaderContext[] leaves = leafContexts;\n\n        for (int i=0; i<leaves.length; i++) {\n          final AtomicReaderContext leaf = leaves[i];\n          final AtomicReader reader = leaf.reader();\n          collector.setNextReader(leaf);\n          InvertedFields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = null;\n          if (terms != null) {\n            final TermsEnum termsEnum = terms.iterator(null);\n            if (termsEnum.seekExact(termBytes, false)) {\n              docsEnum = termsEnum.docs(liveDocs, null, false);\n            }\n          }\n\n          if (docsEnum != null) {\n            int docid;\n            while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n              collector.collect(docid);\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","bugFix":null,"bugIntro":["7c236c213a9b74e1ab39bf9e289391bf6c749c17"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c","date":1340090669,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","sourceNew":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        for (final AtomicReaderContext leaf : leafContexts) {\n          final AtomicReader reader = leaf.reader();\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = null;\n          if (terms != null) {\n            final TermsEnum termsEnum = terms.iterator(null);\n            if (termsEnum.seekExact(termBytes, false)) {\n              docsEnum = termsEnum.docs(liveDocs, null, false);\n            }\n          }\n\n          if (docsEnum != null) {\n            int docid;\n            while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n              collector.collect(docid);\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        final AtomicReaderContext[] leaves = leafContexts;\n\n        for (int i=0; i<leaves.length; i++) {\n          final AtomicReaderContext leaf = leaves[i];\n          final AtomicReader reader = leaf.reader();\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = null;\n          if (terms != null) {\n            final TermsEnum termsEnum = terms.iterator(null);\n            if (termsEnum.seekExact(termBytes, false)) {\n              docsEnum = termsEnum.docs(liveDocs, null, false);\n            }\n          }\n\n          if (docsEnum != null) {\n            int docid;\n            while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n              collector.collect(docid);\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","bugFix":null,"bugIntro":["7c236c213a9b74e1ab39bf9e289391bf6c749c17"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"02331260bb246364779cb6f04919ca47900d01bb","date":1343749884,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","sourceNew":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        for (final AtomicReaderContext leaf : leafContexts) {\n          final AtomicReader reader = leaf.reader();\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = null;\n          if (terms != null) {\n            final TermsEnum termsEnum = terms.iterator(null);\n            if (termsEnum.seekExact(termBytes, false)) {\n              docsEnum = termsEnum.docs(liveDocs, null, 0);\n            }\n          }\n\n          if (docsEnum != null) {\n            int docid;\n            while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n              collector.collect(docid);\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        for (final AtomicReaderContext leaf : leafContexts) {\n          final AtomicReader reader = leaf.reader();\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = null;\n          if (terms != null) {\n            final TermsEnum termsEnum = terms.iterator(null);\n            if (termsEnum.seekExact(termBytes, false)) {\n              docsEnum = termsEnum.docs(liveDocs, null, false);\n            }\n          }\n\n          if (docsEnum != null) {\n            int docid;\n            while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n              collector.collect(docid);\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","bugFix":["96d207426bd26fa5c1014e26d21d87603aea68b7"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","date":1343768312,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","sourceNew":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        for (final AtomicReaderContext leaf : leafContexts) {\n          final AtomicReader reader = leaf.reader();\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = null;\n          if (terms != null) {\n            final TermsEnum termsEnum = terms.iterator(null);\n            if (termsEnum.seekExact(termBytes, false)) {\n              docsEnum = termsEnum.docs(liveDocs, null, 0);\n            }\n          }\n\n          if (docsEnum != null) {\n            int docid;\n            while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n              collector.collect(docid);\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        for (final AtomicReaderContext leaf : leafContexts) {\n          final AtomicReader reader = leaf.reader();\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = null;\n          if (terms != null) {\n            final TermsEnum termsEnum = terms.iterator(null);\n            if (termsEnum.seekExact(termBytes, false)) {\n              docsEnum = termsEnum.docs(liveDocs, null, false);\n            }\n          }\n\n          if (docsEnum != null) {\n            int docid;\n            while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n              collector.collect(docid);\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","sourceNew":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        for (final AtomicReaderContext leaf : leafContexts) {\n          final AtomicReader reader = leaf.reader();\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = null;\n          if (terms != null) {\n            final TermsEnum termsEnum = terms.iterator(null);\n            if (termsEnum.seekExact(termBytes, false)) {\n              docsEnum = termsEnum.docs(liveDocs, null, 0);\n            }\n          }\n\n          if (docsEnum != null) {\n            int docid;\n            while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n              collector.collect(docid);\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        for (final AtomicReaderContext leaf : leafContexts) {\n          final AtomicReader reader = leaf.reader();\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = null;\n          if (terms != null) {\n            final TermsEnum termsEnum = terms.iterator(null);\n            if (termsEnum.seekExact(termBytes, false)) {\n              docsEnum = termsEnum.docs(liveDocs, null, false);\n            }\n          }\n\n          if (docsEnum != null) {\n            int docid;\n            while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n              collector.collect(docid);\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"15250ca94ba8ab3bcdd476daf6bf3f3febb92640","date":1355200097,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","sourceNew":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        for (final AtomicReaderContext leaf : leafContexts) {\n          final AtomicReader reader = leaf.reader();\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = null;\n          if (terms != null) {\n            final TermsEnum termsEnum = terms.iterator(null);\n            if (termsEnum.seekExact(termBytes, false)) {\n              docsEnum = termsEnum.docs(liveDocs, null, DocsEnum.FLAG_NONE);\n            }\n          }\n\n          if (docsEnum != null) {\n            int docid;\n            while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n              collector.collect(docid);\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        for (final AtomicReaderContext leaf : leafContexts) {\n          final AtomicReader reader = leaf.reader();\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = null;\n          if (terms != null) {\n            final TermsEnum termsEnum = terms.iterator(null);\n            if (termsEnum.seekExact(termBytes, false)) {\n              docsEnum = termsEnum.docs(liveDocs, null, 0);\n            }\n          }\n\n          if (docsEnum != null) {\n            int docid;\n            while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n              collector.collect(docid);\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","bugFix":null,"bugIntro":["7c236c213a9b74e1ab39bf9e289391bf6c749c17"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","sourceNew":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        for (final AtomicReaderContext leaf : leafContexts) {\n          final AtomicReader reader = leaf.reader();\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = null;\n          if (terms != null) {\n            final TermsEnum termsEnum = terms.iterator(null);\n            if (termsEnum.seekExact(termBytes, false)) {\n              docsEnum = termsEnum.docs(liveDocs, null, DocsEnum.FLAG_NONE);\n            }\n          }\n\n          if (docsEnum != null) {\n            int docid;\n            while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n              collector.collect(docid);\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        for (final AtomicReaderContext leaf : leafContexts) {\n          final AtomicReader reader = leaf.reader();\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = null;\n          if (terms != null) {\n            final TermsEnum termsEnum = terms.iterator(null);\n            if (termsEnum.seekExact(termBytes, false)) {\n              docsEnum = termsEnum.docs(liveDocs, null, 0);\n            }\n          }\n\n          if (docsEnum != null) {\n            int docid;\n            while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n              collector.collect(docid);\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c236c213a9b74e1ab39bf9e289391bf6c749c17","date":1369930949,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","sourceNew":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      super.search(query,null,collector);\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n    }\n    return collector.getDocSet();\n  }\n\n","sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      if (query instanceof TermQuery) {\n        Term t = ((TermQuery)query).getTerm();\n        for (final AtomicReaderContext leaf : leafContexts) {\n          final AtomicReader reader = leaf.reader();\n          collector.setNextReader(leaf);\n          Fields fields = reader.fields();\n          Terms terms = fields.terms(t.field());\n          BytesRef termBytes = t.bytes();\n          \n          Bits liveDocs = reader.getLiveDocs();\n          DocsEnum docsEnum = null;\n          if (terms != null) {\n            final TermsEnum termsEnum = terms.iterator(null);\n            if (termsEnum.seekExact(termBytes, false)) {\n              docsEnum = termsEnum.docs(liveDocs, null, DocsEnum.FLAG_NONE);\n            }\n          }\n\n          if (docsEnum != null) {\n            int docid;\n            while ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n              collector.collect(docid);\n            }\n          }\n        }\n      } else {\n        super.search(query,null,collector);\n      }\n      return collector.getDocSet();\n\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n      return collector.getDocSet();\n    }\n  }\n\n","bugFix":["0445bcd8433e331f296f5502fc089b336cbac3a6","af88ddf3d03b8f9d83ad08cafaa7438a1206e405","323f871ffe96b871d8c534a614be60751bb023c2","d207b1adc455d5fc979601b3f01fa90ebfaa7609","e2297162a22c55456e200caef2cbcb00fe381120","4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c","24dca205cbeb46e5e9f594f1f87e4a2c9788dd81","e7bd246bb7bc35ac22edfee9157e034dfc4e65eb","15250ca94ba8ab3bcdd476daf6bf3f3febb92640","96d207426bd26fa5c1014e26d21d87603aea68b7","e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf","5d6820cd5ba42858fda6cbe6bcfd7b290fdb9418","79f0559a3f76caeab0d8a1f765d02cd1e038e332","4f29ba80b723649f5feb7e37afe1a558dd2c1304"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f001da93ec624cbfbf3655c529836b5b1ec1aa46","date":1412885266,"type":3,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","sourceNew":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    try {\n      if (filter == null) {\n        super.search(query, null, collector);\n      } else {\n        Filter luceneFilter = filter.getTopFilter();\n        super.search(query, luceneFilter, collector);\n      }\n    } catch ( ExitableDirectoryReader.ExitingReaderException e) {\n        log.warn(\"Query: \" + query + \"; \" + e.getMessage());\n    }\n    return collector.getDocSet();\n  }\n\n","sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      super.search(query,null,collector);\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n    }\n    return collector.getDocSet();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"55980207f1977bd1463465de1659b821347e2fa8","date":1413336386,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","sourceNew":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    try {\n      if (filter == null) {\n        super.search(query, null, collector);\n      } else {\n        Filter luceneFilter = filter.getTopFilter();\n        super.search(query, luceneFilter, collector);\n      }\n    } catch ( ExitableDirectoryReader.ExitingReaderException e) {\n        log.warn(\"Query: \" + query + \"; \" + e.getMessage());\n    }\n    return collector.getDocSet();\n  }\n\n","sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    if (filter==null) {\n      super.search(query,null,collector);\n    } else {\n      Filter luceneFilter = filter.getTopFilter();\n      super.search(query, luceneFilter, collector);\n    }\n    return collector.getDocSet();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc","date":1424799790,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","sourceNew":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    try {\n      if (filter == null) {\n        super.search(query, collector);\n      } else {\n        Filter luceneFilter = filter.getTopFilter();\n        super.search(new FilteredQuery(query, luceneFilter), collector);\n      }\n    } catch ( ExitableDirectoryReader.ExitingReaderException e) {\n        log.warn(\"Query: \" + query + \"; \" + e.getMessage());\n    }\n    return collector.getDocSet();\n  }\n\n","sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    try {\n      if (filter == null) {\n        super.search(query, null, collector);\n      } else {\n        Filter luceneFilter = filter.getTopFilter();\n        super.search(query, luceneFilter, collector);\n      }\n    } catch ( ExitableDirectoryReader.ExitingReaderException e) {\n        log.warn(\"Query: \" + query + \"; \" + e.getMessage());\n    }\n    return collector.getDocSet();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1db68e96dd908fcd79ef809095822736aa601d08","date":1434630596,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","sourceNew":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    try {\n      if (filter != null) {\n        Filter luceneFilter = filter.getTopFilter();\n        query = new BooleanQuery.Builder()\n            .add(query, Occur.MUST)\n            .add(luceneFilter, Occur.FILTER)\n            .build();\n      }\n      super.search(query, collector);\n    } catch ( ExitableDirectoryReader.ExitingReaderException e) {\n        log.warn(\"Query: \" + query + \"; \" + e.getMessage());\n    }\n    return collector.getDocSet();\n  }\n\n","sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    try {\n      if (filter == null) {\n        super.search(query, collector);\n      } else {\n        Filter luceneFilter = filter.getTopFilter();\n        super.search(new FilteredQuery(query, luceneFilter), collector);\n      }\n    } catch ( ExitableDirectoryReader.ExitingReaderException e) {\n        log.warn(\"Query: \" + query + \"; \" + e.getMessage());\n    }\n    return collector.getDocSet();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6727dd701b30630840235b6788bb5c728d20bbfd","date":1439421226,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocSetNC(Query,DocSet).mjava","sourceNew":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    return DocSetUtil.createDocSet(this, query, filter);\n  }\n\n","sourceOld":"  // query must be positive\n  protected DocSet getDocSetNC(Query query, DocSet filter) throws IOException {\n    DocSetCollector collector = new DocSetCollector(maxDoc()>>6, maxDoc());\n\n    try {\n      if (filter != null) {\n        Filter luceneFilter = filter.getTopFilter();\n        query = new BooleanQuery.Builder()\n            .add(query, Occur.MUST)\n            .add(luceneFilter, Occur.FILTER)\n            .build();\n      }\n      super.search(query, collector);\n    } catch ( ExitableDirectoryReader.ExitingReaderException e) {\n        log.warn(\"Query: \" + query + \"; \" + e.getMessage());\n    }\n    return collector.getDocSet();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["02331260bb246364779cb6f04919ca47900d01bb","15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"7c236c213a9b74e1ab39bf9e289391bf6c749c17":["15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"c26f00b574427b55127e869b935845554afde1fa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"96d207426bd26fa5c1014e26d21d87603aea68b7":["872cff1d3a554e0cd64014cd97f88d3002b0f491"],"1db68e96dd908fcd79ef809095822736aa601d08":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc"],"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc":["f001da93ec624cbfbf3655c529836b5b1ec1aa46"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf":["d08eba3d52b63561ebf936481ce73e6b6a14aa03"],"55980207f1977bd1463465de1659b821347e2fa8":["7c236c213a9b74e1ab39bf9e289391bf6c749c17","f001da93ec624cbfbf3655c529836b5b1ec1aa46"],"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c":["e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf"],"0445bcd8433e331f296f5502fc089b336cbac3a6":["e2297162a22c55456e200caef2cbcb00fe381120"],"e2297162a22c55456e200caef2cbcb00fe381120":["c26f00b574427b55127e869b935845554afde1fa"],"d08eba3d52b63561ebf936481ce73e6b6a14aa03":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"872cff1d3a554e0cd64014cd97f88d3002b0f491":["0445bcd8433e331f296f5502fc089b336cbac3a6"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["872cff1d3a554e0cd64014cd97f88d3002b0f491","96d207426bd26fa5c1014e26d21d87603aea68b7"],"6727dd701b30630840235b6788bb5c728d20bbfd":["1db68e96dd908fcd79ef809095822736aa601d08"],"15250ca94ba8ab3bcdd476daf6bf3f3febb92640":["02331260bb246364779cb6f04919ca47900d01bb"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"b65b350ca9588f9fc76ce7d6804160d06c45ff42":["0445bcd8433e331f296f5502fc089b336cbac3a6","872cff1d3a554e0cd64014cd97f88d3002b0f491"],"f001da93ec624cbfbf3655c529836b5b1ec1aa46":["7c236c213a9b74e1ab39bf9e289391bf6c749c17"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c","02331260bb246364779cb6f04919ca47900d01bb"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c","02331260bb246364779cb6f04919ca47900d01bb"],"a258fbb26824fd104ed795e5d9033d2d040049ee":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["6727dd701b30630840235b6788bb5c728d20bbfd"],"02331260bb246364779cb6f04919ca47900d01bb":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"]},"commit2Childs":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"7c236c213a9b74e1ab39bf9e289391bf6c749c17":["55980207f1977bd1463465de1659b821347e2fa8","f001da93ec624cbfbf3655c529836b5b1ec1aa46"],"c26f00b574427b55127e869b935845554afde1fa":["e2297162a22c55456e200caef2cbcb00fe381120"],"96d207426bd26fa5c1014e26d21d87603aea68b7":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"1db68e96dd908fcd79ef809095822736aa601d08":["6727dd701b30630840235b6788bb5c728d20bbfd"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c26f00b574427b55127e869b935845554afde1fa","c903c3d15906a3da96b8c0c2fb704491005fdbdb","a258fbb26824fd104ed795e5d9033d2d040049ee"],"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc":["1db68e96dd908fcd79ef809095822736aa601d08"],"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"55980207f1977bd1463465de1659b821347e2fa8":[],"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b","02331260bb246364779cb6f04919ca47900d01bb"],"0445bcd8433e331f296f5502fc089b336cbac3a6":["872cff1d3a554e0cd64014cd97f88d3002b0f491","b65b350ca9588f9fc76ce7d6804160d06c45ff42"],"e2297162a22c55456e200caef2cbcb00fe381120":["0445bcd8433e331f296f5502fc089b336cbac3a6"],"872cff1d3a554e0cd64014cd97f88d3002b0f491":["96d207426bd26fa5c1014e26d21d87603aea68b7","5cab9a86bd67202d20b6adc463008c8e982b070a","b65b350ca9588f9fc76ce7d6804160d06c45ff42"],"d08eba3d52b63561ebf936481ce73e6b6a14aa03":["e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["d08eba3d52b63561ebf936481ce73e6b6a14aa03"],"6727dd701b30630840235b6788bb5c728d20bbfd":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"15250ca94ba8ab3bcdd476daf6bf3f3febb92640":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","7c236c213a9b74e1ab39bf9e289391bf6c749c17"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"b65b350ca9588f9fc76ce7d6804160d06c45ff42":[],"f001da93ec624cbfbf3655c529836b5b1ec1aa46":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc","55980207f1977bd1463465de1659b821347e2fa8"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":[],"d6f074e73200c07d54f242d3880a8da5a35ff97b":[],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"02331260bb246364779cb6f04919ca47900d01bb":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","15250ca94ba8ab3bcdd476daf6bf3f3febb92640","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","55980207f1977bd1463465de1659b821347e2fa8","b65b350ca9588f9fc76ce7d6804160d06c45ff42","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b","a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}