{"path":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","commits":[{"id":"84b590669deb3d3a471cec6cb13b104b2ee94418","date":1288889547,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","pathOld":"/dev/null","sourceNew":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE)\n        System.out.println(\"TEST: pass=\" + pass);\n      boolean doAbort = pass == 1;\n      long diskFree = 200;\n      while(true) {\n        if (VERBOSE)\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler)\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            writer.rollback();\n          } else {\n            try {\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += 500;\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"85a883878c0af761245ab048babc63d099f835f3","date":1289553330,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","pathOld":"/dev/null","sourceNew":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE)\n        System.out.println(\"TEST: pass=\" + pass);\n      boolean doAbort = pass == 1;\n      long diskFree = 200;\n      while(true) {\n        if (VERBOSE)\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler)\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            writer.rollback();\n          } else {\n            try {\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += 500;\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"53a31399f2471493d67b19a95c028a74e0113b6a","date":1289817072,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","sourceNew":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE)\n        System.out.println(\"TEST: pass=\" + pass);\n      boolean doAbort = pass == 1;\n      long diskFree = 200;\n      while(true) {\n        if (VERBOSE)\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler)\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            writer.rollback();\n          } else {\n            try {\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += 500;\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE)\n        System.out.println(\"TEST: pass=\" + pass);\n      boolean doAbort = pass == 1;\n      long diskFree = 200;\n      while(true) {\n        if (VERBOSE)\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler)\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            writer.rollback();\n          } else {\n            try {\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += 500;\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9ab1f5591dc05f1f2b5407d809c9699f75554a32","date":1290008586,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","sourceNew":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE)\n        System.out.println(\"TEST: pass=\" + pass);\n      boolean doAbort = pass == 1;\n      long diskFree = 200;\n      while(true) {\n        if (VERBOSE)\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler)\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            writer.rollback();\n          } else {\n            try {\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += 500;\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE)\n        System.out.println(\"TEST: pass=\" + pass);\n      boolean doAbort = pass == 1;\n      long diskFree = 200;\n      while(true) {\n        if (VERBOSE)\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler)\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            writer.rollback();\n          } else {\n            try {\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += 500;\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6395eaae7ec8e80087f6325dce5ed5f4b095ca42","date":1290335319,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","sourceNew":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE)\n        System.out.println(\"TEST: pass=\" + pass);\n      boolean doAbort = pass == 1;\n      long diskFree = 200;\n      while(true) {\n        if (VERBOSE)\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n        writer.setInfoStream(VERBOSE ? System.out : null);\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler)\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            writer.rollback();\n          } else {\n            try {\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n            _TestUtil.checkIndex(dir);\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += 500;\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE)\n        System.out.println(\"TEST: pass=\" + pass);\n      boolean doAbort = pass == 1;\n      long diskFree = 200;\n      while(true) {\n        if (VERBOSE)\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler)\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            writer.rollback();\n          } else {\n            try {\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += 500;\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3bb13258feba31ab676502787ab2e1779f129b7a","date":1291596436,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","sourceNew":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE)\n        System.out.println(\"TEST: pass=\" + pass);\n      boolean doAbort = pass == 1;\n      long diskFree = 200;\n      while(true) {\n        if (VERBOSE)\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n        writer.setInfoStream(VERBOSE ? System.out : null);\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler)\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            writer.rollback();\n          } else {\n            try {\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n            _TestUtil.checkIndex(dir);\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += 500;\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE)\n        System.out.println(\"TEST: pass=\" + pass);\n      boolean doAbort = pass == 1;\n      long diskFree = 200;\n      while(true) {\n        if (VERBOSE)\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler)\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            writer.rollback();\n          } else {\n            try {\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += 500;\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"44fcbde6fb2ac44ee3b45e013e54a42911e689ff","date":1292065621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","sourceNew":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = 200;\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n        writer.setInfoStream(VERBOSE ? System.out : null);\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n            _TestUtil.checkIndex(dir);\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += 500;\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE)\n        System.out.println(\"TEST: pass=\" + pass);\n      boolean doAbort = pass == 1;\n      long diskFree = 200;\n      while(true) {\n        if (VERBOSE)\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n        writer.setInfoStream(VERBOSE ? System.out : null);\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler)\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            writer.rollback();\n          } else {\n            try {\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n            _TestUtil.checkIndex(dir);\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += 500;\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e1cbd7e289dc1243c7a59e1a83d078163a147fe","date":1292268032,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","sourceNew":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n        writer.setInfoStream(VERBOSE ? System.out : null);\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n            _TestUtil.checkIndex(dir);\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += _TestUtil.nextInt(random, 400, 600);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = 200;\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n        writer.setInfoStream(VERBOSE ? System.out : null);\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n            _TestUtil.checkIndex(dir);\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += 500;\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab5cb6a74aefb78aa0569857970b9151dfe2e787","date":1292842407,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","sourceNew":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n        writer.setInfoStream(VERBOSE ? System.out : null);\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n            _TestUtil.checkIndex(dir);\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += _TestUtil.nextInt(random, 400, 600);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE)\n        System.out.println(\"TEST: pass=\" + pass);\n      boolean doAbort = pass == 1;\n      long diskFree = 200;\n      while(true) {\n        if (VERBOSE)\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n        writer.setInfoStream(VERBOSE ? System.out : null);\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler)\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            writer.rollback();\n          } else {\n            try {\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n            _TestUtil.checkIndex(dir);\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += 500;\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":0,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","pathOld":"/dev/null","sourceNew":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n        writer.setInfoStream(VERBOSE ? System.out : null);\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n            _TestUtil.checkIndex(dir);\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += _TestUtil.nextInt(random, 400, 600);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ea6df125852017e3592bf98f1465500895e3af97","date":1302188728,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","sourceNew":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n        writer.setInfoStream(VERBOSE ? System.out : null);\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n            _TestUtil.checkIndex(dir);\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 400, 600) : _TestUtil.nextInt(random, 3000, 5000);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n        writer.setInfoStream(VERBOSE ? System.out : null);\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n            _TestUtil.checkIndex(dir);\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += _TestUtil.nextInt(random, 400, 600);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2c5f0cb44df114db4228c8f77861714b5cabaea","date":1302542431,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","sourceNew":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n        writer.setInfoStream(VERBOSE ? System.out : null);\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n            _TestUtil.checkIndex(dir);\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 400, 600) : _TestUtil.nextInt(random, 3000, 5000);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n        writer.setInfoStream(VERBOSE ? System.out : null);\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n            _TestUtil.checkIndex(dir);\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 400, 600) : _TestUtil.nextInt(random, 3000, 5000);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"962d04139994fce5193143ef35615499a9a96d78","date":1302693744,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","sourceNew":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n        writer.setInfoStream(VERBOSE ? System.out : null);\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n            _TestUtil.checkIndex(dir);\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 400, 600) : _TestUtil.nextInt(random, 3000, 5000);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n        writer.setInfoStream(VERBOSE ? System.out : null);\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n            _TestUtil.checkIndex(dir);\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += _TestUtil.nextInt(random, 400, 600);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","sourceNew":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n        writer.setInfoStream(VERBOSE ? System.out : null);\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n            _TestUtil.checkIndex(dir);\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 400, 600) : _TestUtil.nextInt(random, 3000, 5000);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n        writer.setInfoStream(VERBOSE ? System.out : null);\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n            _TestUtil.checkIndex(dir);\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += _TestUtil.nextInt(random, 400, 600);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","sourceNew":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n        writer.setInfoStream(VERBOSE ? System.out : null);\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n            _TestUtil.checkIndex(dir);\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 400, 600) : _TestUtil.nextInt(random, 3000, 5000);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n        writer.setInfoStream(VERBOSE ? System.out : null);\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n            _TestUtil.checkIndex(dir);\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += _TestUtil.nextInt(random, 400, 600);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ff6fd241dc6610f7f81b62e3ba4cedf105939623","date":1307331653,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","sourceNew":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n        writer.setInfoStream(VERBOSE ? System.out : null);\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 400, 600) : _TestUtil.nextInt(random, 3000, 5000);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n        writer.setInfoStream(VERBOSE ? System.out : null);\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n            _TestUtil.checkIndex(dir);\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 400, 600) : _TestUtil.nextInt(random, 3000, 5000);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"79c2cb24929f2649a8875fb629086171f914d5ce","date":1307332717,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","sourceNew":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n        writer.setInfoStream(VERBOSE ? System.out : null);\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 400, 600) : _TestUtil.nextInt(random, 3000, 5000);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n        writer.setInfoStream(VERBOSE ? System.out : null);\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n            _TestUtil.checkIndex(dir);\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 400, 600) : _TestUtil.nextInt(random, 3000, 5000);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"77cf4379b2824f6ea34b091c495d6e95c38ff9e2","date":1307610475,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","sourceNew":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n        writer.setInfoStream(VERBOSE ? System.out : null);\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 400, 600) : _TestUtil.nextInt(random, 3000, 5000);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n        writer.setInfoStream(VERBOSE ? System.out : null);\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n            _TestUtil.checkIndex(dir);\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 400, 600) : _TestUtil.nextInt(random, 3000, 5000);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"06584e6e98d592b34e1329b384182f368d2025e8","date":1320850353,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","sourceNew":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 400, 600) : _TestUtil.nextInt(random, 3000, 5000);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n        writer.setInfoStream(VERBOSE ? System.out : null);\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 400, 600) : _TestUtil.nextInt(random, 3000, 5000);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1c5b026d03cbbb03ca4c0b97d14e9839682281dc","date":1323049298,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","sourceNew":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir).close();\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 400, 600) : _TestUtil.nextInt(random, 3000, 5000);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 400, 600) : _TestUtil.nextInt(random, 3000, 5000);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3615ce4a1f785ae1b779244de52c6a7d99227e60","date":1323422019,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","sourceNew":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir).close();\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 400, 600) : _TestUtil.nextInt(random, 3000, 5000);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 400, 600) : _TestUtil.nextInt(random, 3000, 5000);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","date":1323437438,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","sourceNew":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir).close();\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 400, 600) : _TestUtil.nextInt(random, 3000, 5000);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir, true).close();\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 400, 600) : _TestUtil.nextInt(random, 3000, 5000);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7118b8e5d127b58ad37740f4fa0881259a362090","date":1327618211,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","sourceNew":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir).close();\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 400, 600) : _TestUtil.nextInt(random, 3000, 5000);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir).close();\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 400, 600) : _TestUtil.nextInt(random, 3000, 5000);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"78a55f24d9b493c2a1cecf79f1d78279062b545b","date":1327688152,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","sourceNew":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir).close();\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 400, 600) : _TestUtil.nextInt(random, 3000, 5000);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir).close();\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 400, 600) : _TestUtil.nextInt(random, 3000, 5000);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd92b8bcc88e969302510acf77bd6970da3994c4","date":1327839530,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","sourceNew":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir).close();\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 400, 600) : _TestUtil.nextInt(random, 3000, 5000);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir).close();\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 400, 600) : _TestUtil.nextInt(random, 3000, 5000);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testAddDocumentOnDiskFull().mjava","sourceNew":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir).close();\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 400, 600) : _TestUtil.nextInt(random, 3000, 5000);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /*\n   * Make sure IndexWriter cleans up on hitting a disk\n   * full exception in addDocument.\n   * TODO: how to do this on windows with FSDirectory?\n   */\n  public void testAddDocumentOnDiskFull() throws IOException {\n\n    for(int pass=0;pass<2;pass++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: pass=\" + pass);\n      }\n      boolean doAbort = pass == 1;\n      long diskFree = _TestUtil.nextInt(random, 100, 300);\n      while(true) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: cycle: diskFree=\" + diskFree);\n        }\n        MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory());\n        dir.setMaxSizeInBytes(diskFree);\n        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n        MergeScheduler ms = writer.getConfig().getMergeScheduler();\n        if (ms instanceof ConcurrentMergeScheduler) {\n          // This test intentionally produces exceptions\n          // in the threads that CMS launches; we don't\n          // want to pollute test output with these.\n          ((ConcurrentMergeScheduler) ms).setSuppressExceptions();\n        }\n\n        boolean hitError = false;\n        try {\n          for(int i=0;i<200;i++) {\n            addDoc(writer);\n          }\n          if (VERBOSE) {\n            System.out.println(\"TEST: done adding docs; now commit\");\n          }\n          writer.commit();\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"TEST: exception on addDoc\");\n            e.printStackTrace(System.out);\n          }\n          hitError = true;\n        }\n\n        if (hitError) {\n          if (doAbort) {\n            if (VERBOSE) {\n              System.out.println(\"TEST: now rollback\");\n            }\n            writer.rollback();\n          } else {\n            try {\n              if (VERBOSE) {\n                System.out.println(\"TEST: now close\");\n              }\n              writer.close();\n            } catch (IOException e) {\n              if (VERBOSE) {\n                System.out.println(\"TEST: exception on close; retry w/ no disk space limit\");\n                e.printStackTrace(System.out);\n              }\n              dir.setMaxSizeInBytes(0);\n              writer.close();\n            }\n          }\n\n          //_TestUtil.syncConcurrentMerges(ms);\n\n          if (_TestUtil.anyFilesExceptWriteLock(dir)) {\n            assertNoUnreferencedFiles(dir, \"after disk full during addDocument\");\n            \n            // Make sure reader can open the index:\n            IndexReader.open(dir).close();\n          }\n            \n          dir.close();\n          // Now try again w/ more space:\n\n          diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 400, 600) : _TestUtil.nextInt(random, 3000, 5000);\n        } else {\n          //_TestUtil.syncConcurrentMerges(writer);\n          dir.setMaxSizeInBytes(0);\n          writer.close();\n          dir.close();\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"44fcbde6fb2ac44ee3b45e013e54a42911e689ff":["6395eaae7ec8e80087f6325dce5ed5f4b095ca42"],"7118b8e5d127b58ad37740f4fa0881259a362090":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":["06584e6e98d592b34e1329b384182f368d2025e8","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["7118b8e5d127b58ad37740f4fa0881259a362090"],"fd92b8bcc88e969302510acf77bd6970da3994c4":["3615ce4a1f785ae1b779244de52c6a7d99227e60","7118b8e5d127b58ad37740f4fa0881259a362090"],"1c5b026d03cbbb03ca4c0b97d14e9839682281dc":["06584e6e98d592b34e1329b384182f368d2025e8"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","7e1cbd7e289dc1243c7a59e1a83d078163a147fe"],"6395eaae7ec8e80087f6325dce5ed5f4b095ca42":["53a31399f2471493d67b19a95c028a74e0113b6a"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["ea6df125852017e3592bf98f1465500895e3af97"],"53a31399f2471493d67b19a95c028a74e0113b6a":["84b590669deb3d3a471cec6cb13b104b2ee94418"],"84b590669deb3d3a471cec6cb13b104b2ee94418":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"79c2cb24929f2649a8875fb629086171f914d5ce":["a3776dccca01c11e7046323cfad46a3b4a471233","ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"7e1cbd7e289dc1243c7a59e1a83d078163a147fe":["44fcbde6fb2ac44ee3b45e013e54a42911e689ff"],"ea6df125852017e3592bf98f1465500895e3af97":["7e1cbd7e289dc1243c7a59e1a83d078163a147fe"],"78a55f24d9b493c2a1cecf79f1d78279062b545b":["3615ce4a1f785ae1b779244de52c6a7d99227e60","7118b8e5d127b58ad37740f4fa0881259a362090"],"ff6fd241dc6610f7f81b62e3ba4cedf105939623":["f2c5f0cb44df114db4228c8f77861714b5cabaea"],"9ab1f5591dc05f1f2b5407d809c9699f75554a32":["85a883878c0af761245ab048babc63d099f835f3","53a31399f2471493d67b19a95c028a74e0113b6a"],"06584e6e98d592b34e1329b384182f368d2025e8":["ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"85a883878c0af761245ab048babc63d099f835f3":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","84b590669deb3d3a471cec6cb13b104b2ee94418"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["ab5cb6a74aefb78aa0569857970b9151dfe2e787","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["3bb13258feba31ab676502787ab2e1779f129b7a","7e1cbd7e289dc1243c7a59e1a83d078163a147fe"],"962d04139994fce5193143ef35615499a9a96d78":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"a3776dccca01c11e7046323cfad46a3b4a471233":["7e1cbd7e289dc1243c7a59e1a83d078163a147fe","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":["135621f3a0670a9394eb563224a3b76cc4dddc0f","ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["06584e6e98d592b34e1329b384182f368d2025e8","1c5b026d03cbbb03ca4c0b97d14e9839682281dc"],"3bb13258feba31ab676502787ab2e1779f129b7a":["9ab1f5591dc05f1f2b5407d809c9699f75554a32","6395eaae7ec8e80087f6325dce5ed5f4b095ca42"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"44fcbde6fb2ac44ee3b45e013e54a42911e689ff":["7e1cbd7e289dc1243c7a59e1a83d078163a147fe"],"7118b8e5d127b58ad37740f4fa0881259a362090":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","fd92b8bcc88e969302510acf77bd6970da3994c4","78a55f24d9b493c2a1cecf79f1d78279062b545b"],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"fd92b8bcc88e969302510acf77bd6970da3994c4":[],"1c5b026d03cbbb03ca4c0b97d14e9839682281dc":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["962d04139994fce5193143ef35615499a9a96d78"],"6395eaae7ec8e80087f6325dce5ed5f4b095ca42":["44fcbde6fb2ac44ee3b45e013e54a42911e689ff","3bb13258feba31ab676502787ab2e1779f129b7a"],"53a31399f2471493d67b19a95c028a74e0113b6a":["6395eaae7ec8e80087f6325dce5ed5f4b095ca42","9ab1f5591dc05f1f2b5407d809c9699f75554a32"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["ff6fd241dc6610f7f81b62e3ba4cedf105939623","135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","a3776dccca01c11e7046323cfad46a3b4a471233"],"84b590669deb3d3a471cec6cb13b104b2ee94418":["53a31399f2471493d67b19a95c028a74e0113b6a","85a883878c0af761245ab048babc63d099f835f3"],"79c2cb24929f2649a8875fb629086171f914d5ce":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","84b590669deb3d3a471cec6cb13b104b2ee94418","85a883878c0af761245ab048babc63d099f835f3"],"7e1cbd7e289dc1243c7a59e1a83d078163a147fe":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","ea6df125852017e3592bf98f1465500895e3af97","ab5cb6a74aefb78aa0569857970b9151dfe2e787","a3776dccca01c11e7046323cfad46a3b4a471233"],"ea6df125852017e3592bf98f1465500895e3af97":["f2c5f0cb44df114db4228c8f77861714b5cabaea"],"78a55f24d9b493c2a1cecf79f1d78279062b545b":[],"ff6fd241dc6610f7f81b62e3ba4cedf105939623":["79c2cb24929f2649a8875fb629086171f914d5ce","06584e6e98d592b34e1329b384182f368d2025e8","77cf4379b2824f6ea34b091c495d6e95c38ff9e2"],"9ab1f5591dc05f1f2b5407d809c9699f75554a32":["3bb13258feba31ab676502787ab2e1779f129b7a"],"06584e6e98d592b34e1329b384182f368d2025e8":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","1c5b026d03cbbb03ca4c0b97d14e9839682281dc","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"85a883878c0af761245ab048babc63d099f835f3":["9ab1f5591dc05f1f2b5407d809c9699f75554a32"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["77cf4379b2824f6ea34b091c495d6e95c38ff9e2"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"962d04139994fce5193143ef35615499a9a96d78":[],"a3776dccca01c11e7046323cfad46a3b4a471233":["79c2cb24929f2649a8875fb629086171f914d5ce"],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":[],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["7118b8e5d127b58ad37740f4fa0881259a362090","ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","fd92b8bcc88e969302510acf77bd6970da3994c4","78a55f24d9b493c2a1cecf79f1d78279062b545b"],"3bb13258feba31ab676502787ab2e1779f129b7a":["ab5cb6a74aefb78aa0569857970b9151dfe2e787"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","fd92b8bcc88e969302510acf77bd6970da3994c4","79c2cb24929f2649a8875fb629086171f914d5ce","78a55f24d9b493c2a1cecf79f1d78279062b545b","962d04139994fce5193143ef35615499a9a96d78","77cf4379b2824f6ea34b091c495d6e95c38ff9e2","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}