{"path":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentExpressionDictionaryTest#testBasic().mjava","commits":[{"id":"f6ff8992b4de8c3e2f3e4e363868e5f87eb19039","date":1382209267,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentExpressionDictionaryTest#testBasic().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(10);\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n    IndexReader ir = DirectoryReader.open(dir);\n    Set<SortField> sortFields = new HashSet<SortField>(); \n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_1, SortField.Type.LONG));\n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_2, SortField.Type.LONG));\n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_3, SortField.Type.LONG));\n    Dictionary dictionary = new DocumentExpressionDictionary(ir, FIELD_NAME, \"((w1 + w2) - w3)\", sortFields, PAYLOAD_FIELD_NAME);\n    InputIterator tfp = (InputIterator) dictionary.getWordsIterator();\n    BytesRef f;\n    while((f = tfp.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(tfp.weight(), (w1 + w2) - w3);\n      assertTrue(tfp.payload().equals(doc.getField(PAYLOAD_FIELD_NAME).binaryValue()));\n    }\n    assertTrue(docs.isEmpty());\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["f3cb6c20980e2a6b960e6277e6f2b1e38959ed7e"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f3cb6c20980e2a6b960e6277e6f2b1e38959ed7e","date":1382637312,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentExpressionDictionaryTest#testBasic().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentExpressionDictionaryTest#testBasic().mjava","sourceNew":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(10);\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n    // TODO: once we fix DocumentExpressionDictionary to\n    // accept readers with more than one segment, we can\n    // remove this wrapping:\n    IndexReader ir = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(dir));\n    Set<SortField> sortFields = new HashSet<SortField>(); \n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_1, SortField.Type.LONG));\n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_2, SortField.Type.LONG));\n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_3, SortField.Type.LONG));\n    Dictionary dictionary = new DocumentExpressionDictionary(ir, FIELD_NAME, \"((w1 + w2) - w3)\", sortFields, PAYLOAD_FIELD_NAME);\n    InputIterator tfp = (InputIterator) dictionary.getWordsIterator();\n    BytesRef f;\n    while((f = tfp.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(tfp.weight(), (w1 + w2) - w3);\n      assertTrue(tfp.payload().equals(doc.getField(PAYLOAD_FIELD_NAME).binaryValue()));\n    }\n    assertTrue(docs.isEmpty());\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(10);\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n    IndexReader ir = DirectoryReader.open(dir);\n    Set<SortField> sortFields = new HashSet<SortField>(); \n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_1, SortField.Type.LONG));\n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_2, SortField.Type.LONG));\n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_3, SortField.Type.LONG));\n    Dictionary dictionary = new DocumentExpressionDictionary(ir, FIELD_NAME, \"((w1 + w2) - w3)\", sortFields, PAYLOAD_FIELD_NAME);\n    InputIterator tfp = (InputIterator) dictionary.getWordsIterator();\n    BytesRef f;\n    while((f = tfp.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(tfp.weight(), (w1 + w2) - w3);\n      assertTrue(tfp.payload().equals(doc.getField(PAYLOAD_FIELD_NAME).binaryValue()));\n    }\n    assertTrue(docs.isEmpty());\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":["f6ff8992b4de8c3e2f3e4e363868e5f87eb19039"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"557640e996995f56504248e3347a3c61c1923097","date":1383067984,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentExpressionDictionaryTest#testBasic().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentExpressionDictionaryTest#testBasic().mjava","sourceNew":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(10));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    Set<SortField> sortFields = new HashSet<SortField>(); \n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_1, SortField.Type.LONG));\n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_2, SortField.Type.LONG));\n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_3, SortField.Type.LONG));\n    Dictionary dictionary = new DocumentExpressionDictionary(ir, FIELD_NAME, \"((w1 + w2) - w3)\", sortFields, PAYLOAD_FIELD_NAME);\n    InputIterator tfp = (InputIterator) dictionary.getWordsIterator();\n    BytesRef f;\n    while((f = tfp.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(tfp.weight(), (w1 + w2) - w3);\n      assertTrue(tfp.payload().equals(doc.getField(PAYLOAD_FIELD_NAME).binaryValue()));\n    }\n    assertTrue(docs.isEmpty());\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(10);\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n    // TODO: once we fix DocumentExpressionDictionary to\n    // accept readers with more than one segment, we can\n    // remove this wrapping:\n    IndexReader ir = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(dir));\n    Set<SortField> sortFields = new HashSet<SortField>(); \n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_1, SortField.Type.LONG));\n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_2, SortField.Type.LONG));\n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_3, SortField.Type.LONG));\n    Dictionary dictionary = new DocumentExpressionDictionary(ir, FIELD_NAME, \"((w1 + w2) - w3)\", sortFields, PAYLOAD_FIELD_NAME);\n    InputIterator tfp = (InputIterator) dictionary.getWordsIterator();\n    BytesRef f;\n    while((f = tfp.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(tfp.weight(), (w1 + w2) - w3);\n      assertTrue(tfp.payload().equals(doc.getField(PAYLOAD_FIELD_NAME).binaryValue()));\n    }\n    assertTrue(docs.isEmpty());\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"24730daba4a74cb3bd673ccacc4ddaee5963af02","date":1385133691,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentExpressionDictionaryTest#testBasic().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentExpressionDictionaryTest#testBasic().mjava","sourceNew":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    Set<SortField> sortFields = new HashSet<SortField>(); \n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_1, SortField.Type.LONG));\n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_2, SortField.Type.LONG));\n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_3, SortField.Type.LONG));\n    Dictionary dictionary = new DocumentExpressionDictionary(ir, FIELD_NAME, \"((w1 + w2) - w3)\", sortFields, PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = (InputIterator) dictionary.getWordsIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2) - w3);\n      assertTrue(inputIterator.payload().equals(doc.getField(PAYLOAD_FIELD_NAME).binaryValue()));\n    }\n    assertTrue(docs.isEmpty());\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(10));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    Set<SortField> sortFields = new HashSet<SortField>(); \n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_1, SortField.Type.LONG));\n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_2, SortField.Type.LONG));\n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_3, SortField.Type.LONG));\n    Dictionary dictionary = new DocumentExpressionDictionary(ir, FIELD_NAME, \"((w1 + w2) - w3)\", sortFields, PAYLOAD_FIELD_NAME);\n    InputIterator tfp = (InputIterator) dictionary.getWordsIterator();\n    BytesRef f;\n    while((f = tfp.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(tfp.weight(), (w1 + w2) - w3);\n      assertTrue(tfp.payload().equals(doc.getField(PAYLOAD_FIELD_NAME).binaryValue()));\n    }\n    assertTrue(docs.isEmpty());\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["ee590759ca28a3f2599ba7608ea0a50be4f540f6"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"74f45af4339b0daf7a95c820ab88c1aea74fbce0","date":1387475327,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentExpressionDictionaryTest#testBasic().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentExpressionDictionaryTest#testBasic().mjava","sourceNew":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    Set<SortField> sortFields = new HashSet<SortField>(); \n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_1, SortField.Type.LONG));\n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_2, SortField.Type.LONG));\n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_3, SortField.Type.LONG));\n    Dictionary dictionary = new DocumentExpressionDictionary(ir, FIELD_NAME, \"((w1 + w2) - w3)\", sortFields, PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = (InputIterator) dictionary.getWordsIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2) - w3);\n      assertTrue(inputIterator.payload().equals(doc.getField(PAYLOAD_FIELD_NAME).binaryValue()));\n    }\n    assertTrue(docs.isEmpty());\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(10));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    Set<SortField> sortFields = new HashSet<SortField>(); \n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_1, SortField.Type.LONG));\n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_2, SortField.Type.LONG));\n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_3, SortField.Type.LONG));\n    Dictionary dictionary = new DocumentExpressionDictionary(ir, FIELD_NAME, \"((w1 + w2) - w3)\", sortFields, PAYLOAD_FIELD_NAME);\n    InputIterator tfp = (InputIterator) dictionary.getWordsIterator();\n    BytesRef f;\n    while((f = tfp.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(tfp.weight(), (w1 + w2) - w3);\n      assertTrue(tfp.payload().equals(doc.getField(PAYLOAD_FIELD_NAME).binaryValue()));\n    }\n    assertTrue(docs.isEmpty());\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"11c5f879e49375db0f48ca533856f226c2db57a5","date":1390688316,"type":5,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testBasic().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentExpressionDictionaryTest#testBasic().mjava","sourceNew":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    ValueSource[] toAdd = new ValueSource[] {new LongFieldSource(WEIGHT_FIELD_NAME_1), new LongFieldSource(WEIGHT_FIELD_NAME_2), new LongFieldSource(WEIGHT_FIELD_NAME_3)};\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, new SumFloatFunction(toAdd), PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = (InputIterator) dictionary.getWordsIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2 + w3));\n      assertTrue(inputIterator.payload().equals(doc.getField(PAYLOAD_FIELD_NAME).binaryValue()));\n    }\n    assertTrue(docs.isEmpty());\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    Set<SortField> sortFields = new HashSet<SortField>(); \n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_1, SortField.Type.LONG));\n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_2, SortField.Type.LONG));\n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_3, SortField.Type.LONG));\n    Dictionary dictionary = new DocumentExpressionDictionary(ir, FIELD_NAME, \"((w1 + w2) - w3)\", sortFields, PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = (InputIterator) dictionary.getWordsIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2) - w3);\n      assertTrue(inputIterator.payload().equals(doc.getField(PAYLOAD_FIELD_NAME).binaryValue()));\n    }\n    assertTrue(docs.isEmpty());\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"24730daba4a74cb3bd673ccacc4ddaee5963af02":["557640e996995f56504248e3347a3c61c1923097"],"f3cb6c20980e2a6b960e6277e6f2b1e38959ed7e":["f6ff8992b4de8c3e2f3e4e363868e5f87eb19039"],"f6ff8992b4de8c3e2f3e4e363868e5f87eb19039":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":["557640e996995f56504248e3347a3c61c1923097","24730daba4a74cb3bd673ccacc4ddaee5963af02"],"11c5f879e49375db0f48ca533856f226c2db57a5":["24730daba4a74cb3bd673ccacc4ddaee5963af02"],"557640e996995f56504248e3347a3c61c1923097":["f3cb6c20980e2a6b960e6277e6f2b1e38959ed7e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["11c5f879e49375db0f48ca533856f226c2db57a5"]},"commit2Childs":{"24730daba4a74cb3bd673ccacc4ddaee5963af02":["74f45af4339b0daf7a95c820ab88c1aea74fbce0","11c5f879e49375db0f48ca533856f226c2db57a5"],"f3cb6c20980e2a6b960e6277e6f2b1e38959ed7e":["557640e996995f56504248e3347a3c61c1923097"],"f6ff8992b4de8c3e2f3e4e363868e5f87eb19039":["f3cb6c20980e2a6b960e6277e6f2b1e38959ed7e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["f6ff8992b4de8c3e2f3e4e363868e5f87eb19039"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":[],"557640e996995f56504248e3347a3c61c1923097":["24730daba4a74cb3bd673ccacc4ddaee5963af02","74f45af4339b0daf7a95c820ab88c1aea74fbce0"],"11c5f879e49375db0f48ca533856f226c2db57a5":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["74f45af4339b0daf7a95c820ab88c1aea74fbce0","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}