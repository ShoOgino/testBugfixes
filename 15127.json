{"path":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testSimpleQueryTermScorerHighlighter().mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testSimpleQueryTermScorerHighlighter().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testSimpleQueryTermScorerHighlighter().mjava","sourceNew":"  public void testSimpleQueryTermScorerHighlighter() throws Exception {\n    doSearching(new TermQuery(new Term(FIELD_NAME, \"kennedy\")));\n    Highlighter highlighter = new Highlighter(new QueryTermScorer(query));\n    highlighter.setTextFragmenter(new SimpleFragmenter(40));\n    int maxNumFragmentsRequired = 2;\n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = searcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n\n      String result = highlighter.getBestFragments(tokenStream, text, maxNumFragmentsRequired,\n          \"...\");\n      if (VERBOSE) System.out.println(\"\\t\" + result);\n    }\n    // Not sure we can assert anything here - just running to check we dont\n    // throw any exceptions\n  }\n\n","sourceOld":"  public void testSimpleQueryTermScorerHighlighter() throws Exception {\n    doSearching(new TermQuery(new Term(FIELD_NAME, \"kennedy\")));\n    Highlighter highlighter = new Highlighter(new QueryTermScorer(query));\n    highlighter.setTextFragmenter(new SimpleFragmenter(40));\n    int maxNumFragmentsRequired = 2;\n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = searcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n\n      String result = highlighter.getBestFragments(tokenStream, text, maxNumFragmentsRequired,\n          \"...\");\n      if (VERBOSE) System.out.println(\"\\t\" + result);\n    }\n    // Not sure we can assert anything here - just running to check we dont\n    // throw any exceptions\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c83d6c4335f31cae14f625a222bc842f20073dcd","date":1373306148,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testSimpleQueryTermScorerHighlighter().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testSimpleQueryTermScorerHighlighter().mjava","sourceNew":"  public void testSimpleQueryTermScorerHighlighter() throws Exception {\n    doSearching(new TermQuery(new Term(FIELD_NAME, \"kennedy\")));\n    Highlighter highlighter = new Highlighter(new QueryTermScorer(query));\n    highlighter.setTextFragmenter(new SimpleFragmenter(40));\n    int maxNumFragmentsRequired = 2;\n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = searcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, text);\n\n      String result = highlighter.getBestFragments(tokenStream, text, maxNumFragmentsRequired,\n          \"...\");\n      if (VERBOSE) System.out.println(\"\\t\" + result);\n    }\n    // Not sure we can assert anything here - just running to check we dont\n    // throw any exceptions\n  }\n\n","sourceOld":"  public void testSimpleQueryTermScorerHighlighter() throws Exception {\n    doSearching(new TermQuery(new Term(FIELD_NAME, \"kennedy\")));\n    Highlighter highlighter = new Highlighter(new QueryTermScorer(query));\n    highlighter.setTextFragmenter(new SimpleFragmenter(40));\n    int maxNumFragmentsRequired = 2;\n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = searcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n\n      String result = highlighter.getBestFragments(tokenStream, text, maxNumFragmentsRequired,\n          \"...\");\n      if (VERBOSE) System.out.println(\"\\t\" + result);\n    }\n    // Not sure we can assert anything here - just running to check we dont\n    // throw any exceptions\n  }\n\n","bugFix":["69e043c521d4e8db770cc140c63f5ef51f03426a"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testSimpleQueryTermScorerHighlighter().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testSimpleQueryTermScorerHighlighter().mjava","sourceNew":"  public void testSimpleQueryTermScorerHighlighter() throws Exception {\n    doSearching(new TermQuery(new Term(FIELD_NAME, \"kennedy\")));\n    Highlighter highlighter = new Highlighter(new QueryTermScorer(query));\n    highlighter.setTextFragmenter(new SimpleFragmenter(40));\n    int maxNumFragmentsRequired = 2;\n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = searcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, text);\n\n      String result = highlighter.getBestFragments(tokenStream, text, maxNumFragmentsRequired,\n          \"...\");\n      if (VERBOSE) System.out.println(\"\\t\" + result);\n    }\n    // Not sure we can assert anything here - just running to check we dont\n    // throw any exceptions\n  }\n\n","sourceOld":"  public void testSimpleQueryTermScorerHighlighter() throws Exception {\n    doSearching(new TermQuery(new Term(FIELD_NAME, \"kennedy\")));\n    Highlighter highlighter = new Highlighter(new QueryTermScorer(query));\n    highlighter.setTextFragmenter(new SimpleFragmenter(40));\n    int maxNumFragmentsRequired = 2;\n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = searcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n\n      String result = highlighter.getBestFragments(tokenStream, text, maxNumFragmentsRequired,\n          \"...\");\n      if (VERBOSE) System.out.println(\"\\t\" + result);\n    }\n    // Not sure we can assert anything here - just running to check we dont\n    // throw any exceptions\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aeebe27bce18b879b80f68494c52cda1021b5705","date":1417792137,"type":3,"author":"David Wayne Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testSimpleQueryTermScorerHighlighter().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testSimpleQueryTermScorerHighlighter().mjava","sourceNew":"  public void testSimpleQueryTermScorerHighlighter() throws Exception {\n    doSearching(new TermQuery(new Term(FIELD_NAME, \"kennedy\")));\n    Highlighter highlighter = new Highlighter(new QueryTermScorer(query));\n    highlighter.setTextFragmenter(new SimpleFragmenter(40));\n    int maxNumFragmentsRequired = 2;\n    for (int i = 0; i < hits.totalHits; i++) {\n      final StoredDocument doc = searcher.doc(hits.scoreDocs[i].doc);\n      String text = doc.get(FIELD_NAME);\n      TokenStream tokenStream = TokenSources.getAnyTokenStream(reader, hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      String result = highlighter.getBestFragments(tokenStream, text, maxNumFragmentsRequired,\n          \"...\");\n      if (VERBOSE) System.out.println(\"\\t\" + result);\n    }\n    // Not sure we can assert anything here - just running to check we dont\n    // throw any exceptions\n  }\n\n","sourceOld":"  public void testSimpleQueryTermScorerHighlighter() throws Exception {\n    doSearching(new TermQuery(new Term(FIELD_NAME, \"kennedy\")));\n    Highlighter highlighter = new Highlighter(new QueryTermScorer(query));\n    highlighter.setTextFragmenter(new SimpleFragmenter(40));\n    int maxNumFragmentsRequired = 2;\n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = searcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, text);\n\n      String result = highlighter.getBestFragments(tokenStream, text, maxNumFragmentsRequired,\n          \"...\");\n      if (VERBOSE) System.out.println(\"\\t\" + result);\n    }\n    // Not sure we can assert anything here - just running to check we dont\n    // throw any exceptions\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5d62e4938659e263e96ae8188e11aea8a940aea5","date":1430230314,"type":3,"author":"David Wayne Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testSimpleQueryTermScorerHighlighter().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testSimpleQueryTermScorerHighlighter().mjava","sourceNew":"  public void testSimpleQueryTermScorerHighlighter() throws Exception {\n    doSearching(new TermQuery(new Term(FIELD_NAME, \"kennedy\")));\n    Highlighter highlighter = new Highlighter(new QueryTermScorer(query));\n    highlighter.setTextFragmenter(new SimpleFragmenter(40));\n    int maxNumFragmentsRequired = 2;\n    for (int i = 0; i < hits.totalHits; i++) {\n      final int docId = hits.scoreDocs[i].doc;\n      final StoredDocument doc = searcher.doc(docId);\n      String text = doc.get(FIELD_NAME);\n      TokenStream tokenStream = getAnyTokenStream(FIELD_NAME, docId);\n\n      String result = highlighter.getBestFragments(tokenStream, text, maxNumFragmentsRequired,\n          \"...\");\n      if (VERBOSE) System.out.println(\"\\t\" + result);\n    }\n    // Not sure we can assert anything here - just running to check we dont\n    // throw any exceptions\n  }\n\n","sourceOld":"  public void testSimpleQueryTermScorerHighlighter() throws Exception {\n    doSearching(new TermQuery(new Term(FIELD_NAME, \"kennedy\")));\n    Highlighter highlighter = new Highlighter(new QueryTermScorer(query));\n    highlighter.setTextFragmenter(new SimpleFragmenter(40));\n    int maxNumFragmentsRequired = 2;\n    for (int i = 0; i < hits.totalHits; i++) {\n      final StoredDocument doc = searcher.doc(hits.scoreDocs[i].doc);\n      String text = doc.get(FIELD_NAME);\n      TokenStream tokenStream = TokenSources.getAnyTokenStream(reader, hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      String result = highlighter.getBestFragments(tokenStream, text, maxNumFragmentsRequired,\n          \"...\");\n      if (VERBOSE) System.out.println(\"\\t\" + result);\n    }\n    // Not sure we can assert anything here - just running to check we dont\n    // throw any exceptions\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","date":1453060490,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testSimpleQueryTermScorerHighlighter().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testSimpleQueryTermScorerHighlighter().mjava","sourceNew":"  public void testSimpleQueryTermScorerHighlighter() throws Exception {\n    doSearching(new TermQuery(new Term(FIELD_NAME, \"kennedy\")));\n    Highlighter highlighter = new Highlighter(new QueryTermScorer(query));\n    highlighter.setTextFragmenter(new SimpleFragmenter(40));\n    int maxNumFragmentsRequired = 2;\n    for (int i = 0; i < hits.totalHits; i++) {\n      final int docId = hits.scoreDocs[i].doc;\n      final Document doc = searcher.doc(docId);\n      String text = doc.get(FIELD_NAME);\n      TokenStream tokenStream = getAnyTokenStream(FIELD_NAME, docId);\n\n      String result = highlighter.getBestFragments(tokenStream, text, maxNumFragmentsRequired,\n          \"...\");\n      if (VERBOSE) System.out.println(\"\\t\" + result);\n    }\n    // Not sure we can assert anything here - just running to check we dont\n    // throw any exceptions\n  }\n\n","sourceOld":"  public void testSimpleQueryTermScorerHighlighter() throws Exception {\n    doSearching(new TermQuery(new Term(FIELD_NAME, \"kennedy\")));\n    Highlighter highlighter = new Highlighter(new QueryTermScorer(query));\n    highlighter.setTextFragmenter(new SimpleFragmenter(40));\n    int maxNumFragmentsRequired = 2;\n    for (int i = 0; i < hits.totalHits; i++) {\n      final int docId = hits.scoreDocs[i].doc;\n      final StoredDocument doc = searcher.doc(docId);\n      String text = doc.get(FIELD_NAME);\n      TokenStream tokenStream = getAnyTokenStream(FIELD_NAME, docId);\n\n      String result = highlighter.getBestFragments(tokenStream, text, maxNumFragmentsRequired,\n          \"...\");\n      if (VERBOSE) System.out.println(\"\\t\" + result);\n    }\n    // Not sure we can assert anything here - just running to check we dont\n    // throw any exceptions\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"83788ad129a5154d5c6562c4e8ce3db48793aada","date":1532961485,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testSimpleQueryTermScorerHighlighter().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testSimpleQueryTermScorerHighlighter().mjava","sourceNew":"  public void testSimpleQueryTermScorerHighlighter() throws Exception {\n    doSearching(new TermQuery(new Term(FIELD_NAME, \"kennedy\")));\n    Highlighter highlighter = new Highlighter(new QueryTermScorer(query));\n    highlighter.setTextFragmenter(new SimpleFragmenter(40));\n    int maxNumFragmentsRequired = 2;\n    for (int i = 0; i < hits.totalHits.value; i++) {\n      final int docId = hits.scoreDocs[i].doc;\n      final Document doc = searcher.doc(docId);\n      String text = doc.get(FIELD_NAME);\n      TokenStream tokenStream = getAnyTokenStream(FIELD_NAME, docId);\n\n      String result = highlighter.getBestFragments(tokenStream, text, maxNumFragmentsRequired,\n          \"...\");\n      if (VERBOSE) System.out.println(\"\\t\" + result);\n    }\n    // Not sure we can assert anything here - just running to check we dont\n    // throw any exceptions\n  }\n\n","sourceOld":"  public void testSimpleQueryTermScorerHighlighter() throws Exception {\n    doSearching(new TermQuery(new Term(FIELD_NAME, \"kennedy\")));\n    Highlighter highlighter = new Highlighter(new QueryTermScorer(query));\n    highlighter.setTextFragmenter(new SimpleFragmenter(40));\n    int maxNumFragmentsRequired = 2;\n    for (int i = 0; i < hits.totalHits; i++) {\n      final int docId = hits.scoreDocs[i].doc;\n      final Document doc = searcher.doc(docId);\n      String text = doc.get(FIELD_NAME);\n      TokenStream tokenStream = getAnyTokenStream(FIELD_NAME, docId);\n\n      String result = highlighter.getBestFragments(tokenStream, text, maxNumFragmentsRequired,\n          \"...\");\n      if (VERBOSE) System.out.println(\"\\t\" + result);\n    }\n    // Not sure we can assert anything here - just running to check we dont\n    // throw any exceptions\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["b89678825b68eccaf09e6ab71675fc0b0af1e099","c83d6c4335f31cae14f625a222bc842f20073dcd"],"c83d6c4335f31cae14f625a222bc842f20073dcd":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"5d62e4938659e263e96ae8188e11aea8a940aea5":["aeebe27bce18b879b80f68494c52cda1021b5705"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["83788ad129a5154d5c6562c4e8ce3db48793aada"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["5d62e4938659e263e96ae8188e11aea8a940aea5"],"aeebe27bce18b879b80f68494c52cda1021b5705":["c83d6c4335f31cae14f625a222bc842f20073dcd"]},"commit2Childs":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["37a0f60745e53927c4c876cfe5b5a58170f0646c","c83d6c4335f31cae14f625a222bc842f20073dcd"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":[],"c83d6c4335f31cae14f625a222bc842f20073dcd":["37a0f60745e53927c4c876cfe5b5a58170f0646c","aeebe27bce18b879b80f68494c52cda1021b5705"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"5d62e4938659e263e96ae8188e11aea8a940aea5":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"aeebe27bce18b879b80f68494c52cda1021b5705":["5d62e4938659e263e96ae8188e11aea8a940aea5"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["83788ad129a5154d5c6562c4e8ce3db48793aada"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["37a0f60745e53927c4c876cfe5b5a58170f0646c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}