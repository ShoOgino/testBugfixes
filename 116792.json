{"path":"lucene/src/java/org/apache/lucene/index/FieldsReader#doc(int,FieldSelector).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/FieldsReader#doc(int,FieldSelector).mjava","pathOld":"src/java/org/apache/lucene/index/FieldsReader#doc(int,FieldSelector).mjava","sourceNew":"  final Document doc(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {\n    seekIndex(n);\n    long position = indexStream.readLong();\n    fieldsStream.seek(position);\n\n    Document doc = new Document();\n    int numFields = fieldsStream.readVInt();\n    for (int i = 0; i < numFields; i++) {\n      int fieldNumber = fieldsStream.readVInt();\n      FieldInfo fi = fieldInfos.fieldInfo(fieldNumber);\n      FieldSelectorResult acceptField = fieldSelector == null ? FieldSelectorResult.LOAD : fieldSelector.accept(fi.name);\n      \n      byte bits = fieldsStream.readByte();\n      assert bits <= FieldsWriter.FIELD_IS_COMPRESSED + FieldsWriter.FIELD_IS_TOKENIZED + FieldsWriter.FIELD_IS_BINARY;\n\n      boolean compressed = (bits & FieldsWriter.FIELD_IS_COMPRESSED) != 0;\n      assert (compressed ? (format < FieldsWriter.FORMAT_LUCENE_3_0_NO_COMPRESSED_FIELDS) : true)\n        : \"compressed fields are only allowed in indexes of version <= 2.9\";\n      boolean tokenize = (bits & FieldsWriter.FIELD_IS_TOKENIZED) != 0;\n      boolean binary = (bits & FieldsWriter.FIELD_IS_BINARY) != 0;\n      //TODO: Find an alternative approach here if this list continues to grow beyond the\n      //list of 5 or 6 currently here.  See Lucene 762 for discussion\n      if (acceptField.equals(FieldSelectorResult.LOAD)) {\n        addField(doc, fi, binary, compressed, tokenize);\n      }\n      else if (acceptField.equals(FieldSelectorResult.LOAD_AND_BREAK)){\n        addField(doc, fi, binary, compressed, tokenize);\n        break;//Get out of this loop\n      }\n      else if (acceptField.equals(FieldSelectorResult.LAZY_LOAD)) {\n        addFieldLazy(doc, fi, binary, compressed, tokenize);\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE)){\n        skipField(binary, compressed, addFieldSize(doc, fi, binary, compressed));\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE_AND_BREAK)){\n        addFieldSize(doc, fi, binary, compressed);\n        break;\n      }\n      else {\n        skipField(binary, compressed);\n      }\n    }\n\n    return doc;\n  }\n\n","sourceOld":"  final Document doc(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {\n    seekIndex(n);\n    long position = indexStream.readLong();\n    fieldsStream.seek(position);\n\n    Document doc = new Document();\n    int numFields = fieldsStream.readVInt();\n    for (int i = 0; i < numFields; i++) {\n      int fieldNumber = fieldsStream.readVInt();\n      FieldInfo fi = fieldInfos.fieldInfo(fieldNumber);\n      FieldSelectorResult acceptField = fieldSelector == null ? FieldSelectorResult.LOAD : fieldSelector.accept(fi.name);\n      \n      byte bits = fieldsStream.readByte();\n      assert bits <= FieldsWriter.FIELD_IS_COMPRESSED + FieldsWriter.FIELD_IS_TOKENIZED + FieldsWriter.FIELD_IS_BINARY;\n\n      boolean compressed = (bits & FieldsWriter.FIELD_IS_COMPRESSED) != 0;\n      assert (compressed ? (format < FieldsWriter.FORMAT_LUCENE_3_0_NO_COMPRESSED_FIELDS) : true)\n        : \"compressed fields are only allowed in indexes of version <= 2.9\";\n      boolean tokenize = (bits & FieldsWriter.FIELD_IS_TOKENIZED) != 0;\n      boolean binary = (bits & FieldsWriter.FIELD_IS_BINARY) != 0;\n      //TODO: Find an alternative approach here if this list continues to grow beyond the\n      //list of 5 or 6 currently here.  See Lucene 762 for discussion\n      if (acceptField.equals(FieldSelectorResult.LOAD)) {\n        addField(doc, fi, binary, compressed, tokenize);\n      }\n      else if (acceptField.equals(FieldSelectorResult.LOAD_AND_BREAK)){\n        addField(doc, fi, binary, compressed, tokenize);\n        break;//Get out of this loop\n      }\n      else if (acceptField.equals(FieldSelectorResult.LAZY_LOAD)) {\n        addFieldLazy(doc, fi, binary, compressed, tokenize);\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE)){\n        skipField(binary, compressed, addFieldSize(doc, fi, binary, compressed));\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE_AND_BREAK)){\n        addFieldSize(doc, fi, binary, compressed);\n        break;\n      }\n      else {\n        skipField(binary, compressed);\n      }\n    }\n\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6267e1ce56c2eec111425690cd04e251b6f14952","date":1275222352,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/FieldsReader#doc(int,FieldSelector).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/FieldsReader#doc(int,FieldSelector).mjava","sourceNew":"  final Document doc(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {\n    seekIndex(n);\n    long position = indexStream.readLong();\n    fieldsStream.seek(position);\n\n    Document doc = new Document();\n    int numFields = fieldsStream.readVInt();\n    for (int i = 0; i < numFields; i++) {\n      int fieldNumber = fieldsStream.readVInt();\n      FieldInfo fi = fieldInfos.fieldInfo(fieldNumber);\n      FieldSelectorResult acceptField = fieldSelector == null ? FieldSelectorResult.LOAD : fieldSelector.accept(fi.name);\n      \n      byte bits = fieldsStream.readByte();\n      assert bits <= FieldsWriter.FIELD_IS_TOKENIZED + FieldsWriter.FIELD_IS_BINARY;\n\n      boolean tokenize = (bits & FieldsWriter.FIELD_IS_TOKENIZED) != 0;\n      boolean binary = (bits & FieldsWriter.FIELD_IS_BINARY) != 0;\n      //TODO: Find an alternative approach here if this list continues to grow beyond the\n      //list of 5 or 6 currently here.  See Lucene 762 for discussion\n      if (acceptField.equals(FieldSelectorResult.LOAD)) {\n        addField(doc, fi, binary, tokenize);\n      }\n      else if (acceptField.equals(FieldSelectorResult.LOAD_AND_BREAK)){\n        addField(doc, fi, binary, tokenize);\n        break;//Get out of this loop\n      }\n      else if (acceptField.equals(FieldSelectorResult.LAZY_LOAD)) {\n        addFieldLazy(doc, fi, binary, tokenize);\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE)){\n        skipField(addFieldSize(doc, fi, binary));\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE_AND_BREAK)){\n        addFieldSize(doc, fi, binary);\n        break;\n      }\n      else {\n        skipField();\n      }\n    }\n\n    return doc;\n  }\n\n","sourceOld":"  final Document doc(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {\n    seekIndex(n);\n    long position = indexStream.readLong();\n    fieldsStream.seek(position);\n\n    Document doc = new Document();\n    int numFields = fieldsStream.readVInt();\n    for (int i = 0; i < numFields; i++) {\n      int fieldNumber = fieldsStream.readVInt();\n      FieldInfo fi = fieldInfos.fieldInfo(fieldNumber);\n      FieldSelectorResult acceptField = fieldSelector == null ? FieldSelectorResult.LOAD : fieldSelector.accept(fi.name);\n      \n      byte bits = fieldsStream.readByte();\n      assert bits <= FieldsWriter.FIELD_IS_COMPRESSED + FieldsWriter.FIELD_IS_TOKENIZED + FieldsWriter.FIELD_IS_BINARY;\n\n      boolean compressed = (bits & FieldsWriter.FIELD_IS_COMPRESSED) != 0;\n      assert (compressed ? (format < FieldsWriter.FORMAT_LUCENE_3_0_NO_COMPRESSED_FIELDS) : true)\n        : \"compressed fields are only allowed in indexes of version <= 2.9\";\n      boolean tokenize = (bits & FieldsWriter.FIELD_IS_TOKENIZED) != 0;\n      boolean binary = (bits & FieldsWriter.FIELD_IS_BINARY) != 0;\n      //TODO: Find an alternative approach here if this list continues to grow beyond the\n      //list of 5 or 6 currently here.  See Lucene 762 for discussion\n      if (acceptField.equals(FieldSelectorResult.LOAD)) {\n        addField(doc, fi, binary, compressed, tokenize);\n      }\n      else if (acceptField.equals(FieldSelectorResult.LOAD_AND_BREAK)){\n        addField(doc, fi, binary, compressed, tokenize);\n        break;//Get out of this loop\n      }\n      else if (acceptField.equals(FieldSelectorResult.LAZY_LOAD)) {\n        addFieldLazy(doc, fi, binary, compressed, tokenize);\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE)){\n        skipField(binary, compressed, addFieldSize(doc, fi, binary, compressed));\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE_AND_BREAK)){\n        addFieldSize(doc, fi, binary, compressed);\n        break;\n      }\n      else {\n        skipField(binary, compressed);\n      }\n    }\n\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"371bbd52cb908c7640086aa3aec5880542b81060","date":1277991686,"type":3,"author":"Grant Ingersoll","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/FieldsReader#doc(int,FieldSelector).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/FieldsReader#doc(int,FieldSelector).mjava","sourceNew":"  final Document doc(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {\n    seekIndex(n);\n    long position = indexStream.readLong();\n    fieldsStream.seek(position);\n\n    Document doc = new Document();\n    int numFields = fieldsStream.readVInt();\n    for (int i = 0; i < numFields; i++) {\n      int fieldNumber = fieldsStream.readVInt();\n      FieldInfo fi = fieldInfos.fieldInfo(fieldNumber);\n      FieldSelectorResult acceptField = fieldSelector == null ? FieldSelectorResult.LOAD : fieldSelector.accept(fi.name);\n      \n      byte bits = fieldsStream.readByte();\n      assert bits <= FieldsWriter.FIELD_IS_TOKENIZED + FieldsWriter.FIELD_IS_BINARY;\n\n      boolean tokenize = (bits & FieldsWriter.FIELD_IS_TOKENIZED) != 0;\n      boolean binary = (bits & FieldsWriter.FIELD_IS_BINARY) != 0;\n      //TODO: Find an alternative approach here if this list continues to grow beyond the\n      //list of 5 or 6 currently here.  See Lucene 762 for discussion\n      if (acceptField.equals(FieldSelectorResult.LOAD)) {\n        addField(doc, fi, binary, tokenize);\n      }\n      else if (acceptField.equals(FieldSelectorResult.LOAD_AND_BREAK)){\n        addField(doc, fi, binary, tokenize);\n        break;//Get out of this loop\n      }\n      else if (acceptField.equals(FieldSelectorResult.LAZY_LOAD)) {\n        addFieldLazy(doc, fi, binary, tokenize, true);\n      } else if (acceptField.equals(FieldSelectorResult.LATENT)) {\n        addFieldLazy(doc, fi, binary, tokenize, false);\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE)){\n        skipField(addFieldSize(doc, fi, binary));\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE_AND_BREAK)){\n        addFieldSize(doc, fi, binary);\n        break;\n      }\n      else {\n        skipField();\n      }\n    }\n\n    return doc;\n  }\n\n","sourceOld":"  final Document doc(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {\n    seekIndex(n);\n    long position = indexStream.readLong();\n    fieldsStream.seek(position);\n\n    Document doc = new Document();\n    int numFields = fieldsStream.readVInt();\n    for (int i = 0; i < numFields; i++) {\n      int fieldNumber = fieldsStream.readVInt();\n      FieldInfo fi = fieldInfos.fieldInfo(fieldNumber);\n      FieldSelectorResult acceptField = fieldSelector == null ? FieldSelectorResult.LOAD : fieldSelector.accept(fi.name);\n      \n      byte bits = fieldsStream.readByte();\n      assert bits <= FieldsWriter.FIELD_IS_TOKENIZED + FieldsWriter.FIELD_IS_BINARY;\n\n      boolean tokenize = (bits & FieldsWriter.FIELD_IS_TOKENIZED) != 0;\n      boolean binary = (bits & FieldsWriter.FIELD_IS_BINARY) != 0;\n      //TODO: Find an alternative approach here if this list continues to grow beyond the\n      //list of 5 or 6 currently here.  See Lucene 762 for discussion\n      if (acceptField.equals(FieldSelectorResult.LOAD)) {\n        addField(doc, fi, binary, tokenize);\n      }\n      else if (acceptField.equals(FieldSelectorResult.LOAD_AND_BREAK)){\n        addField(doc, fi, binary, tokenize);\n        break;//Get out of this loop\n      }\n      else if (acceptField.equals(FieldSelectorResult.LAZY_LOAD)) {\n        addFieldLazy(doc, fi, binary, tokenize);\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE)){\n        skipField(addFieldSize(doc, fi, binary));\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE_AND_BREAK)){\n        addFieldSize(doc, fi, binary);\n        break;\n      }\n      else {\n        skipField();\n      }\n    }\n\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4418b107fc5055dc1da859aad224aa49d90ba706","date":1277997890,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/FieldsReader#doc(int,FieldSelector).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/FieldsReader#doc(int,FieldSelector).mjava","sourceNew":"  final Document doc(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {\n    seekIndex(n);\n    long position = indexStream.readLong();\n    fieldsStream.seek(position);\n\n    Document doc = new Document();\n    int numFields = fieldsStream.readVInt();\n    for (int i = 0; i < numFields; i++) {\n      int fieldNumber = fieldsStream.readVInt();\n      FieldInfo fi = fieldInfos.fieldInfo(fieldNumber);\n      FieldSelectorResult acceptField = fieldSelector == null ? FieldSelectorResult.LOAD : fieldSelector.accept(fi.name);\n      \n      byte bits = fieldsStream.readByte();\n      assert bits <= FieldsWriter.FIELD_IS_TOKENIZED + FieldsWriter.FIELD_IS_BINARY;\n\n      boolean tokenize = (bits & FieldsWriter.FIELD_IS_TOKENIZED) != 0;\n      boolean binary = (bits & FieldsWriter.FIELD_IS_BINARY) != 0;\n      //TODO: Find an alternative approach here if this list continues to grow beyond the\n      //list of 5 or 6 currently here.  See Lucene 762 for discussion\n      if (acceptField.equals(FieldSelectorResult.LOAD)) {\n        addField(doc, fi, binary, tokenize);\n      }\n      else if (acceptField.equals(FieldSelectorResult.LOAD_AND_BREAK)){\n        addField(doc, fi, binary, tokenize);\n        break;//Get out of this loop\n      }\n      else if (acceptField.equals(FieldSelectorResult.LAZY_LOAD)) {\n        addFieldLazy(doc, fi, binary, tokenize, true);\n      }\n      else if (acceptField.equals(FieldSelectorResult.LATENT)) {\n        addFieldLazy(doc, fi, binary, tokenize, false);\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE)){\n        skipField(addFieldSize(doc, fi, binary));\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE_AND_BREAK)){\n        addFieldSize(doc, fi, binary);\n        break;\n      }\n      else {\n        skipField();\n      }\n    }\n\n    return doc;\n  }\n\n","sourceOld":"  final Document doc(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {\n    seekIndex(n);\n    long position = indexStream.readLong();\n    fieldsStream.seek(position);\n\n    Document doc = new Document();\n    int numFields = fieldsStream.readVInt();\n    for (int i = 0; i < numFields; i++) {\n      int fieldNumber = fieldsStream.readVInt();\n      FieldInfo fi = fieldInfos.fieldInfo(fieldNumber);\n      FieldSelectorResult acceptField = fieldSelector == null ? FieldSelectorResult.LOAD : fieldSelector.accept(fi.name);\n      \n      byte bits = fieldsStream.readByte();\n      assert bits <= FieldsWriter.FIELD_IS_TOKENIZED + FieldsWriter.FIELD_IS_BINARY;\n\n      boolean tokenize = (bits & FieldsWriter.FIELD_IS_TOKENIZED) != 0;\n      boolean binary = (bits & FieldsWriter.FIELD_IS_BINARY) != 0;\n      //TODO: Find an alternative approach here if this list continues to grow beyond the\n      //list of 5 or 6 currently here.  See Lucene 762 for discussion\n      if (acceptField.equals(FieldSelectorResult.LOAD)) {\n        addField(doc, fi, binary, tokenize);\n      }\n      else if (acceptField.equals(FieldSelectorResult.LOAD_AND_BREAK)){\n        addField(doc, fi, binary, tokenize);\n        break;//Get out of this loop\n      }\n      else if (acceptField.equals(FieldSelectorResult.LAZY_LOAD)) {\n        addFieldLazy(doc, fi, binary, tokenize, true);\n      } else if (acceptField.equals(FieldSelectorResult.LATENT)) {\n        addFieldLazy(doc, fi, binary, tokenize, false);\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE)){\n        skipField(addFieldSize(doc, fi, binary));\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE_AND_BREAK)){\n        addFieldSize(doc, fi, binary);\n        break;\n      }\n      else {\n        skipField();\n      }\n    }\n\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5f4e87790277826a2aea119328600dfb07761f32","date":1279827275,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/FieldsReader#doc(int,FieldSelector).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/FieldsReader#doc(int,FieldSelector).mjava","sourceNew":"  final Document doc(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {\n    seekIndex(n);\n    long position = indexStream.readLong();\n    fieldsStream.seek(position);\n\n    Document doc = new Document();\n    int numFields = fieldsStream.readVInt();\n    for (int i = 0; i < numFields; i++) {\n      int fieldNumber = fieldsStream.readVInt();\n      FieldInfo fi = fieldInfos.fieldInfo(fieldNumber);\n      FieldSelectorResult acceptField = fieldSelector == null ? FieldSelectorResult.LOAD : fieldSelector.accept(fi.name);\n      \n      byte bits = fieldsStream.readByte();\n      assert bits <= FieldsWriter.FIELD_IS_TOKENIZED + FieldsWriter.FIELD_IS_BINARY;\n\n      boolean tokenize = (bits & FieldsWriter.FIELD_IS_TOKENIZED) != 0;\n      boolean binary = (bits & FieldsWriter.FIELD_IS_BINARY) != 0;\n      //TODO: Find an alternative approach here if this list continues to grow beyond the\n      //list of 5 or 6 currently here.  See Lucene 762 for discussion\n      if (acceptField.equals(FieldSelectorResult.LOAD)) {\n        addField(doc, fi, binary, tokenize);\n      }\n      else if (acceptField.equals(FieldSelectorResult.LOAD_AND_BREAK)){\n        addField(doc, fi, binary, tokenize);\n        break;//Get out of this loop\n      }\n      else if (acceptField.equals(FieldSelectorResult.LAZY_LOAD)) {\n        addFieldLazy(doc, fi, binary, tokenize, true);\n      }\n      else if (acceptField.equals(FieldSelectorResult.LATENT)) {\n        addFieldLazy(doc, fi, binary, tokenize, false);\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE)){\n        skipField(addFieldSize(doc, fi, binary));\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE_AND_BREAK)){\n        addFieldSize(doc, fi, binary);\n        break;\n      }\n      else {\n        skipField();\n      }\n    }\n\n    return doc;\n  }\n\n","sourceOld":"  final Document doc(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {\n    seekIndex(n);\n    long position = indexStream.readLong();\n    fieldsStream.seek(position);\n\n    Document doc = new Document();\n    int numFields = fieldsStream.readVInt();\n    for (int i = 0; i < numFields; i++) {\n      int fieldNumber = fieldsStream.readVInt();\n      FieldInfo fi = fieldInfos.fieldInfo(fieldNumber);\n      FieldSelectorResult acceptField = fieldSelector == null ? FieldSelectorResult.LOAD : fieldSelector.accept(fi.name);\n      \n      byte bits = fieldsStream.readByte();\n      assert bits <= FieldsWriter.FIELD_IS_TOKENIZED + FieldsWriter.FIELD_IS_BINARY;\n\n      boolean tokenize = (bits & FieldsWriter.FIELD_IS_TOKENIZED) != 0;\n      boolean binary = (bits & FieldsWriter.FIELD_IS_BINARY) != 0;\n      //TODO: Find an alternative approach here if this list continues to grow beyond the\n      //list of 5 or 6 currently here.  See Lucene 762 for discussion\n      if (acceptField.equals(FieldSelectorResult.LOAD)) {\n        addField(doc, fi, binary, tokenize);\n      }\n      else if (acceptField.equals(FieldSelectorResult.LOAD_AND_BREAK)){\n        addField(doc, fi, binary, tokenize);\n        break;//Get out of this loop\n      }\n      else if (acceptField.equals(FieldSelectorResult.LAZY_LOAD)) {\n        addFieldLazy(doc, fi, binary, tokenize);\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE)){\n        skipField(addFieldSize(doc, fi, binary));\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE_AND_BREAK)){\n        addFieldSize(doc, fi, binary);\n        break;\n      }\n      else {\n        skipField();\n      }\n    }\n\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b9dc373b96fc96e6300e2f5af947f6998e6aa6a6","date":1295759448,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/FieldsReader#doc(int,FieldSelector).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/FieldsReader#doc(int,FieldSelector).mjava","sourceNew":"  public final Document doc(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {\n    seekIndex(n);\n    long position = indexStream.readLong();\n    fieldsStream.seek(position);\n\n    Document doc = new Document();\n    int numFields = fieldsStream.readVInt();\n    for (int i = 0; i < numFields; i++) {\n      int fieldNumber = fieldsStream.readVInt();\n      FieldInfo fi = fieldInfos.fieldInfo(fieldNumber);\n      FieldSelectorResult acceptField = fieldSelector == null ? FieldSelectorResult.LOAD : fieldSelector.accept(fi.name);\n      \n      byte bits = fieldsStream.readByte();\n      assert bits <= FieldsWriter.FIELD_IS_TOKENIZED + FieldsWriter.FIELD_IS_BINARY;\n\n      boolean tokenize = (bits & FieldsWriter.FIELD_IS_TOKENIZED) != 0;\n      boolean binary = (bits & FieldsWriter.FIELD_IS_BINARY) != 0;\n      //TODO: Find an alternative approach here if this list continues to grow beyond the\n      //list of 5 or 6 currently here.  See Lucene 762 for discussion\n      if (acceptField.equals(FieldSelectorResult.LOAD)) {\n        addField(doc, fi, binary, tokenize);\n      }\n      else if (acceptField.equals(FieldSelectorResult.LOAD_AND_BREAK)){\n        addField(doc, fi, binary, tokenize);\n        break;//Get out of this loop\n      }\n      else if (acceptField.equals(FieldSelectorResult.LAZY_LOAD)) {\n        addFieldLazy(doc, fi, binary, tokenize, true);\n      }\n      else if (acceptField.equals(FieldSelectorResult.LATENT)) {\n        addFieldLazy(doc, fi, binary, tokenize, false);\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE)){\n        skipField(addFieldSize(doc, fi, binary));\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE_AND_BREAK)){\n        addFieldSize(doc, fi, binary);\n        break;\n      }\n      else {\n        skipField();\n      }\n    }\n\n    return doc;\n  }\n\n","sourceOld":"  final Document doc(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {\n    seekIndex(n);\n    long position = indexStream.readLong();\n    fieldsStream.seek(position);\n\n    Document doc = new Document();\n    int numFields = fieldsStream.readVInt();\n    for (int i = 0; i < numFields; i++) {\n      int fieldNumber = fieldsStream.readVInt();\n      FieldInfo fi = fieldInfos.fieldInfo(fieldNumber);\n      FieldSelectorResult acceptField = fieldSelector == null ? FieldSelectorResult.LOAD : fieldSelector.accept(fi.name);\n      \n      byte bits = fieldsStream.readByte();\n      assert bits <= FieldsWriter.FIELD_IS_TOKENIZED + FieldsWriter.FIELD_IS_BINARY;\n\n      boolean tokenize = (bits & FieldsWriter.FIELD_IS_TOKENIZED) != 0;\n      boolean binary = (bits & FieldsWriter.FIELD_IS_BINARY) != 0;\n      //TODO: Find an alternative approach here if this list continues to grow beyond the\n      //list of 5 or 6 currently here.  See Lucene 762 for discussion\n      if (acceptField.equals(FieldSelectorResult.LOAD)) {\n        addField(doc, fi, binary, tokenize);\n      }\n      else if (acceptField.equals(FieldSelectorResult.LOAD_AND_BREAK)){\n        addField(doc, fi, binary, tokenize);\n        break;//Get out of this loop\n      }\n      else if (acceptField.equals(FieldSelectorResult.LAZY_LOAD)) {\n        addFieldLazy(doc, fi, binary, tokenize, true);\n      }\n      else if (acceptField.equals(FieldSelectorResult.LATENT)) {\n        addFieldLazy(doc, fi, binary, tokenize, false);\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE)){\n        skipField(addFieldSize(doc, fi, binary));\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE_AND_BREAK)){\n        addFieldSize(doc, fi, binary);\n        break;\n      }\n      else {\n        skipField();\n      }\n    }\n\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bb9b72f7c3d7827c64dd4ec580ded81778da361d","date":1295897920,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/FieldsReader#doc(int,FieldSelector).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/FieldsReader#doc(int,FieldSelector).mjava","sourceNew":"  public final Document doc(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {\n    seekIndex(n);\n    long position = indexStream.readLong();\n    fieldsStream.seek(position);\n\n    Document doc = new Document();\n    int numFields = fieldsStream.readVInt();\n    for (int i = 0; i < numFields; i++) {\n      int fieldNumber = fieldsStream.readVInt();\n      FieldInfo fi = fieldInfos.fieldInfo(fieldNumber);\n      FieldSelectorResult acceptField = fieldSelector == null ? FieldSelectorResult.LOAD : fieldSelector.accept(fi.name);\n      \n      byte bits = fieldsStream.readByte();\n      assert bits <= FieldsWriter.FIELD_IS_TOKENIZED + FieldsWriter.FIELD_IS_BINARY;\n\n      boolean tokenize = (bits & FieldsWriter.FIELD_IS_TOKENIZED) != 0;\n      boolean binary = (bits & FieldsWriter.FIELD_IS_BINARY) != 0;\n      //TODO: Find an alternative approach here if this list continues to grow beyond the\n      //list of 5 or 6 currently here.  See Lucene 762 for discussion\n      if (acceptField.equals(FieldSelectorResult.LOAD)) {\n        addField(doc, fi, binary, tokenize);\n      }\n      else if (acceptField.equals(FieldSelectorResult.LOAD_AND_BREAK)){\n        addField(doc, fi, binary, tokenize);\n        break;//Get out of this loop\n      }\n      else if (acceptField.equals(FieldSelectorResult.LAZY_LOAD)) {\n        addFieldLazy(doc, fi, binary, tokenize, true);\n      }\n      else if (acceptField.equals(FieldSelectorResult.LATENT)) {\n        addFieldLazy(doc, fi, binary, tokenize, false);\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE)){\n        skipField(addFieldSize(doc, fi, binary));\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE_AND_BREAK)){\n        addFieldSize(doc, fi, binary);\n        break;\n      }\n      else {\n        skipField();\n      }\n    }\n\n    return doc;\n  }\n\n","sourceOld":"  final Document doc(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {\n    seekIndex(n);\n    long position = indexStream.readLong();\n    fieldsStream.seek(position);\n\n    Document doc = new Document();\n    int numFields = fieldsStream.readVInt();\n    for (int i = 0; i < numFields; i++) {\n      int fieldNumber = fieldsStream.readVInt();\n      FieldInfo fi = fieldInfos.fieldInfo(fieldNumber);\n      FieldSelectorResult acceptField = fieldSelector == null ? FieldSelectorResult.LOAD : fieldSelector.accept(fi.name);\n      \n      byte bits = fieldsStream.readByte();\n      assert bits <= FieldsWriter.FIELD_IS_TOKENIZED + FieldsWriter.FIELD_IS_BINARY;\n\n      boolean tokenize = (bits & FieldsWriter.FIELD_IS_TOKENIZED) != 0;\n      boolean binary = (bits & FieldsWriter.FIELD_IS_BINARY) != 0;\n      //TODO: Find an alternative approach here if this list continues to grow beyond the\n      //list of 5 or 6 currently here.  See Lucene 762 for discussion\n      if (acceptField.equals(FieldSelectorResult.LOAD)) {\n        addField(doc, fi, binary, tokenize);\n      }\n      else if (acceptField.equals(FieldSelectorResult.LOAD_AND_BREAK)){\n        addField(doc, fi, binary, tokenize);\n        break;//Get out of this loop\n      }\n      else if (acceptField.equals(FieldSelectorResult.LAZY_LOAD)) {\n        addFieldLazy(doc, fi, binary, tokenize, true);\n      }\n      else if (acceptField.equals(FieldSelectorResult.LATENT)) {\n        addFieldLazy(doc, fi, binary, tokenize, false);\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE)){\n        skipField(addFieldSize(doc, fi, binary));\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE_AND_BREAK)){\n        addFieldSize(doc, fi, binary);\n        break;\n      }\n      else {\n        skipField();\n      }\n    }\n\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/FieldsReader#doc(int,FieldSelector).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/FieldsReader#doc(int,FieldSelector).mjava","sourceNew":"  public final Document doc(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {\n    seekIndex(n);\n    long position = indexStream.readLong();\n    fieldsStream.seek(position);\n\n    Document doc = new Document();\n    int numFields = fieldsStream.readVInt();\n    for (int i = 0; i < numFields; i++) {\n      int fieldNumber = fieldsStream.readVInt();\n      FieldInfo fi = fieldInfos.fieldInfo(fieldNumber);\n      FieldSelectorResult acceptField = fieldSelector == null ? FieldSelectorResult.LOAD : fieldSelector.accept(fi.name);\n      \n      byte bits = fieldsStream.readByte();\n      assert bits <= FieldsWriter.FIELD_IS_TOKENIZED + FieldsWriter.FIELD_IS_BINARY;\n\n      boolean tokenize = (bits & FieldsWriter.FIELD_IS_TOKENIZED) != 0;\n      boolean binary = (bits & FieldsWriter.FIELD_IS_BINARY) != 0;\n      //TODO: Find an alternative approach here if this list continues to grow beyond the\n      //list of 5 or 6 currently here.  See Lucene 762 for discussion\n      if (acceptField.equals(FieldSelectorResult.LOAD)) {\n        addField(doc, fi, binary, tokenize);\n      }\n      else if (acceptField.equals(FieldSelectorResult.LOAD_AND_BREAK)){\n        addField(doc, fi, binary, tokenize);\n        break;//Get out of this loop\n      }\n      else if (acceptField.equals(FieldSelectorResult.LAZY_LOAD)) {\n        addFieldLazy(doc, fi, binary, tokenize, true);\n      }\n      else if (acceptField.equals(FieldSelectorResult.LATENT)) {\n        addFieldLazy(doc, fi, binary, tokenize, false);\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE)){\n        skipField(addFieldSize(doc, fi, binary));\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE_AND_BREAK)){\n        addFieldSize(doc, fi, binary);\n        break;\n      }\n      else {\n        skipField();\n      }\n    }\n\n    return doc;\n  }\n\n","sourceOld":"  final Document doc(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {\n    seekIndex(n);\n    long position = indexStream.readLong();\n    fieldsStream.seek(position);\n\n    Document doc = new Document();\n    int numFields = fieldsStream.readVInt();\n    for (int i = 0; i < numFields; i++) {\n      int fieldNumber = fieldsStream.readVInt();\n      FieldInfo fi = fieldInfos.fieldInfo(fieldNumber);\n      FieldSelectorResult acceptField = fieldSelector == null ? FieldSelectorResult.LOAD : fieldSelector.accept(fi.name);\n      \n      byte bits = fieldsStream.readByte();\n      assert bits <= FieldsWriter.FIELD_IS_TOKENIZED + FieldsWriter.FIELD_IS_BINARY;\n\n      boolean tokenize = (bits & FieldsWriter.FIELD_IS_TOKENIZED) != 0;\n      boolean binary = (bits & FieldsWriter.FIELD_IS_BINARY) != 0;\n      //TODO: Find an alternative approach here if this list continues to grow beyond the\n      //list of 5 or 6 currently here.  See Lucene 762 for discussion\n      if (acceptField.equals(FieldSelectorResult.LOAD)) {\n        addField(doc, fi, binary, tokenize);\n      }\n      else if (acceptField.equals(FieldSelectorResult.LOAD_AND_BREAK)){\n        addField(doc, fi, binary, tokenize);\n        break;//Get out of this loop\n      }\n      else if (acceptField.equals(FieldSelectorResult.LAZY_LOAD)) {\n        addFieldLazy(doc, fi, binary, tokenize, true);\n      }\n      else if (acceptField.equals(FieldSelectorResult.LATENT)) {\n        addFieldLazy(doc, fi, binary, tokenize, false);\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE)){\n        skipField(addFieldSize(doc, fi, binary));\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE_AND_BREAK)){\n        addFieldSize(doc, fi, binary);\n        break;\n      }\n      else {\n        skipField();\n      }\n    }\n\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab0e9f7ce724e6aea1fea746dded19e76d231cf8","date":1304774078,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/FieldsReader#doc(int,FieldSelector).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/FieldsReader#doc(int,FieldSelector).mjava","sourceNew":"  public final Document doc(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {\n    seekIndex(n);\n    long position = indexStream.readLong();\n    fieldsStream.seek(position);\n\n    Document doc = new Document();\n    int numFields = fieldsStream.readVInt();\n    out: for (int i = 0; i < numFields; i++) {\n      int fieldNumber = fieldsStream.readVInt();\n      FieldInfo fi = fieldInfos.fieldInfo(fieldNumber);\n      FieldSelectorResult acceptField = fieldSelector == null ? FieldSelectorResult.LOAD : fieldSelector.accept(fi.name);\n      \n      int bits = fieldsStream.readByte() & 0xFF;\n      assert bits <= (FieldsWriter.FIELD_IS_NUMERIC_MASK | FieldsWriter.FIELD_IS_TOKENIZED | FieldsWriter.FIELD_IS_BINARY): \"bits=\" + Integer.toHexString(bits);\n\n      boolean tokenize = (bits & FieldsWriter.FIELD_IS_TOKENIZED) != 0;\n      boolean binary = (bits & FieldsWriter.FIELD_IS_BINARY) != 0;\n      final int numeric = bits & FieldsWriter.FIELD_IS_NUMERIC_MASK;\n\n      switch (acceptField) {\n        case LOAD:\n          addField(doc, fi, binary, tokenize, numeric);\n          break;\n        case LOAD_AND_BREAK:\n          addField(doc, fi, binary, tokenize, numeric);\n          break out; //Get out of this loop\n        case LAZY_LOAD:\n          addFieldLazy(doc, fi, binary, tokenize, true, numeric);\n          break;\n        case LATENT:\n          addFieldLazy(doc, fi, binary, tokenize, false, numeric);\n          break;\n        case SIZE:\n          skipFieldBytes(addFieldSize(doc, fi, binary, numeric));\n          break;\n        case SIZE_AND_BREAK:\n          addFieldSize(doc, fi, binary, numeric);\n          break out; //Get out of this loop\n        default:\n          skipField(numeric);\n      }\n    }\n\n    return doc;\n  }\n\n","sourceOld":"  public final Document doc(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {\n    seekIndex(n);\n    long position = indexStream.readLong();\n    fieldsStream.seek(position);\n\n    Document doc = new Document();\n    int numFields = fieldsStream.readVInt();\n    for (int i = 0; i < numFields; i++) {\n      int fieldNumber = fieldsStream.readVInt();\n      FieldInfo fi = fieldInfos.fieldInfo(fieldNumber);\n      FieldSelectorResult acceptField = fieldSelector == null ? FieldSelectorResult.LOAD : fieldSelector.accept(fi.name);\n      \n      byte bits = fieldsStream.readByte();\n      assert bits <= FieldsWriter.FIELD_IS_TOKENIZED + FieldsWriter.FIELD_IS_BINARY;\n\n      boolean tokenize = (bits & FieldsWriter.FIELD_IS_TOKENIZED) != 0;\n      boolean binary = (bits & FieldsWriter.FIELD_IS_BINARY) != 0;\n      //TODO: Find an alternative approach here if this list continues to grow beyond the\n      //list of 5 or 6 currently here.  See Lucene 762 for discussion\n      if (acceptField.equals(FieldSelectorResult.LOAD)) {\n        addField(doc, fi, binary, tokenize);\n      }\n      else if (acceptField.equals(FieldSelectorResult.LOAD_AND_BREAK)){\n        addField(doc, fi, binary, tokenize);\n        break;//Get out of this loop\n      }\n      else if (acceptField.equals(FieldSelectorResult.LAZY_LOAD)) {\n        addFieldLazy(doc, fi, binary, tokenize, true);\n      }\n      else if (acceptField.equals(FieldSelectorResult.LATENT)) {\n        addFieldLazy(doc, fi, binary, tokenize, false);\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE)){\n        skipField(addFieldSize(doc, fi, binary));\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE_AND_BREAK)){\n        addFieldSize(doc, fi, binary);\n        break;\n      }\n      else {\n        skipField();\n      }\n    }\n\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c700f8d0842d3e52bb2bdfbfdc046a137e836edb","date":1305285499,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/FieldsReader#doc(int,FieldSelector).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/FieldsReader#doc(int,FieldSelector).mjava","sourceNew":"  public final Document doc(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {\n    seekIndex(n);\n    long position = indexStream.readLong();\n    fieldsStream.seek(position);\n\n    Document doc = new Document();\n    int numFields = fieldsStream.readVInt();\n    out: for (int i = 0; i < numFields; i++) {\n      int fieldNumber = fieldsStream.readVInt();\n      FieldInfo fi = fieldInfos.fieldInfo(fieldNumber);\n      FieldSelectorResult acceptField = fieldSelector == null ? FieldSelectorResult.LOAD : fieldSelector.accept(fi.name);\n      \n      int bits = fieldsStream.readByte() & 0xFF;\n      assert bits <= (FieldsWriter.FIELD_IS_NUMERIC_MASK | FieldsWriter.FIELD_IS_TOKENIZED | FieldsWriter.FIELD_IS_BINARY): \"bits=\" + Integer.toHexString(bits);\n\n      boolean tokenize = (bits & FieldsWriter.FIELD_IS_TOKENIZED) != 0;\n      boolean binary = (bits & FieldsWriter.FIELD_IS_BINARY) != 0;\n      final int numeric = bits & FieldsWriter.FIELD_IS_NUMERIC_MASK;\n\n      switch (acceptField) {\n        case LOAD:\n          addField(doc, fi, binary, tokenize, numeric);\n          break;\n        case LOAD_AND_BREAK:\n          addField(doc, fi, binary, tokenize, numeric);\n          break out; //Get out of this loop\n        case LAZY_LOAD:\n          addFieldLazy(doc, fi, binary, tokenize, true, numeric);\n          break;\n        case LATENT:\n          addFieldLazy(doc, fi, binary, tokenize, false, numeric);\n          break;\n        case SIZE:\n          skipFieldBytes(addFieldSize(doc, fi, binary, numeric));\n          break;\n        case SIZE_AND_BREAK:\n          addFieldSize(doc, fi, binary, numeric);\n          break out; //Get out of this loop\n        default:\n          skipField(numeric);\n      }\n    }\n\n    return doc;\n  }\n\n","sourceOld":"  public final Document doc(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {\n    seekIndex(n);\n    long position = indexStream.readLong();\n    fieldsStream.seek(position);\n\n    Document doc = new Document();\n    int numFields = fieldsStream.readVInt();\n    for (int i = 0; i < numFields; i++) {\n      int fieldNumber = fieldsStream.readVInt();\n      FieldInfo fi = fieldInfos.fieldInfo(fieldNumber);\n      FieldSelectorResult acceptField = fieldSelector == null ? FieldSelectorResult.LOAD : fieldSelector.accept(fi.name);\n      \n      byte bits = fieldsStream.readByte();\n      assert bits <= FieldsWriter.FIELD_IS_TOKENIZED + FieldsWriter.FIELD_IS_BINARY;\n\n      boolean tokenize = (bits & FieldsWriter.FIELD_IS_TOKENIZED) != 0;\n      boolean binary = (bits & FieldsWriter.FIELD_IS_BINARY) != 0;\n      //TODO: Find an alternative approach here if this list continues to grow beyond the\n      //list of 5 or 6 currently here.  See Lucene 762 for discussion\n      if (acceptField.equals(FieldSelectorResult.LOAD)) {\n        addField(doc, fi, binary, tokenize);\n      }\n      else if (acceptField.equals(FieldSelectorResult.LOAD_AND_BREAK)){\n        addField(doc, fi, binary, tokenize);\n        break;//Get out of this loop\n      }\n      else if (acceptField.equals(FieldSelectorResult.LAZY_LOAD)) {\n        addFieldLazy(doc, fi, binary, tokenize, true);\n      }\n      else if (acceptField.equals(FieldSelectorResult.LATENT)) {\n        addFieldLazy(doc, fi, binary, tokenize, false);\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE)){\n        skipField(addFieldSize(doc, fi, binary));\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE_AND_BREAK)){\n        addFieldSize(doc, fi, binary);\n        break;\n      }\n      else {\n        skipField();\n      }\n    }\n\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/FieldsReader#doc(int,FieldSelector).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/FieldsReader#doc(int,FieldSelector).mjava","sourceNew":"  public final Document doc(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {\n    seekIndex(n);\n    long position = indexStream.readLong();\n    fieldsStream.seek(position);\n\n    Document doc = new Document();\n    int numFields = fieldsStream.readVInt();\n    out: for (int i = 0; i < numFields; i++) {\n      int fieldNumber = fieldsStream.readVInt();\n      FieldInfo fi = fieldInfos.fieldInfo(fieldNumber);\n      FieldSelectorResult acceptField = fieldSelector == null ? FieldSelectorResult.LOAD : fieldSelector.accept(fi.name);\n      \n      int bits = fieldsStream.readByte() & 0xFF;\n      assert bits <= (FieldsWriter.FIELD_IS_NUMERIC_MASK | FieldsWriter.FIELD_IS_TOKENIZED | FieldsWriter.FIELD_IS_BINARY): \"bits=\" + Integer.toHexString(bits);\n\n      boolean tokenize = (bits & FieldsWriter.FIELD_IS_TOKENIZED) != 0;\n      boolean binary = (bits & FieldsWriter.FIELD_IS_BINARY) != 0;\n      final int numeric = bits & FieldsWriter.FIELD_IS_NUMERIC_MASK;\n\n      switch (acceptField) {\n        case LOAD:\n          addField(doc, fi, binary, tokenize, numeric);\n          break;\n        case LOAD_AND_BREAK:\n          addField(doc, fi, binary, tokenize, numeric);\n          break out; //Get out of this loop\n        case LAZY_LOAD:\n          addFieldLazy(doc, fi, binary, tokenize, true, numeric);\n          break;\n        case LATENT:\n          addFieldLazy(doc, fi, binary, tokenize, false, numeric);\n          break;\n        case SIZE:\n          skipFieldBytes(addFieldSize(doc, fi, binary, numeric));\n          break;\n        case SIZE_AND_BREAK:\n          addFieldSize(doc, fi, binary, numeric);\n          break out; //Get out of this loop\n        default:\n          skipField(numeric);\n      }\n    }\n\n    return doc;\n  }\n\n","sourceOld":"  public final Document doc(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {\n    seekIndex(n);\n    long position = indexStream.readLong();\n    fieldsStream.seek(position);\n\n    Document doc = new Document();\n    int numFields = fieldsStream.readVInt();\n    for (int i = 0; i < numFields; i++) {\n      int fieldNumber = fieldsStream.readVInt();\n      FieldInfo fi = fieldInfos.fieldInfo(fieldNumber);\n      FieldSelectorResult acceptField = fieldSelector == null ? FieldSelectorResult.LOAD : fieldSelector.accept(fi.name);\n      \n      byte bits = fieldsStream.readByte();\n      assert bits <= FieldsWriter.FIELD_IS_TOKENIZED + FieldsWriter.FIELD_IS_BINARY;\n\n      boolean tokenize = (bits & FieldsWriter.FIELD_IS_TOKENIZED) != 0;\n      boolean binary = (bits & FieldsWriter.FIELD_IS_BINARY) != 0;\n      //TODO: Find an alternative approach here if this list continues to grow beyond the\n      //list of 5 or 6 currently here.  See Lucene 762 for discussion\n      if (acceptField.equals(FieldSelectorResult.LOAD)) {\n        addField(doc, fi, binary, tokenize);\n      }\n      else if (acceptField.equals(FieldSelectorResult.LOAD_AND_BREAK)){\n        addField(doc, fi, binary, tokenize);\n        break;//Get out of this loop\n      }\n      else if (acceptField.equals(FieldSelectorResult.LAZY_LOAD)) {\n        addFieldLazy(doc, fi, binary, tokenize, true);\n      }\n      else if (acceptField.equals(FieldSelectorResult.LATENT)) {\n        addFieldLazy(doc, fi, binary, tokenize, false);\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE)){\n        skipField(addFieldSize(doc, fi, binary));\n      }\n      else if (acceptField.equals(FieldSelectorResult.SIZE_AND_BREAK)){\n        addFieldSize(doc, fi, binary);\n        break;\n      }\n      else {\n        skipField();\n      }\n    }\n\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":4,"author":"Michael McCandless","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/FieldsReader#doc(int,FieldSelector).mjava","sourceNew":null,"sourceOld":"  public final Document doc(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {\n    seekIndex(n);\n    long position = indexStream.readLong();\n    fieldsStream.seek(position);\n\n    Document doc = new Document();\n    int numFields = fieldsStream.readVInt();\n    out: for (int i = 0; i < numFields; i++) {\n      int fieldNumber = fieldsStream.readVInt();\n      FieldInfo fi = fieldInfos.fieldInfo(fieldNumber);\n      FieldSelectorResult acceptField = fieldSelector == null ? FieldSelectorResult.LOAD : fieldSelector.accept(fi.name);\n      \n      int bits = fieldsStream.readByte() & 0xFF;\n      assert bits <= (FieldsWriter.FIELD_IS_NUMERIC_MASK | FieldsWriter.FIELD_IS_TOKENIZED | FieldsWriter.FIELD_IS_BINARY): \"bits=\" + Integer.toHexString(bits);\n\n      boolean tokenize = (bits & FieldsWriter.FIELD_IS_TOKENIZED) != 0;\n      boolean binary = (bits & FieldsWriter.FIELD_IS_BINARY) != 0;\n      final int numeric = bits & FieldsWriter.FIELD_IS_NUMERIC_MASK;\n\n      switch (acceptField) {\n        case LOAD:\n          addField(doc, fi, binary, tokenize, numeric);\n          break;\n        case LOAD_AND_BREAK:\n          addField(doc, fi, binary, tokenize, numeric);\n          break out; //Get out of this loop\n        case LAZY_LOAD:\n          addFieldLazy(doc, fi, binary, tokenize, true, numeric);\n          break;\n        case LATENT:\n          addFieldLazy(doc, fi, binary, tokenize, false, numeric);\n          break;\n        case SIZE:\n          skipFieldBytes(addFieldSize(doc, fi, binary, numeric));\n          break;\n        case SIZE_AND_BREAK:\n          addFieldSize(doc, fi, binary, numeric);\n          break out; //Get out of this loop\n        default:\n          skipField(numeric);\n      }\n    }\n\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b9dc373b96fc96e6300e2f5af947f6998e6aa6a6":["4418b107fc5055dc1da859aad224aa49d90ba706"],"ab0e9f7ce724e6aea1fea746dded19e76d231cf8":["b9dc373b96fc96e6300e2f5af947f6998e6aa6a6"],"4418b107fc5055dc1da859aad224aa49d90ba706":["371bbd52cb908c7640086aa3aec5880542b81060"],"371bbd52cb908c7640086aa3aec5880542b81060":["6267e1ce56c2eec111425690cd04e251b6f14952"],"5f4e87790277826a2aea119328600dfb07761f32":["6267e1ce56c2eec111425690cd04e251b6f14952","4418b107fc5055dc1da859aad224aa49d90ba706"],"bb9b72f7c3d7827c64dd4ec580ded81778da361d":["5f4e87790277826a2aea119328600dfb07761f32","b9dc373b96fc96e6300e2f5af947f6998e6aa6a6"],"6267e1ce56c2eec111425690cd04e251b6f14952":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a3776dccca01c11e7046323cfad46a3b4a471233":["b9dc373b96fc96e6300e2f5af947f6998e6aa6a6","ab0e9f7ce724e6aea1fea746dded19e76d231cf8"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["4418b107fc5055dc1da859aad224aa49d90ba706","b9dc373b96fc96e6300e2f5af947f6998e6aa6a6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":["29ef99d61cda9641b6250bf9567329a6e65f901d","ab0e9f7ce724e6aea1fea746dded19e76d231cf8"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["ab0e9f7ce724e6aea1fea746dded19e76d231cf8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"b9dc373b96fc96e6300e2f5af947f6998e6aa6a6":["ab0e9f7ce724e6aea1fea746dded19e76d231cf8","bb9b72f7c3d7827c64dd4ec580ded81778da361d","a3776dccca01c11e7046323cfad46a3b4a471233","29ef99d61cda9641b6250bf9567329a6e65f901d"],"ab0e9f7ce724e6aea1fea746dded19e76d231cf8":["a3776dccca01c11e7046323cfad46a3b4a471233","c700f8d0842d3e52bb2bdfbfdc046a137e836edb","1509f151d7692d84fae414b2b799ac06ba60fcb4"],"4418b107fc5055dc1da859aad224aa49d90ba706":["b9dc373b96fc96e6300e2f5af947f6998e6aa6a6","5f4e87790277826a2aea119328600dfb07761f32","29ef99d61cda9641b6250bf9567329a6e65f901d"],"371bbd52cb908c7640086aa3aec5880542b81060":["4418b107fc5055dc1da859aad224aa49d90ba706"],"5f4e87790277826a2aea119328600dfb07761f32":["bb9b72f7c3d7827c64dd4ec580ded81778da361d"],"bb9b72f7c3d7827c64dd4ec580ded81778da361d":[],"6267e1ce56c2eec111425690cd04e251b6f14952":["371bbd52cb908c7640086aa3aec5880542b81060","5f4e87790277826a2aea119328600dfb07761f32"],"a3776dccca01c11e7046323cfad46a3b4a471233":[],"29ef99d61cda9641b6250bf9567329a6e65f901d":["c700f8d0842d3e52bb2bdfbfdc046a137e836edb"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":[],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["6267e1ce56c2eec111425690cd04e251b6f14952"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["bb9b72f7c3d7827c64dd4ec580ded81778da361d","a3776dccca01c11e7046323cfad46a3b4a471233","c700f8d0842d3e52bb2bdfbfdc046a137e836edb","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}