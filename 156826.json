{"path":"solr/src/java/org/apache/solr/handler/component/SpellCheckComponent#getTokens(String,Analyzer).mjava","commits":[{"id":"893269407f5c988a4b2ee13c7ffc01ec43136c1d","date":1268598046,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/SpellCheckComponent#getTokens(String,Analyzer).mjava","pathOld":"/dev/null","sourceNew":"  private Collection<Token> getTokens(String q, Analyzer analyzer) throws IOException {\n    Collection<Token> result = new ArrayList<Token>();\n    Token token = null;\n    TokenStream ts = analyzer.reusableTokenStream(\"\", new StringReader(q));\n    ts.reset();\n    while ((token = ts.next()) != null){\n      result.add(token);\n    }\n    return result;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","date":1268599006,"type":4,"author":"Mark Robert Miller","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/src/java/org/apache/solr/handler/component/SpellCheckComponent#getTokens(String,Analyzer).mjava","sourceNew":null,"sourceOld":"  private Collection<Token> getTokens(String q, Analyzer analyzer) throws IOException {\n    Collection<Token> result = new ArrayList<Token>();\n    Token token = null;\n    TokenStream ts = analyzer.reusableTokenStream(\"\", new StringReader(q));\n    ts.reset();\n    while ((token = ts.next()) != null){\n      result.add(token);\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/SpellCheckComponent#getTokens(String,Analyzer).mjava","pathOld":"src/java/org/apache/solr/handler/component/SpellCheckComponent#getTokens(String,Analyzer).mjava","sourceNew":"  private Collection<Token> getTokens(String q, Analyzer analyzer) throws IOException {\n    Collection<Token> result = new ArrayList<Token>();\n    TokenStream ts = analyzer.reusableTokenStream(\"\", new StringReader(q));\n    ts.reset();\n    // TODO: support custom attributes\n    TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);\n    OffsetAttribute offsetAtt = (OffsetAttribute) ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = (TypeAttribute) ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = (FlagsAttribute) ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = (PayloadAttribute) ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = (PositionIncrementAttribute) ts.addAttribute(PositionIncrementAttribute.class);\n    \n    while (ts.incrementToken()){\n      Token token = new Token();\n      token.setTermBuffer(termAtt.termBuffer(), 0, termAtt.termLength());\n      token.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n      token.setType(typeAtt.type());\n      token.setFlags(flagsAtt.getFlags());\n      token.setPayload(payloadAtt.getPayload());\n      token.setPositionIncrement(posIncAtt.getPositionIncrement());\n      result.add(token);\n    }\n    return result;\n  }\n\n","sourceOld":"  private Collection<Token> getTokens(String q, Analyzer analyzer) throws IOException {\n    Collection<Token> result = new ArrayList<Token>();\n    TokenStream ts = analyzer.reusableTokenStream(\"\", new StringReader(q));\n    ts.reset();\n    // TODO: support custom attributes\n    TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);\n    OffsetAttribute offsetAtt = (OffsetAttribute) ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = (TypeAttribute) ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = (FlagsAttribute) ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = (PayloadAttribute) ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = (PositionIncrementAttribute) ts.addAttribute(PositionIncrementAttribute.class);\n    \n    while (ts.incrementToken()){\n      Token token = new Token();\n      token.setTermBuffer(termAtt.termBuffer(), 0, termAtt.termLength());\n      token.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n      token.setType(typeAtt.type());\n      token.setFlags(flagsAtt.getFlags());\n      token.setPayload(payloadAtt.getPayload());\n      token.setPositionIncrement(posIncAtt.getPositionIncrement());\n      result.add(token);\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1da8d55113b689b06716246649de6f62430f15c0","date":1453508340,"type":0,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/component/SpellCheckComponent#getTokens(String,Analyzer).mjava","pathOld":"/dev/null","sourceNew":"  private Collection<Token> getTokens(String q, Analyzer analyzer) throws IOException {\n    Collection<Token> result = new ArrayList<Token>();\n    TokenStream ts = analyzer.reusableTokenStream(\"\", new StringReader(q));\n    ts.reset();\n    // TODO: support custom attributes\n    TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);\n    OffsetAttribute offsetAtt = (OffsetAttribute) ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = (TypeAttribute) ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = (FlagsAttribute) ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = (PayloadAttribute) ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = (PositionIncrementAttribute) ts.addAttribute(PositionIncrementAttribute.class);\n    \n    while (ts.incrementToken()){\n      Token token = new Token();\n      token.setTermBuffer(termAtt.termBuffer(), 0, termAtt.termLength());\n      token.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n      token.setType(typeAtt.type());\n      token.setFlags(flagsAtt.getFlags());\n      token.setPayload(payloadAtt.getPayload());\n      token.setPositionIncrement(posIncAtt.getPositionIncrement());\n      result.add(token);\n    }\n    return result;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d085fb336a7208eea2214e5ffcc803960819b60b","date":1270981894,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/SpellCheckComponent#getTokens(String,Analyzer).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/SpellCheckComponent#getTokens(String,Analyzer).mjava","sourceNew":"  private Collection<Token> getTokens(String q, Analyzer analyzer) throws IOException {\n    Collection<Token> result = new ArrayList<Token>();\n    TokenStream ts = analyzer.reusableTokenStream(\"\", new StringReader(q));\n    ts.reset();\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n    \n    while (ts.incrementToken()){\n      Token token = new Token();\n      token.setTermBuffer(termAtt.buffer(), 0, termAtt.length());\n      token.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n      token.setType(typeAtt.type());\n      token.setFlags(flagsAtt.getFlags());\n      token.setPayload(payloadAtt.getPayload());\n      token.setPositionIncrement(posIncAtt.getPositionIncrement());\n      result.add(token);\n    }\n    return result;\n  }\n\n","sourceOld":"  private Collection<Token> getTokens(String q, Analyzer analyzer) throws IOException {\n    Collection<Token> result = new ArrayList<Token>();\n    TokenStream ts = analyzer.reusableTokenStream(\"\", new StringReader(q));\n    ts.reset();\n    // TODO: support custom attributes\n    TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);\n    OffsetAttribute offsetAtt = (OffsetAttribute) ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = (TypeAttribute) ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = (FlagsAttribute) ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = (PayloadAttribute) ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = (PositionIncrementAttribute) ts.addAttribute(PositionIncrementAttribute.class);\n    \n    while (ts.incrementToken()){\n      Token token = new Token();\n      token.setTermBuffer(termAtt.termBuffer(), 0, termAtt.termLength());\n      token.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n      token.setType(typeAtt.type());\n      token.setFlags(flagsAtt.getFlags());\n      token.setPayload(payloadAtt.getPayload());\n      token.setPositionIncrement(posIncAtt.getPositionIncrement());\n      result.add(token);\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":["782ed6a4b4ba50ec19734fc8db4e570ee193d627","782ed6a4b4ba50ec19734fc8db4e570ee193d627","782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a7347509fad0711ac30cb15a746e9a3830a38ebd","date":1275388513,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/SpellCheckComponent#getTokens(String,Analyzer).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/SpellCheckComponent#getTokens(String,Analyzer).mjava","sourceNew":"  private Collection<Token> getTokens(String q, Analyzer analyzer) throws IOException {\n    Collection<Token> result = new ArrayList<Token>();\n    TokenStream ts = analyzer.reusableTokenStream(\"\", new StringReader(q));\n    ts.reset();\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n    \n    while (ts.incrementToken()){\n      Token token = new Token();\n      token.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n      token.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n      token.setType(typeAtt.type());\n      token.setFlags(flagsAtt.getFlags());\n      token.setPayload(payloadAtt.getPayload());\n      token.setPositionIncrement(posIncAtt.getPositionIncrement());\n      result.add(token);\n    }\n    return result;\n  }\n\n","sourceOld":"  private Collection<Token> getTokens(String q, Analyzer analyzer) throws IOException {\n    Collection<Token> result = new ArrayList<Token>();\n    TokenStream ts = analyzer.reusableTokenStream(\"\", new StringReader(q));\n    ts.reset();\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n    \n    while (ts.incrementToken()){\n      Token token = new Token();\n      token.setTermBuffer(termAtt.buffer(), 0, termAtt.length());\n      token.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n      token.setType(typeAtt.type());\n      token.setFlags(flagsAtt.getFlags());\n      token.setPayload(payloadAtt.getPayload());\n      token.setPositionIncrement(posIncAtt.getPositionIncrement());\n      result.add(token);\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":["782ed6a4b4ba50ec19734fc8db4e570ee193d627","782ed6a4b4ba50ec19734fc8db4e570ee193d627","782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/SpellCheckComponent#getTokens(String,Analyzer).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/SpellCheckComponent#getTokens(String,Analyzer).mjava","sourceNew":"  private Collection<Token> getTokens(String q, Analyzer analyzer) throws IOException {\n    Collection<Token> result = new ArrayList<Token>();\n    TokenStream ts = analyzer.reusableTokenStream(\"\", new StringReader(q));\n    ts.reset();\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n    \n    while (ts.incrementToken()){\n      Token token = new Token();\n      token.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n      token.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n      token.setType(typeAtt.type());\n      token.setFlags(flagsAtt.getFlags());\n      token.setPayload(payloadAtt.getPayload());\n      token.setPositionIncrement(posIncAtt.getPositionIncrement());\n      result.add(token);\n    }\n    return result;\n  }\n\n","sourceOld":"  private Collection<Token> getTokens(String q, Analyzer analyzer) throws IOException {\n    Collection<Token> result = new ArrayList<Token>();\n    TokenStream ts = analyzer.reusableTokenStream(\"\", new StringReader(q));\n    ts.reset();\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n    \n    while (ts.incrementToken()){\n      Token token = new Token();\n      token.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n      token.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n      token.setType(typeAtt.type());\n      token.setFlags(flagsAtt.getFlags());\n      token.setPayload(payloadAtt.getPayload());\n      token.setPositionIncrement(posIncAtt.getPositionIncrement());\n      result.add(token);\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/SpellCheckComponent#getTokens(String,Analyzer).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/SpellCheckComponent#getTokens(String,Analyzer).mjava","sourceNew":"  private Collection<Token> getTokens(String q, Analyzer analyzer) throws IOException {\n    Collection<Token> result = new ArrayList<Token>();\n    TokenStream ts = analyzer.reusableTokenStream(\"\", new StringReader(q));\n    ts.reset();\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n    \n    while (ts.incrementToken()){\n      Token token = new Token();\n      token.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n      token.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n      token.setType(typeAtt.type());\n      token.setFlags(flagsAtt.getFlags());\n      token.setPayload(payloadAtt.getPayload());\n      token.setPositionIncrement(posIncAtt.getPositionIncrement());\n      result.add(token);\n    }\n    return result;\n  }\n\n","sourceOld":"  private Collection<Token> getTokens(String q, Analyzer analyzer) throws IOException {\n    Collection<Token> result = new ArrayList<Token>();\n    TokenStream ts = analyzer.reusableTokenStream(\"\", new StringReader(q));\n    ts.reset();\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n    \n    while (ts.incrementToken()){\n      Token token = new Token();\n      token.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n      token.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n      token.setType(typeAtt.type());\n      token.setFlags(flagsAtt.getFlags());\n      token.setPayload(payloadAtt.getPayload());\n      token.setPositionIncrement(posIncAtt.getPositionIncrement());\n      result.add(token);\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/SpellCheckComponent#getTokens(String,Analyzer).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/SpellCheckComponent#getTokens(String,Analyzer).mjava","sourceNew":"  private Collection<Token> getTokens(String q, Analyzer analyzer) throws IOException {\n    Collection<Token> result = new ArrayList<Token>();\n    TokenStream ts = analyzer.reusableTokenStream(\"\", new StringReader(q));\n    ts.reset();\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n    \n    while (ts.incrementToken()){\n      Token token = new Token();\n      token.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n      token.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n      token.setType(typeAtt.type());\n      token.setFlags(flagsAtt.getFlags());\n      token.setPayload(payloadAtt.getPayload());\n      token.setPositionIncrement(posIncAtt.getPositionIncrement());\n      result.add(token);\n    }\n    return result;\n  }\n\n","sourceOld":"  private Collection<Token> getTokens(String q, Analyzer analyzer) throws IOException {\n    Collection<Token> result = new ArrayList<Token>();\n    TokenStream ts = analyzer.reusableTokenStream(\"\", new StringReader(q));\n    ts.reset();\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    TypeAttribute typeAtt = ts.addAttribute(TypeAttribute.class);\n    FlagsAttribute flagsAtt = ts.addAttribute(FlagsAttribute.class);\n    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n    \n    while (ts.incrementToken()){\n      Token token = new Token();\n      token.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n      token.setOffset(offsetAtt.startOffset(), offsetAtt.endOffset());\n      token.setType(typeAtt.type());\n      token.setFlags(flagsAtt.getFlags());\n      token.setPayload(payloadAtt.getPayload());\n      token.setPositionIncrement(posIncAtt.getPositionIncrement());\n      result.add(token);\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"1da8d55113b689b06716246649de6f62430f15c0":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","ad94625fb8d088209f46650c8097196fec67f00c"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["a7347509fad0711ac30cb15a746e9a3830a38ebd"],"c26f00b574427b55127e869b935845554afde1fa":["a7347509fad0711ac30cb15a746e9a3830a38ebd","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"a258fbb26824fd104ed795e5d9033d2d040049ee":["a7347509fad0711ac30cb15a746e9a3830a38ebd"],"ad94625fb8d088209f46650c8097196fec67f00c":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"d085fb336a7208eea2214e5ffcc803960819b60b":["1da8d55113b689b06716246649de6f62430f15c0"],"a7347509fad0711ac30cb15a746e9a3830a38ebd":["d085fb336a7208eea2214e5ffcc803960819b60b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c26f00b574427b55127e869b935845554afde1fa"]},"commit2Childs":{"1da8d55113b689b06716246649de6f62430f15c0":["d085fb336a7208eea2214e5ffcc803960819b60b"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["1da8d55113b689b06716246649de6f62430f15c0"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"c26f00b574427b55127e869b935845554afde1fa":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["ad94625fb8d088209f46650c8097196fec67f00c"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"ad94625fb8d088209f46650c8097196fec67f00c":["1da8d55113b689b06716246649de6f62430f15c0"],"d085fb336a7208eea2214e5ffcc803960819b60b":["a7347509fad0711ac30cb15a746e9a3830a38ebd"],"a7347509fad0711ac30cb15a746e9a3830a38ebd":["c903c3d15906a3da96b8c0c2fb704491005fdbdb","c26f00b574427b55127e869b935845554afde1fa","a258fbb26824fd104ed795e5d9033d2d040049ee"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"pathCommit":null}