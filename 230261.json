{"path":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDimensionalValues(SegmentWriteState).mjava","commits":[{"id":"ca792c26af46bd6c4a08d81117c60440cf6a7e3d","date":1445938295,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDimensionalValues(SegmentWriteState).mjava","pathOld":"/dev/null","sourceNew":"  /** Writes all buffered dimensional values. */\n  private void writeDimensionalValues(SegmentWriteState state) throws IOException {\n    DimensionalWriter dimensionalWriter = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.dimensionalValuesWriter != null) {\n            if (perField.fieldInfo.getDimensionCount() == 0) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no dimensional values but wrote them\");\n            }\n            if (dimensionalWriter == null) {\n              // lazy init\n              DimensionalFormat fmt = state.segmentInfo.getCodec().dimensionalFormat();\n              dimensionalWriter = fmt.fieldsWriter(state);\n            }\n\n            perField.dimensionalValuesWriter.flush(state, dimensionalWriter);\n            perField.dimensionalValuesWriter = null;\n          } else if (perField.fieldInfo.getDimensionCount() != 0) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has dimensional values but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dimensionalWriter);\n      } else {\n        IOUtils.closeWhileHandlingException(dimensionalWriter);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1904709ea0185dc04e3d77ea01c79e909caf2796","date":1447006699,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDimensionalValues(SegmentWriteState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDimensionalValues(SegmentWriteState).mjava","sourceNew":"  /** Writes all buffered dimensional values. */\n  private void writeDimensionalValues(SegmentWriteState state) throws IOException {\n    DimensionalWriter dimensionalWriter = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.dimensionalValuesWriter != null) {\n            if (perField.fieldInfo.getDimensionCount() == 0) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no dimensional values but wrote them\");\n            }\n            if (dimensionalWriter == null) {\n              // lazy init\n              DimensionalFormat fmt = state.segmentInfo.getCodec().dimensionalFormat();\n              if (fmt == null) {\n                throw new IllegalStateException(\"field=\\\"\" + perField.fieldInfo.name + \"\\\" was indexed dimensionally but codec does not support dimensional formats\");\n              }\n              dimensionalWriter = fmt.fieldsWriter(state);\n            }\n\n            perField.dimensionalValuesWriter.flush(state, dimensionalWriter);\n            perField.dimensionalValuesWriter = null;\n          } else if (perField.fieldInfo.getDimensionCount() != 0) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has dimensional values but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dimensionalWriter);\n      } else {\n        IOUtils.closeWhileHandlingException(dimensionalWriter);\n      }\n    }\n  }\n\n","sourceOld":"  /** Writes all buffered dimensional values. */\n  private void writeDimensionalValues(SegmentWriteState state) throws IOException {\n    DimensionalWriter dimensionalWriter = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.dimensionalValuesWriter != null) {\n            if (perField.fieldInfo.getDimensionCount() == 0) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no dimensional values but wrote them\");\n            }\n            if (dimensionalWriter == null) {\n              // lazy init\n              DimensionalFormat fmt = state.segmentInfo.getCodec().dimensionalFormat();\n              dimensionalWriter = fmt.fieldsWriter(state);\n            }\n\n            perField.dimensionalValuesWriter.flush(state, dimensionalWriter);\n            perField.dimensionalValuesWriter = null;\n          } else if (perField.fieldInfo.getDimensionCount() != 0) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has dimensional values but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dimensionalWriter);\n      } else {\n        IOUtils.closeWhileHandlingException(dimensionalWriter);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cab7a79353f33d1a94cd307bf33aa5148601ebe6","date":1453391888,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writePoints(SegmentWriteState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDimensionalValues(SegmentWriteState).mjava","sourceNew":"  /** Writes all buffered points. */\n  private void writePoints(SegmentWriteState state) throws IOException {\n    PointWriter pointWriter = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.pointValuesWriter != null) {\n            if (perField.fieldInfo.getPointDimensionCount() == 0) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no points but wrote them\");\n            }\n            if (pointWriter == null) {\n              // lazy init\n              PointFormat fmt = state.segmentInfo.getCodec().pointFormat();\n              if (fmt == null) {\n                throw new IllegalStateException(\"field=\\\"\" + perField.fieldInfo.name + \"\\\" was indexed as points but codec does not support points\");\n              }\n              pointWriter = fmt.fieldsWriter(state);\n            }\n\n            perField.pointValuesWriter.flush(state, pointWriter);\n            perField.pointValuesWriter = null;\n          } else if (perField.fieldInfo.getPointDimensionCount() != 0) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has points but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(pointWriter);\n      } else {\n        IOUtils.closeWhileHandlingException(pointWriter);\n      }\n    }\n  }\n\n","sourceOld":"  /** Writes all buffered dimensional values. */\n  private void writeDimensionalValues(SegmentWriteState state) throws IOException {\n    DimensionalWriter dimensionalWriter = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.dimensionalValuesWriter != null) {\n            if (perField.fieldInfo.getDimensionCount() == 0) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no dimensional values but wrote them\");\n            }\n            if (dimensionalWriter == null) {\n              // lazy init\n              DimensionalFormat fmt = state.segmentInfo.getCodec().dimensionalFormat();\n              if (fmt == null) {\n                throw new IllegalStateException(\"field=\\\"\" + perField.fieldInfo.name + \"\\\" was indexed dimensionally but codec does not support dimensional formats\");\n              }\n              dimensionalWriter = fmt.fieldsWriter(state);\n            }\n\n            perField.dimensionalValuesWriter.flush(state, dimensionalWriter);\n            perField.dimensionalValuesWriter = null;\n          } else if (perField.fieldInfo.getDimensionCount() != 0) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has dimensional values but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dimensionalWriter);\n      } else {\n        IOUtils.closeWhileHandlingException(dimensionalWriter);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["4522ffca5a1f420c6a02198c9332d7c596a30ca5"],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"cab7a79353f33d1a94cd307bf33aa5148601ebe6":["1904709ea0185dc04e3d77ea01c79e909caf2796"],"ca792c26af46bd6c4a08d81117c60440cf6a7e3d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1904709ea0185dc04e3d77ea01c79e909caf2796":["ca792c26af46bd6c4a08d81117c60440cf6a7e3d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["cab7a79353f33d1a94cd307bf33aa5148601ebe6"]},"commit2Childs":{"cab7a79353f33d1a94cd307bf33aa5148601ebe6":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ca792c26af46bd6c4a08d81117c60440cf6a7e3d":["1904709ea0185dc04e3d77ea01c79e909caf2796"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ca792c26af46bd6c4a08d81117c60440cf6a7e3d"],"1904709ea0185dc04e3d77ea01c79e909caf2796":["cab7a79353f33d1a94cd307bf33aa5148601ebe6"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}