{"path":"lucene/src/java/org/apache/lucene/search/ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","commits":[{"id":"744486748bc5bee772100e49230e5bca39bac99a","date":1289776426,"type":0,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n    // Get the enum and start visiting terms.  If we\n    // exhaust the enum before hitting either of the\n    // cutoffs, we use ConstantBooleanQueryRewrite; else,\n    // ConstantFilterRewrite:\n    final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n    final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n    final CutOffTermCollector col = new CutOffTermCollector(docCountCutoff, termCountLimit);\n    collectTerms(reader, query, col);\n    final int size = col.pendingTerms.size();\n    if (col.hasCutOff) {\n      return MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n    } else if (size == 0) {\n      return getTopLevelQuery();\n    } else {\n      final BooleanQuery bq = getTopLevelQuery();\n      final Term placeholderTerm = new Term(query.field);\n      final BytesRefHash pendingTerms = col.pendingTerms;\n      final int sort[] = pendingTerms.sort(col.termsEnum.getComparator());\n      for(int i = 0; i < size; i++) {\n        // docFreq is not used for constant score here, we pass 1\n        // to explicitely set a fake value, so it's not calculated\n        addClause(bq, placeholderTerm.createTerm(pendingTerms.get(sort[i], new BytesRef())), 1, 1.0f);\n      }\n      // Strip scores\n      final Query result = new ConstantScoreQuery(new QueryWrapperFilter(bq));\n      result.setBoost(query.getBoost());\n      query.incTotalNumberOfTerms(size);\n      return result;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9ab1f5591dc05f1f2b5407d809c9699f75554a32","date":1290008586,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/search/ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n    // Get the enum and start visiting terms.  If we\n    // exhaust the enum before hitting either of the\n    // cutoffs, we use ConstantBooleanQueryRewrite; else,\n    // ConstantFilterRewrite:\n    final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n    final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n    final CutOffTermCollector col = new CutOffTermCollector(docCountCutoff, termCountLimit);\n    collectTerms(reader, query, col);\n    final int size = col.pendingTerms.size();\n    if (col.hasCutOff) {\n      return MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n    } else if (size == 0) {\n      return getTopLevelQuery();\n    } else {\n      final BooleanQuery bq = getTopLevelQuery();\n      final Term placeholderTerm = new Term(query.field);\n      final BytesRefHash pendingTerms = col.pendingTerms;\n      final int sort[] = pendingTerms.sort(col.termsEnum.getComparator());\n      for(int i = 0; i < size; i++) {\n        // docFreq is not used for constant score here, we pass 1\n        // to explicitely set a fake value, so it's not calculated\n        addClause(bq, placeholderTerm.createTerm(pendingTerms.get(sort[i], new BytesRef())), 1, 1.0f);\n      }\n      // Strip scores\n      final Query result = new ConstantScoreQuery(new QueryWrapperFilter(bq));\n      result.setBoost(query.getBoost());\n      query.incTotalNumberOfTerms(size);\n      return result;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":0,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/search/ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n    // Get the enum and start visiting terms.  If we\n    // exhaust the enum before hitting either of the\n    // cutoffs, we use ConstantBooleanQueryRewrite; else,\n    // ConstantFilterRewrite:\n    final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n    final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n    final CutOffTermCollector col = new CutOffTermCollector(docCountCutoff, termCountLimit);\n    collectTerms(reader, query, col);\n    final int size = col.pendingTerms.size();\n    if (col.hasCutOff) {\n      return MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n    } else if (size == 0) {\n      return getTopLevelQuery();\n    } else {\n      final BooleanQuery bq = getTopLevelQuery();\n      final Term placeholderTerm = new Term(query.field);\n      final BytesRefHash pendingTerms = col.pendingTerms;\n      final int sort[] = pendingTerms.sort(col.termsEnum.getComparator());\n      for(int i = 0; i < size; i++) {\n        // docFreq is not used for constant score here, we pass 1\n        // to explicitely set a fake value, so it's not calculated\n        addClause(bq, placeholderTerm.createTerm(pendingTerms.get(sort[i], new BytesRef())), 1, 1.0f);\n      }\n      // Strip scores\n      final Query result = new ConstantScoreQuery(new QueryWrapperFilter(bq));\n      result.setBoost(query.getBoost());\n      query.incTotalNumberOfTerms(size);\n      return result;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3e37a877cbb3c0d736bdc1fcb3aea4c24015799f","date":1293976079,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n    // Get the enum and start visiting terms.  If we\n    // exhaust the enum before hitting either of the\n    // cutoffs, we use ConstantBooleanQueryRewrite; else,\n    // ConstantFilterRewrite:\n    final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n    final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n    final CutOffTermCollector col = new CutOffTermCollector(docCountCutoff, termCountLimit);\n    collectTerms(reader, query, col);\n    final int size = col.pendingTerms.size();\n    if (col.hasCutOff) {\n      return MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n    } else if (size == 0) {\n      return getTopLevelQuery();\n    } else {\n      final BooleanQuery bq = getTopLevelQuery();\n      final Term placeholderTerm = new Term(query.field);\n      final BytesRefHash pendingTerms = col.pendingTerms;\n      final int sort[] = pendingTerms.sort(col.termsEnum.getComparator());\n      for(int i = 0; i < size; i++) {\n        // docFreq is not used for constant score here, we pass 1\n        // to explicitely set a fake value, so it's not calculated\n        addClause(bq, placeholderTerm.createTerm(pendingTerms.get(sort[i], new BytesRef())), 1, 1.0f);\n      }\n      // Strip scores\n      final Query result = new ConstantScoreQuery(bq);\n      result.setBoost(query.getBoost());\n      query.incTotalNumberOfTerms(size);\n      return result;\n    }\n  }\n\n","sourceOld":"  @Override\n  public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n    // Get the enum and start visiting terms.  If we\n    // exhaust the enum before hitting either of the\n    // cutoffs, we use ConstantBooleanQueryRewrite; else,\n    // ConstantFilterRewrite:\n    final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n    final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n    final CutOffTermCollector col = new CutOffTermCollector(docCountCutoff, termCountLimit);\n    collectTerms(reader, query, col);\n    final int size = col.pendingTerms.size();\n    if (col.hasCutOff) {\n      return MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n    } else if (size == 0) {\n      return getTopLevelQuery();\n    } else {\n      final BooleanQuery bq = getTopLevelQuery();\n      final Term placeholderTerm = new Term(query.field);\n      final BytesRefHash pendingTerms = col.pendingTerms;\n      final int sort[] = pendingTerms.sort(col.termsEnum.getComparator());\n      for(int i = 0; i < size; i++) {\n        // docFreq is not used for constant score here, we pass 1\n        // to explicitely set a fake value, so it's not calculated\n        addClause(bq, placeholderTerm.createTerm(pendingTerms.get(sort[i], new BytesRef())), 1, 1.0f);\n      }\n      // Strip scores\n      final Query result = new ConstantScoreQuery(new QueryWrapperFilter(bq));\n      result.setBoost(query.getBoost());\n      query.incTotalNumberOfTerms(size);\n      return result;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ff9cf7165d6cbafe4ef4431ecc2dc1af9cb2316c","date":1294014627,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/search/ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n    // Get the enum and start visiting terms.  If we\n    // exhaust the enum before hitting either of the\n    // cutoffs, we use ConstantBooleanQueryRewrite; else,\n    // ConstantFilterRewrite:\n    final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n    final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n    final CutOffTermCollector col = new CutOffTermCollector(docCountCutoff, termCountLimit);\n    collectTerms(reader, query, col);\n    final int size = col.pendingTerms.size();\n    if (col.hasCutOff) {\n      return MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n    } else if (size == 0) {\n      return getTopLevelQuery();\n    } else {\n      final BooleanQuery bq = getTopLevelQuery();\n      final Term placeholderTerm = new Term(query.field);\n      final BytesRefHash pendingTerms = col.pendingTerms;\n      final int sort[] = pendingTerms.sort(col.termsEnum.getComparator());\n      for(int i = 0; i < size; i++) {\n        // docFreq is not used for constant score here, we pass 1\n        // to explicitely set a fake value, so it's not calculated\n        addClause(bq, placeholderTerm.createTerm(pendingTerms.get(sort[i], new BytesRef())), 1, 1.0f);\n      }\n      // Strip scores\n      final Query result = new ConstantScoreQuery(bq);\n      result.setBoost(query.getBoost());\n      query.incTotalNumberOfTerms(size);\n      return result;\n    }\n  }\n\n","sourceOld":"  @Override\n  public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n    // Get the enum and start visiting terms.  If we\n    // exhaust the enum before hitting either of the\n    // cutoffs, we use ConstantBooleanQueryRewrite; else,\n    // ConstantFilterRewrite:\n    final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n    final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n    final CutOffTermCollector col = new CutOffTermCollector(docCountCutoff, termCountLimit);\n    collectTerms(reader, query, col);\n    final int size = col.pendingTerms.size();\n    if (col.hasCutOff) {\n      return MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n    } else if (size == 0) {\n      return getTopLevelQuery();\n    } else {\n      final BooleanQuery bq = getTopLevelQuery();\n      final Term placeholderTerm = new Term(query.field);\n      final BytesRefHash pendingTerms = col.pendingTerms;\n      final int sort[] = pendingTerms.sort(col.termsEnum.getComparator());\n      for(int i = 0; i < size; i++) {\n        // docFreq is not used for constant score here, we pass 1\n        // to explicitely set a fake value, so it's not calculated\n        addClause(bq, placeholderTerm.createTerm(pendingTerms.get(sort[i], new BytesRef())), 1, 1.0f);\n      }\n      // Strip scores\n      final Query result = new ConstantScoreQuery(new QueryWrapperFilter(bq));\n      result.setBoost(query.getBoost());\n      query.incTotalNumberOfTerms(size);\n      return result;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70ad682703b8585f5d0a637efec044d57ec05efb","date":1294259117,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/search/ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n    // Get the enum and start visiting terms.  If we\n    // exhaust the enum before hitting either of the\n    // cutoffs, we use ConstantBooleanQueryRewrite; else,\n    // ConstantFilterRewrite:\n    final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n    final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n    final CutOffTermCollector col = new CutOffTermCollector(docCountCutoff, termCountLimit);\n    collectTerms(reader, query, col);\n    final int size = col.pendingTerms.size();\n    if (col.hasCutOff) {\n      return MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n    } else if (size == 0) {\n      return getTopLevelQuery();\n    } else {\n      final BooleanQuery bq = getTopLevelQuery();\n      final Term placeholderTerm = new Term(query.field);\n      final BytesRefHash pendingTerms = col.pendingTerms;\n      final int sort[] = pendingTerms.sort(col.termsEnum.getComparator());\n      for(int i = 0; i < size; i++) {\n        // docFreq is not used for constant score here, we pass 1\n        // to explicitely set a fake value, so it's not calculated\n        addClause(bq, placeholderTerm.createTerm(pendingTerms.get(sort[i], new BytesRef())), 1, 1.0f);\n      }\n      // Strip scores\n      final Query result = new ConstantScoreQuery(bq);\n      result.setBoost(query.getBoost());\n      query.incTotalNumberOfTerms(size);\n      return result;\n    }\n  }\n\n","sourceOld":"  @Override\n  public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n    // Get the enum and start visiting terms.  If we\n    // exhaust the enum before hitting either of the\n    // cutoffs, we use ConstantBooleanQueryRewrite; else,\n    // ConstantFilterRewrite:\n    final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n    final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n    final CutOffTermCollector col = new CutOffTermCollector(docCountCutoff, termCountLimit);\n    collectTerms(reader, query, col);\n    final int size = col.pendingTerms.size();\n    if (col.hasCutOff) {\n      return MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n    } else if (size == 0) {\n      return getTopLevelQuery();\n    } else {\n      final BooleanQuery bq = getTopLevelQuery();\n      final Term placeholderTerm = new Term(query.field);\n      final BytesRefHash pendingTerms = col.pendingTerms;\n      final int sort[] = pendingTerms.sort(col.termsEnum.getComparator());\n      for(int i = 0; i < size; i++) {\n        // docFreq is not used for constant score here, we pass 1\n        // to explicitely set a fake value, so it's not calculated\n        addClause(bq, placeholderTerm.createTerm(pendingTerms.get(sort[i], new BytesRef())), 1, 1.0f);\n      }\n      // Strip scores\n      final Query result = new ConstantScoreQuery(new QueryWrapperFilter(bq));\n      result.setBoost(query.getBoost());\n      query.incTotalNumberOfTerms(size);\n      return result;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fa1a999d6674423e5c4ac858b410283f6fe03f20","date":1294868331,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n    // Get the enum and start visiting terms.  If we\n    // exhaust the enum before hitting either of the\n    // cutoffs, we use ConstantBooleanQueryRewrite; else,\n    // ConstantFilterRewrite:\n    final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n    final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n    final CutOffTermCollector col = new CutOffTermCollector(docCountCutoff, termCountLimit);\n    collectTerms(reader, query, col);\n    final int size = col.pendingTerms.size();\n    if (col.hasCutOff) {\n      return MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n    } else if (size == 0) {\n      return getTopLevelQuery();\n    } else {\n      final BooleanQuery bq = getTopLevelQuery();\n      final Term placeholderTerm = new Term(query.field);\n      final BytesRefHash pendingTerms = col.pendingTerms;\n      final int sort[] = pendingTerms.sort(col.termsEnum.getComparator());\n      for(int i = 0; i < size; i++) {\n        final int pos = sort[i];\n        // docFreq is not used for constant score here, we pass 1\n        // to explicitely set a fake value, so it's not calculated\n        addClause(bq, placeholderTerm.createTerm(pendingTerms.get(pos, new BytesRef())), 1, 1.0f, col.array.termState[pos]);\n      }\n      // Strip scores\n      final Query result = new ConstantScoreQuery(bq);\n      result.setBoost(query.getBoost());\n      query.incTotalNumberOfTerms(size);\n      return result;\n    }\n  }\n\n","sourceOld":"  @Override\n  public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n    // Get the enum and start visiting terms.  If we\n    // exhaust the enum before hitting either of the\n    // cutoffs, we use ConstantBooleanQueryRewrite; else,\n    // ConstantFilterRewrite:\n    final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n    final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n    final CutOffTermCollector col = new CutOffTermCollector(docCountCutoff, termCountLimit);\n    collectTerms(reader, query, col);\n    final int size = col.pendingTerms.size();\n    if (col.hasCutOff) {\n      return MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n    } else if (size == 0) {\n      return getTopLevelQuery();\n    } else {\n      final BooleanQuery bq = getTopLevelQuery();\n      final Term placeholderTerm = new Term(query.field);\n      final BytesRefHash pendingTerms = col.pendingTerms;\n      final int sort[] = pendingTerms.sort(col.termsEnum.getComparator());\n      for(int i = 0; i < size; i++) {\n        // docFreq is not used for constant score here, we pass 1\n        // to explicitely set a fake value, so it's not calculated\n        addClause(bq, placeholderTerm.createTerm(pendingTerms.get(sort[i], new BytesRef())), 1, 1.0f);\n      }\n      // Strip scores\n      final Query result = new ConstantScoreQuery(bq);\n      result.setBoost(query.getBoost());\n      query.incTotalNumberOfTerms(size);\n      return result;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/search/ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n    // Get the enum and start visiting terms.  If we\n    // exhaust the enum before hitting either of the\n    // cutoffs, we use ConstantBooleanQueryRewrite; else,\n    // ConstantFilterRewrite:\n    final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n    final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n    final CutOffTermCollector col = new CutOffTermCollector(docCountCutoff, termCountLimit);\n    collectTerms(reader, query, col);\n    final int size = col.pendingTerms.size();\n    if (col.hasCutOff) {\n      return MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n    } else if (size == 0) {\n      return getTopLevelQuery();\n    } else {\n      final BooleanQuery bq = getTopLevelQuery();\n      final Term placeholderTerm = new Term(query.field);\n      final BytesRefHash pendingTerms = col.pendingTerms;\n      final int sort[] = pendingTerms.sort(col.termsEnum.getComparator());\n      for(int i = 0; i < size; i++) {\n        final int pos = sort[i];\n        // docFreq is not used for constant score here, we pass 1\n        // to explicitely set a fake value, so it's not calculated\n        addClause(bq, placeholderTerm.createTerm(pendingTerms.get(pos, new BytesRef())), 1, 1.0f, col.array.termState[pos]);\n      }\n      // Strip scores\n      final Query result = new ConstantScoreQuery(bq);\n      result.setBoost(query.getBoost());\n      query.incTotalNumberOfTerms(size);\n      return result;\n    }\n  }\n\n","sourceOld":"  @Override\n  public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n    // Get the enum and start visiting terms.  If we\n    // exhaust the enum before hitting either of the\n    // cutoffs, we use ConstantBooleanQueryRewrite; else,\n    // ConstantFilterRewrite:\n    final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n    final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n    final CutOffTermCollector col = new CutOffTermCollector(docCountCutoff, termCountLimit);\n    collectTerms(reader, query, col);\n    final int size = col.pendingTerms.size();\n    if (col.hasCutOff) {\n      return MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n    } else if (size == 0) {\n      return getTopLevelQuery();\n    } else {\n      final BooleanQuery bq = getTopLevelQuery();\n      final Term placeholderTerm = new Term(query.field);\n      final BytesRefHash pendingTerms = col.pendingTerms;\n      final int sort[] = pendingTerms.sort(col.termsEnum.getComparator());\n      for(int i = 0; i < size; i++) {\n        // docFreq is not used for constant score here, we pass 1\n        // to explicitely set a fake value, so it's not calculated\n        addClause(bq, placeholderTerm.createTerm(pendingTerms.get(sort[i], new BytesRef())), 1, 1.0f);\n      }\n      // Strip scores\n      final Query result = new ConstantScoreQuery(bq);\n      result.setBoost(query.getBoost());\n      query.incTotalNumberOfTerms(size);\n      return result;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/search/ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n    // Get the enum and start visiting terms.  If we\n    // exhaust the enum before hitting either of the\n    // cutoffs, we use ConstantBooleanQueryRewrite; else,\n    // ConstantFilterRewrite:\n    final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n    final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n    final CutOffTermCollector col = new CutOffTermCollector(docCountCutoff, termCountLimit);\n    collectTerms(reader, query, col);\n    final int size = col.pendingTerms.size();\n    if (col.hasCutOff) {\n      return MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n    } else if (size == 0) {\n      return getTopLevelQuery();\n    } else {\n      final BooleanQuery bq = getTopLevelQuery();\n      final Term placeholderTerm = new Term(query.field);\n      final BytesRefHash pendingTerms = col.pendingTerms;\n      final int sort[] = pendingTerms.sort(col.termsEnum.getComparator());\n      for(int i = 0; i < size; i++) {\n        final int pos = sort[i];\n        // docFreq is not used for constant score here, we pass 1\n        // to explicitely set a fake value, so it's not calculated\n        addClause(bq, placeholderTerm.createTerm(pendingTerms.get(pos, new BytesRef())), 1, 1.0f, col.array.termState[pos]);\n      }\n      // Strip scores\n      final Query result = new ConstantScoreQuery(bq);\n      result.setBoost(query.getBoost());\n      query.incTotalNumberOfTerms(size);\n      return result;\n    }\n  }\n\n","sourceOld":"  @Override\n  public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n    // Get the enum and start visiting terms.  If we\n    // exhaust the enum before hitting either of the\n    // cutoffs, we use ConstantBooleanQueryRewrite; else,\n    // ConstantFilterRewrite:\n    final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n    final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n    final CutOffTermCollector col = new CutOffTermCollector(docCountCutoff, termCountLimit);\n    collectTerms(reader, query, col);\n    final int size = col.pendingTerms.size();\n    if (col.hasCutOff) {\n      return MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n    } else if (size == 0) {\n      return getTopLevelQuery();\n    } else {\n      final BooleanQuery bq = getTopLevelQuery();\n      final Term placeholderTerm = new Term(query.field);\n      final BytesRefHash pendingTerms = col.pendingTerms;\n      final int sort[] = pendingTerms.sort(col.termsEnum.getComparator());\n      for(int i = 0; i < size; i++) {\n        // docFreq is not used for constant score here, we pass 1\n        // to explicitely set a fake value, so it's not calculated\n        addClause(bq, placeholderTerm.createTerm(pendingTerms.get(sort[i], new BytesRef())), 1, 1.0f);\n      }\n      // Strip scores\n      final Query result = new ConstantScoreQuery(bq);\n      result.setBoost(query.getBoost());\n      query.incTotalNumberOfTerms(size);\n      return result;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fafef7c83fe8e0b3ca9298d5d75d6b943dc28153","date":1308670974,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n    // Get the enum and start visiting terms.  If we\n    // exhaust the enum before hitting either of the\n    // cutoffs, we use ConstantBooleanQueryRewrite; else,\n    // ConstantFilterRewrite:\n    final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n    final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n    final CutOffTermCollector col = new CutOffTermCollector(docCountCutoff, termCountLimit);\n    collectTerms(reader, query, col);\n    final int size = col.pendingTerms.size();\n    if (col.hasCutOff) {\n      return MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n    } else if (size == 0) {\n      return getTopLevelQuery();\n    } else {\n      final BooleanQuery bq = getTopLevelQuery();\n      final BytesRefHash pendingTerms = col.pendingTerms;\n      final int sort[] = pendingTerms.sort(col.termsEnum.getComparator());\n      for(int i = 0; i < size; i++) {\n        final int pos = sort[i];\n        // docFreq is not used for constant score here, we pass 1\n        // to explicitely set a fake value, so it's not calculated\n        addClause(bq, new Term(query.field, pendingTerms.get(pos, new BytesRef())), 1, 1.0f, col.array.termState[pos]);\n      }\n      // Strip scores\n      final Query result = new ConstantScoreQuery(bq);\n      result.setBoost(query.getBoost());\n      query.incTotalNumberOfTerms(size);\n      return result;\n    }\n  }\n\n","sourceOld":"  @Override\n  public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n    // Get the enum and start visiting terms.  If we\n    // exhaust the enum before hitting either of the\n    // cutoffs, we use ConstantBooleanQueryRewrite; else,\n    // ConstantFilterRewrite:\n    final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n    final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n    final CutOffTermCollector col = new CutOffTermCollector(docCountCutoff, termCountLimit);\n    collectTerms(reader, query, col);\n    final int size = col.pendingTerms.size();\n    if (col.hasCutOff) {\n      return MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n    } else if (size == 0) {\n      return getTopLevelQuery();\n    } else {\n      final BooleanQuery bq = getTopLevelQuery();\n      final Term placeholderTerm = new Term(query.field);\n      final BytesRefHash pendingTerms = col.pendingTerms;\n      final int sort[] = pendingTerms.sort(col.termsEnum.getComparator());\n      for(int i = 0; i < size; i++) {\n        final int pos = sort[i];\n        // docFreq is not used for constant score here, we pass 1\n        // to explicitely set a fake value, so it's not calculated\n        addClause(bq, placeholderTerm.createTerm(pendingTerms.get(pos, new BytesRef())), 1, 1.0f, col.array.termState[pos]);\n      }\n      // Strip scores\n      final Query result = new ConstantScoreQuery(bq);\n      result.setBoost(query.getBoost());\n      query.incTotalNumberOfTerms(size);\n      return result;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2553b00f699380c64959ccb27991289aae87be2e","date":1309290151,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/search/ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n    // Get the enum and start visiting terms.  If we\n    // exhaust the enum before hitting either of the\n    // cutoffs, we use ConstantBooleanQueryRewrite; else,\n    // ConstantFilterRewrite:\n    final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n    final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n    final CutOffTermCollector col = new CutOffTermCollector(docCountCutoff, termCountLimit);\n    collectTerms(reader, query, col);\n    final int size = col.pendingTerms.size();\n    if (col.hasCutOff) {\n      return MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n    } else if (size == 0) {\n      return getTopLevelQuery();\n    } else {\n      final BooleanQuery bq = getTopLevelQuery();\n      final BytesRefHash pendingTerms = col.pendingTerms;\n      final int sort[] = pendingTerms.sort(col.termsEnum.getComparator());\n      for(int i = 0; i < size; i++) {\n        final int pos = sort[i];\n        // docFreq is not used for constant score here, we pass 1\n        // to explicitely set a fake value, so it's not calculated\n        addClause(bq, new Term(query.field, pendingTerms.get(pos, new BytesRef())), 1, 1.0f, col.array.termState[pos]);\n      }\n      // Strip scores\n      final Query result = new ConstantScoreQuery(bq);\n      result.setBoost(query.getBoost());\n      query.incTotalNumberOfTerms(size);\n      return result;\n    }\n  }\n\n","sourceOld":"  @Override\n  public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n    // Get the enum and start visiting terms.  If we\n    // exhaust the enum before hitting either of the\n    // cutoffs, we use ConstantBooleanQueryRewrite; else,\n    // ConstantFilterRewrite:\n    final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n    final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n    final CutOffTermCollector col = new CutOffTermCollector(docCountCutoff, termCountLimit);\n    collectTerms(reader, query, col);\n    final int size = col.pendingTerms.size();\n    if (col.hasCutOff) {\n      return MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n    } else if (size == 0) {\n      return getTopLevelQuery();\n    } else {\n      final BooleanQuery bq = getTopLevelQuery();\n      final Term placeholderTerm = new Term(query.field);\n      final BytesRefHash pendingTerms = col.pendingTerms;\n      final int sort[] = pendingTerms.sort(col.termsEnum.getComparator());\n      for(int i = 0; i < size; i++) {\n        final int pos = sort[i];\n        // docFreq is not used for constant score here, we pass 1\n        // to explicitely set a fake value, so it's not calculated\n        addClause(bq, placeholderTerm.createTerm(pendingTerms.get(pos, new BytesRef())), 1, 1.0f, col.array.termState[pos]);\n      }\n      // Strip scores\n      final Query result = new ConstantScoreQuery(bq);\n      result.setBoost(query.getBoost());\n      query.incTotalNumberOfTerms(size);\n      return result;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/search/ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n    // Get the enum and start visiting terms.  If we\n    // exhaust the enum before hitting either of the\n    // cutoffs, we use ConstantBooleanQueryRewrite; else,\n    // ConstantFilterRewrite:\n    final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n    final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n    final CutOffTermCollector col = new CutOffTermCollector(docCountCutoff, termCountLimit);\n    collectTerms(reader, query, col);\n    final int size = col.pendingTerms.size();\n    if (col.hasCutOff) {\n      return MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n    } else if (size == 0) {\n      return getTopLevelQuery();\n    } else {\n      final BooleanQuery bq = getTopLevelQuery();\n      final BytesRefHash pendingTerms = col.pendingTerms;\n      final int sort[] = pendingTerms.sort(col.termsEnum.getComparator());\n      for(int i = 0; i < size; i++) {\n        final int pos = sort[i];\n        // docFreq is not used for constant score here, we pass 1\n        // to explicitely set a fake value, so it's not calculated\n        addClause(bq, new Term(query.field, pendingTerms.get(pos, new BytesRef())), 1, 1.0f, col.array.termState[pos]);\n      }\n      // Strip scores\n      final Query result = new ConstantScoreQuery(bq);\n      result.setBoost(query.getBoost());\n      query.incTotalNumberOfTerms(size);\n      return result;\n    }\n  }\n\n","sourceOld":"  @Override\n  public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n    // Get the enum and start visiting terms.  If we\n    // exhaust the enum before hitting either of the\n    // cutoffs, we use ConstantBooleanQueryRewrite; else,\n    // ConstantFilterRewrite:\n    final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n    final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n    final CutOffTermCollector col = new CutOffTermCollector(docCountCutoff, termCountLimit);\n    collectTerms(reader, query, col);\n    final int size = col.pendingTerms.size();\n    if (col.hasCutOff) {\n      return MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n    } else if (size == 0) {\n      return getTopLevelQuery();\n    } else {\n      final BooleanQuery bq = getTopLevelQuery();\n      final Term placeholderTerm = new Term(query.field);\n      final BytesRefHash pendingTerms = col.pendingTerms;\n      final int sort[] = pendingTerms.sort(col.termsEnum.getComparator());\n      for(int i = 0; i < size; i++) {\n        final int pos = sort[i];\n        // docFreq is not used for constant score here, we pass 1\n        // to explicitely set a fake value, so it's not calculated\n        addClause(bq, placeholderTerm.createTerm(pendingTerms.get(pos, new BytesRef())), 1, 1.0f, col.array.termState[pos]);\n      }\n      // Strip scores\n      final Query result = new ConstantScoreQuery(bq);\n      result.setBoost(query.getBoost());\n      query.incTotalNumberOfTerms(size);\n      return result;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2a4965b25e439626b575c2281b39ad875f89d891","date":1321132400,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n    // Get the enum and start visiting terms.  If we\n    // exhaust the enum before hitting either of the\n    // cutoffs, we use ConstantBooleanQueryRewrite; else,\n    // ConstantFilterRewrite:\n    final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n    final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n    final CutOffTermCollector col = new CutOffTermCollector(docCountCutoff, termCountLimit);\n    collectTerms(reader, query, col);\n    final int size = col.pendingTerms.size();\n    if (col.hasCutOff) {\n      return MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n    } else if (size == 0) {\n      return getTopLevelQuery();\n    } else {\n      final BooleanQuery bq = getTopLevelQuery();\n      final BytesRefHash pendingTerms = col.pendingTerms;\n      final int sort[] = pendingTerms.sort(col.termsEnum.getComparator());\n      for(int i = 0; i < size; i++) {\n        final int pos = sort[i];\n        // docFreq is not used for constant score here, we pass 1\n        // to explicitely set a fake value, so it's not calculated\n        addClause(bq, new Term(query.field, pendingTerms.get(pos, new BytesRef())), 1, 1.0f, col.array.termState[pos]);\n      }\n      // Strip scores\n      final Query result = new ConstantScoreQuery(bq);\n      result.setBoost(query.getBoost());\n      return result;\n    }\n  }\n\n","sourceOld":"  @Override\n  public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n    // Get the enum and start visiting terms.  If we\n    // exhaust the enum before hitting either of the\n    // cutoffs, we use ConstantBooleanQueryRewrite; else,\n    // ConstantFilterRewrite:\n    final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n    final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n    final CutOffTermCollector col = new CutOffTermCollector(docCountCutoff, termCountLimit);\n    collectTerms(reader, query, col);\n    final int size = col.pendingTerms.size();\n    if (col.hasCutOff) {\n      return MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n    } else if (size == 0) {\n      return getTopLevelQuery();\n    } else {\n      final BooleanQuery bq = getTopLevelQuery();\n      final BytesRefHash pendingTerms = col.pendingTerms;\n      final int sort[] = pendingTerms.sort(col.termsEnum.getComparator());\n      for(int i = 0; i < size; i++) {\n        final int pos = sort[i];\n        // docFreq is not used for constant score here, we pass 1\n        // to explicitely set a fake value, so it's not calculated\n        addClause(bq, new Term(query.field, pendingTerms.get(pos, new BytesRef())), 1, 1.0f, col.array.termState[pos]);\n      }\n      // Strip scores\n      final Query result = new ConstantScoreQuery(bq);\n      result.setBoost(query.getBoost());\n      query.incTotalNumberOfTerms(size);\n      return result;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n    // Get the enum and start visiting terms.  If we\n    // exhaust the enum before hitting either of the\n    // cutoffs, we use ConstantBooleanQueryRewrite; else,\n    // ConstantFilterRewrite:\n    final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n    final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n    final CutOffTermCollector col = new CutOffTermCollector(docCountCutoff, termCountLimit);\n    collectTerms(reader, query, col);\n    final int size = col.pendingTerms.size();\n    if (col.hasCutOff) {\n      return MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n    } else if (size == 0) {\n      return getTopLevelQuery();\n    } else {\n      final BooleanQuery bq = getTopLevelQuery();\n      final BytesRefHash pendingTerms = col.pendingTerms;\n      final int sort[] = pendingTerms.sort(col.termsEnum.getComparator());\n      for(int i = 0; i < size; i++) {\n        final int pos = sort[i];\n        // docFreq is not used for constant score here, we pass 1\n        // to explicitely set a fake value, so it's not calculated\n        addClause(bq, new Term(query.field, pendingTerms.get(pos, new BytesRef())), 1, 1.0f, col.array.termState[pos]);\n      }\n      // Strip scores\n      final Query result = new ConstantScoreQuery(bq);\n      result.setBoost(query.getBoost());\n      return result;\n    }\n  }\n\n","sourceOld":"  @Override\n  public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n    // Get the enum and start visiting terms.  If we\n    // exhaust the enum before hitting either of the\n    // cutoffs, we use ConstantBooleanQueryRewrite; else,\n    // ConstantFilterRewrite:\n    final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n    final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n    final CutOffTermCollector col = new CutOffTermCollector(docCountCutoff, termCountLimit);\n    collectTerms(reader, query, col);\n    final int size = col.pendingTerms.size();\n    if (col.hasCutOff) {\n      return MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n    } else if (size == 0) {\n      return getTopLevelQuery();\n    } else {\n      final BooleanQuery bq = getTopLevelQuery();\n      final BytesRefHash pendingTerms = col.pendingTerms;\n      final int sort[] = pendingTerms.sort(col.termsEnum.getComparator());\n      for(int i = 0; i < size; i++) {\n        final int pos = sort[i];\n        // docFreq is not used for constant score here, we pass 1\n        // to explicitely set a fake value, so it's not calculated\n        addClause(bq, new Term(query.field, pendingTerms.get(pos, new BytesRef())), 1, 1.0f, col.array.termState[pos]);\n      }\n      // Strip scores\n      final Query result = new ConstantScoreQuery(bq);\n      result.setBoost(query.getBoost());\n      return result;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"70ad682703b8585f5d0a637efec044d57ec05efb":["9ab1f5591dc05f1f2b5407d809c9699f75554a32","3e37a877cbb3c0d736bdc1fcb3aea4c24015799f"],"9ab1f5591dc05f1f2b5407d809c9699f75554a32":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","744486748bc5bee772100e49230e5bca39bac99a"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["2a4965b25e439626b575c2281b39ad875f89d891"],"fafef7c83fe8e0b3ca9298d5d75d6b943dc28153":["fa1a999d6674423e5c4ac858b410283f6fe03f20"],"3e37a877cbb3c0d736bdc1fcb3aea4c24015799f":["744486748bc5bee772100e49230e5bca39bac99a"],"2553b00f699380c64959ccb27991289aae87be2e":["fa1a999d6674423e5c4ac858b410283f6fe03f20","fafef7c83fe8e0b3ca9298d5d75d6b943dc28153"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","744486748bc5bee772100e49230e5bca39bac99a"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["fa1a999d6674423e5c4ac858b410283f6fe03f20","fafef7c83fe8e0b3ca9298d5d75d6b943dc28153"],"ff9cf7165d6cbafe4ef4431ecc2dc1af9cb2316c":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","3e37a877cbb3c0d736bdc1fcb3aea4c24015799f"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["70ad682703b8585f5d0a637efec044d57ec05efb","fa1a999d6674423e5c4ac858b410283f6fe03f20"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"2a4965b25e439626b575c2281b39ad875f89d891":["fafef7c83fe8e0b3ca9298d5d75d6b943dc28153"],"fa1a999d6674423e5c4ac858b410283f6fe03f20":["3e37a877cbb3c0d736bdc1fcb3aea4c24015799f"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["ff9cf7165d6cbafe4ef4431ecc2dc1af9cb2316c","fa1a999d6674423e5c4ac858b410283f6fe03f20"],"744486748bc5bee772100e49230e5bca39bac99a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"70ad682703b8585f5d0a637efec044d57ec05efb":["29ef99d61cda9641b6250bf9567329a6e65f901d"],"9ab1f5591dc05f1f2b5407d809c9699f75554a32":["70ad682703b8585f5d0a637efec044d57ec05efb"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"fafef7c83fe8e0b3ca9298d5d75d6b943dc28153":["2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c","2a4965b25e439626b575c2281b39ad875f89d891"],"3e37a877cbb3c0d736bdc1fcb3aea4c24015799f":["70ad682703b8585f5d0a637efec044d57ec05efb","ff9cf7165d6cbafe4ef4431ecc2dc1af9cb2316c","fa1a999d6674423e5c4ac858b410283f6fe03f20"],"2553b00f699380c64959ccb27991289aae87be2e":[],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["ff9cf7165d6cbafe4ef4431ecc2dc1af9cb2316c"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"ff9cf7165d6cbafe4ef4431ecc2dc1af9cb2316c":["868da859b43505d9d2a023bfeae6dd0c795f5295"],"29ef99d61cda9641b6250bf9567329a6e65f901d":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9ab1f5591dc05f1f2b5407d809c9699f75554a32","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","744486748bc5bee772100e49230e5bca39bac99a"],"2a4965b25e439626b575c2281b39ad875f89d891":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"fa1a999d6674423e5c4ac858b410283f6fe03f20":["fafef7c83fe8e0b3ca9298d5d75d6b943dc28153","2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c","29ef99d61cda9641b6250bf9567329a6e65f901d","868da859b43505d9d2a023bfeae6dd0c795f5295"],"868da859b43505d9d2a023bfeae6dd0c795f5295":[],"744486748bc5bee772100e49230e5bca39bac99a":["9ab1f5591dc05f1f2b5407d809c9699f75554a32","3e37a877cbb3c0d736bdc1fcb3aea4c24015799f","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c","29ef99d61cda9641b6250bf9567329a6e65f901d","868da859b43505d9d2a023bfeae6dd0c795f5295","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}