{"path":"lucene/core/src/java/org/apache/lucene/search/ExactPhraseScorer#ExactPhraseScorer(Weight,PhraseQuery.PostingsAndFreq[],Similarity.ExactSimScorer).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/ExactPhraseScorer#ExactPhraseScorer(Weight,PhraseQuery.PostingsAndFreq[],Similarity.ExactSimScorer).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/ExactPhraseScorer#ExactPhraseScorer(Weight,PhraseQuery.PostingsAndFreq[],Similarity.ExactSimScorer).mjava","sourceNew":"  ExactPhraseScorer(Weight weight, PhraseQuery.PostingsAndFreq[] postings,\n                    Similarity.ExactSimScorer docScorer) throws IOException {\n    super(weight);\n    this.docScorer = docScorer;\n\n    chunkStates = new ChunkState[postings.length];\n\n    endMinus1 = postings.length-1;\n\n    for(int i=0;i<postings.length;i++) {\n\n      // Coarse optimization: advance(target) is fairly\n      // costly, so, if the relative freq of the 2nd\n      // rarest term is not that much (> 1/5th) rarer than\n      // the first term, then we just use .nextDoc() when\n      // ANDing.  This buys ~15% gain for phrases where\n      // freq of rarest 2 terms is close:\n      final boolean useAdvance = postings[i].docFreq > 5*postings[0].docFreq;\n      chunkStates[i] = new ChunkState(postings[i].postings, -postings[i].position, useAdvance);\n      if (i > 0 && postings[i].postings.nextDoc() == DocsEnum.NO_MORE_DOCS) {\n        noDocs = true;\n        return;\n      }\n    }\n  }\n\n","sourceOld":"  ExactPhraseScorer(Weight weight, PhraseQuery.PostingsAndFreq[] postings,\n                    Similarity.ExactSimScorer docScorer) throws IOException {\n    super(weight);\n    this.docScorer = docScorer;\n\n    chunkStates = new ChunkState[postings.length];\n\n    endMinus1 = postings.length-1;\n\n    for(int i=0;i<postings.length;i++) {\n\n      // Coarse optimization: advance(target) is fairly\n      // costly, so, if the relative freq of the 2nd\n      // rarest term is not that much (> 1/5th) rarer than\n      // the first term, then we just use .nextDoc() when\n      // ANDing.  This buys ~15% gain for phrases where\n      // freq of rarest 2 terms is close:\n      final boolean useAdvance = postings[i].docFreq > 5*postings[0].docFreq;\n      chunkStates[i] = new ChunkState(postings[i].postings, -postings[i].position, useAdvance);\n      if (i > 0 && postings[i].postings.nextDoc() == DocsEnum.NO_MORE_DOCS) {\n        noDocs = true;\n        return;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f08557cdb6c60ac7b88a9342c983a20cd236e74f","date":1330954480,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/ExactPhraseScorer#ExactPhraseScorer(Weight,PhraseQuery.PostingsAndFreq[],Similarity.ExactSimScorer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/ExactPhraseScorer#ExactPhraseScorer(Weight,PhraseQuery.PostingsAndFreq[],Similarity.ExactSimScorer).mjava","sourceNew":"  ExactPhraseScorer(Weight weight, PhraseQuery.PostingsAndFreq[] postings,\n                    Similarity.ExactSimScorer docScorer) throws IOException {\n    super(weight);\n    this.docScorer = docScorer;\n\n    chunkStates = new ChunkState[postings.length];\n\n    endMinus1 = postings.length-1;\n\n    for(int i=0;i<postings.length;i++) {\n\n      // Coarse optimization: advance(target) is fairly\n      // costly, so, if the relative freq of the 2nd\n      // rarest term is not that much (> 1/5th) rarer than\n      // the first term, then we just use .nextDoc() when\n      // ANDing.  This buys ~15% gain for phrases where\n      // freq of rarest 2 terms is close:\n      final boolean useAdvance = postings[i].docFreq > 5*postings[0].docFreq;\n      chunkStates[i] = new ChunkState(postings[i].postings, -postings[i].position, useAdvance);\n      if (i > 0 && postings[i].postings.nextDoc() == DocIdSetIterator.NO_MORE_DOCS) {\n        noDocs = true;\n        return;\n      }\n    }\n  }\n\n","sourceOld":"  ExactPhraseScorer(Weight weight, PhraseQuery.PostingsAndFreq[] postings,\n                    Similarity.ExactSimScorer docScorer) throws IOException {\n    super(weight);\n    this.docScorer = docScorer;\n\n    chunkStates = new ChunkState[postings.length];\n\n    endMinus1 = postings.length-1;\n\n    for(int i=0;i<postings.length;i++) {\n\n      // Coarse optimization: advance(target) is fairly\n      // costly, so, if the relative freq of the 2nd\n      // rarest term is not that much (> 1/5th) rarer than\n      // the first term, then we just use .nextDoc() when\n      // ANDing.  This buys ~15% gain for phrases where\n      // freq of rarest 2 terms is close:\n      final boolean useAdvance = postings[i].docFreq > 5*postings[0].docFreq;\n      chunkStates[i] = new ChunkState(postings[i].postings, -postings[i].position, useAdvance);\n      if (i > 0 && postings[i].postings.nextDoc() == DocsEnum.NO_MORE_DOCS) {\n        noDocs = true;\n        return;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","date":1331075828,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/ExactPhraseScorer#ExactPhraseScorer(Weight,PhraseQuery.PostingsAndFreq[],Similarity.ExactSimScorer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/ExactPhraseScorer#ExactPhraseScorer(Weight,PhraseQuery.PostingsAndFreq[],Similarity.ExactSimScorer).mjava","sourceNew":"  ExactPhraseScorer(Weight weight, PhraseQuery.PostingsAndFreq[] postings,\n                    Similarity.ExactSimScorer docScorer) throws IOException {\n    super(weight);\n    this.docScorer = docScorer;\n\n    chunkStates = new ChunkState[postings.length];\n\n    endMinus1 = postings.length-1;\n\n    for(int i=0;i<postings.length;i++) {\n\n      // Coarse optimization: advance(target) is fairly\n      // costly, so, if the relative freq of the 2nd\n      // rarest term is not that much (> 1/5th) rarer than\n      // the first term, then we just use .nextDoc() when\n      // ANDing.  This buys ~15% gain for phrases where\n      // freq of rarest 2 terms is close:\n      final boolean useAdvance = postings[i].docFreq > 5*postings[0].docFreq;\n      chunkStates[i] = new ChunkState(postings[i].postings, -postings[i].position, useAdvance);\n      if (i > 0 && postings[i].postings.nextDoc() == DocIdSetIterator.NO_MORE_DOCS) {\n        noDocs = true;\n        return;\n      }\n    }\n  }\n\n","sourceOld":"  ExactPhraseScorer(Weight weight, PhraseQuery.PostingsAndFreq[] postings,\n                    Similarity.ExactSimScorer docScorer) throws IOException {\n    super(weight);\n    this.docScorer = docScorer;\n\n    chunkStates = new ChunkState[postings.length];\n\n    endMinus1 = postings.length-1;\n\n    for(int i=0;i<postings.length;i++) {\n\n      // Coarse optimization: advance(target) is fairly\n      // costly, so, if the relative freq of the 2nd\n      // rarest term is not that much (> 1/5th) rarer than\n      // the first term, then we just use .nextDoc() when\n      // ANDing.  This buys ~15% gain for phrases where\n      // freq of rarest 2 terms is close:\n      final boolean useAdvance = postings[i].docFreq > 5*postings[0].docFreq;\n      chunkStates[i] = new ChunkState(postings[i].postings, -postings[i].position, useAdvance);\n      if (i > 0 && postings[i].postings.nextDoc() == DocsEnum.NO_MORE_DOCS) {\n        noDocs = true;\n        return;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7b9f056598bc578796f7c2eaa4b2bb8eaab5c23a","date":1363294103,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/ExactPhraseScorer#ExactPhraseScorer(Weight,PhraseQuery.PostingsAndFreq[],Similarity.ExactSimScorer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/ExactPhraseScorer#ExactPhraseScorer(Weight,PhraseQuery.PostingsAndFreq[],Similarity.ExactSimScorer).mjava","sourceNew":"  ExactPhraseScorer(Weight weight, PhraseQuery.PostingsAndFreq[] postings,\n                    Similarity.ExactSimScorer docScorer) throws IOException {\n    super(weight);\n    this.docScorer = docScorer;\n\n    chunkStates = new ChunkState[postings.length];\n\n    endMinus1 = postings.length-1;\n    \n    // min(cost)\n    cost = postings[0].postings.cost();\n\n    for(int i=0;i<postings.length;i++) {\n\n      // Coarse optimization: advance(target) is fairly\n      // costly, so, if the relative freq of the 2nd\n      // rarest term is not that much (> 1/5th) rarer than\n      // the first term, then we just use .nextDoc() when\n      // ANDing.  This buys ~15% gain for phrases where\n      // freq of rarest 2 terms is close:\n      final boolean useAdvance = postings[i].docFreq > 5*postings[0].docFreq;\n      chunkStates[i] = new ChunkState(postings[i].postings, -postings[i].position, useAdvance);\n      if (i > 0 && postings[i].postings.nextDoc() == DocIdSetIterator.NO_MORE_DOCS) {\n        noDocs = true;\n        return;\n      }\n    }\n  }\n\n","sourceOld":"  ExactPhraseScorer(Weight weight, PhraseQuery.PostingsAndFreq[] postings,\n                    Similarity.ExactSimScorer docScorer) throws IOException {\n    super(weight);\n    this.docScorer = docScorer;\n\n    chunkStates = new ChunkState[postings.length];\n\n    endMinus1 = postings.length-1;\n\n    for(int i=0;i<postings.length;i++) {\n\n      // Coarse optimization: advance(target) is fairly\n      // costly, so, if the relative freq of the 2nd\n      // rarest term is not that much (> 1/5th) rarer than\n      // the first term, then we just use .nextDoc() when\n      // ANDing.  This buys ~15% gain for phrases where\n      // freq of rarest 2 terms is close:\n      final boolean useAdvance = postings[i].docFreq > 5*postings[0].docFreq;\n      chunkStates[i] = new ChunkState(postings[i].postings, -postings[i].position, useAdvance);\n      if (i > 0 && postings[i].postings.nextDoc() == DocIdSetIterator.NO_MORE_DOCS) {\n        noDocs = true;\n        return;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b799defcfda6d303cbb180917bf1e749089adf42","date":1370695356,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/ExactPhraseScorer#ExactPhraseScorer(Weight,PhraseQuery.PostingsAndFreq[],Similarity.SimScorer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/ExactPhraseScorer#ExactPhraseScorer(Weight,PhraseQuery.PostingsAndFreq[],Similarity.ExactSimScorer).mjava","sourceNew":"  ExactPhraseScorer(Weight weight, PhraseQuery.PostingsAndFreq[] postings,\n                    Similarity.SimScorer docScorer) throws IOException {\n    super(weight);\n    this.docScorer = docScorer;\n\n    chunkStates = new ChunkState[postings.length];\n\n    endMinus1 = postings.length-1;\n    \n    // min(cost)\n    cost = postings[0].postings.cost();\n\n    for(int i=0;i<postings.length;i++) {\n\n      // Coarse optimization: advance(target) is fairly\n      // costly, so, if the relative freq of the 2nd\n      // rarest term is not that much (> 1/5th) rarer than\n      // the first term, then we just use .nextDoc() when\n      // ANDing.  This buys ~15% gain for phrases where\n      // freq of rarest 2 terms is close:\n      final boolean useAdvance = postings[i].docFreq > 5*postings[0].docFreq;\n      chunkStates[i] = new ChunkState(postings[i].postings, -postings[i].position, useAdvance);\n      if (i > 0 && postings[i].postings.nextDoc() == DocIdSetIterator.NO_MORE_DOCS) {\n        noDocs = true;\n        return;\n      }\n    }\n  }\n\n","sourceOld":"  ExactPhraseScorer(Weight weight, PhraseQuery.PostingsAndFreq[] postings,\n                    Similarity.ExactSimScorer docScorer) throws IOException {\n    super(weight);\n    this.docScorer = docScorer;\n\n    chunkStates = new ChunkState[postings.length];\n\n    endMinus1 = postings.length-1;\n    \n    // min(cost)\n    cost = postings[0].postings.cost();\n\n    for(int i=0;i<postings.length;i++) {\n\n      // Coarse optimization: advance(target) is fairly\n      // costly, so, if the relative freq of the 2nd\n      // rarest term is not that much (> 1/5th) rarer than\n      // the first term, then we just use .nextDoc() when\n      // ANDing.  This buys ~15% gain for phrases where\n      // freq of rarest 2 terms is close:\n      final boolean useAdvance = postings[i].docFreq > 5*postings[0].docFreq;\n      chunkStates[i] = new ChunkState(postings[i].postings, -postings[i].position, useAdvance);\n      if (i > 0 && postings[i].postings.nextDoc() == DocIdSetIterator.NO_MORE_DOCS) {\n        noDocs = true;\n        return;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"b799defcfda6d303cbb180917bf1e749089adf42":["7b9f056598bc578796f7c2eaa4b2bb8eaab5c23a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"7b9f056598bc578796f7c2eaa4b2bb8eaab5c23a":["f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b799defcfda6d303cbb180917bf1e749089adf42"]},"commit2Childs":{"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","7b9f056598bc578796f7c2eaa4b2bb8eaab5c23a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"b799defcfda6d303cbb180917bf1e749089adf42":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"7b9f056598bc578796f7c2eaa4b2bb8eaab5c23a":["b799defcfda6d303cbb180917bf1e749089adf42"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}