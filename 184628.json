{"path":"modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupsCollectorTest#testTotalGroupCount().mjava","commits":[{"id":"c5f61d6a2927b52517a31a8bf022549d33b1dfec","date":1305652854,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupsCollectorTest#testTotalGroupCount().mjava","pathOld":"/dev/null","sourceNew":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    AllGroupsCollector c1 = new AllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertEquals(4, c1.getGroupCount());\n\n    AllGroupsCollector c2 = new AllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertEquals(3, c2.getGroupCount());\n\n    AllGroupsCollector c3 = new AllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertEquals(2, c3.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c3a8a449466c1ff7ce2274fe73dab487256964b4","date":1305735867,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupsCollectorTest#testTotalGroupCount().mjava","pathOld":"/dev/null","sourceNew":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    AllGroupsCollector c1 = new AllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertEquals(4, c1.getGroupCount());\n\n    AllGroupsCollector c2 = new AllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertEquals(3, c2.getGroupCount());\n\n    AllGroupsCollector c3 = new AllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertEquals(2, c3.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":0,"author":"Steven Rowe","isMerge":true,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupsCollectorTest#testTotalGroupCount().mjava","pathOld":"/dev/null","sourceNew":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    AllGroupsCollector c1 = new AllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertEquals(4, c1.getGroupCount());\n\n    AllGroupsCollector c2 = new AllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertEquals(3, c2.getGroupCount());\n\n    AllGroupsCollector c3 = new AllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertEquals(2, c3.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3e1a83e28efa5e061642117ae7766034f738f142","date":1307054547,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupsCollectorTest#testTotalGroupCount().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupsCollectorTest#testTotalGroupCount().mjava","sourceNew":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    TermAllGroupsCollector c1 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertEquals(4, c1.getGroupCount());\n\n    TermAllGroupsCollector c2 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertEquals(3, c2.getGroupCount());\n\n    TermAllGroupsCollector c3 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertEquals(2, c3.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    AllGroupsCollector c1 = new AllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertEquals(4, c1.getGroupCount());\n\n    AllGroupsCollector c2 = new AllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertEquals(3, c2.getGroupCount());\n\n    AllGroupsCollector c3 = new AllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertEquals(2, c3.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c715a0f99152be7566591f323c6c5a25725a1bcb","date":1307118449,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupsCollectorTest#testTotalGroupCount().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupsCollectorTest#testTotalGroupCount().mjava","sourceNew":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    TermAllGroupsCollector c1 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertEquals(4, c1.getGroupCount());\n\n    TermAllGroupsCollector c2 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertEquals(3, c2.getGroupCount());\n\n    TermAllGroupsCollector c3 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertEquals(2, c3.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    AllGroupsCollector c1 = new AllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertEquals(4, c1.getGroupCount());\n\n    AllGroupsCollector c2 = new AllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertEquals(3, c2.getGroupCount());\n\n    AllGroupsCollector c3 = new AllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertEquals(2, c3.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db36d4499cafd89fde36f3772ecc148d710071d8","date":1307128660,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/TermAllGroupsCollectorTest#testTotalGroupCount().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupsCollectorTest#testTotalGroupCount().mjava","sourceNew":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    TermAllGroupsCollector c1 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertEquals(4, c1.getGroupCount());\n\n    TermAllGroupsCollector c2 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertEquals(3, c2.getGroupCount());\n\n    TermAllGroupsCollector c3 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertEquals(2, c3.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    TermAllGroupsCollector c1 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertEquals(4, c1.getGroupCount());\n\n    TermAllGroupsCollector c2 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertEquals(3, c2.getGroupCount());\n\n    TermAllGroupsCollector c3 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertEquals(2, c3.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c03daa6ddcb4768a702115ec63799cab5fff3d92","date":1307140842,"type":5,"author":"Simon Willnauer","isMerge":true,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/TermAllGroupsCollectorTest#testTotalGroupCount().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupsCollectorTest#testTotalGroupCount().mjava","sourceNew":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    TermAllGroupsCollector c1 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertEquals(4, c1.getGroupCount());\n\n    TermAllGroupsCollector c2 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertEquals(3, c2.getGroupCount());\n\n    TermAllGroupsCollector c3 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertEquals(2, c3.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    TermAllGroupsCollector c1 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertEquals(4, c1.getGroupCount());\n\n    TermAllGroupsCollector c2 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertEquals(3, c2.getGroupCount());\n\n    TermAllGroupsCollector c3 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertEquals(2, c3.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1e7c99bd45fa88a3d93a03fdd773053bef72268e","date":1307218088,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/TermAllGroupsCollectorTest#testTotalGroupCount().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupsCollectorTest#testTotalGroupCount().mjava","sourceNew":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    TermAllGroupsCollector c1 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertEquals(4, c1.getGroupCount());\n\n    TermAllGroupsCollector c2 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertEquals(3, c2.getGroupCount());\n\n    TermAllGroupsCollector c3 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertEquals(2, c3.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random blob\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    AllGroupsCollector c1 = new AllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertEquals(4, c1.getGroupCount());\n\n    AllGroupsCollector c2 = new AllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertEquals(3, c2.getGroupCount());\n\n    AllGroupsCollector c3 = new AllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertEquals(2, c3.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8b48c85d1bf438ef65fbc1abe44f4e2c04a43e00","date":1317931776,"type":1,"author":"Martijn van Groningen","isMerge":false,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupsCollectorTest#testTotalGroupCount().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/TermAllGroupsCollectorTest#testTotalGroupCount().mjava","sourceNew":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"1\", customType));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some more random text blob\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"2\", customType));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some more random textual data\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"3\", customType));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"4\", customType));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"5\", customType));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"random blob\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    AbstractAllGroupsCollector c1 = createRandomCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertEquals(4, c1.getGroupCount());\n\n    AbstractAllGroupsCollector c2 = createRandomCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertEquals(3, c2.getGroupCount());\n\n    AbstractAllGroupsCollector c3 = createRandomCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertEquals(2, c3.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"1\", customType));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some more random text blob\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"2\", customType));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some more random textual data\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"3\", customType));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"4\", customType));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"5\", customType));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"random blob\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    TermAllGroupsCollector c1 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertEquals(4, c1.getGroupCount());\n\n    TermAllGroupsCollector c2 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertEquals(3, c2.getGroupCount());\n\n    TermAllGroupsCollector c3 = new TermAllGroupsCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertEquals(2, c3.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4739c84c362b9673ab5ed3e038ff760c718c30c8","date":1322161679,"type":3,"author":"Martijn van Groningen","isMerge":false,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupsCollectorTest#testTotalGroupCount().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupsCollectorTest#testTotalGroupCount().mjava","sourceNew":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT,\n            new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    boolean canUseIDV = !\"Lucene3x\".equals(w.w.getConfig().getCodec().getName());\n\n    // 0\n    Document doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"1\", customType));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text blob\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"2\", customType));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random textual data\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"3\", customType));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    addGroupField(doc, groupField, \"author2\", canUseIDV);\n    doc.add(new Field(\"content\", \"some random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"4\", customType));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"5\", customType));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"random blob\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    AbstractAllGroupsCollector c1 = createRandomCollector(groupField, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertEquals(4, c1.getGroupCount());\n\n    AbstractAllGroupsCollector c2 = createRandomCollector(groupField, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertEquals(3, c2.getGroupCount());\n\n    AbstractAllGroupsCollector c3 = createRandomCollector(groupField, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertEquals(2, c3.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"1\", customType));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some more random text blob\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"2\", customType));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some more random textual data\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"3\", customType));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"4\", customType));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"5\", customType));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"random blob\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    AbstractAllGroupsCollector c1 = createRandomCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertEquals(4, c1.getGroupCount());\n\n    AbstractAllGroupsCollector c2 = createRandomCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertEquals(3, c2.getGroupCount());\n\n    AbstractAllGroupsCollector c3 = createRandomCollector(groupField);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertEquals(2, c3.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"200be48c182b79811a4fed24fd2d2ad852f092cb","date":1331204120,"type":3,"author":"Martijn van Groningen","isMerge":false,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupsCollectorTest#testTotalGroupCount().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupsCollectorTest#testTotalGroupCount().mjava","sourceNew":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT,\n            new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    boolean canUseIDV = !\"Lucene3x\".equals(w.w.getConfig().getCodec().getName());\n\n    // 0\n    Document doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"1\", customType));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text blob\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"2\", customType));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random textual data\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"3\", customType));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    addGroupField(doc, groupField, \"author2\", canUseIDV);\n    doc.add(new Field(\"content\", \"some random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"4\", customType));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"5\", customType));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"random blob\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    AbstractAllGroupsCollector<?> allGroupsCollector = createRandomCollector(groupField, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), allGroupsCollector);\n    assertEquals(4, allGroupsCollector.getGroupCount());\n\n    allGroupsCollector = createRandomCollector(groupField, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), allGroupsCollector);\n    assertEquals(3, allGroupsCollector.getGroupCount());\n\n    allGroupsCollector = createRandomCollector(groupField, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), allGroupsCollector);\n    assertEquals(2, allGroupsCollector.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT,\n            new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    boolean canUseIDV = !\"Lucene3x\".equals(w.w.getConfig().getCodec().getName());\n\n    // 0\n    Document doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"1\", customType));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text blob\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"2\", customType));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random textual data\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"3\", customType));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    addGroupField(doc, groupField, \"author2\", canUseIDV);\n    doc.add(new Field(\"content\", \"some random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"4\", customType));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"5\", customType));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"random blob\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    AbstractAllGroupsCollector c1 = createRandomCollector(groupField, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertEquals(4, c1.getGroupCount());\n\n    AbstractAllGroupsCollector c2 = createRandomCollector(groupField, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertEquals(3, c2.getGroupCount());\n\n    AbstractAllGroupsCollector c3 = createRandomCollector(groupField, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertEquals(2, c3.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"38e3b736c7ca086d61b7dbb841c905ee115490da","date":1331657018,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupsCollectorTest#testTotalGroupCount().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupsCollectorTest#testTotalGroupCount().mjava","sourceNew":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT,\n            new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    boolean canUseIDV = !\"Lucene3x\".equals(w.w.getConfig().getCodec().getName());\n\n    // 0\n    Document doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"1\", customType));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text blob\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"2\", customType));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random textual data\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"3\", customType));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    addGroupField(doc, groupField, \"author2\", canUseIDV);\n    doc.add(new Field(\"content\", \"some random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"4\", customType));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"5\", customType));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"random blob\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    AbstractAllGroupsCollector<?> allGroupsCollector = createRandomCollector(groupField, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), allGroupsCollector);\n    assertEquals(4, allGroupsCollector.getGroupCount());\n\n    allGroupsCollector = createRandomCollector(groupField, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), allGroupsCollector);\n    assertEquals(3, allGroupsCollector.getGroupCount());\n\n    allGroupsCollector = createRandomCollector(groupField, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), allGroupsCollector);\n    assertEquals(2, allGroupsCollector.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT,\n            new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    boolean canUseIDV = !\"Lucene3x\".equals(w.w.getConfig().getCodec().getName());\n\n    // 0\n    Document doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"1\", customType));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text blob\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"2\", customType));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random textual data\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"3\", customType));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    addGroupField(doc, groupField, \"author2\", canUseIDV);\n    doc.add(new Field(\"content\", \"some random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"4\", customType));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"5\", customType));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"random blob\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    AbstractAllGroupsCollector c1 = createRandomCollector(groupField, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n    assertEquals(4, c1.getGroupCount());\n\n    AbstractAllGroupsCollector c2 = createRandomCollector(groupField, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), c2);\n    assertEquals(3, c2.getGroupCount());\n\n    AbstractAllGroupsCollector c3 = createRandomCollector(groupField, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), c3);\n    assertEquals(2, c3.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupsCollectorTest#testTotalGroupCount().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupsCollectorTest#testTotalGroupCount().mjava","sourceNew":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT,\n            new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    boolean canUseIDV = !\"Lucene3x\".equals(w.w.getConfig().getCodec().getName());\n\n    // 0\n    Document doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"1\", customType));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text blob\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"2\", customType));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random textual data\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"3\", customType));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    addGroupField(doc, groupField, \"author2\", canUseIDV);\n    doc.add(new Field(\"content\", \"some random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"4\", customType));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"5\", customType));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"random blob\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    AbstractAllGroupsCollector<?> allGroupsCollector = createRandomCollector(groupField, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), allGroupsCollector);\n    assertEquals(4, allGroupsCollector.getGroupCount());\n\n    allGroupsCollector = createRandomCollector(groupField, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), allGroupsCollector);\n    assertEquals(3, allGroupsCollector.getGroupCount());\n\n    allGroupsCollector = createRandomCollector(groupField, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), allGroupsCollector);\n    assertEquals(2, allGroupsCollector.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT,\n            new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    boolean canUseIDV = !\"Lucene3x\".equals(w.w.getConfig().getCodec().getName());\n\n    // 0\n    Document doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"1\", customType));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text blob\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"2\", customType));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random textual data\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"3\", customType));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    addGroupField(doc, groupField, \"author2\", canUseIDV);\n    doc.add(new Field(\"content\", \"some random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"4\", customType));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"5\", customType));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"random blob\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    AbstractAllGroupsCollector<?> allGroupsCollector = createRandomCollector(groupField, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), allGroupsCollector);\n    assertEquals(4, allGroupsCollector.getGroupCount());\n\n    allGroupsCollector = createRandomCollector(groupField, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), allGroupsCollector);\n    assertEquals(3, allGroupsCollector.getGroupCount());\n\n    allGroupsCollector = createRandomCollector(groupField, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), allGroupsCollector);\n    assertEquals(2, allGroupsCollector.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/AllGroupsCollectorTest#testTotalGroupCount().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/AllGroupsCollectorTest#testTotalGroupCount().mjava","sourceNew":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT,\n            new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    boolean canUseIDV = !\"Lucene3x\".equals(w.w.getConfig().getCodec().getName());\n\n    // 0\n    Document doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"1\", customType));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text blob\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"2\", customType));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random textual data\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"3\", customType));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    addGroupField(doc, groupField, \"author2\", canUseIDV);\n    doc.add(new Field(\"content\", \"some random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"4\", customType));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"5\", customType));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"random blob\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    AbstractAllGroupsCollector<?> allGroupsCollector = createRandomCollector(groupField, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), allGroupsCollector);\n    assertEquals(4, allGroupsCollector.getGroupCount());\n\n    allGroupsCollector = createRandomCollector(groupField, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), allGroupsCollector);\n    assertEquals(3, allGroupsCollector.getGroupCount());\n\n    allGroupsCollector = createRandomCollector(groupField, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), allGroupsCollector);\n    assertEquals(2, allGroupsCollector.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTotalGroupCount() throws Exception {\n\n    final String groupField = \"author\";\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT,\n            new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    boolean canUseIDV = !\"Lucene3x\".equals(w.w.getConfig().getCodec().getName());\n\n    // 0\n    Document doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"1\", customType));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text blob\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"2\", customType));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random textual data\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"3\", customType));\n    w.addDocument(doc);\n    w.commit(); // To ensure a second segment\n\n    // 3\n    doc = new Document();\n    addGroupField(doc, groupField, \"author2\", canUseIDV);\n    doc.add(new Field(\"content\", \"some random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"4\", customType));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"5\", customType));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"random blob\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    AbstractAllGroupsCollector<?> allGroupsCollector = createRandomCollector(groupField, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), allGroupsCollector);\n    assertEquals(4, allGroupsCollector.getGroupCount());\n\n    allGroupsCollector = createRandomCollector(groupField, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"some\")), allGroupsCollector);\n    assertEquals(3, allGroupsCollector.getGroupCount());\n\n    allGroupsCollector = createRandomCollector(groupField, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"blob\")), allGroupsCollector);\n    assertEquals(2, allGroupsCollector.getGroupCount());\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"c5f61d6a2927b52517a31a8bf022549d33b1dfec":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"38e3b736c7ca086d61b7dbb841c905ee115490da":["4739c84c362b9673ab5ed3e038ff760c718c30c8","200be48c182b79811a4fed24fd2d2ad852f092cb"],"3e1a83e28efa5e061642117ae7766034f738f142":["c5f61d6a2927b52517a31a8bf022549d33b1dfec"],"4739c84c362b9673ab5ed3e038ff760c718c30c8":["8b48c85d1bf438ef65fbc1abe44f4e2c04a43e00"],"c715a0f99152be7566591f323c6c5a25725a1bcb":["c3a8a449466c1ff7ce2274fe73dab487256964b4","3e1a83e28efa5e061642117ae7766034f738f142"],"8b48c85d1bf438ef65fbc1abe44f4e2c04a43e00":["db36d4499cafd89fde36f3772ecc148d710071d8"],"1e7c99bd45fa88a3d93a03fdd773053bef72268e":["a3776dccca01c11e7046323cfad46a3b4a471233","db36d4499cafd89fde36f3772ecc148d710071d8"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"200be48c182b79811a4fed24fd2d2ad852f092cb":["4739c84c362b9673ab5ed3e038ff760c718c30c8"],"c3a8a449466c1ff7ce2274fe73dab487256964b4":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c5f61d6a2927b52517a31a8bf022549d33b1dfec"],"a3776dccca01c11e7046323cfad46a3b4a471233":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c5f61d6a2927b52517a31a8bf022549d33b1dfec"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["200be48c182b79811a4fed24fd2d2ad852f092cb"],"db36d4499cafd89fde36f3772ecc148d710071d8":["3e1a83e28efa5e061642117ae7766034f738f142"],"c03daa6ddcb4768a702115ec63799cab5fff3d92":["c715a0f99152be7566591f323c6c5a25725a1bcb","db36d4499cafd89fde36f3772ecc148d710071d8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b89678825b68eccaf09e6ab71675fc0b0af1e099"]},"commit2Childs":{"c5f61d6a2927b52517a31a8bf022549d33b1dfec":["3e1a83e28efa5e061642117ae7766034f738f142","c3a8a449466c1ff7ce2274fe73dab487256964b4","a3776dccca01c11e7046323cfad46a3b4a471233"],"38e3b736c7ca086d61b7dbb841c905ee115490da":[],"3e1a83e28efa5e061642117ae7766034f738f142":["c715a0f99152be7566591f323c6c5a25725a1bcb","db36d4499cafd89fde36f3772ecc148d710071d8"],"4739c84c362b9673ab5ed3e038ff760c718c30c8":["38e3b736c7ca086d61b7dbb841c905ee115490da","200be48c182b79811a4fed24fd2d2ad852f092cb"],"c715a0f99152be7566591f323c6c5a25725a1bcb":["c03daa6ddcb4768a702115ec63799cab5fff3d92"],"8b48c85d1bf438ef65fbc1abe44f4e2c04a43e00":["4739c84c362b9673ab5ed3e038ff760c718c30c8"],"1e7c99bd45fa88a3d93a03fdd773053bef72268e":[],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"200be48c182b79811a4fed24fd2d2ad852f092cb":["38e3b736c7ca086d61b7dbb841c905ee115490da","629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"c3a8a449466c1ff7ce2274fe73dab487256964b4":["c715a0f99152be7566591f323c6c5a25725a1bcb"],"a3776dccca01c11e7046323cfad46a3b4a471233":["1e7c99bd45fa88a3d93a03fdd773053bef72268e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c5f61d6a2927b52517a31a8bf022549d33b1dfec","c3a8a449466c1ff7ce2274fe73dab487256964b4","a3776dccca01c11e7046323cfad46a3b4a471233"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"db36d4499cafd89fde36f3772ecc148d710071d8":["8b48c85d1bf438ef65fbc1abe44f4e2c04a43e00","1e7c99bd45fa88a3d93a03fdd773053bef72268e","c03daa6ddcb4768a702115ec63799cab5fff3d92"],"c03daa6ddcb4768a702115ec63799cab5fff3d92":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["38e3b736c7ca086d61b7dbb841c905ee115490da","1e7c99bd45fa88a3d93a03fdd773053bef72268e","c03daa6ddcb4768a702115ec63799cab5fff3d92","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}