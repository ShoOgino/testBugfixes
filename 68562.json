{"path":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressReorderVersions().mjava","commits":[{"id":"2c007e7c4cf8c55bc2a5884e315123afaaeec87f","date":1327520966,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressReorderVersions().mjava","pathOld":"/dev/null","sourceNew":"  // This version simulates updates coming from the leader and sometimes being reordered\n  @Test\n  public void testStressReorderVersions() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    final int commitPercent = 5 + random.nextInt(20);\n    final int softCommitPercent = 30+random.nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random.nextInt(25);\n    final int deleteByQueryPercent = 0;  // delete-by-query can't be reordered on replicas\n    final int ndocs = 5 + (random.nextBoolean() ? random.nextInt(25) : random.nextInt(200));\n    int nWriteThreads = 5 + random.nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 75;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random.nextInt(25);\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n\n    final AtomicLong testVersion = new AtomicLong(0);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id;\n\n            if (rand.nextBoolean()) {\n              id = rand.nextInt(ndocs);\n            } else {\n              id = lastId;  // reuse the last ID half of the time to force more race conditions\n            }\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            DocInfo info = model.get(id);\n\n            long val = info.val;\n            long nextVal = Math.abs(val)+1;\n\n            // the version we set on the update should determine who wins\n            // These versions are not derived from the actual leader update handler hand hence this\n            // test may need to change depending on how we handle version numbers.\n            long version = testVersion.incrementAndGet();\n\n            // yield after getting the next version to increase the odds of updates happening out of order\n            if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent) {\n                verbose(\"deleting id\",id,\"val=\",nextVal,\"version\",version);\n\n                Long returnedVersion = deleteAndGetVersion(Integer.toString(id), params(\"_version_\",Long.toString(-version), SEEN_LEADER,SEEN_LEADER_VAL));\n\n                // TODO: returning versions for these types of updates is redundant\n                // but if we do return, they had better be equal\n                if (returnedVersion != null) {\n                  assertEquals(-version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (Math.abs(version) > Math.abs(currInfo.version)) {\n                    model.put(id, new DocInfo(version, -nextVal));\n                  }\n                }\n\n                verbose(\"deleting id\", id, \"val=\",nextVal,\"version\",version,\"DONE\");\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n\n              } else {\n                verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version);\n\n                Long returnedVersion = addAndGetVersion(sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal), \"_version_\",Long.toString(version)), params(SEEN_LEADER,SEEN_LEADER_VAL));\n                if (returnedVersion != null) {\n                  assertEquals(version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (version > currInfo.version) {\n                    model.put(id, new DocInfo(version, nextVal));\n                  }\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version,\"DONE\");\n                }\n\n              }\n            // }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          SolrException.log(log, e);\n          fail(e.getMessage());\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVer < Math.abs(info.version)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log, e);\n            fail(e.getMessage());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","date":1327523564,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressReorderVersions().mjava","pathOld":"/dev/null","sourceNew":"  // This version simulates updates coming from the leader and sometimes being reordered\n  @Test\n  public void testStressReorderVersions() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    final int commitPercent = 5 + random.nextInt(20);\n    final int softCommitPercent = 30+random.nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random.nextInt(25);\n    final int deleteByQueryPercent = 0;  // delete-by-query can't be reordered on replicas\n    final int ndocs = 5 + (random.nextBoolean() ? random.nextInt(25) : random.nextInt(200));\n    int nWriteThreads = 5 + random.nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 75;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random.nextInt(25);\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n\n    final AtomicLong testVersion = new AtomicLong(0);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id;\n\n            if (rand.nextBoolean()) {\n              id = rand.nextInt(ndocs);\n            } else {\n              id = lastId;  // reuse the last ID half of the time to force more race conditions\n            }\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            DocInfo info = model.get(id);\n\n            long val = info.val;\n            long nextVal = Math.abs(val)+1;\n\n            // the version we set on the update should determine who wins\n            // These versions are not derived from the actual leader update handler hand hence this\n            // test may need to change depending on how we handle version numbers.\n            long version = testVersion.incrementAndGet();\n\n            // yield after getting the next version to increase the odds of updates happening out of order\n            if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent) {\n                verbose(\"deleting id\",id,\"val=\",nextVal,\"version\",version);\n\n                Long returnedVersion = deleteAndGetVersion(Integer.toString(id), params(\"_version_\",Long.toString(-version), SEEN_LEADER,SEEN_LEADER_VAL));\n\n                // TODO: returning versions for these types of updates is redundant\n                // but if we do return, they had better be equal\n                if (returnedVersion != null) {\n                  assertEquals(-version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (Math.abs(version) > Math.abs(currInfo.version)) {\n                    model.put(id, new DocInfo(version, -nextVal));\n                  }\n                }\n\n                verbose(\"deleting id\", id, \"val=\",nextVal,\"version\",version,\"DONE\");\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n\n              } else {\n                verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version);\n\n                Long returnedVersion = addAndGetVersion(sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal), \"_version_\",Long.toString(version)), params(SEEN_LEADER,SEEN_LEADER_VAL));\n                if (returnedVersion != null) {\n                  assertEquals(version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (version > currInfo.version) {\n                    model.put(id, new DocInfo(version, nextVal));\n                  }\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version,\"DONE\");\n                }\n\n              }\n            // }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          SolrException.log(log, e);\n          fail(e.getMessage());\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVer < Math.abs(info.version)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log, e);\n            fail(e.getMessage());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0d22ac6a4146774c1bc8400160fc0b6150294e92","date":1327528604,"type":0,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressReorderVersions().mjava","pathOld":"/dev/null","sourceNew":"  // This version simulates updates coming from the leader and sometimes being reordered\n  @Test\n  public void testStressReorderVersions() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    final int commitPercent = 5 + random.nextInt(20);\n    final int softCommitPercent = 30+random.nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random.nextInt(25);\n    final int deleteByQueryPercent = 0;  // delete-by-query can't be reordered on replicas\n    final int ndocs = 5 + (random.nextBoolean() ? random.nextInt(25) : random.nextInt(200));\n    int nWriteThreads = 5 + random.nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 75;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random.nextInt(25);\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n\n    final AtomicLong testVersion = new AtomicLong(0);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id;\n\n            if (rand.nextBoolean()) {\n              id = rand.nextInt(ndocs);\n            } else {\n              id = lastId;  // reuse the last ID half of the time to force more race conditions\n            }\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            DocInfo info = model.get(id);\n\n            long val = info.val;\n            long nextVal = Math.abs(val)+1;\n\n            // the version we set on the update should determine who wins\n            // These versions are not derived from the actual leader update handler hand hence this\n            // test may need to change depending on how we handle version numbers.\n            long version = testVersion.incrementAndGet();\n\n            // yield after getting the next version to increase the odds of updates happening out of order\n            if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent) {\n                verbose(\"deleting id\",id,\"val=\",nextVal,\"version\",version);\n\n                Long returnedVersion = deleteAndGetVersion(Integer.toString(id), params(\"_version_\",Long.toString(-version), SEEN_LEADER,SEEN_LEADER_VAL));\n\n                // TODO: returning versions for these types of updates is redundant\n                // but if we do return, they had better be equal\n                if (returnedVersion != null) {\n                  assertEquals(-version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (Math.abs(version) > Math.abs(currInfo.version)) {\n                    model.put(id, new DocInfo(version, -nextVal));\n                  }\n                }\n\n                verbose(\"deleting id\", id, \"val=\",nextVal,\"version\",version,\"DONE\");\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n\n              } else {\n                verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version);\n\n                Long returnedVersion = addAndGetVersion(sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal), \"_version_\",Long.toString(version)), params(SEEN_LEADER,SEEN_LEADER_VAL));\n                if (returnedVersion != null) {\n                  assertEquals(version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (version > currInfo.version) {\n                    model.put(id, new DocInfo(version, nextVal));\n                  }\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version,\"DONE\");\n                }\n\n              }\n            // }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          SolrException.log(log, e);\n          fail(e.getMessage());\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVer < Math.abs(info.version)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log, e);\n            fail(e.getMessage());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f08557cdb6c60ac7b88a9342c983a20cd236e74f","date":1330954480,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressReorderVersions().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressReorderVersions().mjava","sourceNew":"  // This version simulates updates coming from the leader and sometimes being reordered\n  @Test\n  public void testStressReorderVersions() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    final int commitPercent = 5 + random.nextInt(20);\n    final int softCommitPercent = 30+random.nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random.nextInt(25);\n    final int deleteByQueryPercent = 0;  // delete-by-query can't be reordered on replicas\n    final int ndocs = 5 + (random.nextBoolean() ? random.nextInt(25) : random.nextInt(200));\n    int nWriteThreads = 5 + random.nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 75;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random.nextInt(25);\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n\n    final AtomicLong testVersion = new AtomicLong(0);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id;\n\n            if (rand.nextBoolean()) {\n              id = rand.nextInt(ndocs);\n            } else {\n              id = lastId;  // reuse the last ID half of the time to force more race conditions\n            }\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            DocInfo info = model.get(id);\n\n            long val = info.val;\n            long nextVal = Math.abs(val)+1;\n\n            // the version we set on the update should determine who wins\n            // These versions are not derived from the actual leader update handler hand hence this\n            // test may need to change depending on how we handle version numbers.\n            long version = testVersion.incrementAndGet();\n\n            // yield after getting the next version to increase the odds of updates happening out of order\n            if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent) {\n                verbose(\"deleting id\",id,\"val=\",nextVal,\"version\",version);\n\n                Long returnedVersion = deleteAndGetVersion(Integer.toString(id), params(\"_version_\",Long.toString(-version), SEEN_LEADER,SEEN_LEADER_VAL));\n\n                // TODO: returning versions for these types of updates is redundant\n                // but if we do return, they had better be equal\n                if (returnedVersion != null) {\n                  assertEquals(-version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (Math.abs(version) > Math.abs(currInfo.version)) {\n                    model.put(id, new DocInfo(version, -nextVal));\n                  }\n                }\n\n                verbose(\"deleting id\", id, \"val=\",nextVal,\"version\",version,\"DONE\");\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n\n              } else {\n                verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version);\n\n                Long returnedVersion = addAndGetVersion(sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal), \"_version_\",Long.toString(version)), params(SEEN_LEADER,SEEN_LEADER_VAL));\n                if (returnedVersion != null) {\n                  assertEquals(version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (version > currInfo.version) {\n                    model.put(id, new DocInfo(version, nextVal));\n                  }\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version,\"DONE\");\n                }\n\n              }\n            // }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          SolrException.log(log, e);\n          fail(e.getMessage());\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVer < Math.abs(info.version)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log, e);\n            fail(e.getMessage());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"  // This version simulates updates coming from the leader and sometimes being reordered\n  @Test\n  public void testStressReorderVersions() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    final int commitPercent = 5 + random.nextInt(20);\n    final int softCommitPercent = 30+random.nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random.nextInt(25);\n    final int deleteByQueryPercent = 0;  // delete-by-query can't be reordered on replicas\n    final int ndocs = 5 + (random.nextBoolean() ? random.nextInt(25) : random.nextInt(200));\n    int nWriteThreads = 5 + random.nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 75;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random.nextInt(25);\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n\n    final AtomicLong testVersion = new AtomicLong(0);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id;\n\n            if (rand.nextBoolean()) {\n              id = rand.nextInt(ndocs);\n            } else {\n              id = lastId;  // reuse the last ID half of the time to force more race conditions\n            }\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            DocInfo info = model.get(id);\n\n            long val = info.val;\n            long nextVal = Math.abs(val)+1;\n\n            // the version we set on the update should determine who wins\n            // These versions are not derived from the actual leader update handler hand hence this\n            // test may need to change depending on how we handle version numbers.\n            long version = testVersion.incrementAndGet();\n\n            // yield after getting the next version to increase the odds of updates happening out of order\n            if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent) {\n                verbose(\"deleting id\",id,\"val=\",nextVal,\"version\",version);\n\n                Long returnedVersion = deleteAndGetVersion(Integer.toString(id), params(\"_version_\",Long.toString(-version), SEEN_LEADER,SEEN_LEADER_VAL));\n\n                // TODO: returning versions for these types of updates is redundant\n                // but if we do return, they had better be equal\n                if (returnedVersion != null) {\n                  assertEquals(-version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (Math.abs(version) > Math.abs(currInfo.version)) {\n                    model.put(id, new DocInfo(version, -nextVal));\n                  }\n                }\n\n                verbose(\"deleting id\", id, \"val=\",nextVal,\"version\",version,\"DONE\");\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n\n              } else {\n                verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version);\n\n                Long returnedVersion = addAndGetVersion(sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal), \"_version_\",Long.toString(version)), params(SEEN_LEADER,SEEN_LEADER_VAL));\n                if (returnedVersion != null) {\n                  assertEquals(version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (version > currInfo.version) {\n                    model.put(id, new DocInfo(version, nextVal));\n                  }\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version,\"DONE\");\n                }\n\n              }\n            // }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          SolrException.log(log, e);\n          fail(e.getMessage());\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVer < Math.abs(info.version)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log, e);\n            fail(e.getMessage());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","date":1331075828,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressReorderVersions().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressReorderVersions().mjava","sourceNew":"  // This version simulates updates coming from the leader and sometimes being reordered\n  @Test\n  public void testStressReorderVersions() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    final int commitPercent = 5 + random.nextInt(20);\n    final int softCommitPercent = 30+random.nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random.nextInt(25);\n    final int deleteByQueryPercent = 0;  // delete-by-query can't be reordered on replicas\n    final int ndocs = 5 + (random.nextBoolean() ? random.nextInt(25) : random.nextInt(200));\n    int nWriteThreads = 5 + random.nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 75;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random.nextInt(25);\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n\n    final AtomicLong testVersion = new AtomicLong(0);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id;\n\n            if (rand.nextBoolean()) {\n              id = rand.nextInt(ndocs);\n            } else {\n              id = lastId;  // reuse the last ID half of the time to force more race conditions\n            }\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            DocInfo info = model.get(id);\n\n            long val = info.val;\n            long nextVal = Math.abs(val)+1;\n\n            // the version we set on the update should determine who wins\n            // These versions are not derived from the actual leader update handler hand hence this\n            // test may need to change depending on how we handle version numbers.\n            long version = testVersion.incrementAndGet();\n\n            // yield after getting the next version to increase the odds of updates happening out of order\n            if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent) {\n                verbose(\"deleting id\",id,\"val=\",nextVal,\"version\",version);\n\n                Long returnedVersion = deleteAndGetVersion(Integer.toString(id), params(\"_version_\",Long.toString(-version), SEEN_LEADER,SEEN_LEADER_VAL));\n\n                // TODO: returning versions for these types of updates is redundant\n                // but if we do return, they had better be equal\n                if (returnedVersion != null) {\n                  assertEquals(-version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (Math.abs(version) > Math.abs(currInfo.version)) {\n                    model.put(id, new DocInfo(version, -nextVal));\n                  }\n                }\n\n                verbose(\"deleting id\", id, \"val=\",nextVal,\"version\",version,\"DONE\");\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n\n              } else {\n                verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version);\n\n                Long returnedVersion = addAndGetVersion(sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal), \"_version_\",Long.toString(version)), params(SEEN_LEADER,SEEN_LEADER_VAL));\n                if (returnedVersion != null) {\n                  assertEquals(version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (version > currInfo.version) {\n                    model.put(id, new DocInfo(version, nextVal));\n                  }\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version,\"DONE\");\n                }\n\n              }\n            // }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          SolrException.log(log, e);\n          fail(e.getMessage());\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVer < Math.abs(info.version)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log, e);\n            fail(e.getMessage());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"  // This version simulates updates coming from the leader and sometimes being reordered\n  @Test\n  public void testStressReorderVersions() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    final int commitPercent = 5 + random.nextInt(20);\n    final int softCommitPercent = 30+random.nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random.nextInt(25);\n    final int deleteByQueryPercent = 0;  // delete-by-query can't be reordered on replicas\n    final int ndocs = 5 + (random.nextBoolean() ? random.nextInt(25) : random.nextInt(200));\n    int nWriteThreads = 5 + random.nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 75;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random.nextInt(25);\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n\n    final AtomicLong testVersion = new AtomicLong(0);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id;\n\n            if (rand.nextBoolean()) {\n              id = rand.nextInt(ndocs);\n            } else {\n              id = lastId;  // reuse the last ID half of the time to force more race conditions\n            }\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            DocInfo info = model.get(id);\n\n            long val = info.val;\n            long nextVal = Math.abs(val)+1;\n\n            // the version we set on the update should determine who wins\n            // These versions are not derived from the actual leader update handler hand hence this\n            // test may need to change depending on how we handle version numbers.\n            long version = testVersion.incrementAndGet();\n\n            // yield after getting the next version to increase the odds of updates happening out of order\n            if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent) {\n                verbose(\"deleting id\",id,\"val=\",nextVal,\"version\",version);\n\n                Long returnedVersion = deleteAndGetVersion(Integer.toString(id), params(\"_version_\",Long.toString(-version), SEEN_LEADER,SEEN_LEADER_VAL));\n\n                // TODO: returning versions for these types of updates is redundant\n                // but if we do return, they had better be equal\n                if (returnedVersion != null) {\n                  assertEquals(-version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (Math.abs(version) > Math.abs(currInfo.version)) {\n                    model.put(id, new DocInfo(version, -nextVal));\n                  }\n                }\n\n                verbose(\"deleting id\", id, \"val=\",nextVal,\"version\",version,\"DONE\");\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n\n              } else {\n                verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version);\n\n                Long returnedVersion = addAndGetVersion(sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal), \"_version_\",Long.toString(version)), params(SEEN_LEADER,SEEN_LEADER_VAL));\n                if (returnedVersion != null) {\n                  assertEquals(version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (version > currInfo.version) {\n                    model.put(id, new DocInfo(version, nextVal));\n                  }\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version,\"DONE\");\n                }\n\n              }\n            // }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          SolrException.log(log, e);\n          fail(e.getMessage());\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVer < Math.abs(info.version)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log, e);\n            fail(e.getMessage());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressReorderVersions().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressReorderVersions().mjava","sourceNew":"  // This version simulates updates coming from the leader and sometimes being reordered\n  @Test\n  public void testStressReorderVersions() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 0;  // delete-by-query can't be reordered on replicas\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 75;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n\n    final AtomicLong testVersion = new AtomicLong(0);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id;\n\n            if (rand.nextBoolean()) {\n              id = rand.nextInt(ndocs);\n            } else {\n              id = lastId;  // reuse the last ID half of the time to force more race conditions\n            }\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            DocInfo info = model.get(id);\n\n            long val = info.val;\n            long nextVal = Math.abs(val)+1;\n\n            // the version we set on the update should determine who wins\n            // These versions are not derived from the actual leader update handler hand hence this\n            // test may need to change depending on how we handle version numbers.\n            long version = testVersion.incrementAndGet();\n\n            // yield after getting the next version to increase the odds of updates happening out of order\n            if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent) {\n                verbose(\"deleting id\",id,\"val=\",nextVal,\"version\",version);\n\n                Long returnedVersion = deleteAndGetVersion(Integer.toString(id), params(\"_version_\",Long.toString(-version), SEEN_LEADER,SEEN_LEADER_VAL));\n\n                // TODO: returning versions for these types of updates is redundant\n                // but if we do return, they had better be equal\n                if (returnedVersion != null) {\n                  assertEquals(-version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (Math.abs(version) > Math.abs(currInfo.version)) {\n                    model.put(id, new DocInfo(version, -nextVal));\n                  }\n                }\n\n                verbose(\"deleting id\", id, \"val=\",nextVal,\"version\",version,\"DONE\");\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n\n              } else {\n                verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version);\n\n                Long returnedVersion = addAndGetVersion(sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal), \"_version_\",Long.toString(version)), params(SEEN_LEADER,SEEN_LEADER_VAL));\n                if (returnedVersion != null) {\n                  assertEquals(version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (version > currInfo.version) {\n                    model.put(id, new DocInfo(version, nextVal));\n                  }\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version,\"DONE\");\n                }\n\n              }\n            // }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          SolrException.log(log, e);\n          fail(e.getMessage());\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVer < Math.abs(info.version)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log, e);\n            fail(e.getMessage());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"  // This version simulates updates coming from the leader and sometimes being reordered\n  @Test\n  public void testStressReorderVersions() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    final int commitPercent = 5 + random.nextInt(20);\n    final int softCommitPercent = 30+random.nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random.nextInt(25);\n    final int deleteByQueryPercent = 0;  // delete-by-query can't be reordered on replicas\n    final int ndocs = 5 + (random.nextBoolean() ? random.nextInt(25) : random.nextInt(200));\n    int nWriteThreads = 5 + random.nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 75;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random.nextInt(25);\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n\n    final AtomicLong testVersion = new AtomicLong(0);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id;\n\n            if (rand.nextBoolean()) {\n              id = rand.nextInt(ndocs);\n            } else {\n              id = lastId;  // reuse the last ID half of the time to force more race conditions\n            }\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            DocInfo info = model.get(id);\n\n            long val = info.val;\n            long nextVal = Math.abs(val)+1;\n\n            // the version we set on the update should determine who wins\n            // These versions are not derived from the actual leader update handler hand hence this\n            // test may need to change depending on how we handle version numbers.\n            long version = testVersion.incrementAndGet();\n\n            // yield after getting the next version to increase the odds of updates happening out of order\n            if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent) {\n                verbose(\"deleting id\",id,\"val=\",nextVal,\"version\",version);\n\n                Long returnedVersion = deleteAndGetVersion(Integer.toString(id), params(\"_version_\",Long.toString(-version), SEEN_LEADER,SEEN_LEADER_VAL));\n\n                // TODO: returning versions for these types of updates is redundant\n                // but if we do return, they had better be equal\n                if (returnedVersion != null) {\n                  assertEquals(-version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (Math.abs(version) > Math.abs(currInfo.version)) {\n                    model.put(id, new DocInfo(version, -nextVal));\n                  }\n                }\n\n                verbose(\"deleting id\", id, \"val=\",nextVal,\"version\",version,\"DONE\");\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n\n              } else {\n                verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version);\n\n                Long returnedVersion = addAndGetVersion(sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal), \"_version_\",Long.toString(version)), params(SEEN_LEADER,SEEN_LEADER_VAL));\n                if (returnedVersion != null) {\n                  assertEquals(version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (version > currInfo.version) {\n                    model.put(id, new DocInfo(version, nextVal));\n                  }\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version,\"DONE\");\n                }\n\n              }\n            // }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          SolrException.log(log, e);\n          fail(e.getMessage());\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVer < Math.abs(info.version)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log, e);\n            fail(e.getMessage());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1bea3922196318026c4274f2013416acb60c691e","date":1336496433,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressReorderVersions().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressReorderVersions().mjava","sourceNew":"  // This version simulates updates coming from the leader and sometimes being reordered\n  @Test\n  public void testStressReorderVersions() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 0;  // delete-by-query can't be reordered on replicas\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 75;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n\n    final AtomicLong testVersion = new AtomicLong(0);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id;\n\n            if (rand.nextBoolean()) {\n              id = rand.nextInt(ndocs);\n            } else {\n              id = lastId;  // reuse the last ID half of the time to force more race conditions\n            }\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            DocInfo info = model.get(id);\n\n            long val = info.val;\n            long nextVal = Math.abs(val)+1;\n\n            // the version we set on the update should determine who wins\n            // These versions are not derived from the actual leader update handler hand hence this\n            // test may need to change depending on how we handle version numbers.\n            long version = testVersion.incrementAndGet();\n\n            // yield after getting the next version to increase the odds of updates happening out of order\n            if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent) {\n                verbose(\"deleting id\",id,\"val=\",nextVal,\"version\",version);\n\n                Long returnedVersion = deleteAndGetVersion(Integer.toString(id), params(\"_version_\",Long.toString(-version), SEEN_LEADER,SEEN_LEADER_VAL));\n\n                // TODO: returning versions for these types of updates is redundant\n                // but if we do return, they had better be equal\n                if (returnedVersion != null) {\n                  assertEquals(-version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (Math.abs(version) > Math.abs(currInfo.version)) {\n                    model.put(id, new DocInfo(version, -nextVal));\n                  }\n                }\n\n                verbose(\"deleting id\", id, \"val=\",nextVal,\"version\",version,\"DONE\");\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n\n              } else {\n                verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version);\n\n                Long returnedVersion = addAndGetVersion(sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal), \"_version_\",Long.toString(version)), params(SEEN_LEADER,SEEN_LEADER_VAL));\n                if (returnedVersion != null) {\n                  assertEquals(version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (version > currInfo.version) {\n                    model.put(id, new DocInfo(version, nextVal));\n                  }\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version,\"DONE\");\n                }\n\n              }\n            // }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVer < Math.abs(info.version)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"  // This version simulates updates coming from the leader and sometimes being reordered\n  @Test\n  public void testStressReorderVersions() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 0;  // delete-by-query can't be reordered on replicas\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 75;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n\n    final AtomicLong testVersion = new AtomicLong(0);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id;\n\n            if (rand.nextBoolean()) {\n              id = rand.nextInt(ndocs);\n            } else {\n              id = lastId;  // reuse the last ID half of the time to force more race conditions\n            }\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            DocInfo info = model.get(id);\n\n            long val = info.val;\n            long nextVal = Math.abs(val)+1;\n\n            // the version we set on the update should determine who wins\n            // These versions are not derived from the actual leader update handler hand hence this\n            // test may need to change depending on how we handle version numbers.\n            long version = testVersion.incrementAndGet();\n\n            // yield after getting the next version to increase the odds of updates happening out of order\n            if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent) {\n                verbose(\"deleting id\",id,\"val=\",nextVal,\"version\",version);\n\n                Long returnedVersion = deleteAndGetVersion(Integer.toString(id), params(\"_version_\",Long.toString(-version), SEEN_LEADER,SEEN_LEADER_VAL));\n\n                // TODO: returning versions for these types of updates is redundant\n                // but if we do return, they had better be equal\n                if (returnedVersion != null) {\n                  assertEquals(-version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (Math.abs(version) > Math.abs(currInfo.version)) {\n                    model.put(id, new DocInfo(version, -nextVal));\n                  }\n                }\n\n                verbose(\"deleting id\", id, \"val=\",nextVal,\"version\",version,\"DONE\");\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n\n              } else {\n                verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version);\n\n                Long returnedVersion = addAndGetVersion(sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal), \"_version_\",Long.toString(version)), params(SEEN_LEADER,SEEN_LEADER_VAL));\n                if (returnedVersion != null) {\n                  assertEquals(version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (version > currInfo.version) {\n                    model.put(id, new DocInfo(version, nextVal));\n                  }\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version,\"DONE\");\n                }\n\n              }\n            // }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          SolrException.log(log, e);\n          fail(e.getMessage());\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVer < Math.abs(info.version)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log, e);\n            fail(e.getMessage());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e2fe35ac47f8f51356d6c1724455d18f31c94fae","date":1337966698,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressReorderVersions().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressReorderVersions().mjava","sourceNew":"  // This version simulates updates coming from the leader and sometimes being reordered\n  @Test\n  public void testStressReorderVersions() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 0;  // delete-by-query can't be reordered on replicas\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 75;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n\n    final AtomicLong testVersion = new AtomicLong(0);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id;\n\n            if (rand.nextBoolean()) {\n              id = rand.nextInt(ndocs);\n            } else {\n              id = lastId;  // reuse the last ID half of the time to force more race conditions\n            }\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            DocInfo info = model.get(id);\n\n            long val = info.val;\n            long nextVal = Math.abs(val)+1;\n\n            // the version we set on the update should determine who wins\n            // These versions are not derived from the actual leader update handler hand hence this\n            // test may need to change depending on how we handle version numbers.\n            long version = testVersion.incrementAndGet();\n\n            // yield after getting the next version to increase the odds of updates happening out of order\n            if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent) {\n                verbose(\"deleting id\",id,\"val=\",nextVal,\"version\",version);\n\n                Long returnedVersion = deleteAndGetVersion(Integer.toString(id), params(\"_version_\",Long.toString(-version), DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n                // TODO: returning versions for these types of updates is redundant\n                // but if we do return, they had better be equal\n                if (returnedVersion != null) {\n                  assertEquals(-version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (Math.abs(version) > Math.abs(currInfo.version)) {\n                    model.put(id, new DocInfo(version, -nextVal));\n                  }\n                }\n\n                verbose(\"deleting id\", id, \"val=\",nextVal,\"version\",version,\"DONE\");\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n\n              } else {\n                verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version);\n\n                Long returnedVersion = addAndGetVersion(sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal), \"_version_\",Long.toString(version)), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n                if (returnedVersion != null) {\n                  assertEquals(version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (version > currInfo.version) {\n                    model.put(id, new DocInfo(version, nextVal));\n                  }\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version,\"DONE\");\n                }\n\n              }\n            // }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVer < Math.abs(info.version)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"  // This version simulates updates coming from the leader and sometimes being reordered\n  @Test\n  public void testStressReorderVersions() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 0;  // delete-by-query can't be reordered on replicas\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 75;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n\n    final AtomicLong testVersion = new AtomicLong(0);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id;\n\n            if (rand.nextBoolean()) {\n              id = rand.nextInt(ndocs);\n            } else {\n              id = lastId;  // reuse the last ID half of the time to force more race conditions\n            }\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            DocInfo info = model.get(id);\n\n            long val = info.val;\n            long nextVal = Math.abs(val)+1;\n\n            // the version we set on the update should determine who wins\n            // These versions are not derived from the actual leader update handler hand hence this\n            // test may need to change depending on how we handle version numbers.\n            long version = testVersion.incrementAndGet();\n\n            // yield after getting the next version to increase the odds of updates happening out of order\n            if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent) {\n                verbose(\"deleting id\",id,\"val=\",nextVal,\"version\",version);\n\n                Long returnedVersion = deleteAndGetVersion(Integer.toString(id), params(\"_version_\",Long.toString(-version), SEEN_LEADER,SEEN_LEADER_VAL));\n\n                // TODO: returning versions for these types of updates is redundant\n                // but if we do return, they had better be equal\n                if (returnedVersion != null) {\n                  assertEquals(-version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (Math.abs(version) > Math.abs(currInfo.version)) {\n                    model.put(id, new DocInfo(version, -nextVal));\n                  }\n                }\n\n                verbose(\"deleting id\", id, \"val=\",nextVal,\"version\",version,\"DONE\");\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n\n              } else {\n                verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version);\n\n                Long returnedVersion = addAndGetVersion(sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal), \"_version_\",Long.toString(version)), params(SEEN_LEADER,SEEN_LEADER_VAL));\n                if (returnedVersion != null) {\n                  assertEquals(version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (version > currInfo.version) {\n                    model.put(id, new DocInfo(version, nextVal));\n                  }\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version,\"DONE\");\n                }\n\n              }\n            // }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVer < Math.abs(info.version)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fb999ed3fc6e419b9104de9ebfe62ace27f31d5f","date":1341327930,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressReorderVersions().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressReorderVersions().mjava","sourceNew":"  // This version simulates updates coming from the leader and sometimes being reordered\n  @Test\n  public void testStressReorderVersions() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 1+random().nextInt(7);\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 75;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    /** // testing\n    final int commitPercent = 5;\n    final int softCommitPercent = 100; // what percent of the commits are soft\n    final int deletePercent = 0;\n    final int deleteByQueryPercent = 50;\n    final int ndocs = 1;\n    int nWriteThreads = 2;\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n    // query variables\n    final int percentRealtimeQuery = 101;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 1;\n    **/\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n\n    final AtomicLong testVersion = new AtomicLong(0);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id;\n\n            if (rand.nextBoolean()) {\n              id = rand.nextInt(ndocs);\n            } else {\n              id = lastId;  // reuse the last ID half of the time to force more race conditions\n            }\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            DocInfo info = model.get(id);\n\n            long val = info.val;\n            long nextVal = Math.abs(val)+1;\n\n            // the version we set on the update should determine who wins\n            // These versions are not derived from the actual leader update handler hand hence this\n            // test may need to change depending on how we handle version numbers.\n            long version = testVersion.incrementAndGet();\n\n            // yield after getting the next version to increase the odds of updates happening out of order\n            if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent) {\n                verbose(\"deleting id\",id,\"val=\",nextVal,\"version\",version);\n\n                Long returnedVersion = deleteAndGetVersion(Integer.toString(id), params(\"_version_\",Long.toString(-version), DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n                // TODO: returning versions for these types of updates is redundant\n                // but if we do return, they had better be equal\n                if (returnedVersion != null) {\n                  assertEquals(-version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (Math.abs(version) > Math.abs(currInfo.version)) {\n                    model.put(id, new DocInfo(version, -nextVal));\n                  }\n                }\n\n                verbose(\"deleting id\", id, \"val=\",nextVal,\"version\",version,\"DONE\");\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n\n                verbose(\"deleteByQuery id\",id,\"val=\",nextVal,\"version\",version);\n\n                Long returnedVersion = deleteByQueryAndGetVersion(\"id:\"+Integer.toString(id), params(\"_version_\",Long.toString(-version), DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n                // TODO: returning versions for these types of updates is redundant\n                // but if we do return, they had better be equal\n                if (returnedVersion != null) {\n                  assertEquals(-version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (Math.abs(version) > Math.abs(currInfo.version)) {\n                    model.put(id, new DocInfo(version, -nextVal));\n                  }\n                }\n\n                verbose(\"deleteByQuery id\", id, \"val=\",nextVal,\"version\",version,\"DONE\");\n\n              } else {\n                verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version);\n\n                Long returnedVersion = addAndGetVersion(sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal), \"_version_\",Long.toString(version)), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n                if (returnedVersion != null) {\n                  assertEquals(version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (version > currInfo.version) {\n                    model.put(id, new DocInfo(version, nextVal));\n                  }\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version,\"DONE\");\n                }\n\n              }\n            // }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\",e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVer < Math.abs(info.version)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\",e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"  // This version simulates updates coming from the leader and sometimes being reordered\n  @Test\n  public void testStressReorderVersions() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 0;  // delete-by-query can't be reordered on replicas\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 75;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n\n    final AtomicLong testVersion = new AtomicLong(0);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id;\n\n            if (rand.nextBoolean()) {\n              id = rand.nextInt(ndocs);\n            } else {\n              id = lastId;  // reuse the last ID half of the time to force more race conditions\n            }\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            DocInfo info = model.get(id);\n\n            long val = info.val;\n            long nextVal = Math.abs(val)+1;\n\n            // the version we set on the update should determine who wins\n            // These versions are not derived from the actual leader update handler hand hence this\n            // test may need to change depending on how we handle version numbers.\n            long version = testVersion.incrementAndGet();\n\n            // yield after getting the next version to increase the odds of updates happening out of order\n            if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent) {\n                verbose(\"deleting id\",id,\"val=\",nextVal,\"version\",version);\n\n                Long returnedVersion = deleteAndGetVersion(Integer.toString(id), params(\"_version_\",Long.toString(-version), DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n                // TODO: returning versions for these types of updates is redundant\n                // but if we do return, they had better be equal\n                if (returnedVersion != null) {\n                  assertEquals(-version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (Math.abs(version) > Math.abs(currInfo.version)) {\n                    model.put(id, new DocInfo(version, -nextVal));\n                  }\n                }\n\n                verbose(\"deleting id\", id, \"val=\",nextVal,\"version\",version,\"DONE\");\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n\n              } else {\n                verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version);\n\n                Long returnedVersion = addAndGetVersion(sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal), \"_version_\",Long.toString(version)), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n                if (returnedVersion != null) {\n                  assertEquals(version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (version > currInfo.version) {\n                    model.put(id, new DocInfo(version, nextVal));\n                  }\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version,\"DONE\");\n                }\n\n              }\n            // }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVer < Math.abs(info.version)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"082bf4ef6a721f2673b8f1e99c69c80cfe0de8fe","date":1341363293,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressReorderVersions().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressReorderVersions().mjava","sourceNew":"  // This version simulates updates coming from the leader and sometimes being reordered\n  @Test\n  public void testStressReorderVersions() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 0; // 1+random().nextInt(7);\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 75;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    /** // testing\n    final int commitPercent = 5;\n    final int softCommitPercent = 100; // what percent of the commits are soft\n    final int deletePercent = 0;\n    final int deleteByQueryPercent = 50;\n    final int ndocs = 1;\n    int nWriteThreads = 2;\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n    // query variables\n    final int percentRealtimeQuery = 101;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 1;\n    **/\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n\n    final AtomicLong testVersion = new AtomicLong(0);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id;\n\n            if (rand.nextBoolean()) {\n              id = rand.nextInt(ndocs);\n            } else {\n              id = lastId;  // reuse the last ID half of the time to force more race conditions\n            }\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            DocInfo info = model.get(id);\n\n            long val = info.val;\n            long nextVal = Math.abs(val)+1;\n\n            // the version we set on the update should determine who wins\n            // These versions are not derived from the actual leader update handler hand hence this\n            // test may need to change depending on how we handle version numbers.\n            long version = testVersion.incrementAndGet();\n\n            // yield after getting the next version to increase the odds of updates happening out of order\n            if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent) {\n                verbose(\"deleting id\",id,\"val=\",nextVal,\"version\",version);\n\n                Long returnedVersion = deleteAndGetVersion(Integer.toString(id), params(\"_version_\",Long.toString(-version), DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n                // TODO: returning versions for these types of updates is redundant\n                // but if we do return, they had better be equal\n                if (returnedVersion != null) {\n                  assertEquals(-version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (Math.abs(version) > Math.abs(currInfo.version)) {\n                    model.put(id, new DocInfo(version, -nextVal));\n                  }\n                }\n\n                verbose(\"deleting id\", id, \"val=\",nextVal,\"version\",version,\"DONE\");\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n\n                verbose(\"deleteByQuery id\",id,\"val=\",nextVal,\"version\",version);\n\n                Long returnedVersion = deleteByQueryAndGetVersion(\"id:\"+Integer.toString(id), params(\"_version_\",Long.toString(-version), DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n                // TODO: returning versions for these types of updates is redundant\n                // but if we do return, they had better be equal\n                if (returnedVersion != null) {\n                  assertEquals(-version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (Math.abs(version) > Math.abs(currInfo.version)) {\n                    model.put(id, new DocInfo(version, -nextVal));\n                  }\n                }\n\n                verbose(\"deleteByQuery id\", id, \"val=\",nextVal,\"version\",version,\"DONE\");\n\n              } else {\n                verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version);\n\n                Long returnedVersion = addAndGetVersion(sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal), \"_version_\",Long.toString(version)), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n                if (returnedVersion != null) {\n                  assertEquals(version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (version > currInfo.version) {\n                    model.put(id, new DocInfo(version, nextVal));\n                  }\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version,\"DONE\");\n                }\n\n              }\n            // }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\",e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVer < Math.abs(info.version)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\",e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"  // This version simulates updates coming from the leader and sometimes being reordered\n  @Test\n  public void testStressReorderVersions() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 1+random().nextInt(7);\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 75;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    /** // testing\n    final int commitPercent = 5;\n    final int softCommitPercent = 100; // what percent of the commits are soft\n    final int deletePercent = 0;\n    final int deleteByQueryPercent = 50;\n    final int ndocs = 1;\n    int nWriteThreads = 2;\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n    // query variables\n    final int percentRealtimeQuery = 101;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 1;\n    **/\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n\n    final AtomicLong testVersion = new AtomicLong(0);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id;\n\n            if (rand.nextBoolean()) {\n              id = rand.nextInt(ndocs);\n            } else {\n              id = lastId;  // reuse the last ID half of the time to force more race conditions\n            }\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            DocInfo info = model.get(id);\n\n            long val = info.val;\n            long nextVal = Math.abs(val)+1;\n\n            // the version we set on the update should determine who wins\n            // These versions are not derived from the actual leader update handler hand hence this\n            // test may need to change depending on how we handle version numbers.\n            long version = testVersion.incrementAndGet();\n\n            // yield after getting the next version to increase the odds of updates happening out of order\n            if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent) {\n                verbose(\"deleting id\",id,\"val=\",nextVal,\"version\",version);\n\n                Long returnedVersion = deleteAndGetVersion(Integer.toString(id), params(\"_version_\",Long.toString(-version), DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n                // TODO: returning versions for these types of updates is redundant\n                // but if we do return, they had better be equal\n                if (returnedVersion != null) {\n                  assertEquals(-version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (Math.abs(version) > Math.abs(currInfo.version)) {\n                    model.put(id, new DocInfo(version, -nextVal));\n                  }\n                }\n\n                verbose(\"deleting id\", id, \"val=\",nextVal,\"version\",version,\"DONE\");\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n\n                verbose(\"deleteByQuery id\",id,\"val=\",nextVal,\"version\",version);\n\n                Long returnedVersion = deleteByQueryAndGetVersion(\"id:\"+Integer.toString(id), params(\"_version_\",Long.toString(-version), DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n                // TODO: returning versions for these types of updates is redundant\n                // but if we do return, they had better be equal\n                if (returnedVersion != null) {\n                  assertEquals(-version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (Math.abs(version) > Math.abs(currInfo.version)) {\n                    model.put(id, new DocInfo(version, -nextVal));\n                  }\n                }\n\n                verbose(\"deleteByQuery id\", id, \"val=\",nextVal,\"version\",version,\"DONE\");\n\n              } else {\n                verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version);\n\n                Long returnedVersion = addAndGetVersion(sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal), \"_version_\",Long.toString(version)), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n                if (returnedVersion != null) {\n                  assertEquals(version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (version > currInfo.version) {\n                    model.put(id, new DocInfo(version, nextVal));\n                  }\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version,\"DONE\");\n                }\n\n              }\n            // }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\",e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVer < Math.abs(info.version)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\",e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2b2e7536fb06d1abad6c7543a0657bdad5242c5e","date":1341417762,"type":5,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestStressReorder#testStressReorderVersions().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressReorderVersions().mjava","sourceNew":"  // This version simulates updates coming from the leader and sometimes being reordered\n  @Test\n  public void testStressReorderVersions() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 0; // 1+random().nextInt(7);\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 75;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    /** // testing\n    final int commitPercent = 5;\n    final int softCommitPercent = 100; // what percent of the commits are soft\n    final int deletePercent = 0;\n    final int deleteByQueryPercent = 50;\n    final int ndocs = 1;\n    int nWriteThreads = 2;\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n    // query variables\n    final int percentRealtimeQuery = 101;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 1;\n    **/\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n\n    final AtomicLong testVersion = new AtomicLong(0);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestStressReorder.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestStressReorder.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id;\n\n            if (rand.nextBoolean()) {\n              id = rand.nextInt(ndocs);\n            } else {\n              id = lastId;  // reuse the last ID half of the time to force more race conditions\n            }\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            DocInfo info = model.get(id);\n\n            long val = info.val;\n            long nextVal = Math.abs(val)+1;\n\n            // the version we set on the update should determine who wins\n            // These versions are not derived from the actual leader update handler hand hence this\n            // test may need to change depending on how we handle version numbers.\n            long version = testVersion.incrementAndGet();\n\n            // yield after getting the next version to increase the odds of updates happening out of order\n            if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent) {\n                verbose(\"deleting id\",id,\"val=\",nextVal,\"version\",version);\n\n                Long returnedVersion = deleteAndGetVersion(Integer.toString(id), params(\"_version_\",Long.toString(-version), DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n                // TODO: returning versions for these types of updates is redundant\n                // but if we do return, they had better be equal\n                if (returnedVersion != null) {\n                  assertEquals(-version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (Math.abs(version) > Math.abs(currInfo.version)) {\n                    model.put(id, new DocInfo(version, -nextVal));\n                  }\n                }\n\n                verbose(\"deleting id\", id, \"val=\",nextVal,\"version\",version,\"DONE\");\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n\n                verbose(\"deleteByQuery id\",id,\"val=\",nextVal,\"version\",version);\n\n                Long returnedVersion = deleteByQueryAndGetVersion(\"id:\"+Integer.toString(id), params(\"_version_\",Long.toString(-version), DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n                // TODO: returning versions for these types of updates is redundant\n                // but if we do return, they had better be equal\n                if (returnedVersion != null) {\n                  assertEquals(-version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (Math.abs(version) > Math.abs(currInfo.version)) {\n                    model.put(id, new DocInfo(version, -nextVal));\n                  }\n                }\n\n                verbose(\"deleteByQuery id\", id, \"val=\",nextVal,\"version\",version,\"DONE\");\n\n              } else {\n                verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version);\n\n                Long returnedVersion = addAndGetVersion(sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal), \"_version_\",Long.toString(version)), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n                if (returnedVersion != null) {\n                  assertEquals(version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (version > currInfo.version) {\n                    model.put(id, new DocInfo(version, nextVal));\n                  }\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version,\"DONE\");\n                }\n\n              }\n            // }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\",e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestStressReorder.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVer < Math.abs(info.version)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  log.error(\"ERROR, id=\" + id + \" found=\" + response + \" model\" + info);\n                  assertTrue(false);\n                }\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\",e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"  // This version simulates updates coming from the leader and sometimes being reordered\n  @Test\n  public void testStressReorderVersions() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 0; // 1+random().nextInt(7);\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 75;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    /** // testing\n    final int commitPercent = 5;\n    final int softCommitPercent = 100; // what percent of the commits are soft\n    final int deletePercent = 0;\n    final int deleteByQueryPercent = 50;\n    final int ndocs = 1;\n    int nWriteThreads = 2;\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n    // query variables\n    final int percentRealtimeQuery = 101;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 1;\n    **/\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n\n    final AtomicLong testVersion = new AtomicLong(0);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id;\n\n            if (rand.nextBoolean()) {\n              id = rand.nextInt(ndocs);\n            } else {\n              id = lastId;  // reuse the last ID half of the time to force more race conditions\n            }\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            DocInfo info = model.get(id);\n\n            long val = info.val;\n            long nextVal = Math.abs(val)+1;\n\n            // the version we set on the update should determine who wins\n            // These versions are not derived from the actual leader update handler hand hence this\n            // test may need to change depending on how we handle version numbers.\n            long version = testVersion.incrementAndGet();\n\n            // yield after getting the next version to increase the odds of updates happening out of order\n            if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent) {\n                verbose(\"deleting id\",id,\"val=\",nextVal,\"version\",version);\n\n                Long returnedVersion = deleteAndGetVersion(Integer.toString(id), params(\"_version_\",Long.toString(-version), DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n                // TODO: returning versions for these types of updates is redundant\n                // but if we do return, they had better be equal\n                if (returnedVersion != null) {\n                  assertEquals(-version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (Math.abs(version) > Math.abs(currInfo.version)) {\n                    model.put(id, new DocInfo(version, -nextVal));\n                  }\n                }\n\n                verbose(\"deleting id\", id, \"val=\",nextVal,\"version\",version,\"DONE\");\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n\n                verbose(\"deleteByQuery id\",id,\"val=\",nextVal,\"version\",version);\n\n                Long returnedVersion = deleteByQueryAndGetVersion(\"id:\"+Integer.toString(id), params(\"_version_\",Long.toString(-version), DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n                // TODO: returning versions for these types of updates is redundant\n                // but if we do return, they had better be equal\n                if (returnedVersion != null) {\n                  assertEquals(-version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (Math.abs(version) > Math.abs(currInfo.version)) {\n                    model.put(id, new DocInfo(version, -nextVal));\n                  }\n                }\n\n                verbose(\"deleteByQuery id\", id, \"val=\",nextVal,\"version\",version,\"DONE\");\n\n              } else {\n                verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version);\n\n                Long returnedVersion = addAndGetVersion(sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal), \"_version_\",Long.toString(version)), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n                if (returnedVersion != null) {\n                  assertEquals(version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (version > currInfo.version) {\n                    model.put(id, new DocInfo(version, nextVal));\n                  }\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version,\"DONE\");\n                }\n\n              }\n            // }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\",e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVer < Math.abs(info.version)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\",e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":4,"author":"Michael McCandless","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressReorderVersions().mjava","sourceNew":null,"sourceOld":"  // This version simulates updates coming from the leader and sometimes being reordered\n  @Test\n  public void testStressReorderVersions() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 0;  // delete-by-query can't be reordered on replicas\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 75;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n\n    final AtomicLong testVersion = new AtomicLong(0);\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id;\n\n            if (rand.nextBoolean()) {\n              id = rand.nextInt(ndocs);\n            } else {\n              id = lastId;  // reuse the last ID half of the time to force more race conditions\n            }\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            DocInfo info = model.get(id);\n\n            long val = info.val;\n            long nextVal = Math.abs(val)+1;\n\n            // the version we set on the update should determine who wins\n            // These versions are not derived from the actual leader update handler hand hence this\n            // test may need to change depending on how we handle version numbers.\n            long version = testVersion.incrementAndGet();\n\n            // yield after getting the next version to increase the odds of updates happening out of order\n            if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent) {\n                verbose(\"deleting id\",id,\"val=\",nextVal,\"version\",version);\n\n                Long returnedVersion = deleteAndGetVersion(Integer.toString(id), params(\"_version_\",Long.toString(-version), DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n                // TODO: returning versions for these types of updates is redundant\n                // but if we do return, they had better be equal\n                if (returnedVersion != null) {\n                  assertEquals(-version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (Math.abs(version) > Math.abs(currInfo.version)) {\n                    model.put(id, new DocInfo(version, -nextVal));\n                  }\n                }\n\n                verbose(\"deleting id\", id, \"val=\",nextVal,\"version\",version,\"DONE\");\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n\n              } else {\n                verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version);\n\n                Long returnedVersion = addAndGetVersion(sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal), \"_version_\",Long.toString(version)), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n                if (returnedVersion != null) {\n                  assertEquals(version, returnedVersion.longValue());\n                }\n\n                // only update model if the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (version > currInfo.version) {\n                    model.put(id, new DocInfo(version, nextVal));\n                  }\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"version\",version,\"DONE\");\n                }\n\n              }\n            // }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVer < Math.abs(info.version)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"fb999ed3fc6e419b9104de9ebfe62ace27f31d5f":["e2fe35ac47f8f51356d6c1724455d18f31c94fae"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":["2c007e7c4cf8c55bc2a5884e315123afaaeec87f","f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"1bea3922196318026c4274f2013416acb60c691e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"0d22ac6a4146774c1bc8400160fc0b6150294e92":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["e2fe35ac47f8f51356d6c1724455d18f31c94fae","2b2e7536fb06d1abad6c7543a0657bdad5242c5e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"2b2e7536fb06d1abad6c7543a0657bdad5242c5e":["082bf4ef6a721f2673b8f1e99c69c80cfe0de8fe"],"2c007e7c4cf8c55bc2a5884e315123afaaeec87f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"082bf4ef6a721f2673b8f1e99c69c80cfe0de8fe":["fb999ed3fc6e419b9104de9ebfe62ace27f31d5f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["2b2e7536fb06d1abad6c7543a0657bdad5242c5e"],"e2fe35ac47f8f51356d6c1724455d18f31c94fae":["1bea3922196318026c4274f2013416acb60c691e"]},"commit2Childs":{"fb999ed3fc6e419b9104de9ebfe62ace27f31d5f":["082bf4ef6a721f2673b8f1e99c69c80cfe0de8fe"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":[],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d":[],"1bea3922196318026c4274f2013416acb60c691e":["e2fe35ac47f8f51356d6c1724455d18f31c94fae"],"0d22ac6a4146774c1bc8400160fc0b6150294e92":[],"fe33227f6805edab2036cbb80645cc4e2d1fa424":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","0d22ac6a4146774c1bc8400160fc0b6150294e92","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"2c007e7c4cf8c55bc2a5884e315123afaaeec87f":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","f08557cdb6c60ac7b88a9342c983a20cd236e74f","a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","0d22ac6a4146774c1bc8400160fc0b6150294e92"],"2b2e7536fb06d1abad6c7543a0657bdad5242c5e":["fe33227f6805edab2036cbb80645cc4e2d1fa424","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["1bea3922196318026c4274f2013416acb60c691e"],"082bf4ef6a721f2673b8f1e99c69c80cfe0de8fe":["2b2e7536fb06d1abad6c7543a0657bdad5242c5e"],"e2fe35ac47f8f51356d6c1724455d18f31c94fae":["fb999ed3fc6e419b9104de9ebfe62ace27f31d5f","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","0d22ac6a4146774c1bc8400160fc0b6150294e92","fe33227f6805edab2036cbb80645cc4e2d1fa424","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}