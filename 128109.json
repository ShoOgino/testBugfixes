{"path":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/TokenStreamFromTermVector#initLinkAndSortTokens(TokenLL[]).mjava","commits":[{"id":"1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2","date":1475611903,"type":0,"author":"David Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/TokenStreamFromTermVector#initLinkAndSortTokens(TokenLL[]).mjava","pathOld":"/dev/null","sourceNew":"  private static TokenLL initLinkAndSortTokens(TokenLL[] tokenBuckets) {\n    TokenLL firstToken = null;\n    List<TokenLL> scratchTokenArray = new ArrayList<>(); // declare here for re-use.  TODO use native array\n    TokenLL prevToken = null;\n    for (TokenLL tokenHead : tokenBuckets) {\n      if (tokenHead == null) {\n        continue;\n      }\n      //sort tokens at this position and link them; return the first\n      TokenLL tokenTail;\n      // just one token\n      if (tokenHead.next == null) {\n        tokenTail = tokenHead;\n      } else {\n        // add the linked list to a temporary array\n        for (TokenLL cur = tokenHead; cur != null; cur = cur.next) {\n          scratchTokenArray.add(cur);\n        }\n        // sort; and set tokenHead & tokenTail\n        if (scratchTokenArray.size() < INSERTION_SORT_THRESHOLD) {\n          // insertion sort by creating a linked list (leave scratchTokenArray alone)\n          tokenHead = tokenTail = scratchTokenArray.get(0);\n          tokenHead.next = null;\n          for (int i = 1; i < scratchTokenArray.size(); i++) {\n            TokenLL insertToken = scratchTokenArray.get(i);\n            if (insertToken.compareTo(tokenHead) <= 0) {\n              // takes the place of tokenHead\n              insertToken.next = tokenHead;\n              tokenHead = insertToken;\n            } else {\n              // goes somewhere after tokenHead\n              for (TokenLL prev = tokenHead; true; prev = prev.next) {\n                if (prev.next == null || insertToken.compareTo(prev.next) <= 0) {\n                  if (prev.next == null) {\n                    tokenTail = insertToken;\n                  }\n                  insertToken.next = prev.next;\n                  prev.next = insertToken;\n                  break;\n                }\n              }\n            }\n          }\n        } else {\n          Collections.sort(scratchTokenArray);\n          // take back out and create a linked list\n          TokenLL prev = tokenHead = scratchTokenArray.get(0);\n          for (int i = 1; i < scratchTokenArray.size(); i++) {\n            prev.next = scratchTokenArray.get(i);\n            prev = prev.next;\n          }\n          tokenTail = prev;\n          tokenTail.next = null;\n        }\n        scratchTokenArray.clear();//too bad ArrayList nulls it out; we don't actually need that\n      }\n\n      //link to previous\n      if (prevToken != null) {\n        assert prevToken.next == null;\n        prevToken.next = tokenHead; //concatenate linked-list\n        assert prevToken.compareTo(tokenHead) < 0 : \"wrong offset / position ordering expectations\";\n      } else {\n        assert firstToken == null;\n        firstToken = tokenHead;\n      }\n\n      prevToken = tokenTail;\n    }\n    return firstToken;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/TokenStreamFromTermVector#initLinkAndSortTokens(TokenLL[]).mjava","pathOld":"/dev/null","sourceNew":"  private static TokenLL initLinkAndSortTokens(TokenLL[] tokenBuckets) {\n    TokenLL firstToken = null;\n    List<TokenLL> scratchTokenArray = new ArrayList<>(); // declare here for re-use.  TODO use native array\n    TokenLL prevToken = null;\n    for (TokenLL tokenHead : tokenBuckets) {\n      if (tokenHead == null) {\n        continue;\n      }\n      //sort tokens at this position and link them; return the first\n      TokenLL tokenTail;\n      // just one token\n      if (tokenHead.next == null) {\n        tokenTail = tokenHead;\n      } else {\n        // add the linked list to a temporary array\n        for (TokenLL cur = tokenHead; cur != null; cur = cur.next) {\n          scratchTokenArray.add(cur);\n        }\n        // sort; and set tokenHead & tokenTail\n        if (scratchTokenArray.size() < INSERTION_SORT_THRESHOLD) {\n          // insertion sort by creating a linked list (leave scratchTokenArray alone)\n          tokenHead = tokenTail = scratchTokenArray.get(0);\n          tokenHead.next = null;\n          for (int i = 1; i < scratchTokenArray.size(); i++) {\n            TokenLL insertToken = scratchTokenArray.get(i);\n            if (insertToken.compareTo(tokenHead) <= 0) {\n              // takes the place of tokenHead\n              insertToken.next = tokenHead;\n              tokenHead = insertToken;\n            } else {\n              // goes somewhere after tokenHead\n              for (TokenLL prev = tokenHead; true; prev = prev.next) {\n                if (prev.next == null || insertToken.compareTo(prev.next) <= 0) {\n                  if (prev.next == null) {\n                    tokenTail = insertToken;\n                  }\n                  insertToken.next = prev.next;\n                  prev.next = insertToken;\n                  break;\n                }\n              }\n            }\n          }\n        } else {\n          Collections.sort(scratchTokenArray);\n          // take back out and create a linked list\n          TokenLL prev = tokenHead = scratchTokenArray.get(0);\n          for (int i = 1; i < scratchTokenArray.size(); i++) {\n            prev.next = scratchTokenArray.get(i);\n            prev = prev.next;\n          }\n          tokenTail = prev;\n          tokenTail.next = null;\n        }\n        scratchTokenArray.clear();//too bad ArrayList nulls it out; we don't actually need that\n      }\n\n      //link to previous\n      if (prevToken != null) {\n        assert prevToken.next == null;\n        prevToken.next = tokenHead; //concatenate linked-list\n        assert prevToken.compareTo(tokenHead) < 0 : \"wrong offset / position ordering expectations\";\n      } else {\n        assert firstToken == null;\n        firstToken = tokenHead;\n      }\n\n      prevToken = tokenTail;\n    }\n    return firstToken;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2e9861e4a2b724d9fc51b618714c579491b78d7","date":1479244606,"type":4,"author":"David Smiley","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/TokenStreamFromTermVector#initLinkAndSortTokens(TokenLL[]).mjava","sourceNew":null,"sourceOld":"  private static TokenLL initLinkAndSortTokens(TokenLL[] tokenBuckets) {\n    TokenLL firstToken = null;\n    List<TokenLL> scratchTokenArray = new ArrayList<>(); // declare here for re-use.  TODO use native array\n    TokenLL prevToken = null;\n    for (TokenLL tokenHead : tokenBuckets) {\n      if (tokenHead == null) {\n        continue;\n      }\n      //sort tokens at this position and link them; return the first\n      TokenLL tokenTail;\n      // just one token\n      if (tokenHead.next == null) {\n        tokenTail = tokenHead;\n      } else {\n        // add the linked list to a temporary array\n        for (TokenLL cur = tokenHead; cur != null; cur = cur.next) {\n          scratchTokenArray.add(cur);\n        }\n        // sort; and set tokenHead & tokenTail\n        if (scratchTokenArray.size() < INSERTION_SORT_THRESHOLD) {\n          // insertion sort by creating a linked list (leave scratchTokenArray alone)\n          tokenHead = tokenTail = scratchTokenArray.get(0);\n          tokenHead.next = null;\n          for (int i = 1; i < scratchTokenArray.size(); i++) {\n            TokenLL insertToken = scratchTokenArray.get(i);\n            if (insertToken.compareTo(tokenHead) <= 0) {\n              // takes the place of tokenHead\n              insertToken.next = tokenHead;\n              tokenHead = insertToken;\n            } else {\n              // goes somewhere after tokenHead\n              for (TokenLL prev = tokenHead; true; prev = prev.next) {\n                if (prev.next == null || insertToken.compareTo(prev.next) <= 0) {\n                  if (prev.next == null) {\n                    tokenTail = insertToken;\n                  }\n                  insertToken.next = prev.next;\n                  prev.next = insertToken;\n                  break;\n                }\n              }\n            }\n          }\n        } else {\n          Collections.sort(scratchTokenArray);\n          // take back out and create a linked list\n          TokenLL prev = tokenHead = scratchTokenArray.get(0);\n          for (int i = 1; i < scratchTokenArray.size(); i++) {\n            prev.next = scratchTokenArray.get(i);\n            prev = prev.next;\n          }\n          tokenTail = prev;\n          tokenTail.next = null;\n        }\n        scratchTokenArray.clear();//too bad ArrayList nulls it out; we don't actually need that\n      }\n\n      //link to previous\n      if (prevToken != null) {\n        assert prevToken.next == null;\n        prevToken.next = tokenHead; //concatenate linked-list\n        assert prevToken.compareTo(tokenHead) < 0 : \"wrong offset / position ordering expectations\";\n      } else {\n        assert firstToken == null;\n        firstToken = tokenHead;\n      }\n\n      prevToken = tokenTail;\n    }\n    return firstToken;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a1ef55e1fff7ff44354432770ad8bc19be1fcc75","date":1479266056,"type":4,"author":"Kevin Risden","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/TokenStreamFromTermVector#initLinkAndSortTokens(TokenLL[]).mjava","sourceNew":null,"sourceOld":"  private static TokenLL initLinkAndSortTokens(TokenLL[] tokenBuckets) {\n    TokenLL firstToken = null;\n    List<TokenLL> scratchTokenArray = new ArrayList<>(); // declare here for re-use.  TODO use native array\n    TokenLL prevToken = null;\n    for (TokenLL tokenHead : tokenBuckets) {\n      if (tokenHead == null) {\n        continue;\n      }\n      //sort tokens at this position and link them; return the first\n      TokenLL tokenTail;\n      // just one token\n      if (tokenHead.next == null) {\n        tokenTail = tokenHead;\n      } else {\n        // add the linked list to a temporary array\n        for (TokenLL cur = tokenHead; cur != null; cur = cur.next) {\n          scratchTokenArray.add(cur);\n        }\n        // sort; and set tokenHead & tokenTail\n        if (scratchTokenArray.size() < INSERTION_SORT_THRESHOLD) {\n          // insertion sort by creating a linked list (leave scratchTokenArray alone)\n          tokenHead = tokenTail = scratchTokenArray.get(0);\n          tokenHead.next = null;\n          for (int i = 1; i < scratchTokenArray.size(); i++) {\n            TokenLL insertToken = scratchTokenArray.get(i);\n            if (insertToken.compareTo(tokenHead) <= 0) {\n              // takes the place of tokenHead\n              insertToken.next = tokenHead;\n              tokenHead = insertToken;\n            } else {\n              // goes somewhere after tokenHead\n              for (TokenLL prev = tokenHead; true; prev = prev.next) {\n                if (prev.next == null || insertToken.compareTo(prev.next) <= 0) {\n                  if (prev.next == null) {\n                    tokenTail = insertToken;\n                  }\n                  insertToken.next = prev.next;\n                  prev.next = insertToken;\n                  break;\n                }\n              }\n            }\n          }\n        } else {\n          Collections.sort(scratchTokenArray);\n          // take back out and create a linked list\n          TokenLL prev = tokenHead = scratchTokenArray.get(0);\n          for (int i = 1; i < scratchTokenArray.size(); i++) {\n            prev.next = scratchTokenArray.get(i);\n            prev = prev.next;\n          }\n          tokenTail = prev;\n          tokenTail.next = null;\n        }\n        scratchTokenArray.clear();//too bad ArrayList nulls it out; we don't actually need that\n      }\n\n      //link to previous\n      if (prevToken != null) {\n        assert prevToken.next == null;\n        prevToken.next = tokenHead; //concatenate linked-list\n        assert prevToken.compareTo(tokenHead) < 0 : \"wrong offset / position ordering expectations\";\n      } else {\n        assert firstToken == null;\n        firstToken = tokenHead;\n      }\n\n      prevToken = tokenTail;\n    }\n    return firstToken;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"f2e9861e4a2b724d9fc51b618714c579491b78d7":["1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a1ef55e1fff7ff44354432770ad8bc19be1fcc75":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","f2e9861e4a2b724d9fc51b618714c579491b78d7"],"1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["f2e9861e4a2b724d9fc51b618714c579491b78d7"]},"commit2Childs":{"f2e9861e4a2b724d9fc51b618714c579491b78d7":["a1ef55e1fff7ff44354432770ad8bc19be1fcc75","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"a1ef55e1fff7ff44354432770ad8bc19be1fcc75":[],"1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2":["f2e9861e4a2b724d9fc51b618714c579491b78d7","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a1ef55e1fff7ff44354432770ad8bc19be1fcc75"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a1ef55e1fff7ff44354432770ad8bc19be1fcc75","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}