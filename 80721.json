{"path":"modules/grouping/src/test/org/apache/lucene/search/grouping/DistinctValuesCollectorTest#createIndexContext().mjava","commits":[{"id":"166661dd25a09458b128e5c0b86e3b762a6ded68","date":1332333666,"type":0,"author":"Martijn van Groningen","isMerge":false,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/DistinctValuesCollectorTest#createIndexContext().mjava","pathOld":"/dev/null","sourceNew":"  private IndexContext createIndexContext() throws Exception {\n    DocValues.Type[] dvTypes = new DocValues.Type[]{\n        DocValues.Type.BYTES_VAR_STRAIGHT,\n        DocValues.Type.BYTES_VAR_SORTED\n    };\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy())\n      );\n\n    boolean canUseDV = !\"Lucene3x\".equals(w.w.getConfig().getCodec().getName());\n    DocValues.Type dvType = canUseDV ? dvTypes[random.nextInt(dvTypes.length)] : null;\n\n    int numDocs = 86 + random.nextInt(1087) * RANDOM_MULTIPLIER;\n    String[] groupValues = new String[numDocs / 5];\n    String[] countValues = new String[numDocs / 10];\n    for (int i = 0; i < groupValues.length; i++) {\n      groupValues[i] = generateRandomNonEmptyString();\n    }\n    for (int i = 0; i < countValues.length; i++) {\n      countValues[i] = generateRandomNonEmptyString();\n    }\n    \n    List<String> contentStrings = new ArrayList<String>();\n    Map<String, Map<String, Set<String>>> searchTermToGroupCounts = new HashMap<String, Map<String, Set<String>>>();\n    for (int i = 1; i <= numDocs; i++) {\n      String groupValue = random.nextInt(23) == 14 ? null : groupValues[random.nextInt(groupValues.length)];\n      String countValue = random.nextInt(21) == 13 ? null : countValues[random.nextInt(countValues.length)];\n      String content = \"random\" + random.nextInt(numDocs / 20);\n      Map<String, Set<String>> groupToCounts = searchTermToGroupCounts.get(content);\n      if (groupToCounts == null) {\n        // Groups sort always DOCID asc...\n        searchTermToGroupCounts.put(content, groupToCounts = new LinkedHashMap<String, Set<String>>());\n        contentStrings.add(content);\n      }\n\n      Set<String> countsVals = groupToCounts.get(groupValue);\n      if (countsVals == null) {\n        groupToCounts.put(groupValue, countsVals = new HashSet<String>());\n      }\n      countsVals.add(countValue);\n\n      Document doc = new Document();\n      doc.add(new Field(\"id\", String.format(\"%09d\", i), StringField.TYPE_UNSTORED));\n      if (groupValue != null) {\n        addField(doc, groupField, groupValue, dvType);\n      }\n      if (countValue != null) {\n        addField(doc, countField, countValue, dvType);\n      }\n      doc.add(new Field(\"content\", content, TextField.TYPE_UNSTORED));\n      w.addDocument(doc);\n    }\n\n    DirectoryReader reader = w.getReader();\n    w.close();\n    return new IndexContext(dir, reader, dvType, searchTermToGroupCounts, contentStrings.toArray(new String[contentStrings.size()]));\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2","d4d69c535930b5cce125cff868d40f6373dc27d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/DistinctValuesCollectorTest#createIndexContext().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/DistinctValuesCollectorTest#createIndexContext().mjava","sourceNew":"  private IndexContext createIndexContext() throws Exception {\n    Random random = random();\n    DocValues.Type[] dvTypes = new DocValues.Type[]{\n        DocValues.Type.BYTES_VAR_STRAIGHT,\n        DocValues.Type.BYTES_VAR_SORTED\n    };\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy())\n      );\n\n    boolean canUseDV = !\"Lucene3x\".equals(w.w.getConfig().getCodec().getName());\n    DocValues.Type dvType = canUseDV ? dvTypes[random.nextInt(dvTypes.length)] : null;\n\n    int numDocs = 86 + random.nextInt(1087) * RANDOM_MULTIPLIER;\n    String[] groupValues = new String[numDocs / 5];\n    String[] countValues = new String[numDocs / 10];\n    for (int i = 0; i < groupValues.length; i++) {\n      groupValues[i] = generateRandomNonEmptyString();\n    }\n    for (int i = 0; i < countValues.length; i++) {\n      countValues[i] = generateRandomNonEmptyString();\n    }\n    \n    List<String> contentStrings = new ArrayList<String>();\n    Map<String, Map<String, Set<String>>> searchTermToGroupCounts = new HashMap<String, Map<String, Set<String>>>();\n    for (int i = 1; i <= numDocs; i++) {\n      String groupValue = random.nextInt(23) == 14 ? null : groupValues[random.nextInt(groupValues.length)];\n      String countValue = random.nextInt(21) == 13 ? null : countValues[random.nextInt(countValues.length)];\n      String content = \"random\" + random.nextInt(numDocs / 20);\n      Map<String, Set<String>> groupToCounts = searchTermToGroupCounts.get(content);\n      if (groupToCounts == null) {\n        // Groups sort always DOCID asc...\n        searchTermToGroupCounts.put(content, groupToCounts = new LinkedHashMap<String, Set<String>>());\n        contentStrings.add(content);\n      }\n\n      Set<String> countsVals = groupToCounts.get(groupValue);\n      if (countsVals == null) {\n        groupToCounts.put(groupValue, countsVals = new HashSet<String>());\n      }\n      countsVals.add(countValue);\n\n      Document doc = new Document();\n      doc.add(new Field(\"id\", String.format(\"%09d\", i), StringField.TYPE_UNSTORED));\n      if (groupValue != null) {\n        addField(doc, groupField, groupValue, dvType);\n      }\n      if (countValue != null) {\n        addField(doc, countField, countValue, dvType);\n      }\n      doc.add(new Field(\"content\", content, TextField.TYPE_UNSTORED));\n      w.addDocument(doc);\n    }\n\n    DirectoryReader reader = w.getReader();\n    w.close();\n    return new IndexContext(dir, reader, dvType, searchTermToGroupCounts, contentStrings.toArray(new String[contentStrings.size()]));\n  }\n\n","sourceOld":"  private IndexContext createIndexContext() throws Exception {\n    DocValues.Type[] dvTypes = new DocValues.Type[]{\n        DocValues.Type.BYTES_VAR_STRAIGHT,\n        DocValues.Type.BYTES_VAR_SORTED\n    };\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy())\n      );\n\n    boolean canUseDV = !\"Lucene3x\".equals(w.w.getConfig().getCodec().getName());\n    DocValues.Type dvType = canUseDV ? dvTypes[random.nextInt(dvTypes.length)] : null;\n\n    int numDocs = 86 + random.nextInt(1087) * RANDOM_MULTIPLIER;\n    String[] groupValues = new String[numDocs / 5];\n    String[] countValues = new String[numDocs / 10];\n    for (int i = 0; i < groupValues.length; i++) {\n      groupValues[i] = generateRandomNonEmptyString();\n    }\n    for (int i = 0; i < countValues.length; i++) {\n      countValues[i] = generateRandomNonEmptyString();\n    }\n    \n    List<String> contentStrings = new ArrayList<String>();\n    Map<String, Map<String, Set<String>>> searchTermToGroupCounts = new HashMap<String, Map<String, Set<String>>>();\n    for (int i = 1; i <= numDocs; i++) {\n      String groupValue = random.nextInt(23) == 14 ? null : groupValues[random.nextInt(groupValues.length)];\n      String countValue = random.nextInt(21) == 13 ? null : countValues[random.nextInt(countValues.length)];\n      String content = \"random\" + random.nextInt(numDocs / 20);\n      Map<String, Set<String>> groupToCounts = searchTermToGroupCounts.get(content);\n      if (groupToCounts == null) {\n        // Groups sort always DOCID asc...\n        searchTermToGroupCounts.put(content, groupToCounts = new LinkedHashMap<String, Set<String>>());\n        contentStrings.add(content);\n      }\n\n      Set<String> countsVals = groupToCounts.get(groupValue);\n      if (countsVals == null) {\n        groupToCounts.put(groupValue, countsVals = new HashSet<String>());\n      }\n      countsVals.add(countValue);\n\n      Document doc = new Document();\n      doc.add(new Field(\"id\", String.format(\"%09d\", i), StringField.TYPE_UNSTORED));\n      if (groupValue != null) {\n        addField(doc, groupField, groupValue, dvType);\n      }\n      if (countValue != null) {\n        addField(doc, countField, countValue, dvType);\n      }\n      doc.add(new Field(\"content\", content, TextField.TYPE_UNSTORED));\n      w.addDocument(doc);\n    }\n\n    DirectoryReader reader = w.getReader();\n    w.close();\n    return new IndexContext(dir, reader, dvType, searchTermToGroupCounts, contentStrings.toArray(new String[contentStrings.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/DistinctValuesCollectorTest#createIndexContext().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/DistinctValuesCollectorTest#createIndexContext().mjava","sourceNew":"  private IndexContext createIndexContext() throws Exception {\n    Random random = random();\n    DocValues.Type[] dvTypes = new DocValues.Type[]{\n        DocValues.Type.BYTES_VAR_STRAIGHT,\n        DocValues.Type.BYTES_VAR_SORTED\n    };\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy())\n      );\n\n    boolean canUseDV = !\"Lucene3x\".equals(w.w.getConfig().getCodec().getName());\n    DocValues.Type dvType = canUseDV ? dvTypes[random.nextInt(dvTypes.length)] : null;\n\n    int numDocs = 86 + random.nextInt(1087) * RANDOM_MULTIPLIER;\n    String[] groupValues = new String[numDocs / 5];\n    String[] countValues = new String[numDocs / 10];\n    for (int i = 0; i < groupValues.length; i++) {\n      groupValues[i] = generateRandomNonEmptyString();\n    }\n    for (int i = 0; i < countValues.length; i++) {\n      countValues[i] = generateRandomNonEmptyString();\n    }\n    \n    List<String> contentStrings = new ArrayList<String>();\n    Map<String, Map<String, Set<String>>> searchTermToGroupCounts = new HashMap<String, Map<String, Set<String>>>();\n    for (int i = 1; i <= numDocs; i++) {\n      String groupValue = random.nextInt(23) == 14 ? null : groupValues[random.nextInt(groupValues.length)];\n      String countValue = random.nextInt(21) == 13 ? null : countValues[random.nextInt(countValues.length)];\n      String content = \"random\" + random.nextInt(numDocs / 20);\n      Map<String, Set<String>> groupToCounts = searchTermToGroupCounts.get(content);\n      if (groupToCounts == null) {\n        // Groups sort always DOCID asc...\n        searchTermToGroupCounts.put(content, groupToCounts = new LinkedHashMap<String, Set<String>>());\n        contentStrings.add(content);\n      }\n\n      Set<String> countsVals = groupToCounts.get(groupValue);\n      if (countsVals == null) {\n        groupToCounts.put(groupValue, countsVals = new HashSet<String>());\n      }\n      countsVals.add(countValue);\n\n      Document doc = new Document();\n      doc.add(new Field(\"id\", String.format(\"%09d\", i), StringField.TYPE_UNSTORED));\n      if (groupValue != null) {\n        addField(doc, groupField, groupValue, dvType);\n      }\n      if (countValue != null) {\n        addField(doc, countField, countValue, dvType);\n      }\n      doc.add(new Field(\"content\", content, TextField.TYPE_UNSTORED));\n      w.addDocument(doc);\n    }\n\n    DirectoryReader reader = w.getReader();\n    w.close();\n    return new IndexContext(dir, reader, dvType, searchTermToGroupCounts, contentStrings.toArray(new String[contentStrings.size()]));\n  }\n\n","sourceOld":"  private IndexContext createIndexContext() throws Exception {\n    Random random = random();\n    DocValues.Type[] dvTypes = new DocValues.Type[]{\n        DocValues.Type.BYTES_VAR_STRAIGHT,\n        DocValues.Type.BYTES_VAR_SORTED\n    };\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy())\n      );\n\n    boolean canUseDV = !\"Lucene3x\".equals(w.w.getConfig().getCodec().getName());\n    DocValues.Type dvType = canUseDV ? dvTypes[random.nextInt(dvTypes.length)] : null;\n\n    int numDocs = 86 + random.nextInt(1087) * RANDOM_MULTIPLIER;\n    String[] groupValues = new String[numDocs / 5];\n    String[] countValues = new String[numDocs / 10];\n    for (int i = 0; i < groupValues.length; i++) {\n      groupValues[i] = generateRandomNonEmptyString();\n    }\n    for (int i = 0; i < countValues.length; i++) {\n      countValues[i] = generateRandomNonEmptyString();\n    }\n    \n    List<String> contentStrings = new ArrayList<String>();\n    Map<String, Map<String, Set<String>>> searchTermToGroupCounts = new HashMap<String, Map<String, Set<String>>>();\n    for (int i = 1; i <= numDocs; i++) {\n      String groupValue = random.nextInt(23) == 14 ? null : groupValues[random.nextInt(groupValues.length)];\n      String countValue = random.nextInt(21) == 13 ? null : countValues[random.nextInt(countValues.length)];\n      String content = \"random\" + random.nextInt(numDocs / 20);\n      Map<String, Set<String>> groupToCounts = searchTermToGroupCounts.get(content);\n      if (groupToCounts == null) {\n        // Groups sort always DOCID asc...\n        searchTermToGroupCounts.put(content, groupToCounts = new LinkedHashMap<String, Set<String>>());\n        contentStrings.add(content);\n      }\n\n      Set<String> countsVals = groupToCounts.get(groupValue);\n      if (countsVals == null) {\n        groupToCounts.put(groupValue, countsVals = new HashSet<String>());\n      }\n      countsVals.add(countValue);\n\n      Document doc = new Document();\n      doc.add(new Field(\"id\", String.format(\"%09d\", i), StringField.TYPE_UNSTORED));\n      if (groupValue != null) {\n        addField(doc, groupField, groupValue, dvType);\n      }\n      if (countValue != null) {\n        addField(doc, countField, countValue, dvType);\n      }\n      doc.add(new Field(\"content\", content, TextField.TYPE_UNSTORED));\n      w.addDocument(doc);\n    }\n\n    DirectoryReader reader = w.getReader();\n    w.close();\n    return new IndexContext(dir, reader, dvType, searchTermToGroupCounts, contentStrings.toArray(new String[contentStrings.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["166661dd25a09458b128e5c0b86e3b762a6ded68"],"166661dd25a09458b128e5c0b86e3b762a6ded68":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b89678825b68eccaf09e6ab71675fc0b0af1e099"]},"commit2Childs":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["166661dd25a09458b128e5c0b86e3b762a6ded68"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"166661dd25a09458b128e5c0b86e3b762a6ded68":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}