{"path":"lucene/contrib/wordnet/src/java/org/apache/lucene/wordnet/AnalyzerUtil#getSentences(String,int).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/wordnet/src/java/org/apache/lucene/wordnet/AnalyzerUtil#getSentences(String,int).mjava","pathOld":"contrib/wordnet/src/java/org/apache/lucene/wordnet/AnalyzerUtil#getSentences(String,int).mjava","sourceNew":"  /**\n   * Returns at most the first N sentences of the given text. Delimiting\n   * characters are excluded from the results. Each returned sentence is\n   * whitespace-trimmed via String.trim(), potentially an empty string.\n   * \n   * @param text\n   *            the text to tokenize into sentences\n   * @param limit\n   *            the maximum number of sentences to return; zero indicates \"as\n   *            many as possible\".\n   * @return the first N sentences\n   */\n  public static String[] getSentences(String text, int limit) {\n//    return tokenize(SENTENCES, text, limit); // equivalent but slower\n    int len = text.length();\n    if (len == 0) return new String[] { text };\n    if (limit <= 0) limit = Integer.MAX_VALUE;\n    \n    // average sentence length heuristic\n    String[] tokens = new String[Math.min(limit, 1 + len/40)];\n    int size = 0;\n    int i = 0;\n    \n    while (i < len && size < limit) {\n      \n      // scan to end of current sentence\n      int start = i;\n      while (i < len && !isSentenceSeparator(text.charAt(i))) i++;\n      \n      if (size == tokens.length) { // grow array\n        String[] tmp = new String[tokens.length << 1];\n        System.arraycopy(tokens, 0, tmp, 0, size);\n        tokens = tmp;\n      }\n      // add sentence (potentially empty)\n      tokens[size++] = text.substring(start, i).trim();\n\n      // scan to beginning of next sentence\n      while (i < len && isSentenceSeparator(text.charAt(i))) i++;\n    }\n    \n    if (size == tokens.length) return tokens;\n    String[] results = new String[size];\n    System.arraycopy(tokens, 0, results, 0, size);\n    return results;\n  }\n\n","sourceOld":"  /**\n   * Returns at most the first N sentences of the given text. Delimiting\n   * characters are excluded from the results. Each returned sentence is\n   * whitespace-trimmed via String.trim(), potentially an empty string.\n   * \n   * @param text\n   *            the text to tokenize into sentences\n   * @param limit\n   *            the maximum number of sentences to return; zero indicates \"as\n   *            many as possible\".\n   * @return the first N sentences\n   */\n  public static String[] getSentences(String text, int limit) {\n//    return tokenize(SENTENCES, text, limit); // equivalent but slower\n    int len = text.length();\n    if (len == 0) return new String[] { text };\n    if (limit <= 0) limit = Integer.MAX_VALUE;\n    \n    // average sentence length heuristic\n    String[] tokens = new String[Math.min(limit, 1 + len/40)];\n    int size = 0;\n    int i = 0;\n    \n    while (i < len && size < limit) {\n      \n      // scan to end of current sentence\n      int start = i;\n      while (i < len && !isSentenceSeparator(text.charAt(i))) i++;\n      \n      if (size == tokens.length) { // grow array\n        String[] tmp = new String[tokens.length << 1];\n        System.arraycopy(tokens, 0, tmp, 0, size);\n        tokens = tmp;\n      }\n      // add sentence (potentially empty)\n      tokens[size++] = text.substring(start, i).trim();\n\n      // scan to beginning of next sentence\n      while (i < len && isSentenceSeparator(text.charAt(i))) i++;\n    }\n    \n    if (size == tokens.length) return tokens;\n    String[] results = new String[size];\n    System.arraycopy(tokens, 0, results, 0, size);\n    return results;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"689f35bd9818b47b8d9fe96cf06518228e949ab6","date":1272894884,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/contrib/wordnet/src/java/org/apache/lucene/wordnet/AnalyzerUtil#getSentences(String,int).mjava","sourceNew":null,"sourceOld":"  /**\n   * Returns at most the first N sentences of the given text. Delimiting\n   * characters are excluded from the results. Each returned sentence is\n   * whitespace-trimmed via String.trim(), potentially an empty string.\n   * \n   * @param text\n   *            the text to tokenize into sentences\n   * @param limit\n   *            the maximum number of sentences to return; zero indicates \"as\n   *            many as possible\".\n   * @return the first N sentences\n   */\n  public static String[] getSentences(String text, int limit) {\n//    return tokenize(SENTENCES, text, limit); // equivalent but slower\n    int len = text.length();\n    if (len == 0) return new String[] { text };\n    if (limit <= 0) limit = Integer.MAX_VALUE;\n    \n    // average sentence length heuristic\n    String[] tokens = new String[Math.min(limit, 1 + len/40)];\n    int size = 0;\n    int i = 0;\n    \n    while (i < len && size < limit) {\n      \n      // scan to end of current sentence\n      int start = i;\n      while (i < len && !isSentenceSeparator(text.charAt(i))) i++;\n      \n      if (size == tokens.length) { // grow array\n        String[] tmp = new String[tokens.length << 1];\n        System.arraycopy(tokens, 0, tmp, 0, size);\n        tokens = tmp;\n      }\n      // add sentence (potentially empty)\n      tokens[size++] = text.substring(start, i).trim();\n\n      // scan to beginning of next sentence\n      while (i < len && isSentenceSeparator(text.charAt(i))) i++;\n    }\n    \n    if (size == tokens.length) return tokens;\n    String[] results = new String[size];\n    System.arraycopy(tokens, 0, results, 0, size);\n    return results;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"689f35bd9818b47b8d9fe96cf06518228e949ab6":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["689f35bd9818b47b8d9fe96cf06518228e949ab6"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"689f35bd9818b47b8d9fe96cf06518228e949ab6":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["689f35bd9818b47b8d9fe96cf06518228e949ab6"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}