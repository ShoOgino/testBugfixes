{"path":"src/test/org/apache/solr/analysis/TestWordDelimiterFilter#testPositionIncrements().mjava","commits":[{"id":"1d786062be6da940351591ec2372ddd0ae56bd39","date":1251293566,"type":0,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/test/org/apache/solr/analysis/TestWordDelimiterFilter#testPositionIncrements().mjava","pathOld":"/dev/null","sourceNew":"  public void testPositionIncrements() throws Exception {\n    final CharArraySet protWords = new CharArraySet(new HashSet<String>(Arrays.asList(\"NUTCH\")), false);\n    \n    /* analyzer that uses whitespace + wdf */\n    Analyzer a = new Analyzer() {\n      public TokenStream tokenStream(String field, Reader reader) {\n        return new WordDelimiterFilter(\n            new WhitespaceTokenizer(reader),\n            1, 1, 0, 0, 1, 1, 0, 1, 1, protWords);\n      }\n    };\n\n    /* in this case, works as expected. */\n    assertAnalyzesTo(a, \"LUCENE / SOLR\", new String[] { \"LUCENE\", \"SOLR\" },\n        new int[] { 0, 9 },\n        new int[] { 6, 13 },\n        new int[] { 1, 1 });\n    \n    /* only in this case, posInc of 2 ?! */\n    assertAnalyzesTo(a, \"LUCENE / solR\", new String[] { \"LUCENE\", \"sol\", \"R\", \"solR\" },\n        new int[] { 0, 9, 12, 9 },\n        new int[] { 6, 12, 13, 13 },\n        new int[] { 1, 1, 1, 0 });\n    \n    assertAnalyzesTo(a, \"LUCENE / NUTCH SOLR\", new String[] { \"LUCENE\", \"NUTCH\", \"SOLR\" },\n        new int[] { 0, 9, 15 },\n        new int[] { 6, 14, 19 },\n        new int[] { 1, 1, 1 });\n    \n    /* analyzer that will consume tokens with large position increments */\n    Analyzer a2 = new Analyzer() {\n      public TokenStream tokenStream(String field, Reader reader) {\n        return new WordDelimiterFilter(\n            new LargePosIncTokenFilter(\n            new WhitespaceTokenizer(reader)),\n            1, 1, 0, 0, 1, 1, 0, 1, 1, protWords);\n      }\n    };\n    \n    /* increment of \"largegap\" is preserved */\n    assertAnalyzesTo(a2, \"LUCENE largegap SOLR\", new String[] { \"LUCENE\", \"largegap\", \"SOLR\" },\n        new int[] { 0, 7, 16 },\n        new int[] { 6, 15, 20 },\n        new int[] { 1, 10, 1 });\n    \n    /* the \"/\" had a position increment of 10, where did it go?!?!! */\n    assertAnalyzesTo(a2, \"LUCENE / SOLR\", new String[] { \"LUCENE\", \"SOLR\" },\n        new int[] { 0, 9 },\n        new int[] { 6, 13 },\n        new int[] { 1, 11 });\n    \n    /* in this case, the increment of 10 from the \"/\" is carried over */\n    assertAnalyzesTo(a2, \"LUCENE / solR\", new String[] { \"LUCENE\", \"sol\", \"R\", \"solR\" },\n        new int[] { 0, 9, 12, 9 },\n        new int[] { 6, 12, 13, 13 },\n        new int[] { 1, 11, 1, 0 });\n    \n    assertAnalyzesTo(a2, \"LUCENE / NUTCH SOLR\", new String[] { \"LUCENE\", \"NUTCH\", \"SOLR\" },\n        new int[] { 0, 9, 15 },\n        new int[] { 6, 14, 19 },\n        new int[] { 1, 11, 1 });\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["c85fa43e6918808743daa7847ba0264373af687f","ad9e3deabce40d9849c1b75ef706bfa79f4f0d1e"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/analysis/TestWordDelimiterFilter#testPositionIncrements().mjava","pathOld":"src/test/org/apache/solr/analysis/TestWordDelimiterFilter#testPositionIncrements().mjava","sourceNew":"  public void testPositionIncrements() throws Exception {\n    final CharArraySet protWords = new CharArraySet(new HashSet<String>(Arrays.asList(\"NUTCH\")), false);\n    \n    /* analyzer that uses whitespace + wdf */\n    Analyzer a = new Analyzer() {\n      public TokenStream tokenStream(String field, Reader reader) {\n        return new WordDelimiterFilter(\n            new WhitespaceTokenizer(reader),\n            1, 1, 0, 0, 1, 1, 0, 1, 1, protWords);\n      }\n    };\n\n    /* in this case, works as expected. */\n    assertAnalyzesTo(a, \"LUCENE / SOLR\", new String[] { \"LUCENE\", \"SOLR\" },\n        new int[] { 0, 9 },\n        new int[] { 6, 13 },\n        new int[] { 1, 1 });\n    \n    /* only in this case, posInc of 2 ?! */\n    assertAnalyzesTo(a, \"LUCENE / solR\", new String[] { \"LUCENE\", \"sol\", \"R\", \"solR\" },\n        new int[] { 0, 9, 12, 9 },\n        new int[] { 6, 12, 13, 13 },\n        new int[] { 1, 1, 1, 0 });\n    \n    assertAnalyzesTo(a, \"LUCENE / NUTCH SOLR\", new String[] { \"LUCENE\", \"NUTCH\", \"SOLR\" },\n        new int[] { 0, 9, 15 },\n        new int[] { 6, 14, 19 },\n        new int[] { 1, 1, 1 });\n    \n    /* analyzer that will consume tokens with large position increments */\n    Analyzer a2 = new Analyzer() {\n      public TokenStream tokenStream(String field, Reader reader) {\n        return new WordDelimiterFilter(\n            new LargePosIncTokenFilter(\n            new WhitespaceTokenizer(reader)),\n            1, 1, 0, 0, 1, 1, 0, 1, 1, protWords);\n      }\n    };\n    \n    /* increment of \"largegap\" is preserved */\n    assertAnalyzesTo(a2, \"LUCENE largegap SOLR\", new String[] { \"LUCENE\", \"largegap\", \"SOLR\" },\n        new int[] { 0, 7, 16 },\n        new int[] { 6, 15, 20 },\n        new int[] { 1, 10, 1 });\n    \n    /* the \"/\" had a position increment of 10, where did it go?!?!! */\n    assertAnalyzesTo(a2, \"LUCENE / SOLR\", new String[] { \"LUCENE\", \"SOLR\" },\n        new int[] { 0, 9 },\n        new int[] { 6, 13 },\n        new int[] { 1, 11 });\n    \n    /* in this case, the increment of 10 from the \"/\" is carried over */\n    assertAnalyzesTo(a2, \"LUCENE / solR\", new String[] { \"LUCENE\", \"sol\", \"R\", \"solR\" },\n        new int[] { 0, 9, 12, 9 },\n        new int[] { 6, 12, 13, 13 },\n        new int[] { 1, 11, 1, 0 });\n    \n    assertAnalyzesTo(a2, \"LUCENE / NUTCH SOLR\", new String[] { \"LUCENE\", \"NUTCH\", \"SOLR\" },\n        new int[] { 0, 9, 15 },\n        new int[] { 6, 14, 19 },\n        new int[] { 1, 11, 1 });\n  }\n\n","sourceOld":"  public void testPositionIncrements() throws Exception {\n    final CharArraySet protWords = new CharArraySet(new HashSet<String>(Arrays.asList(\"NUTCH\")), false);\n    \n    /* analyzer that uses whitespace + wdf */\n    Analyzer a = new Analyzer() {\n      public TokenStream tokenStream(String field, Reader reader) {\n        return new WordDelimiterFilter(\n            new WhitespaceTokenizer(reader),\n            1, 1, 0, 0, 1, 1, 0, 1, 1, protWords);\n      }\n    };\n\n    /* in this case, works as expected. */\n    assertAnalyzesTo(a, \"LUCENE / SOLR\", new String[] { \"LUCENE\", \"SOLR\" },\n        new int[] { 0, 9 },\n        new int[] { 6, 13 },\n        new int[] { 1, 1 });\n    \n    /* only in this case, posInc of 2 ?! */\n    assertAnalyzesTo(a, \"LUCENE / solR\", new String[] { \"LUCENE\", \"sol\", \"R\", \"solR\" },\n        new int[] { 0, 9, 12, 9 },\n        new int[] { 6, 12, 13, 13 },\n        new int[] { 1, 1, 1, 0 });\n    \n    assertAnalyzesTo(a, \"LUCENE / NUTCH SOLR\", new String[] { \"LUCENE\", \"NUTCH\", \"SOLR\" },\n        new int[] { 0, 9, 15 },\n        new int[] { 6, 14, 19 },\n        new int[] { 1, 1, 1 });\n    \n    /* analyzer that will consume tokens with large position increments */\n    Analyzer a2 = new Analyzer() {\n      public TokenStream tokenStream(String field, Reader reader) {\n        return new WordDelimiterFilter(\n            new LargePosIncTokenFilter(\n            new WhitespaceTokenizer(reader)),\n            1, 1, 0, 0, 1, 1, 0, 1, 1, protWords);\n      }\n    };\n    \n    /* increment of \"largegap\" is preserved */\n    assertAnalyzesTo(a2, \"LUCENE largegap SOLR\", new String[] { \"LUCENE\", \"largegap\", \"SOLR\" },\n        new int[] { 0, 7, 16 },\n        new int[] { 6, 15, 20 },\n        new int[] { 1, 10, 1 });\n    \n    /* the \"/\" had a position increment of 10, where did it go?!?!! */\n    assertAnalyzesTo(a2, \"LUCENE / SOLR\", new String[] { \"LUCENE\", \"SOLR\" },\n        new int[] { 0, 9 },\n        new int[] { 6, 13 },\n        new int[] { 1, 11 });\n    \n    /* in this case, the increment of 10 from the \"/\" is carried over */\n    assertAnalyzesTo(a2, \"LUCENE / solR\", new String[] { \"LUCENE\", \"sol\", \"R\", \"solR\" },\n        new int[] { 0, 9, 12, 9 },\n        new int[] { 6, 12, 13, 13 },\n        new int[] { 1, 11, 1, 0 });\n    \n    assertAnalyzesTo(a2, \"LUCENE / NUTCH SOLR\", new String[] { \"LUCENE\", \"NUTCH\", \"SOLR\" },\n        new int[] { 0, 9, 15 },\n        new int[] { 6, 14, 19 },\n        new int[] { 1, 11, 1 });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"1d786062be6da940351591ec2372ddd0ae56bd39":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"ad94625fb8d088209f46650c8097196fec67f00c":["1d786062be6da940351591ec2372ddd0ae56bd39"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"1d786062be6da940351591ec2372ddd0ae56bd39":["ad94625fb8d088209f46650c8097196fec67f00c"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["1d786062be6da940351591ec2372ddd0ae56bd39"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ad94625fb8d088209f46650c8097196fec67f00c":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ad94625fb8d088209f46650c8097196fec67f00c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}