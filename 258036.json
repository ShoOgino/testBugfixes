{"path":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testSpanNear().mjava","commits":[{"id":"dd81b1d062b9688a18721a1adfc489577479856a","date":1390711758,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testSpanNear().mjava","pathOld":"/dev/null","sourceNew":"  public void testSpanNear() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"This is a test.\");\n    iw.addDocument(doc);\n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    SpanQuery childQuery = new SpanMultiTermQueryWrapper<WildcardQuery>(new WildcardQuery(new Term(\"body\", \"te*\")));\n    Query query = new SpanNearQuery(new SpanQuery[] { childQuery }, 0, true);\n    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testSpanNear().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testSpanNear().mjava","sourceNew":"  public void testSpanNear() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"This is a test.\");\n    iw.addDocument(doc);\n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    SpanQuery childQuery = new SpanMultiTermQueryWrapper<>(new WildcardQuery(new Term(\"body\", \"te*\")));\n    Query query = new SpanNearQuery(new SpanQuery[] { childQuery }, 0, true);\n    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testSpanNear() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"This is a test.\");\n    iw.addDocument(doc);\n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    SpanQuery childQuery = new SpanMultiTermQueryWrapper<WildcardQuery>(new WildcardQuery(new Term(\"body\", \"te*\")));\n    Query query = new SpanNearQuery(new SpanQuery[] { childQuery }, 0, true);\n    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testSpanNear().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testSpanNear().mjava","sourceNew":"  public void testSpanNear() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"This is a test.\");\n    iw.addDocument(doc);\n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.shutdown();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    SpanQuery childQuery = new SpanMultiTermQueryWrapper<>(new WildcardQuery(new Term(\"body\", \"te*\")));\n    Query query = new SpanNearQuery(new SpanQuery[] { childQuery }, 0, true);\n    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testSpanNear() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"This is a test.\");\n    iw.addDocument(doc);\n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    SpanQuery childQuery = new SpanMultiTermQueryWrapper<>(new WildcardQuery(new Term(\"body\", \"te*\")));\n    Query query = new SpanNearQuery(new SpanQuery[] { childQuery }, 0, true);\n    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testSpanNear().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testSpanNear().mjava","sourceNew":"  public void testSpanNear() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"This is a test.\");\n    iw.addDocument(doc);\n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.shutdown();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    SpanQuery childQuery = new SpanMultiTermQueryWrapper<>(new WildcardQuery(new Term(\"body\", \"te*\")));\n    Query query = new SpanNearQuery(new SpanQuery[] { childQuery }, 0, true);\n    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testSpanNear() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"This is a test.\");\n    iw.addDocument(doc);\n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.shutdown();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    SpanQuery childQuery = new SpanMultiTermQueryWrapper<>(new WildcardQuery(new Term(\"body\", \"te*\")));\n    Query query = new SpanNearQuery(new SpanQuery[] { childQuery }, 0, true);\n    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testSpanNear().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testSpanNear().mjava","sourceNew":"  public void testSpanNear() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"This is a test.\");\n    iw.addDocument(doc);\n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    SpanQuery childQuery = new SpanMultiTermQueryWrapper<>(new WildcardQuery(new Term(\"body\", \"te*\")));\n    Query query = new SpanNearQuery(new SpanQuery[] { childQuery }, 0, true);\n    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testSpanNear() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"This is a test.\");\n    iw.addDocument(doc);\n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.shutdown();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    SpanQuery childQuery = new SpanMultiTermQueryWrapper<>(new WildcardQuery(new Term(\"body\", \"te*\")));\n    Query query = new SpanNearQuery(new SpanQuery[] { childQuery }, 0, true);\n    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc","date":1424799790,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testSpanNear().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testSpanNear().mjava","sourceNew":"  public void testSpanNear() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"This is a test.\");\n    iw.addDocument(doc);\n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    SpanQuery childQuery = new SpanMultiTermQueryWrapper<>(new WildcardQuery(new Term(\"body\", \"te*\")));\n    Query query = new SpanNearQuery(new SpanQuery[] { childQuery }, 0, true);\n    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testSpanNear() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"This is a test.\");\n    iw.addDocument(doc);\n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    SpanQuery childQuery = new SpanMultiTermQueryWrapper<>(new WildcardQuery(new Term(\"body\", \"te*\")));\n    Query query = new SpanNearQuery(new SpanQuery[] { childQuery }, 0, true);\n    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"30de45e50bdc1a79a6797f34dca6271c8866cb6e","date":1427790465,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testSpanNear().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testSpanNear().mjava","sourceNew":"  public void testSpanNear() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"This is a test.\");\n    iw.addDocument(doc);\n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    SpanQuery childQuery = new SpanMultiTermQueryWrapper<>(new WildcardQuery(new Term(\"body\", \"te*\")));\n    Query query = new SpanNearQuery(new SpanQuery[] { childQuery, childQuery }, 0, false);\n    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testSpanNear() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"This is a test.\");\n    iw.addDocument(doc);\n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    SpanQuery childQuery = new SpanMultiTermQueryWrapper<>(new WildcardQuery(new Term(\"body\", \"te*\")));\n    Query query = new SpanNearQuery(new SpanQuery[] { childQuery }, 0, true);\n    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fab172655716b96f7e42376116235017a922de3a","date":1427850611,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testSpanNear().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testSpanNear().mjava","sourceNew":"  public void testSpanNear() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"This is a test.\");\n    iw.addDocument(doc);\n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    SpanQuery childQuery = new SpanMultiTermQueryWrapper<>(new WildcardQuery(new Term(\"body\", \"te*\")));\n    Query query = new SpanNearQuery(new SpanQuery[] { childQuery, childQuery }, 0, false);\n    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testSpanNear() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"This is a test.\");\n    iw.addDocument(doc);\n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    SpanQuery childQuery = new SpanMultiTermQueryWrapper<>(new WildcardQuery(new Term(\"body\", \"te*\")));\n    Query query = new SpanNearQuery(new SpanQuery[] { childQuery }, 0, true);\n    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"381618eac2691bb34ab9a3fca76ad55c6274517e","date":1495564791,"type":4,"author":"David Smiley","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testSpanNear().mjava","sourceNew":null,"sourceOld":"  public void testSpanNear() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"This is a test.\");\n    iw.addDocument(doc);\n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    SpanQuery childQuery = new SpanMultiTermQueryWrapper<>(new WildcardQuery(new Term(\"body\", \"te*\")));\n    Query query = new SpanNearQuery(new SpanQuery[] { childQuery, childQuery }, 0, false);\n    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e9017cf144952056066919f1ebc7897ff9bd71b1","date":1496757600,"type":4,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testSpanNear().mjava","sourceNew":null,"sourceOld":"  public void testSpanNear() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"This is a test.\");\n    iw.addDocument(doc);\n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    SpanQuery childQuery = new SpanMultiTermQueryWrapper<>(new WildcardQuery(new Term(\"body\", \"te*\")));\n    Query query = new SpanNearQuery(new SpanQuery[] { childQuery, childQuery }, 0, false);\n    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"381618eac2691bb34ab9a3fca76ad55c6274517e":["30de45e50bdc1a79a6797f34dca6271c8866cb6e"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["dd81b1d062b9688a18721a1adfc489577479856a"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["30de45e50bdc1a79a6797f34dca6271c8866cb6e","381618eac2691bb34ab9a3fca76ad55c6274517e"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"30de45e50bdc1a79a6797f34dca6271c8866cb6e":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc"],"dd81b1d062b9688a18721a1adfc489577479856a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"fab172655716b96f7e42376116235017a922de3a":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc","30de45e50bdc1a79a6797f34dca6271c8866cb6e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["381618eac2691bb34ab9a3fca76ad55c6274517e"]},"commit2Childs":{"381618eac2691bb34ab9a3fca76ad55c6274517e":["e9017cf144952056066919f1ebc7897ff9bd71b1","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"e9017cf144952056066919f1ebc7897ff9bd71b1":[],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc":["30de45e50bdc1a79a6797f34dca6271c8866cb6e","fab172655716b96f7e42376116235017a922de3a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["dd81b1d062b9688a18721a1adfc489577479856a"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"30de45e50bdc1a79a6797f34dca6271c8866cb6e":["381618eac2691bb34ab9a3fca76ad55c6274517e","e9017cf144952056066919f1ebc7897ff9bd71b1","fab172655716b96f7e42376116235017a922de3a"],"dd81b1d062b9688a18721a1adfc489577479856a":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"fab172655716b96f7e42376116235017a922de3a":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["e9017cf144952056066919f1ebc7897ff9bd71b1","fab172655716b96f7e42376116235017a922de3a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}