{"path":"lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#collectionStatistics(String).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#collectionStatistics(String).mjava","pathOld":"lucene/src/test-framework/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#collectionStatistics(String).mjava","sourceNew":"      @Override\n      public CollectionStatistics collectionStatistics(String field) throws IOException {\n        // TODO: we could compute this on init and cache,\n        // since we are re-inited whenever any nodes have a\n        // new reader\n        long docCount = 0;\n        long sumTotalTermFreq = 0;\n        long sumDocFreq = 0;\n        long maxDoc = 0;\n\n        for(int nodeID=0;nodeID<nodeVersions.length;nodeID++) {\n          final FieldAndShardVersion key = new FieldAndShardVersion(nodeID, nodeVersions[nodeID], field);\n          final CollectionStatistics nodeStats;\n          if (nodeID == myNodeID) {\n            nodeStats = super.collectionStatistics(field);\n          } else {\n            nodeStats = collectionStatsCache.get(key);\n          }\n          if (nodeStats == null) {\n            System.out.println(\"coll stats myNodeID=\" + myNodeID + \": \" + collectionStatsCache.keySet());\n          }\n          // Collection stats are pre-shared on reopen, so,\n          // we better not have a cache miss:\n          assert nodeStats != null: \"myNodeID=\" + myNodeID + \" nodeID=\" + nodeID + \" version=\" + nodeVersions[nodeID] + \" field=\" + field;\n          \n          long nodeDocCount = nodeStats.docCount();\n          if (docCount >= 0 && nodeDocCount >= 0) {\n            docCount += nodeDocCount;\n          } else {\n            docCount = -1;\n          }\n          \n          long nodeSumTotalTermFreq = nodeStats.sumTotalTermFreq();\n          if (sumTotalTermFreq >= 0 && nodeSumTotalTermFreq >= 0) {\n            sumTotalTermFreq += nodeSumTotalTermFreq;\n          } else {\n            sumTotalTermFreq = -1;\n          }\n          \n          long nodeSumDocFreq = nodeStats.sumDocFreq();\n          if (sumDocFreq >= 0 && nodeSumDocFreq >= 0) {\n            sumDocFreq += nodeSumDocFreq;\n          } else {\n            sumDocFreq = -1;\n          }\n          \n          assert nodeStats.maxDoc() >= 0;\n          maxDoc += nodeStats.maxDoc();\n        }\n\n        return new CollectionStatistics(field, maxDoc, docCount, sumTotalTermFreq, sumDocFreq);\n      }\n\n","sourceOld":"      @Override\n      public CollectionStatistics collectionStatistics(String field) throws IOException {\n        // TODO: we could compute this on init and cache,\n        // since we are re-inited whenever any nodes have a\n        // new reader\n        long docCount = 0;\n        long sumTotalTermFreq = 0;\n        long sumDocFreq = 0;\n        long maxDoc = 0;\n\n        for(int nodeID=0;nodeID<nodeVersions.length;nodeID++) {\n          final FieldAndShardVersion key = new FieldAndShardVersion(nodeID, nodeVersions[nodeID], field);\n          final CollectionStatistics nodeStats;\n          if (nodeID == myNodeID) {\n            nodeStats = super.collectionStatistics(field);\n          } else {\n            nodeStats = collectionStatsCache.get(key);\n          }\n          if (nodeStats == null) {\n            System.out.println(\"coll stats myNodeID=\" + myNodeID + \": \" + collectionStatsCache.keySet());\n          }\n          // Collection stats are pre-shared on reopen, so,\n          // we better not have a cache miss:\n          assert nodeStats != null: \"myNodeID=\" + myNodeID + \" nodeID=\" + nodeID + \" version=\" + nodeVersions[nodeID] + \" field=\" + field;\n          \n          long nodeDocCount = nodeStats.docCount();\n          if (docCount >= 0 && nodeDocCount >= 0) {\n            docCount += nodeDocCount;\n          } else {\n            docCount = -1;\n          }\n          \n          long nodeSumTotalTermFreq = nodeStats.sumTotalTermFreq();\n          if (sumTotalTermFreq >= 0 && nodeSumTotalTermFreq >= 0) {\n            sumTotalTermFreq += nodeSumTotalTermFreq;\n          } else {\n            sumTotalTermFreq = -1;\n          }\n          \n          long nodeSumDocFreq = nodeStats.sumDocFreq();\n          if (sumDocFreq >= 0 && nodeSumDocFreq >= 0) {\n            sumDocFreq += nodeSumDocFreq;\n          } else {\n            sumDocFreq = -1;\n          }\n          \n          assert nodeStats.maxDoc() >= 0;\n          maxDoc += nodeStats.maxDoc();\n        }\n\n        return new CollectionStatistics(field, maxDoc, docCount, sumTotalTermFreq, sumDocFreq);\n      }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c3119ed4143b91eaf5ac74a4dc4625f5036d472c","date":1509409932,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#collectionStatistics(String).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#collectionStatistics(String).mjava","sourceNew":"      @Override\n      public CollectionStatistics collectionStatistics(String field) throws IOException {\n        // TODO: we could compute this on init and cache,\n        // since we are re-inited whenever any nodes have a\n        // new reader\n        long docCount = 0;\n        long sumTotalTermFreq = 0;\n        long sumDocFreq = 0;\n        long maxDoc = 0;\n\n        for(int nodeID=0;nodeID<nodeVersions.length;nodeID++) {\n          final FieldAndShardVersion key = new FieldAndShardVersion(nodeID, nodeVersions[nodeID], field);\n          final CollectionStatistics nodeStats;\n          if (nodeID == myNodeID) {\n            nodeStats = super.collectionStatistics(field);\n          } else {\n            nodeStats = collectionStatsCache.get(key);\n          }\n          if (nodeStats == null) {\n            continue; // field not in sub at all\n          }\n          \n          long nodeDocCount = nodeStats.docCount();\n          if (docCount >= 0 && nodeDocCount >= 0) {\n            docCount += nodeDocCount;\n          } else {\n            docCount = -1;\n          }\n          \n          long nodeSumTotalTermFreq = nodeStats.sumTotalTermFreq();\n          if (sumTotalTermFreq >= 0 && nodeSumTotalTermFreq >= 0) {\n            sumTotalTermFreq += nodeSumTotalTermFreq;\n          } else {\n            sumTotalTermFreq = -1;\n          }\n          \n          long nodeSumDocFreq = nodeStats.sumDocFreq();\n          if (sumDocFreq >= 0 && nodeSumDocFreq >= 0) {\n            sumDocFreq += nodeSumDocFreq;\n          } else {\n            sumDocFreq = -1;\n          }\n          \n          assert nodeStats.maxDoc() >= 0;\n          maxDoc += nodeStats.maxDoc();\n        }\n\n        if (maxDoc == 0) {\n          return null; // field not found across any node whatsoever\n        } else {\n          return new CollectionStatistics(field, maxDoc, docCount, sumTotalTermFreq, sumDocFreq);\n        }\n      }\n\n","sourceOld":"      @Override\n      public CollectionStatistics collectionStatistics(String field) throws IOException {\n        // TODO: we could compute this on init and cache,\n        // since we are re-inited whenever any nodes have a\n        // new reader\n        long docCount = 0;\n        long sumTotalTermFreq = 0;\n        long sumDocFreq = 0;\n        long maxDoc = 0;\n\n        for(int nodeID=0;nodeID<nodeVersions.length;nodeID++) {\n          final FieldAndShardVersion key = new FieldAndShardVersion(nodeID, nodeVersions[nodeID], field);\n          final CollectionStatistics nodeStats;\n          if (nodeID == myNodeID) {\n            nodeStats = super.collectionStatistics(field);\n          } else {\n            nodeStats = collectionStatsCache.get(key);\n          }\n          if (nodeStats == null) {\n            System.out.println(\"coll stats myNodeID=\" + myNodeID + \": \" + collectionStatsCache.keySet());\n          }\n          // Collection stats are pre-shared on reopen, so,\n          // we better not have a cache miss:\n          assert nodeStats != null: \"myNodeID=\" + myNodeID + \" nodeID=\" + nodeID + \" version=\" + nodeVersions[nodeID] + \" field=\" + field;\n          \n          long nodeDocCount = nodeStats.docCount();\n          if (docCount >= 0 && nodeDocCount >= 0) {\n            docCount += nodeDocCount;\n          } else {\n            docCount = -1;\n          }\n          \n          long nodeSumTotalTermFreq = nodeStats.sumTotalTermFreq();\n          if (sumTotalTermFreq >= 0 && nodeSumTotalTermFreq >= 0) {\n            sumTotalTermFreq += nodeSumTotalTermFreq;\n          } else {\n            sumTotalTermFreq = -1;\n          }\n          \n          long nodeSumDocFreq = nodeStats.sumDocFreq();\n          if (sumDocFreq >= 0 && nodeSumDocFreq >= 0) {\n            sumDocFreq += nodeSumDocFreq;\n          } else {\n            sumDocFreq = -1;\n          }\n          \n          assert nodeStats.maxDoc() >= 0;\n          maxDoc += nodeStats.maxDoc();\n        }\n\n        return new CollectionStatistics(field, maxDoc, docCount, sumTotalTermFreq, sumDocFreq);\n      }\n\n","bugFix":["226aae72c0326f4299c16280195bade4530de537"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"086ffe31d8fba0110227db122974163709ecc1b4","date":1509678141,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#collectionStatistics(String).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#collectionStatistics(String).mjava","sourceNew":"      @Override\n      public CollectionStatistics collectionStatistics(String field) throws IOException {\n        // TODO: we could compute this on init and cache,\n        // since we are re-inited whenever any nodes have a\n        // new reader\n        long docCount = 0;\n        long sumTotalTermFreq = 0;\n        long sumDocFreq = 0;\n        long maxDoc = 0;\n\n        for(int nodeID=0;nodeID<nodeVersions.length;nodeID++) {\n          final FieldAndShardVersion key = new FieldAndShardVersion(nodeID, nodeVersions[nodeID], field);\n          final CollectionStatistics nodeStats;\n          if (nodeID == myNodeID) {\n            nodeStats = super.collectionStatistics(field);\n          } else {\n            nodeStats = collectionStatsCache.get(key);\n          }\n          if (nodeStats == null) {\n            continue; // field not in sub at all\n          }\n          \n          long nodeDocCount = nodeStats.docCount();\n          docCount += nodeDocCount;\n          \n          long nodeSumTotalTermFreq = nodeStats.sumTotalTermFreq();\n          sumTotalTermFreq += nodeSumTotalTermFreq;\n          \n          long nodeSumDocFreq = nodeStats.sumDocFreq();\n          sumDocFreq += nodeSumDocFreq;\n          \n          assert nodeStats.maxDoc() >= 0;\n          maxDoc += nodeStats.maxDoc();\n        }\n\n        if (maxDoc == 0) {\n          return null; // field not found across any node whatsoever\n        } else {\n          return new CollectionStatistics(field, maxDoc, docCount, sumTotalTermFreq, sumDocFreq);\n        }\n      }\n\n","sourceOld":"      @Override\n      public CollectionStatistics collectionStatistics(String field) throws IOException {\n        // TODO: we could compute this on init and cache,\n        // since we are re-inited whenever any nodes have a\n        // new reader\n        long docCount = 0;\n        long sumTotalTermFreq = 0;\n        long sumDocFreq = 0;\n        long maxDoc = 0;\n\n        for(int nodeID=0;nodeID<nodeVersions.length;nodeID++) {\n          final FieldAndShardVersion key = new FieldAndShardVersion(nodeID, nodeVersions[nodeID], field);\n          final CollectionStatistics nodeStats;\n          if (nodeID == myNodeID) {\n            nodeStats = super.collectionStatistics(field);\n          } else {\n            nodeStats = collectionStatsCache.get(key);\n          }\n          if (nodeStats == null) {\n            continue; // field not in sub at all\n          }\n          \n          long nodeDocCount = nodeStats.docCount();\n          if (docCount >= 0 && nodeDocCount >= 0) {\n            docCount += nodeDocCount;\n          } else {\n            docCount = -1;\n          }\n          \n          long nodeSumTotalTermFreq = nodeStats.sumTotalTermFreq();\n          if (sumTotalTermFreq >= 0 && nodeSumTotalTermFreq >= 0) {\n            sumTotalTermFreq += nodeSumTotalTermFreq;\n          } else {\n            sumTotalTermFreq = -1;\n          }\n          \n          long nodeSumDocFreq = nodeStats.sumDocFreq();\n          if (sumDocFreq >= 0 && nodeSumDocFreq >= 0) {\n            sumDocFreq += nodeSumDocFreq;\n          } else {\n            sumDocFreq = -1;\n          }\n          \n          assert nodeStats.maxDoc() >= 0;\n          maxDoc += nodeStats.maxDoc();\n        }\n\n        if (maxDoc == 0) {\n          return null; // field not found across any node whatsoever\n        } else {\n          return new CollectionStatistics(field, maxDoc, docCount, sumTotalTermFreq, sumDocFreq);\n        }\n      }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d523b8189b211dd1630166aa77b8c88bb48b3fcc","date":1510144168,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#collectionStatistics(String).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#collectionStatistics(String).mjava","sourceNew":"      @Override\n      public CollectionStatistics collectionStatistics(String field) throws IOException {\n        // TODO: we could compute this on init and cache,\n        // since we are re-inited whenever any nodes have a\n        // new reader\n        long docCount = 0;\n        long sumTotalTermFreq = 0;\n        long sumDocFreq = 0;\n        long maxDoc = 0;\n\n        for(int nodeID=0;nodeID<nodeVersions.length;nodeID++) {\n          final FieldAndShardVersion key = new FieldAndShardVersion(nodeID, nodeVersions[nodeID], field);\n          final CollectionStatistics nodeStats;\n          if (nodeID == myNodeID) {\n            nodeStats = super.collectionStatistics(field);\n          } else {\n            nodeStats = collectionStatsCache.get(key);\n          }\n          if (nodeStats == null) {\n            continue; // field not in sub at all\n          }\n          \n          long nodeDocCount = nodeStats.docCount();\n          docCount += nodeDocCount;\n          \n          long nodeSumTotalTermFreq = nodeStats.sumTotalTermFreq();\n          sumTotalTermFreq += nodeSumTotalTermFreq;\n          \n          long nodeSumDocFreq = nodeStats.sumDocFreq();\n          sumDocFreq += nodeSumDocFreq;\n          \n          assert nodeStats.maxDoc() >= 0;\n          maxDoc += nodeStats.maxDoc();\n        }\n\n        if (maxDoc == 0) {\n          return null; // field not found across any node whatsoever\n        } else {\n          return new CollectionStatistics(field, maxDoc, docCount, sumTotalTermFreq, sumDocFreq);\n        }\n      }\n\n","sourceOld":"      @Override\n      public CollectionStatistics collectionStatistics(String field) throws IOException {\n        // TODO: we could compute this on init and cache,\n        // since we are re-inited whenever any nodes have a\n        // new reader\n        long docCount = 0;\n        long sumTotalTermFreq = 0;\n        long sumDocFreq = 0;\n        long maxDoc = 0;\n\n        for(int nodeID=0;nodeID<nodeVersions.length;nodeID++) {\n          final FieldAndShardVersion key = new FieldAndShardVersion(nodeID, nodeVersions[nodeID], field);\n          final CollectionStatistics nodeStats;\n          if (nodeID == myNodeID) {\n            nodeStats = super.collectionStatistics(field);\n          } else {\n            nodeStats = collectionStatsCache.get(key);\n          }\n          if (nodeStats == null) {\n            continue; // field not in sub at all\n          }\n          \n          long nodeDocCount = nodeStats.docCount();\n          if (docCount >= 0 && nodeDocCount >= 0) {\n            docCount += nodeDocCount;\n          } else {\n            docCount = -1;\n          }\n          \n          long nodeSumTotalTermFreq = nodeStats.sumTotalTermFreq();\n          if (sumTotalTermFreq >= 0 && nodeSumTotalTermFreq >= 0) {\n            sumTotalTermFreq += nodeSumTotalTermFreq;\n          } else {\n            sumTotalTermFreq = -1;\n          }\n          \n          long nodeSumDocFreq = nodeStats.sumDocFreq();\n          if (sumDocFreq >= 0 && nodeSumDocFreq >= 0) {\n            sumDocFreq += nodeSumDocFreq;\n          } else {\n            sumDocFreq = -1;\n          }\n          \n          assert nodeStats.maxDoc() >= 0;\n          maxDoc += nodeStats.maxDoc();\n        }\n\n        if (maxDoc == 0) {\n          return null; // field not found across any node whatsoever\n        } else {\n          return new CollectionStatistics(field, maxDoc, docCount, sumTotalTermFreq, sumDocFreq);\n        }\n      }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"086ffe31d8fba0110227db122974163709ecc1b4":["c3119ed4143b91eaf5ac74a4dc4625f5036d472c"],"d523b8189b211dd1630166aa77b8c88bb48b3fcc":["c3119ed4143b91eaf5ac74a4dc4625f5036d472c","086ffe31d8fba0110227db122974163709ecc1b4"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d523b8189b211dd1630166aa77b8c88bb48b3fcc"],"c3119ed4143b91eaf5ac74a4dc4625f5036d472c":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"086ffe31d8fba0110227db122974163709ecc1b4":["d523b8189b211dd1630166aa77b8c88bb48b3fcc"],"d523b8189b211dd1630166aa77b8c88bb48b3fcc":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["c3119ed4143b91eaf5ac74a4dc4625f5036d472c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"c3119ed4143b91eaf5ac74a4dc4625f5036d472c":["086ffe31d8fba0110227db122974163709ecc1b4","d523b8189b211dd1630166aa77b8c88bb48b3fcc"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}