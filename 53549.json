{"path":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testCommonTermsQueryHighlight().mjava","commits":[{"id":"94221e4190ec47a1ec4f0bd8f99b3648af295a06","date":1389175887,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testCommonTermsQueryHighlight().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testCommonTermsQueryHighlightTest().mjava","sourceNew":"  public void testCommonTermsQueryHighlight() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,  new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET)));\n    FieldType type = new FieldType(TextField.TYPE_STORED);\n    type.setStoreTermVectorOffsets(true);\n    type.setStoreTermVectorPositions(true);\n    type.setStoreTermVectors(true);\n    type.freeze();\n    String[] texts = {\n        \"Hello this is a piece of text that is very long and contains too much preamble and the meat is really here which says kennedy has been shot\",\n        \"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is very long in the middle and finally ends with another reference to Kennedy\",\n        \"JFK has been shot\", \"John Kennedy has been shot\",\n        \"This text has a typo in referring to Keneddy\",\n        \"wordx wordy wordz wordx wordy wordx worda wordb wordy wordc\", \"y z x y z a b\", \"lets is a the lets is a the lets is a the lets\" };\n    for (int i = 0; i < texts.length; i++) {\n      Document doc = new Document();\n      Field field = new Field(\"field\", texts[i], type);\n      doc.add(field);\n      writer.addDocument(doc);\n    }\n    CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 2);\n    query.add(new Term(\"field\", \"text\"));\n    query.add(new Term(\"field\", \"long\"));\n    query.add(new Term(\"field\", \"very\"));\n   \n    FastVectorHighlighter highlighter = new FastVectorHighlighter();\n    IndexReader reader = DirectoryReader.open(writer, true);\n    IndexSearcher searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    FieldQuery fieldQuery  = highlighter.getFieldQuery(query, reader);\n    String[] bestFragments = highlighter.getBestFragments(fieldQuery, reader, hits.scoreDocs[0].doc, \"field\", 1000, 1);\n    assertEquals(\"This piece of <b>text</b> refers to Kennedy at the beginning then has a longer piece of <b>text</b> that is <b>very</b> <b>long</b> in the middle and finally ends with another reference to Kennedy\", bestFragments[0]);\n\n    fieldQuery  = highlighter.getFieldQuery(query, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, hits.scoreDocs[1].doc, \"field\", 1000, 1);\n    assertEquals(\"Hello this is a piece of <b>text</b> that is <b>very</b> <b>long</b> and contains too much preamble and the meat is really here which says kennedy has been shot\", bestFragments[0]);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testCommonTermsQueryHighlightTest() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,  new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET)));\n    FieldType type = new FieldType(TextField.TYPE_STORED);\n    type.setStoreTermVectorOffsets(true);\n    type.setStoreTermVectorPositions(true);\n    type.setStoreTermVectors(true);\n    type.freeze();\n    String[] texts = {\n        \"Hello this is a piece of text that is very long and contains too much preamble and the meat is really here which says kennedy has been shot\",\n        \"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is very long in the middle and finally ends with another reference to Kennedy\",\n        \"JFK has been shot\", \"John Kennedy has been shot\",\n        \"This text has a typo in referring to Keneddy\",\n        \"wordx wordy wordz wordx wordy wordx worda wordb wordy wordc\", \"y z x y z a b\", \"lets is a the lets is a the lets is a the lets\" };\n    for (int i = 0; i < texts.length; i++) {\n      Document doc = new Document();\n      Field field = new Field(\"field\", texts[i], type);\n      doc.add(field);\n      writer.addDocument(doc);\n    }\n    CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 2);\n    query.add(new Term(\"field\", \"text\"));\n    query.add(new Term(\"field\", \"long\"));\n    query.add(new Term(\"field\", \"very\"));\n   \n    FastVectorHighlighter highlighter = new FastVectorHighlighter();\n    IndexReader reader = DirectoryReader.open(writer, true);\n    IndexSearcher searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    FieldQuery fieldQuery  = highlighter.getFieldQuery(query, reader);\n    String[] bestFragments = highlighter.getBestFragments(fieldQuery, reader, hits.scoreDocs[0].doc, \"field\", 1000, 1);\n    assertEquals(\"This piece of <b>text</b> refers to Kennedy at the beginning then has a longer piece of <b>text</b> that is <b>very</b> <b>long</b> in the middle and finally ends with another reference to Kennedy\", bestFragments[0]);\n\n    fieldQuery  = highlighter.getFieldQuery(query, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, hits.scoreDocs[1].doc, \"field\", 1000, 1);\n    assertEquals(\"Hello this is a piece of <b>text</b> that is <b>very</b> <b>long</b> and contains too much preamble and the meat is really here which says kennedy has been shot\", bestFragments[0]);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testCommonTermsQueryHighlight().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testCommonTermsQueryHighlight().mjava","sourceNew":"  public void testCommonTermsQueryHighlight() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,  new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET)));\n    FieldType type = new FieldType(TextField.TYPE_STORED);\n    type.setStoreTermVectorOffsets(true);\n    type.setStoreTermVectorPositions(true);\n    type.setStoreTermVectors(true);\n    type.freeze();\n    String[] texts = {\n        \"Hello this is a piece of text that is very long and contains too much preamble and the meat is really here which says kennedy has been shot\",\n        \"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is very long in the middle and finally ends with another reference to Kennedy\",\n        \"JFK has been shot\", \"John Kennedy has been shot\",\n        \"This text has a typo in referring to Keneddy\",\n        \"wordx wordy wordz wordx wordy wordx worda wordb wordy wordc\", \"y z x y z a b\", \"lets is a the lets is a the lets is a the lets\" };\n    for (int i = 0; i < texts.length; i++) {\n      Document doc = new Document();\n      Field field = new Field(\"field\", texts[i], type);\n      doc.add(field);\n      writer.addDocument(doc);\n    }\n    CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 2);\n    query.add(new Term(\"field\", \"text\"));\n    query.add(new Term(\"field\", \"long\"));\n    query.add(new Term(\"field\", \"very\"));\n   \n    FastVectorHighlighter highlighter = new FastVectorHighlighter();\n    IndexReader reader = DirectoryReader.open(writer, true);\n    IndexSearcher searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    FieldQuery fieldQuery  = highlighter.getFieldQuery(query, reader);\n    String[] bestFragments = highlighter.getBestFragments(fieldQuery, reader, hits.scoreDocs[0].doc, \"field\", 1000, 1);\n    assertEquals(\"This piece of <b>text</b> refers to Kennedy at the beginning then has a longer piece of <b>text</b> that is <b>very</b> <b>long</b> in the middle and finally ends with another reference to Kennedy\", bestFragments[0]);\n\n    fieldQuery  = highlighter.getFieldQuery(query, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, hits.scoreDocs[1].doc, \"field\", 1000, 1);\n    assertEquals(\"Hello this is a piece of <b>text</b> that is <b>very</b> <b>long</b> and contains too much preamble and the meat is really here which says kennedy has been shot\", bestFragments[0]);\n\n    reader.close();\n    writer.shutdown();\n    dir.close();\n  }\n\n","sourceOld":"  public void testCommonTermsQueryHighlight() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,  new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET)));\n    FieldType type = new FieldType(TextField.TYPE_STORED);\n    type.setStoreTermVectorOffsets(true);\n    type.setStoreTermVectorPositions(true);\n    type.setStoreTermVectors(true);\n    type.freeze();\n    String[] texts = {\n        \"Hello this is a piece of text that is very long and contains too much preamble and the meat is really here which says kennedy has been shot\",\n        \"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is very long in the middle and finally ends with another reference to Kennedy\",\n        \"JFK has been shot\", \"John Kennedy has been shot\",\n        \"This text has a typo in referring to Keneddy\",\n        \"wordx wordy wordz wordx wordy wordx worda wordb wordy wordc\", \"y z x y z a b\", \"lets is a the lets is a the lets is a the lets\" };\n    for (int i = 0; i < texts.length; i++) {\n      Document doc = new Document();\n      Field field = new Field(\"field\", texts[i], type);\n      doc.add(field);\n      writer.addDocument(doc);\n    }\n    CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 2);\n    query.add(new Term(\"field\", \"text\"));\n    query.add(new Term(\"field\", \"long\"));\n    query.add(new Term(\"field\", \"very\"));\n   \n    FastVectorHighlighter highlighter = new FastVectorHighlighter();\n    IndexReader reader = DirectoryReader.open(writer, true);\n    IndexSearcher searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    FieldQuery fieldQuery  = highlighter.getFieldQuery(query, reader);\n    String[] bestFragments = highlighter.getBestFragments(fieldQuery, reader, hits.scoreDocs[0].doc, \"field\", 1000, 1);\n    assertEquals(\"This piece of <b>text</b> refers to Kennedy at the beginning then has a longer piece of <b>text</b> that is <b>very</b> <b>long</b> in the middle and finally ends with another reference to Kennedy\", bestFragments[0]);\n\n    fieldQuery  = highlighter.getFieldQuery(query, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, hits.scoreDocs[1].doc, \"field\", 1000, 1);\n    assertEquals(\"Hello this is a piece of <b>text</b> that is <b>very</b> <b>long</b> and contains too much preamble and the meat is really here which says kennedy has been shot\", bestFragments[0]);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testCommonTermsQueryHighlight().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testCommonTermsQueryHighlight().mjava","sourceNew":"  public void testCommonTermsQueryHighlight() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET)));\n    FieldType type = new FieldType(TextField.TYPE_STORED);\n    type.setStoreTermVectorOffsets(true);\n    type.setStoreTermVectorPositions(true);\n    type.setStoreTermVectors(true);\n    type.freeze();\n    String[] texts = {\n        \"Hello this is a piece of text that is very long and contains too much preamble and the meat is really here which says kennedy has been shot\",\n        \"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is very long in the middle and finally ends with another reference to Kennedy\",\n        \"JFK has been shot\", \"John Kennedy has been shot\",\n        \"This text has a typo in referring to Keneddy\",\n        \"wordx wordy wordz wordx wordy wordx worda wordb wordy wordc\", \"y z x y z a b\", \"lets is a the lets is a the lets is a the lets\" };\n    for (int i = 0; i < texts.length; i++) {\n      Document doc = new Document();\n      Field field = new Field(\"field\", texts[i], type);\n      doc.add(field);\n      writer.addDocument(doc);\n    }\n    CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 2);\n    query.add(new Term(\"field\", \"text\"));\n    query.add(new Term(\"field\", \"long\"));\n    query.add(new Term(\"field\", \"very\"));\n   \n    FastVectorHighlighter highlighter = new FastVectorHighlighter();\n    IndexReader reader = DirectoryReader.open(writer, true);\n    IndexSearcher searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    FieldQuery fieldQuery  = highlighter.getFieldQuery(query, reader);\n    String[] bestFragments = highlighter.getBestFragments(fieldQuery, reader, hits.scoreDocs[0].doc, \"field\", 1000, 1);\n    assertEquals(\"This piece of <b>text</b> refers to Kennedy at the beginning then has a longer piece of <b>text</b> that is <b>very</b> <b>long</b> in the middle and finally ends with another reference to Kennedy\", bestFragments[0]);\n\n    fieldQuery  = highlighter.getFieldQuery(query, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, hits.scoreDocs[1].doc, \"field\", 1000, 1);\n    assertEquals(\"Hello this is a piece of <b>text</b> that is <b>very</b> <b>long</b> and contains too much preamble and the meat is really here which says kennedy has been shot\", bestFragments[0]);\n\n    reader.close();\n    writer.shutdown();\n    dir.close();\n  }\n\n","sourceOld":"  public void testCommonTermsQueryHighlight() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,  new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET)));\n    FieldType type = new FieldType(TextField.TYPE_STORED);\n    type.setStoreTermVectorOffsets(true);\n    type.setStoreTermVectorPositions(true);\n    type.setStoreTermVectors(true);\n    type.freeze();\n    String[] texts = {\n        \"Hello this is a piece of text that is very long and contains too much preamble and the meat is really here which says kennedy has been shot\",\n        \"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is very long in the middle and finally ends with another reference to Kennedy\",\n        \"JFK has been shot\", \"John Kennedy has been shot\",\n        \"This text has a typo in referring to Keneddy\",\n        \"wordx wordy wordz wordx wordy wordx worda wordb wordy wordc\", \"y z x y z a b\", \"lets is a the lets is a the lets is a the lets\" };\n    for (int i = 0; i < texts.length; i++) {\n      Document doc = new Document();\n      Field field = new Field(\"field\", texts[i], type);\n      doc.add(field);\n      writer.addDocument(doc);\n    }\n    CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 2);\n    query.add(new Term(\"field\", \"text\"));\n    query.add(new Term(\"field\", \"long\"));\n    query.add(new Term(\"field\", \"very\"));\n   \n    FastVectorHighlighter highlighter = new FastVectorHighlighter();\n    IndexReader reader = DirectoryReader.open(writer, true);\n    IndexSearcher searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    FieldQuery fieldQuery  = highlighter.getFieldQuery(query, reader);\n    String[] bestFragments = highlighter.getBestFragments(fieldQuery, reader, hits.scoreDocs[0].doc, \"field\", 1000, 1);\n    assertEquals(\"This piece of <b>text</b> refers to Kennedy at the beginning then has a longer piece of <b>text</b> that is <b>very</b> <b>long</b> in the middle and finally ends with another reference to Kennedy\", bestFragments[0]);\n\n    fieldQuery  = highlighter.getFieldQuery(query, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, hits.scoreDocs[1].doc, \"field\", 1000, 1);\n    assertEquals(\"Hello this is a piece of <b>text</b> that is <b>very</b> <b>long</b> and contains too much preamble and the meat is really here which says kennedy has been shot\", bestFragments[0]);\n\n    reader.close();\n    writer.shutdown();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testCommonTermsQueryHighlight().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testCommonTermsQueryHighlight().mjava","sourceNew":"  public void testCommonTermsQueryHighlight() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET)));\n    FieldType type = new FieldType(TextField.TYPE_STORED);\n    type.setStoreTermVectorOffsets(true);\n    type.setStoreTermVectorPositions(true);\n    type.setStoreTermVectors(true);\n    type.freeze();\n    String[] texts = {\n        \"Hello this is a piece of text that is very long and contains too much preamble and the meat is really here which says kennedy has been shot\",\n        \"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is very long in the middle and finally ends with another reference to Kennedy\",\n        \"JFK has been shot\", \"John Kennedy has been shot\",\n        \"This text has a typo in referring to Keneddy\",\n        \"wordx wordy wordz wordx wordy wordx worda wordb wordy wordc\", \"y z x y z a b\", \"lets is a the lets is a the lets is a the lets\" };\n    for (int i = 0; i < texts.length; i++) {\n      Document doc = new Document();\n      Field field = new Field(\"field\", texts[i], type);\n      doc.add(field);\n      writer.addDocument(doc);\n    }\n    CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 2);\n    query.add(new Term(\"field\", \"text\"));\n    query.add(new Term(\"field\", \"long\"));\n    query.add(new Term(\"field\", \"very\"));\n   \n    FastVectorHighlighter highlighter = new FastVectorHighlighter();\n    IndexReader reader = DirectoryReader.open(writer, true);\n    IndexSearcher searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    FieldQuery fieldQuery  = highlighter.getFieldQuery(query, reader);\n    String[] bestFragments = highlighter.getBestFragments(fieldQuery, reader, hits.scoreDocs[0].doc, \"field\", 1000, 1);\n    assertEquals(\"This piece of <b>text</b> refers to Kennedy at the beginning then has a longer piece of <b>text</b> that is <b>very</b> <b>long</b> in the middle and finally ends with another reference to Kennedy\", bestFragments[0]);\n\n    fieldQuery  = highlighter.getFieldQuery(query, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, hits.scoreDocs[1].doc, \"field\", 1000, 1);\n    assertEquals(\"Hello this is a piece of <b>text</b> that is <b>very</b> <b>long</b> and contains too much preamble and the meat is really here which says kennedy has been shot\", bestFragments[0]);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testCommonTermsQueryHighlight() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET)));\n    FieldType type = new FieldType(TextField.TYPE_STORED);\n    type.setStoreTermVectorOffsets(true);\n    type.setStoreTermVectorPositions(true);\n    type.setStoreTermVectors(true);\n    type.freeze();\n    String[] texts = {\n        \"Hello this is a piece of text that is very long and contains too much preamble and the meat is really here which says kennedy has been shot\",\n        \"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is very long in the middle and finally ends with another reference to Kennedy\",\n        \"JFK has been shot\", \"John Kennedy has been shot\",\n        \"This text has a typo in referring to Keneddy\",\n        \"wordx wordy wordz wordx wordy wordx worda wordb wordy wordc\", \"y z x y z a b\", \"lets is a the lets is a the lets is a the lets\" };\n    for (int i = 0; i < texts.length; i++) {\n      Document doc = new Document();\n      Field field = new Field(\"field\", texts[i], type);\n      doc.add(field);\n      writer.addDocument(doc);\n    }\n    CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 2);\n    query.add(new Term(\"field\", \"text\"));\n    query.add(new Term(\"field\", \"long\"));\n    query.add(new Term(\"field\", \"very\"));\n   \n    FastVectorHighlighter highlighter = new FastVectorHighlighter();\n    IndexReader reader = DirectoryReader.open(writer, true);\n    IndexSearcher searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    FieldQuery fieldQuery  = highlighter.getFieldQuery(query, reader);\n    String[] bestFragments = highlighter.getBestFragments(fieldQuery, reader, hits.scoreDocs[0].doc, \"field\", 1000, 1);\n    assertEquals(\"This piece of <b>text</b> refers to Kennedy at the beginning then has a longer piece of <b>text</b> that is <b>very</b> <b>long</b> in the middle and finally ends with another reference to Kennedy\", bestFragments[0]);\n\n    fieldQuery  = highlighter.getFieldQuery(query, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, hits.scoreDocs[1].doc, \"field\", 1000, 1);\n    assertEquals(\"Hello this is a piece of <b>text</b> that is <b>very</b> <b>long</b> and contains too much preamble and the meat is really here which says kennedy has been shot\", bestFragments[0]);\n\n    reader.close();\n    writer.shutdown();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2a1862266772deb28cdcb7d996b64d2177022687","date":1453077824,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testCommonTermsQueryHighlight().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testCommonTermsQueryHighlight().mjava","sourceNew":"  public void testCommonTermsQueryHighlight() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET)));\n    FieldType type = new FieldType(TextField.TYPE_STORED);\n    type.setStoreTermVectorOffsets(true);\n    type.setStoreTermVectorPositions(true);\n    type.setStoreTermVectors(true);\n    type.freeze();\n    String[] texts = {\n        \"Hello this is a piece of text that is very long and contains too much preamble and the meat is really here which says kennedy has been shot\",\n        \"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is very long in the middle and finally ends with another reference to Kennedy\",\n        \"JFK has been shot\", \"John Kennedy has been shot\",\n        \"This text has a typo in referring to Keneddy\",\n        \"wordx wordy wordz wordx wordy wordx worda wordb wordy wordc\", \"y z x y z a b\", \"lets is a the lets is a the lets is a the lets\" };\n    for (int i = 0; i < texts.length; i++) {\n      Document doc = new Document();\n      Field field = new Field(\"field\", texts[i], type);\n      doc.add(field);\n      writer.addDocument(doc);\n    }\n    CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 2);\n    query.add(new Term(\"field\", \"text\"));\n    query.add(new Term(\"field\", \"long\"));\n    query.add(new Term(\"field\", \"very\"));\n   \n    FastVectorHighlighter highlighter = new FastVectorHighlighter();\n    IndexReader reader = DirectoryReader.open(writer);\n    IndexSearcher searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    FieldQuery fieldQuery  = highlighter.getFieldQuery(query, reader);\n    String[] bestFragments = highlighter.getBestFragments(fieldQuery, reader, hits.scoreDocs[0].doc, \"field\", 1000, 1);\n    assertEquals(\"This piece of <b>text</b> refers to Kennedy at the beginning then has a longer piece of <b>text</b> that is <b>very</b> <b>long</b> in the middle and finally ends with another reference to Kennedy\", bestFragments[0]);\n\n    fieldQuery  = highlighter.getFieldQuery(query, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, hits.scoreDocs[1].doc, \"field\", 1000, 1);\n    assertEquals(\"Hello this is a piece of <b>text</b> that is <b>very</b> <b>long</b> and contains too much preamble and the meat is really here which says kennedy has been shot\", bestFragments[0]);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testCommonTermsQueryHighlight() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET)));\n    FieldType type = new FieldType(TextField.TYPE_STORED);\n    type.setStoreTermVectorOffsets(true);\n    type.setStoreTermVectorPositions(true);\n    type.setStoreTermVectors(true);\n    type.freeze();\n    String[] texts = {\n        \"Hello this is a piece of text that is very long and contains too much preamble and the meat is really here which says kennedy has been shot\",\n        \"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is very long in the middle and finally ends with another reference to Kennedy\",\n        \"JFK has been shot\", \"John Kennedy has been shot\",\n        \"This text has a typo in referring to Keneddy\",\n        \"wordx wordy wordz wordx wordy wordx worda wordb wordy wordc\", \"y z x y z a b\", \"lets is a the lets is a the lets is a the lets\" };\n    for (int i = 0; i < texts.length; i++) {\n      Document doc = new Document();\n      Field field = new Field(\"field\", texts[i], type);\n      doc.add(field);\n      writer.addDocument(doc);\n    }\n    CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 2);\n    query.add(new Term(\"field\", \"text\"));\n    query.add(new Term(\"field\", \"long\"));\n    query.add(new Term(\"field\", \"very\"));\n   \n    FastVectorHighlighter highlighter = new FastVectorHighlighter();\n    IndexReader reader = DirectoryReader.open(writer, true);\n    IndexSearcher searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    FieldQuery fieldQuery  = highlighter.getFieldQuery(query, reader);\n    String[] bestFragments = highlighter.getBestFragments(fieldQuery, reader, hits.scoreDocs[0].doc, \"field\", 1000, 1);\n    assertEquals(\"This piece of <b>text</b> refers to Kennedy at the beginning then has a longer piece of <b>text</b> that is <b>very</b> <b>long</b> in the middle and finally ends with another reference to Kennedy\", bestFragments[0]);\n\n    fieldQuery  = highlighter.getFieldQuery(query, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, hits.scoreDocs[1].doc, \"field\", 1000, 1);\n    assertEquals(\"Hello this is a piece of <b>text</b> that is <b>very</b> <b>long</b> and contains too much preamble and the meat is really here which says kennedy has been shot\", bestFragments[0]);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b382270e8a439e411e7a08bff0b008073ad5cefd","date":1478975568,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testCommonTermsQueryHighlight().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testCommonTermsQueryHighlight().mjava","sourceNew":"  public void testCommonTermsQueryHighlight() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET)));\n    FieldType type = new FieldType(TextField.TYPE_STORED);\n    type.setStoreTermVectorOffsets(true);\n    type.setStoreTermVectorPositions(true);\n    type.setStoreTermVectors(true);\n    type.freeze();\n    String[] texts = {\n        \"Hello this is a piece of text that is very long and contains too much preamble and the meat is really here which says kennedy has been shot\",\n        \"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is very long in the middle and finally ends with another reference to Kennedy\",\n        \"JFK has been shot\", \"John Kennedy has been shot\",\n        \"This text has a typo in referring to Keneddy\",\n        \"wordx wordy wordz wordx wordy wordx worda wordb wordy wordc\", \"y z x y z a b\", \"lets is a the lets is a the lets is a the lets\" };\n    for (int i = 0; i < texts.length; i++) {\n      Document doc = new Document();\n      Field field = new Field(\"field\", texts[i], type);\n      doc.add(field);\n      writer.addDocument(doc);\n    }\n    CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 2);\n    query.add(new Term(\"field\", \"text\"));\n    query.add(new Term(\"field\", \"long\"));\n    query.add(new Term(\"field\", \"very\"));\n   \n    FastVectorHighlighter highlighter = new FastVectorHighlighter();\n    IndexReader reader = DirectoryReader.open(writer);\n    IndexSearcher searcher = newSearcher(reader);\n    searcher.setSimilarity(new BM25Similarity());\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    FieldQuery fieldQuery  = highlighter.getFieldQuery(query, reader);\n    String[] bestFragments = highlighter.getBestFragments(fieldQuery, reader, hits.scoreDocs[0].doc, \"field\", 1000, 1);\n    assertEquals(\"This piece of <b>text</b> refers to Kennedy at the beginning then has a longer piece of <b>text</b> that is <b>very</b> <b>long</b> in the middle and finally ends with another reference to Kennedy\", bestFragments[0]);\n\n    fieldQuery  = highlighter.getFieldQuery(query, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, hits.scoreDocs[1].doc, \"field\", 1000, 1);\n    assertEquals(\"Hello this is a piece of <b>text</b> that is <b>very</b> <b>long</b> and contains too much preamble and the meat is really here which says kennedy has been shot\", bestFragments[0]);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testCommonTermsQueryHighlight() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET)));\n    FieldType type = new FieldType(TextField.TYPE_STORED);\n    type.setStoreTermVectorOffsets(true);\n    type.setStoreTermVectorPositions(true);\n    type.setStoreTermVectors(true);\n    type.freeze();\n    String[] texts = {\n        \"Hello this is a piece of text that is very long and contains too much preamble and the meat is really here which says kennedy has been shot\",\n        \"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is very long in the middle and finally ends with another reference to Kennedy\",\n        \"JFK has been shot\", \"John Kennedy has been shot\",\n        \"This text has a typo in referring to Keneddy\",\n        \"wordx wordy wordz wordx wordy wordx worda wordb wordy wordc\", \"y z x y z a b\", \"lets is a the lets is a the lets is a the lets\" };\n    for (int i = 0; i < texts.length; i++) {\n      Document doc = new Document();\n      Field field = new Field(\"field\", texts[i], type);\n      doc.add(field);\n      writer.addDocument(doc);\n    }\n    CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 2);\n    query.add(new Term(\"field\", \"text\"));\n    query.add(new Term(\"field\", \"long\"));\n    query.add(new Term(\"field\", \"very\"));\n   \n    FastVectorHighlighter highlighter = new FastVectorHighlighter();\n    IndexReader reader = DirectoryReader.open(writer);\n    IndexSearcher searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    FieldQuery fieldQuery  = highlighter.getFieldQuery(query, reader);\n    String[] bestFragments = highlighter.getBestFragments(fieldQuery, reader, hits.scoreDocs[0].doc, \"field\", 1000, 1);\n    assertEquals(\"This piece of <b>text</b> refers to Kennedy at the beginning then has a longer piece of <b>text</b> that is <b>very</b> <b>long</b> in the middle and finally ends with another reference to Kennedy\", bestFragments[0]);\n\n    fieldQuery  = highlighter.getFieldQuery(query, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, hits.scoreDocs[1].doc, \"field\", 1000, 1);\n    assertEquals(\"Hello this is a piece of <b>text</b> that is <b>very</b> <b>long</b> and contains too much preamble and the meat is really here which says kennedy has been shot\", bestFragments[0]);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba79d1112f6fde2f07278366feefdfeacc3b7097","date":1479075127,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testCommonTermsQueryHighlight().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testCommonTermsQueryHighlight().mjava","sourceNew":"  public void testCommonTermsQueryHighlight() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET)));\n    FieldType type = new FieldType(TextField.TYPE_STORED);\n    type.setStoreTermVectorOffsets(true);\n    type.setStoreTermVectorPositions(true);\n    type.setStoreTermVectors(true);\n    type.freeze();\n    String[] texts = {\n        \"Hello this is a piece of text that is very long and contains too much preamble and the meat is really here which says kennedy has been shot\",\n        \"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is very long in the middle and finally ends with another reference to Kennedy\",\n        \"JFK has been shot\", \"John Kennedy has been shot\",\n        \"This text has a typo in referring to Keneddy\",\n        \"wordx wordy wordz wordx wordy wordx worda wordb wordy wordc\", \"y z x y z a b\", \"lets is a the lets is a the lets is a the lets\" };\n    for (int i = 0; i < texts.length; i++) {\n      Document doc = new Document();\n      Field field = new Field(\"field\", texts[i], type);\n      doc.add(field);\n      writer.addDocument(doc);\n    }\n    CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 2);\n    query.add(new Term(\"field\", \"text\"));\n    query.add(new Term(\"field\", \"long\"));\n    query.add(new Term(\"field\", \"very\"));\n   \n    FastVectorHighlighter highlighter = new FastVectorHighlighter();\n    IndexReader reader = DirectoryReader.open(writer);\n    IndexSearcher searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    FieldQuery fieldQuery  = highlighter.getFieldQuery(query, reader);\n    String[] bestFragments = highlighter.getBestFragments(fieldQuery, reader, hits.scoreDocs[0].doc, \"field\", 1000, 1);\n    assertEquals(\"This piece of <b>text</b> refers to Kennedy at the beginning then has a longer piece of <b>text</b> that is <b>very</b> <b>long</b> in the middle and finally ends with another reference to Kennedy\", bestFragments[0]);\n\n    fieldQuery  = highlighter.getFieldQuery(query, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, hits.scoreDocs[1].doc, \"field\", 1000, 1);\n    assertEquals(\"Hello this is a piece of <b>text</b> that is <b>very</b> <b>long</b> and contains too much preamble and the meat is really here which says kennedy has been shot\", bestFragments[0]);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testCommonTermsQueryHighlight() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET)));\n    FieldType type = new FieldType(TextField.TYPE_STORED);\n    type.setStoreTermVectorOffsets(true);\n    type.setStoreTermVectorPositions(true);\n    type.setStoreTermVectors(true);\n    type.freeze();\n    String[] texts = {\n        \"Hello this is a piece of text that is very long and contains too much preamble and the meat is really here which says kennedy has been shot\",\n        \"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is very long in the middle and finally ends with another reference to Kennedy\",\n        \"JFK has been shot\", \"John Kennedy has been shot\",\n        \"This text has a typo in referring to Keneddy\",\n        \"wordx wordy wordz wordx wordy wordx worda wordb wordy wordc\", \"y z x y z a b\", \"lets is a the lets is a the lets is a the lets\" };\n    for (int i = 0; i < texts.length; i++) {\n      Document doc = new Document();\n      Field field = new Field(\"field\", texts[i], type);\n      doc.add(field);\n      writer.addDocument(doc);\n    }\n    CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 2);\n    query.add(new Term(\"field\", \"text\"));\n    query.add(new Term(\"field\", \"long\"));\n    query.add(new Term(\"field\", \"very\"));\n   \n    FastVectorHighlighter highlighter = new FastVectorHighlighter();\n    IndexReader reader = DirectoryReader.open(writer);\n    IndexSearcher searcher = newSearcher(reader);\n    searcher.setSimilarity(new BM25Similarity());\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    FieldQuery fieldQuery  = highlighter.getFieldQuery(query, reader);\n    String[] bestFragments = highlighter.getBestFragments(fieldQuery, reader, hits.scoreDocs[0].doc, \"field\", 1000, 1);\n    assertEquals(\"This piece of <b>text</b> refers to Kennedy at the beginning then has a longer piece of <b>text</b> that is <b>very</b> <b>long</b> in the middle and finally ends with another reference to Kennedy\", bestFragments[0]);\n\n    fieldQuery  = highlighter.getFieldQuery(query, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, hits.scoreDocs[1].doc, \"field\", 1000, 1);\n    assertEquals(\"Hello this is a piece of <b>text</b> that is <b>very</b> <b>long</b> and contains too much preamble and the meat is really here which says kennedy has been shot\", bestFragments[0]);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f25db587f13320e9cdb74b71d585968ae7a0547","date":1514645175,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testCommonTermsQueryHighlight().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testCommonTermsQueryHighlight().mjava","sourceNew":"  public void testCommonTermsQueryHighlight() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET))\n        .setMergePolicy(newLogMergePolicy())); // don't reorder doc ids\n    FieldType type = new FieldType(TextField.TYPE_STORED);\n    type.setStoreTermVectorOffsets(true);\n    type.setStoreTermVectorPositions(true);\n    type.setStoreTermVectors(true);\n    type.freeze();\n    String[] texts = {\n        \"Hello this is a piece of text that is very long and contains too much preamble and the meat is really here which says kennedy has been shot\",\n        \"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is very long in the middle and finally ends with another reference to Kennedy\",\n        \"JFK has been shot\", \"John Kennedy has been shot\",\n        \"This text has a typo in referring to Keneddy\",\n        \"wordx wordy wordz wordx wordy wordx worda wordb wordy wordc\", \"y z x y z a b\", \"lets is a the lets is a the lets is a the lets\" };\n    for (int i = 0; i < texts.length; i++) {\n      Document doc = new Document();\n      Field field = new Field(\"field\", texts[i], type);\n      doc.add(field);\n      writer.addDocument(doc);\n    }\n    CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 2);\n    query.add(new Term(\"field\", \"text\"));\n    query.add(new Term(\"field\", \"long\"));\n    query.add(new Term(\"field\", \"very\"));\n   \n    FastVectorHighlighter highlighter = new FastVectorHighlighter();\n    IndexReader reader = DirectoryReader.open(writer);\n    IndexSearcher searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    FieldQuery fieldQuery  = highlighter.getFieldQuery(query, reader);\n    String[] bestFragments = highlighter.getBestFragments(fieldQuery, reader, 1, \"field\", 1000, 1);\n    assertEquals(\"This piece of <b>text</b> refers to Kennedy at the beginning then has a longer piece of <b>text</b> that is <b>very</b> <b>long</b> in the middle and finally ends with another reference to Kennedy\", bestFragments[0]);\n\n    fieldQuery  = highlighter.getFieldQuery(query, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, 0, \"field\", 1000, 1);\n    assertEquals(\"Hello this is a piece of <b>text</b> that is <b>very</b> <b>long</b> and contains too much preamble and the meat is really here which says kennedy has been shot\", bestFragments[0]);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testCommonTermsQueryHighlight() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET)));\n    FieldType type = new FieldType(TextField.TYPE_STORED);\n    type.setStoreTermVectorOffsets(true);\n    type.setStoreTermVectorPositions(true);\n    type.setStoreTermVectors(true);\n    type.freeze();\n    String[] texts = {\n        \"Hello this is a piece of text that is very long and contains too much preamble and the meat is really here which says kennedy has been shot\",\n        \"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is very long in the middle and finally ends with another reference to Kennedy\",\n        \"JFK has been shot\", \"John Kennedy has been shot\",\n        \"This text has a typo in referring to Keneddy\",\n        \"wordx wordy wordz wordx wordy wordx worda wordb wordy wordc\", \"y z x y z a b\", \"lets is a the lets is a the lets is a the lets\" };\n    for (int i = 0; i < texts.length; i++) {\n      Document doc = new Document();\n      Field field = new Field(\"field\", texts[i], type);\n      doc.add(field);\n      writer.addDocument(doc);\n    }\n    CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 2);\n    query.add(new Term(\"field\", \"text\"));\n    query.add(new Term(\"field\", \"long\"));\n    query.add(new Term(\"field\", \"very\"));\n   \n    FastVectorHighlighter highlighter = new FastVectorHighlighter();\n    IndexReader reader = DirectoryReader.open(writer);\n    IndexSearcher searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    FieldQuery fieldQuery  = highlighter.getFieldQuery(query, reader);\n    String[] bestFragments = highlighter.getBestFragments(fieldQuery, reader, hits.scoreDocs[0].doc, \"field\", 1000, 1);\n    assertEquals(\"This piece of <b>text</b> refers to Kennedy at the beginning then has a longer piece of <b>text</b> that is <b>very</b> <b>long</b> in the middle and finally ends with another reference to Kennedy\", bestFragments[0]);\n\n    fieldQuery  = highlighter.getFieldQuery(query, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, hits.scoreDocs[1].doc, \"field\", 1000, 1);\n    assertEquals(\"Hello this is a piece of <b>text</b> that is <b>very</b> <b>long</b> and contains too much preamble and the meat is really here which says kennedy has been shot\", bestFragments[0]);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"83788ad129a5154d5c6562c4e8ce3db48793aada","date":1532961485,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testCommonTermsQueryHighlight().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testCommonTermsQueryHighlight().mjava","sourceNew":"  public void testCommonTermsQueryHighlight() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET))\n        .setMergePolicy(newLogMergePolicy())); // don't reorder doc ids\n    FieldType type = new FieldType(TextField.TYPE_STORED);\n    type.setStoreTermVectorOffsets(true);\n    type.setStoreTermVectorPositions(true);\n    type.setStoreTermVectors(true);\n    type.freeze();\n    String[] texts = {\n        \"Hello this is a piece of text that is very long and contains too much preamble and the meat is really here which says kennedy has been shot\",\n        \"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is very long in the middle and finally ends with another reference to Kennedy\",\n        \"JFK has been shot\", \"John Kennedy has been shot\",\n        \"This text has a typo in referring to Keneddy\",\n        \"wordx wordy wordz wordx wordy wordx worda wordb wordy wordc\", \"y z x y z a b\", \"lets is a the lets is a the lets is a the lets\" };\n    for (int i = 0; i < texts.length; i++) {\n      Document doc = new Document();\n      Field field = new Field(\"field\", texts[i], type);\n      doc.add(field);\n      writer.addDocument(doc);\n    }\n    CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 2);\n    query.add(new Term(\"field\", \"text\"));\n    query.add(new Term(\"field\", \"long\"));\n    query.add(new Term(\"field\", \"very\"));\n   \n    FastVectorHighlighter highlighter = new FastVectorHighlighter();\n    IndexReader reader = DirectoryReader.open(writer);\n    IndexSearcher searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits.value);\n    FieldQuery fieldQuery  = highlighter.getFieldQuery(query, reader);\n    String[] bestFragments = highlighter.getBestFragments(fieldQuery, reader, 1, \"field\", 1000, 1);\n    assertEquals(\"This piece of <b>text</b> refers to Kennedy at the beginning then has a longer piece of <b>text</b> that is <b>very</b> <b>long</b> in the middle and finally ends with another reference to Kennedy\", bestFragments[0]);\n\n    fieldQuery  = highlighter.getFieldQuery(query, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, 0, \"field\", 1000, 1);\n    assertEquals(\"Hello this is a piece of <b>text</b> that is <b>very</b> <b>long</b> and contains too much preamble and the meat is really here which says kennedy has been shot\", bestFragments[0]);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testCommonTermsQueryHighlight() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir,\n        newIndexWriterConfig(new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET))\n        .setMergePolicy(newLogMergePolicy())); // don't reorder doc ids\n    FieldType type = new FieldType(TextField.TYPE_STORED);\n    type.setStoreTermVectorOffsets(true);\n    type.setStoreTermVectorPositions(true);\n    type.setStoreTermVectors(true);\n    type.freeze();\n    String[] texts = {\n        \"Hello this is a piece of text that is very long and contains too much preamble and the meat is really here which says kennedy has been shot\",\n        \"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is very long in the middle and finally ends with another reference to Kennedy\",\n        \"JFK has been shot\", \"John Kennedy has been shot\",\n        \"This text has a typo in referring to Keneddy\",\n        \"wordx wordy wordz wordx wordy wordx worda wordb wordy wordc\", \"y z x y z a b\", \"lets is a the lets is a the lets is a the lets\" };\n    for (int i = 0; i < texts.length; i++) {\n      Document doc = new Document();\n      Field field = new Field(\"field\", texts[i], type);\n      doc.add(field);\n      writer.addDocument(doc);\n    }\n    CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 2);\n    query.add(new Term(\"field\", \"text\"));\n    query.add(new Term(\"field\", \"long\"));\n    query.add(new Term(\"field\", \"very\"));\n   \n    FastVectorHighlighter highlighter = new FastVectorHighlighter();\n    IndexReader reader = DirectoryReader.open(writer);\n    IndexSearcher searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    FieldQuery fieldQuery  = highlighter.getFieldQuery(query, reader);\n    String[] bestFragments = highlighter.getBestFragments(fieldQuery, reader, 1, \"field\", 1000, 1);\n    assertEquals(\"This piece of <b>text</b> refers to Kennedy at the beginning then has a longer piece of <b>text</b> that is <b>very</b> <b>long</b> in the middle and finally ends with another reference to Kennedy\", bestFragments[0]);\n\n    fieldQuery  = highlighter.getFieldQuery(query, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, 0, \"field\", 1000, 1);\n    assertEquals(\"Hello this is a piece of <b>text</b> that is <b>very</b> <b>long</b> and contains too much preamble and the meat is really here which says kennedy has been shot\", bestFragments[0]);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"2a1862266772deb28cdcb7d996b64d2177022687":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"ba79d1112f6fde2f07278366feefdfeacc3b7097":["b382270e8a439e411e7a08bff0b008073ad5cefd"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"1f25db587f13320e9cdb74b71d585968ae7a0547":["2a1862266772deb28cdcb7d996b64d2177022687"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["94221e4190ec47a1ec4f0bd8f99b3648af295a06"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["1f25db587f13320e9cdb74b71d585968ae7a0547"],"94221e4190ec47a1ec4f0bd8f99b3648af295a06":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["83788ad129a5154d5c6562c4e8ce3db48793aada"],"b382270e8a439e411e7a08bff0b008073ad5cefd":["2a1862266772deb28cdcb7d996b64d2177022687"]},"commit2Childs":{"2a1862266772deb28cdcb7d996b64d2177022687":["1f25db587f13320e9cdb74b71d585968ae7a0547","b382270e8a439e411e7a08bff0b008073ad5cefd"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"ba79d1112f6fde2f07278366feefdfeacc3b7097":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["94221e4190ec47a1ec4f0bd8f99b3648af295a06"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["2a1862266772deb28cdcb7d996b64d2177022687"],"1f25db587f13320e9cdb74b71d585968ae7a0547":["83788ad129a5154d5c6562c4e8ce3db48793aada"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"94221e4190ec47a1ec4f0bd8f99b3648af295a06":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"b382270e8a439e411e7a08bff0b008073ad5cefd":["ba79d1112f6fde2f07278366feefdfeacc3b7097"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ba79d1112f6fde2f07278366feefdfeacc3b7097","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}