{"path":"lucene/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testBackgroundForceMerge().mjava","commits":[{"id":"d14e8d18c0e3970c20354dbeeb49da11bd587fbd","date":1321041051,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testBackgroundForceMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOptimize#testBackgroundOptimize().mjava","sourceNew":"  // Test calling forceMerge(1, false) whereby forceMerge is kicked\n  // off but we don't wait for it to finish (but\n  // writer.close()) does wait\n  public void testBackgroundForceMerge() throws IOException {\n\n    Directory dir = newDirectory();\n    for(int pass=0;pass<2;pass++) {\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setOpenMode(OpenMode.CREATE).\n              setMaxBufferedDocs(2).\n              setMergePolicy(newLogMergePolicy(51))\n      );\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", StringField.TYPE_UNSTORED));\n      for(int i=0;i<100;i++)\n        writer.addDocument(doc);\n      writer.forceMerge(1, false);\n\n      if (0 == pass) {\n        writer.close();\n        IndexReader reader = IndexReader.open(dir, true);\n        assertEquals(1, reader.getSequentialSubReaders().length);\n        reader.close();\n      } else {\n        // Get another segment to flush so we can verify it is\n        // NOT included in the merging\n        writer.addDocument(doc);\n        writer.addDocument(doc);\n        writer.close();\n\n        IndexReader reader = IndexReader.open(dir, true);\n        assertTrue(reader.getSequentialSubReaders().length > 1);\n        reader.close();\n\n        SegmentInfos infos = new SegmentInfos();\n        infos.read(dir);\n        assertEquals(2, infos.size());\n      }\n    }\n\n    dir.close();\n  }\n\n","sourceOld":"  // Test calling optimize(false) whereby optimize is kicked\n  // off but we don't wait for it to finish (but\n  // writer.close()) does wait\n  public void testBackgroundOptimize() throws IOException {\n\n    Directory dir = newDirectory();\n    for(int pass=0;pass<2;pass++) {\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setOpenMode(OpenMode.CREATE).\n              setMaxBufferedDocs(2).\n              setMergePolicy(newLogMergePolicy(51))\n      );\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", StringField.TYPE_UNSTORED));\n      for(int i=0;i<100;i++)\n        writer.addDocument(doc);\n      writer.optimize(false);\n\n      if (0 == pass) {\n        writer.close();\n        IndexReader reader = IndexReader.open(dir, true);\n        assertTrue(reader.isOptimized());\n        reader.close();\n      } else {\n        // Get another segment to flush so we can verify it is\n        // NOT included in the optimization\n        writer.addDocument(doc);\n        writer.addDocument(doc);\n        writer.close();\n\n        IndexReader reader = IndexReader.open(dir, true);\n        assertTrue(!reader.isOptimized());\n        reader.close();\n\n        SegmentInfos infos = new SegmentInfos();\n        infos.read(dir);\n        assertEquals(2, infos.size());\n      }\n    }\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1c5b026d03cbbb03ca4c0b97d14e9839682281dc","date":1323049298,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testBackgroundForceMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testBackgroundForceMerge().mjava","sourceNew":"  // Test calling forceMerge(1, false) whereby forceMerge is kicked\n  // off but we don't wait for it to finish (but\n  // writer.close()) does wait\n  public void testBackgroundForceMerge() throws IOException {\n\n    Directory dir = newDirectory();\n    for(int pass=0;pass<2;pass++) {\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setOpenMode(OpenMode.CREATE).\n              setMaxBufferedDocs(2).\n              setMergePolicy(newLogMergePolicy(51))\n      );\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", StringField.TYPE_UNSTORED));\n      for(int i=0;i<100;i++)\n        writer.addDocument(doc);\n      writer.forceMerge(1, false);\n\n      if (0 == pass) {\n        writer.close();\n        IndexReader reader = IndexReader.open(dir);\n        assertEquals(1, reader.getSequentialSubReaders().length);\n        reader.close();\n      } else {\n        // Get another segment to flush so we can verify it is\n        // NOT included in the merging\n        writer.addDocument(doc);\n        writer.addDocument(doc);\n        writer.close();\n\n        IndexReader reader = IndexReader.open(dir);\n        assertTrue(reader.getSequentialSubReaders().length > 1);\n        reader.close();\n\n        SegmentInfos infos = new SegmentInfos();\n        infos.read(dir);\n        assertEquals(2, infos.size());\n      }\n    }\n\n    dir.close();\n  }\n\n","sourceOld":"  // Test calling forceMerge(1, false) whereby forceMerge is kicked\n  // off but we don't wait for it to finish (but\n  // writer.close()) does wait\n  public void testBackgroundForceMerge() throws IOException {\n\n    Directory dir = newDirectory();\n    for(int pass=0;pass<2;pass++) {\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setOpenMode(OpenMode.CREATE).\n              setMaxBufferedDocs(2).\n              setMergePolicy(newLogMergePolicy(51))\n      );\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", StringField.TYPE_UNSTORED));\n      for(int i=0;i<100;i++)\n        writer.addDocument(doc);\n      writer.forceMerge(1, false);\n\n      if (0 == pass) {\n        writer.close();\n        IndexReader reader = IndexReader.open(dir, true);\n        assertEquals(1, reader.getSequentialSubReaders().length);\n        reader.close();\n      } else {\n        // Get another segment to flush so we can verify it is\n        // NOT included in the merging\n        writer.addDocument(doc);\n        writer.addDocument(doc);\n        writer.close();\n\n        IndexReader reader = IndexReader.open(dir, true);\n        assertTrue(reader.getSequentialSubReaders().length > 1);\n        reader.close();\n\n        SegmentInfos infos = new SegmentInfos();\n        infos.read(dir);\n        assertEquals(2, infos.size());\n      }\n    }\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3615ce4a1f785ae1b779244de52c6a7d99227e60","date":1323422019,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testBackgroundForceMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testBackgroundForceMerge().mjava","sourceNew":"  // Test calling forceMerge(1, false) whereby forceMerge is kicked\n  // off but we don't wait for it to finish (but\n  // writer.close()) does wait\n  public void testBackgroundForceMerge() throws IOException {\n\n    Directory dir = newDirectory();\n    for(int pass=0;pass<2;pass++) {\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setOpenMode(OpenMode.CREATE).\n              setMaxBufferedDocs(2).\n              setMergePolicy(newLogMergePolicy(51))\n      );\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", StringField.TYPE_UNSTORED));\n      for(int i=0;i<100;i++)\n        writer.addDocument(doc);\n      writer.forceMerge(1, false);\n\n      if (0 == pass) {\n        writer.close();\n        IndexReader reader = IndexReader.open(dir);\n        assertEquals(1, reader.getSequentialSubReaders().length);\n        reader.close();\n      } else {\n        // Get another segment to flush so we can verify it is\n        // NOT included in the merging\n        writer.addDocument(doc);\n        writer.addDocument(doc);\n        writer.close();\n\n        IndexReader reader = IndexReader.open(dir);\n        assertTrue(reader.getSequentialSubReaders().length > 1);\n        reader.close();\n\n        SegmentInfos infos = new SegmentInfos();\n        infos.read(dir);\n        assertEquals(2, infos.size());\n      }\n    }\n\n    dir.close();\n  }\n\n","sourceOld":"  // Test calling forceMerge(1, false) whereby forceMerge is kicked\n  // off but we don't wait for it to finish (but\n  // writer.close()) does wait\n  public void testBackgroundForceMerge() throws IOException {\n\n    Directory dir = newDirectory();\n    for(int pass=0;pass<2;pass++) {\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setOpenMode(OpenMode.CREATE).\n              setMaxBufferedDocs(2).\n              setMergePolicy(newLogMergePolicy(51))\n      );\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", StringField.TYPE_UNSTORED));\n      for(int i=0;i<100;i++)\n        writer.addDocument(doc);\n      writer.forceMerge(1, false);\n\n      if (0 == pass) {\n        writer.close();\n        IndexReader reader = IndexReader.open(dir, true);\n        assertEquals(1, reader.getSequentialSubReaders().length);\n        reader.close();\n      } else {\n        // Get another segment to flush so we can verify it is\n        // NOT included in the merging\n        writer.addDocument(doc);\n        writer.addDocument(doc);\n        writer.close();\n\n        IndexReader reader = IndexReader.open(dir, true);\n        assertTrue(reader.getSequentialSubReaders().length > 1);\n        reader.close();\n\n        SegmentInfos infos = new SegmentInfos();\n        infos.read(dir);\n        assertEquals(2, infos.size());\n      }\n    }\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","date":1323437438,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testBackgroundForceMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testBackgroundForceMerge().mjava","sourceNew":"  // Test calling forceMerge(1, false) whereby forceMerge is kicked\n  // off but we don't wait for it to finish (but\n  // writer.close()) does wait\n  public void testBackgroundForceMerge() throws IOException {\n\n    Directory dir = newDirectory();\n    for(int pass=0;pass<2;pass++) {\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setOpenMode(OpenMode.CREATE).\n              setMaxBufferedDocs(2).\n              setMergePolicy(newLogMergePolicy(51))\n      );\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", StringField.TYPE_UNSTORED));\n      for(int i=0;i<100;i++)\n        writer.addDocument(doc);\n      writer.forceMerge(1, false);\n\n      if (0 == pass) {\n        writer.close();\n        IndexReader reader = IndexReader.open(dir);\n        assertEquals(1, reader.getSequentialSubReaders().length);\n        reader.close();\n      } else {\n        // Get another segment to flush so we can verify it is\n        // NOT included in the merging\n        writer.addDocument(doc);\n        writer.addDocument(doc);\n        writer.close();\n\n        IndexReader reader = IndexReader.open(dir);\n        assertTrue(reader.getSequentialSubReaders().length > 1);\n        reader.close();\n\n        SegmentInfos infos = new SegmentInfos();\n        infos.read(dir);\n        assertEquals(2, infos.size());\n      }\n    }\n\n    dir.close();\n  }\n\n","sourceOld":"  // Test calling forceMerge(1, false) whereby forceMerge is kicked\n  // off but we don't wait for it to finish (but\n  // writer.close()) does wait\n  public void testBackgroundForceMerge() throws IOException {\n\n    Directory dir = newDirectory();\n    for(int pass=0;pass<2;pass++) {\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setOpenMode(OpenMode.CREATE).\n              setMaxBufferedDocs(2).\n              setMergePolicy(newLogMergePolicy(51))\n      );\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", StringField.TYPE_UNSTORED));\n      for(int i=0;i<100;i++)\n        writer.addDocument(doc);\n      writer.forceMerge(1, false);\n\n      if (0 == pass) {\n        writer.close();\n        IndexReader reader = IndexReader.open(dir, true);\n        assertEquals(1, reader.getSequentialSubReaders().length);\n        reader.close();\n      } else {\n        // Get another segment to flush so we can verify it is\n        // NOT included in the merging\n        writer.addDocument(doc);\n        writer.addDocument(doc);\n        writer.close();\n\n        IndexReader reader = IndexReader.open(dir, true);\n        assertTrue(reader.getSequentialSubReaders().length > 1);\n        reader.close();\n\n        SegmentInfos infos = new SegmentInfos();\n        infos.read(dir);\n        assertEquals(2, infos.size());\n      }\n    }\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a81e1267c45ab68de86e86ac4b4c99e6e628ceb","date":1327857831,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testBackgroundForceMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testBackgroundForceMerge().mjava","sourceNew":"  // Test calling forceMerge(1, false) whereby forceMerge is kicked\n  // off but we don't wait for it to finish (but\n  // writer.close()) does wait\n  public void testBackgroundForceMerge() throws IOException {\n\n    Directory dir = newDirectory();\n    for(int pass=0;pass<2;pass++) {\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setOpenMode(OpenMode.CREATE).\n              setMaxBufferedDocs(2).\n              setMergePolicy(newLogMergePolicy(51))\n      );\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", StringField.TYPE_UNSTORED));\n      for(int i=0;i<100;i++)\n        writer.addDocument(doc);\n      writer.forceMerge(1, false);\n\n      if (0 == pass) {\n        writer.close();\n        DirectoryReader reader = IndexReader.open(dir);\n        assertEquals(1, reader.getSequentialSubReaders().length);\n        reader.close();\n      } else {\n        // Get another segment to flush so we can verify it is\n        // NOT included in the merging\n        writer.addDocument(doc);\n        writer.addDocument(doc);\n        writer.close();\n\n        DirectoryReader reader = IndexReader.open(dir);\n        assertTrue(reader.getSequentialSubReaders().length > 1);\n        reader.close();\n\n        SegmentInfos infos = new SegmentInfos();\n        infos.read(dir);\n        assertEquals(2, infos.size());\n      }\n    }\n\n    dir.close();\n  }\n\n","sourceOld":"  // Test calling forceMerge(1, false) whereby forceMerge is kicked\n  // off but we don't wait for it to finish (but\n  // writer.close()) does wait\n  public void testBackgroundForceMerge() throws IOException {\n\n    Directory dir = newDirectory();\n    for(int pass=0;pass<2;pass++) {\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setOpenMode(OpenMode.CREATE).\n              setMaxBufferedDocs(2).\n              setMergePolicy(newLogMergePolicy(51))\n      );\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", StringField.TYPE_UNSTORED));\n      for(int i=0;i<100;i++)\n        writer.addDocument(doc);\n      writer.forceMerge(1, false);\n\n      if (0 == pass) {\n        writer.close();\n        IndexReader reader = IndexReader.open(dir);\n        assertEquals(1, reader.getSequentialSubReaders().length);\n        reader.close();\n      } else {\n        // Get another segment to flush so we can verify it is\n        // NOT included in the merging\n        writer.addDocument(doc);\n        writer.addDocument(doc);\n        writer.close();\n\n        IndexReader reader = IndexReader.open(dir);\n        assertTrue(reader.getSequentialSubReaders().length > 1);\n        reader.close();\n\n        SegmentInfos infos = new SegmentInfos();\n        infos.read(dir);\n        assertEquals(2, infos.size());\n      }\n    }\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5cab9a86bd67202d20b6adc463008c8e982b070a","date":1327966443,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testBackgroundForceMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testBackgroundForceMerge().mjava","sourceNew":"  // Test calling forceMerge(1, false) whereby forceMerge is kicked\n  // off but we don't wait for it to finish (but\n  // writer.close()) does wait\n  public void testBackgroundForceMerge() throws IOException {\n\n    Directory dir = newDirectory();\n    for(int pass=0;pass<2;pass++) {\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setOpenMode(OpenMode.CREATE).\n              setMaxBufferedDocs(2).\n              setMergePolicy(newLogMergePolicy(51))\n      );\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", StringField.TYPE_UNSTORED));\n      for(int i=0;i<100;i++)\n        writer.addDocument(doc);\n      writer.forceMerge(1, false);\n\n      if (0 == pass) {\n        writer.close();\n        DirectoryReader reader = IndexReader.open(dir);\n        assertEquals(1, reader.getSequentialSubReaders().length);\n        reader.close();\n      } else {\n        // Get another segment to flush so we can verify it is\n        // NOT included in the merging\n        writer.addDocument(doc);\n        writer.addDocument(doc);\n        writer.close();\n\n        DirectoryReader reader = IndexReader.open(dir);\n        assertTrue(reader.getSequentialSubReaders().length > 1);\n        reader.close();\n\n        SegmentInfos infos = new SegmentInfos();\n        infos.read(dir);\n        assertEquals(2, infos.size());\n      }\n    }\n\n    dir.close();\n  }\n\n","sourceOld":"  // Test calling forceMerge(1, false) whereby forceMerge is kicked\n  // off but we don't wait for it to finish (but\n  // writer.close()) does wait\n  public void testBackgroundForceMerge() throws IOException {\n\n    Directory dir = newDirectory();\n    for(int pass=0;pass<2;pass++) {\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setOpenMode(OpenMode.CREATE).\n              setMaxBufferedDocs(2).\n              setMergePolicy(newLogMergePolicy(51))\n      );\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", StringField.TYPE_UNSTORED));\n      for(int i=0;i<100;i++)\n        writer.addDocument(doc);\n      writer.forceMerge(1, false);\n\n      if (0 == pass) {\n        writer.close();\n        IndexReader reader = IndexReader.open(dir);\n        assertEquals(1, reader.getSequentialSubReaders().length);\n        reader.close();\n      } else {\n        // Get another segment to flush so we can verify it is\n        // NOT included in the merging\n        writer.addDocument(doc);\n        writer.addDocument(doc);\n        writer.close();\n\n        IndexReader reader = IndexReader.open(dir);\n        assertTrue(reader.getSequentialSubReaders().length > 1);\n        reader.close();\n\n        SegmentInfos infos = new SegmentInfos();\n        infos.read(dir);\n        assertEquals(2, infos.size());\n      }\n    }\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testBackgroundForceMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testBackgroundForceMerge().mjava","sourceNew":"  // Test calling forceMerge(1, false) whereby forceMerge is kicked\n  // off but we don't wait for it to finish (but\n  // writer.close()) does wait\n  public void testBackgroundForceMerge() throws IOException {\n\n    Directory dir = newDirectory();\n    for(int pass=0;pass<2;pass++) {\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setOpenMode(OpenMode.CREATE).\n              setMaxBufferedDocs(2).\n              setMergePolicy(newLogMergePolicy(51))\n      );\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", StringField.TYPE_UNSTORED));\n      for(int i=0;i<100;i++)\n        writer.addDocument(doc);\n      writer.forceMerge(1, false);\n\n      if (0 == pass) {\n        writer.close();\n        DirectoryReader reader = IndexReader.open(dir);\n        assertEquals(1, reader.getSequentialSubReaders().length);\n        reader.close();\n      } else {\n        // Get another segment to flush so we can verify it is\n        // NOT included in the merging\n        writer.addDocument(doc);\n        writer.addDocument(doc);\n        writer.close();\n\n        DirectoryReader reader = IndexReader.open(dir);\n        assertTrue(reader.getSequentialSubReaders().length > 1);\n        reader.close();\n\n        SegmentInfos infos = new SegmentInfos();\n        infos.read(dir);\n        assertEquals(2, infos.size());\n      }\n    }\n\n    dir.close();\n  }\n\n","sourceOld":"  // Test calling forceMerge(1, false) whereby forceMerge is kicked\n  // off but we don't wait for it to finish (but\n  // writer.close()) does wait\n  public void testBackgroundForceMerge() throws IOException {\n\n    Directory dir = newDirectory();\n    for(int pass=0;pass<2;pass++) {\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setOpenMode(OpenMode.CREATE).\n              setMaxBufferedDocs(2).\n              setMergePolicy(newLogMergePolicy(51))\n      );\n      Document doc = new Document();\n      doc.add(newField(\"field\", \"aaa\", StringField.TYPE_UNSTORED));\n      for(int i=0;i<100;i++)\n        writer.addDocument(doc);\n      writer.forceMerge(1, false);\n\n      if (0 == pass) {\n        writer.close();\n        DirectoryReader reader = IndexReader.open(dir);\n        assertEquals(1, reader.getSequentialSubReaders().length);\n        reader.close();\n      } else {\n        // Get another segment to flush so we can verify it is\n        // NOT included in the merging\n        writer.addDocument(doc);\n        writer.addDocument(doc);\n        writer.close();\n\n        DirectoryReader reader = IndexReader.open(dir);\n        assertTrue(reader.getSequentialSubReaders().length > 1);\n        reader.close();\n\n        SegmentInfos infos = new SegmentInfos();\n        infos.read(dir);\n        assertEquals(2, infos.size());\n      }\n    }\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd","1c5b026d03cbbb03ca4c0b97d14e9839682281dc"],"1c5b026d03cbbb03ca4c0b97d14e9839682281dc":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3a81e1267c45ab68de86e86ac4b4c99e6e628ceb":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["3615ce4a1f785ae1b779244de52c6a7d99227e60","3a81e1267c45ab68de86e86ac4b4c99e6e628ceb"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","3a81e1267c45ab68de86e86ac4b4c99e6e628ceb","5cab9a86bd67202d20b6adc463008c8e982b070a"],"1c5b026d03cbbb03ca4c0b97d14e9839682281dc":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","3615ce4a1f785ae1b779244de52c6a7d99227e60","1c5b026d03cbbb03ca4c0b97d14e9839682281dc"],"3a81e1267c45ab68de86e86ac4b4c99e6e628ceb":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}