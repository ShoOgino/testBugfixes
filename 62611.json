{"path":"lucene/highlighter/src/java/org/apache/lucene/search/postingshighlight/PostingsHighlighter#highlightFields(String[],Query,IndexSearcher,TopDocs,int).mjava","commits":[{"id":"4b3d16cba9355e2e97962eb1c441bbd0b6735c15","date":1357426290,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/postingshighlight/PostingsHighlighter#highlightFields(String[],Query,IndexSearcher,TopDocs,int).mjava","pathOld":"lucene/sandbox/src/java/org/apache/lucene/sandbox/postingshighlight/PostingsHighlighter#highlightFields(String[],Query,IndexSearcher,TopDocs,int).mjava","sourceNew":"  /**\n   * Highlights the top-N passages from multiple fields.\n   * <p>\n   * Conceptually, this behaves as a more efficient form of:\n   * <pre class=\"prettyprint\">\n   * Map m = new HashMap();\n   * for (String field : fields) {\n   *   m.put(field, highlight(field, query, searcher, topDocs, maxPassages));\n   * }\n   * return m;\n   * </pre>\n   * \n   * @param fields field names to highlight. \n   *        Must have a stored string value and also be indexed with offsets.\n   * @param query query to highlight.\n   * @param searcher searcher that was previously used to execute the query.\n   * @param topDocs TopDocs containing the summary result documents to highlight.\n   * @param maxPassages The maximum number of top-N ranked passages per-field used to \n   *        form the highlighted snippets.\n   * @return Map keyed on field name, containing the array of formatted snippets \n   *         corresponding to the documents in <code>topDocs</code>. \n   *         If no highlights were found for a document, its value is <code>null</code>.\n   * @throws IOException if an I/O error occurred during processing\n   * @throws IllegalArgumentException if <code>field</code> was indexed without \n   *         {@link IndexOptions#DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS}\n   */\n  public Map<String,String[]> highlightFields(String fields[], Query query, IndexSearcher searcher, TopDocs topDocs, int maxPassages) throws IOException {\n    final IndexReader reader = searcher.getIndexReader();\n    final ScoreDoc scoreDocs[] = topDocs.scoreDocs;\n    query = rewrite(query);\n    SortedSet<Term> queryTerms = new TreeSet<Term>();\n    query.extractTerms(queryTerms);\n\n    int docids[] = new int[scoreDocs.length];\n    for (int i = 0; i < docids.length; i++) {\n      docids[i] = scoreDocs[i].doc;\n    }\n    IndexReaderContext readerContext = reader.getContext();\n    List<AtomicReaderContext> leaves = readerContext.leaves();\n\n    BreakIterator bi = (BreakIterator)breakIterator.clone();\n\n    // sort for sequential io\n    Arrays.sort(docids);\n    Arrays.sort(fields);\n    \n    // pull stored data:\n    LimitedStoredFieldVisitor visitor = new LimitedStoredFieldVisitor(fields, maxLength);\n    String contents[][] = new String[fields.length][docids.length];\n    for (int i = 0; i < docids.length; i++) {\n      searcher.doc(docids[i], visitor);\n      for (int j = 0; j < fields.length; j++) {\n        contents[j][i] = visitor.getValue(j).toString();\n      }\n      visitor.reset();\n    }\n    \n    Map<String,String[]> highlights = new HashMap<String,String[]>();\n    for (int i = 0; i < fields.length; i++) {\n      String field = fields[i];\n      Term floor = new Term(field, \"\");\n      Term ceiling = new Term(field, UnicodeUtil.BIG_TERM);\n      SortedSet<Term> fieldTerms = queryTerms.subSet(floor, ceiling);\n      // TODO: should we have some reasonable defaults for term pruning? (e.g. stopwords)\n      Term terms[] = fieldTerms.toArray(new Term[fieldTerms.size()]);\n      Map<Integer,String> fieldHighlights = highlightField(field, contents[i], bi, terms, docids, leaves, maxPassages);\n        \n      String[] result = new String[scoreDocs.length];\n      for (int j = 0; j < scoreDocs.length; j++) {\n        result[j] = fieldHighlights.get(scoreDocs[j].doc);\n      }\n      highlights.put(field, result);\n    }\n    return highlights;\n  }\n\n","sourceOld":"  /**\n   * Highlights the top-N passages from multiple fields.\n   * <p>\n   * Conceptually, this behaves as a more efficient form of:\n   * <pre class=\"prettyprint\">\n   * Map m = new HashMap();\n   * for (String field : fields) {\n   *   m.put(field, highlight(field, query, searcher, topDocs, maxPassages));\n   * }\n   * return m;\n   * </pre>\n   * \n   * @param fields field names to highlight. \n   *        Must have a stored string value and also be indexed with offsets.\n   * @param query query to highlight.\n   * @param searcher searcher that was previously used to execute the query.\n   * @param topDocs TopDocs containing the summary result documents to highlight.\n   * @param maxPassages The maximum number of top-N ranked passages per-field used to \n   *        form the highlighted snippets.\n   * @return Map keyed on field name, containing the array of formatted snippets \n   *         corresponding to the documents in <code>topDocs</code>. \n   *         If no highlights were found for a document, its value is <code>null</code>.\n   * @throws IOException if an I/O error occurred during processing\n   * @throws IllegalArgumentException if <code>field</code> was indexed without \n   *         {@link IndexOptions#DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS}\n   */\n  public Map<String,String[]> highlightFields(String fields[], Query query, IndexSearcher searcher, TopDocs topDocs, int maxPassages) throws IOException {\n    final IndexReader reader = searcher.getIndexReader();\n    final ScoreDoc scoreDocs[] = topDocs.scoreDocs;\n    query = rewrite(query);\n    SortedSet<Term> queryTerms = new TreeSet<Term>();\n    query.extractTerms(queryTerms);\n\n    int docids[] = new int[scoreDocs.length];\n    for (int i = 0; i < docids.length; i++) {\n      docids[i] = scoreDocs[i].doc;\n    }\n    IndexReaderContext readerContext = reader.getContext();\n    List<AtomicReaderContext> leaves = readerContext.leaves();\n\n    BreakIterator bi = (BreakIterator)breakIterator.clone();\n\n    // sort for sequential io\n    Arrays.sort(docids);\n    Arrays.sort(fields);\n    \n    // pull stored data:\n    LimitedStoredFieldVisitor visitor = new LimitedStoredFieldVisitor(fields, maxLength);\n    String contents[][] = new String[fields.length][docids.length];\n    for (int i = 0; i < docids.length; i++) {\n      reader.document(docids[i], visitor);\n      for (int j = 0; j < fields.length; j++) {\n        contents[j][i] = visitor.getValue(j).toString();\n      }\n      visitor.reset();\n    }\n    \n    Map<String,String[]> highlights = new HashMap<String,String[]>();\n    for (int i = 0; i < fields.length; i++) {\n      String field = fields[i];\n      Term floor = new Term(field, \"\");\n      Term ceiling = new Term(field, UnicodeUtil.BIG_TERM);\n      SortedSet<Term> fieldTerms = queryTerms.subSet(floor, ceiling);\n      // TODO: should we have some reasonable defaults for term pruning? (e.g. stopwords)\n      Term terms[] = fieldTerms.toArray(new Term[fieldTerms.size()]);\n      Map<Integer,String> fieldHighlights = highlightField(field, contents[i], bi, terms, docids, leaves, maxPassages);\n        \n      String[] result = new String[scoreDocs.length];\n      for (int j = 0; j < scoreDocs.length; j++) {\n        result[j] = fieldHighlights.get(scoreDocs[j].doc);\n      }\n      highlights.put(field, result);\n    }\n    return highlights;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/postingshighlight/PostingsHighlighter#highlightFields(String[],Query,IndexSearcher,TopDocs,int).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Highlights the top-N passages from multiple fields.\n   * <p>\n   * Conceptually, this behaves as a more efficient form of:\n   * <pre class=\"prettyprint\">\n   * Map m = new HashMap();\n   * for (String field : fields) {\n   *   m.put(field, highlight(field, query, searcher, topDocs, maxPassages));\n   * }\n   * return m;\n   * </pre>\n   * \n   * @param fields field names to highlight. \n   *        Must have a stored string value and also be indexed with offsets.\n   * @param query query to highlight.\n   * @param searcher searcher that was previously used to execute the query.\n   * @param topDocs TopDocs containing the summary result documents to highlight.\n   * @param maxPassages The maximum number of top-N ranked passages per-field used to \n   *        form the highlighted snippets.\n   * @return Map keyed on field name, containing the array of formatted snippets \n   *         corresponding to the documents in <code>topDocs</code>. \n   *         If no highlights were found for a document, its value is <code>null</code>.\n   * @throws IOException if an I/O error occurred during processing\n   * @throws IllegalArgumentException if <code>field</code> was indexed without \n   *         {@link IndexOptions#DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS}\n   */\n  public Map<String,String[]> highlightFields(String fields[], Query query, IndexSearcher searcher, TopDocs topDocs, int maxPassages) throws IOException {\n    final IndexReader reader = searcher.getIndexReader();\n    final ScoreDoc scoreDocs[] = topDocs.scoreDocs;\n    query = rewrite(query);\n    SortedSet<Term> queryTerms = new TreeSet<Term>();\n    query.extractTerms(queryTerms);\n\n    int docids[] = new int[scoreDocs.length];\n    for (int i = 0; i < docids.length; i++) {\n      docids[i] = scoreDocs[i].doc;\n    }\n    IndexReaderContext readerContext = reader.getContext();\n    List<AtomicReaderContext> leaves = readerContext.leaves();\n\n    BreakIterator bi = (BreakIterator)breakIterator.clone();\n\n    // sort for sequential io\n    Arrays.sort(docids);\n    Arrays.sort(fields);\n    \n    // pull stored data:\n    LimitedStoredFieldVisitor visitor = new LimitedStoredFieldVisitor(fields, maxLength);\n    String contents[][] = new String[fields.length][docids.length];\n    for (int i = 0; i < docids.length; i++) {\n      searcher.doc(docids[i], visitor);\n      for (int j = 0; j < fields.length; j++) {\n        contents[j][i] = visitor.getValue(j).toString();\n      }\n      visitor.reset();\n    }\n    \n    Map<String,String[]> highlights = new HashMap<String,String[]>();\n    for (int i = 0; i < fields.length; i++) {\n      String field = fields[i];\n      Term floor = new Term(field, \"\");\n      Term ceiling = new Term(field, UnicodeUtil.BIG_TERM);\n      SortedSet<Term> fieldTerms = queryTerms.subSet(floor, ceiling);\n      // TODO: should we have some reasonable defaults for term pruning? (e.g. stopwords)\n      Term terms[] = fieldTerms.toArray(new Term[fieldTerms.size()]);\n      Map<Integer,String> fieldHighlights = highlightField(field, contents[i], bi, terms, docids, leaves, maxPassages);\n        \n      String[] result = new String[scoreDocs.length];\n      for (int j = 0; j < scoreDocs.length; j++) {\n        result[j] = fieldHighlights.get(scoreDocs[j].doc);\n      }\n      highlights.put(field, result);\n    }\n    return highlights;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4d8affc7eee92d19bf9869be92b1037e3d86b60f","date":1363641611,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/postingshighlight/PostingsHighlighter#highlightFields(String[],Query,IndexSearcher,TopDocs,int).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/postingshighlight/PostingsHighlighter#highlightFields(String[],Query,IndexSearcher,TopDocs,int).mjava","sourceNew":"  /**\n   * Highlights the top-N passages from multiple fields.\n   * <p>\n   * Conceptually, this behaves as a more efficient form of:\n   * <pre class=\"prettyprint\">\n   * Map m = new HashMap();\n   * for (String field : fields) {\n   *   m.put(field, highlight(field, query, searcher, topDocs, maxPassages));\n   * }\n   * return m;\n   * </pre>\n   * \n   * @param fields field names to highlight. \n   *        Must have a stored string value and also be indexed with offsets.\n   * @param query query to highlight.\n   * @param searcher searcher that was previously used to execute the query.\n   * @param topDocs TopDocs containing the summary result documents to highlight.\n   * @param maxPassages The maximum number of top-N ranked passages per-field used to \n   *        form the highlighted snippets.\n   * @return Map keyed on field name, containing the array of formatted snippets \n   *         corresponding to the documents in <code>topDocs</code>. \n   *         If no highlights were found for a document, its value is <code>null</code>.\n   * @throws IOException if an I/O error occurred during processing\n   * @throws IllegalArgumentException if <code>field</code> was indexed without \n   *         {@link IndexOptions#DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS}\n   */\n  public Map<String,String[]> highlightFields(String fields[], Query query, IndexSearcher searcher, TopDocs topDocs, int maxPassages) throws IOException {\n    final IndexReader reader = searcher.getIndexReader();\n    final ScoreDoc scoreDocs[] = topDocs.scoreDocs;\n    query = rewrite(query);\n    SortedSet<Term> queryTerms = new TreeSet<Term>();\n    query.extractTerms(queryTerms);\n\n    int docids[] = new int[scoreDocs.length];\n    for (int i = 0; i < docids.length; i++) {\n      docids[i] = scoreDocs[i].doc;\n    }\n    IndexReaderContext readerContext = reader.getContext();\n    List<AtomicReaderContext> leaves = readerContext.leaves();\n\n    BreakIterator bi = (BreakIterator)breakIterator.clone();\n\n    // sort for sequential io\n    Arrays.sort(docids);\n    Arrays.sort(fields);\n    \n    // pull stored data:\n    String[][] contents = loadFieldValues(searcher, fields, docids, maxLength);\n    \n    Map<String,String[]> highlights = new HashMap<String,String[]>();\n    for (int i = 0; i < fields.length; i++) {\n      String field = fields[i];\n      Term floor = new Term(field, \"\");\n      Term ceiling = new Term(field, UnicodeUtil.BIG_TERM);\n      SortedSet<Term> fieldTerms = queryTerms.subSet(floor, ceiling);\n      // TODO: should we have some reasonable defaults for term pruning? (e.g. stopwords)\n      Term terms[] = fieldTerms.toArray(new Term[fieldTerms.size()]);\n      Map<Integer,String> fieldHighlights = highlightField(field, contents[i], bi, terms, docids, leaves, maxPassages);\n        \n      String[] result = new String[scoreDocs.length];\n      for (int j = 0; j < scoreDocs.length; j++) {\n        result[j] = fieldHighlights.get(scoreDocs[j].doc);\n      }\n      highlights.put(field, result);\n    }\n    return highlights;\n  }\n\n","sourceOld":"  /**\n   * Highlights the top-N passages from multiple fields.\n   * <p>\n   * Conceptually, this behaves as a more efficient form of:\n   * <pre class=\"prettyprint\">\n   * Map m = new HashMap();\n   * for (String field : fields) {\n   *   m.put(field, highlight(field, query, searcher, topDocs, maxPassages));\n   * }\n   * return m;\n   * </pre>\n   * \n   * @param fields field names to highlight. \n   *        Must have a stored string value and also be indexed with offsets.\n   * @param query query to highlight.\n   * @param searcher searcher that was previously used to execute the query.\n   * @param topDocs TopDocs containing the summary result documents to highlight.\n   * @param maxPassages The maximum number of top-N ranked passages per-field used to \n   *        form the highlighted snippets.\n   * @return Map keyed on field name, containing the array of formatted snippets \n   *         corresponding to the documents in <code>topDocs</code>. \n   *         If no highlights were found for a document, its value is <code>null</code>.\n   * @throws IOException if an I/O error occurred during processing\n   * @throws IllegalArgumentException if <code>field</code> was indexed without \n   *         {@link IndexOptions#DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS}\n   */\n  public Map<String,String[]> highlightFields(String fields[], Query query, IndexSearcher searcher, TopDocs topDocs, int maxPassages) throws IOException {\n    final IndexReader reader = searcher.getIndexReader();\n    final ScoreDoc scoreDocs[] = topDocs.scoreDocs;\n    query = rewrite(query);\n    SortedSet<Term> queryTerms = new TreeSet<Term>();\n    query.extractTerms(queryTerms);\n\n    int docids[] = new int[scoreDocs.length];\n    for (int i = 0; i < docids.length; i++) {\n      docids[i] = scoreDocs[i].doc;\n    }\n    IndexReaderContext readerContext = reader.getContext();\n    List<AtomicReaderContext> leaves = readerContext.leaves();\n\n    BreakIterator bi = (BreakIterator)breakIterator.clone();\n\n    // sort for sequential io\n    Arrays.sort(docids);\n    Arrays.sort(fields);\n    \n    // pull stored data:\n    LimitedStoredFieldVisitor visitor = new LimitedStoredFieldVisitor(fields, maxLength);\n    String contents[][] = new String[fields.length][docids.length];\n    for (int i = 0; i < docids.length; i++) {\n      searcher.doc(docids[i], visitor);\n      for (int j = 0; j < fields.length; j++) {\n        contents[j][i] = visitor.getValue(j).toString();\n      }\n      visitor.reset();\n    }\n    \n    Map<String,String[]> highlights = new HashMap<String,String[]>();\n    for (int i = 0; i < fields.length; i++) {\n      String field = fields[i];\n      Term floor = new Term(field, \"\");\n      Term ceiling = new Term(field, UnicodeUtil.BIG_TERM);\n      SortedSet<Term> fieldTerms = queryTerms.subSet(floor, ceiling);\n      // TODO: should we have some reasonable defaults for term pruning? (e.g. stopwords)\n      Term terms[] = fieldTerms.toArray(new Term[fieldTerms.size()]);\n      Map<Integer,String> fieldHighlights = highlightField(field, contents[i], bi, terms, docids, leaves, maxPassages);\n        \n      String[] result = new String[scoreDocs.length];\n      for (int j = 0; j < scoreDocs.length; j++) {\n        result[j] = fieldHighlights.get(scoreDocs[j].doc);\n      }\n      highlights.put(field, result);\n    }\n    return highlights;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"603175ca08914b73fa328e1ac07c772f8103ecd0","date":1363642166,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/postingshighlight/PostingsHighlighter#highlightFields(String[],Query,IndexSearcher,TopDocs,int).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/postingshighlight/PostingsHighlighter#highlightFields(String[],Query,IndexSearcher,TopDocs,int).mjava","sourceNew":"  /**\n   * Highlights the top-N passages from multiple fields.\n   * <p>\n   * Conceptually, this behaves as a more efficient form of:\n   * <pre class=\"prettyprint\">\n   * Map m = new HashMap();\n   * for (String field : fields) {\n   *   m.put(field, highlight(field, query, searcher, topDocs, maxPassages));\n   * }\n   * return m;\n   * </pre>\n   * \n   * @param fields field names to highlight. \n   *        Must have a stored string value and also be indexed with offsets.\n   * @param query query to highlight.\n   * @param searcher searcher that was previously used to execute the query.\n   * @param topDocs TopDocs containing the summary result documents to highlight.\n   * @param maxPassages The maximum number of top-N ranked passages per-field used to \n   *        form the highlighted snippets.\n   * @return Map keyed on field name, containing the array of formatted snippets \n   *         corresponding to the documents in <code>topDocs</code>. \n   *         If no highlights were found for a document, its value is <code>null</code>.\n   * @throws IOException if an I/O error occurred during processing\n   * @throws IllegalArgumentException if <code>field</code> was indexed without \n   *         {@link IndexOptions#DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS}\n   */\n  public Map<String,String[]> highlightFields(String fields[], Query query, IndexSearcher searcher, TopDocs topDocs, int maxPassages) throws IOException {\n    final ScoreDoc scoreDocs[] = topDocs.scoreDocs;\n    int docids[] = new int[scoreDocs.length];\n    for (int i = 0; i < docids.length; i++) {\n      docids[i] = scoreDocs[i].doc;\n    }\n\n    return highlightFields(fields, query, searcher, docids, maxPassages);\n  }\n\n","sourceOld":"  /**\n   * Highlights the top-N passages from multiple fields.\n   * <p>\n   * Conceptually, this behaves as a more efficient form of:\n   * <pre class=\"prettyprint\">\n   * Map m = new HashMap();\n   * for (String field : fields) {\n   *   m.put(field, highlight(field, query, searcher, topDocs, maxPassages));\n   * }\n   * return m;\n   * </pre>\n   * \n   * @param fields field names to highlight. \n   *        Must have a stored string value and also be indexed with offsets.\n   * @param query query to highlight.\n   * @param searcher searcher that was previously used to execute the query.\n   * @param topDocs TopDocs containing the summary result documents to highlight.\n   * @param maxPassages The maximum number of top-N ranked passages per-field used to \n   *        form the highlighted snippets.\n   * @return Map keyed on field name, containing the array of formatted snippets \n   *         corresponding to the documents in <code>topDocs</code>. \n   *         If no highlights were found for a document, its value is <code>null</code>.\n   * @throws IOException if an I/O error occurred during processing\n   * @throws IllegalArgumentException if <code>field</code> was indexed without \n   *         {@link IndexOptions#DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS}\n   */\n  public Map<String,String[]> highlightFields(String fields[], Query query, IndexSearcher searcher, TopDocs topDocs, int maxPassages) throws IOException {\n    final IndexReader reader = searcher.getIndexReader();\n    final ScoreDoc scoreDocs[] = topDocs.scoreDocs;\n    query = rewrite(query);\n    SortedSet<Term> queryTerms = new TreeSet<Term>();\n    query.extractTerms(queryTerms);\n\n    int docids[] = new int[scoreDocs.length];\n    for (int i = 0; i < docids.length; i++) {\n      docids[i] = scoreDocs[i].doc;\n    }\n    IndexReaderContext readerContext = reader.getContext();\n    List<AtomicReaderContext> leaves = readerContext.leaves();\n\n    BreakIterator bi = (BreakIterator)breakIterator.clone();\n\n    // sort for sequential io\n    Arrays.sort(docids);\n    Arrays.sort(fields);\n    \n    // pull stored data:\n    String[][] contents = loadFieldValues(searcher, fields, docids, maxLength);\n    \n    Map<String,String[]> highlights = new HashMap<String,String[]>();\n    for (int i = 0; i < fields.length; i++) {\n      String field = fields[i];\n      Term floor = new Term(field, \"\");\n      Term ceiling = new Term(field, UnicodeUtil.BIG_TERM);\n      SortedSet<Term> fieldTerms = queryTerms.subSet(floor, ceiling);\n      // TODO: should we have some reasonable defaults for term pruning? (e.g. stopwords)\n      Term terms[] = fieldTerms.toArray(new Term[fieldTerms.size()]);\n      Map<Integer,String> fieldHighlights = highlightField(field, contents[i], bi, terms, docids, leaves, maxPassages);\n        \n      String[] result = new String[scoreDocs.length];\n      for (int j = 0; j < scoreDocs.length; j++) {\n        result[j] = fieldHighlights.get(scoreDocs[j].doc);\n      }\n      highlights.put(field, result);\n    }\n    return highlights;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"77fc0eb4b8857a9f5235049cdfe6f678a3ddae55","date":1363791725,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/postingshighlight/PostingsHighlighter#highlightFields(String[],Query,IndexSearcher,TopDocs,int).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/postingshighlight/PostingsHighlighter#highlightFields(String[],Query,IndexSearcher,TopDocs,int).mjava","sourceNew":"  /**\n   * Highlights the top-N passages from multiple fields.\n   * <p>\n   * Conceptually, this behaves as a more efficient form of:\n   * <pre class=\"prettyprint\">\n   * Map m = new HashMap();\n   * for (String field : fields) {\n   *   m.put(field, highlight(field, query, searcher, topDocs, maxPassages));\n   * }\n   * return m;\n   * </pre>\n   * \n   * @param fields field names to highlight. \n   *        Must have a stored string value and also be indexed with offsets.\n   * @param query query to highlight.\n   * @param searcher searcher that was previously used to execute the query.\n   * @param topDocs TopDocs containing the summary result documents to highlight.\n   * @param maxPassages The maximum number of top-N ranked passages per-field used to \n   *        form the highlighted snippets.\n   * @return Map keyed on field name, containing the array of formatted snippets \n   *         corresponding to the documents in <code>topDocs</code>. \n   *         If no highlights were found for a document, the\n   *         first {@code maxPassages} sentences from the\n   *         field will be returned.\n   * @throws IOException if an I/O error occurred during processing\n   * @throws IllegalArgumentException if <code>field</code> was indexed without \n   *         {@link IndexOptions#DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS}\n   */\n  public Map<String,String[]> highlightFields(String fields[], Query query, IndexSearcher searcher, TopDocs topDocs, int maxPassages) throws IOException {\n    final ScoreDoc scoreDocs[] = topDocs.scoreDocs;\n    int docids[] = new int[scoreDocs.length];\n    for (int i = 0; i < docids.length; i++) {\n      docids[i] = scoreDocs[i].doc;\n    }\n\n    return highlightFields(fields, query, searcher, docids, maxPassages);\n  }\n\n","sourceOld":"  /**\n   * Highlights the top-N passages from multiple fields.\n   * <p>\n   * Conceptually, this behaves as a more efficient form of:\n   * <pre class=\"prettyprint\">\n   * Map m = new HashMap();\n   * for (String field : fields) {\n   *   m.put(field, highlight(field, query, searcher, topDocs, maxPassages));\n   * }\n   * return m;\n   * </pre>\n   * \n   * @param fields field names to highlight. \n   *        Must have a stored string value and also be indexed with offsets.\n   * @param query query to highlight.\n   * @param searcher searcher that was previously used to execute the query.\n   * @param topDocs TopDocs containing the summary result documents to highlight.\n   * @param maxPassages The maximum number of top-N ranked passages per-field used to \n   *        form the highlighted snippets.\n   * @return Map keyed on field name, containing the array of formatted snippets \n   *         corresponding to the documents in <code>topDocs</code>. \n   *         If no highlights were found for a document, its value is <code>null</code>.\n   * @throws IOException if an I/O error occurred during processing\n   * @throws IllegalArgumentException if <code>field</code> was indexed without \n   *         {@link IndexOptions#DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS}\n   */\n  public Map<String,String[]> highlightFields(String fields[], Query query, IndexSearcher searcher, TopDocs topDocs, int maxPassages) throws IOException {\n    final ScoreDoc scoreDocs[] = topDocs.scoreDocs;\n    int docids[] = new int[scoreDocs.length];\n    for (int i = 0; i < docids.length; i++) {\n      docids[i] = scoreDocs[i].doc;\n    }\n\n    return highlightFields(fields, query, searcher, docids, maxPassages);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a385683d8ce32386bb71e8c427cb78573debda2b","date":1363792009,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/postingshighlight/PostingsHighlighter#highlightFields(String[],Query,IndexSearcher,TopDocs,int).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/postingshighlight/PostingsHighlighter#highlightFields(String[],Query,IndexSearcher,TopDocs,int).mjava","sourceNew":"  /**\n   * Highlights the top-N passages from multiple fields.\n   * <p>\n   * Conceptually, this behaves as a more efficient form of:\n   * <pre class=\"prettyprint\">\n   * Map m = new HashMap();\n   * for (String field : fields) {\n   *   m.put(field, highlight(field, query, searcher, topDocs, maxPassages));\n   * }\n   * return m;\n   * </pre>\n   * \n   * @param fields field names to highlight. \n   *        Must have a stored string value and also be indexed with offsets.\n   * @param query query to highlight.\n   * @param searcher searcher that was previously used to execute the query.\n   * @param topDocs TopDocs containing the summary result documents to highlight.\n   * @param maxPassages The maximum number of top-N ranked passages per-field used to \n   *        form the highlighted snippets.\n   * @return Map keyed on field name, containing the array of formatted snippets \n   *         corresponding to the documents in <code>topDocs</code>. \n   *         If no highlights were found for a document, its value is <code>null</code>.\n   * @throws IOException if an I/O error occurred during processing\n   * @throws IllegalArgumentException if <code>field</code> was indexed without \n   *         {@link IndexOptions#DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS}\n   */\n  public Map<String,String[]> highlightFields(String fields[], Query query, IndexSearcher searcher, TopDocs topDocs, int maxPassages) throws IOException {\n    final ScoreDoc scoreDocs[] = topDocs.scoreDocs;\n    int docids[] = new int[scoreDocs.length];\n    for (int i = 0; i < docids.length; i++) {\n      docids[i] = scoreDocs[i].doc;\n    }\n\n    return highlightFields(fields, query, searcher, docids, maxPassages);\n  }\n\n","sourceOld":"  /**\n   * Highlights the top-N passages from multiple fields.\n   * <p>\n   * Conceptually, this behaves as a more efficient form of:\n   * <pre class=\"prettyprint\">\n   * Map m = new HashMap();\n   * for (String field : fields) {\n   *   m.put(field, highlight(field, query, searcher, topDocs, maxPassages));\n   * }\n   * return m;\n   * </pre>\n   * \n   * @param fields field names to highlight. \n   *        Must have a stored string value and also be indexed with offsets.\n   * @param query query to highlight.\n   * @param searcher searcher that was previously used to execute the query.\n   * @param topDocs TopDocs containing the summary result documents to highlight.\n   * @param maxPassages The maximum number of top-N ranked passages per-field used to \n   *        form the highlighted snippets.\n   * @return Map keyed on field name, containing the array of formatted snippets \n   *         corresponding to the documents in <code>topDocs</code>. \n   *         If no highlights were found for a document, the\n   *         first {@code maxPassages} sentences from the\n   *         field will be returned.\n   * @throws IOException if an I/O error occurred during processing\n   * @throws IllegalArgumentException if <code>field</code> was indexed without \n   *         {@link IndexOptions#DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS}\n   */\n  public Map<String,String[]> highlightFields(String fields[], Query query, IndexSearcher searcher, TopDocs topDocs, int maxPassages) throws IOException {\n    final ScoreDoc scoreDocs[] = topDocs.scoreDocs;\n    int docids[] = new int[scoreDocs.length];\n    for (int i = 0; i < docids.length; i++) {\n      docids[i] = scoreDocs[i].doc;\n    }\n\n    return highlightFields(fields, query, searcher, docids, maxPassages);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4ca2025fc6d81ec43c276473ba49e4fbcb15ccb1","date":1363793774,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/postingshighlight/PostingsHighlighter#highlightFields(String[],Query,IndexSearcher,TopDocs,int).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/postingshighlight/PostingsHighlighter#highlightFields(String[],Query,IndexSearcher,TopDocs,int).mjava","sourceNew":"  /**\n   * Highlights the top-N passages from multiple fields.\n   * <p>\n   * Conceptually, this behaves as a more efficient form of:\n   * <pre class=\"prettyprint\">\n   * Map m = new HashMap();\n   * for (String field : fields) {\n   *   m.put(field, highlight(field, query, searcher, topDocs, maxPassages));\n   * }\n   * return m;\n   * </pre>\n   * \n   * @param fields field names to highlight. \n   *        Must have a stored string value and also be indexed with offsets.\n   * @param query query to highlight.\n   * @param searcher searcher that was previously used to execute the query.\n   * @param topDocs TopDocs containing the summary result documents to highlight.\n   * @param maxPassages The maximum number of top-N ranked passages per-field used to \n   *        form the highlighted snippets.\n   * @return Map keyed on field name, containing the array of formatted snippets \n   *         corresponding to the documents in <code>topDocs</code>. \n   *         If no highlights were found for a document, the\n   *         first {@code maxPassages} sentences from the\n   *         field will be returned.\n   * @throws IOException if an I/O error occurred during processing\n   * @throws IllegalArgumentException if <code>field</code> was indexed without \n   *         {@link IndexOptions#DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS}\n   */\n  public Map<String,String[]> highlightFields(String fields[], Query query, IndexSearcher searcher, TopDocs topDocs, int maxPassages) throws IOException {\n    final ScoreDoc scoreDocs[] = topDocs.scoreDocs;\n    int docids[] = new int[scoreDocs.length];\n    for (int i = 0; i < docids.length; i++) {\n      docids[i] = scoreDocs[i].doc;\n    }\n\n    return highlightFields(fields, query, searcher, docids, maxPassages);\n  }\n\n","sourceOld":"  /**\n   * Highlights the top-N passages from multiple fields.\n   * <p>\n   * Conceptually, this behaves as a more efficient form of:\n   * <pre class=\"prettyprint\">\n   * Map m = new HashMap();\n   * for (String field : fields) {\n   *   m.put(field, highlight(field, query, searcher, topDocs, maxPassages));\n   * }\n   * return m;\n   * </pre>\n   * \n   * @param fields field names to highlight. \n   *        Must have a stored string value and also be indexed with offsets.\n   * @param query query to highlight.\n   * @param searcher searcher that was previously used to execute the query.\n   * @param topDocs TopDocs containing the summary result documents to highlight.\n   * @param maxPassages The maximum number of top-N ranked passages per-field used to \n   *        form the highlighted snippets.\n   * @return Map keyed on field name, containing the array of formatted snippets \n   *         corresponding to the documents in <code>topDocs</code>. \n   *         If no highlights were found for a document, its value is <code>null</code>.\n   * @throws IOException if an I/O error occurred during processing\n   * @throws IllegalArgumentException if <code>field</code> was indexed without \n   *         {@link IndexOptions#DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS}\n   */\n  public Map<String,String[]> highlightFields(String fields[], Query query, IndexSearcher searcher, TopDocs topDocs, int maxPassages) throws IOException {\n    final ScoreDoc scoreDocs[] = topDocs.scoreDocs;\n    int docids[] = new int[scoreDocs.length];\n    for (int i = 0; i < docids.length; i++) {\n      docids[i] = scoreDocs[i].doc;\n    }\n\n    return highlightFields(fields, query, searcher, docids, maxPassages);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e8176b5c0894f97addb4b77198ec5684476b1b32","date":1365103218,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/postingshighlight/PostingsHighlighter#highlightFields(String[],Query,IndexSearcher,TopDocs,int[]).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/postingshighlight/PostingsHighlighter#highlightFields(String[],Query,IndexSearcher,TopDocs,int).mjava","sourceNew":"  /**\n   * Highlights the top-N passages from multiple fields.\n   * <p>\n   * Conceptually, this behaves as a more efficient form of:\n   * <pre class=\"prettyprint\">\n   * Map m = new HashMap();\n   * for (String field : fields) {\n   *   m.put(field, highlight(field, query, searcher, topDocs, maxPassages));\n   * }\n   * return m;\n   * </pre>\n   * \n   * @param fields field names to highlight. \n   *        Must have a stored string value and also be indexed with offsets.\n   * @param query query to highlight.\n   * @param searcher searcher that was previously used to execute the query.\n   * @param topDocs TopDocs containing the summary result documents to highlight.\n   * @param maxPassages The maximum number of top-N ranked passages per-field used to \n   *        form the highlighted snippets.\n   * @return Map keyed on field name, containing the array of formatted snippets \n   *         corresponding to the documents in <code>topDocs</code>. \n   *         If no highlights were found for a document, the\n   *         first {@code maxPassages} sentences from the\n   *         field will be returned.\n   * @throws IOException if an I/O error occurred during processing\n   * @throws IllegalArgumentException if <code>field</code> was indexed without \n   *         {@link IndexOptions#DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS}\n   */\n  public Map<String,String[]> highlightFields(String fields[], Query query, IndexSearcher searcher, TopDocs topDocs, int maxPassages[]) throws IOException {\n    final ScoreDoc scoreDocs[] = topDocs.scoreDocs;\n    int docids[] = new int[scoreDocs.length];\n    for (int i = 0; i < docids.length; i++) {\n      docids[i] = scoreDocs[i].doc;\n    }\n\n    return highlightFields(fields, query, searcher, docids, maxPassages);\n  }\n\n","sourceOld":"  /**\n   * Highlights the top-N passages from multiple fields.\n   * <p>\n   * Conceptually, this behaves as a more efficient form of:\n   * <pre class=\"prettyprint\">\n   * Map m = new HashMap();\n   * for (String field : fields) {\n   *   m.put(field, highlight(field, query, searcher, topDocs, maxPassages));\n   * }\n   * return m;\n   * </pre>\n   * \n   * @param fields field names to highlight. \n   *        Must have a stored string value and also be indexed with offsets.\n   * @param query query to highlight.\n   * @param searcher searcher that was previously used to execute the query.\n   * @param topDocs TopDocs containing the summary result documents to highlight.\n   * @param maxPassages The maximum number of top-N ranked passages per-field used to \n   *        form the highlighted snippets.\n   * @return Map keyed on field name, containing the array of formatted snippets \n   *         corresponding to the documents in <code>topDocs</code>. \n   *         If no highlights were found for a document, the\n   *         first {@code maxPassages} sentences from the\n   *         field will be returned.\n   * @throws IOException if an I/O error occurred during processing\n   * @throws IllegalArgumentException if <code>field</code> was indexed without \n   *         {@link IndexOptions#DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS}\n   */\n  public Map<String,String[]> highlightFields(String fields[], Query query, IndexSearcher searcher, TopDocs topDocs, int maxPassages) throws IOException {\n    final ScoreDoc scoreDocs[] = topDocs.scoreDocs;\n    int docids[] = new int[scoreDocs.length];\n    for (int i = 0; i < docids.length; i++) {\n      docids[i] = scoreDocs[i].doc;\n    }\n\n    return highlightFields(fields, query, searcher, docids, maxPassages);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","4b3d16cba9355e2e97962eb1c441bbd0b6735c15"],"4b3d16cba9355e2e97962eb1c441bbd0b6735c15":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a385683d8ce32386bb71e8c427cb78573debda2b":["77fc0eb4b8857a9f5235049cdfe6f678a3ddae55"],"e8176b5c0894f97addb4b77198ec5684476b1b32":["4ca2025fc6d81ec43c276473ba49e4fbcb15ccb1"],"603175ca08914b73fa328e1ac07c772f8103ecd0":["4d8affc7eee92d19bf9869be92b1037e3d86b60f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4d8affc7eee92d19bf9869be92b1037e3d86b60f":["4b3d16cba9355e2e97962eb1c441bbd0b6735c15"],"77fc0eb4b8857a9f5235049cdfe6f678a3ddae55":["603175ca08914b73fa328e1ac07c772f8103ecd0"],"4ca2025fc6d81ec43c276473ba49e4fbcb15ccb1":["a385683d8ce32386bb71e8c427cb78573debda2b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e8176b5c0894f97addb4b77198ec5684476b1b32"]},"commit2Childs":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"4b3d16cba9355e2e97962eb1c441bbd0b6735c15":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","4d8affc7eee92d19bf9869be92b1037e3d86b60f"],"a385683d8ce32386bb71e8c427cb78573debda2b":["4ca2025fc6d81ec43c276473ba49e4fbcb15ccb1"],"e8176b5c0894f97addb4b77198ec5684476b1b32":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"603175ca08914b73fa328e1ac07c772f8103ecd0":["77fc0eb4b8857a9f5235049cdfe6f678a3ddae55"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","4b3d16cba9355e2e97962eb1c441bbd0b6735c15"],"4d8affc7eee92d19bf9869be92b1037e3d86b60f":["603175ca08914b73fa328e1ac07c772f8103ecd0"],"77fc0eb4b8857a9f5235049cdfe6f678a3ddae55":["a385683d8ce32386bb71e8c427cb78573debda2b"],"4ca2025fc6d81ec43c276473ba49e4fbcb15ccb1":["e8176b5c0894f97addb4b77198ec5684476b1b32"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}