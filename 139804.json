{"path":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","commits":[{"id":"86a2e8a56b368d37ef3ba7180541fa317d6fd6c7","date":1524496660,"type":1,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.deleteDocIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.deleteDocIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.deleteDocIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.deleteDocIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.deleteDocIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      sortMap = consumer.flush(flushState);\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush,\n          sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.deleteDocIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.deleteDocIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.deleteDocIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.deleteDocIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.deleteDocIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      sortMap = consumer.flush(flushState);\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush,\n          sortMap);\n      sealFlushedSegment(fs, sortMap);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fb8a3dfca2d8b39c20bdfc87eb7171c06ea9400d","date":1525873214,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.deleteDocIDs.size() > 0) {\n      flushState.liveDocs = new FixedBitSet(numDocsInRAM);\n      flushState.liveDocs.set(0, numDocsInRAM);\n      for(int delDocID : pendingUpdates.deleteDocIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.deleteDocIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.deleteDocIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.deleteDocIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      sortMap = consumer.flush(flushState);\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush,\n          sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.deleteDocIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.deleteDocIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.deleteDocIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.deleteDocIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.deleteDocIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      sortMap = consumer.flush(flushState);\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush,\n          sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8f2203cb8ae87188877cfbf6ad170c5738a0aad5","date":1528117512,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.deleteDocIDs.size() > 0) {\n      flushState.liveDocs = new FixedBitSet(numDocsInRAM);\n      flushState.liveDocs.set(0, numDocsInRAM);\n      for(int delDocID : pendingUpdates.deleteDocIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.deleteDocIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.deleteDocIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.deleteDocIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      DocIdSetIterator softDeletedDocs;\n      if (indexWriterConfig.getSoftDeletesField() != null) {\n        softDeletedDocs = consumer.getHasDocValues(indexWriterConfig.getSoftDeletesField());\n      } else {\n        softDeletedDocs = null;\n      }\n      sortMap = consumer.flush(flushState);\n      if (softDeletedDocs == null) {\n        flushState.softDelCountOnFlush = 0;\n      } else {\n        flushState.softDelCountOnFlush = PendingSoftDeletes.countSoftDeletes(softDeletedDocs, flushState.liveDocs);\n        assert flushState.segmentInfo.maxDoc() >= flushState.softDelCountOnFlush + flushState.delCountOnFlush;\n      }\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, flushState.softDelCountOnFlush, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" + flushState.softDelCountOnFlush + \" soft-deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush, sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.deleteDocIDs.size() > 0) {\n      flushState.liveDocs = new FixedBitSet(numDocsInRAM);\n      flushState.liveDocs.set(0, numDocsInRAM);\n      for(int delDocID : pendingUpdates.deleteDocIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.deleteDocIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.deleteDocIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.deleteDocIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      sortMap = consumer.flush(flushState);\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush,\n          sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f592209545c71895260367152601e9200399776d","date":1528238935,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.deleteDocIDs.size() > 0) {\n      flushState.liveDocs = new FixedBitSet(numDocsInRAM);\n      flushState.liveDocs.set(0, numDocsInRAM);\n      for(int delDocID : pendingUpdates.deleteDocIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.deleteDocIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.deleteDocIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.deleteDocIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      DocIdSetIterator softDeletedDocs;\n      if (indexWriterConfig.getSoftDeletesField() != null) {\n        softDeletedDocs = consumer.getHasDocValues(indexWriterConfig.getSoftDeletesField());\n      } else {\n        softDeletedDocs = null;\n      }\n      sortMap = consumer.flush(flushState);\n      if (softDeletedDocs == null) {\n        flushState.softDelCountOnFlush = 0;\n      } else {\n        flushState.softDelCountOnFlush = PendingSoftDeletes.countSoftDeletes(softDeletedDocs, flushState.liveDocs);\n        assert flushState.segmentInfo.maxDoc() >= flushState.softDelCountOnFlush + flushState.delCountOnFlush;\n      }\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, flushState.softDelCountOnFlush, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" + flushState.softDelCountOnFlush + \" soft-deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush, sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.deleteDocIDs.size() > 0) {\n      flushState.liveDocs = new FixedBitSet(numDocsInRAM);\n      flushState.liveDocs.set(0, numDocsInRAM);\n      for(int delDocID : pendingUpdates.deleteDocIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.deleteDocIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.deleteDocIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.deleteDocIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      sortMap = consumer.flush(flushState);\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush,\n          sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b70042a8a492f7054d480ccdd2be9796510d4327","date":1528386658,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.deleteDocIDs.size() > 0) {\n      flushState.liveDocs = new FixedBitSet(numDocsInRAM);\n      flushState.liveDocs.set(0, numDocsInRAM);\n      for(int delDocID : pendingUpdates.deleteDocIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.deleteDocIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.deleteDocIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.deleteDocIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      DocIdSetIterator softDeletedDocs;\n      if (indexWriterConfig.getSoftDeletesField() != null) {\n        softDeletedDocs = consumer.getHasDocValues(indexWriterConfig.getSoftDeletesField());\n      } else {\n        softDeletedDocs = null;\n      }\n      sortMap = consumer.flush(flushState);\n      if (softDeletedDocs == null) {\n        flushState.softDelCountOnFlush = 0;\n      } else {\n        flushState.softDelCountOnFlush = PendingSoftDeletes.countSoftDeletes(softDeletedDocs, flushState.liveDocs);\n        assert flushState.segmentInfo.maxDoc() >= flushState.softDelCountOnFlush + flushState.delCountOnFlush;\n      }\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, flushState.softDelCountOnFlush, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" + flushState.softDelCountOnFlush + \" soft-deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush, sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.deleteDocIDs.size() > 0) {\n      flushState.liveDocs = new FixedBitSet(numDocsInRAM);\n      flushState.liveDocs.set(0, numDocsInRAM);\n      for(int delDocID : pendingUpdates.deleteDocIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.deleteDocIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.deleteDocIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.deleteDocIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      sortMap = consumer.flush(flushState);\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush,\n          sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28211671436f185419b3f7e53ccfc3911441ab65","date":1544026960,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.deleteDocIDs.size() > 0) {\n      flushState.liveDocs = new FixedBitSet(numDocsInRAM);\n      flushState.liveDocs.set(0, numDocsInRAM);\n      for(int delDocID : pendingUpdates.deleteDocIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.deleteDocIDs.size();\n      pendingUpdates.clearDeletedDocIds();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      DocIdSetIterator softDeletedDocs;\n      if (indexWriterConfig.getSoftDeletesField() != null) {\n        softDeletedDocs = consumer.getHasDocValues(indexWriterConfig.getSoftDeletesField());\n      } else {\n        softDeletedDocs = null;\n      }\n      sortMap = consumer.flush(flushState);\n      if (softDeletedDocs == null) {\n        flushState.softDelCountOnFlush = 0;\n      } else {\n        flushState.softDelCountOnFlush = PendingSoftDeletes.countSoftDeletes(softDeletedDocs, flushState.liveDocs);\n        assert flushState.segmentInfo.maxDoc() >= flushState.softDelCountOnFlush + flushState.delCountOnFlush;\n      }\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, flushState.softDelCountOnFlush, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" + flushState.softDelCountOnFlush + \" soft-deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numFieldUpdates.get() == 0) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush, sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.deleteDocIDs.size() > 0) {\n      flushState.liveDocs = new FixedBitSet(numDocsInRAM);\n      flushState.liveDocs.set(0, numDocsInRAM);\n      for(int delDocID : pendingUpdates.deleteDocIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.deleteDocIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.deleteDocIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.deleteDocIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      DocIdSetIterator softDeletedDocs;\n      if (indexWriterConfig.getSoftDeletesField() != null) {\n        softDeletedDocs = consumer.getHasDocValues(indexWriterConfig.getSoftDeletesField());\n      } else {\n        softDeletedDocs = null;\n      }\n      sortMap = consumer.flush(flushState);\n      if (softDeletedDocs == null) {\n        flushState.softDelCountOnFlush = 0;\n      } else {\n        flushState.softDelCountOnFlush = PendingSoftDeletes.countSoftDeletes(softDeletedDocs, flushState.liveDocs);\n        assert flushState.segmentInfo.maxDoc() >= flushState.softDelCountOnFlush + flushState.delCountOnFlush;\n      }\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, flushState.softDelCountOnFlush, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" + flushState.softDelCountOnFlush + \" soft-deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush, sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"264935965977b4a9e2f3920420647072c9c49176","date":1586600626,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert flushPending.get() == Boolean.TRUE;\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.deleteDocIDs.size() > 0) {\n      flushState.liveDocs = new FixedBitSet(numDocsInRAM);\n      flushState.liveDocs.set(0, numDocsInRAM);\n      for(int delDocID : pendingUpdates.deleteDocIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.deleteDocIDs.size();\n      pendingUpdates.clearDeletedDocIds();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      DocIdSetIterator softDeletedDocs;\n      if (indexWriterConfig.getSoftDeletesField() != null) {\n        softDeletedDocs = consumer.getHasDocValues(indexWriterConfig.getSoftDeletesField());\n      } else {\n        softDeletedDocs = null;\n      }\n      sortMap = consumer.flush(flushState);\n      if (softDeletedDocs == null) {\n        flushState.softDelCountOnFlush = 0;\n      } else {\n        flushState.softDelCountOnFlush = PendingSoftDeletes.countSoftDeletes(softDeletedDocs, flushState.liveDocs);\n        assert flushState.segmentInfo.maxDoc() >= flushState.softDelCountOnFlush + flushState.delCountOnFlush;\n      }\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, flushState.softDelCountOnFlush, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" + flushState.softDelCountOnFlush + \" soft-deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numFieldUpdates.get() == 0) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush, sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n      hasFlushed.set(Boolean.TRUE);\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.deleteDocIDs.size() > 0) {\n      flushState.liveDocs = new FixedBitSet(numDocsInRAM);\n      flushState.liveDocs.set(0, numDocsInRAM);\n      for(int delDocID : pendingUpdates.deleteDocIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.deleteDocIDs.size();\n      pendingUpdates.clearDeletedDocIds();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      DocIdSetIterator softDeletedDocs;\n      if (indexWriterConfig.getSoftDeletesField() != null) {\n        softDeletedDocs = consumer.getHasDocValues(indexWriterConfig.getSoftDeletesField());\n      } else {\n        softDeletedDocs = null;\n      }\n      sortMap = consumer.flush(flushState);\n      if (softDeletedDocs == null) {\n        flushState.softDelCountOnFlush = 0;\n      } else {\n        flushState.softDelCountOnFlush = PendingSoftDeletes.countSoftDeletes(softDeletedDocs, flushState.liveDocs);\n        assert flushState.segmentInfo.maxDoc() >= flushState.softDelCountOnFlush + flushState.delCountOnFlush;\n      }\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, flushState.softDelCountOnFlush, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" + flushState.softDelCountOnFlush + \" soft-deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numFieldUpdates.get() == 0) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush, sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7aff85e853fc8018761caa9a7803b1db411db8c","date":1586893039,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert flushPending.get() == Boolean.TRUE;\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (numDeletedDocIds > 0) {\n      flushState.liveDocs = new FixedBitSet(numDocsInRAM);\n      flushState.liveDocs.set(0, numDocsInRAM);\n      for (int i = 0; i < numDeletedDocIds; i++) {\n        flushState.liveDocs.clear(deleteDocIDs[i]);\n      }\n      flushState.delCountOnFlush = numDeletedDocIds;\n      bytesUsed.addAndGet(-(deleteDocIDs.length * Integer.SIZE));\n      deleteDocIDs = null;\n\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      DocIdSetIterator softDeletedDocs;\n      if (indexWriterConfig.getSoftDeletesField() != null) {\n        softDeletedDocs = consumer.getHasDocValues(indexWriterConfig.getSoftDeletesField());\n      } else {\n        softDeletedDocs = null;\n      }\n      sortMap = consumer.flush(flushState);\n      if (softDeletedDocs == null) {\n        flushState.softDelCountOnFlush = 0;\n      } else {\n        flushState.softDelCountOnFlush = PendingSoftDeletes.countSoftDeletes(softDeletedDocs, flushState.liveDocs);\n        assert flushState.segmentInfo.maxDoc() >= flushState.softDelCountOnFlush + flushState.delCountOnFlush;\n      }\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, flushState.softDelCountOnFlush, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" + flushState.softDelCountOnFlush + \" soft-deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numFieldUpdates.get() == 0) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush, sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n      hasFlushed.set(Boolean.TRUE);\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert flushPending.get() == Boolean.TRUE;\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.deleteDocIDs.size() > 0) {\n      flushState.liveDocs = new FixedBitSet(numDocsInRAM);\n      flushState.liveDocs.set(0, numDocsInRAM);\n      for(int delDocID : pendingUpdates.deleteDocIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.deleteDocIDs.size();\n      pendingUpdates.clearDeletedDocIds();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      DocIdSetIterator softDeletedDocs;\n      if (indexWriterConfig.getSoftDeletesField() != null) {\n        softDeletedDocs = consumer.getHasDocValues(indexWriterConfig.getSoftDeletesField());\n      } else {\n        softDeletedDocs = null;\n      }\n      sortMap = consumer.flush(flushState);\n      if (softDeletedDocs == null) {\n        flushState.softDelCountOnFlush = 0;\n      } else {\n        flushState.softDelCountOnFlush = PendingSoftDeletes.countSoftDeletes(softDeletedDocs, flushState.liveDocs);\n        assert flushState.segmentInfo.maxDoc() >= flushState.softDelCountOnFlush + flushState.delCountOnFlush;\n      }\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, flushState.softDelCountOnFlush, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" + flushState.softDelCountOnFlush + \" soft-deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numFieldUpdates.get() == 0) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush, sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n      hasFlushed.set(Boolean.TRUE);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"14654be3f7a82c9a3c52169e365baa55bfe64f66","date":1587212697,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert flushPending.get() == Boolean.TRUE;\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (numDeletedDocIds > 0) {\n      flushState.liveDocs = new FixedBitSet(numDocsInRAM);\n      flushState.liveDocs.set(0, numDocsInRAM);\n      for (int i = 0; i < numDeletedDocIds; i++) {\n        flushState.liveDocs.clear(deleteDocIDs[i]);\n      }\n      flushState.delCountOnFlush = numDeletedDocIds;\n      bytesUsed.addAndGet(-(deleteDocIDs.length * Integer.SIZE));\n      deleteDocIDs = null;\n\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      DocIdSetIterator softDeletedDocs;\n      if (indexWriterConfig.getSoftDeletesField() != null) {\n        softDeletedDocs = consumer.getHasDocValues(indexWriterConfig.getSoftDeletesField());\n      } else {\n        softDeletedDocs = null;\n      }\n      sortMap = consumer.flush(flushState);\n      if (softDeletedDocs == null) {\n        flushState.softDelCountOnFlush = 0;\n      } else {\n        flushState.softDelCountOnFlush = PendingSoftDeletes.countSoftDeletes(softDeletedDocs, flushState.liveDocs);\n        assert flushState.segmentInfo.maxDoc() >= flushState.softDelCountOnFlush + flushState.delCountOnFlush;\n      }\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, flushState.softDelCountOnFlush, -1L, -1L, -1L, StringHelper.randomId());\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" + flushState.softDelCountOnFlush + \" soft-deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numFieldUpdates.get() == 0) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush, sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n      hasFlushed.set(Boolean.TRUE);\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert flushPending.get() == Boolean.TRUE;\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (numDeletedDocIds > 0) {\n      flushState.liveDocs = new FixedBitSet(numDocsInRAM);\n      flushState.liveDocs.set(0, numDocsInRAM);\n      for (int i = 0; i < numDeletedDocIds; i++) {\n        flushState.liveDocs.clear(deleteDocIDs[i]);\n      }\n      flushState.delCountOnFlush = numDeletedDocIds;\n      bytesUsed.addAndGet(-(deleteDocIDs.length * Integer.SIZE));\n      deleteDocIDs = null;\n\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      DocIdSetIterator softDeletedDocs;\n      if (indexWriterConfig.getSoftDeletesField() != null) {\n        softDeletedDocs = consumer.getHasDocValues(indexWriterConfig.getSoftDeletesField());\n      } else {\n        softDeletedDocs = null;\n      }\n      sortMap = consumer.flush(flushState);\n      if (softDeletedDocs == null) {\n        flushState.softDelCountOnFlush = 0;\n      } else {\n        flushState.softDelCountOnFlush = PendingSoftDeletes.countSoftDeletes(softDeletedDocs, flushState.liveDocs);\n        assert flushState.segmentInfo.maxDoc() >= flushState.softDelCountOnFlush + flushState.delCountOnFlush;\n      }\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, flushState.softDelCountOnFlush, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" + flushState.softDelCountOnFlush + \" soft-deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numFieldUpdates.get() == 0) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush, sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n      hasFlushed.set(Boolean.TRUE);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f97270426d92300e08ac1bd1a4ef499ae02e88b7","date":1592503330,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert flushPending.get() == Boolean.TRUE;\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (numDeletedDocIds > 0) {\n      flushState.liveDocs = new FixedBitSet(numDocsInRAM);\n      flushState.liveDocs.set(0, numDocsInRAM);\n      for (int i = 0; i < numDeletedDocIds; i++) {\n        flushState.liveDocs.clear(deleteDocIDs[i]);\n      }\n      flushState.delCountOnFlush = numDeletedDocIds;\n      bytesUsed.addAndGet(-(deleteDocIDs.length * Integer.SIZE));\n      deleteDocIDs = null;\n\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      DocIdSetIterator softDeletedDocs;\n      if (getIndexWriterConfig().getSoftDeletesField() != null) {\n        softDeletedDocs = consumer.getHasDocValues(getIndexWriterConfig().getSoftDeletesField());\n      } else {\n        softDeletedDocs = null;\n      }\n      sortMap = consumer.flush(flushState);\n      if (softDeletedDocs == null) {\n        flushState.softDelCountOnFlush = 0;\n      } else {\n        flushState.softDelCountOnFlush = PendingSoftDeletes.countSoftDeletes(softDeletedDocs, flushState.liveDocs);\n        assert flushState.segmentInfo.maxDoc() >= flushState.softDelCountOnFlush + flushState.delCountOnFlush;\n      }\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, flushState.softDelCountOnFlush, -1L, -1L, -1L, StringHelper.randomId());\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" + flushState.softDelCountOnFlush + \" soft-deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numFieldUpdates.get() == 0) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush, sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n      hasFlushed.set(Boolean.TRUE);\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert flushPending.get() == Boolean.TRUE;\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (numDeletedDocIds > 0) {\n      flushState.liveDocs = new FixedBitSet(numDocsInRAM);\n      flushState.liveDocs.set(0, numDocsInRAM);\n      for (int i = 0; i < numDeletedDocIds; i++) {\n        flushState.liveDocs.clear(deleteDocIDs[i]);\n      }\n      flushState.delCountOnFlush = numDeletedDocIds;\n      bytesUsed.addAndGet(-(deleteDocIDs.length * Integer.SIZE));\n      deleteDocIDs = null;\n\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      DocIdSetIterator softDeletedDocs;\n      if (indexWriterConfig.getSoftDeletesField() != null) {\n        softDeletedDocs = consumer.getHasDocValues(indexWriterConfig.getSoftDeletesField());\n      } else {\n        softDeletedDocs = null;\n      }\n      sortMap = consumer.flush(flushState);\n      if (softDeletedDocs == null) {\n        flushState.softDelCountOnFlush = 0;\n      } else {\n        flushState.softDelCountOnFlush = PendingSoftDeletes.countSoftDeletes(softDeletedDocs, flushState.liveDocs);\n        assert flushState.segmentInfo.maxDoc() >= flushState.softDelCountOnFlush + flushState.delCountOnFlush;\n      }\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, flushState.softDelCountOnFlush, -1L, -1L, -1L, StringHelper.randomId());\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" + flushState.softDelCountOnFlush + \" soft-deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numFieldUpdates.get() == 0) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush, sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n      hasFlushed.set(Boolean.TRUE);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6926606ec5e0dd8d4ec79166d39a3b4ddb862bf4","date":1599581893,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert flushPending.get() == Boolean.TRUE;\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, ramBytesUsed())));\n    final double startMBUsed = ramBytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (numDeletedDocIds > 0) {\n      flushState.liveDocs = new FixedBitSet(numDocsInRAM);\n      flushState.liveDocs.set(0, numDocsInRAM);\n      for (int i = 0; i < numDeletedDocIds; i++) {\n        flushState.liveDocs.clear(deleteDocIDs[i]);\n      }\n      flushState.delCountOnFlush = numDeletedDocIds;\n      bytesUsed.addAndGet(-(deleteDocIDs.length * Integer.BYTES));\n      deleteDocIDs = null;\n\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      DocIdSetIterator softDeletedDocs;\n      if (getIndexWriterConfig().getSoftDeletesField() != null) {\n        softDeletedDocs = consumer.getHasDocValues(getIndexWriterConfig().getSoftDeletesField());\n      } else {\n        softDeletedDocs = null;\n      }\n      sortMap = consumer.flush(flushState);\n      if (softDeletedDocs == null) {\n        flushState.softDelCountOnFlush = 0;\n      } else {\n        flushState.softDelCountOnFlush = PendingSoftDeletes.countSoftDeletes(softDeletedDocs, flushState.liveDocs);\n        assert flushState.segmentInfo.maxDoc() >= flushState.softDelCountOnFlush + flushState.delCountOnFlush;\n      }\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, flushState.softDelCountOnFlush, -1L, -1L, -1L, StringHelper.randomId());\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" + flushState.softDelCountOnFlush + \" soft-deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numFieldUpdates.get() == 0) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush, sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n      hasFlushed.set(Boolean.TRUE);\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert flushPending.get() == Boolean.TRUE;\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (numDeletedDocIds > 0) {\n      flushState.liveDocs = new FixedBitSet(numDocsInRAM);\n      flushState.liveDocs.set(0, numDocsInRAM);\n      for (int i = 0; i < numDeletedDocIds; i++) {\n        flushState.liveDocs.clear(deleteDocIDs[i]);\n      }\n      flushState.delCountOnFlush = numDeletedDocIds;\n      bytesUsed.addAndGet(-(deleteDocIDs.length * Integer.SIZE));\n      deleteDocIDs = null;\n\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      DocIdSetIterator softDeletedDocs;\n      if (getIndexWriterConfig().getSoftDeletesField() != null) {\n        softDeletedDocs = consumer.getHasDocValues(getIndexWriterConfig().getSoftDeletesField());\n      } else {\n        softDeletedDocs = null;\n      }\n      sortMap = consumer.flush(flushState);\n      if (softDeletedDocs == null) {\n        flushState.softDelCountOnFlush = 0;\n      } else {\n        flushState.softDelCountOnFlush = PendingSoftDeletes.countSoftDeletes(softDeletedDocs, flushState.liveDocs);\n        assert flushState.segmentInfo.maxDoc() >= flushState.softDelCountOnFlush + flushState.delCountOnFlush;\n      }\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, flushState.softDelCountOnFlush, -1L, -1L, -1L, StringHelper.randomId());\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" + flushState.softDelCountOnFlush + \" soft-deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numFieldUpdates.get() == 0) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush, sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n      hasFlushed.set(Boolean.TRUE);\n    }\n  }\n\n","bugFix":null,"bugIntro":["3a1e047b18d79d7214c04b78dfa1c3e14f639425"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"49f1924bd448393fbdfef8b5ebed799f938169d3","date":1600069616,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert flushPending.get() == Boolean.TRUE;\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, ramBytesUsed())));\n    final double startMBUsed = ramBytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (numDeletedDocIds > 0) {\n      flushState.liveDocs = new FixedBitSet(numDocsInRAM);\n      flushState.liveDocs.set(0, numDocsInRAM);\n      for (int i = 0; i < numDeletedDocIds; i++) {\n        flushState.liveDocs.clear(deleteDocIDs[i]);\n      }\n      flushState.delCountOnFlush = numDeletedDocIds;\n      deleteDocIDs = new int[0];\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      DocIdSetIterator softDeletedDocs;\n      if (indexWriterConfig.getSoftDeletesField() != null) {\n        softDeletedDocs = consumer.getHasDocValues(indexWriterConfig.getSoftDeletesField());\n      } else {\n        softDeletedDocs = null;\n      }\n      sortMap = consumer.flush(flushState);\n      if (softDeletedDocs == null) {\n        flushState.softDelCountOnFlush = 0;\n      } else {\n        flushState.softDelCountOnFlush = PendingSoftDeletes.countSoftDeletes(softDeletedDocs, flushState.liveDocs);\n        assert flushState.segmentInfo.maxDoc() >= flushState.softDelCountOnFlush + flushState.delCountOnFlush;\n      }\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, flushState.softDelCountOnFlush, -1L, -1L, -1L, StringHelper.randomId());\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" + flushState.softDelCountOnFlush + \" soft-deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numFieldUpdates.get() == 0) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush, sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n      hasFlushed.set(Boolean.TRUE);\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert flushPending.get() == Boolean.TRUE;\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, ramBytesUsed())));\n    final double startMBUsed = ramBytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (numDeletedDocIds > 0) {\n      flushState.liveDocs = new FixedBitSet(numDocsInRAM);\n      flushState.liveDocs.set(0, numDocsInRAM);\n      for (int i = 0; i < numDeletedDocIds; i++) {\n        flushState.liveDocs.clear(deleteDocIDs[i]);\n      }\n      flushState.delCountOnFlush = numDeletedDocIds;\n      bytesUsed.addAndGet(-(deleteDocIDs.length * Integer.BYTES));\n      deleteDocIDs = null;\n\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      DocIdSetIterator softDeletedDocs;\n      if (getIndexWriterConfig().getSoftDeletesField() != null) {\n        softDeletedDocs = consumer.getHasDocValues(getIndexWriterConfig().getSoftDeletesField());\n      } else {\n        softDeletedDocs = null;\n      }\n      sortMap = consumer.flush(flushState);\n      if (softDeletedDocs == null) {\n        flushState.softDelCountOnFlush = 0;\n      } else {\n        flushState.softDelCountOnFlush = PendingSoftDeletes.countSoftDeletes(softDeletedDocs, flushState.liveDocs);\n        assert flushState.segmentInfo.maxDoc() >= flushState.softDelCountOnFlush + flushState.delCountOnFlush;\n      }\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, flushState.softDelCountOnFlush, -1L, -1L, -1L, StringHelper.randomId());\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" + flushState.softDelCountOnFlush + \" soft-deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numFieldUpdates.get() == 0) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush, sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n      hasFlushed.set(Boolean.TRUE);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0dcf8f79417865e5028d753e669fae06457e8369","date":1600073240,"type":3,"author":"noblepaul","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert flushPending.get() == Boolean.TRUE;\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, ramBytesUsed())));\n    final double startMBUsed = ramBytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (numDeletedDocIds > 0) {\n      flushState.liveDocs = new FixedBitSet(numDocsInRAM);\n      flushState.liveDocs.set(0, numDocsInRAM);\n      for (int i = 0; i < numDeletedDocIds; i++) {\n        flushState.liveDocs.clear(deleteDocIDs[i]);\n      }\n      flushState.delCountOnFlush = numDeletedDocIds;\n      deleteDocIDs = new int[0];\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      DocIdSetIterator softDeletedDocs;\n      if (indexWriterConfig.getSoftDeletesField() != null) {\n        softDeletedDocs = consumer.getHasDocValues(indexWriterConfig.getSoftDeletesField());\n      } else {\n        softDeletedDocs = null;\n      }\n      sortMap = consumer.flush(flushState);\n      if (softDeletedDocs == null) {\n        flushState.softDelCountOnFlush = 0;\n      } else {\n        flushState.softDelCountOnFlush = PendingSoftDeletes.countSoftDeletes(softDeletedDocs, flushState.liveDocs);\n        assert flushState.segmentInfo.maxDoc() >= flushState.softDelCountOnFlush + flushState.delCountOnFlush;\n      }\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, flushState.softDelCountOnFlush, -1L, -1L, -1L, StringHelper.randomId());\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" + flushState.softDelCountOnFlush + \" soft-deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numFieldUpdates.get() == 0) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush, sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n      hasFlushed.set(Boolean.TRUE);\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert flushPending.get() == Boolean.TRUE;\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, ramBytesUsed())));\n    final double startMBUsed = ramBytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (numDeletedDocIds > 0) {\n      flushState.liveDocs = new FixedBitSet(numDocsInRAM);\n      flushState.liveDocs.set(0, numDocsInRAM);\n      for (int i = 0; i < numDeletedDocIds; i++) {\n        flushState.liveDocs.clear(deleteDocIDs[i]);\n      }\n      flushState.delCountOnFlush = numDeletedDocIds;\n      bytesUsed.addAndGet(-(deleteDocIDs.length * Integer.BYTES));\n      deleteDocIDs = null;\n\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      DocIdSetIterator softDeletedDocs;\n      if (getIndexWriterConfig().getSoftDeletesField() != null) {\n        softDeletedDocs = consumer.getHasDocValues(getIndexWriterConfig().getSoftDeletesField());\n      } else {\n        softDeletedDocs = null;\n      }\n      sortMap = consumer.flush(flushState);\n      if (softDeletedDocs == null) {\n        flushState.softDelCountOnFlush = 0;\n      } else {\n        flushState.softDelCountOnFlush = PendingSoftDeletes.countSoftDeletes(softDeletedDocs, flushState.liveDocs);\n        assert flushState.segmentInfo.maxDoc() >= flushState.softDelCountOnFlush + flushState.delCountOnFlush;\n      }\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, flushState.softDelCountOnFlush, -1L, -1L, -1L, StringHelper.randomId());\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" + flushState.softDelCountOnFlush + \" soft-deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numFieldUpdates.get() == 0) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush, sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n      hasFlushed.set(Boolean.TRUE);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7a6f8af01d9b3067b143bbdc0a492720e2af97cf","date":1600157724,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert flushPending.get() == Boolean.TRUE;\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, ramBytesUsed())));\n    final double startMBUsed = ramBytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (numDeletedDocIds > 0) {\n      flushState.liveDocs = new FixedBitSet(numDocsInRAM);\n      flushState.liveDocs.set(0, numDocsInRAM);\n      for (int i = 0; i < numDeletedDocIds; i++) {\n        flushState.liveDocs.clear(deleteDocIDs[i]);\n      }\n      flushState.delCountOnFlush = numDeletedDocIds;\n      deleteDocIDs = new int[0];\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      DocIdSetIterator softDeletedDocs;\n      if (indexWriterConfig.getSoftDeletesField() != null) {\n        softDeletedDocs = indexingChain.getHasDocValues(indexWriterConfig.getSoftDeletesField());\n      } else {\n        softDeletedDocs = null;\n      }\n      sortMap = indexingChain.flush(flushState);\n      if (softDeletedDocs == null) {\n        flushState.softDelCountOnFlush = 0;\n      } else {\n        flushState.softDelCountOnFlush = PendingSoftDeletes.countSoftDeletes(softDeletedDocs, flushState.liveDocs);\n        assert flushState.segmentInfo.maxDoc() >= flushState.softDelCountOnFlush + flushState.delCountOnFlush;\n      }\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, flushState.softDelCountOnFlush, -1L, -1L, -1L, StringHelper.randomId());\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" + flushState.softDelCountOnFlush + \" soft-deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numFieldUpdates.get() == 0) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush, sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n      hasFlushed.set(Boolean.TRUE);\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert flushPending.get() == Boolean.TRUE;\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, ramBytesUsed())));\n    final double startMBUsed = ramBytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (numDeletedDocIds > 0) {\n      flushState.liveDocs = new FixedBitSet(numDocsInRAM);\n      flushState.liveDocs.set(0, numDocsInRAM);\n      for (int i = 0; i < numDeletedDocIds; i++) {\n        flushState.liveDocs.clear(deleteDocIDs[i]);\n      }\n      flushState.delCountOnFlush = numDeletedDocIds;\n      deleteDocIDs = new int[0];\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      DocIdSetIterator softDeletedDocs;\n      if (indexWriterConfig.getSoftDeletesField() != null) {\n        softDeletedDocs = consumer.getHasDocValues(indexWriterConfig.getSoftDeletesField());\n      } else {\n        softDeletedDocs = null;\n      }\n      sortMap = consumer.flush(flushState);\n      if (softDeletedDocs == null) {\n        flushState.softDelCountOnFlush = 0;\n      } else {\n        flushState.softDelCountOnFlush = PendingSoftDeletes.countSoftDeletes(softDeletedDocs, flushState.liveDocs);\n        assert flushState.segmentInfo.maxDoc() >= flushState.softDelCountOnFlush + flushState.delCountOnFlush;\n      }\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, flushState.softDelCountOnFlush, -1L, -1L, -1L, StringHelper.randomId());\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" + flushState.softDelCountOnFlush + \" soft-deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numFieldUpdates.get() == 0) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush, sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n      hasFlushed.set(Boolean.TRUE);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"680b6449f09827f58fe987aff279e014c311d966","date":1600247985,"type":3,"author":"noblepaul","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert flushPending.get() == Boolean.TRUE;\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, ramBytesUsed())));\n    final double startMBUsed = ramBytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (numDeletedDocIds > 0) {\n      flushState.liveDocs = new FixedBitSet(numDocsInRAM);\n      flushState.liveDocs.set(0, numDocsInRAM);\n      for (int i = 0; i < numDeletedDocIds; i++) {\n        flushState.liveDocs.clear(deleteDocIDs[i]);\n      }\n      flushState.delCountOnFlush = numDeletedDocIds;\n      deleteDocIDs = new int[0];\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      DocIdSetIterator softDeletedDocs;\n      if (indexWriterConfig.getSoftDeletesField() != null) {\n        softDeletedDocs = indexingChain.getHasDocValues(indexWriterConfig.getSoftDeletesField());\n      } else {\n        softDeletedDocs = null;\n      }\n      sortMap = indexingChain.flush(flushState);\n      if (softDeletedDocs == null) {\n        flushState.softDelCountOnFlush = 0;\n      } else {\n        flushState.softDelCountOnFlush = PendingSoftDeletes.countSoftDeletes(softDeletedDocs, flushState.liveDocs);\n        assert flushState.segmentInfo.maxDoc() >= flushState.softDelCountOnFlush + flushState.delCountOnFlush;\n      }\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, flushState.softDelCountOnFlush, -1L, -1L, -1L, StringHelper.randomId());\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" + flushState.softDelCountOnFlush + \" soft-deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numFieldUpdates.get() == 0) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush, sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n      hasFlushed.set(Boolean.TRUE);\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert flushPending.get() == Boolean.TRUE;\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, ramBytesUsed())));\n    final double startMBUsed = ramBytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (numDeletedDocIds > 0) {\n      flushState.liveDocs = new FixedBitSet(numDocsInRAM);\n      flushState.liveDocs.set(0, numDocsInRAM);\n      for (int i = 0; i < numDeletedDocIds; i++) {\n        flushState.liveDocs.clear(deleteDocIDs[i]);\n      }\n      flushState.delCountOnFlush = numDeletedDocIds;\n      deleteDocIDs = new int[0];\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      DocIdSetIterator softDeletedDocs;\n      if (indexWriterConfig.getSoftDeletesField() != null) {\n        softDeletedDocs = consumer.getHasDocValues(indexWriterConfig.getSoftDeletesField());\n      } else {\n        softDeletedDocs = null;\n      }\n      sortMap = consumer.flush(flushState);\n      if (softDeletedDocs == null) {\n        flushState.softDelCountOnFlush = 0;\n      } else {\n        flushState.softDelCountOnFlush = PendingSoftDeletes.countSoftDeletes(softDeletedDocs, flushState.liveDocs);\n        assert flushState.segmentInfo.maxDoc() >= flushState.softDelCountOnFlush + flushState.delCountOnFlush;\n      }\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, flushState.softDelCountOnFlush, -1L, -1L, -1L, StringHelper.randomId());\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" + flushState.softDelCountOnFlush + \" soft-deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numFieldUpdates.get() == 0) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush, sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n      hasFlushed.set(Boolean.TRUE);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3a1e047b18d79d7214c04b78dfa1c3e14f639425","date":1600444745,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert flushPending.get() == Boolean.TRUE;\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, lastCommittedBytesUsed)));\n    final double startMBUsed = lastCommittedBytesUsed / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (numDeletedDocIds > 0) {\n      flushState.liveDocs = new FixedBitSet(numDocsInRAM);\n      flushState.liveDocs.set(0, numDocsInRAM);\n      for (int i = 0; i < numDeletedDocIds; i++) {\n        flushState.liveDocs.clear(deleteDocIDs[i]);\n      }\n      flushState.delCountOnFlush = numDeletedDocIds;\n      deleteDocIDs = new int[0];\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      DocIdSetIterator softDeletedDocs;\n      if (indexWriterConfig.getSoftDeletesField() != null) {\n        softDeletedDocs = indexingChain.getHasDocValues(indexWriterConfig.getSoftDeletesField());\n      } else {\n        softDeletedDocs = null;\n      }\n      sortMap = indexingChain.flush(flushState);\n      if (softDeletedDocs == null) {\n        flushState.softDelCountOnFlush = 0;\n      } else {\n        flushState.softDelCountOnFlush = PendingSoftDeletes.countSoftDeletes(softDeletedDocs, flushState.liveDocs);\n        assert flushState.segmentInfo.maxDoc() >= flushState.softDelCountOnFlush + flushState.delCountOnFlush;\n      }\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, flushState.softDelCountOnFlush, -1L, -1L, -1L, StringHelper.randomId());\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" + flushState.softDelCountOnFlush + \" soft-deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numFieldUpdates.get() == 0) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush, sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n      hasFlushed.set(Boolean.TRUE);\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert flushPending.get() == Boolean.TRUE;\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, ramBytesUsed())));\n    final double startMBUsed = ramBytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (numDeletedDocIds > 0) {\n      flushState.liveDocs = new FixedBitSet(numDocsInRAM);\n      flushState.liveDocs.set(0, numDocsInRAM);\n      for (int i = 0; i < numDeletedDocIds; i++) {\n        flushState.liveDocs.clear(deleteDocIDs[i]);\n      }\n      flushState.delCountOnFlush = numDeletedDocIds;\n      deleteDocIDs = new int[0];\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      DocIdSetIterator softDeletedDocs;\n      if (indexWriterConfig.getSoftDeletesField() != null) {\n        softDeletedDocs = indexingChain.getHasDocValues(indexWriterConfig.getSoftDeletesField());\n      } else {\n        softDeletedDocs = null;\n      }\n      sortMap = indexingChain.flush(flushState);\n      if (softDeletedDocs == null) {\n        flushState.softDelCountOnFlush = 0;\n      } else {\n        flushState.softDelCountOnFlush = PendingSoftDeletes.countSoftDeletes(softDeletedDocs, flushState.liveDocs);\n        assert flushState.segmentInfo.maxDoc() >= flushState.softDelCountOnFlush + flushState.delCountOnFlush;\n      }\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, flushState.softDelCountOnFlush, -1L, -1L, -1L, StringHelper.randomId());\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" + flushState.softDelCountOnFlush + \" soft-deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numFieldUpdates.get() == 0) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush, sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n      hasFlushed.set(Boolean.TRUE);\n    }\n  }\n\n","bugFix":["6926606ec5e0dd8d4ec79166d39a3b4ddb862bf4"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"6926606ec5e0dd8d4ec79166d39a3b4ddb862bf4":["f97270426d92300e08ac1bd1a4ef499ae02e88b7"],"264935965977b4a9e2f3920420647072c9c49176":["28211671436f185419b3f7e53ccfc3911441ab65"],"49f1924bd448393fbdfef8b5ebed799f938169d3":["6926606ec5e0dd8d4ec79166d39a3b4ddb862bf4"],"7a6f8af01d9b3067b143bbdc0a492720e2af97cf":["49f1924bd448393fbdfef8b5ebed799f938169d3"],"86a2e8a56b368d37ef3ba7180541fa317d6fd6c7":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"0dcf8f79417865e5028d753e669fae06457e8369":["6926606ec5e0dd8d4ec79166d39a3b4ddb862bf4","49f1924bd448393fbdfef8b5ebed799f938169d3"],"28211671436f185419b3f7e53ccfc3911441ab65":["8f2203cb8ae87188877cfbf6ad170c5738a0aad5"],"680b6449f09827f58fe987aff279e014c311d966":["0dcf8f79417865e5028d753e669fae06457e8369","7a6f8af01d9b3067b143bbdc0a492720e2af97cf"],"3a1e047b18d79d7214c04b78dfa1c3e14f639425":["680b6449f09827f58fe987aff279e014c311d966"],"e7aff85e853fc8018761caa9a7803b1db411db8c":["264935965977b4a9e2f3920420647072c9c49176"],"14654be3f7a82c9a3c52169e365baa55bfe64f66":["e7aff85e853fc8018761caa9a7803b1db411db8c"],"fb8a3dfca2d8b39c20bdfc87eb7171c06ea9400d":["86a2e8a56b368d37ef3ba7180541fa317d6fd6c7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b70042a8a492f7054d480ccdd2be9796510d4327":["fb8a3dfca2d8b39c20bdfc87eb7171c06ea9400d","8f2203cb8ae87188877cfbf6ad170c5738a0aad5"],"8f2203cb8ae87188877cfbf6ad170c5738a0aad5":["fb8a3dfca2d8b39c20bdfc87eb7171c06ea9400d"],"f97270426d92300e08ac1bd1a4ef499ae02e88b7":["14654be3f7a82c9a3c52169e365baa55bfe64f66"],"f592209545c71895260367152601e9200399776d":["fb8a3dfca2d8b39c20bdfc87eb7171c06ea9400d","8f2203cb8ae87188877cfbf6ad170c5738a0aad5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a1e047b18d79d7214c04b78dfa1c3e14f639425"]},"commit2Childs":{"6926606ec5e0dd8d4ec79166d39a3b4ddb862bf4":["49f1924bd448393fbdfef8b5ebed799f938169d3","0dcf8f79417865e5028d753e669fae06457e8369"],"264935965977b4a9e2f3920420647072c9c49176":["e7aff85e853fc8018761caa9a7803b1db411db8c"],"49f1924bd448393fbdfef8b5ebed799f938169d3":["7a6f8af01d9b3067b143bbdc0a492720e2af97cf","0dcf8f79417865e5028d753e669fae06457e8369"],"7a6f8af01d9b3067b143bbdc0a492720e2af97cf":["680b6449f09827f58fe987aff279e014c311d966"],"86a2e8a56b368d37ef3ba7180541fa317d6fd6c7":["fb8a3dfca2d8b39c20bdfc87eb7171c06ea9400d"],"0dcf8f79417865e5028d753e669fae06457e8369":["680b6449f09827f58fe987aff279e014c311d966"],"28211671436f185419b3f7e53ccfc3911441ab65":["264935965977b4a9e2f3920420647072c9c49176"],"680b6449f09827f58fe987aff279e014c311d966":["3a1e047b18d79d7214c04b78dfa1c3e14f639425"],"3a1e047b18d79d7214c04b78dfa1c3e14f639425":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"e7aff85e853fc8018761caa9a7803b1db411db8c":["14654be3f7a82c9a3c52169e365baa55bfe64f66"],"14654be3f7a82c9a3c52169e365baa55bfe64f66":["f97270426d92300e08ac1bd1a4ef499ae02e88b7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["86a2e8a56b368d37ef3ba7180541fa317d6fd6c7"],"fb8a3dfca2d8b39c20bdfc87eb7171c06ea9400d":["b70042a8a492f7054d480ccdd2be9796510d4327","8f2203cb8ae87188877cfbf6ad170c5738a0aad5","f592209545c71895260367152601e9200399776d"],"b70042a8a492f7054d480ccdd2be9796510d4327":[],"8f2203cb8ae87188877cfbf6ad170c5738a0aad5":["28211671436f185419b3f7e53ccfc3911441ab65","b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d"],"f97270426d92300e08ac1bd1a4ef499ae02e88b7":["6926606ec5e0dd8d4ec79166d39a3b4ddb862bf4"],"f592209545c71895260367152601e9200399776d":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}