{"path":"src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","commits":[{"id":"68df8db3f6c0c0ebbd1e40ba638115a748fb6a2a","date":1240390408,"type":0,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, null, false));\n\n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.solr.analysis.EnglishPorterFilter\");\n    assertNotNull(\"Expecting the 'EnglishPorterFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n    tokenList = valueResult.get(\"org.apache.solr.analysis.EnglishPorterFilter\");\n    assertNotNull(\"Expecting the 'EnglishPorterFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["78da6990f140a712adfb145ea6faa99db270e1bc","fb1921ba901ad34c1b448d0b8c98a563dfea7dd9","fb1921ba901ad34c1b448d0b8c98a563dfea7dd9","fb1921ba901ad34c1b448d0b8c98a563dfea7dd9"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"78da6990f140a712adfb145ea6faa99db270e1bc","date":1249582196,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.solr.analysis.EnglishPorterFilter\");\n    assertNotNull(\"Expecting the 'EnglishPorterFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n    tokenList = valueResult.get(\"org.apache.solr.analysis.EnglishPorterFilter\");\n    assertNotNull(\"Expecting the 'EnglishPorterFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n  }\n\n","sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, null, false));\n\n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.solr.analysis.EnglishPorterFilter\");\n    assertNotNull(\"Expecting the 'EnglishPorterFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n    tokenList = valueResult.get(\"org.apache.solr.analysis.EnglishPorterFilter\");\n    assertNotNull(\"Expecting the 'EnglishPorterFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n  }\n\n","bugFix":["68df8db3f6c0c0ebbd1e40ba638115a748fb6a2a"],"bugIntro":["fb1921ba901ad34c1b448d0b8c98a563dfea7dd9","fb1921ba901ad34c1b448d0b8c98a563dfea7dd9","fb1921ba901ad34c1b448d0b8c98a563dfea7dd9"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.solr.analysis.EnglishPorterFilter\");\n    assertNotNull(\"Expecting the 'EnglishPorterFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n    tokenList = valueResult.get(\"org.apache.solr.analysis.EnglishPorterFilter\");\n    assertNotNull(\"Expecting the 'EnglishPorterFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n  }\n\n","sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.solr.analysis.EnglishPorterFilter\");\n    assertNotNull(\"Expecting the 'EnglishPorterFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n    tokenList = valueResult.get(\"org.apache.solr.analysis.EnglishPorterFilter\");\n    assertNotNull(\"Expecting the 'EnglishPorterFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"78da6990f140a712adfb145ea6faa99db270e1bc":["68df8db3f6c0c0ebbd1e40ba638115a748fb6a2a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"68df8db3f6c0c0ebbd1e40ba638115a748fb6a2a":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"ad94625fb8d088209f46650c8097196fec67f00c":["78da6990f140a712adfb145ea6faa99db270e1bc"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"78da6990f140a712adfb145ea6faa99db270e1bc":["ad94625fb8d088209f46650c8097196fec67f00c"],"68df8db3f6c0c0ebbd1e40ba638115a748fb6a2a":["78da6990f140a712adfb145ea6faa99db270e1bc"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["68df8db3f6c0c0ebbd1e40ba638115a748fb6a2a"],"ad94625fb8d088209f46650c8097196fec67f00c":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ad94625fb8d088209f46650c8097196fec67f00c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"pathCommit":null}