{"path":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#analyze(Collection[Token],Reader,int,int).mjava","commits":[{"id":"0ad9ec888e587ca9a3279368245cdf00aabdc108","date":1338832525,"type":1,"author":"James Dyer","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#analyze(Collection[Token],Reader,int,int).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#analyze(Collection[Token],Reader,int).mjava","sourceNew":"  protected void analyze(Collection<Token> result, Reader text, int offset, int flagsAttValue) throws IOException {\n    TokenStream stream = analyzer.tokenStream(\"\", text);\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = stream.addAttribute(CharTermAttribute.class);\n    TypeAttribute typeAtt = stream.addAttribute(TypeAttribute.class);\n    PayloadAttribute payloadAtt = stream.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = stream.addAttribute(PositionIncrementAttribute.class);\n    OffsetAttribute offsetAtt = stream.addAttribute(OffsetAttribute.class);\n    stream.reset();\n    while (stream.incrementToken()) {      \n      Token token = new Token();\n      token.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n      token.setStartOffset(offset + offsetAtt.startOffset());\n      token.setEndOffset(offset + offsetAtt.endOffset());\n      token.setFlags(flagsAttValue); //overwriting any flags already set...\n      token.setType(typeAtt.type());\n      token.setPayload(payloadAtt.getPayload());\n      token.setPositionIncrement(posIncAtt.getPositionIncrement());\n      result.add(token);\n    }\n    stream.end();\n    stream.close();\n  }\n\n","sourceOld":"  protected void analyze(Collection<Token> result, Reader text, int offset) throws IOException {\n    TokenStream stream = analyzer.tokenStream(\"\", text);\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = stream.addAttribute(CharTermAttribute.class);\n    FlagsAttribute flagsAtt = stream.addAttribute(FlagsAttribute.class);\n    TypeAttribute typeAtt = stream.addAttribute(TypeAttribute.class);\n    PayloadAttribute payloadAtt = stream.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = stream.addAttribute(PositionIncrementAttribute.class);\n    OffsetAttribute offsetAtt = stream.addAttribute(OffsetAttribute.class);\n    stream.reset();\n    while (stream.incrementToken()) {\n      Token token = new Token();\n      token.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n      token.setStartOffset(offset + offsetAtt.startOffset());\n      token.setEndOffset(offset + offsetAtt.endOffset());\n      token.setFlags(flagsAtt.getFlags());\n      token.setType(typeAtt.type());\n      token.setPayload(payloadAtt.getPayload());\n      token.setPositionIncrement(posIncAtt.getPositionIncrement());\n      result.add(token);\n    }\n    stream.end();\n    stream.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cd65a3c65e7917a381c935b0b663d8e783bd9a1e","date":1339372221,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#analyze(Collection[Token],Reader,int,int).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#analyze(Collection[Token],Reader,int,int).mjava","sourceNew":"  protected void analyze(Collection<Token> result, Reader text, int offset, int flagsAttValue) throws IOException {\n    TokenStream stream = analyzer.tokenStream(\"\", text);\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = stream.addAttribute(CharTermAttribute.class);\n    TypeAttribute typeAtt = stream.addAttribute(TypeAttribute.class);\n    PayloadAttribute payloadAtt = stream.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = stream.addAttribute(PositionIncrementAttribute.class);\n    OffsetAttribute offsetAtt = stream.addAttribute(OffsetAttribute.class);\n    stream.reset();\n    while (stream.incrementToken()) {      \n      Token token = new Token();\n      token.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n      token.setOffset(offset + offsetAtt.startOffset(), \n                      offset + offsetAtt.endOffset());\n      token.setFlags(flagsAttValue); //overwriting any flags already set...\n      token.setType(typeAtt.type());\n      token.setPayload(payloadAtt.getPayload());\n      token.setPositionIncrement(posIncAtt.getPositionIncrement());\n      result.add(token);\n    }\n    stream.end();\n    stream.close();\n  }\n\n","sourceOld":"  protected void analyze(Collection<Token> result, Reader text, int offset, int flagsAttValue) throws IOException {\n    TokenStream stream = analyzer.tokenStream(\"\", text);\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = stream.addAttribute(CharTermAttribute.class);\n    TypeAttribute typeAtt = stream.addAttribute(TypeAttribute.class);\n    PayloadAttribute payloadAtt = stream.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = stream.addAttribute(PositionIncrementAttribute.class);\n    OffsetAttribute offsetAtt = stream.addAttribute(OffsetAttribute.class);\n    stream.reset();\n    while (stream.incrementToken()) {      \n      Token token = new Token();\n      token.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n      token.setStartOffset(offset + offsetAtt.startOffset());\n      token.setEndOffset(offset + offsetAtt.endOffset());\n      token.setFlags(flagsAttValue); //overwriting any flags already set...\n      token.setType(typeAtt.type());\n      token.setPayload(payloadAtt.getPayload());\n      token.setPositionIncrement(posIncAtt.getPositionIncrement());\n      result.add(token);\n    }\n    stream.end();\n    stream.close();\n  }\n\n","bugFix":["dfe519e9d72e08fa9d4ffdec80b908a20c8c2b5e"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c83d6c4335f31cae14f625a222bc842f20073dcd","date":1373306148,"type":5,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#analyze(Collection[Token],String,int,int).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#analyze(Collection[Token],Reader,int,int).mjava","sourceNew":"  protected void analyze(Collection<Token> result, String text, int offset, int flagsAttValue) throws IOException {\n    TokenStream stream = analyzer.tokenStream(\"\", text);\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = stream.addAttribute(CharTermAttribute.class);\n    TypeAttribute typeAtt = stream.addAttribute(TypeAttribute.class);\n    PayloadAttribute payloadAtt = stream.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = stream.addAttribute(PositionIncrementAttribute.class);\n    OffsetAttribute offsetAtt = stream.addAttribute(OffsetAttribute.class);\n    stream.reset();\n    while (stream.incrementToken()) {      \n      Token token = new Token();\n      token.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n      token.setOffset(offset + offsetAtt.startOffset(), \n                      offset + offsetAtt.endOffset());\n      token.setFlags(flagsAttValue); //overwriting any flags already set...\n      token.setType(typeAtt.type());\n      token.setPayload(payloadAtt.getPayload());\n      token.setPositionIncrement(posIncAtt.getPositionIncrement());\n      result.add(token);\n    }\n    stream.end();\n    stream.close();\n  }\n\n","sourceOld":"  protected void analyze(Collection<Token> result, Reader text, int offset, int flagsAttValue) throws IOException {\n    TokenStream stream = analyzer.tokenStream(\"\", text);\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = stream.addAttribute(CharTermAttribute.class);\n    TypeAttribute typeAtt = stream.addAttribute(TypeAttribute.class);\n    PayloadAttribute payloadAtt = stream.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = stream.addAttribute(PositionIncrementAttribute.class);\n    OffsetAttribute offsetAtt = stream.addAttribute(OffsetAttribute.class);\n    stream.reset();\n    while (stream.incrementToken()) {      \n      Token token = new Token();\n      token.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n      token.setOffset(offset + offsetAtt.startOffset(), \n                      offset + offsetAtt.endOffset());\n      token.setFlags(flagsAttValue); //overwriting any flags already set...\n      token.setType(typeAtt.type());\n      token.setPayload(payloadAtt.getPayload());\n      token.setPositionIncrement(posIncAtt.getPositionIncrement());\n      result.add(token);\n    }\n    stream.end();\n    stream.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":4,"author":"Han Jiang","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#analyze(Collection[Token],Reader,int,int).mjava","sourceNew":null,"sourceOld":"  protected void analyze(Collection<Token> result, Reader text, int offset, int flagsAttValue) throws IOException {\n    TokenStream stream = analyzer.tokenStream(\"\", text);\n    // TODO: support custom attributes\n    CharTermAttribute termAtt = stream.addAttribute(CharTermAttribute.class);\n    TypeAttribute typeAtt = stream.addAttribute(TypeAttribute.class);\n    PayloadAttribute payloadAtt = stream.addAttribute(PayloadAttribute.class);\n    PositionIncrementAttribute posIncAtt = stream.addAttribute(PositionIncrementAttribute.class);\n    OffsetAttribute offsetAtt = stream.addAttribute(OffsetAttribute.class);\n    stream.reset();\n    while (stream.incrementToken()) {      \n      Token token = new Token();\n      token.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n      token.setOffset(offset + offsetAtt.startOffset(), \n                      offset + offsetAtt.endOffset());\n      token.setFlags(flagsAttValue); //overwriting any flags already set...\n      token.setType(typeAtt.type());\n      token.setPayload(payloadAtt.getPayload());\n      token.setPositionIncrement(posIncAtt.getPositionIncrement());\n      result.add(token);\n    }\n    stream.end();\n    stream.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0ad9ec888e587ca9a3279368245cdf00aabdc108":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd65a3c65e7917a381c935b0b663d8e783bd9a1e":["0ad9ec888e587ca9a3279368245cdf00aabdc108"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["cd65a3c65e7917a381c935b0b663d8e783bd9a1e","c83d6c4335f31cae14f625a222bc842f20073dcd"],"c83d6c4335f31cae14f625a222bc842f20073dcd":["cd65a3c65e7917a381c935b0b663d8e783bd9a1e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c83d6c4335f31cae14f625a222bc842f20073dcd"]},"commit2Childs":{"0ad9ec888e587ca9a3279368245cdf00aabdc108":["cd65a3c65e7917a381c935b0b663d8e783bd9a1e"],"cd65a3c65e7917a381c935b0b663d8e783bd9a1e":["37a0f60745e53927c4c876cfe5b5a58170f0646c","c83d6c4335f31cae14f625a222bc842f20073dcd"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":[],"c83d6c4335f31cae14f625a222bc842f20073dcd":["37a0f60745e53927c4c876cfe5b5a58170f0646c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0ad9ec888e587ca9a3279368245cdf00aabdc108"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["37a0f60745e53927c4c876cfe5b5a58170f0646c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}