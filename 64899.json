{"path":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,IOContext,int,String).mjava","commits":[{"id":"7b91922b55d15444d554721b352861d028eb8278","date":1320421415,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,IOContext,int,String).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,IOContext,int,int).mjava","sourceNew":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, IOContext context,\n                          int termsCacheSize, String segmentSuffix)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    // this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, BlockTermsWriter.TERMS_EXTENSION),\n                       context);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.indexOptions == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        final long sumDocFreq = in.readVLong();\n        final int docCount = in.readVInt();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq, sumDocFreq, docCount));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","sourceOld":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, IOContext context,\n                          int termsCacheSize, int codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    // this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       context);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.indexOptions == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        final long sumDocFreq = in.readVLong();\n        final int docCount = in.readVInt();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq, sumDocFreq, docCount));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3cc749c053615f5871f3b95715fe292f34e70a53","date":1321470575,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,IOContext,int,String).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,IOContext,int,String).mjava","sourceNew":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, IOContext context,\n                          int termsCacheSize, String segmentSuffix)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    // this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, BlockTermsWriter.TERMS_EXTENSION),\n                       context);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.indexOptions == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        final long sumDocFreq = in.readVLong();\n        final int docCount = in.readVInt();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq, sumDocFreq, docCount));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","sourceOld":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, IOContext context,\n                          int termsCacheSize, String segmentSuffix)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    // this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, BlockTermsWriter.TERMS_EXTENSION),\n                       context);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.indexOptions == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        final long sumDocFreq = in.readVLong();\n        final int docCount = in.readVInt();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq, sumDocFreq, docCount));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0ae5e3ed1232483b7b8a014f175a5fe43595982","date":1324062192,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,IOContext,int,String).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,IOContext,int,String).mjava","sourceNew":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, IOContext context,\n                          int termsCacheSize, String segmentSuffix)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    // this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, BlockTermsWriter.TERMS_EXTENSION),\n                       context);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.indexOptions == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        final long sumDocFreq = in.readVLong();\n        final int docCount = in.readVInt();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq, sumDocFreq, docCount));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","sourceOld":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, IOContext context,\n                          int termsCacheSize, String segmentSuffix)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    // this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, BlockTermsWriter.TERMS_EXTENSION),\n                       context);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.indexOptions == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        final long sumDocFreq = in.readVLong();\n        final int docCount = in.readVInt();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq, sumDocFreq, docCount));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7b91922b55d15444d554721b352861d028eb8278":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cc749c053615f5871f3b95715fe292f34e70a53":["7b91922b55d15444d554721b352861d028eb8278"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["3cc749c053615f5871f3b95715fe292f34e70a53"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"]},"commit2Childs":{"7b91922b55d15444d554721b352861d028eb8278":["3cc749c053615f5871f3b95715fe292f34e70a53"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["7b91922b55d15444d554721b352861d028eb8278"],"3cc749c053615f5871f3b95715fe292f34e70a53":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}