{"path":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestIndexSplitter#testDeleteThenOptimize().mjava","commits":[{"id":"fec0d7b897279d9441884bfaa0cb01dd9a3cd58c","date":1307835543,"type":0,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestIndexSplitter#testDeleteThenOptimize().mjava","pathOld":"/dev/null","sourceNew":"  public void testDeleteThenOptimize() throws Exception {\n    // Create directories where the indexes will reside\n    File indexPath = new File(TEMP_DIR, \"testfilesplitter\");\n    _TestUtil.rmDir(indexPath);\n    indexPath.mkdirs();\n    File indexSplitPath = new File(TEMP_DIR, \"testfilesplitterdest\");\n    _TestUtil.rmDir(indexSplitPath);\n    indexSplitPath.mkdirs();\n    \n    // Create the original index\n    LogMergePolicy mergePolicy = new LogByteSizeMergePolicy();\n    mergePolicy.setNoCFSRatio(1);\n    IndexWriterConfig iwConfig\n        = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n              .setOpenMode(OpenMode.CREATE)\n              .setMergePolicy(mergePolicy);\n    Directory fsDir = newFSDirectory(indexPath);\n    IndexWriter indexWriter = new IndexWriter(fsDir, iwConfig);\n    Document doc = new Document();\n    doc.add(new Field(\"content\", \"doc 1\", Field.Store.YES, Field.Index.ANALYZED_NO_NORMS));\n    indexWriter.addDocument(doc);\n    doc = new Document();\n    doc.add(new Field(\"content\", \"doc 2\", Field.Store.YES, Field.Index.ANALYZED_NO_NORMS));\n    indexWriter.addDocument(doc);\n    indexWriter.close();\n    fsDir.close();\n    \n    // Create the split index\n    IndexSplitter indexSplitter = new IndexSplitter(indexPath);\n    String splitSegName = indexSplitter.infos.info(0).name;\n    indexSplitter.split(indexSplitPath, new String[] {splitSegName});\n\n    // Delete the first document in the split index\n    Directory fsDirDest = newFSDirectory(indexSplitPath);\n    IndexReader indexReader = IndexReader.open(fsDirDest, false);\n    indexReader.deleteDocument(0);\n    assertEquals(1, indexReader.numDocs());\n    indexReader.close();\n    fsDirDest.close();\n\n    // Optimize the split index\n    mergePolicy = new LogByteSizeMergePolicy();\n    mergePolicy.setNoCFSRatio(1);\n    iwConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n                   .setOpenMode(OpenMode.APPEND)\n                   .setMergePolicy(mergePolicy);\n    fsDirDest = newFSDirectory(indexSplitPath);\n    indexWriter = new IndexWriter(fsDirDest, iwConfig);\n    indexWriter.optimize();\n    indexWriter.close();\n    fsDirDest.close();\n\n    // Read the number of docs in the index\n    fsDirDest = newFSDirectory(indexSplitPath);\n    indexReader = IndexReader.open(fsDirDest);\n\t  assertEquals(1, indexReader.numDocs());\n    indexReader.close();\n    fsDirDest.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9ed208afa1e7aa98899ddb1dedfddedddf898253","date":1308079587,"type":0,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestIndexSplitter#testDeleteThenOptimize().mjava","pathOld":"/dev/null","sourceNew":"  public void testDeleteThenOptimize() throws Exception {\n    // Create directories where the indexes will reside\n    File indexPath = new File(TEMP_DIR, \"testfilesplitter\");\n    _TestUtil.rmDir(indexPath);\n    indexPath.mkdirs();\n    File indexSplitPath = new File(TEMP_DIR, \"testfilesplitterdest\");\n    _TestUtil.rmDir(indexSplitPath);\n    indexSplitPath.mkdirs();\n    \n    // Create the original index\n    LogMergePolicy mergePolicy = new LogByteSizeMergePolicy();\n    mergePolicy.setNoCFSRatio(1);\n    IndexWriterConfig iwConfig\n        = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n              .setOpenMode(OpenMode.CREATE)\n              .setMergePolicy(mergePolicy);\n    Directory fsDir = newFSDirectory(indexPath);\n    IndexWriter indexWriter = new IndexWriter(fsDir, iwConfig);\n    Document doc = new Document();\n    doc.add(new Field(\"content\", \"doc 1\", Field.Store.YES, Field.Index.ANALYZED_NO_NORMS));\n    indexWriter.addDocument(doc);\n    doc = new Document();\n    doc.add(new Field(\"content\", \"doc 2\", Field.Store.YES, Field.Index.ANALYZED_NO_NORMS));\n    indexWriter.addDocument(doc);\n    indexWriter.close();\n    fsDir.close();\n    \n    // Create the split index\n    IndexSplitter indexSplitter = new IndexSplitter(indexPath);\n    String splitSegName = indexSplitter.infos.info(0).name;\n    indexSplitter.split(indexSplitPath, new String[] {splitSegName});\n\n    // Delete the first document in the split index\n    Directory fsDirDest = newFSDirectory(indexSplitPath);\n    IndexReader indexReader = IndexReader.open(fsDirDest, false);\n    indexReader.deleteDocument(0);\n    assertEquals(1, indexReader.numDocs());\n    indexReader.close();\n    fsDirDest.close();\n\n    // Optimize the split index\n    mergePolicy = new LogByteSizeMergePolicy();\n    mergePolicy.setNoCFSRatio(1);\n    iwConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n                   .setOpenMode(OpenMode.APPEND)\n                   .setMergePolicy(mergePolicy);\n    fsDirDest = newFSDirectory(indexSplitPath);\n    indexWriter = new IndexWriter(fsDirDest, iwConfig);\n    indexWriter.optimize();\n    indexWriter.close();\n    fsDirDest.close();\n\n    // Read the number of docs in the index\n    fsDirDest = newFSDirectory(indexSplitPath);\n    indexReader = IndexReader.open(fsDirDest);\n\t  assertEquals(1, indexReader.numDocs());\n    indexReader.close();\n    fsDirDest.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestIndexSplitter#testDeleteThenOptimize().mjava","pathOld":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestIndexSplitter#testDeleteThenOptimize().mjava","sourceNew":"  public void testDeleteThenOptimize() throws Exception {\n    // Create directories where the indexes will reside\n    File indexPath = new File(TEMP_DIR, \"testfilesplitter\");\n    _TestUtil.rmDir(indexPath);\n    indexPath.mkdirs();\n    File indexSplitPath = new File(TEMP_DIR, \"testfilesplitterdest\");\n    _TestUtil.rmDir(indexSplitPath);\n    indexSplitPath.mkdirs();\n    \n    // Create the original index\n    LogMergePolicy mergePolicy = new LogByteSizeMergePolicy();\n    mergePolicy.setNoCFSRatio(1);\n    IndexWriterConfig iwConfig\n        = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n              .setOpenMode(OpenMode.CREATE)\n              .setMergePolicy(mergePolicy);\n    Directory fsDir = newFSDirectory(indexPath);\n    IndexWriter indexWriter = new IndexWriter(fsDir, iwConfig);\n    Document doc = new Document();\n    doc.add(new Field(\"content\", StringField.TYPE_STORED, \"doc 1\"));\n    indexWriter.addDocument(doc);\n    doc = new Document();\n    doc.add(new Field(\"content\", StringField.TYPE_STORED, \"doc 2\"));\n    indexWriter.addDocument(doc);\n    indexWriter.close();\n    fsDir.close();\n    \n    // Create the split index\n    IndexSplitter indexSplitter = new IndexSplitter(indexPath);\n    String splitSegName = indexSplitter.infos.info(0).name;\n    indexSplitter.split(indexSplitPath, new String[] {splitSegName});\n\n    // Delete the first document in the split index\n    Directory fsDirDest = newFSDirectory(indexSplitPath);\n    IndexReader indexReader = IndexReader.open(fsDirDest, false);\n    indexReader.deleteDocument(0);\n    assertEquals(1, indexReader.numDocs());\n    indexReader.close();\n    fsDirDest.close();\n\n    // Optimize the split index\n    mergePolicy = new LogByteSizeMergePolicy();\n    mergePolicy.setNoCFSRatio(1);\n    iwConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n                   .setOpenMode(OpenMode.APPEND)\n                   .setMergePolicy(mergePolicy);\n    fsDirDest = newFSDirectory(indexSplitPath);\n    indexWriter = new IndexWriter(fsDirDest, iwConfig);\n    indexWriter.optimize();\n    indexWriter.close();\n    fsDirDest.close();\n\n    // Read the number of docs in the index\n    fsDirDest = newFSDirectory(indexSplitPath);\n    indexReader = IndexReader.open(fsDirDest);\n\t  assertEquals(1, indexReader.numDocs());\n    indexReader.close();\n    fsDirDest.close();\n  }\n\n","sourceOld":"  public void testDeleteThenOptimize() throws Exception {\n    // Create directories where the indexes will reside\n    File indexPath = new File(TEMP_DIR, \"testfilesplitter\");\n    _TestUtil.rmDir(indexPath);\n    indexPath.mkdirs();\n    File indexSplitPath = new File(TEMP_DIR, \"testfilesplitterdest\");\n    _TestUtil.rmDir(indexSplitPath);\n    indexSplitPath.mkdirs();\n    \n    // Create the original index\n    LogMergePolicy mergePolicy = new LogByteSizeMergePolicy();\n    mergePolicy.setNoCFSRatio(1);\n    IndexWriterConfig iwConfig\n        = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n              .setOpenMode(OpenMode.CREATE)\n              .setMergePolicy(mergePolicy);\n    Directory fsDir = newFSDirectory(indexPath);\n    IndexWriter indexWriter = new IndexWriter(fsDir, iwConfig);\n    Document doc = new Document();\n    doc.add(new Field(\"content\", \"doc 1\", Field.Store.YES, Field.Index.ANALYZED_NO_NORMS));\n    indexWriter.addDocument(doc);\n    doc = new Document();\n    doc.add(new Field(\"content\", \"doc 2\", Field.Store.YES, Field.Index.ANALYZED_NO_NORMS));\n    indexWriter.addDocument(doc);\n    indexWriter.close();\n    fsDir.close();\n    \n    // Create the split index\n    IndexSplitter indexSplitter = new IndexSplitter(indexPath);\n    String splitSegName = indexSplitter.infos.info(0).name;\n    indexSplitter.split(indexSplitPath, new String[] {splitSegName});\n\n    // Delete the first document in the split index\n    Directory fsDirDest = newFSDirectory(indexSplitPath);\n    IndexReader indexReader = IndexReader.open(fsDirDest, false);\n    indexReader.deleteDocument(0);\n    assertEquals(1, indexReader.numDocs());\n    indexReader.close();\n    fsDirDest.close();\n\n    // Optimize the split index\n    mergePolicy = new LogByteSizeMergePolicy();\n    mergePolicy.setNoCFSRatio(1);\n    iwConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n                   .setOpenMode(OpenMode.APPEND)\n                   .setMergePolicy(mergePolicy);\n    fsDirDest = newFSDirectory(indexSplitPath);\n    indexWriter = new IndexWriter(fsDirDest, iwConfig);\n    indexWriter.optimize();\n    indexWriter.close();\n    fsDirDest.close();\n\n    // Read the number of docs in the index\n    fsDirDest = newFSDirectory(indexSplitPath);\n    indexReader = IndexReader.open(fsDirDest);\n\t  assertEquals(1, indexReader.numDocs());\n    indexReader.close();\n    fsDirDest.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e4db59c6b6c10e25322cfb41c4c19d78b4298bd","date":1317197236,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestIndexSplitter#testDeleteThenOptimize().mjava","pathOld":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestIndexSplitter#testDeleteThenOptimize().mjava","sourceNew":"  public void testDeleteThenOptimize() throws Exception {\n    // Create directories where the indexes will reside\n    File indexPath = new File(TEMP_DIR, \"testfilesplitter\");\n    _TestUtil.rmDir(indexPath);\n    indexPath.mkdirs();\n    File indexSplitPath = new File(TEMP_DIR, \"testfilesplitterdest\");\n    _TestUtil.rmDir(indexSplitPath);\n    indexSplitPath.mkdirs();\n    \n    // Create the original index\n    LogMergePolicy mergePolicy = new LogByteSizeMergePolicy();\n    mergePolicy.setNoCFSRatio(1);\n    IndexWriterConfig iwConfig\n        = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n              .setOpenMode(OpenMode.CREATE)\n              .setMergePolicy(mergePolicy);\n    Directory fsDir = newFSDirectory(indexPath);\n    IndexWriter indexWriter = new IndexWriter(fsDir, iwConfig);\n    Document doc = new Document();\n    doc.add(new Field(\"content\", \"doc 1\", StringField.TYPE_STORED));\n    indexWriter.addDocument(doc);\n    doc = new Document();\n    doc.add(new Field(\"content\", \"doc 2\", StringField.TYPE_STORED));\n    indexWriter.addDocument(doc);\n    indexWriter.close();\n    fsDir.close();\n    \n    // Create the split index\n    IndexSplitter indexSplitter = new IndexSplitter(indexPath);\n    String splitSegName = indexSplitter.infos.info(0).name;\n    indexSplitter.split(indexSplitPath, new String[] {splitSegName});\n\n    // Delete the first document in the split index\n    Directory fsDirDest = newFSDirectory(indexSplitPath);\n    IndexReader indexReader = IndexReader.open(fsDirDest, false);\n    indexReader.deleteDocument(0);\n    assertEquals(1, indexReader.numDocs());\n    indexReader.close();\n    fsDirDest.close();\n\n    // Optimize the split index\n    mergePolicy = new LogByteSizeMergePolicy();\n    mergePolicy.setNoCFSRatio(1);\n    iwConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n                   .setOpenMode(OpenMode.APPEND)\n                   .setMergePolicy(mergePolicy);\n    fsDirDest = newFSDirectory(indexSplitPath);\n    indexWriter = new IndexWriter(fsDirDest, iwConfig);\n    indexWriter.optimize();\n    indexWriter.close();\n    fsDirDest.close();\n\n    // Read the number of docs in the index\n    fsDirDest = newFSDirectory(indexSplitPath);\n    indexReader = IndexReader.open(fsDirDest);\n\t  assertEquals(1, indexReader.numDocs());\n    indexReader.close();\n    fsDirDest.close();\n  }\n\n","sourceOld":"  public void testDeleteThenOptimize() throws Exception {\n    // Create directories where the indexes will reside\n    File indexPath = new File(TEMP_DIR, \"testfilesplitter\");\n    _TestUtil.rmDir(indexPath);\n    indexPath.mkdirs();\n    File indexSplitPath = new File(TEMP_DIR, \"testfilesplitterdest\");\n    _TestUtil.rmDir(indexSplitPath);\n    indexSplitPath.mkdirs();\n    \n    // Create the original index\n    LogMergePolicy mergePolicy = new LogByteSizeMergePolicy();\n    mergePolicy.setNoCFSRatio(1);\n    IndexWriterConfig iwConfig\n        = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n              .setOpenMode(OpenMode.CREATE)\n              .setMergePolicy(mergePolicy);\n    Directory fsDir = newFSDirectory(indexPath);\n    IndexWriter indexWriter = new IndexWriter(fsDir, iwConfig);\n    Document doc = new Document();\n    doc.add(new Field(\"content\", StringField.TYPE_STORED, \"doc 1\"));\n    indexWriter.addDocument(doc);\n    doc = new Document();\n    doc.add(new Field(\"content\", StringField.TYPE_STORED, \"doc 2\"));\n    indexWriter.addDocument(doc);\n    indexWriter.close();\n    fsDir.close();\n    \n    // Create the split index\n    IndexSplitter indexSplitter = new IndexSplitter(indexPath);\n    String splitSegName = indexSplitter.infos.info(0).name;\n    indexSplitter.split(indexSplitPath, new String[] {splitSegName});\n\n    // Delete the first document in the split index\n    Directory fsDirDest = newFSDirectory(indexSplitPath);\n    IndexReader indexReader = IndexReader.open(fsDirDest, false);\n    indexReader.deleteDocument(0);\n    assertEquals(1, indexReader.numDocs());\n    indexReader.close();\n    fsDirDest.close();\n\n    // Optimize the split index\n    mergePolicy = new LogByteSizeMergePolicy();\n    mergePolicy.setNoCFSRatio(1);\n    iwConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n                   .setOpenMode(OpenMode.APPEND)\n                   .setMergePolicy(mergePolicy);\n    fsDirDest = newFSDirectory(indexSplitPath);\n    indexWriter = new IndexWriter(fsDirDest, iwConfig);\n    indexWriter.optimize();\n    indexWriter.close();\n    fsDirDest.close();\n\n    // Read the number of docs in the index\n    fsDirDest = newFSDirectory(indexSplitPath);\n    indexReader = IndexReader.open(fsDirDest);\n\t  assertEquals(1, indexReader.numDocs());\n    indexReader.close();\n    fsDirDest.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d14e8d18c0e3970c20354dbeeb49da11bd587fbd","date":1321041051,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestIndexSplitter#testDeleteThenFullMerge().mjava","pathOld":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestIndexSplitter#testDeleteThenOptimize().mjava","sourceNew":"  public void testDeleteThenFullMerge() throws Exception {\n    // Create directories where the indexes will reside\n    File indexPath = new File(TEMP_DIR, \"testfilesplitter\");\n    _TestUtil.rmDir(indexPath);\n    indexPath.mkdirs();\n    File indexSplitPath = new File(TEMP_DIR, \"testfilesplitterdest\");\n    _TestUtil.rmDir(indexSplitPath);\n    indexSplitPath.mkdirs();\n    \n    // Create the original index\n    LogMergePolicy mergePolicy = new LogByteSizeMergePolicy();\n    mergePolicy.setNoCFSRatio(1);\n    IndexWriterConfig iwConfig\n        = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n              .setOpenMode(OpenMode.CREATE)\n              .setMergePolicy(mergePolicy);\n    Directory fsDir = newFSDirectory(indexPath);\n    IndexWriter indexWriter = new IndexWriter(fsDir, iwConfig);\n    Document doc = new Document();\n    doc.add(new Field(\"content\", \"doc 1\", StringField.TYPE_STORED));\n    indexWriter.addDocument(doc);\n    doc = new Document();\n    doc.add(new Field(\"content\", \"doc 2\", StringField.TYPE_STORED));\n    indexWriter.addDocument(doc);\n    indexWriter.close();\n    fsDir.close();\n    \n    // Create the split index\n    IndexSplitter indexSplitter = new IndexSplitter(indexPath);\n    String splitSegName = indexSplitter.infos.info(0).name;\n    indexSplitter.split(indexSplitPath, new String[] {splitSegName});\n\n    // Delete the first document in the split index\n    Directory fsDirDest = newFSDirectory(indexSplitPath);\n    IndexReader indexReader = IndexReader.open(fsDirDest, false);\n    indexReader.deleteDocument(0);\n    assertEquals(1, indexReader.numDocs());\n    indexReader.close();\n    fsDirDest.close();\n\n    // Fully merge the split index\n    mergePolicy = new LogByteSizeMergePolicy();\n    mergePolicy.setNoCFSRatio(1);\n    iwConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n                   .setOpenMode(OpenMode.APPEND)\n                   .setMergePolicy(mergePolicy);\n    fsDirDest = newFSDirectory(indexSplitPath);\n    indexWriter = new IndexWriter(fsDirDest, iwConfig);\n    indexWriter.forceMerge(1);\n    indexWriter.close();\n    fsDirDest.close();\n\n    // Read the number of docs in the index\n    fsDirDest = newFSDirectory(indexSplitPath);\n    indexReader = IndexReader.open(fsDirDest);\n\t  assertEquals(1, indexReader.numDocs());\n    indexReader.close();\n    fsDirDest.close();\n  }\n\n","sourceOld":"  public void testDeleteThenOptimize() throws Exception {\n    // Create directories where the indexes will reside\n    File indexPath = new File(TEMP_DIR, \"testfilesplitter\");\n    _TestUtil.rmDir(indexPath);\n    indexPath.mkdirs();\n    File indexSplitPath = new File(TEMP_DIR, \"testfilesplitterdest\");\n    _TestUtil.rmDir(indexSplitPath);\n    indexSplitPath.mkdirs();\n    \n    // Create the original index\n    LogMergePolicy mergePolicy = new LogByteSizeMergePolicy();\n    mergePolicy.setNoCFSRatio(1);\n    IndexWriterConfig iwConfig\n        = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n              .setOpenMode(OpenMode.CREATE)\n              .setMergePolicy(mergePolicy);\n    Directory fsDir = newFSDirectory(indexPath);\n    IndexWriter indexWriter = new IndexWriter(fsDir, iwConfig);\n    Document doc = new Document();\n    doc.add(new Field(\"content\", \"doc 1\", StringField.TYPE_STORED));\n    indexWriter.addDocument(doc);\n    doc = new Document();\n    doc.add(new Field(\"content\", \"doc 2\", StringField.TYPE_STORED));\n    indexWriter.addDocument(doc);\n    indexWriter.close();\n    fsDir.close();\n    \n    // Create the split index\n    IndexSplitter indexSplitter = new IndexSplitter(indexPath);\n    String splitSegName = indexSplitter.infos.info(0).name;\n    indexSplitter.split(indexSplitPath, new String[] {splitSegName});\n\n    // Delete the first document in the split index\n    Directory fsDirDest = newFSDirectory(indexSplitPath);\n    IndexReader indexReader = IndexReader.open(fsDirDest, false);\n    indexReader.deleteDocument(0);\n    assertEquals(1, indexReader.numDocs());\n    indexReader.close();\n    fsDirDest.close();\n\n    // Optimize the split index\n    mergePolicy = new LogByteSizeMergePolicy();\n    mergePolicy.setNoCFSRatio(1);\n    iwConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n                   .setOpenMode(OpenMode.APPEND)\n                   .setMergePolicy(mergePolicy);\n    fsDirDest = newFSDirectory(indexSplitPath);\n    indexWriter = new IndexWriter(fsDirDest, iwConfig);\n    indexWriter.optimize();\n    indexWriter.close();\n    fsDirDest.close();\n\n    // Read the number of docs in the index\n    fsDirDest = newFSDirectory(indexSplitPath);\n    indexReader = IndexReader.open(fsDirDest);\n\t  assertEquals(1, indexReader.numDocs());\n    indexReader.close();\n    fsDirDest.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"fec0d7b897279d9441884bfaa0cb01dd9a3cd58c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["7e4db59c6b6c10e25322cfb41c4c19d78b4298bd"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["fec0d7b897279d9441884bfaa0cb01dd9a3cd58c"],"9ed208afa1e7aa98899ddb1dedfddedddf898253":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","fec0d7b897279d9441884bfaa0cb01dd9a3cd58c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"],"7e4db59c6b6c10e25322cfb41c4c19d78b4298bd":["1509f151d7692d84fae414b2b799ac06ba60fcb4"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["fec0d7b897279d9441884bfaa0cb01dd9a3cd58c","9ed208afa1e7aa98899ddb1dedfddedddf898253"],"fec0d7b897279d9441884bfaa0cb01dd9a3cd58c":["1509f151d7692d84fae414b2b799ac06ba60fcb4","9ed208afa1e7aa98899ddb1dedfddedddf898253"],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["7e4db59c6b6c10e25322cfb41c4c19d78b4298bd"],"9ed208afa1e7aa98899ddb1dedfddedddf898253":[],"7e4db59c6b6c10e25322cfb41c4c19d78b4298bd":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9ed208afa1e7aa98899ddb1dedfddedddf898253","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}