{"path":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simUpdate(UpdateRequest).mjava","commits":[{"id":"ce71a9836bf1eba34a0ab31884e9eb8ad3f1cef1","date":1523453934,"type":0,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simUpdate(UpdateRequest).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Simulate an update by modifying replica metrics.\n   * The following core metrics are updated:\n   * <ul>\n   *   <li><code>SEARCHER.searcher.numDocs</code> - increased by added docs, decreased by deleteById and deleteByQuery</li>\n   *   <li><code>SEARCHER.searcher.deletedDocs</code> - decreased by deleteById and deleteByQuery by up to <code>numDocs</code></li>\n   *   <li><code>SEARCHER.searcher.maxDoc</code> - always increased by the number of added docs.</li>\n   * </ul>\n   * <p>IMPORTANT limitations:</p>\n   * <ul>\n   *   <li>document replacements are always counted as new docs</li>\n   *   <li>delete by ID always succeeds (unless numDocs == 0)</li>\n   *   <li>deleteByQuery is not supported unless the query is <code>*:*</code></li>\n   * </ul>\n   * @param req update request. This request MUST have the <code>collection</code> param set.\n   * @return {@link UpdateResponse}\n   * @throws SolrException on errors, such as nonexistent collection or unsupported deleteByQuery\n   */\n  public UpdateResponse simUpdate(UpdateRequest req) throws SolrException, InterruptedException, IOException {\n    String collection = req.getCollection();\n    if (collection == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection not set\");\n    }\n    if (!simListCollections().contains(collection)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection '\" + collection + \"' doesn't exist\");\n    }\n    // always reset first to get the current metrics - it's easier than to keep matching\n    // Replica with ReplicaInfo where the current real counts are stored\n    collectionsStatesRef.set(null);\n    DocCollection coll = getClusterState().getCollection(collection);\n    DocRouter router = coll.getRouter();\n\n    boolean modified = false;\n\n    lock.lockInterruptibly();\n    try {\n      List<String> deletes = req.getDeleteById();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String id : deletes) {\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          // NOTE: we don't use getProperty because it uses PROPERTY_PROP_PREFIX\n          String numDocsStr = s.getLeader().getStr(\"SEARCHER.searcher.numDocs\");\n          if (numDocsStr == null) {\n            LOG.debug(\"-- no docs in \" + s.getLeader());\n            continue;\n          }\n          long numDocs = Long.parseLong(numDocsStr);\n          if (numDocs == 0) {\n            LOG.debug(\"-- attempting to delete nonexistent doc \" + id + \" from \" + s.getLeader());\n            continue;\n          }\n          if (numDocsStr != null) {\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", 1, true, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", -1, true, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      deletes = req.getDeleteQuery();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String q : deletes) {\n          if (!\"*:*\".equals(q)) {\n            throw new UnsupportedOperationException(\"Only '*:*' query is supported in deleteByQuery\");\n          }\n          for (Slice s : coll.getSlices()) {\n            String numDocsStr = s.getLeader().getStr(\"SEARCHER.searcher.numDocs\");\n            if (numDocsStr == null) {\n              continue;\n            }\n            long numDocs = Long.parseLong(numDocsStr);\n            if (numDocs == 0) {\n              continue;\n            }\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", numDocs, false, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 0, false, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      List<SolrInputDocument> docs = req.getDocuments();\n      if (docs != null && !docs.isEmpty()) {\n        for (SolrInputDocument doc : docs) {\n          String id = (String) doc.getFieldValue(\"id\");\n          if (id == null) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Document without id: \" + doc);\n          }\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          modified = true;\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 1, true, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.maxDoc\", 1, true, false);\n            // Policy reuses this value and expects it to be in GB units!!!\n            // the idea here is to increase the index size by 500 bytes with each doc\n            // simSetShardValue(collection, s.getName(), \"INDEX.sizeInBytes\", 500, true, false);\n          } catch (Exception e) {\n            throw new IOException(e);\n          }\n        }\n      }\n      if (modified) {\n        collectionsStatesRef.set(null);\n      }\n    } finally {\n      lock.unlock();\n    }\n    return new UpdateResponse();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"43345f1452f9510f8aaadae6156fe0c834e7d957","date":1523483670,"type":0,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simUpdate(UpdateRequest).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Simulate an update by modifying replica metrics.\n   * The following core metrics are updated:\n   * <ul>\n   *   <li><code>SEARCHER.searcher.numDocs</code> - increased by added docs, decreased by deleteById and deleteByQuery</li>\n   *   <li><code>SEARCHER.searcher.deletedDocs</code> - decreased by deleteById and deleteByQuery by up to <code>numDocs</code></li>\n   *   <li><code>SEARCHER.searcher.maxDoc</code> - always increased by the number of added docs.</li>\n   * </ul>\n   * <p>IMPORTANT limitations:</p>\n   * <ul>\n   *   <li>document replacements are always counted as new docs</li>\n   *   <li>delete by ID always succeeds (unless numDocs == 0)</li>\n   *   <li>deleteByQuery is not supported unless the query is <code>*:*</code></li>\n   * </ul>\n   * @param req update request. This request MUST have the <code>collection</code> param set.\n   * @return {@link UpdateResponse}\n   * @throws SolrException on errors, such as nonexistent collection or unsupported deleteByQuery\n   */\n  public UpdateResponse simUpdate(UpdateRequest req) throws SolrException, InterruptedException, IOException {\n    String collection = req.getCollection();\n    if (collection == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection not set\");\n    }\n    if (!simListCollections().contains(collection)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection '\" + collection + \"' doesn't exist\");\n    }\n    // always reset first to get the current metrics - it's easier than to keep matching\n    // Replica with ReplicaInfo where the current real counts are stored\n    collectionsStatesRef.set(null);\n    DocCollection coll = getClusterState().getCollection(collection);\n    DocRouter router = coll.getRouter();\n\n    boolean modified = false;\n\n    lock.lockInterruptibly();\n    try {\n      List<String> deletes = req.getDeleteById();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String id : deletes) {\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          // NOTE: we don't use getProperty because it uses PROPERTY_PROP_PREFIX\n          String numDocsStr = s.getLeader().getStr(\"SEARCHER.searcher.numDocs\");\n          if (numDocsStr == null) {\n            LOG.debug(\"-- no docs in \" + s.getLeader());\n            continue;\n          }\n          long numDocs = Long.parseLong(numDocsStr);\n          if (numDocs == 0) {\n            LOG.debug(\"-- attempting to delete nonexistent doc \" + id + \" from \" + s.getLeader());\n            continue;\n          }\n          if (numDocsStr != null) {\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", 1, true, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", -1, true, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      deletes = req.getDeleteQuery();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String q : deletes) {\n          if (!\"*:*\".equals(q)) {\n            throw new UnsupportedOperationException(\"Only '*:*' query is supported in deleteByQuery\");\n          }\n          for (Slice s : coll.getSlices()) {\n            String numDocsStr = s.getLeader().getStr(\"SEARCHER.searcher.numDocs\");\n            if (numDocsStr == null) {\n              continue;\n            }\n            long numDocs = Long.parseLong(numDocsStr);\n            if (numDocs == 0) {\n              continue;\n            }\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", numDocs, false, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 0, false, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      List<SolrInputDocument> docs = req.getDocuments();\n      if (docs != null && !docs.isEmpty()) {\n        for (SolrInputDocument doc : docs) {\n          String id = (String) doc.getFieldValue(\"id\");\n          if (id == null) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Document without id: \" + doc);\n          }\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          modified = true;\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 1, true, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.maxDoc\", 1, true, false);\n            // Policy reuses this value and expects it to be in GB units!!!\n            // the idea here is to increase the index size by 500 bytes with each doc\n            // simSetShardValue(collection, s.getName(), \"INDEX.sizeInBytes\", 500, true, false);\n          } catch (Exception e) {\n            throw new IOException(e);\n          }\n        }\n      }\n      if (modified) {\n        collectionsStatesRef.set(null);\n      }\n    } finally {\n      lock.unlock();\n    }\n    return new UpdateResponse();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"35d82bbcb7dc7df226e79bcfbea9942ba25f5e6c","date":1523616354,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simUpdate(UpdateRequest).mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simUpdate(UpdateRequest).mjava","sourceNew":"  /**\n   * Simulate an update by modifying replica metrics.\n   * The following core metrics are updated:\n   * <ul>\n   *   <li><code>SEARCHER.searcher.numDocs</code> - increased by added docs, decreased by deleteById and deleteByQuery</li>\n   *   <li><code>SEARCHER.searcher.deletedDocs</code> - decreased by deleteById and deleteByQuery by up to <code>numDocs</code></li>\n   *   <li><code>SEARCHER.searcher.maxDoc</code> - always increased by the number of added docs.</li>\n   * </ul>\n   * <p>IMPORTANT limitations:</p>\n   * <ul>\n   *   <li>document replacements are always counted as new docs</li>\n   *   <li>delete by ID always succeeds (unless numDocs == 0)</li>\n   *   <li>deleteByQuery is not supported unless the query is <code>*:*</code></li>\n   * </ul>\n   * @param req update request. This request MUST have the <code>collection</code> param set.\n   * @return {@link UpdateResponse}\n   * @throws SolrException on errors, such as nonexistent collection or unsupported deleteByQuery\n   */\n  public UpdateResponse simUpdate(UpdateRequest req) throws SolrException, InterruptedException, IOException {\n    String collection = req.getCollection();\n    if (collection == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection not set\");\n    }\n    if (!simListCollections().contains(collection)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection '\" + collection + \"' doesn't exist\");\n    }\n    // always reset first to get the current metrics - it's easier than to keep matching\n    // Replica with ReplicaInfo where the current real counts are stored\n    collectionsStatesRef.set(null);\n    DocCollection coll = getClusterState().getCollection(collection);\n    DocRouter router = coll.getRouter();\n\n    boolean modified = false;\n\n    lock.lockInterruptibly();\n    try {\n      List<String> deletes = req.getDeleteById();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String id : deletes) {\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          // NOTE: we don't use getProperty because it uses PROPERTY_PROP_PREFIX\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            LOG.debug(\"-- no leader in \" + s);\n            continue;\n          }\n          String numDocsStr = leader.getStr(\"SEARCHER.searcher.numDocs\");\n          if (numDocsStr == null) {\n            LOG.debug(\"-- no docs in \" + leader);\n            continue;\n          }\n          long numDocs = Long.parseLong(numDocsStr);\n          if (numDocs == 0) {\n            LOG.debug(\"-- attempting to delete nonexistent doc \" + id + \" from \" + s.getLeader());\n            continue;\n          }\n          if (numDocsStr != null) {\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", 1, true, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", -1, true, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      deletes = req.getDeleteQuery();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String q : deletes) {\n          if (!\"*:*\".equals(q)) {\n            throw new UnsupportedOperationException(\"Only '*:*' query is supported in deleteByQuery\");\n          }\n          for (Slice s : coll.getSlices()) {\n            String numDocsStr = s.getLeader().getStr(\"SEARCHER.searcher.numDocs\");\n            if (numDocsStr == null) {\n              continue;\n            }\n            long numDocs = Long.parseLong(numDocsStr);\n            if (numDocs == 0) {\n              continue;\n            }\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", numDocs, false, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 0, false, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      List<SolrInputDocument> docs = req.getDocuments();\n      if (docs != null && !docs.isEmpty()) {\n        for (SolrInputDocument doc : docs) {\n          String id = (String) doc.getFieldValue(\"id\");\n          if (id == null) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Document without id: \" + doc);\n          }\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          modified = true;\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 1, true, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.maxDoc\", 1, true, false);\n            // Policy reuses this value and expects it to be in GB units!!!\n            // the idea here is to increase the index size by 500 bytes with each doc\n            // simSetShardValue(collection, s.getName(), \"INDEX.sizeInBytes\", 500, true, false);\n          } catch (Exception e) {\n            throw new IOException(e);\n          }\n        }\n      }\n      if (modified) {\n        collectionsStatesRef.set(null);\n      }\n    } finally {\n      lock.unlock();\n    }\n    return new UpdateResponse();\n  }\n\n","sourceOld":"  /**\n   * Simulate an update by modifying replica metrics.\n   * The following core metrics are updated:\n   * <ul>\n   *   <li><code>SEARCHER.searcher.numDocs</code> - increased by added docs, decreased by deleteById and deleteByQuery</li>\n   *   <li><code>SEARCHER.searcher.deletedDocs</code> - decreased by deleteById and deleteByQuery by up to <code>numDocs</code></li>\n   *   <li><code>SEARCHER.searcher.maxDoc</code> - always increased by the number of added docs.</li>\n   * </ul>\n   * <p>IMPORTANT limitations:</p>\n   * <ul>\n   *   <li>document replacements are always counted as new docs</li>\n   *   <li>delete by ID always succeeds (unless numDocs == 0)</li>\n   *   <li>deleteByQuery is not supported unless the query is <code>*:*</code></li>\n   * </ul>\n   * @param req update request. This request MUST have the <code>collection</code> param set.\n   * @return {@link UpdateResponse}\n   * @throws SolrException on errors, such as nonexistent collection or unsupported deleteByQuery\n   */\n  public UpdateResponse simUpdate(UpdateRequest req) throws SolrException, InterruptedException, IOException {\n    String collection = req.getCollection();\n    if (collection == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection not set\");\n    }\n    if (!simListCollections().contains(collection)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection '\" + collection + \"' doesn't exist\");\n    }\n    // always reset first to get the current metrics - it's easier than to keep matching\n    // Replica with ReplicaInfo where the current real counts are stored\n    collectionsStatesRef.set(null);\n    DocCollection coll = getClusterState().getCollection(collection);\n    DocRouter router = coll.getRouter();\n\n    boolean modified = false;\n\n    lock.lockInterruptibly();\n    try {\n      List<String> deletes = req.getDeleteById();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String id : deletes) {\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          // NOTE: we don't use getProperty because it uses PROPERTY_PROP_PREFIX\n          String numDocsStr = s.getLeader().getStr(\"SEARCHER.searcher.numDocs\");\n          if (numDocsStr == null) {\n            LOG.debug(\"-- no docs in \" + s.getLeader());\n            continue;\n          }\n          long numDocs = Long.parseLong(numDocsStr);\n          if (numDocs == 0) {\n            LOG.debug(\"-- attempting to delete nonexistent doc \" + id + \" from \" + s.getLeader());\n            continue;\n          }\n          if (numDocsStr != null) {\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", 1, true, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", -1, true, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      deletes = req.getDeleteQuery();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String q : deletes) {\n          if (!\"*:*\".equals(q)) {\n            throw new UnsupportedOperationException(\"Only '*:*' query is supported in deleteByQuery\");\n          }\n          for (Slice s : coll.getSlices()) {\n            String numDocsStr = s.getLeader().getStr(\"SEARCHER.searcher.numDocs\");\n            if (numDocsStr == null) {\n              continue;\n            }\n            long numDocs = Long.parseLong(numDocsStr);\n            if (numDocs == 0) {\n              continue;\n            }\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", numDocs, false, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 0, false, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      List<SolrInputDocument> docs = req.getDocuments();\n      if (docs != null && !docs.isEmpty()) {\n        for (SolrInputDocument doc : docs) {\n          String id = (String) doc.getFieldValue(\"id\");\n          if (id == null) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Document without id: \" + doc);\n          }\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          modified = true;\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 1, true, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.maxDoc\", 1, true, false);\n            // Policy reuses this value and expects it to be in GB units!!!\n            // the idea here is to increase the index size by 500 bytes with each doc\n            // simSetShardValue(collection, s.getName(), \"INDEX.sizeInBytes\", 500, true, false);\n          } catch (Exception e) {\n            throw new IOException(e);\n          }\n        }\n      }\n      if (modified) {\n        collectionsStatesRef.set(null);\n      }\n    } finally {\n      lock.unlock();\n    }\n    return new UpdateResponse();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5c6453827f947004a68ad9db7418781e9df2f660","date":1523626811,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simUpdate(UpdateRequest).mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simUpdate(UpdateRequest).mjava","sourceNew":"  /**\n   * Simulate an update by modifying replica metrics.\n   * The following core metrics are updated:\n   * <ul>\n   *   <li><code>SEARCHER.searcher.numDocs</code> - increased by added docs, decreased by deleteById and deleteByQuery</li>\n   *   <li><code>SEARCHER.searcher.deletedDocs</code> - decreased by deleteById and deleteByQuery by up to <code>numDocs</code></li>\n   *   <li><code>SEARCHER.searcher.maxDoc</code> - always increased by the number of added docs.</li>\n   * </ul>\n   * <p>IMPORTANT limitations:</p>\n   * <ul>\n   *   <li>document replacements are always counted as new docs</li>\n   *   <li>delete by ID always succeeds (unless numDocs == 0)</li>\n   *   <li>deleteByQuery is not supported unless the query is <code>*:*</code></li>\n   * </ul>\n   * @param req update request. This request MUST have the <code>collection</code> param set.\n   * @return {@link UpdateResponse}\n   * @throws SolrException on errors, such as nonexistent collection or unsupported deleteByQuery\n   */\n  public UpdateResponse simUpdate(UpdateRequest req) throws SolrException, InterruptedException, IOException {\n    String collection = req.getCollection();\n    if (collection == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection not set\");\n    }\n    if (!simListCollections().contains(collection)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection '\" + collection + \"' doesn't exist\");\n    }\n    // always reset first to get the current metrics - it's easier than to keep matching\n    // Replica with ReplicaInfo where the current real counts are stored\n    collectionsStatesRef.set(null);\n    DocCollection coll = getClusterState().getCollection(collection);\n    DocRouter router = coll.getRouter();\n\n    boolean modified = false;\n\n    lock.lockInterruptibly();\n    try {\n      List<String> deletes = req.getDeleteById();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String id : deletes) {\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          // NOTE: we don't use getProperty because it uses PROPERTY_PROP_PREFIX\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            LOG.debug(\"-- no leader in \" + s);\n            continue;\n          }\n          String numDocsStr = leader.getStr(\"SEARCHER.searcher.numDocs\");\n          if (numDocsStr == null) {\n            LOG.debug(\"-- no docs in \" + leader);\n            continue;\n          }\n          long numDocs = Long.parseLong(numDocsStr);\n          if (numDocs == 0) {\n            LOG.debug(\"-- attempting to delete nonexistent doc \" + id + \" from \" + s.getLeader());\n            continue;\n          }\n          if (numDocsStr != null) {\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", 1, true, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", -1, true, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      deletes = req.getDeleteQuery();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String q : deletes) {\n          if (!\"*:*\".equals(q)) {\n            throw new UnsupportedOperationException(\"Only '*:*' query is supported in deleteByQuery\");\n          }\n          for (Slice s : coll.getSlices()) {\n            String numDocsStr = s.getLeader().getStr(\"SEARCHER.searcher.numDocs\");\n            if (numDocsStr == null) {\n              continue;\n            }\n            long numDocs = Long.parseLong(numDocsStr);\n            if (numDocs == 0) {\n              continue;\n            }\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", numDocs, false, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 0, false, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      List<SolrInputDocument> docs = req.getDocuments();\n      if (docs != null && !docs.isEmpty()) {\n        for (SolrInputDocument doc : docs) {\n          String id = (String) doc.getFieldValue(\"id\");\n          if (id == null) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Document without id: \" + doc);\n          }\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          modified = true;\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 1, true, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.maxDoc\", 1, true, false);\n            // Policy reuses this value and expects it to be in GB units!!!\n            // the idea here is to increase the index size by 500 bytes with each doc\n            // simSetShardValue(collection, s.getName(), \"INDEX.sizeInBytes\", 500, true, false);\n          } catch (Exception e) {\n            throw new IOException(e);\n          }\n        }\n      }\n      if (modified) {\n        collectionsStatesRef.set(null);\n      }\n    } finally {\n      lock.unlock();\n    }\n    return new UpdateResponse();\n  }\n\n","sourceOld":"  /**\n   * Simulate an update by modifying replica metrics.\n   * The following core metrics are updated:\n   * <ul>\n   *   <li><code>SEARCHER.searcher.numDocs</code> - increased by added docs, decreased by deleteById and deleteByQuery</li>\n   *   <li><code>SEARCHER.searcher.deletedDocs</code> - decreased by deleteById and deleteByQuery by up to <code>numDocs</code></li>\n   *   <li><code>SEARCHER.searcher.maxDoc</code> - always increased by the number of added docs.</li>\n   * </ul>\n   * <p>IMPORTANT limitations:</p>\n   * <ul>\n   *   <li>document replacements are always counted as new docs</li>\n   *   <li>delete by ID always succeeds (unless numDocs == 0)</li>\n   *   <li>deleteByQuery is not supported unless the query is <code>*:*</code></li>\n   * </ul>\n   * @param req update request. This request MUST have the <code>collection</code> param set.\n   * @return {@link UpdateResponse}\n   * @throws SolrException on errors, such as nonexistent collection or unsupported deleteByQuery\n   */\n  public UpdateResponse simUpdate(UpdateRequest req) throws SolrException, InterruptedException, IOException {\n    String collection = req.getCollection();\n    if (collection == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection not set\");\n    }\n    if (!simListCollections().contains(collection)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection '\" + collection + \"' doesn't exist\");\n    }\n    // always reset first to get the current metrics - it's easier than to keep matching\n    // Replica with ReplicaInfo where the current real counts are stored\n    collectionsStatesRef.set(null);\n    DocCollection coll = getClusterState().getCollection(collection);\n    DocRouter router = coll.getRouter();\n\n    boolean modified = false;\n\n    lock.lockInterruptibly();\n    try {\n      List<String> deletes = req.getDeleteById();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String id : deletes) {\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          // NOTE: we don't use getProperty because it uses PROPERTY_PROP_PREFIX\n          String numDocsStr = s.getLeader().getStr(\"SEARCHER.searcher.numDocs\");\n          if (numDocsStr == null) {\n            LOG.debug(\"-- no docs in \" + s.getLeader());\n            continue;\n          }\n          long numDocs = Long.parseLong(numDocsStr);\n          if (numDocs == 0) {\n            LOG.debug(\"-- attempting to delete nonexistent doc \" + id + \" from \" + s.getLeader());\n            continue;\n          }\n          if (numDocsStr != null) {\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", 1, true, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", -1, true, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      deletes = req.getDeleteQuery();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String q : deletes) {\n          if (!\"*:*\".equals(q)) {\n            throw new UnsupportedOperationException(\"Only '*:*' query is supported in deleteByQuery\");\n          }\n          for (Slice s : coll.getSlices()) {\n            String numDocsStr = s.getLeader().getStr(\"SEARCHER.searcher.numDocs\");\n            if (numDocsStr == null) {\n              continue;\n            }\n            long numDocs = Long.parseLong(numDocsStr);\n            if (numDocs == 0) {\n              continue;\n            }\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", numDocs, false, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 0, false, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      List<SolrInputDocument> docs = req.getDocuments();\n      if (docs != null && !docs.isEmpty()) {\n        for (SolrInputDocument doc : docs) {\n          String id = (String) doc.getFieldValue(\"id\");\n          if (id == null) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Document without id: \" + doc);\n          }\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          modified = true;\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 1, true, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.maxDoc\", 1, true, false);\n            // Policy reuses this value and expects it to be in GB units!!!\n            // the idea here is to increase the index size by 500 bytes with each doc\n            // simSetShardValue(collection, s.getName(), \"INDEX.sizeInBytes\", 500, true, false);\n          } catch (Exception e) {\n            throw new IOException(e);\n          }\n        }\n      }\n      if (modified) {\n        collectionsStatesRef.set(null);\n      }\n    } finally {\n      lock.unlock();\n    }\n    return new UpdateResponse();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4181b4cf0450ea3c6d1aff8dc3ad4ed9cd3eeb6a","date":1527582939,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simUpdate(UpdateRequest).mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simUpdate(UpdateRequest).mjava","sourceNew":"  /**\n   * Simulate an update by modifying replica metrics.\n   * The following core metrics are updated:\n   * <ul>\n   *   <li><code>SEARCHER.searcher.numDocs</code> - increased by added docs, decreased by deleteById and deleteByQuery</li>\n   *   <li><code>SEARCHER.searcher.deletedDocs</code> - decreased by deleteById and deleteByQuery by up to <code>numDocs</code></li>\n   *   <li><code>SEARCHER.searcher.maxDoc</code> - always increased by the number of added docs.</li>\n   * </ul>\n   * <p>IMPORTANT limitations:</p>\n   * <ul>\n   *   <li>document replacements are always counted as new docs</li>\n   *   <li>delete by ID always succeeds (unless numDocs == 0)</li>\n   *   <li>deleteByQuery is not supported unless the query is <code>*:*</code></li>\n   * </ul>\n   * @param req update request. This request MUST have the <code>collection</code> param set.\n   * @return {@link UpdateResponse}\n   * @throws SolrException on errors, such as nonexistent collection or unsupported deleteByQuery\n   */\n  public UpdateResponse simUpdate(UpdateRequest req) throws SolrException, InterruptedException, IOException {\n    String collection = req.getCollection();\n    if (collection == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection not set\");\n    }\n    if (!simListCollections().contains(collection)) {\n      if (CollectionAdminParams.SYSTEM_COLL.equals(collection)) {\n        // auto-create\n        createSystemCollection();\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection '\" + collection + \"' doesn't exist\");\n      }\n    }\n    // always reset first to get the current metrics - it's easier than to keep matching\n    // Replica with ReplicaInfo where the current real counts are stored\n    collectionsStatesRef.set(null);\n    DocCollection coll = getClusterState().getCollection(collection);\n    DocRouter router = coll.getRouter();\n\n    boolean modified = false;\n\n    lock.lockInterruptibly();\n    try {\n      List<String> deletes = req.getDeleteById();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String id : deletes) {\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          // NOTE: we don't use getProperty because it uses PROPERTY_PROP_PREFIX\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            LOG.debug(\"-- no leader in \" + s);\n            continue;\n          }\n          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          String numDocsStr = leader.getStr(\"SEARCHER.searcher.numDocs\");\n          if (numDocsStr == null) {\n            LOG.debug(\"-- no docs in \" + leader);\n            continue;\n          }\n          long numDocs = Long.parseLong(numDocsStr);\n          if (numDocs == 0) {\n            LOG.debug(\"-- attempting to delete nonexistent doc \" + id + \" from \" + s.getLeader());\n            continue;\n          }\n          if (numDocsStr != null) {\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", 1, true, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", -1, true, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      deletes = req.getDeleteQuery();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String q : deletes) {\n          if (!\"*:*\".equals(q)) {\n            throw new UnsupportedOperationException(\"Only '*:*' query is supported in deleteByQuery\");\n          }\n          for (Slice s : coll.getSlices()) {\n            Replica leader = s.getLeader();\n            if (leader == null) {\n              LOG.debug(\"-- no leader in \" + s);\n              continue;\n            }\n\n            cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n            String numDocsStr = leader.getStr(\"SEARCHER.searcher.numDocs\");\n            if (numDocsStr == null) {\n              continue;\n            }\n            long numDocs = Long.parseLong(numDocsStr);\n            if (numDocs == 0) {\n              continue;\n            }\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", numDocs, false, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 0, false, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      List<SolrInputDocument> docs = req.getDocuments();\n      if (docs != null && !docs.isEmpty()) {\n        for (SolrInputDocument doc : docs) {\n          String id = (String) doc.getFieldValue(\"id\");\n          if (id == null) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Document without id: \" + doc);\n          }\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          Replica leader = s.getLeader();\n          if (leader != null) {\n            cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          }\n          modified = true;\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 1, true, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.maxDoc\", 1, true, false);\n            // Policy reuses this value and expects it to be in GB units!!!\n            // the idea here is to increase the index size by 500 bytes with each doc\n            // simSetShardValue(collection, s.getName(), \"INDEX.sizeInBytes\", 500, true, false);\n          } catch (Exception e) {\n            throw new IOException(e);\n          }\n        }\n      }\n      if (modified) {\n        collectionsStatesRef.set(null);\n      }\n    } finally {\n      lock.unlock();\n    }\n    return new UpdateResponse();\n  }\n\n","sourceOld":"  /**\n   * Simulate an update by modifying replica metrics.\n   * The following core metrics are updated:\n   * <ul>\n   *   <li><code>SEARCHER.searcher.numDocs</code> - increased by added docs, decreased by deleteById and deleteByQuery</li>\n   *   <li><code>SEARCHER.searcher.deletedDocs</code> - decreased by deleteById and deleteByQuery by up to <code>numDocs</code></li>\n   *   <li><code>SEARCHER.searcher.maxDoc</code> - always increased by the number of added docs.</li>\n   * </ul>\n   * <p>IMPORTANT limitations:</p>\n   * <ul>\n   *   <li>document replacements are always counted as new docs</li>\n   *   <li>delete by ID always succeeds (unless numDocs == 0)</li>\n   *   <li>deleteByQuery is not supported unless the query is <code>*:*</code></li>\n   * </ul>\n   * @param req update request. This request MUST have the <code>collection</code> param set.\n   * @return {@link UpdateResponse}\n   * @throws SolrException on errors, such as nonexistent collection or unsupported deleteByQuery\n   */\n  public UpdateResponse simUpdate(UpdateRequest req) throws SolrException, InterruptedException, IOException {\n    String collection = req.getCollection();\n    if (collection == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection not set\");\n    }\n    if (!simListCollections().contains(collection)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection '\" + collection + \"' doesn't exist\");\n    }\n    // always reset first to get the current metrics - it's easier than to keep matching\n    // Replica with ReplicaInfo where the current real counts are stored\n    collectionsStatesRef.set(null);\n    DocCollection coll = getClusterState().getCollection(collection);\n    DocRouter router = coll.getRouter();\n\n    boolean modified = false;\n\n    lock.lockInterruptibly();\n    try {\n      List<String> deletes = req.getDeleteById();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String id : deletes) {\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          // NOTE: we don't use getProperty because it uses PROPERTY_PROP_PREFIX\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            LOG.debug(\"-- no leader in \" + s);\n            continue;\n          }\n          String numDocsStr = leader.getStr(\"SEARCHER.searcher.numDocs\");\n          if (numDocsStr == null) {\n            LOG.debug(\"-- no docs in \" + leader);\n            continue;\n          }\n          long numDocs = Long.parseLong(numDocsStr);\n          if (numDocs == 0) {\n            LOG.debug(\"-- attempting to delete nonexistent doc \" + id + \" from \" + s.getLeader());\n            continue;\n          }\n          if (numDocsStr != null) {\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", 1, true, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", -1, true, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      deletes = req.getDeleteQuery();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String q : deletes) {\n          if (!\"*:*\".equals(q)) {\n            throw new UnsupportedOperationException(\"Only '*:*' query is supported in deleteByQuery\");\n          }\n          for (Slice s : coll.getSlices()) {\n            String numDocsStr = s.getLeader().getStr(\"SEARCHER.searcher.numDocs\");\n            if (numDocsStr == null) {\n              continue;\n            }\n            long numDocs = Long.parseLong(numDocsStr);\n            if (numDocs == 0) {\n              continue;\n            }\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", numDocs, false, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 0, false, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      List<SolrInputDocument> docs = req.getDocuments();\n      if (docs != null && !docs.isEmpty()) {\n        for (SolrInputDocument doc : docs) {\n          String id = (String) doc.getFieldValue(\"id\");\n          if (id == null) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Document without id: \" + doc);\n          }\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          modified = true;\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 1, true, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.maxDoc\", 1, true, false);\n            // Policy reuses this value and expects it to be in GB units!!!\n            // the idea here is to increase the index size by 500 bytes with each doc\n            // simSetShardValue(collection, s.getName(), \"INDEX.sizeInBytes\", 500, true, false);\n          } catch (Exception e) {\n            throw new IOException(e);\n          }\n        }\n      }\n      if (modified) {\n        collectionsStatesRef.set(null);\n      }\n    } finally {\n      lock.unlock();\n    }\n    return new UpdateResponse();\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6b55cd711a129fb7fc4c3c4672d652149c9a4faa","date":1528813320,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simUpdate(UpdateRequest).mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simUpdate(UpdateRequest).mjava","sourceNew":"  /**\n   * Simulate an update by modifying replica metrics.\n   * The following core metrics are updated:\n   * <ul>\n   *   <li><code>SEARCHER.searcher.numDocs</code> - increased by added docs, decreased by deleteById and deleteByQuery</li>\n   *   <li><code>SEARCHER.searcher.deletedDocs</code> - decreased by deleteById and deleteByQuery by up to <code>numDocs</code></li>\n   *   <li><code>SEARCHER.searcher.maxDoc</code> - always increased by the number of added docs.</li>\n   * </ul>\n   * <p>IMPORTANT limitations:</p>\n   * <ul>\n   *   <li>document replacements are always counted as new docs</li>\n   *   <li>delete by ID always succeeds (unless numDocs == 0)</li>\n   *   <li>deleteByQuery is not supported unless the query is <code>*:*</code></li>\n   * </ul>\n   * @param req update request. This request MUST have the <code>collection</code> param set.\n   * @return {@link UpdateResponse}\n   * @throws SolrException on errors, such as nonexistent collection or unsupported deleteByQuery\n   */\n  public UpdateResponse simUpdate(UpdateRequest req) throws SolrException, InterruptedException, IOException {\n    String collection = req.getCollection();\n    if (collection == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection not set\");\n    }\n    if (!simListCollections().contains(collection)) {\n      if (CollectionAdminParams.SYSTEM_COLL.equals(collection)) {\n        // auto-create\n        createSystemCollection();\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection '\" + collection + \"' doesn't exist\");\n      }\n    }\n    // always reset first to get the current metrics - it's easier than to keep matching\n    // Replica with ReplicaInfo where the current real counts are stored\n    collectionsStatesRef.set(null);\n    DocCollection coll = getClusterState().getCollection(collection);\n    DocRouter router = coll.getRouter();\n\n    boolean modified = false;\n\n    lock.lockInterruptibly();\n    try {\n      List<String> deletes = req.getDeleteById();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String id : deletes) {\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          // NOTE: we don't use getProperty because it uses PROPERTY_PROP_PREFIX\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            LOG.debug(\"-- no leader in \" + s);\n            continue;\n          }\n          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          ReplicaInfo ri = getReplicaInfo(leader);\n          Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n          if (numDocs == null || numDocs.intValue() <= 0) {\n            LOG.debug(\"-- attempting to delete nonexistent doc \" + id + \" from \" + s.getLeader());\n            continue;\n          }\n          modified = true;\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", 1, true, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", -1, true, false);\n            Number indexSize = (Number)ri.getVariable(Suggestion.ConditionType.CORE_IDX.metricsAttribute);\n            if (indexSize != null && indexSize.longValue() > SimCloudManager.DEFAULT_IDX_SIZE_BYTES) {\n              indexSize = indexSize.longValue() - DEFAULT_DOC_SIZE_BYTES;\n              simSetShardValue(collection, s.getName(), Suggestion.ConditionType.CORE_IDX.metricsAttribute,\n                  indexSize.intValue(), false, false);\n              simSetShardValue(collection, s.getName(), Suggestion.coreidxsize,\n                  Suggestion.ConditionType.CORE_IDX.convertVal(indexSize), false, false);\n            } else {\n              throw new Exception(\"unexpected indexSize ri=\" + ri);\n            }\n          } catch (Exception e) {\n            throw new IOException(e);\n          }\n        }\n      }\n      deletes = req.getDeleteQuery();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String q : deletes) {\n          if (!\"*:*\".equals(q)) {\n            throw new UnsupportedOperationException(\"Only '*:*' query is supported in deleteByQuery\");\n          }\n          for (Slice s : coll.getSlices()) {\n            Replica leader = s.getLeader();\n            if (leader == null) {\n              LOG.debug(\"-- no leader in \" + s);\n              continue;\n            }\n\n            cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n            ReplicaInfo ri = getReplicaInfo(leader);\n            Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n            if (numDocs == null || numDocs.intValue() == 0) {\n              continue;\n            }\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", numDocs, false, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 0, false, false);\n              simSetShardValue(collection, s.getName(), Suggestion.ConditionType.CORE_IDX.metricsAttribute,\n                  SimCloudManager.DEFAULT_IDX_SIZE_BYTES, false, false);\n              simSetShardValue(collection, s.getName(), Suggestion.coreidxsize,\n                  Suggestion.ConditionType.CORE_IDX.convertVal(SimCloudManager.DEFAULT_IDX_SIZE_BYTES), false, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      List<SolrInputDocument> docs = req.getDocuments();\n      if (docs != null && !docs.isEmpty()) {\n        for (SolrInputDocument doc : docs) {\n          String id = (String) doc.getFieldValue(\"id\");\n          if (id == null) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Document without id: \" + doc);\n          }\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            LOG.debug(\"-- no leader in \" + s);\n            continue;\n          }\n          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          modified = true;\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 1, true, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.maxDoc\", 1, true, false);\n\n            ReplicaInfo ri = getReplicaInfo(leader);\n            Number indexSize = (Number)ri.getVariable(Suggestion.ConditionType.CORE_IDX.metricsAttribute);\n            // for each new document increase the size by DEFAULT_DOC_SIZE_BYTES\n            indexSize = indexSize.longValue() + DEFAULT_DOC_SIZE_BYTES;\n            simSetShardValue(collection, s.getName(), Suggestion.ConditionType.CORE_IDX.metricsAttribute,\n                indexSize.longValue(), false, false);\n            simSetShardValue(collection, s.getName(), Suggestion.coreidxsize,\n                Suggestion.ConditionType.CORE_IDX.convertVal(indexSize), false, false);\n          } catch (Exception e) {\n            throw new IOException(e);\n          }\n        }\n      }\n      if (modified) {\n        collectionsStatesRef.set(null);\n      }\n    } finally {\n      lock.unlock();\n    }\n    return new UpdateResponse();\n  }\n\n","sourceOld":"  /**\n   * Simulate an update by modifying replica metrics.\n   * The following core metrics are updated:\n   * <ul>\n   *   <li><code>SEARCHER.searcher.numDocs</code> - increased by added docs, decreased by deleteById and deleteByQuery</li>\n   *   <li><code>SEARCHER.searcher.deletedDocs</code> - decreased by deleteById and deleteByQuery by up to <code>numDocs</code></li>\n   *   <li><code>SEARCHER.searcher.maxDoc</code> - always increased by the number of added docs.</li>\n   * </ul>\n   * <p>IMPORTANT limitations:</p>\n   * <ul>\n   *   <li>document replacements are always counted as new docs</li>\n   *   <li>delete by ID always succeeds (unless numDocs == 0)</li>\n   *   <li>deleteByQuery is not supported unless the query is <code>*:*</code></li>\n   * </ul>\n   * @param req update request. This request MUST have the <code>collection</code> param set.\n   * @return {@link UpdateResponse}\n   * @throws SolrException on errors, such as nonexistent collection or unsupported deleteByQuery\n   */\n  public UpdateResponse simUpdate(UpdateRequest req) throws SolrException, InterruptedException, IOException {\n    String collection = req.getCollection();\n    if (collection == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection not set\");\n    }\n    if (!simListCollections().contains(collection)) {\n      if (CollectionAdminParams.SYSTEM_COLL.equals(collection)) {\n        // auto-create\n        createSystemCollection();\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection '\" + collection + \"' doesn't exist\");\n      }\n    }\n    // always reset first to get the current metrics - it's easier than to keep matching\n    // Replica with ReplicaInfo where the current real counts are stored\n    collectionsStatesRef.set(null);\n    DocCollection coll = getClusterState().getCollection(collection);\n    DocRouter router = coll.getRouter();\n\n    boolean modified = false;\n\n    lock.lockInterruptibly();\n    try {\n      List<String> deletes = req.getDeleteById();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String id : deletes) {\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          // NOTE: we don't use getProperty because it uses PROPERTY_PROP_PREFIX\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            LOG.debug(\"-- no leader in \" + s);\n            continue;\n          }\n          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          String numDocsStr = leader.getStr(\"SEARCHER.searcher.numDocs\");\n          if (numDocsStr == null) {\n            LOG.debug(\"-- no docs in \" + leader);\n            continue;\n          }\n          long numDocs = Long.parseLong(numDocsStr);\n          if (numDocs == 0) {\n            LOG.debug(\"-- attempting to delete nonexistent doc \" + id + \" from \" + s.getLeader());\n            continue;\n          }\n          if (numDocsStr != null) {\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", 1, true, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", -1, true, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      deletes = req.getDeleteQuery();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String q : deletes) {\n          if (!\"*:*\".equals(q)) {\n            throw new UnsupportedOperationException(\"Only '*:*' query is supported in deleteByQuery\");\n          }\n          for (Slice s : coll.getSlices()) {\n            Replica leader = s.getLeader();\n            if (leader == null) {\n              LOG.debug(\"-- no leader in \" + s);\n              continue;\n            }\n\n            cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n            String numDocsStr = leader.getStr(\"SEARCHER.searcher.numDocs\");\n            if (numDocsStr == null) {\n              continue;\n            }\n            long numDocs = Long.parseLong(numDocsStr);\n            if (numDocs == 0) {\n              continue;\n            }\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", numDocs, false, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 0, false, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      List<SolrInputDocument> docs = req.getDocuments();\n      if (docs != null && !docs.isEmpty()) {\n        for (SolrInputDocument doc : docs) {\n          String id = (String) doc.getFieldValue(\"id\");\n          if (id == null) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Document without id: \" + doc);\n          }\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          Replica leader = s.getLeader();\n          if (leader != null) {\n            cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          }\n          modified = true;\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 1, true, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.maxDoc\", 1, true, false);\n            // Policy reuses this value and expects it to be in GB units!!!\n            // the idea here is to increase the index size by 500 bytes with each doc\n            // simSetShardValue(collection, s.getName(), \"INDEX.sizeInBytes\", 500, true, false);\n          } catch (Exception e) {\n            throw new IOException(e);\n          }\n        }\n      }\n      if (modified) {\n        collectionsStatesRef.set(null);\n      }\n    } finally {\n      lock.unlock();\n    }\n    return new UpdateResponse();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simUpdate(UpdateRequest).mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simUpdate(UpdateRequest).mjava","sourceNew":"  /**\n   * Simulate an update by modifying replica metrics.\n   * The following core metrics are updated:\n   * <ul>\n   *   <li><code>SEARCHER.searcher.numDocs</code> - increased by added docs, decreased by deleteById and deleteByQuery</li>\n   *   <li><code>SEARCHER.searcher.deletedDocs</code> - decreased by deleteById and deleteByQuery by up to <code>numDocs</code></li>\n   *   <li><code>SEARCHER.searcher.maxDoc</code> - always increased by the number of added docs.</li>\n   * </ul>\n   * <p>IMPORTANT limitations:</p>\n   * <ul>\n   *   <li>document replacements are always counted as new docs</li>\n   *   <li>delete by ID always succeeds (unless numDocs == 0)</li>\n   *   <li>deleteByQuery is not supported unless the query is <code>*:*</code></li>\n   * </ul>\n   * @param req update request. This request MUST have the <code>collection</code> param set.\n   * @return {@link UpdateResponse}\n   * @throws SolrException on errors, such as nonexistent collection or unsupported deleteByQuery\n   */\n  public UpdateResponse simUpdate(UpdateRequest req) throws SolrException, InterruptedException, IOException {\n    String collection = req.getCollection();\n    if (collection == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection not set\");\n    }\n    if (!simListCollections().contains(collection)) {\n      if (CollectionAdminParams.SYSTEM_COLL.equals(collection)) {\n        // auto-create\n        createSystemCollection();\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection '\" + collection + \"' doesn't exist\");\n      }\n    }\n    // always reset first to get the current metrics - it's easier than to keep matching\n    // Replica with ReplicaInfo where the current real counts are stored\n    collectionsStatesRef.set(null);\n    DocCollection coll = getClusterState().getCollection(collection);\n    DocRouter router = coll.getRouter();\n\n    boolean modified = false;\n\n    lock.lockInterruptibly();\n    try {\n      List<String> deletes = req.getDeleteById();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String id : deletes) {\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          // NOTE: we don't use getProperty because it uses PROPERTY_PROP_PREFIX\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            LOG.debug(\"-- no leader in \" + s);\n            continue;\n          }\n          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          ReplicaInfo ri = getReplicaInfo(leader);\n          Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n          if (numDocs == null || numDocs.intValue() <= 0) {\n            LOG.debug(\"-- attempting to delete nonexistent doc \" + id + \" from \" + s.getLeader());\n            continue;\n          }\n          modified = true;\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", 1, true, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", -1, true, false);\n            Number indexSize = (Number)ri.getVariable(Suggestion.ConditionType.CORE_IDX.metricsAttribute);\n            if (indexSize != null && indexSize.longValue() > SimCloudManager.DEFAULT_IDX_SIZE_BYTES) {\n              indexSize = indexSize.longValue() - DEFAULT_DOC_SIZE_BYTES;\n              simSetShardValue(collection, s.getName(), Suggestion.ConditionType.CORE_IDX.metricsAttribute,\n                  indexSize.intValue(), false, false);\n              simSetShardValue(collection, s.getName(), Suggestion.coreidxsize,\n                  Suggestion.ConditionType.CORE_IDX.convertVal(indexSize), false, false);\n            } else {\n              throw new Exception(\"unexpected indexSize ri=\" + ri);\n            }\n          } catch (Exception e) {\n            throw new IOException(e);\n          }\n        }\n      }\n      deletes = req.getDeleteQuery();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String q : deletes) {\n          if (!\"*:*\".equals(q)) {\n            throw new UnsupportedOperationException(\"Only '*:*' query is supported in deleteByQuery\");\n          }\n          for (Slice s : coll.getSlices()) {\n            Replica leader = s.getLeader();\n            if (leader == null) {\n              LOG.debug(\"-- no leader in \" + s);\n              continue;\n            }\n\n            cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n            ReplicaInfo ri = getReplicaInfo(leader);\n            Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n            if (numDocs == null || numDocs.intValue() == 0) {\n              continue;\n            }\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", numDocs, false, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 0, false, false);\n              simSetShardValue(collection, s.getName(), Suggestion.ConditionType.CORE_IDX.metricsAttribute,\n                  SimCloudManager.DEFAULT_IDX_SIZE_BYTES, false, false);\n              simSetShardValue(collection, s.getName(), Suggestion.coreidxsize,\n                  Suggestion.ConditionType.CORE_IDX.convertVal(SimCloudManager.DEFAULT_IDX_SIZE_BYTES), false, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      List<SolrInputDocument> docs = req.getDocuments();\n      if (docs != null && !docs.isEmpty()) {\n        for (SolrInputDocument doc : docs) {\n          String id = (String) doc.getFieldValue(\"id\");\n          if (id == null) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Document without id: \" + doc);\n          }\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            LOG.debug(\"-- no leader in \" + s);\n            continue;\n          }\n          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          modified = true;\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 1, true, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.maxDoc\", 1, true, false);\n\n            ReplicaInfo ri = getReplicaInfo(leader);\n            Number indexSize = (Number)ri.getVariable(Suggestion.ConditionType.CORE_IDX.metricsAttribute);\n            // for each new document increase the size by DEFAULT_DOC_SIZE_BYTES\n            indexSize = indexSize.longValue() + DEFAULT_DOC_SIZE_BYTES;\n            simSetShardValue(collection, s.getName(), Suggestion.ConditionType.CORE_IDX.metricsAttribute,\n                indexSize.longValue(), false, false);\n            simSetShardValue(collection, s.getName(), Suggestion.coreidxsize,\n                Suggestion.ConditionType.CORE_IDX.convertVal(indexSize), false, false);\n          } catch (Exception e) {\n            throw new IOException(e);\n          }\n        }\n      }\n      if (modified) {\n        collectionsStatesRef.set(null);\n      }\n    } finally {\n      lock.unlock();\n    }\n    return new UpdateResponse();\n  }\n\n","sourceOld":"  /**\n   * Simulate an update by modifying replica metrics.\n   * The following core metrics are updated:\n   * <ul>\n   *   <li><code>SEARCHER.searcher.numDocs</code> - increased by added docs, decreased by deleteById and deleteByQuery</li>\n   *   <li><code>SEARCHER.searcher.deletedDocs</code> - decreased by deleteById and deleteByQuery by up to <code>numDocs</code></li>\n   *   <li><code>SEARCHER.searcher.maxDoc</code> - always increased by the number of added docs.</li>\n   * </ul>\n   * <p>IMPORTANT limitations:</p>\n   * <ul>\n   *   <li>document replacements are always counted as new docs</li>\n   *   <li>delete by ID always succeeds (unless numDocs == 0)</li>\n   *   <li>deleteByQuery is not supported unless the query is <code>*:*</code></li>\n   * </ul>\n   * @param req update request. This request MUST have the <code>collection</code> param set.\n   * @return {@link UpdateResponse}\n   * @throws SolrException on errors, such as nonexistent collection or unsupported deleteByQuery\n   */\n  public UpdateResponse simUpdate(UpdateRequest req) throws SolrException, InterruptedException, IOException {\n    String collection = req.getCollection();\n    if (collection == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection not set\");\n    }\n    if (!simListCollections().contains(collection)) {\n      if (CollectionAdminParams.SYSTEM_COLL.equals(collection)) {\n        // auto-create\n        createSystemCollection();\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection '\" + collection + \"' doesn't exist\");\n      }\n    }\n    // always reset first to get the current metrics - it's easier than to keep matching\n    // Replica with ReplicaInfo where the current real counts are stored\n    collectionsStatesRef.set(null);\n    DocCollection coll = getClusterState().getCollection(collection);\n    DocRouter router = coll.getRouter();\n\n    boolean modified = false;\n\n    lock.lockInterruptibly();\n    try {\n      List<String> deletes = req.getDeleteById();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String id : deletes) {\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          // NOTE: we don't use getProperty because it uses PROPERTY_PROP_PREFIX\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            LOG.debug(\"-- no leader in \" + s);\n            continue;\n          }\n          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          String numDocsStr = leader.getStr(\"SEARCHER.searcher.numDocs\");\n          if (numDocsStr == null) {\n            LOG.debug(\"-- no docs in \" + leader);\n            continue;\n          }\n          long numDocs = Long.parseLong(numDocsStr);\n          if (numDocs == 0) {\n            LOG.debug(\"-- attempting to delete nonexistent doc \" + id + \" from \" + s.getLeader());\n            continue;\n          }\n          if (numDocsStr != null) {\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", 1, true, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", -1, true, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      deletes = req.getDeleteQuery();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String q : deletes) {\n          if (!\"*:*\".equals(q)) {\n            throw new UnsupportedOperationException(\"Only '*:*' query is supported in deleteByQuery\");\n          }\n          for (Slice s : coll.getSlices()) {\n            Replica leader = s.getLeader();\n            if (leader == null) {\n              LOG.debug(\"-- no leader in \" + s);\n              continue;\n            }\n\n            cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n            String numDocsStr = leader.getStr(\"SEARCHER.searcher.numDocs\");\n            if (numDocsStr == null) {\n              continue;\n            }\n            long numDocs = Long.parseLong(numDocsStr);\n            if (numDocs == 0) {\n              continue;\n            }\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", numDocs, false, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 0, false, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      List<SolrInputDocument> docs = req.getDocuments();\n      if (docs != null && !docs.isEmpty()) {\n        for (SolrInputDocument doc : docs) {\n          String id = (String) doc.getFieldValue(\"id\");\n          if (id == null) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Document without id: \" + doc);\n          }\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          Replica leader = s.getLeader();\n          if (leader != null) {\n            cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          }\n          modified = true;\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 1, true, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.maxDoc\", 1, true, false);\n            // Policy reuses this value and expects it to be in GB units!!!\n            // the idea here is to increase the index size by 500 bytes with each doc\n            // simSetShardValue(collection, s.getName(), \"INDEX.sizeInBytes\", 500, true, false);\n          } catch (Exception e) {\n            throw new IOException(e);\n          }\n        }\n      }\n      if (modified) {\n        collectionsStatesRef.set(null);\n      }\n    } finally {\n      lock.unlock();\n    }\n    return new UpdateResponse();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simUpdate(UpdateRequest).mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simUpdate(UpdateRequest).mjava","sourceNew":"  /**\n   * Simulate an update by modifying replica metrics.\n   * The following core metrics are updated:\n   * <ul>\n   *   <li><code>SEARCHER.searcher.numDocs</code> - increased by added docs, decreased by deleteById and deleteByQuery</li>\n   *   <li><code>SEARCHER.searcher.deletedDocs</code> - decreased by deleteById and deleteByQuery by up to <code>numDocs</code></li>\n   *   <li><code>SEARCHER.searcher.maxDoc</code> - always increased by the number of added docs.</li>\n   * </ul>\n   * <p>IMPORTANT limitations:</p>\n   * <ul>\n   *   <li>document replacements are always counted as new docs</li>\n   *   <li>delete by ID always succeeds (unless numDocs == 0)</li>\n   *   <li>deleteByQuery is not supported unless the query is <code>*:*</code></li>\n   * </ul>\n   * @param req update request. This request MUST have the <code>collection</code> param set.\n   * @return {@link UpdateResponse}\n   * @throws SolrException on errors, such as nonexistent collection or unsupported deleteByQuery\n   */\n  public UpdateResponse simUpdate(UpdateRequest req) throws SolrException, InterruptedException, IOException {\n    String collection = req.getCollection();\n    if (collection == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection not set\");\n    }\n    if (!simListCollections().contains(collection)) {\n      if (CollectionAdminParams.SYSTEM_COLL.equals(collection)) {\n        // auto-create\n        createSystemCollection();\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection '\" + collection + \"' doesn't exist\");\n      }\n    }\n    // always reset first to get the current metrics - it's easier than to keep matching\n    // Replica with ReplicaInfo where the current real counts are stored\n    collectionsStatesRef.set(null);\n    DocCollection coll = getClusterState().getCollection(collection);\n    DocRouter router = coll.getRouter();\n\n    boolean modified = false;\n\n    lock.lockInterruptibly();\n    try {\n      List<String> deletes = req.getDeleteById();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String id : deletes) {\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          // NOTE: we don't use getProperty because it uses PROPERTY_PROP_PREFIX\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            LOG.debug(\"-- no leader in \" + s);\n            continue;\n          }\n          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          ReplicaInfo ri = getReplicaInfo(leader);\n          Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n          if (numDocs == null || numDocs.intValue() <= 0) {\n            LOG.debug(\"-- attempting to delete nonexistent doc \" + id + \" from \" + s.getLeader());\n            continue;\n          }\n          modified = true;\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", 1, true, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", -1, true, false);\n            Number indexSize = (Number)ri.getVariable(Suggestion.ConditionType.CORE_IDX.metricsAttribute);\n            if (indexSize != null && indexSize.longValue() > SimCloudManager.DEFAULT_IDX_SIZE_BYTES) {\n              indexSize = indexSize.longValue() - DEFAULT_DOC_SIZE_BYTES;\n              simSetShardValue(collection, s.getName(), Suggestion.ConditionType.CORE_IDX.metricsAttribute,\n                  indexSize.intValue(), false, false);\n              simSetShardValue(collection, s.getName(), Suggestion.coreidxsize,\n                  Suggestion.ConditionType.CORE_IDX.convertVal(indexSize), false, false);\n            } else {\n              throw new Exception(\"unexpected indexSize ri=\" + ri);\n            }\n          } catch (Exception e) {\n            throw new IOException(e);\n          }\n        }\n      }\n      deletes = req.getDeleteQuery();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String q : deletes) {\n          if (!\"*:*\".equals(q)) {\n            throw new UnsupportedOperationException(\"Only '*:*' query is supported in deleteByQuery\");\n          }\n          for (Slice s : coll.getSlices()) {\n            Replica leader = s.getLeader();\n            if (leader == null) {\n              LOG.debug(\"-- no leader in \" + s);\n              continue;\n            }\n\n            cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n            ReplicaInfo ri = getReplicaInfo(leader);\n            Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n            if (numDocs == null || numDocs.intValue() == 0) {\n              continue;\n            }\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", numDocs, false, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 0, false, false);\n              simSetShardValue(collection, s.getName(), Suggestion.ConditionType.CORE_IDX.metricsAttribute,\n                  SimCloudManager.DEFAULT_IDX_SIZE_BYTES, false, false);\n              simSetShardValue(collection, s.getName(), Suggestion.coreidxsize,\n                  Suggestion.ConditionType.CORE_IDX.convertVal(SimCloudManager.DEFAULT_IDX_SIZE_BYTES), false, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      List<SolrInputDocument> docs = req.getDocuments();\n      if (docs != null && !docs.isEmpty()) {\n        for (SolrInputDocument doc : docs) {\n          String id = (String) doc.getFieldValue(\"id\");\n          if (id == null) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Document without id: \" + doc);\n          }\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            LOG.debug(\"-- no leader in \" + s);\n            continue;\n          }\n          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          modified = true;\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 1, true, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.maxDoc\", 1, true, false);\n\n            ReplicaInfo ri = getReplicaInfo(leader);\n            Number indexSize = (Number)ri.getVariable(Suggestion.ConditionType.CORE_IDX.metricsAttribute);\n            // for each new document increase the size by DEFAULT_DOC_SIZE_BYTES\n            indexSize = indexSize.longValue() + DEFAULT_DOC_SIZE_BYTES;\n            simSetShardValue(collection, s.getName(), Suggestion.ConditionType.CORE_IDX.metricsAttribute,\n                indexSize.longValue(), false, false);\n            simSetShardValue(collection, s.getName(), Suggestion.coreidxsize,\n                Suggestion.ConditionType.CORE_IDX.convertVal(indexSize), false, false);\n          } catch (Exception e) {\n            throw new IOException(e);\n          }\n        }\n      }\n      if (modified) {\n        collectionsStatesRef.set(null);\n      }\n    } finally {\n      lock.unlock();\n    }\n    return new UpdateResponse();\n  }\n\n","sourceOld":"  /**\n   * Simulate an update by modifying replica metrics.\n   * The following core metrics are updated:\n   * <ul>\n   *   <li><code>SEARCHER.searcher.numDocs</code> - increased by added docs, decreased by deleteById and deleteByQuery</li>\n   *   <li><code>SEARCHER.searcher.deletedDocs</code> - decreased by deleteById and deleteByQuery by up to <code>numDocs</code></li>\n   *   <li><code>SEARCHER.searcher.maxDoc</code> - always increased by the number of added docs.</li>\n   * </ul>\n   * <p>IMPORTANT limitations:</p>\n   * <ul>\n   *   <li>document replacements are always counted as new docs</li>\n   *   <li>delete by ID always succeeds (unless numDocs == 0)</li>\n   *   <li>deleteByQuery is not supported unless the query is <code>*:*</code></li>\n   * </ul>\n   * @param req update request. This request MUST have the <code>collection</code> param set.\n   * @return {@link UpdateResponse}\n   * @throws SolrException on errors, such as nonexistent collection or unsupported deleteByQuery\n   */\n  public UpdateResponse simUpdate(UpdateRequest req) throws SolrException, InterruptedException, IOException {\n    String collection = req.getCollection();\n    if (collection == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection not set\");\n    }\n    if (!simListCollections().contains(collection)) {\n      if (CollectionAdminParams.SYSTEM_COLL.equals(collection)) {\n        // auto-create\n        createSystemCollection();\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection '\" + collection + \"' doesn't exist\");\n      }\n    }\n    // always reset first to get the current metrics - it's easier than to keep matching\n    // Replica with ReplicaInfo where the current real counts are stored\n    collectionsStatesRef.set(null);\n    DocCollection coll = getClusterState().getCollection(collection);\n    DocRouter router = coll.getRouter();\n\n    boolean modified = false;\n\n    lock.lockInterruptibly();\n    try {\n      List<String> deletes = req.getDeleteById();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String id : deletes) {\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          // NOTE: we don't use getProperty because it uses PROPERTY_PROP_PREFIX\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            LOG.debug(\"-- no leader in \" + s);\n            continue;\n          }\n          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          String numDocsStr = leader.getStr(\"SEARCHER.searcher.numDocs\");\n          if (numDocsStr == null) {\n            LOG.debug(\"-- no docs in \" + leader);\n            continue;\n          }\n          long numDocs = Long.parseLong(numDocsStr);\n          if (numDocs == 0) {\n            LOG.debug(\"-- attempting to delete nonexistent doc \" + id + \" from \" + s.getLeader());\n            continue;\n          }\n          if (numDocsStr != null) {\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", 1, true, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", -1, true, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      deletes = req.getDeleteQuery();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String q : deletes) {\n          if (!\"*:*\".equals(q)) {\n            throw new UnsupportedOperationException(\"Only '*:*' query is supported in deleteByQuery\");\n          }\n          for (Slice s : coll.getSlices()) {\n            Replica leader = s.getLeader();\n            if (leader == null) {\n              LOG.debug(\"-- no leader in \" + s);\n              continue;\n            }\n\n            cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n            String numDocsStr = leader.getStr(\"SEARCHER.searcher.numDocs\");\n            if (numDocsStr == null) {\n              continue;\n            }\n            long numDocs = Long.parseLong(numDocsStr);\n            if (numDocs == 0) {\n              continue;\n            }\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", numDocs, false, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 0, false, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      List<SolrInputDocument> docs = req.getDocuments();\n      if (docs != null && !docs.isEmpty()) {\n        for (SolrInputDocument doc : docs) {\n          String id = (String) doc.getFieldValue(\"id\");\n          if (id == null) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Document without id: \" + doc);\n          }\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          Replica leader = s.getLeader();\n          if (leader != null) {\n            cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          }\n          modified = true;\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 1, true, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.maxDoc\", 1, true, false);\n            // Policy reuses this value and expects it to be in GB units!!!\n            // the idea here is to increase the index size by 500 bytes with each doc\n            // simSetShardValue(collection, s.getName(), \"INDEX.sizeInBytes\", 500, true, false);\n          } catch (Exception e) {\n            throw new IOException(e);\n          }\n        }\n      }\n      if (modified) {\n        collectionsStatesRef.set(null);\n      }\n    } finally {\n      lock.unlock();\n    }\n    return new UpdateResponse();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"427edb17549d4bb82462a16eec4ee0533d12d5b7","date":1533006754,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simUpdate(UpdateRequest).mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simUpdate(UpdateRequest).mjava","sourceNew":"  /**\n   * Simulate an update by modifying replica metrics.\n   * The following core metrics are updated:\n   * <ul>\n   *   <li><code>SEARCHER.searcher.numDocs</code> - increased by added docs, decreased by deleteById and deleteByQuery</li>\n   *   <li><code>SEARCHER.searcher.deletedDocs</code> - decreased by deleteById and deleteByQuery by up to <code>numDocs</code></li>\n   *   <li><code>SEARCHER.searcher.maxDoc</code> - always increased by the number of added docs.</li>\n   * </ul>\n   * <p>IMPORTANT limitations:</p>\n   * <ul>\n   *   <li>document replacements are always counted as new docs</li>\n   *   <li>delete by ID always succeeds (unless numDocs == 0)</li>\n   *   <li>deleteByQuery is not supported unless the query is <code>*:*</code></li>\n   * </ul>\n   * @param req update request. This request MUST have the <code>collection</code> param set.\n   * @return {@link UpdateResponse}\n   * @throws SolrException on errors, such as nonexistent collection or unsupported deleteByQuery\n   */\n  public UpdateResponse simUpdate(UpdateRequest req) throws SolrException, InterruptedException, IOException {\n    String collection = req.getCollection();\n    if (collection == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection not set\");\n    }\n    if (!simListCollections().contains(collection)) {\n      if (CollectionAdminParams.SYSTEM_COLL.equals(collection)) {\n        // auto-create\n        createSystemCollection();\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection '\" + collection + \"' doesn't exist\");\n      }\n    }\n    // always reset first to get the current metrics - it's easier than to keep matching\n    // Replica with ReplicaInfo where the current real counts are stored\n    collectionsStatesRef.set(null);\n    DocCollection coll = getClusterState().getCollection(collection);\n    DocRouter router = coll.getRouter();\n\n    boolean modified = false;\n\n    lock.lockInterruptibly();\n    try {\n      List<String> deletes = req.getDeleteById();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String id : deletes) {\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          // NOTE: we don't use getProperty because it uses PROPERTY_PROP_PREFIX\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            LOG.debug(\"-- no leader in \" + s);\n            continue;\n          }\n          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          ReplicaInfo ri = getReplicaInfo(leader);\n          Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n          if (numDocs == null || numDocs.intValue() <= 0) {\n            LOG.debug(\"-- attempting to delete nonexistent doc \" + id + \" from \" + s.getLeader());\n            continue;\n          }\n          modified = true;\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", 1, true, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", -1, true, false);\n            Number indexSize = (Number)ri.getVariable(Type.CORE_IDX.metricsAttribute);\n            if (indexSize != null && indexSize.longValue() > SimCloudManager.DEFAULT_IDX_SIZE_BYTES) {\n              indexSize = indexSize.longValue() - DEFAULT_DOC_SIZE_BYTES;\n              simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                  indexSize.intValue(), false, false);\n              simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                  Type.CORE_IDX.convertVal(indexSize), false, false);\n            } else {\n              throw new Exception(\"unexpected indexSize ri=\" + ri);\n            }\n          } catch (Exception e) {\n            throw new IOException(e);\n          }\n        }\n      }\n      deletes = req.getDeleteQuery();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String q : deletes) {\n          if (!\"*:*\".equals(q)) {\n            throw new UnsupportedOperationException(\"Only '*:*' query is supported in deleteByQuery\");\n          }\n          for (Slice s : coll.getSlices()) {\n            Replica leader = s.getLeader();\n            if (leader == null) {\n              LOG.debug(\"-- no leader in \" + s);\n              continue;\n            }\n\n            cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n            ReplicaInfo ri = getReplicaInfo(leader);\n            Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n            if (numDocs == null || numDocs.intValue() == 0) {\n              continue;\n            }\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", numDocs, false, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 0, false, false);\n              simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                  SimCloudManager.DEFAULT_IDX_SIZE_BYTES, false, false);\n              simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                  Type.CORE_IDX.convertVal(SimCloudManager.DEFAULT_IDX_SIZE_BYTES), false, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      List<SolrInputDocument> docs = req.getDocuments();\n      if (docs != null && !docs.isEmpty()) {\n        for (SolrInputDocument doc : docs) {\n          String id = (String) doc.getFieldValue(\"id\");\n          if (id == null) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Document without id: \" + doc);\n          }\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            LOG.debug(\"-- no leader in \" + s);\n            continue;\n          }\n          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          modified = true;\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 1, true, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.maxDoc\", 1, true, false);\n\n            ReplicaInfo ri = getReplicaInfo(leader);\n            Number indexSize = (Number)ri.getVariable(Type.CORE_IDX.metricsAttribute);\n            // for each new document increase the size by DEFAULT_DOC_SIZE_BYTES\n            indexSize = indexSize.longValue() + DEFAULT_DOC_SIZE_BYTES;\n            simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                indexSize.longValue(), false, false);\n            simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                Type.CORE_IDX.convertVal(indexSize), false, false);\n          } catch (Exception e) {\n            throw new IOException(e);\n          }\n        }\n      }\n      if (modified) {\n        collectionsStatesRef.set(null);\n      }\n    } finally {\n      lock.unlock();\n    }\n    return new UpdateResponse();\n  }\n\n","sourceOld":"  /**\n   * Simulate an update by modifying replica metrics.\n   * The following core metrics are updated:\n   * <ul>\n   *   <li><code>SEARCHER.searcher.numDocs</code> - increased by added docs, decreased by deleteById and deleteByQuery</li>\n   *   <li><code>SEARCHER.searcher.deletedDocs</code> - decreased by deleteById and deleteByQuery by up to <code>numDocs</code></li>\n   *   <li><code>SEARCHER.searcher.maxDoc</code> - always increased by the number of added docs.</li>\n   * </ul>\n   * <p>IMPORTANT limitations:</p>\n   * <ul>\n   *   <li>document replacements are always counted as new docs</li>\n   *   <li>delete by ID always succeeds (unless numDocs == 0)</li>\n   *   <li>deleteByQuery is not supported unless the query is <code>*:*</code></li>\n   * </ul>\n   * @param req update request. This request MUST have the <code>collection</code> param set.\n   * @return {@link UpdateResponse}\n   * @throws SolrException on errors, such as nonexistent collection or unsupported deleteByQuery\n   */\n  public UpdateResponse simUpdate(UpdateRequest req) throws SolrException, InterruptedException, IOException {\n    String collection = req.getCollection();\n    if (collection == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection not set\");\n    }\n    if (!simListCollections().contains(collection)) {\n      if (CollectionAdminParams.SYSTEM_COLL.equals(collection)) {\n        // auto-create\n        createSystemCollection();\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection '\" + collection + \"' doesn't exist\");\n      }\n    }\n    // always reset first to get the current metrics - it's easier than to keep matching\n    // Replica with ReplicaInfo where the current real counts are stored\n    collectionsStatesRef.set(null);\n    DocCollection coll = getClusterState().getCollection(collection);\n    DocRouter router = coll.getRouter();\n\n    boolean modified = false;\n\n    lock.lockInterruptibly();\n    try {\n      List<String> deletes = req.getDeleteById();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String id : deletes) {\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          // NOTE: we don't use getProperty because it uses PROPERTY_PROP_PREFIX\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            LOG.debug(\"-- no leader in \" + s);\n            continue;\n          }\n          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          ReplicaInfo ri = getReplicaInfo(leader);\n          Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n          if (numDocs == null || numDocs.intValue() <= 0) {\n            LOG.debug(\"-- attempting to delete nonexistent doc \" + id + \" from \" + s.getLeader());\n            continue;\n          }\n          modified = true;\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", 1, true, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", -1, true, false);\n            Number indexSize = (Number)ri.getVariable(Suggestion.ConditionType.CORE_IDX.metricsAttribute);\n            if (indexSize != null && indexSize.longValue() > SimCloudManager.DEFAULT_IDX_SIZE_BYTES) {\n              indexSize = indexSize.longValue() - DEFAULT_DOC_SIZE_BYTES;\n              simSetShardValue(collection, s.getName(), Suggestion.ConditionType.CORE_IDX.metricsAttribute,\n                  indexSize.intValue(), false, false);\n              simSetShardValue(collection, s.getName(), Suggestion.coreidxsize,\n                  Suggestion.ConditionType.CORE_IDX.convertVal(indexSize), false, false);\n            } else {\n              throw new Exception(\"unexpected indexSize ri=\" + ri);\n            }\n          } catch (Exception e) {\n            throw new IOException(e);\n          }\n        }\n      }\n      deletes = req.getDeleteQuery();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String q : deletes) {\n          if (!\"*:*\".equals(q)) {\n            throw new UnsupportedOperationException(\"Only '*:*' query is supported in deleteByQuery\");\n          }\n          for (Slice s : coll.getSlices()) {\n            Replica leader = s.getLeader();\n            if (leader == null) {\n              LOG.debug(\"-- no leader in \" + s);\n              continue;\n            }\n\n            cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n            ReplicaInfo ri = getReplicaInfo(leader);\n            Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n            if (numDocs == null || numDocs.intValue() == 0) {\n              continue;\n            }\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", numDocs, false, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 0, false, false);\n              simSetShardValue(collection, s.getName(), Suggestion.ConditionType.CORE_IDX.metricsAttribute,\n                  SimCloudManager.DEFAULT_IDX_SIZE_BYTES, false, false);\n              simSetShardValue(collection, s.getName(), Suggestion.coreidxsize,\n                  Suggestion.ConditionType.CORE_IDX.convertVal(SimCloudManager.DEFAULT_IDX_SIZE_BYTES), false, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      List<SolrInputDocument> docs = req.getDocuments();\n      if (docs != null && !docs.isEmpty()) {\n        for (SolrInputDocument doc : docs) {\n          String id = (String) doc.getFieldValue(\"id\");\n          if (id == null) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Document without id: \" + doc);\n          }\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            LOG.debug(\"-- no leader in \" + s);\n            continue;\n          }\n          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          modified = true;\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 1, true, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.maxDoc\", 1, true, false);\n\n            ReplicaInfo ri = getReplicaInfo(leader);\n            Number indexSize = (Number)ri.getVariable(Suggestion.ConditionType.CORE_IDX.metricsAttribute);\n            // for each new document increase the size by DEFAULT_DOC_SIZE_BYTES\n            indexSize = indexSize.longValue() + DEFAULT_DOC_SIZE_BYTES;\n            simSetShardValue(collection, s.getName(), Suggestion.ConditionType.CORE_IDX.metricsAttribute,\n                indexSize.longValue(), false, false);\n            simSetShardValue(collection, s.getName(), Suggestion.coreidxsize,\n                Suggestion.ConditionType.CORE_IDX.convertVal(indexSize), false, false);\n          } catch (Exception e) {\n            throw new IOException(e);\n          }\n        }\n      }\n      if (modified) {\n        collectionsStatesRef.set(null);\n      }\n    } finally {\n      lock.unlock();\n    }\n    return new UpdateResponse();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"042b92cf48996255bedb0c3c4bf772d7e06e4dea","date":1534272102,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simUpdate(UpdateRequest).mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simUpdate(UpdateRequest).mjava","sourceNew":"  /**\n   * Simulate an update by modifying replica metrics.\n   * The following core metrics are updated:\n   * <ul>\n   *   <li><code>SEARCHER.searcher.numDocs</code> - increased by added docs, decreased by deleteById and deleteByQuery</li>\n   *   <li><code>SEARCHER.searcher.deletedDocs</code> - decreased by deleteById and deleteByQuery by up to <code>numDocs</code></li>\n   *   <li><code>SEARCHER.searcher.maxDoc</code> - always increased by the number of added docs.</li>\n   * </ul>\n   * <p>IMPORTANT limitations:</p>\n   * <ul>\n   *   <li>document replacements are always counted as new docs</li>\n   *   <li>delete by ID always succeeds (unless numDocs == 0)</li>\n   *   <li>deleteByQuery is not supported unless the query is <code>*:*</code></li>\n   * </ul>\n   * @param req update request. This request MUST have the <code>collection</code> param set.\n   * @return {@link UpdateResponse}\n   * @throws SolrException on errors, such as nonexistent collection or unsupported deleteByQuery\n   */\n  public UpdateResponse simUpdate(UpdateRequest req) throws SolrException, InterruptedException, IOException {\n    ensureNotClosed();\n    String collection = req.getCollection();\n    if (collection == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection not set\");\n    }\n    if (!simListCollections().contains(collection)) {\n      if (CollectionAdminParams.SYSTEM_COLL.equals(collection)) {\n        // auto-create\n        createSystemCollection();\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection '\" + collection + \"' doesn't exist\");\n      }\n    }\n    // always reset first to get the current metrics - it's easier than to keep matching\n    // Replica with ReplicaInfo where the current real counts are stored\n    collectionsStatesRef.set(null);\n    DocCollection coll = getClusterState().getCollection(collection);\n    DocRouter router = coll.getRouter();\n\n    boolean modified = false;\n\n    lock.lockInterruptibly();\n    try {\n      List<String> deletes = req.getDeleteById();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String id : deletes) {\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          // NOTE: we don't use getProperty because it uses PROPERTY_PROP_PREFIX\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            LOG.debug(\"-- no leader in \" + s);\n            continue;\n          }\n          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          ReplicaInfo ri = getReplicaInfo(leader);\n          Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n          if (numDocs == null || numDocs.intValue() <= 0) {\n            LOG.debug(\"-- attempting to delete nonexistent doc \" + id + \" from \" + s.getLeader());\n            continue;\n          }\n          modified = true;\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", 1, true, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", -1, true, false);\n            Number indexSize = (Number)ri.getVariable(Type.CORE_IDX.metricsAttribute);\n            if (indexSize != null && indexSize.longValue() > SimCloudManager.DEFAULT_IDX_SIZE_BYTES) {\n              indexSize = indexSize.longValue() - DEFAULT_DOC_SIZE_BYTES;\n              simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                  indexSize.intValue(), false, false);\n              simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                  Type.CORE_IDX.convertVal(indexSize), false, false);\n            } else {\n              throw new Exception(\"unexpected indexSize ri=\" + ri);\n            }\n          } catch (Exception e) {\n            throw new IOException(e);\n          }\n        }\n      }\n      deletes = req.getDeleteQuery();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String q : deletes) {\n          if (!\"*:*\".equals(q)) {\n            throw new UnsupportedOperationException(\"Only '*:*' query is supported in deleteByQuery\");\n          }\n          for (Slice s : coll.getSlices()) {\n            Replica leader = s.getLeader();\n            if (leader == null) {\n              LOG.debug(\"-- no leader in \" + s);\n              continue;\n            }\n\n            cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n            ReplicaInfo ri = getReplicaInfo(leader);\n            Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n            if (numDocs == null || numDocs.intValue() == 0) {\n              continue;\n            }\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", numDocs, false, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 0, false, false);\n              simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                  SimCloudManager.DEFAULT_IDX_SIZE_BYTES, false, false);\n              simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                  Type.CORE_IDX.convertVal(SimCloudManager.DEFAULT_IDX_SIZE_BYTES), false, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      List<SolrInputDocument> docs = req.getDocuments();\n      if (docs != null && !docs.isEmpty()) {\n        for (SolrInputDocument doc : docs) {\n          String id = (String) doc.getFieldValue(\"id\");\n          if (id == null) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Document without id: \" + doc);\n          }\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            LOG.debug(\"-- no leader in \" + s);\n            continue;\n          }\n          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          modified = true;\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 1, true, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.maxDoc\", 1, true, false);\n\n            ReplicaInfo ri = getReplicaInfo(leader);\n            Number indexSize = (Number)ri.getVariable(Type.CORE_IDX.metricsAttribute);\n            // for each new document increase the size by DEFAULT_DOC_SIZE_BYTES\n            indexSize = indexSize.longValue() + DEFAULT_DOC_SIZE_BYTES;\n            simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                indexSize.longValue(), false, false);\n            simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                Type.CORE_IDX.convertVal(indexSize), false, false);\n          } catch (Exception e) {\n            throw new IOException(e);\n          }\n        }\n      }\n      if (modified) {\n        collectionsStatesRef.set(null);\n      }\n    } finally {\n      lock.unlock();\n    }\n    return new UpdateResponse();\n  }\n\n","sourceOld":"  /**\n   * Simulate an update by modifying replica metrics.\n   * The following core metrics are updated:\n   * <ul>\n   *   <li><code>SEARCHER.searcher.numDocs</code> - increased by added docs, decreased by deleteById and deleteByQuery</li>\n   *   <li><code>SEARCHER.searcher.deletedDocs</code> - decreased by deleteById and deleteByQuery by up to <code>numDocs</code></li>\n   *   <li><code>SEARCHER.searcher.maxDoc</code> - always increased by the number of added docs.</li>\n   * </ul>\n   * <p>IMPORTANT limitations:</p>\n   * <ul>\n   *   <li>document replacements are always counted as new docs</li>\n   *   <li>delete by ID always succeeds (unless numDocs == 0)</li>\n   *   <li>deleteByQuery is not supported unless the query is <code>*:*</code></li>\n   * </ul>\n   * @param req update request. This request MUST have the <code>collection</code> param set.\n   * @return {@link UpdateResponse}\n   * @throws SolrException on errors, such as nonexistent collection or unsupported deleteByQuery\n   */\n  public UpdateResponse simUpdate(UpdateRequest req) throws SolrException, InterruptedException, IOException {\n    String collection = req.getCollection();\n    if (collection == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection not set\");\n    }\n    if (!simListCollections().contains(collection)) {\n      if (CollectionAdminParams.SYSTEM_COLL.equals(collection)) {\n        // auto-create\n        createSystemCollection();\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection '\" + collection + \"' doesn't exist\");\n      }\n    }\n    // always reset first to get the current metrics - it's easier than to keep matching\n    // Replica with ReplicaInfo where the current real counts are stored\n    collectionsStatesRef.set(null);\n    DocCollection coll = getClusterState().getCollection(collection);\n    DocRouter router = coll.getRouter();\n\n    boolean modified = false;\n\n    lock.lockInterruptibly();\n    try {\n      List<String> deletes = req.getDeleteById();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String id : deletes) {\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          // NOTE: we don't use getProperty because it uses PROPERTY_PROP_PREFIX\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            LOG.debug(\"-- no leader in \" + s);\n            continue;\n          }\n          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          ReplicaInfo ri = getReplicaInfo(leader);\n          Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n          if (numDocs == null || numDocs.intValue() <= 0) {\n            LOG.debug(\"-- attempting to delete nonexistent doc \" + id + \" from \" + s.getLeader());\n            continue;\n          }\n          modified = true;\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", 1, true, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", -1, true, false);\n            Number indexSize = (Number)ri.getVariable(Type.CORE_IDX.metricsAttribute);\n            if (indexSize != null && indexSize.longValue() > SimCloudManager.DEFAULT_IDX_SIZE_BYTES) {\n              indexSize = indexSize.longValue() - DEFAULT_DOC_SIZE_BYTES;\n              simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                  indexSize.intValue(), false, false);\n              simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                  Type.CORE_IDX.convertVal(indexSize), false, false);\n            } else {\n              throw new Exception(\"unexpected indexSize ri=\" + ri);\n            }\n          } catch (Exception e) {\n            throw new IOException(e);\n          }\n        }\n      }\n      deletes = req.getDeleteQuery();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String q : deletes) {\n          if (!\"*:*\".equals(q)) {\n            throw new UnsupportedOperationException(\"Only '*:*' query is supported in deleteByQuery\");\n          }\n          for (Slice s : coll.getSlices()) {\n            Replica leader = s.getLeader();\n            if (leader == null) {\n              LOG.debug(\"-- no leader in \" + s);\n              continue;\n            }\n\n            cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n            ReplicaInfo ri = getReplicaInfo(leader);\n            Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n            if (numDocs == null || numDocs.intValue() == 0) {\n              continue;\n            }\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", numDocs, false, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 0, false, false);\n              simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                  SimCloudManager.DEFAULT_IDX_SIZE_BYTES, false, false);\n              simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                  Type.CORE_IDX.convertVal(SimCloudManager.DEFAULT_IDX_SIZE_BYTES), false, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      List<SolrInputDocument> docs = req.getDocuments();\n      if (docs != null && !docs.isEmpty()) {\n        for (SolrInputDocument doc : docs) {\n          String id = (String) doc.getFieldValue(\"id\");\n          if (id == null) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Document without id: \" + doc);\n          }\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            LOG.debug(\"-- no leader in \" + s);\n            continue;\n          }\n          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          modified = true;\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 1, true, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.maxDoc\", 1, true, false);\n\n            ReplicaInfo ri = getReplicaInfo(leader);\n            Number indexSize = (Number)ri.getVariable(Type.CORE_IDX.metricsAttribute);\n            // for each new document increase the size by DEFAULT_DOC_SIZE_BYTES\n            indexSize = indexSize.longValue() + DEFAULT_DOC_SIZE_BYTES;\n            simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                indexSize.longValue(), false, false);\n            simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                Type.CORE_IDX.convertVal(indexSize), false, false);\n          } catch (Exception e) {\n            throw new IOException(e);\n          }\n        }\n      }\n      if (modified) {\n        collectionsStatesRef.set(null);\n      }\n    } finally {\n      lock.unlock();\n    }\n    return new UpdateResponse();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e9c81f7e703d7ccca5bc78beb61253f0a8a22afd","date":1534976797,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simUpdate(UpdateRequest).mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simUpdate(UpdateRequest).mjava","sourceNew":"  /**\n   * Simulate an update by modifying replica metrics.\n   * The following core metrics are updated:\n   * <ul>\n   *   <li><code>SEARCHER.searcher.numDocs</code> - increased by added docs, decreased by deleteById and deleteByQuery</li>\n   *   <li><code>SEARCHER.searcher.deletedDocs</code> - decreased by deleteById and deleteByQuery by up to <code>numDocs</code></li>\n   *   <li><code>SEARCHER.searcher.maxDoc</code> - always increased by the number of added docs.</li>\n   * </ul>\n   * <p>IMPORTANT limitations:</p>\n   * <ul>\n   *   <li>document replacements are always counted as new docs</li>\n   *   <li>delete by ID always succeeds (unless numDocs == 0)</li>\n   *   <li>deleteByQuery is not supported unless the query is <code>*:*</code></li>\n   * </ul>\n   * @param req update request. This request MUST have the <code>collection</code> param set.\n   * @return {@link UpdateResponse}\n   * @throws SolrException on errors, such as nonexistent collection or unsupported deleteByQuery\n   */\n  public UpdateResponse simUpdate(UpdateRequest req) throws SolrException, InterruptedException, IOException {\n    ensureNotClosed();\n    String collection = req.getCollection();\n    if (collection == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection not set\");\n    }\n    if (!simListCollections().contains(collection)) {\n      if (CollectionAdminParams.SYSTEM_COLL.equals(collection)) {\n        // auto-create\n        createSystemCollection();\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection '\" + collection + \"' doesn't exist\");\n      }\n    }\n    // always reset first to get the current metrics - it's easier than to keep matching\n    // Replica with ReplicaInfo where the current real counts are stored\n    collectionsStatesRef.set(null);\n    DocCollection coll = getClusterState().getCollection(collection);\n    DocRouter router = coll.getRouter();\n\n    boolean modified = false;\n\n    lock.lockInterruptibly();\n    try {\n      List<String> deletes = req.getDeleteById();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String id : deletes) {\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          // NOTE: we don't use getProperty because it uses PROPERTY_PROP_PREFIX\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            log.debug(\"-- no leader in \" + s);\n            continue;\n          }\n          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          ReplicaInfo ri = getReplicaInfo(leader);\n          Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n          if (numDocs == null || numDocs.intValue() <= 0) {\n            log.debug(\"-- attempting to delete nonexistent doc \" + id + \" from \" + s.getLeader());\n            continue;\n          }\n          modified = true;\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", 1, true, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", -1, true, false);\n            Number indexSize = (Number)ri.getVariable(Type.CORE_IDX.metricsAttribute);\n            if (indexSize != null && indexSize.longValue() > SimCloudManager.DEFAULT_IDX_SIZE_BYTES) {\n              indexSize = indexSize.longValue() - DEFAULT_DOC_SIZE_BYTES;\n              simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                  indexSize.intValue(), false, false);\n              simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                  Type.CORE_IDX.convertVal(indexSize), false, false);\n            } else {\n              throw new Exception(\"unexpected indexSize ri=\" + ri);\n            }\n          } catch (Exception e) {\n            throw new IOException(e);\n          }\n        }\n      }\n      deletes = req.getDeleteQuery();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String q : deletes) {\n          if (!\"*:*\".equals(q)) {\n            throw new UnsupportedOperationException(\"Only '*:*' query is supported in deleteByQuery\");\n          }\n          for (Slice s : coll.getSlices()) {\n            Replica leader = s.getLeader();\n            if (leader == null) {\n              log.debug(\"-- no leader in \" + s);\n              continue;\n            }\n\n            cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n            ReplicaInfo ri = getReplicaInfo(leader);\n            Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n            if (numDocs == null || numDocs.intValue() == 0) {\n              continue;\n            }\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", numDocs, false, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 0, false, false);\n              simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                  SimCloudManager.DEFAULT_IDX_SIZE_BYTES, false, false);\n              simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                  Type.CORE_IDX.convertVal(SimCloudManager.DEFAULT_IDX_SIZE_BYTES), false, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      List<SolrInputDocument> docs = req.getDocuments();\n      if (docs != null && !docs.isEmpty()) {\n        for (SolrInputDocument doc : docs) {\n          String id = (String) doc.getFieldValue(\"id\");\n          if (id == null) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Document without id: \" + doc);\n          }\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            log.debug(\"-- no leader in \" + s);\n            continue;\n          }\n          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          modified = true;\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 1, true, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.maxDoc\", 1, true, false);\n\n            ReplicaInfo ri = getReplicaInfo(leader);\n            Number indexSize = (Number)ri.getVariable(Type.CORE_IDX.metricsAttribute);\n            // for each new document increase the size by DEFAULT_DOC_SIZE_BYTES\n            indexSize = indexSize.longValue() + DEFAULT_DOC_SIZE_BYTES;\n            simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                indexSize.longValue(), false, false);\n            simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                Type.CORE_IDX.convertVal(indexSize), false, false);\n          } catch (Exception e) {\n            throw new IOException(e);\n          }\n        }\n      }\n      if (modified) {\n        collectionsStatesRef.set(null);\n      }\n    } finally {\n      lock.unlock();\n    }\n    return new UpdateResponse();\n  }\n\n","sourceOld":"  /**\n   * Simulate an update by modifying replica metrics.\n   * The following core metrics are updated:\n   * <ul>\n   *   <li><code>SEARCHER.searcher.numDocs</code> - increased by added docs, decreased by deleteById and deleteByQuery</li>\n   *   <li><code>SEARCHER.searcher.deletedDocs</code> - decreased by deleteById and deleteByQuery by up to <code>numDocs</code></li>\n   *   <li><code>SEARCHER.searcher.maxDoc</code> - always increased by the number of added docs.</li>\n   * </ul>\n   * <p>IMPORTANT limitations:</p>\n   * <ul>\n   *   <li>document replacements are always counted as new docs</li>\n   *   <li>delete by ID always succeeds (unless numDocs == 0)</li>\n   *   <li>deleteByQuery is not supported unless the query is <code>*:*</code></li>\n   * </ul>\n   * @param req update request. This request MUST have the <code>collection</code> param set.\n   * @return {@link UpdateResponse}\n   * @throws SolrException on errors, such as nonexistent collection or unsupported deleteByQuery\n   */\n  public UpdateResponse simUpdate(UpdateRequest req) throws SolrException, InterruptedException, IOException {\n    ensureNotClosed();\n    String collection = req.getCollection();\n    if (collection == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection not set\");\n    }\n    if (!simListCollections().contains(collection)) {\n      if (CollectionAdminParams.SYSTEM_COLL.equals(collection)) {\n        // auto-create\n        createSystemCollection();\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection '\" + collection + \"' doesn't exist\");\n      }\n    }\n    // always reset first to get the current metrics - it's easier than to keep matching\n    // Replica with ReplicaInfo where the current real counts are stored\n    collectionsStatesRef.set(null);\n    DocCollection coll = getClusterState().getCollection(collection);\n    DocRouter router = coll.getRouter();\n\n    boolean modified = false;\n\n    lock.lockInterruptibly();\n    try {\n      List<String> deletes = req.getDeleteById();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String id : deletes) {\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          // NOTE: we don't use getProperty because it uses PROPERTY_PROP_PREFIX\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            LOG.debug(\"-- no leader in \" + s);\n            continue;\n          }\n          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          ReplicaInfo ri = getReplicaInfo(leader);\n          Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n          if (numDocs == null || numDocs.intValue() <= 0) {\n            LOG.debug(\"-- attempting to delete nonexistent doc \" + id + \" from \" + s.getLeader());\n            continue;\n          }\n          modified = true;\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", 1, true, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", -1, true, false);\n            Number indexSize = (Number)ri.getVariable(Type.CORE_IDX.metricsAttribute);\n            if (indexSize != null && indexSize.longValue() > SimCloudManager.DEFAULT_IDX_SIZE_BYTES) {\n              indexSize = indexSize.longValue() - DEFAULT_DOC_SIZE_BYTES;\n              simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                  indexSize.intValue(), false, false);\n              simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                  Type.CORE_IDX.convertVal(indexSize), false, false);\n            } else {\n              throw new Exception(\"unexpected indexSize ri=\" + ri);\n            }\n          } catch (Exception e) {\n            throw new IOException(e);\n          }\n        }\n      }\n      deletes = req.getDeleteQuery();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String q : deletes) {\n          if (!\"*:*\".equals(q)) {\n            throw new UnsupportedOperationException(\"Only '*:*' query is supported in deleteByQuery\");\n          }\n          for (Slice s : coll.getSlices()) {\n            Replica leader = s.getLeader();\n            if (leader == null) {\n              LOG.debug(\"-- no leader in \" + s);\n              continue;\n            }\n\n            cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n            ReplicaInfo ri = getReplicaInfo(leader);\n            Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n            if (numDocs == null || numDocs.intValue() == 0) {\n              continue;\n            }\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", numDocs, false, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 0, false, false);\n              simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                  SimCloudManager.DEFAULT_IDX_SIZE_BYTES, false, false);\n              simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                  Type.CORE_IDX.convertVal(SimCloudManager.DEFAULT_IDX_SIZE_BYTES), false, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      List<SolrInputDocument> docs = req.getDocuments();\n      if (docs != null && !docs.isEmpty()) {\n        for (SolrInputDocument doc : docs) {\n          String id = (String) doc.getFieldValue(\"id\");\n          if (id == null) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Document without id: \" + doc);\n          }\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            LOG.debug(\"-- no leader in \" + s);\n            continue;\n          }\n          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          modified = true;\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 1, true, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.maxDoc\", 1, true, false);\n\n            ReplicaInfo ri = getReplicaInfo(leader);\n            Number indexSize = (Number)ri.getVariable(Type.CORE_IDX.metricsAttribute);\n            // for each new document increase the size by DEFAULT_DOC_SIZE_BYTES\n            indexSize = indexSize.longValue() + DEFAULT_DOC_SIZE_BYTES;\n            simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                indexSize.longValue(), false, false);\n            simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                Type.CORE_IDX.convertVal(indexSize), false, false);\n          } catch (Exception e) {\n            throw new IOException(e);\n          }\n        }\n      }\n      if (modified) {\n        collectionsStatesRef.set(null);\n      }\n    } finally {\n      lock.unlock();\n    }\n    return new UpdateResponse();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fc18bc8ea2e2c1e308757ff50671c774438e9f3e","date":1538052583,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simUpdate(UpdateRequest).mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simUpdate(UpdateRequest).mjava","sourceNew":"  /**\n   * Simulate an update by modifying replica metrics.\n   * The following core metrics are updated:\n   * <ul>\n   *   <li><code>SEARCHER.searcher.numDocs</code> - increased by added docs, decreased by deleteById and deleteByQuery</li>\n   *   <li><code>SEARCHER.searcher.deletedDocs</code> - decreased by deleteById and deleteByQuery by up to <code>numDocs</code></li>\n   *   <li><code>SEARCHER.searcher.maxDoc</code> - always increased by the number of added docs.</li>\n   * </ul>\n   * <p>IMPORTANT limitations:</p>\n   * <ul>\n   *   <li>document replacements are always counted as new docs</li>\n   *   <li>delete by ID always succeeds (unless numDocs == 0)</li>\n   *   <li>deleteByQuery is not supported unless the query is <code>*:*</code></li>\n   * </ul>\n   * @param req update request. This request MUST have the <code>collection</code> param set.\n   * @return {@link UpdateResponse}\n   * @throws SolrException on errors, such as nonexistent collection or unsupported deleteByQuery\n   */\n  public UpdateResponse simUpdate(UpdateRequest req) throws SolrException, InterruptedException, IOException {\n    ensureNotClosed();\n    String collection = req.getCollection();\n    if (collection == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection not set\");\n    }\n    if (!colShardReplicaMap.containsKey(collection)) {\n      if (CollectionAdminParams.SYSTEM_COLL.equals(collection)) {\n        // auto-create\n        createSystemCollection();\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection '\" + collection + \"' doesn't exist\");\n      }\n    }\n\n    DocCollection coll = getClusterState().getCollection(collection);\n    DocRouter router = coll.getRouter();\n    List<String> deletes = req.getDeleteById();\n    if (deletes != null && !deletes.isEmpty()) {\n      for (String id : deletes) {\n        Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n        Replica leader = s.getLeader();\n        if (leader == null) {\n          log.debug(\"-- no leader in \" + s);\n          continue;\n        }\n        cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n        ReplicaInfo ri = getReplicaInfo(leader);\n        Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n        if (numDocs == null || numDocs.intValue() <= 0) {\n          log.debug(\"-- attempting to delete nonexistent doc \" + id + \" from \" + s.getLeader());\n          continue;\n        }\n        AtomicLong bufferedUpdates = (AtomicLong)sliceProperties.get(collection).get(s.getName()).get(BUFFERED_UPDATES);\n        if (bufferedUpdates != null) {\n          if (bufferedUpdates.get() > 0) {\n            bufferedUpdates.decrementAndGet();\n          } else {\n            log.debug(\"-- attempting to delete nonexistent buffered doc \" + id + \" from \" + s.getLeader());\n          }\n          continue;\n        }\n        lock.lockInterruptibly();\n        try {\n          simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", 1, true, false);\n          simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", -1, true, false);\n          Number indexSize = (Number)ri.getVariable(Type.CORE_IDX.metricsAttribute);\n          if (indexSize != null && indexSize.longValue() > SimCloudManager.DEFAULT_IDX_SIZE_BYTES) {\n            indexSize = indexSize.longValue() - DEFAULT_DOC_SIZE_BYTES;\n            simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                new AtomicLong(indexSize.longValue()), false, false);\n            simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                new AtomicDouble((Double)Type.CORE_IDX.convertVal(indexSize)), false, false);\n          } else {\n            throw new Exception(\"unexpected indexSize ri=\" + ri);\n          }\n        } catch (Exception e) {\n          throw new IOException(e);\n        } finally {\n          lock.unlock();\n        }\n      }\n    }\n    deletes = req.getDeleteQuery();\n    if (deletes != null && !deletes.isEmpty()) {\n      for (String q : deletes) {\n        if (!\"*:*\".equals(q)) {\n          throw new UnsupportedOperationException(\"Only '*:*' query is supported in deleteByQuery\");\n        }\n        for (Slice s : coll.getSlices()) {\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            log.debug(\"-- no leader in \" + s);\n            continue;\n          }\n\n          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          ReplicaInfo ri = getReplicaInfo(leader);\n          Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n          if (numDocs == null || numDocs.intValue() == 0) {\n            continue;\n          }\n          lock.lockInterruptibly();\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", new AtomicLong(numDocs.longValue()), false, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", new AtomicLong(0), false, false);\n            simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                new AtomicLong(SimCloudManager.DEFAULT_IDX_SIZE_BYTES), false, false);\n            simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                new AtomicDouble((Double)Type.CORE_IDX.convertVal(SimCloudManager.DEFAULT_IDX_SIZE_BYTES)), false, false);\n          } catch (Exception e) {\n            throw new IOException(e);\n          } finally {\n            lock.unlock();\n          }\n        }\n      }\n    }\n    List<SolrInputDocument> docs = req.getDocuments();\n    int docCount = 0;\n    Iterator<SolrInputDocument> it = null;\n    if (docs != null) {\n      docCount = docs.size();\n    } else {\n      it = req.getDocIterator();\n      if (it != null) {\n        while (it.hasNext()) {\n          it.next();\n          docCount++;\n        }\n      }\n    }\n    if (docCount > 0) {\n      // this approach to updating counters and metrics drastically increases performance\n      // of bulk updates, because simSetShardValue is relatively costly\n\n      Map<String, AtomicLong> docUpdates = new HashMap<>();\n      Map<String, Map<String, AtomicLong>> metricUpdates = new HashMap<>();\n\n      // XXX don't add more than 2bln docs in one request\n      boolean modified = false;\n      lock.lockInterruptibly();\n      try {\n        coll = getClusterState().getCollection(collection);\n        Slice[] slices = coll.getActiveSlicesArr();\n        if (slices.length == 0) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection without slices\");\n        }\n        int[] perSlice = new int[slices.length];\n\n        if (it != null) {\n          // BULK UPDATE: simulate random doc assignment without actually calling DocRouter,\n          // which adds significant overhead\n\n          int totalAdded = 0;\n          for (int i = 0; i < slices.length; i++) {\n            Slice s = slices[i];\n            long count = (long) docCount * ((long) s.getRange().max - (long) s.getRange().min) / 0x100000000L;\n            perSlice[i] = (int) count;\n            totalAdded += perSlice[i];\n          }\n          // loss of precision due to integer math\n          int diff = docCount - totalAdded;\n          if (diff > 0) {\n            // spread the remainder more or less equally\n            int perRemain = diff / slices.length;\n            int remainder = diff % slices.length;\n            int remainderSlice = slices.length > 1 ? bulkUpdateRandom.nextInt(slices.length) : 0;\n            for (int i = 0; i < slices.length; i++) {\n              perSlice[i] += perRemain;\n              if (i == remainderSlice) {\n                perSlice[i] += remainder;\n              }\n            }\n          }\n          for (int i = 0; i < slices.length; i++) {\n            Slice s = slices[i];\n            Replica leader = s.getLeader();\n            if (leader == null) {\n              log.debug(\"-- no leader in \" + s);\n              continue;\n            }\n            metricUpdates.computeIfAbsent(s.getName(), sh -> new HashMap<>())\n                .computeIfAbsent(leader.getCoreName(), cn -> new AtomicLong())\n                .addAndGet(perSlice[i]);\n            modified = true;\n            AtomicLong bufferedUpdates = (AtomicLong)sliceProperties.get(collection).get(s.getName()).get(BUFFERED_UPDATES);\n            if (bufferedUpdates != null) {\n              bufferedUpdates.addAndGet(perSlice[i]);\n              continue;\n            }\n            docUpdates.computeIfAbsent(s.getName(), sh -> new AtomicLong())\n                .addAndGet(perSlice[i]);\n          }\n        } else {\n          // SMALL UPDATE: use exact assignment via DocRouter\n          for (SolrInputDocument doc : docs) {\n            String id = (String) doc.getFieldValue(\"id\");\n            if (id == null) {\n              throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Document without id: \" + doc);\n            }\n            Slice s = coll.getRouter().getTargetSlice(id, doc, null, null, coll);\n            Replica leader = s.getLeader();\n            if (leader == null) {\n              log.debug(\"-- no leader in \" + s);\n              continue;\n            }\n            metricUpdates.computeIfAbsent(s.getName(), sh -> new HashMap<>())\n                .computeIfAbsent(leader.getCoreName(), cn -> new AtomicLong())\n                .incrementAndGet();\n            modified = true;\n            AtomicLong bufferedUpdates = (AtomicLong)sliceProperties.get(collection).get(s.getName()).get(BUFFERED_UPDATES);\n            if (bufferedUpdates != null) {\n              bufferedUpdates.incrementAndGet();\n              continue;\n            }\n            docUpdates.computeIfAbsent(s.getName(), sh -> new AtomicLong())\n                .incrementAndGet();\n          }\n        }\n\n        if (modified) {\n          docUpdates.forEach((sh, count) -> {\n            try {\n              simSetShardValue(collection, sh, \"SEARCHER.searcher.numDocs\", count.get(), true, false);\n              simSetShardValue(collection, sh, \"SEARCHER.searcher.maxDoc\", count.get(), true, false);\n              // for each new document increase the size by DEFAULT_DOC_SIZE_BYTES\n              simSetShardValue(collection, sh, Type.CORE_IDX.metricsAttribute,\n                  DEFAULT_DOC_SIZE_BYTES * count.get(), true, false);\n              simSetShardValue(collection, sh, Variable.coreidxsize,\n                  Type.CORE_IDX.convertVal(DEFAULT_DOC_SIZE_BYTES * count.get()), true, false);\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          });\n          metricUpdates.forEach((sh, cores) -> {\n            cores.forEach((core, count) -> {\n              String registry = SolrMetricManager.getRegistryName(SolrInfoBean.Group.core, collection, sh,\n                  Utils.parseMetricsReplicaName(collection, core));\n              cloudManager.getMetricManager().registry(registry).counter(\"UPDATE./update.requests\").inc(count.get());\n            });\n          });\n        }\n      } finally {\n        lock.unlock();\n      }\n    }\n    return new UpdateResponse();\n  }\n\n","sourceOld":"  /**\n   * Simulate an update by modifying replica metrics.\n   * The following core metrics are updated:\n   * <ul>\n   *   <li><code>SEARCHER.searcher.numDocs</code> - increased by added docs, decreased by deleteById and deleteByQuery</li>\n   *   <li><code>SEARCHER.searcher.deletedDocs</code> - decreased by deleteById and deleteByQuery by up to <code>numDocs</code></li>\n   *   <li><code>SEARCHER.searcher.maxDoc</code> - always increased by the number of added docs.</li>\n   * </ul>\n   * <p>IMPORTANT limitations:</p>\n   * <ul>\n   *   <li>document replacements are always counted as new docs</li>\n   *   <li>delete by ID always succeeds (unless numDocs == 0)</li>\n   *   <li>deleteByQuery is not supported unless the query is <code>*:*</code></li>\n   * </ul>\n   * @param req update request. This request MUST have the <code>collection</code> param set.\n   * @return {@link UpdateResponse}\n   * @throws SolrException on errors, such as nonexistent collection or unsupported deleteByQuery\n   */\n  public UpdateResponse simUpdate(UpdateRequest req) throws SolrException, InterruptedException, IOException {\n    ensureNotClosed();\n    String collection = req.getCollection();\n    if (collection == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection not set\");\n    }\n    if (!simListCollections().contains(collection)) {\n      if (CollectionAdminParams.SYSTEM_COLL.equals(collection)) {\n        // auto-create\n        createSystemCollection();\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection '\" + collection + \"' doesn't exist\");\n      }\n    }\n    // always reset first to get the current metrics - it's easier than to keep matching\n    // Replica with ReplicaInfo where the current real counts are stored\n    collectionsStatesRef.set(null);\n    DocCollection coll = getClusterState().getCollection(collection);\n    DocRouter router = coll.getRouter();\n\n    boolean modified = false;\n\n    lock.lockInterruptibly();\n    try {\n      List<String> deletes = req.getDeleteById();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String id : deletes) {\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          // NOTE: we don't use getProperty because it uses PROPERTY_PROP_PREFIX\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            log.debug(\"-- no leader in \" + s);\n            continue;\n          }\n          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          ReplicaInfo ri = getReplicaInfo(leader);\n          Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n          if (numDocs == null || numDocs.intValue() <= 0) {\n            log.debug(\"-- attempting to delete nonexistent doc \" + id + \" from \" + s.getLeader());\n            continue;\n          }\n          modified = true;\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", 1, true, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", -1, true, false);\n            Number indexSize = (Number)ri.getVariable(Type.CORE_IDX.metricsAttribute);\n            if (indexSize != null && indexSize.longValue() > SimCloudManager.DEFAULT_IDX_SIZE_BYTES) {\n              indexSize = indexSize.longValue() - DEFAULT_DOC_SIZE_BYTES;\n              simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                  indexSize.intValue(), false, false);\n              simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                  Type.CORE_IDX.convertVal(indexSize), false, false);\n            } else {\n              throw new Exception(\"unexpected indexSize ri=\" + ri);\n            }\n          } catch (Exception e) {\n            throw new IOException(e);\n          }\n        }\n      }\n      deletes = req.getDeleteQuery();\n      if (deletes != null && !deletes.isEmpty()) {\n        for (String q : deletes) {\n          if (!\"*:*\".equals(q)) {\n            throw new UnsupportedOperationException(\"Only '*:*' query is supported in deleteByQuery\");\n          }\n          for (Slice s : coll.getSlices()) {\n            Replica leader = s.getLeader();\n            if (leader == null) {\n              log.debug(\"-- no leader in \" + s);\n              continue;\n            }\n\n            cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n            ReplicaInfo ri = getReplicaInfo(leader);\n            Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n            if (numDocs == null || numDocs.intValue() == 0) {\n              continue;\n            }\n            modified = true;\n            try {\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", numDocs, false, false);\n              simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 0, false, false);\n              simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                  SimCloudManager.DEFAULT_IDX_SIZE_BYTES, false, false);\n              simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                  Type.CORE_IDX.convertVal(SimCloudManager.DEFAULT_IDX_SIZE_BYTES), false, false);\n            } catch (Exception e) {\n              throw new IOException(e);\n            }\n          }\n        }\n      }\n      List<SolrInputDocument> docs = req.getDocuments();\n      if (docs != null && !docs.isEmpty()) {\n        for (SolrInputDocument doc : docs) {\n          String id = (String) doc.getFieldValue(\"id\");\n          if (id == null) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Document without id: \" + doc);\n          }\n          Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            log.debug(\"-- no leader in \" + s);\n            continue;\n          }\n          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          modified = true;\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", 1, true, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.maxDoc\", 1, true, false);\n\n            ReplicaInfo ri = getReplicaInfo(leader);\n            Number indexSize = (Number)ri.getVariable(Type.CORE_IDX.metricsAttribute);\n            // for each new document increase the size by DEFAULT_DOC_SIZE_BYTES\n            indexSize = indexSize.longValue() + DEFAULT_DOC_SIZE_BYTES;\n            simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                indexSize.longValue(), false, false);\n            simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                Type.CORE_IDX.convertVal(indexSize), false, false);\n          } catch (Exception e) {\n            throw new IOException(e);\n          }\n        }\n      }\n      if (modified) {\n        collectionsStatesRef.set(null);\n      }\n    } finally {\n      lock.unlock();\n    }\n    return new UpdateResponse();\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8254aa20264eb7a88d556bbe0346667937ed9c2a","date":1538494545,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simUpdate(UpdateRequest).mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simUpdate(UpdateRequest).mjava","sourceNew":"  /**\n   * Simulate an update by modifying replica metrics.\n   * The following core metrics are updated:\n   * <ul>\n   *   <li><code>SEARCHER.searcher.numDocs</code> - increased by added docs, decreased by deleteById and deleteByQuery</li>\n   *   <li><code>SEARCHER.searcher.deletedDocs</code> - decreased by deleteById and deleteByQuery by up to <code>numDocs</code></li>\n   *   <li><code>SEARCHER.searcher.maxDoc</code> - always increased by the number of added docs.</li>\n   * </ul>\n   * <p>IMPORTANT limitations:</p>\n   * <ul>\n   *   <li>document replacements are always counted as new docs</li>\n   *   <li>delete by ID always succeeds (unless numDocs == 0)</li>\n   *   <li>deleteByQuery is not supported unless the query is <code>*:*</code></li>\n   * </ul>\n   * @param req update request. This request MUST have the <code>collection</code> param set.\n   * @return {@link UpdateResponse}\n   * @throws SolrException on errors, such as nonexistent collection or unsupported deleteByQuery\n   */\n  public UpdateResponse simUpdate(UpdateRequest req) throws SolrException, InterruptedException, IOException {\n    ensureNotClosed();\n    String collection = req.getCollection();\n    if (collection == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection not set\");\n    }\n    if (!colShardReplicaMap.containsKey(collection)) {\n      if (CollectionAdminParams.SYSTEM_COLL.equals(collection)) {\n        // auto-create\n        log.trace(\"-- auto-create .system when req=\" + req);\n        createSystemCollection();\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection '\" + collection + \"' doesn't exist\");\n      }\n    }\n\n    DocCollection coll = getClusterState().getCollection(collection);\n    DocRouter router = coll.getRouter();\n    List<String> deletes = req.getDeleteById();\n    if (deletes != null && !deletes.isEmpty()) {\n      for (String id : deletes) {\n        Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n        Replica leader = s.getLeader();\n        if (leader == null) {\n          log.debug(\"-- no leader in \" + s);\n          continue;\n        }\n        cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n        ReplicaInfo ri = getReplicaInfo(leader);\n        Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n        if (numDocs == null || numDocs.intValue() <= 0) {\n          log.debug(\"-- attempting to delete nonexistent doc \" + id + \" from \" + s.getLeader());\n          continue;\n        }\n        AtomicLong bufferedUpdates = (AtomicLong)sliceProperties.get(collection).get(s.getName()).get(BUFFERED_UPDATES);\n        if (bufferedUpdates != null) {\n          if (bufferedUpdates.get() > 0) {\n            bufferedUpdates.decrementAndGet();\n          } else {\n            log.debug(\"-- attempting to delete nonexistent buffered doc \" + id + \" from \" + s.getLeader());\n          }\n          continue;\n        }\n        lock.lockInterruptibly();\n        try {\n          simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", 1, true, false);\n          simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", -1, true, false);\n          Number indexSize = (Number)ri.getVariable(Type.CORE_IDX.metricsAttribute);\n          if (indexSize != null && indexSize.longValue() > SimCloudManager.DEFAULT_IDX_SIZE_BYTES) {\n            indexSize = indexSize.longValue() - DEFAULT_DOC_SIZE_BYTES;\n            simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                new AtomicLong(indexSize.longValue()), false, false);\n            simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                new AtomicDouble((Double)Type.CORE_IDX.convertVal(indexSize)), false, false);\n          } else {\n            throw new Exception(\"unexpected indexSize ri=\" + ri);\n          }\n        } catch (Exception e) {\n          throw new IOException(e);\n        } finally {\n          lock.unlock();\n        }\n      }\n    }\n    deletes = req.getDeleteQuery();\n    if (deletes != null && !deletes.isEmpty()) {\n      for (String q : deletes) {\n        if (!\"*:*\".equals(q)) {\n          throw new UnsupportedOperationException(\"Only '*:*' query is supported in deleteByQuery\");\n        }\n        for (Slice s : coll.getSlices()) {\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            log.debug(\"-- no leader in \" + s);\n            continue;\n          }\n\n          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          ReplicaInfo ri = getReplicaInfo(leader);\n          Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n          if (numDocs == null || numDocs.intValue() == 0) {\n            continue;\n          }\n          lock.lockInterruptibly();\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", new AtomicLong(numDocs.longValue()), false, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", new AtomicLong(0), false, false);\n            simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                new AtomicLong(SimCloudManager.DEFAULT_IDX_SIZE_BYTES), false, false);\n            simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                new AtomicDouble((Double)Type.CORE_IDX.convertVal(SimCloudManager.DEFAULT_IDX_SIZE_BYTES)), false, false);\n          } catch (Exception e) {\n            throw new IOException(e);\n          } finally {\n            lock.unlock();\n          }\n        }\n      }\n    }\n    List<SolrInputDocument> docs = req.getDocuments();\n    int docCount = 0;\n    Iterator<SolrInputDocument> it = null;\n    if (docs != null) {\n      docCount = docs.size();\n    } else {\n      it = req.getDocIterator();\n      if (it != null) {\n        while (it.hasNext()) {\n          it.next();\n          docCount++;\n        }\n      }\n    }\n    if (docCount > 0) {\n      // this approach to updating counters and metrics drastically increases performance\n      // of bulk updates, because simSetShardValue is relatively costly\n\n      Map<String, AtomicLong> docUpdates = new HashMap<>();\n      Map<String, Map<String, AtomicLong>> metricUpdates = new HashMap<>();\n\n      // XXX don't add more than 2bln docs in one request\n      boolean modified = false;\n      lock.lockInterruptibly();\n      try {\n        coll = getClusterState().getCollection(collection);\n        Slice[] slices = coll.getActiveSlicesArr();\n        if (slices.length == 0) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection without slices\");\n        }\n        int[] perSlice = new int[slices.length];\n\n        if (it != null) {\n          // BULK UPDATE: simulate random doc assignment without actually calling DocRouter,\n          // which adds significant overhead\n\n          int totalAdded = 0;\n          for (int i = 0; i < slices.length; i++) {\n            Slice s = slices[i];\n            long count = (long) docCount * ((long) s.getRange().max - (long) s.getRange().min) / 0x100000000L;\n            perSlice[i] = (int) count;\n            totalAdded += perSlice[i];\n          }\n          // loss of precision due to integer math\n          int diff = docCount - totalAdded;\n          if (diff > 0) {\n            // spread the remainder more or less equally\n            int perRemain = diff / slices.length;\n            int remainder = diff % slices.length;\n            int remainderSlice = slices.length > 1 ? bulkUpdateRandom.nextInt(slices.length) : 0;\n            for (int i = 0; i < slices.length; i++) {\n              perSlice[i] += perRemain;\n              if (i == remainderSlice) {\n                perSlice[i] += remainder;\n              }\n            }\n          }\n          for (int i = 0; i < slices.length; i++) {\n            Slice s = slices[i];\n            Replica leader = s.getLeader();\n            if (leader == null) {\n              log.debug(\"-- no leader in \" + s);\n              continue;\n            }\n            metricUpdates.computeIfAbsent(s.getName(), sh -> new HashMap<>())\n                .computeIfAbsent(leader.getCoreName(), cn -> new AtomicLong())\n                .addAndGet(perSlice[i]);\n            modified = true;\n            AtomicLong bufferedUpdates = (AtomicLong)sliceProperties.get(collection).get(s.getName()).get(BUFFERED_UPDATES);\n            if (bufferedUpdates != null) {\n              bufferedUpdates.addAndGet(perSlice[i]);\n              continue;\n            }\n            docUpdates.computeIfAbsent(s.getName(), sh -> new AtomicLong())\n                .addAndGet(perSlice[i]);\n          }\n        } else {\n          // SMALL UPDATE: use exact assignment via DocRouter\n          for (SolrInputDocument doc : docs) {\n            String id = (String) doc.getFieldValue(\"id\");\n            if (id == null) {\n              throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Document without id: \" + doc);\n            }\n            Slice s = coll.getRouter().getTargetSlice(id, doc, null, null, coll);\n            Replica leader = s.getLeader();\n            if (leader == null) {\n              log.debug(\"-- no leader in \" + s);\n              continue;\n            }\n            metricUpdates.computeIfAbsent(s.getName(), sh -> new HashMap<>())\n                .computeIfAbsent(leader.getCoreName(), cn -> new AtomicLong())\n                .incrementAndGet();\n            modified = true;\n            AtomicLong bufferedUpdates = (AtomicLong)sliceProperties.get(collection).get(s.getName()).get(BUFFERED_UPDATES);\n            if (bufferedUpdates != null) {\n              bufferedUpdates.incrementAndGet();\n              continue;\n            }\n            docUpdates.computeIfAbsent(s.getName(), sh -> new AtomicLong())\n                .incrementAndGet();\n          }\n        }\n\n        if (modified) {\n          docUpdates.forEach((sh, count) -> {\n            try {\n              simSetShardValue(collection, sh, \"SEARCHER.searcher.numDocs\", count.get(), true, false);\n              simSetShardValue(collection, sh, \"SEARCHER.searcher.maxDoc\", count.get(), true, false);\n              // for each new document increase the size by DEFAULT_DOC_SIZE_BYTES\n              simSetShardValue(collection, sh, Type.CORE_IDX.metricsAttribute,\n                  DEFAULT_DOC_SIZE_BYTES * count.get(), true, false);\n              simSetShardValue(collection, sh, Variable.coreidxsize,\n                  Type.CORE_IDX.convertVal(DEFAULT_DOC_SIZE_BYTES * count.get()), true, false);\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          });\n          metricUpdates.forEach((sh, cores) -> {\n            cores.forEach((core, count) -> {\n              String registry = SolrMetricManager.getRegistryName(SolrInfoBean.Group.core, collection, sh,\n                  Utils.parseMetricsReplicaName(collection, core));\n              cloudManager.getMetricManager().registry(registry).counter(\"UPDATE./update.requests\").inc(count.get());\n            });\n          });\n        }\n      } finally {\n        lock.unlock();\n      }\n    }\n    return new UpdateResponse();\n  }\n\n","sourceOld":"  /**\n   * Simulate an update by modifying replica metrics.\n   * The following core metrics are updated:\n   * <ul>\n   *   <li><code>SEARCHER.searcher.numDocs</code> - increased by added docs, decreased by deleteById and deleteByQuery</li>\n   *   <li><code>SEARCHER.searcher.deletedDocs</code> - decreased by deleteById and deleteByQuery by up to <code>numDocs</code></li>\n   *   <li><code>SEARCHER.searcher.maxDoc</code> - always increased by the number of added docs.</li>\n   * </ul>\n   * <p>IMPORTANT limitations:</p>\n   * <ul>\n   *   <li>document replacements are always counted as new docs</li>\n   *   <li>delete by ID always succeeds (unless numDocs == 0)</li>\n   *   <li>deleteByQuery is not supported unless the query is <code>*:*</code></li>\n   * </ul>\n   * @param req update request. This request MUST have the <code>collection</code> param set.\n   * @return {@link UpdateResponse}\n   * @throws SolrException on errors, such as nonexistent collection or unsupported deleteByQuery\n   */\n  public UpdateResponse simUpdate(UpdateRequest req) throws SolrException, InterruptedException, IOException {\n    ensureNotClosed();\n    String collection = req.getCollection();\n    if (collection == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection not set\");\n    }\n    if (!colShardReplicaMap.containsKey(collection)) {\n      if (CollectionAdminParams.SYSTEM_COLL.equals(collection)) {\n        // auto-create\n        createSystemCollection();\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection '\" + collection + \"' doesn't exist\");\n      }\n    }\n\n    DocCollection coll = getClusterState().getCollection(collection);\n    DocRouter router = coll.getRouter();\n    List<String> deletes = req.getDeleteById();\n    if (deletes != null && !deletes.isEmpty()) {\n      for (String id : deletes) {\n        Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n        Replica leader = s.getLeader();\n        if (leader == null) {\n          log.debug(\"-- no leader in \" + s);\n          continue;\n        }\n        cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n        ReplicaInfo ri = getReplicaInfo(leader);\n        Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n        if (numDocs == null || numDocs.intValue() <= 0) {\n          log.debug(\"-- attempting to delete nonexistent doc \" + id + \" from \" + s.getLeader());\n          continue;\n        }\n        AtomicLong bufferedUpdates = (AtomicLong)sliceProperties.get(collection).get(s.getName()).get(BUFFERED_UPDATES);\n        if (bufferedUpdates != null) {\n          if (bufferedUpdates.get() > 0) {\n            bufferedUpdates.decrementAndGet();\n          } else {\n            log.debug(\"-- attempting to delete nonexistent buffered doc \" + id + \" from \" + s.getLeader());\n          }\n          continue;\n        }\n        lock.lockInterruptibly();\n        try {\n          simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", 1, true, false);\n          simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", -1, true, false);\n          Number indexSize = (Number)ri.getVariable(Type.CORE_IDX.metricsAttribute);\n          if (indexSize != null && indexSize.longValue() > SimCloudManager.DEFAULT_IDX_SIZE_BYTES) {\n            indexSize = indexSize.longValue() - DEFAULT_DOC_SIZE_BYTES;\n            simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                new AtomicLong(indexSize.longValue()), false, false);\n            simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                new AtomicDouble((Double)Type.CORE_IDX.convertVal(indexSize)), false, false);\n          } else {\n            throw new Exception(\"unexpected indexSize ri=\" + ri);\n          }\n        } catch (Exception e) {\n          throw new IOException(e);\n        } finally {\n          lock.unlock();\n        }\n      }\n    }\n    deletes = req.getDeleteQuery();\n    if (deletes != null && !deletes.isEmpty()) {\n      for (String q : deletes) {\n        if (!\"*:*\".equals(q)) {\n          throw new UnsupportedOperationException(\"Only '*:*' query is supported in deleteByQuery\");\n        }\n        for (Slice s : coll.getSlices()) {\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            log.debug(\"-- no leader in \" + s);\n            continue;\n          }\n\n          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          ReplicaInfo ri = getReplicaInfo(leader);\n          Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n          if (numDocs == null || numDocs.intValue() == 0) {\n            continue;\n          }\n          lock.lockInterruptibly();\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", new AtomicLong(numDocs.longValue()), false, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", new AtomicLong(0), false, false);\n            simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                new AtomicLong(SimCloudManager.DEFAULT_IDX_SIZE_BYTES), false, false);\n            simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                new AtomicDouble((Double)Type.CORE_IDX.convertVal(SimCloudManager.DEFAULT_IDX_SIZE_BYTES)), false, false);\n          } catch (Exception e) {\n            throw new IOException(e);\n          } finally {\n            lock.unlock();\n          }\n        }\n      }\n    }\n    List<SolrInputDocument> docs = req.getDocuments();\n    int docCount = 0;\n    Iterator<SolrInputDocument> it = null;\n    if (docs != null) {\n      docCount = docs.size();\n    } else {\n      it = req.getDocIterator();\n      if (it != null) {\n        while (it.hasNext()) {\n          it.next();\n          docCount++;\n        }\n      }\n    }\n    if (docCount > 0) {\n      // this approach to updating counters and metrics drastically increases performance\n      // of bulk updates, because simSetShardValue is relatively costly\n\n      Map<String, AtomicLong> docUpdates = new HashMap<>();\n      Map<String, Map<String, AtomicLong>> metricUpdates = new HashMap<>();\n\n      // XXX don't add more than 2bln docs in one request\n      boolean modified = false;\n      lock.lockInterruptibly();\n      try {\n        coll = getClusterState().getCollection(collection);\n        Slice[] slices = coll.getActiveSlicesArr();\n        if (slices.length == 0) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection without slices\");\n        }\n        int[] perSlice = new int[slices.length];\n\n        if (it != null) {\n          // BULK UPDATE: simulate random doc assignment without actually calling DocRouter,\n          // which adds significant overhead\n\n          int totalAdded = 0;\n          for (int i = 0; i < slices.length; i++) {\n            Slice s = slices[i];\n            long count = (long) docCount * ((long) s.getRange().max - (long) s.getRange().min) / 0x100000000L;\n            perSlice[i] = (int) count;\n            totalAdded += perSlice[i];\n          }\n          // loss of precision due to integer math\n          int diff = docCount - totalAdded;\n          if (diff > 0) {\n            // spread the remainder more or less equally\n            int perRemain = diff / slices.length;\n            int remainder = diff % slices.length;\n            int remainderSlice = slices.length > 1 ? bulkUpdateRandom.nextInt(slices.length) : 0;\n            for (int i = 0; i < slices.length; i++) {\n              perSlice[i] += perRemain;\n              if (i == remainderSlice) {\n                perSlice[i] += remainder;\n              }\n            }\n          }\n          for (int i = 0; i < slices.length; i++) {\n            Slice s = slices[i];\n            Replica leader = s.getLeader();\n            if (leader == null) {\n              log.debug(\"-- no leader in \" + s);\n              continue;\n            }\n            metricUpdates.computeIfAbsent(s.getName(), sh -> new HashMap<>())\n                .computeIfAbsent(leader.getCoreName(), cn -> new AtomicLong())\n                .addAndGet(perSlice[i]);\n            modified = true;\n            AtomicLong bufferedUpdates = (AtomicLong)sliceProperties.get(collection).get(s.getName()).get(BUFFERED_UPDATES);\n            if (bufferedUpdates != null) {\n              bufferedUpdates.addAndGet(perSlice[i]);\n              continue;\n            }\n            docUpdates.computeIfAbsent(s.getName(), sh -> new AtomicLong())\n                .addAndGet(perSlice[i]);\n          }\n        } else {\n          // SMALL UPDATE: use exact assignment via DocRouter\n          for (SolrInputDocument doc : docs) {\n            String id = (String) doc.getFieldValue(\"id\");\n            if (id == null) {\n              throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Document without id: \" + doc);\n            }\n            Slice s = coll.getRouter().getTargetSlice(id, doc, null, null, coll);\n            Replica leader = s.getLeader();\n            if (leader == null) {\n              log.debug(\"-- no leader in \" + s);\n              continue;\n            }\n            metricUpdates.computeIfAbsent(s.getName(), sh -> new HashMap<>())\n                .computeIfAbsent(leader.getCoreName(), cn -> new AtomicLong())\n                .incrementAndGet();\n            modified = true;\n            AtomicLong bufferedUpdates = (AtomicLong)sliceProperties.get(collection).get(s.getName()).get(BUFFERED_UPDATES);\n            if (bufferedUpdates != null) {\n              bufferedUpdates.incrementAndGet();\n              continue;\n            }\n            docUpdates.computeIfAbsent(s.getName(), sh -> new AtomicLong())\n                .incrementAndGet();\n          }\n        }\n\n        if (modified) {\n          docUpdates.forEach((sh, count) -> {\n            try {\n              simSetShardValue(collection, sh, \"SEARCHER.searcher.numDocs\", count.get(), true, false);\n              simSetShardValue(collection, sh, \"SEARCHER.searcher.maxDoc\", count.get(), true, false);\n              // for each new document increase the size by DEFAULT_DOC_SIZE_BYTES\n              simSetShardValue(collection, sh, Type.CORE_IDX.metricsAttribute,\n                  DEFAULT_DOC_SIZE_BYTES * count.get(), true, false);\n              simSetShardValue(collection, sh, Variable.coreidxsize,\n                  Type.CORE_IDX.convertVal(DEFAULT_DOC_SIZE_BYTES * count.get()), true, false);\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          });\n          metricUpdates.forEach((sh, cores) -> {\n            cores.forEach((core, count) -> {\n              String registry = SolrMetricManager.getRegistryName(SolrInfoBean.Group.core, collection, sh,\n                  Utils.parseMetricsReplicaName(collection, core));\n              cloudManager.getMetricManager().registry(registry).counter(\"UPDATE./update.requests\").inc(count.get());\n            });\n          });\n        }\n      } finally {\n        lock.unlock();\n      }\n    }\n    return new UpdateResponse();\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simUpdate(UpdateRequest).mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simUpdate(UpdateRequest).mjava","sourceNew":"  /**\n   * Simulate an update by modifying replica metrics.\n   * The following core metrics are updated:\n   * <ul>\n   *   <li><code>SEARCHER.searcher.numDocs</code> - increased by added docs, decreased by deleteById and deleteByQuery</li>\n   *   <li><code>SEARCHER.searcher.deletedDocs</code> - decreased by deleteById and deleteByQuery by up to <code>numDocs</code></li>\n   *   <li><code>SEARCHER.searcher.maxDoc</code> - always increased by the number of added docs.</li>\n   * </ul>\n   * <p>IMPORTANT limitations:</p>\n   * <ul>\n   *   <li>document replacements are always counted as new docs</li>\n   *   <li>delete by ID always succeeds (unless numDocs == 0)</li>\n   *   <li>deleteByQuery is not supported unless the query is <code>*:*</code></li>\n   * </ul>\n   * @param req update request. This request MUST have the <code>collection</code> param set.\n   * @return {@link UpdateResponse}\n   * @throws SolrException on errors, such as nonexistent collection or unsupported deleteByQuery\n   */\n  public UpdateResponse simUpdate(UpdateRequest req) throws SolrException, InterruptedException, IOException {\n    ensureNotClosed();\n    String collection = req.getCollection();\n    if (collection == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection not set\");\n    }\n    ensureSystemCollection(collection);\n    \n    DocCollection coll = getClusterState().getCollection(collection);\n    DocRouter router = coll.getRouter();\n    List<String> deletes = req.getDeleteById();\n    if (deletes != null && !deletes.isEmpty()) {\n      for (String id : deletes) {\n        Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n        Replica leader = s.getLeader();\n        if (leader == null) {\n          log.debug(\"-- no leader in \" + s);\n          continue;\n        }\n        cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n        ReplicaInfo ri = getReplicaInfo(leader);\n        Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n        if (numDocs == null || numDocs.intValue() <= 0) {\n          log.debug(\"-- attempting to delete nonexistent doc \" + id + \" from \" + s.getLeader());\n          continue;\n        }\n        AtomicLong bufferedUpdates = (AtomicLong)sliceProperties.get(collection).get(s.getName()).get(BUFFERED_UPDATES);\n        if (bufferedUpdates != null) {\n          if (bufferedUpdates.get() > 0) {\n            bufferedUpdates.decrementAndGet();\n          } else {\n            log.debug(\"-- attempting to delete nonexistent buffered doc \" + id + \" from \" + s.getLeader());\n          }\n          continue;\n        }\n        lock.lockInterruptibly();\n        try {\n          simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", 1, true, false);\n          simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", -1, true, false);\n          Number indexSize = (Number)ri.getVariable(Type.CORE_IDX.metricsAttribute);\n          if (indexSize != null && indexSize.longValue() > SimCloudManager.DEFAULT_IDX_SIZE_BYTES) {\n            indexSize = indexSize.longValue() - DEFAULT_DOC_SIZE_BYTES;\n            simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                new AtomicLong(indexSize.longValue()), false, false);\n            simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                new AtomicDouble((Double)Type.CORE_IDX.convertVal(indexSize)), false, false);\n          } else {\n            throw new Exception(\"unexpected indexSize ri=\" + ri);\n          }\n        } catch (Exception e) {\n          throw new IOException(e);\n        } finally {\n          lock.unlock();\n        }\n      }\n    }\n    deletes = req.getDeleteQuery();\n    if (deletes != null && !deletes.isEmpty()) {\n      for (String q : deletes) {\n        if (!\"*:*\".equals(q)) {\n          throw new UnsupportedOperationException(\"Only '*:*' query is supported in deleteByQuery\");\n        }\n        for (Slice s : coll.getSlices()) {\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            log.debug(\"-- no leader in \" + s);\n            continue;\n          }\n\n          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          ReplicaInfo ri = getReplicaInfo(leader);\n          Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n          if (numDocs == null || numDocs.intValue() == 0) {\n            continue;\n          }\n          lock.lockInterruptibly();\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", new AtomicLong(numDocs.longValue()), false, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", new AtomicLong(0), false, false);\n            simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                new AtomicLong(SimCloudManager.DEFAULT_IDX_SIZE_BYTES), false, false);\n            simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                new AtomicDouble((Double)Type.CORE_IDX.convertVal(SimCloudManager.DEFAULT_IDX_SIZE_BYTES)), false, false);\n          } catch (Exception e) {\n            throw new IOException(e);\n          } finally {\n            lock.unlock();\n          }\n        }\n      }\n    }\n    List<SolrInputDocument> docs = req.getDocuments();\n    int docCount = 0;\n    Iterator<SolrInputDocument> it = null;\n    if (docs != null) {\n      docCount = docs.size();\n    } else {\n      it = req.getDocIterator();\n      if (it != null) {\n        while (it.hasNext()) {\n          it.next();\n          docCount++;\n        }\n      }\n    }\n    if (docCount > 0) {\n      // this approach to updating counters and metrics drastically increases performance\n      // of bulk updates, because simSetShardValue is relatively costly\n\n      Map<String, AtomicLong> docUpdates = new HashMap<>();\n      Map<String, Map<String, AtomicLong>> metricUpdates = new HashMap<>();\n\n      // XXX don't add more than 2bln docs in one request\n      boolean modified = false;\n      lock.lockInterruptibly();\n      try {\n        coll = getClusterState().getCollection(collection);\n        Slice[] slices = coll.getActiveSlicesArr();\n        if (slices.length == 0) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection without slices\");\n        }\n        int[] perSlice = new int[slices.length];\n\n        if (it != null) {\n          // BULK UPDATE: simulate random doc assignment without actually calling DocRouter,\n          // which adds significant overhead\n\n          int totalAdded = 0;\n          for (int i = 0; i < slices.length; i++) {\n            Slice s = slices[i];\n            long count = (long) docCount * ((long) s.getRange().max - (long) s.getRange().min) / 0x100000000L;\n            perSlice[i] = (int) count;\n            totalAdded += perSlice[i];\n          }\n          // loss of precision due to integer math\n          int diff = docCount - totalAdded;\n          if (diff > 0) {\n            // spread the remainder more or less equally\n            int perRemain = diff / slices.length;\n            int remainder = diff % slices.length;\n            int remainderSlice = slices.length > 1 ? bulkUpdateRandom.nextInt(slices.length) : 0;\n            for (int i = 0; i < slices.length; i++) {\n              perSlice[i] += perRemain;\n              if (i == remainderSlice) {\n                perSlice[i] += remainder;\n              }\n            }\n          }\n          for (int i = 0; i < slices.length; i++) {\n            Slice s = slices[i];\n            Replica leader = s.getLeader();\n            if (leader == null) {\n              log.debug(\"-- no leader in \" + s);\n              continue;\n            }\n            metricUpdates.computeIfAbsent(s.getName(), sh -> new HashMap<>())\n                .computeIfAbsent(leader.getCoreName(), cn -> new AtomicLong())\n                .addAndGet(perSlice[i]);\n            modified = true;\n            AtomicLong bufferedUpdates = (AtomicLong)sliceProperties.get(collection).get(s.getName()).get(BUFFERED_UPDATES);\n            if (bufferedUpdates != null) {\n              bufferedUpdates.addAndGet(perSlice[i]);\n              continue;\n            }\n            docUpdates.computeIfAbsent(s.getName(), sh -> new AtomicLong())\n                .addAndGet(perSlice[i]);\n          }\n        } else {\n          // SMALL UPDATE: use exact assignment via DocRouter\n          for (SolrInputDocument doc : docs) {\n            String id = (String) doc.getFieldValue(\"id\");\n            if (id == null) {\n              throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Document without id: \" + doc);\n            }\n            Slice s = coll.getRouter().getTargetSlice(id, doc, null, null, coll);\n            Replica leader = s.getLeader();\n            if (leader == null) {\n              log.debug(\"-- no leader in \" + s);\n              continue;\n            }\n            metricUpdates.computeIfAbsent(s.getName(), sh -> new HashMap<>())\n                .computeIfAbsent(leader.getCoreName(), cn -> new AtomicLong())\n                .incrementAndGet();\n            modified = true;\n            AtomicLong bufferedUpdates = (AtomicLong)sliceProperties.get(collection).get(s.getName()).get(BUFFERED_UPDATES);\n            if (bufferedUpdates != null) {\n              bufferedUpdates.incrementAndGet();\n              continue;\n            }\n            docUpdates.computeIfAbsent(s.getName(), sh -> new AtomicLong())\n                .incrementAndGet();\n          }\n        }\n\n        if (modified) {\n          docUpdates.forEach((sh, count) -> {\n            try {\n              simSetShardValue(collection, sh, \"SEARCHER.searcher.numDocs\", count.get(), true, false);\n              simSetShardValue(collection, sh, \"SEARCHER.searcher.maxDoc\", count.get(), true, false);\n              // for each new document increase the size by DEFAULT_DOC_SIZE_BYTES\n              simSetShardValue(collection, sh, Type.CORE_IDX.metricsAttribute,\n                  DEFAULT_DOC_SIZE_BYTES * count.get(), true, false);\n              simSetShardValue(collection, sh, Variable.coreidxsize,\n                  Type.CORE_IDX.convertVal(DEFAULT_DOC_SIZE_BYTES * count.get()), true, false);\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          });\n          metricUpdates.forEach((sh, cores) -> {\n            cores.forEach((core, count) -> {\n              String registry = SolrMetricManager.getRegistryName(SolrInfoBean.Group.core, collection, sh,\n                  Utils.parseMetricsReplicaName(collection, core));\n              cloudManager.getMetricManager().registry(registry).counter(\"UPDATE./update.requests\").inc(count.get());\n            });\n          });\n        }\n      } finally {\n        lock.unlock();\n      }\n    }\n    return new UpdateResponse();\n  }\n\n","sourceOld":"  /**\n   * Simulate an update by modifying replica metrics.\n   * The following core metrics are updated:\n   * <ul>\n   *   <li><code>SEARCHER.searcher.numDocs</code> - increased by added docs, decreased by deleteById and deleteByQuery</li>\n   *   <li><code>SEARCHER.searcher.deletedDocs</code> - decreased by deleteById and deleteByQuery by up to <code>numDocs</code></li>\n   *   <li><code>SEARCHER.searcher.maxDoc</code> - always increased by the number of added docs.</li>\n   * </ul>\n   * <p>IMPORTANT limitations:</p>\n   * <ul>\n   *   <li>document replacements are always counted as new docs</li>\n   *   <li>delete by ID always succeeds (unless numDocs == 0)</li>\n   *   <li>deleteByQuery is not supported unless the query is <code>*:*</code></li>\n   * </ul>\n   * @param req update request. This request MUST have the <code>collection</code> param set.\n   * @return {@link UpdateResponse}\n   * @throws SolrException on errors, such as nonexistent collection or unsupported deleteByQuery\n   */\n  public UpdateResponse simUpdate(UpdateRequest req) throws SolrException, InterruptedException, IOException {\n    ensureNotClosed();\n    String collection = req.getCollection();\n    if (collection == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection not set\");\n    }\n    if (!colShardReplicaMap.containsKey(collection)) {\n      if (CollectionAdminParams.SYSTEM_COLL.equals(collection)) {\n        // auto-create\n        log.trace(\"-- auto-create .system when req=\" + req);\n        createSystemCollection();\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection '\" + collection + \"' doesn't exist\");\n      }\n    }\n\n    DocCollection coll = getClusterState().getCollection(collection);\n    DocRouter router = coll.getRouter();\n    List<String> deletes = req.getDeleteById();\n    if (deletes != null && !deletes.isEmpty()) {\n      for (String id : deletes) {\n        Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n        Replica leader = s.getLeader();\n        if (leader == null) {\n          log.debug(\"-- no leader in \" + s);\n          continue;\n        }\n        cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n        ReplicaInfo ri = getReplicaInfo(leader);\n        Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n        if (numDocs == null || numDocs.intValue() <= 0) {\n          log.debug(\"-- attempting to delete nonexistent doc \" + id + \" from \" + s.getLeader());\n          continue;\n        }\n        AtomicLong bufferedUpdates = (AtomicLong)sliceProperties.get(collection).get(s.getName()).get(BUFFERED_UPDATES);\n        if (bufferedUpdates != null) {\n          if (bufferedUpdates.get() > 0) {\n            bufferedUpdates.decrementAndGet();\n          } else {\n            log.debug(\"-- attempting to delete nonexistent buffered doc \" + id + \" from \" + s.getLeader());\n          }\n          continue;\n        }\n        lock.lockInterruptibly();\n        try {\n          simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", 1, true, false);\n          simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", -1, true, false);\n          Number indexSize = (Number)ri.getVariable(Type.CORE_IDX.metricsAttribute);\n          if (indexSize != null && indexSize.longValue() > SimCloudManager.DEFAULT_IDX_SIZE_BYTES) {\n            indexSize = indexSize.longValue() - DEFAULT_DOC_SIZE_BYTES;\n            simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                new AtomicLong(indexSize.longValue()), false, false);\n            simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                new AtomicDouble((Double)Type.CORE_IDX.convertVal(indexSize)), false, false);\n          } else {\n            throw new Exception(\"unexpected indexSize ri=\" + ri);\n          }\n        } catch (Exception e) {\n          throw new IOException(e);\n        } finally {\n          lock.unlock();\n        }\n      }\n    }\n    deletes = req.getDeleteQuery();\n    if (deletes != null && !deletes.isEmpty()) {\n      for (String q : deletes) {\n        if (!\"*:*\".equals(q)) {\n          throw new UnsupportedOperationException(\"Only '*:*' query is supported in deleteByQuery\");\n        }\n        for (Slice s : coll.getSlices()) {\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            log.debug(\"-- no leader in \" + s);\n            continue;\n          }\n\n          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          ReplicaInfo ri = getReplicaInfo(leader);\n          Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n          if (numDocs == null || numDocs.intValue() == 0) {\n            continue;\n          }\n          lock.lockInterruptibly();\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", new AtomicLong(numDocs.longValue()), false, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", new AtomicLong(0), false, false);\n            simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                new AtomicLong(SimCloudManager.DEFAULT_IDX_SIZE_BYTES), false, false);\n            simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                new AtomicDouble((Double)Type.CORE_IDX.convertVal(SimCloudManager.DEFAULT_IDX_SIZE_BYTES)), false, false);\n          } catch (Exception e) {\n            throw new IOException(e);\n          } finally {\n            lock.unlock();\n          }\n        }\n      }\n    }\n    List<SolrInputDocument> docs = req.getDocuments();\n    int docCount = 0;\n    Iterator<SolrInputDocument> it = null;\n    if (docs != null) {\n      docCount = docs.size();\n    } else {\n      it = req.getDocIterator();\n      if (it != null) {\n        while (it.hasNext()) {\n          it.next();\n          docCount++;\n        }\n      }\n    }\n    if (docCount > 0) {\n      // this approach to updating counters and metrics drastically increases performance\n      // of bulk updates, because simSetShardValue is relatively costly\n\n      Map<String, AtomicLong> docUpdates = new HashMap<>();\n      Map<String, Map<String, AtomicLong>> metricUpdates = new HashMap<>();\n\n      // XXX don't add more than 2bln docs in one request\n      boolean modified = false;\n      lock.lockInterruptibly();\n      try {\n        coll = getClusterState().getCollection(collection);\n        Slice[] slices = coll.getActiveSlicesArr();\n        if (slices.length == 0) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection without slices\");\n        }\n        int[] perSlice = new int[slices.length];\n\n        if (it != null) {\n          // BULK UPDATE: simulate random doc assignment without actually calling DocRouter,\n          // which adds significant overhead\n\n          int totalAdded = 0;\n          for (int i = 0; i < slices.length; i++) {\n            Slice s = slices[i];\n            long count = (long) docCount * ((long) s.getRange().max - (long) s.getRange().min) / 0x100000000L;\n            perSlice[i] = (int) count;\n            totalAdded += perSlice[i];\n          }\n          // loss of precision due to integer math\n          int diff = docCount - totalAdded;\n          if (diff > 0) {\n            // spread the remainder more or less equally\n            int perRemain = diff / slices.length;\n            int remainder = diff % slices.length;\n            int remainderSlice = slices.length > 1 ? bulkUpdateRandom.nextInt(slices.length) : 0;\n            for (int i = 0; i < slices.length; i++) {\n              perSlice[i] += perRemain;\n              if (i == remainderSlice) {\n                perSlice[i] += remainder;\n              }\n            }\n          }\n          for (int i = 0; i < slices.length; i++) {\n            Slice s = slices[i];\n            Replica leader = s.getLeader();\n            if (leader == null) {\n              log.debug(\"-- no leader in \" + s);\n              continue;\n            }\n            metricUpdates.computeIfAbsent(s.getName(), sh -> new HashMap<>())\n                .computeIfAbsent(leader.getCoreName(), cn -> new AtomicLong())\n                .addAndGet(perSlice[i]);\n            modified = true;\n            AtomicLong bufferedUpdates = (AtomicLong)sliceProperties.get(collection).get(s.getName()).get(BUFFERED_UPDATES);\n            if (bufferedUpdates != null) {\n              bufferedUpdates.addAndGet(perSlice[i]);\n              continue;\n            }\n            docUpdates.computeIfAbsent(s.getName(), sh -> new AtomicLong())\n                .addAndGet(perSlice[i]);\n          }\n        } else {\n          // SMALL UPDATE: use exact assignment via DocRouter\n          for (SolrInputDocument doc : docs) {\n            String id = (String) doc.getFieldValue(\"id\");\n            if (id == null) {\n              throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Document without id: \" + doc);\n            }\n            Slice s = coll.getRouter().getTargetSlice(id, doc, null, null, coll);\n            Replica leader = s.getLeader();\n            if (leader == null) {\n              log.debug(\"-- no leader in \" + s);\n              continue;\n            }\n            metricUpdates.computeIfAbsent(s.getName(), sh -> new HashMap<>())\n                .computeIfAbsent(leader.getCoreName(), cn -> new AtomicLong())\n                .incrementAndGet();\n            modified = true;\n            AtomicLong bufferedUpdates = (AtomicLong)sliceProperties.get(collection).get(s.getName()).get(BUFFERED_UPDATES);\n            if (bufferedUpdates != null) {\n              bufferedUpdates.incrementAndGet();\n              continue;\n            }\n            docUpdates.computeIfAbsent(s.getName(), sh -> new AtomicLong())\n                .incrementAndGet();\n          }\n        }\n\n        if (modified) {\n          docUpdates.forEach((sh, count) -> {\n            try {\n              simSetShardValue(collection, sh, \"SEARCHER.searcher.numDocs\", count.get(), true, false);\n              simSetShardValue(collection, sh, \"SEARCHER.searcher.maxDoc\", count.get(), true, false);\n              // for each new document increase the size by DEFAULT_DOC_SIZE_BYTES\n              simSetShardValue(collection, sh, Type.CORE_IDX.metricsAttribute,\n                  DEFAULT_DOC_SIZE_BYTES * count.get(), true, false);\n              simSetShardValue(collection, sh, Variable.coreidxsize,\n                  Type.CORE_IDX.convertVal(DEFAULT_DOC_SIZE_BYTES * count.get()), true, false);\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          });\n          metricUpdates.forEach((sh, cores) -> {\n            cores.forEach((core, count) -> {\n              String registry = SolrMetricManager.getRegistryName(SolrInfoBean.Group.core, collection, sh,\n                  Utils.parseMetricsReplicaName(collection, core));\n              cloudManager.getMetricManager().registry(registry).counter(\"UPDATE./update.requests\").inc(count.get());\n            });\n          });\n        }\n      } finally {\n        lock.unlock();\n      }\n    }\n    return new UpdateResponse();\n  }\n\n","bugFix":["fc18bc8ea2e2c1e308757ff50671c774438e9f3e","ce71a9836bf1eba34a0ab31884e9eb8ad3f1cef1","8254aa20264eb7a88d556bbe0346667937ed9c2a","4181b4cf0450ea3c6d1aff8dc3ad4ed9cd3eeb6a"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5","date":1556572478,"type":5,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simUpdate(UpdateRequest).mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simUpdate(UpdateRequest).mjava","sourceNew":"  /**\n   * Simulate an update by modifying replica metrics.\n   * The following core metrics are updated:\n   * <ul>\n   *   <li><code>SEARCHER.searcher.numDocs</code> - increased by added docs, decreased by deleteById and deleteByQuery</li>\n   *   <li><code>SEARCHER.searcher.deletedDocs</code> - decreased by deleteById and deleteByQuery by up to <code>numDocs</code></li>\n   *   <li><code>SEARCHER.searcher.maxDoc</code> - always increased by the number of added docs.</li>\n   * </ul>\n   * <p>IMPORTANT limitations:</p>\n   * <ul>\n   *   <li>document replacements are always counted as new docs</li>\n   *   <li>delete by ID always succeeds (unless numDocs == 0)</li>\n   *   <li>deleteByQuery is not supported unless the query is <code>*:*</code></li>\n   * </ul>\n   * @param req update request. This request MUST have the <code>collection</code> param set.\n   * @return {@link UpdateResponse}\n   * @throws SolrException on errors, such as nonexistent collection or unsupported deleteByQuery\n   */\n  public UpdateResponse simUpdate(UpdateRequest req) throws SolrException, InterruptedException, IOException {\n    ensureNotClosed();\n    String collection = req.getCollection();\n    if (collection == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection not set\");\n    }\n    ensureSystemCollection(collection);\n    \n    DocCollection coll = getClusterState().getCollection(collection);\n    DocRouter router = coll.getRouter();\n    List<String> deletes = req.getDeleteById();\n    if (deletes != null && !deletes.isEmpty()) {\n      for (String id : deletes) {\n        Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n        Replica leader = s.getLeader();\n        if (leader == null) {\n          log.debug(\"-- no leader in \" + s);\n          continue;\n        }\n        cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n        ReplicaInfo ri = getReplicaInfo(leader);\n        Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n        if (numDocs == null || numDocs.intValue() <= 0) {\n          log.debug(\"-- attempting to delete nonexistent doc \" + id + \" from \" + s.getLeader());\n          continue;\n        }\n        AtomicLong bufferedUpdates = (AtomicLong)sliceProperties.get(collection).get(s.getName()).get(BUFFERED_UPDATES);\n        if (bufferedUpdates != null) {\n          if (bufferedUpdates.get() > 0) {\n            bufferedUpdates.decrementAndGet();\n          } else {\n            log.debug(\"-- attempting to delete nonexistent buffered doc \" + id + \" from \" + s.getLeader());\n          }\n          continue;\n        }\n        lock.lockInterruptibly();\n        try {\n          simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", 1, true, false);\n          simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", -1, true, false);\n          Number indexSize = (Number)ri.getVariable(Type.CORE_IDX.metricsAttribute);\n          if (indexSize != null && indexSize.longValue() > SimCloudManager.DEFAULT_IDX_SIZE_BYTES) {\n            indexSize = indexSize.longValue() - DEFAULT_DOC_SIZE_BYTES;\n            simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                new AtomicLong(indexSize.longValue()), false, false);\n            simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                new AtomicDouble((Double)Type.CORE_IDX.convertVal(indexSize)), false, false);\n          } else {\n            throw new Exception(\"unexpected indexSize ri=\" + ri);\n          }\n        } catch (Exception e) {\n          throw new IOException(e);\n        } finally {\n          lock.unlock();\n        }\n      }\n    }\n    deletes = req.getDeleteQuery();\n    if (deletes != null && !deletes.isEmpty()) {\n      for (String q : deletes) {\n        if (!\"*:*\".equals(q)) {\n          throw new UnsupportedOperationException(\"Only '*:*' query is supported in deleteByQuery\");\n        }\n        for (Slice s : coll.getSlices()) {\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            log.debug(\"-- no leader in \" + s);\n            continue;\n          }\n\n          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          ReplicaInfo ri = getReplicaInfo(leader);\n          Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n          if (numDocs == null || numDocs.intValue() == 0) {\n            continue;\n          }\n          lock.lockInterruptibly();\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", new AtomicLong(numDocs.longValue()), false, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", new AtomicLong(0), false, false);\n            simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                new AtomicLong(SimCloudManager.DEFAULT_IDX_SIZE_BYTES), false, false);\n            simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                new AtomicDouble((Double)Type.CORE_IDX.convertVal(SimCloudManager.DEFAULT_IDX_SIZE_BYTES)), false, false);\n          } catch (Exception e) {\n            throw new IOException(e);\n          } finally {\n            lock.unlock();\n          }\n        }\n      }\n    }\n    List<SolrInputDocument> docs = req.getDocuments();\n    int docCount = 0;\n    Iterator<SolrInputDocument> it = null;\n    if (docs != null) {\n      docCount = docs.size();\n    } else {\n      it = req.getDocIterator();\n      if (it != null) {\n        while (it.hasNext()) {\n          it.next();\n          docCount++;\n        }\n      }\n    }\n    if (docCount > 0) {\n      // this approach to updating counters and metrics drastically increases performance\n      // of bulk updates, because simSetShardValue is relatively costly\n\n      Map<String, AtomicLong> docUpdates = new HashMap<>();\n      Map<String, Map<String, AtomicLong>> metricUpdates = new HashMap<>();\n\n      // XXX don't add more than 2bln docs in one request\n      boolean modified = false;\n      lock.lockInterruptibly();\n      try {\n        coll = getClusterState().getCollection(collection);\n        Slice[] slices = coll.getActiveSlicesArr();\n        if (slices.length == 0) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection without slices\");\n        }\n        int[] perSlice = new int[slices.length];\n\n        if (it != null) {\n          // BULK UPDATE: simulate random doc assignment without actually calling DocRouter,\n          // which adds significant overhead\n\n          int totalAdded = 0;\n          for (int i = 0; i < slices.length; i++) {\n            Slice s = slices[i];\n            long count = (long) docCount * ((long) s.getRange().max - (long) s.getRange().min) / 0x100000000L;\n            perSlice[i] = (int) count;\n            totalAdded += perSlice[i];\n          }\n          // loss of precision due to integer math\n          int diff = docCount - totalAdded;\n          if (diff > 0) {\n            // spread the remainder more or less equally\n            int perRemain = diff / slices.length;\n            int remainder = diff % slices.length;\n            int remainderSlice = slices.length > 1 ? bulkUpdateRandom.nextInt(slices.length) : 0;\n            for (int i = 0; i < slices.length; i++) {\n              perSlice[i] += perRemain;\n              if (i == remainderSlice) {\n                perSlice[i] += remainder;\n              }\n            }\n          }\n          for (int i = 0; i < slices.length; i++) {\n            Slice s = slices[i];\n            Replica leader = s.getLeader();\n            if (leader == null) {\n              log.debug(\"-- no leader in \" + s);\n              continue;\n            }\n            metricUpdates.computeIfAbsent(s.getName(), sh -> new HashMap<>())\n                .computeIfAbsent(leader.getCoreName(), cn -> new AtomicLong())\n                .addAndGet(perSlice[i]);\n            modified = true;\n            AtomicLong bufferedUpdates = (AtomicLong)sliceProperties.get(collection).get(s.getName()).get(BUFFERED_UPDATES);\n            if (bufferedUpdates != null) {\n              bufferedUpdates.addAndGet(perSlice[i]);\n              continue;\n            }\n            docUpdates.computeIfAbsent(s.getName(), sh -> new AtomicLong())\n                .addAndGet(perSlice[i]);\n          }\n        } else {\n          // SMALL UPDATE: use exact assignment via DocRouter\n          for (SolrInputDocument doc : docs) {\n            String id = (String) doc.getFieldValue(\"id\");\n            if (id == null) {\n              throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Document without id: \" + doc);\n            }\n            Slice s = coll.getRouter().getTargetSlice(id, doc, null, null, coll);\n            Replica leader = s.getLeader();\n            if (leader == null) {\n              log.debug(\"-- no leader in \" + s);\n              continue;\n            }\n            metricUpdates.computeIfAbsent(s.getName(), sh -> new HashMap<>())\n                .computeIfAbsent(leader.getCoreName(), cn -> new AtomicLong())\n                .incrementAndGet();\n            modified = true;\n            AtomicLong bufferedUpdates = (AtomicLong)sliceProperties.get(collection).get(s.getName()).get(BUFFERED_UPDATES);\n            if (bufferedUpdates != null) {\n              bufferedUpdates.incrementAndGet();\n              continue;\n            }\n            docUpdates.computeIfAbsent(s.getName(), sh -> new AtomicLong())\n                .incrementAndGet();\n          }\n        }\n\n        if (modified) {\n          docUpdates.forEach((sh, count) -> {\n            try {\n              simSetShardValue(collection, sh, \"SEARCHER.searcher.numDocs\", count.get(), true, false);\n              simSetShardValue(collection, sh, \"SEARCHER.searcher.maxDoc\", count.get(), true, false);\n              // for each new document increase the size by DEFAULT_DOC_SIZE_BYTES\n              simSetShardValue(collection, sh, Type.CORE_IDX.metricsAttribute,\n                  DEFAULT_DOC_SIZE_BYTES * count.get(), true, false);\n              simSetShardValue(collection, sh, Variable.coreidxsize,\n                  Type.CORE_IDX.convertVal(DEFAULT_DOC_SIZE_BYTES * count.get()), true, false);\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          });\n          metricUpdates.forEach((sh, cores) -> {\n            cores.forEach((core, count) -> {\n              String registry = SolrMetricManager.getRegistryName(SolrInfoBean.Group.core, collection, sh,\n                  Utils.parseMetricsReplicaName(collection, core));\n              cloudManager.getMetricManager().registry(registry).counter(\"UPDATE./update.requests\").inc(count.get());\n            });\n          });\n        }\n      } finally {\n        lock.unlock();\n      }\n    }\n    return new UpdateResponse();\n  }\n\n","sourceOld":"  /**\n   * Simulate an update by modifying replica metrics.\n   * The following core metrics are updated:\n   * <ul>\n   *   <li><code>SEARCHER.searcher.numDocs</code> - increased by added docs, decreased by deleteById and deleteByQuery</li>\n   *   <li><code>SEARCHER.searcher.deletedDocs</code> - decreased by deleteById and deleteByQuery by up to <code>numDocs</code></li>\n   *   <li><code>SEARCHER.searcher.maxDoc</code> - always increased by the number of added docs.</li>\n   * </ul>\n   * <p>IMPORTANT limitations:</p>\n   * <ul>\n   *   <li>document replacements are always counted as new docs</li>\n   *   <li>delete by ID always succeeds (unless numDocs == 0)</li>\n   *   <li>deleteByQuery is not supported unless the query is <code>*:*</code></li>\n   * </ul>\n   * @param req update request. This request MUST have the <code>collection</code> param set.\n   * @return {@link UpdateResponse}\n   * @throws SolrException on errors, such as nonexistent collection or unsupported deleteByQuery\n   */\n  public UpdateResponse simUpdate(UpdateRequest req) throws SolrException, InterruptedException, IOException {\n    ensureNotClosed();\n    String collection = req.getCollection();\n    if (collection == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection not set\");\n    }\n    ensureSystemCollection(collection);\n    \n    DocCollection coll = getClusterState().getCollection(collection);\n    DocRouter router = coll.getRouter();\n    List<String> deletes = req.getDeleteById();\n    if (deletes != null && !deletes.isEmpty()) {\n      for (String id : deletes) {\n        Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);\n        Replica leader = s.getLeader();\n        if (leader == null) {\n          log.debug(\"-- no leader in \" + s);\n          continue;\n        }\n        cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n        ReplicaInfo ri = getReplicaInfo(leader);\n        Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n        if (numDocs == null || numDocs.intValue() <= 0) {\n          log.debug(\"-- attempting to delete nonexistent doc \" + id + \" from \" + s.getLeader());\n          continue;\n        }\n        AtomicLong bufferedUpdates = (AtomicLong)sliceProperties.get(collection).get(s.getName()).get(BUFFERED_UPDATES);\n        if (bufferedUpdates != null) {\n          if (bufferedUpdates.get() > 0) {\n            bufferedUpdates.decrementAndGet();\n          } else {\n            log.debug(\"-- attempting to delete nonexistent buffered doc \" + id + \" from \" + s.getLeader());\n          }\n          continue;\n        }\n        lock.lockInterruptibly();\n        try {\n          simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", 1, true, false);\n          simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", -1, true, false);\n          Number indexSize = (Number)ri.getVariable(Type.CORE_IDX.metricsAttribute);\n          if (indexSize != null && indexSize.longValue() > SimCloudManager.DEFAULT_IDX_SIZE_BYTES) {\n            indexSize = indexSize.longValue() - DEFAULT_DOC_SIZE_BYTES;\n            simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                new AtomicLong(indexSize.longValue()), false, false);\n            simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                new AtomicDouble((Double)Type.CORE_IDX.convertVal(indexSize)), false, false);\n          } else {\n            throw new Exception(\"unexpected indexSize ri=\" + ri);\n          }\n        } catch (Exception e) {\n          throw new IOException(e);\n        } finally {\n          lock.unlock();\n        }\n      }\n    }\n    deletes = req.getDeleteQuery();\n    if (deletes != null && !deletes.isEmpty()) {\n      for (String q : deletes) {\n        if (!\"*:*\".equals(q)) {\n          throw new UnsupportedOperationException(\"Only '*:*' query is supported in deleteByQuery\");\n        }\n        for (Slice s : coll.getSlices()) {\n          Replica leader = s.getLeader();\n          if (leader == null) {\n            log.debug(\"-- no leader in \" + s);\n            continue;\n          }\n\n          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter(\"UPDATE./update.requests\").inc();\n          ReplicaInfo ri = getReplicaInfo(leader);\n          Number numDocs = (Number)ri.getVariable(\"SEARCHER.searcher.numDocs\");\n          if (numDocs == null || numDocs.intValue() == 0) {\n            continue;\n          }\n          lock.lockInterruptibly();\n          try {\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.deletedDocs\", new AtomicLong(numDocs.longValue()), false, false);\n            simSetShardValue(collection, s.getName(), \"SEARCHER.searcher.numDocs\", new AtomicLong(0), false, false);\n            simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,\n                new AtomicLong(SimCloudManager.DEFAULT_IDX_SIZE_BYTES), false, false);\n            simSetShardValue(collection, s.getName(), Variable.coreidxsize,\n                new AtomicDouble((Double)Type.CORE_IDX.convertVal(SimCloudManager.DEFAULT_IDX_SIZE_BYTES)), false, false);\n          } catch (Exception e) {\n            throw new IOException(e);\n          } finally {\n            lock.unlock();\n          }\n        }\n      }\n    }\n    List<SolrInputDocument> docs = req.getDocuments();\n    int docCount = 0;\n    Iterator<SolrInputDocument> it = null;\n    if (docs != null) {\n      docCount = docs.size();\n    } else {\n      it = req.getDocIterator();\n      if (it != null) {\n        while (it.hasNext()) {\n          it.next();\n          docCount++;\n        }\n      }\n    }\n    if (docCount > 0) {\n      // this approach to updating counters and metrics drastically increases performance\n      // of bulk updates, because simSetShardValue is relatively costly\n\n      Map<String, AtomicLong> docUpdates = new HashMap<>();\n      Map<String, Map<String, AtomicLong>> metricUpdates = new HashMap<>();\n\n      // XXX don't add more than 2bln docs in one request\n      boolean modified = false;\n      lock.lockInterruptibly();\n      try {\n        coll = getClusterState().getCollection(collection);\n        Slice[] slices = coll.getActiveSlicesArr();\n        if (slices.length == 0) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Collection without slices\");\n        }\n        int[] perSlice = new int[slices.length];\n\n        if (it != null) {\n          // BULK UPDATE: simulate random doc assignment without actually calling DocRouter,\n          // which adds significant overhead\n\n          int totalAdded = 0;\n          for (int i = 0; i < slices.length; i++) {\n            Slice s = slices[i];\n            long count = (long) docCount * ((long) s.getRange().max - (long) s.getRange().min) / 0x100000000L;\n            perSlice[i] = (int) count;\n            totalAdded += perSlice[i];\n          }\n          // loss of precision due to integer math\n          int diff = docCount - totalAdded;\n          if (diff > 0) {\n            // spread the remainder more or less equally\n            int perRemain = diff / slices.length;\n            int remainder = diff % slices.length;\n            int remainderSlice = slices.length > 1 ? bulkUpdateRandom.nextInt(slices.length) : 0;\n            for (int i = 0; i < slices.length; i++) {\n              perSlice[i] += perRemain;\n              if (i == remainderSlice) {\n                perSlice[i] += remainder;\n              }\n            }\n          }\n          for (int i = 0; i < slices.length; i++) {\n            Slice s = slices[i];\n            Replica leader = s.getLeader();\n            if (leader == null) {\n              log.debug(\"-- no leader in \" + s);\n              continue;\n            }\n            metricUpdates.computeIfAbsent(s.getName(), sh -> new HashMap<>())\n                .computeIfAbsent(leader.getCoreName(), cn -> new AtomicLong())\n                .addAndGet(perSlice[i]);\n            modified = true;\n            AtomicLong bufferedUpdates = (AtomicLong)sliceProperties.get(collection).get(s.getName()).get(BUFFERED_UPDATES);\n            if (bufferedUpdates != null) {\n              bufferedUpdates.addAndGet(perSlice[i]);\n              continue;\n            }\n            docUpdates.computeIfAbsent(s.getName(), sh -> new AtomicLong())\n                .addAndGet(perSlice[i]);\n          }\n        } else {\n          // SMALL UPDATE: use exact assignment via DocRouter\n          for (SolrInputDocument doc : docs) {\n            String id = (String) doc.getFieldValue(\"id\");\n            if (id == null) {\n              throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Document without id: \" + doc);\n            }\n            Slice s = coll.getRouter().getTargetSlice(id, doc, null, null, coll);\n            Replica leader = s.getLeader();\n            if (leader == null) {\n              log.debug(\"-- no leader in \" + s);\n              continue;\n            }\n            metricUpdates.computeIfAbsent(s.getName(), sh -> new HashMap<>())\n                .computeIfAbsent(leader.getCoreName(), cn -> new AtomicLong())\n                .incrementAndGet();\n            modified = true;\n            AtomicLong bufferedUpdates = (AtomicLong)sliceProperties.get(collection).get(s.getName()).get(BUFFERED_UPDATES);\n            if (bufferedUpdates != null) {\n              bufferedUpdates.incrementAndGet();\n              continue;\n            }\n            docUpdates.computeIfAbsent(s.getName(), sh -> new AtomicLong())\n                .incrementAndGet();\n          }\n        }\n\n        if (modified) {\n          docUpdates.forEach((sh, count) -> {\n            try {\n              simSetShardValue(collection, sh, \"SEARCHER.searcher.numDocs\", count.get(), true, false);\n              simSetShardValue(collection, sh, \"SEARCHER.searcher.maxDoc\", count.get(), true, false);\n              // for each new document increase the size by DEFAULT_DOC_SIZE_BYTES\n              simSetShardValue(collection, sh, Type.CORE_IDX.metricsAttribute,\n                  DEFAULT_DOC_SIZE_BYTES * count.get(), true, false);\n              simSetShardValue(collection, sh, Variable.coreidxsize,\n                  Type.CORE_IDX.convertVal(DEFAULT_DOC_SIZE_BYTES * count.get()), true, false);\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          });\n          metricUpdates.forEach((sh, cores) -> {\n            cores.forEach((core, count) -> {\n              String registry = SolrMetricManager.getRegistryName(SolrInfoBean.Group.core, collection, sh,\n                  Utils.parseMetricsReplicaName(collection, core));\n              cloudManager.getMetricManager().registry(registry).counter(\"UPDATE./update.requests\").inc(count.get());\n            });\n          });\n        }\n      } finally {\n        lock.unlock();\n      }\n    }\n    return new UpdateResponse();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"fc18bc8ea2e2c1e308757ff50671c774438e9f3e":["e9c81f7e703d7ccca5bc78beb61253f0a8a22afd"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["8254aa20264eb7a88d556bbe0346667937ed9c2a"],"8254aa20264eb7a88d556bbe0346667937ed9c2a":["fc18bc8ea2e2c1e308757ff50671c774438e9f3e"],"43345f1452f9510f8aaadae6156fe0c834e7d957":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","ce71a9836bf1eba34a0ab31884e9eb8ad3f1cef1"],"35d82bbcb7dc7df226e79bcfbea9942ba25f5e6c":["43345f1452f9510f8aaadae6156fe0c834e7d957"],"042b92cf48996255bedb0c3c4bf772d7e06e4dea":["427edb17549d4bb82462a16eec4ee0533d12d5b7"],"6b55cd711a129fb7fc4c3c4672d652149c9a4faa":["4181b4cf0450ea3c6d1aff8dc3ad4ed9cd3eeb6a"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["4181b4cf0450ea3c6d1aff8dc3ad4ed9cd3eeb6a","6b55cd711a129fb7fc4c3c4672d652149c9a4faa"],"4181b4cf0450ea3c6d1aff8dc3ad4ed9cd3eeb6a":["5c6453827f947004a68ad9db7418781e9df2f660"],"ce71a9836bf1eba34a0ab31884e9eb8ad3f1cef1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"427edb17549d4bb82462a16eec4ee0533d12d5b7":["6b55cd711a129fb7fc4c3c4672d652149c9a4faa"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5"],"e9c81f7e703d7ccca5bc78beb61253f0a8a22afd":["042b92cf48996255bedb0c3c4bf772d7e06e4dea"],"5c6453827f947004a68ad9db7418781e9df2f660":["43345f1452f9510f8aaadae6156fe0c834e7d957","35d82bbcb7dc7df226e79bcfbea9942ba25f5e6c"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["4181b4cf0450ea3c6d1aff8dc3ad4ed9cd3eeb6a","6b55cd711a129fb7fc4c3c4672d652149c9a4faa"]},"commit2Childs":{"fc18bc8ea2e2c1e308757ff50671c774438e9f3e":["8254aa20264eb7a88d556bbe0346667937ed9c2a"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5"],"8254aa20264eb7a88d556bbe0346667937ed9c2a":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"43345f1452f9510f8aaadae6156fe0c834e7d957":["35d82bbcb7dc7df226e79bcfbea9942ba25f5e6c","5c6453827f947004a68ad9db7418781e9df2f660"],"35d82bbcb7dc7df226e79bcfbea9942ba25f5e6c":["5c6453827f947004a68ad9db7418781e9df2f660"],"042b92cf48996255bedb0c3c4bf772d7e06e4dea":["e9c81f7e703d7ccca5bc78beb61253f0a8a22afd"],"6b55cd711a129fb7fc4c3c4672d652149c9a4faa":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","427edb17549d4bb82462a16eec4ee0533d12d5b7","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"4181b4cf0450ea3c6d1aff8dc3ad4ed9cd3eeb6a":["6b55cd711a129fb7fc4c3c4672d652149c9a4faa","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"ce71a9836bf1eba34a0ab31884e9eb8ad3f1cef1":["43345f1452f9510f8aaadae6156fe0c834e7d957"],"427edb17549d4bb82462a16eec4ee0533d12d5b7":["042b92cf48996255bedb0c3c4bf772d7e06e4dea"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["43345f1452f9510f8aaadae6156fe0c834e7d957","ce71a9836bf1eba34a0ab31884e9eb8ad3f1cef1"],"9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"e9c81f7e703d7ccca5bc78beb61253f0a8a22afd":["fc18bc8ea2e2c1e308757ff50671c774438e9f3e"],"5c6453827f947004a68ad9db7418781e9df2f660":["4181b4cf0450ea3c6d1aff8dc3ad4ed9cd3eeb6a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[]},"heads":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}