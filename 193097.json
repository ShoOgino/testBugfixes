{"path":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher).mjava","commits":[{"id":"77855215e331ce146763531cb9b0c050726f6ae5","date":1338323851,"type":0,"author":"Martijn van Groningen","isMerge":false,"pathNew":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher);\n    return new Weight() {\n\n      private TermsEnum segmentTermsEnum;\n\n      public Explanation explain(AtomicReaderContext context, int doc) throws IOException {\n        SVInnerScorer scorer = (SVInnerScorer) scorer(context, true, false, context.reader().getLiveDocs());\n        if (scorer != null) {\n          if (scorer.advance(doc) == doc) {\n            return scorer.explain();\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      public Query getQuery() {\n        return TermsIncludingScoreQuery.this;\n      }\n\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (multipleValuesPerDocument) {\n          return new MVInnerScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc());\n        } else {\n          return new SVInnerScorer(this, acceptDocs, segmentTermsEnum);\n        }\n      }\n    };\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["7b9f056598bc578796f7c2eaa4b2bb8eaab5c23a"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b64a4420c88dd81303e7f7959057baf9f3b45f94","date":1346077333,"type":3,"author":"Martijn van Groningen","isMerge":false,"pathNew":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher).mjava","pathOld":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher);\n    return new Weight() {\n\n      private TermsEnum segmentTermsEnum;\n\n      public Explanation explain(AtomicReaderContext context, int doc) throws IOException {\n        SVInnerScorer scorer = (SVInnerScorer) scorer(context, false, false, context.reader().getLiveDocs());\n        if (scorer != null) {\n          if (scorer.advanceForExplainOnly(doc) == doc) {\n            return scorer.explain();\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      public Query getQuery() {\n        return TermsIncludingScoreQuery.this;\n      }\n\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (scoreDocsInOrder) {\n          if (multipleValuesPerDocument) {\n            return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc());\n          } else {\n            return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc());\n          }\n        } else if (multipleValuesPerDocument) {\n          return new MVInnerScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc());\n        } else {\n          return new SVInnerScorer(this, acceptDocs, segmentTermsEnum);\n        }\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher);\n    return new Weight() {\n\n      private TermsEnum segmentTermsEnum;\n\n      public Explanation explain(AtomicReaderContext context, int doc) throws IOException {\n        SVInnerScorer scorer = (SVInnerScorer) scorer(context, true, false, context.reader().getLiveDocs());\n        if (scorer != null) {\n          if (scorer.advance(doc) == doc) {\n            return scorer.explain();\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      public Query getQuery() {\n        return TermsIncludingScoreQuery.this;\n      }\n\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (multipleValuesPerDocument) {\n          return new MVInnerScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc());\n        } else {\n          return new SVInnerScorer(this, acceptDocs, segmentTermsEnum);\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":["7b9f056598bc578796f7c2eaa4b2bb8eaab5c23a"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"05a14b2611ead08655a2b2bdc61632eb31316e57","date":1346366621,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher).mjava","pathOld":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher);\n    return new Weight() {\n\n      private TermsEnum segmentTermsEnum;\n\n      public Explanation explain(AtomicReaderContext context, int doc) throws IOException {\n        SVInnerScorer scorer = (SVInnerScorer) scorer(context, false, false, context.reader().getLiveDocs());\n        if (scorer != null) {\n          if (scorer.advanceForExplainOnly(doc) == doc) {\n            return scorer.explain();\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      public Query getQuery() {\n        return TermsIncludingScoreQuery.this;\n      }\n\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (scoreDocsInOrder) {\n          if (multipleValuesPerDocument) {\n            return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc());\n          } else {\n            return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc());\n          }\n        } else if (multipleValuesPerDocument) {\n          return new MVInnerScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc());\n        } else {\n          return new SVInnerScorer(this, acceptDocs, segmentTermsEnum);\n        }\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher);\n    return new Weight() {\n\n      private TermsEnum segmentTermsEnum;\n\n      public Explanation explain(AtomicReaderContext context, int doc) throws IOException {\n        SVInnerScorer scorer = (SVInnerScorer) scorer(context, true, false, context.reader().getLiveDocs());\n        if (scorer != null) {\n          if (scorer.advance(doc) == doc) {\n            return scorer.explain();\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      public Query getQuery() {\n        return TermsIncludingScoreQuery.this;\n      }\n\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (multipleValuesPerDocument) {\n          return new MVInnerScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc());\n        } else {\n          return new SVInnerScorer(this, acceptDocs, segmentTermsEnum);\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7530de27b87b961b51f01bd1299b7004d46e8823","date":1355236261,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher).mjava","pathOld":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher);\n    return new Weight() {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(AtomicReaderContext context, int doc) throws IOException {\n        SVInnerScorer scorer = (SVInnerScorer) scorer(context, false, false, context.reader().getLiveDocs());\n        if (scorer != null) {\n          if (scorer.advanceForExplainOnly(doc) == doc) {\n            return scorer.explain();\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public Query getQuery() {\n        return TermsIncludingScoreQuery.this;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (scoreDocsInOrder) {\n          if (multipleValuesPerDocument) {\n            return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc());\n          } else {\n            return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc());\n          }\n        } else if (multipleValuesPerDocument) {\n          return new MVInnerScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc());\n        } else {\n          return new SVInnerScorer(this, acceptDocs, segmentTermsEnum);\n        }\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher);\n    return new Weight() {\n\n      private TermsEnum segmentTermsEnum;\n\n      public Explanation explain(AtomicReaderContext context, int doc) throws IOException {\n        SVInnerScorer scorer = (SVInnerScorer) scorer(context, false, false, context.reader().getLiveDocs());\n        if (scorer != null) {\n          if (scorer.advanceForExplainOnly(doc) == doc) {\n            return scorer.explain();\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      public Query getQuery() {\n        return TermsIncludingScoreQuery.this;\n      }\n\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (scoreDocsInOrder) {\n          if (multipleValuesPerDocument) {\n            return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc());\n          } else {\n            return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc());\n          }\n        } else if (multipleValuesPerDocument) {\n          return new MVInnerScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc());\n        } else {\n          return new SVInnerScorer(this, acceptDocs, segmentTermsEnum);\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher).mjava","pathOld":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher);\n    return new Weight() {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(AtomicReaderContext context, int doc) throws IOException {\n        SVInnerScorer scorer = (SVInnerScorer) scorer(context, false, false, context.reader().getLiveDocs());\n        if (scorer != null) {\n          if (scorer.advanceForExplainOnly(doc) == doc) {\n            return scorer.explain();\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public Query getQuery() {\n        return TermsIncludingScoreQuery.this;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (scoreDocsInOrder) {\n          if (multipleValuesPerDocument) {\n            return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc());\n          } else {\n            return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc());\n          }\n        } else if (multipleValuesPerDocument) {\n          return new MVInnerScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc());\n        } else {\n          return new SVInnerScorer(this, acceptDocs, segmentTermsEnum);\n        }\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher);\n    return new Weight() {\n\n      private TermsEnum segmentTermsEnum;\n\n      public Explanation explain(AtomicReaderContext context, int doc) throws IOException {\n        SVInnerScorer scorer = (SVInnerScorer) scorer(context, false, false, context.reader().getLiveDocs());\n        if (scorer != null) {\n          if (scorer.advanceForExplainOnly(doc) == doc) {\n            return scorer.explain();\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      public Query getQuery() {\n        return TermsIncludingScoreQuery.this;\n      }\n\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (scoreDocsInOrder) {\n          if (multipleValuesPerDocument) {\n            return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc());\n          } else {\n            return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc());\n          }\n        } else if (multipleValuesPerDocument) {\n          return new MVInnerScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc());\n        } else {\n          return new SVInnerScorer(this, acceptDocs, segmentTermsEnum);\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7b9f056598bc578796f7c2eaa4b2bb8eaab5c23a","date":1363294103,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher).mjava","pathOld":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher);\n    return new Weight() {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(AtomicReaderContext context, int doc) throws IOException {\n        SVInnerScorer scorer = (SVInnerScorer) scorer(context, false, false, context.reader().getLiveDocs());\n        if (scorer != null) {\n          if (scorer.advanceForExplainOnly(doc) == doc) {\n            return scorer.explain();\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public Query getQuery() {\n        return TermsIncludingScoreQuery.this;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (scoreDocsInOrder) {\n          if (multipleValuesPerDocument) {\n            return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n          } else {\n            return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n          }\n        } else if (multipleValuesPerDocument) {\n          return new MVInnerScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInnerScorer(this, acceptDocs, segmentTermsEnum, cost);\n        }\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher);\n    return new Weight() {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(AtomicReaderContext context, int doc) throws IOException {\n        SVInnerScorer scorer = (SVInnerScorer) scorer(context, false, false, context.reader().getLiveDocs());\n        if (scorer != null) {\n          if (scorer.advanceForExplainOnly(doc) == doc) {\n            return scorer.explain();\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public Query getQuery() {\n        return TermsIncludingScoreQuery.this;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (scoreDocsInOrder) {\n          if (multipleValuesPerDocument) {\n            return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc());\n          } else {\n            return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc());\n          }\n        } else if (multipleValuesPerDocument) {\n          return new MVInnerScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc());\n        } else {\n          return new SVInnerScorer(this, acceptDocs, segmentTermsEnum);\n        }\n      }\n    };\n  }\n\n","bugFix":["77855215e331ce146763531cb9b0c050726f6ae5","b64a4420c88dd81303e7f7959057baf9f3b45f94"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"66222ffeaa9b434e7840f3c18a875ea65ddaf91f","date":1393866645,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher).mjava","pathOld":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher);\n    return new Weight() {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(AtomicReaderContext context, int doc) throws IOException {\n        SVInnerScorer scorer = (SVInnerScorer) scorer(context, false, false, context.reader().getLiveDocs());\n        if (scorer != null) {\n          if (scorer.advanceForExplainOnly(doc) == doc) {\n            return scorer.explain();\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        // We have optimized impls below if we are allowed\n        // to score out-of-order:\n        return true;\n      }\n\n      @Override\n      public Query getQuery() {\n        return TermsIncludingScoreQuery.this;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (scoreDocsInOrder) {\n          if (multipleValuesPerDocument) {\n            return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n          } else {\n            return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n          }\n        } else if (multipleValuesPerDocument) {\n          return new MVInnerScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInnerScorer(this, acceptDocs, segmentTermsEnum, cost);\n        }\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher);\n    return new Weight() {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(AtomicReaderContext context, int doc) throws IOException {\n        SVInnerScorer scorer = (SVInnerScorer) scorer(context, false, false, context.reader().getLiveDocs());\n        if (scorer != null) {\n          if (scorer.advanceForExplainOnly(doc) == doc) {\n            return scorer.explain();\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public Query getQuery() {\n        return TermsIncludingScoreQuery.this;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (scoreDocsInOrder) {\n          if (multipleValuesPerDocument) {\n            return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n          } else {\n            return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n          }\n        } else if (multipleValuesPerDocument) {\n          return new MVInnerScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInnerScorer(this, acceptDocs, segmentTermsEnum, cost);\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2e18c86f811939bfa8cd24046c96ed026f2e9b34","date":1393893071,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher).mjava","pathOld":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher);\n    return new Weight() {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(AtomicReaderContext context, int doc) throws IOException {\n        SVInnerScorer scorer = (SVInnerScorer) topScorer(context, false, null);\n        if (scorer != null) {\n          return scorer.explain(doc);\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        // We have optimized impls below if we are allowed\n        // to score out-of-order:\n        return true;\n      }\n\n      @Override\n      public Query getQuery() {\n        return TermsIncludingScoreQuery.this;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n      @Override\n      public TopScorer topScorer(AtomicReaderContext context, boolean scoreDocsInOrder, Bits acceptDocs) throws IOException {\n\n        if (scoreDocsInOrder) {\n          return super.topScorer(context, scoreDocsInOrder, acceptDocs);\n        } else {\n          Terms terms = context.reader().terms(field);\n          if (terms == null) {\n            return null;\n          }\n          // what is the runtime...seems ok?\n          final long cost = context.reader().maxDoc() * terms.size();\n\n          segmentTermsEnum = terms.iterator(segmentTermsEnum);\n          // Optimized impls that take advantage of docs\n          // being allowed to be out of order:\n          if (multipleValuesPerDocument) {\n            return new MVInnerScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n          } else {\n            return new SVInnerScorer(this, acceptDocs, segmentTermsEnum, cost);\n          }\n        }\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher);\n    return new Weight() {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(AtomicReaderContext context, int doc) throws IOException {\n        SVInnerScorer scorer = (SVInnerScorer) scorer(context, false, false, context.reader().getLiveDocs());\n        if (scorer != null) {\n          if (scorer.advanceForExplainOnly(doc) == doc) {\n            return scorer.explain();\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        // We have optimized impls below if we are allowed\n        // to score out-of-order:\n        return true;\n      }\n\n      @Override\n      public Query getQuery() {\n        return TermsIncludingScoreQuery.this;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (scoreDocsInOrder) {\n          if (multipleValuesPerDocument) {\n            return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n          } else {\n            return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n          }\n        } else if (multipleValuesPerDocument) {\n          return new MVInnerScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInnerScorer(this, acceptDocs, segmentTermsEnum, cost);\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a5794e5c995c57444b154b01a9f3c837cd530a77","date":1394190201,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher).mjava","pathOld":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher);\n    return new Weight() {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(AtomicReaderContext context, int doc) throws IOException {\n        SVInnerScorer scorer = (SVInnerScorer) bulkScorer(context, false, null);\n        if (scorer != null) {\n          return scorer.explain(doc);\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        // We have optimized impls below if we are allowed\n        // to score out-of-order:\n        return true;\n      }\n\n      @Override\n      public Query getQuery() {\n        return TermsIncludingScoreQuery.this;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n      @Override\n      public BulkScorer bulkScorer(AtomicReaderContext context, boolean scoreDocsInOrder, Bits acceptDocs) throws IOException {\n\n        if (scoreDocsInOrder) {\n          return super.bulkScorer(context, scoreDocsInOrder, acceptDocs);\n        } else {\n          Terms terms = context.reader().terms(field);\n          if (terms == null) {\n            return null;\n          }\n          // what is the runtime...seems ok?\n          final long cost = context.reader().maxDoc() * terms.size();\n\n          segmentTermsEnum = terms.iterator(segmentTermsEnum);\n          // Optimized impls that take advantage of docs\n          // being allowed to be out of order:\n          if (multipleValuesPerDocument) {\n            return new MVInnerScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n          } else {\n            return new SVInnerScorer(this, acceptDocs, segmentTermsEnum, cost);\n          }\n        }\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher);\n    return new Weight() {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(AtomicReaderContext context, int doc) throws IOException {\n        SVInnerScorer scorer = (SVInnerScorer) topScorer(context, false, null);\n        if (scorer != null) {\n          return scorer.explain(doc);\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        // We have optimized impls below if we are allowed\n        // to score out-of-order:\n        return true;\n      }\n\n      @Override\n      public Query getQuery() {\n        return TermsIncludingScoreQuery.this;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n      @Override\n      public TopScorer topScorer(AtomicReaderContext context, boolean scoreDocsInOrder, Bits acceptDocs) throws IOException {\n\n        if (scoreDocsInOrder) {\n          return super.topScorer(context, scoreDocsInOrder, acceptDocs);\n        } else {\n          Terms terms = context.reader().terms(field);\n          if (terms == null) {\n            return null;\n          }\n          // what is the runtime...seems ok?\n          final long cost = context.reader().maxDoc() * terms.size();\n\n          segmentTermsEnum = terms.iterator(segmentTermsEnum);\n          // Optimized impls that take advantage of docs\n          // being allowed to be out of order:\n          if (multipleValuesPerDocument) {\n            return new MVInnerScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n          } else {\n            return new SVInnerScorer(this, acceptDocs, segmentTermsEnum, cost);\n          }\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"acf00221f44c5f08ccea014f2492b53af15ecd66","date":1394568293,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher).mjava","pathOld":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher);\n    return new Weight() {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(AtomicReaderContext context, int doc) throws IOException {\n        SVInnerScorer scorer = (SVInnerScorer) bulkScorer(context, false, null);\n        if (scorer != null) {\n          return scorer.explain(doc);\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        // We have optimized impls below if we are allowed\n        // to score out-of-order:\n        return true;\n      }\n\n      @Override\n      public Query getQuery() {\n        return TermsIncludingScoreQuery.this;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n      @Override\n      public BulkScorer bulkScorer(AtomicReaderContext context, boolean scoreDocsInOrder, Bits acceptDocs) throws IOException {\n\n        if (scoreDocsInOrder) {\n          return super.bulkScorer(context, scoreDocsInOrder, acceptDocs);\n        } else {\n          Terms terms = context.reader().terms(field);\n          if (terms == null) {\n            return null;\n          }\n          // what is the runtime...seems ok?\n          final long cost = context.reader().maxDoc() * terms.size();\n\n          segmentTermsEnum = terms.iterator(segmentTermsEnum);\n          // Optimized impls that take advantage of docs\n          // being allowed to be out of order:\n          if (multipleValuesPerDocument) {\n            return new MVInnerScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n          } else {\n            return new SVInnerScorer(this, acceptDocs, segmentTermsEnum, cost);\n          }\n        }\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher);\n    return new Weight() {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(AtomicReaderContext context, int doc) throws IOException {\n        SVInnerScorer scorer = (SVInnerScorer) scorer(context, false, false, context.reader().getLiveDocs());\n        if (scorer != null) {\n          if (scorer.advanceForExplainOnly(doc) == doc) {\n            return scorer.explain();\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        // We have optimized impls below if we are allowed\n        // to score out-of-order:\n        return true;\n      }\n\n      @Override\n      public Query getQuery() {\n        return TermsIncludingScoreQuery.this;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (scoreDocsInOrder) {\n          if (multipleValuesPerDocument) {\n            return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n          } else {\n            return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n          }\n        } else if (multipleValuesPerDocument) {\n          return new MVInnerScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInnerScorer(this, acceptDocs, segmentTermsEnum, cost);\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher).mjava","pathOld":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher);\n    return new Weight() {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        SVInnerScorer scorer = (SVInnerScorer) bulkScorer(context, false, null);\n        if (scorer != null) {\n          return scorer.explain(doc);\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        // We have optimized impls below if we are allowed\n        // to score out-of-order:\n        return true;\n      }\n\n      @Override\n      public Query getQuery() {\n        return TermsIncludingScoreQuery.this;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context, boolean scoreDocsInOrder, Bits acceptDocs) throws IOException {\n\n        if (scoreDocsInOrder) {\n          return super.bulkScorer(context, scoreDocsInOrder, acceptDocs);\n        } else {\n          Terms terms = context.reader().terms(field);\n          if (terms == null) {\n            return null;\n          }\n          // what is the runtime...seems ok?\n          final long cost = context.reader().maxDoc() * terms.size();\n\n          segmentTermsEnum = terms.iterator(segmentTermsEnum);\n          // Optimized impls that take advantage of docs\n          // being allowed to be out of order:\n          if (multipleValuesPerDocument) {\n            return new MVInnerScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n          } else {\n            return new SVInnerScorer(this, acceptDocs, segmentTermsEnum, cost);\n          }\n        }\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher);\n    return new Weight() {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(AtomicReaderContext context, int doc) throws IOException {\n        SVInnerScorer scorer = (SVInnerScorer) bulkScorer(context, false, null);\n        if (scorer != null) {\n          return scorer.explain(doc);\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        // We have optimized impls below if we are allowed\n        // to score out-of-order:\n        return true;\n      }\n\n      @Override\n      public Query getQuery() {\n        return TermsIncludingScoreQuery.this;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n      @Override\n      public BulkScorer bulkScorer(AtomicReaderContext context, boolean scoreDocsInOrder, Bits acceptDocs) throws IOException {\n\n        if (scoreDocsInOrder) {\n          return super.bulkScorer(context, scoreDocsInOrder, acceptDocs);\n        } else {\n          Terms terms = context.reader().terms(field);\n          if (terms == null) {\n            return null;\n          }\n          // what is the runtime...seems ok?\n          final long cost = context.reader().maxDoc() * terms.size();\n\n          segmentTermsEnum = terms.iterator(segmentTermsEnum);\n          // Optimized impls that take advantage of docs\n          // being allowed to be out of order:\n          if (multipleValuesPerDocument) {\n            return new MVInnerScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n          } else {\n            return new SVInnerScorer(this, acceptDocs, segmentTermsEnum, cost);\n          }\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":["781239fc84d36be12b84e4d3e2618f5f07a182e3"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f582f18c13d4852b01d4fe0a0196432c5c6f2b7f","date":1421314520,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher).mjava","pathOld":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher);\n    return new Weight() {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          segmentTermsEnum = terms.iterator(segmentTermsEnum);\n          BytesRef spare = new BytesRef();\n          DocsEnum docsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              docsEnum = segmentTermsEnum.docs(null, docsEnum, DocsEnum.FLAG_NONE);\n              if (docsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return new ComplexExplanation(true, score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public Query getQuery() {\n        return TermsIncludingScoreQuery.this;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher);\n    return new Weight() {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        SVInnerScorer scorer = (SVInnerScorer) bulkScorer(context, false, null);\n        if (scorer != null) {\n          return scorer.explain(doc);\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        // We have optimized impls below if we are allowed\n        // to score out-of-order:\n        return true;\n      }\n\n      @Override\n      public Query getQuery() {\n        return TermsIncludingScoreQuery.this;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context, boolean scoreDocsInOrder, Bits acceptDocs) throws IOException {\n\n        if (scoreDocsInOrder) {\n          return super.bulkScorer(context, scoreDocsInOrder, acceptDocs);\n        } else {\n          Terms terms = context.reader().terms(field);\n          if (terms == null) {\n            return null;\n          }\n          // what is the runtime...seems ok?\n          final long cost = context.reader().maxDoc() * terms.size();\n\n          segmentTermsEnum = terms.iterator(segmentTermsEnum);\n          // Optimized impls that take advantage of docs\n          // being allowed to be out of order:\n          if (multipleValuesPerDocument) {\n            return new MVInnerScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n          } else {\n            return new SVInnerScorer(this, acceptDocs, segmentTermsEnum, cost);\n          }\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"781239fc84d36be12b84e4d3e2618f5f07a182e3","date":1423139668,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher).mjava","pathOld":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher);\n    return new Weight() {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          segmentTermsEnum = terms.iterator(segmentTermsEnum);\n          BytesRef spare = new BytesRef();\n          DocsEnum docsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              docsEnum = segmentTermsEnum.docs(null, docsEnum, DocsEnum.FLAG_NONE);\n              if (docsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return new ComplexExplanation(true, score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public Query getQuery() {\n        return TermsIncludingScoreQuery.this;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs, boolean needsScores) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher);\n    return new Weight() {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          segmentTermsEnum = terms.iterator(segmentTermsEnum);\n          BytesRef spare = new BytesRef();\n          DocsEnum docsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              docsEnum = segmentTermsEnum.docs(null, docsEnum, DocsEnum.FLAG_NONE);\n              if (docsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return new ComplexExplanation(true, score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public Query getQuery() {\n        return TermsIncludingScoreQuery.this;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n    };\n  }\n\n","bugFix":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"51f5280f31484820499077f41fcdfe92d527d9dc","date":1423229122,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher).mjava","pathOld":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher);\n    return new Weight() {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          segmentTermsEnum = terms.iterator(segmentTermsEnum);\n          BytesRef spare = new BytesRef();\n          PostingsEnum postingsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              postingsEnum = segmentTermsEnum.postings(null, postingsEnum, PostingsEnum.FLAG_NONE);\n              if (postingsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return new ComplexExplanation(true, score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public Query getQuery() {\n        return TermsIncludingScoreQuery.this;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs, boolean needsScores) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher);\n    return new Weight() {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          segmentTermsEnum = terms.iterator(segmentTermsEnum);\n          BytesRef spare = new BytesRef();\n          DocsEnum docsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              docsEnum = segmentTermsEnum.docs(null, docsEnum, DocsEnum.FLAG_NONE);\n              if (docsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return new ComplexExplanation(true, score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public Query getQuery() {\n        return TermsIncludingScoreQuery.this;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs, boolean needsScores) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fb17639909a369c1e64866842e5c213440acc17e","date":1423238093,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher,boolean).mjava","pathOld":"lucene/join/src/java/org/apache/lucene/search/join/TermsIncludingScoreQuery#createWeight(IndexSearcher).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher, needsScores);\n    return new Weight(TermsIncludingScoreQuery.this) {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          segmentTermsEnum = terms.iterator(segmentTermsEnum);\n          BytesRef spare = new BytesRef();\n          PostingsEnum postingsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              postingsEnum = segmentTermsEnum.postings(null, postingsEnum, PostingsEnum.FLAG_NONE);\n              if (postingsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return new ComplexExplanation(true, score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher) throws IOException {\n    final Weight originalWeight = originalQuery.createWeight(searcher);\n    return new Weight() {\n\n      private TermsEnum segmentTermsEnum;\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms != null) {\n          segmentTermsEnum = terms.iterator(segmentTermsEnum);\n          BytesRef spare = new BytesRef();\n          PostingsEnum postingsEnum = null;\n          for (int i = 0; i < TermsIncludingScoreQuery.this.terms.size(); i++) {\n            if (segmentTermsEnum.seekExact(TermsIncludingScoreQuery.this.terms.get(ords[i], spare))) {\n              postingsEnum = segmentTermsEnum.postings(null, postingsEnum, PostingsEnum.FLAG_NONE);\n              if (postingsEnum.advance(doc) == doc) {\n                final float score = TermsIncludingScoreQuery.this.scores[ords[i]];\n                return new ComplexExplanation(true, score, \"Score based on join value \" + segmentTermsEnum.term().utf8ToString());\n              }\n            }\n          }\n        }\n        return new ComplexExplanation(false, 0.0f, \"Not a match\");\n      }\n\n      @Override\n      public Query getQuery() {\n        return TermsIncludingScoreQuery.this;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException {\n        return originalWeight.getValueForNormalization() * TermsIncludingScoreQuery.this.getBoost() * TermsIncludingScoreQuery.this.getBoost();\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) {\n        originalWeight.normalize(norm, topLevelBoost * TermsIncludingScoreQuery.this.getBoost());\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs, boolean needsScores) throws IOException {\n        Terms terms = context.reader().terms(field);\n        if (terms == null) {\n          return null;\n        }\n        \n        // what is the runtime...seems ok?\n        final long cost = context.reader().maxDoc() * terms.size();\n\n        segmentTermsEnum = terms.iterator(segmentTermsEnum);\n        if (multipleValuesPerDocument) {\n          return new MVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        } else {\n          return new SVInOrderScorer(this, acceptDocs, segmentTermsEnum, context.reader().maxDoc(), cost);\n        }\n      }\n\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"2e18c86f811939bfa8cd24046c96ed026f2e9b34":["66222ffeaa9b434e7840f3c18a875ea65ddaf91f"],"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["b64a4420c88dd81303e7f7959057baf9f3b45f94","7530de27b87b961b51f01bd1299b7004d46e8823"],"fb17639909a369c1e64866842e5c213440acc17e":["51f5280f31484820499077f41fcdfe92d527d9dc"],"781239fc84d36be12b84e4d3e2618f5f07a182e3":["f582f18c13d4852b01d4fe0a0196432c5c6f2b7f"],"7b9f056598bc578796f7c2eaa4b2bb8eaab5c23a":["7530de27b87b961b51f01bd1299b7004d46e8823"],"05a14b2611ead08655a2b2bdc61632eb31316e57":["77855215e331ce146763531cb9b0c050726f6ae5","b64a4420c88dd81303e7f7959057baf9f3b45f94"],"51f5280f31484820499077f41fcdfe92d527d9dc":["781239fc84d36be12b84e4d3e2618f5f07a182e3"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["acf00221f44c5f08ccea014f2492b53af15ecd66"],"b64a4420c88dd81303e7f7959057baf9f3b45f94":["77855215e331ce146763531cb9b0c050726f6ae5"],"66222ffeaa9b434e7840f3c18a875ea65ddaf91f":["7b9f056598bc578796f7c2eaa4b2bb8eaab5c23a"],"f582f18c13d4852b01d4fe0a0196432c5c6f2b7f":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a5794e5c995c57444b154b01a9f3c837cd530a77":["2e18c86f811939bfa8cd24046c96ed026f2e9b34"],"77855215e331ce146763531cb9b0c050726f6ae5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"acf00221f44c5f08ccea014f2492b53af15ecd66":["66222ffeaa9b434e7840f3c18a875ea65ddaf91f","a5794e5c995c57444b154b01a9f3c837cd530a77"],"7530de27b87b961b51f01bd1299b7004d46e8823":["b64a4420c88dd81303e7f7959057baf9f3b45f94"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["fb17639909a369c1e64866842e5c213440acc17e"]},"commit2Childs":{"2e18c86f811939bfa8cd24046c96ed026f2e9b34":["a5794e5c995c57444b154b01a9f3c837cd530a77"],"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"fb17639909a369c1e64866842e5c213440acc17e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"781239fc84d36be12b84e4d3e2618f5f07a182e3":["51f5280f31484820499077f41fcdfe92d527d9dc"],"7b9f056598bc578796f7c2eaa4b2bb8eaab5c23a":["66222ffeaa9b434e7840f3c18a875ea65ddaf91f"],"05a14b2611ead08655a2b2bdc61632eb31316e57":[],"51f5280f31484820499077f41fcdfe92d527d9dc":["fb17639909a369c1e64866842e5c213440acc17e"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["f582f18c13d4852b01d4fe0a0196432c5c6f2b7f"],"b64a4420c88dd81303e7f7959057baf9f3b45f94":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","05a14b2611ead08655a2b2bdc61632eb31316e57","7530de27b87b961b51f01bd1299b7004d46e8823"],"66222ffeaa9b434e7840f3c18a875ea65ddaf91f":["2e18c86f811939bfa8cd24046c96ed026f2e9b34","acf00221f44c5f08ccea014f2492b53af15ecd66"],"f582f18c13d4852b01d4fe0a0196432c5c6f2b7f":["781239fc84d36be12b84e4d3e2618f5f07a182e3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["77855215e331ce146763531cb9b0c050726f6ae5"],"a5794e5c995c57444b154b01a9f3c837cd530a77":["acf00221f44c5f08ccea014f2492b53af15ecd66"],"77855215e331ce146763531cb9b0c050726f6ae5":["05a14b2611ead08655a2b2bdc61632eb31316e57","b64a4420c88dd81303e7f7959057baf9f3b45f94"],"acf00221f44c5f08ccea014f2492b53af15ecd66":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"7530de27b87b961b51f01bd1299b7004d46e8823":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","7b9f056598bc578796f7c2eaa4b2bb8eaab5c23a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","05a14b2611ead08655a2b2bdc61632eb31316e57","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}