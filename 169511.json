{"path":"lucene/replicator/src/test/org/apache/lucene/replicator/nrt/TestNRTReplication.IndexThread#run().mjava","commits":[{"id":"0d49a158012a8ff48f328a4558e4bfcffbaed16f","date":1453677440,"type":0,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/replicator/src/test/org/apache/lucene/replicator/nrt/TestNRTReplication.IndexThread#run().mjava","pathOld":"/dev/null","sourceNew":"    @Override\n    public void run() {\n\n      try {\n        LineFileDocs docs = new LineFileDocs(random());\n        int docCount = 0;\n\n        // How often we do an update/delete vs add:\n        double updatePct = random().nextDouble();\n\n        // Varies how many docs/sec we index:\n        int sleepChance = TestUtil.nextInt(random(), 4, 100);\n\n        message(\"top: indexer: updatePct=\" + updatePct + \" sleepChance=\" + sleepChance);\n\n        long lastTransLogLoc = transLog.getNextLocation();\n        \n        NodeProcess curPrimary = null;\n        Connection c = null;\n\n        while (stop.get() == false) {\n\n          try {\n            while (stop.get() == false && curPrimary == null) {\n              Thread.sleep(10);\n              curPrimary = primary;\n              if (curPrimary != null) {\n                c = new Connection(curPrimary.tcpPort);\n                c.out.writeByte(SimplePrimaryNode.CMD_INDEXING);\n                break;\n              }\n            }\n\n            if (stop.get()) {\n              break;\n            }\n\n            Thread.currentThread().setName(\"indexer p\" + curPrimary.id);\n\n            if (random().nextInt(10) == 7) {\n              // We use the marker docs to check for data loss in search thread:\n              Document doc = new Document();\n              int id = markerUpto.getAndIncrement();\n              String idString = \"m\"+id;\n              doc.add(newStringField(\"docid\", idString, Field.Store.YES));\n              doc.add(newStringField(\"marker\", \"marker\", Field.Store.YES));\n              curPrimary.addOrUpdateDocument(c, doc, false);\n              transLog.addDocument(idString, doc);\n              message(\"index marker=\" + idString + \"; translog is \" + Node.bytesToString(Files.size(transLogPath)));\n            }\n\n            if (docCount > 0 && random().nextDouble() < updatePct) {\n              int randomID = random().nextInt(docCount);\n              String randomIDString = Integer.toString(randomID);\n              if (random().nextBoolean()) {\n                // Replace previous doc\n                Document doc = docs.nextDoc();\n                ((Field) doc.getField(\"docid\")).setStringValue(randomIDString);\n                curPrimary.addOrUpdateDocument(c, doc, true);\n                transLog.updateDocument(randomIDString, doc);\n              } else {\n                // Delete previous doc\n                curPrimary.deleteDocument(c, randomIDString);\n                transLog.deleteDocuments(randomIDString);\n              }\n            } else {\n              // Add new doc:\n              Document doc = docs.nextDoc();\n              String idString = Integer.toString(docCount++);\n              ((Field) doc.getField(\"docid\")).setStringValue(idString);\n              curPrimary.addOrUpdateDocument(c, doc, false);\n              transLog.addDocument(idString, doc);\n\n              if (DO_RANDOM_XLOG_REPLAY && random().nextInt(10) == 7) {\n                long curLoc = transLog.getNextLocation();\n                // randomly replay chunks of translog just to test replay:\n                message(\"now randomly replay translog from \" + lastTransLogLoc + \" to \" + curLoc);\n                transLog.replay(curPrimary, lastTransLogLoc, curLoc);\n                lastTransLogLoc = curLoc;\n              }\n            }\n          } catch (IOException se) {\n            // Assume primary crashed\n            message(\"top: indexer lost connection to primary\");\n            try {\n              c.close();\n            } catch (Throwable t) {\n            }\n            curPrimary = null;\n            c = null;\n          }\n\n          if (random().nextInt(sleepChance) == 0) {\n            Thread.sleep(1);\n          }\n\n          if (random().nextInt(100) == 17) {\n            System.out.println(\"Indexer: now pause for a bit...\");\n            Thread.sleep(TestUtil.nextInt(random(), 500, 2000));\n            System.out.println(\"Indexer: done pause for a bit...\");\n          }\n        }\n        if (curPrimary != null) {\n          try {\n            c.out.writeByte(SimplePrimaryNode.CMD_INDEXING_DONE);\n            c.flush();\n            c.in.readByte();\n          } catch (IOException se) {\n            // Assume primary crashed\n            message(\"top: indexer lost connection to primary\");\n            try {\n              c.close();\n            } catch (Throwable t) {\n            }\n            curPrimary = null;\n            c = null;\n          }\n        }\n        System.out.println(\"Indexer: now stop\");\n      } catch (Throwable t) {\n        failed.set(true);\n        stop.set(true);\n        throw new RuntimeException(t);\n      }\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1baa9aa50ea2e3bb6e5c03f150789720fbcedbc9","date":1453892412,"type":5,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/replicator/src/test/org/apache/lucene/replicator/nrt/TestStressNRTReplication.IndexThread#run().mjava","pathOld":"lucene/replicator/src/test/org/apache/lucene/replicator/nrt/TestNRTReplication.IndexThread#run().mjava","sourceNew":"    @Override\n    public void run() {\n\n      try {\n        LineFileDocs docs = new LineFileDocs(random());\n        int docCount = 0;\n\n        // How often we do an update/delete vs add:\n        double updatePct = random().nextDouble();\n\n        // Varies how many docs/sec we index:\n        int sleepChance = TestUtil.nextInt(random(), 4, 100);\n\n        message(\"top: indexer: updatePct=\" + updatePct + \" sleepChance=\" + sleepChance);\n\n        long lastTransLogLoc = transLog.getNextLocation();\n        \n        NodeProcess curPrimary = null;\n        Connection c = null;\n\n        while (stop.get() == false) {\n\n          try {\n            while (stop.get() == false && curPrimary == null) {\n              Thread.sleep(10);\n              curPrimary = primary;\n              if (curPrimary != null) {\n                c = new Connection(curPrimary.tcpPort);\n                c.out.writeByte(SimplePrimaryNode.CMD_INDEXING);\n                break;\n              }\n            }\n\n            if (stop.get()) {\n              break;\n            }\n\n            Thread.currentThread().setName(\"indexer p\" + curPrimary.id);\n\n            if (random().nextInt(10) == 7) {\n              // We use the marker docs to check for data loss in search thread:\n              Document doc = new Document();\n              int id = markerUpto.getAndIncrement();\n              String idString = \"m\"+id;\n              doc.add(newStringField(\"docid\", idString, Field.Store.YES));\n              doc.add(newStringField(\"marker\", \"marker\", Field.Store.YES));\n              curPrimary.addOrUpdateDocument(c, doc, false);\n              transLog.addDocument(idString, doc);\n              message(\"index marker=\" + idString + \"; translog is \" + Node.bytesToString(Files.size(transLogPath)));\n            }\n\n            if (docCount > 0 && random().nextDouble() < updatePct) {\n              int randomID = random().nextInt(docCount);\n              String randomIDString = Integer.toString(randomID);\n              if (random().nextBoolean()) {\n                // Replace previous doc\n                Document doc = docs.nextDoc();\n                ((Field) doc.getField(\"docid\")).setStringValue(randomIDString);\n                curPrimary.addOrUpdateDocument(c, doc, true);\n                transLog.updateDocument(randomIDString, doc);\n              } else {\n                // Delete previous doc\n                curPrimary.deleteDocument(c, randomIDString);\n                transLog.deleteDocuments(randomIDString);\n              }\n            } else {\n              // Add new doc:\n              Document doc = docs.nextDoc();\n              String idString = Integer.toString(docCount++);\n              ((Field) doc.getField(\"docid\")).setStringValue(idString);\n              curPrimary.addOrUpdateDocument(c, doc, false);\n              transLog.addDocument(idString, doc);\n\n              if (DO_RANDOM_XLOG_REPLAY && random().nextInt(10) == 7) {\n                long curLoc = transLog.getNextLocation();\n                // randomly replay chunks of translog just to test replay:\n                message(\"now randomly replay translog from \" + lastTransLogLoc + \" to \" + curLoc);\n                transLog.replay(curPrimary, lastTransLogLoc, curLoc);\n                lastTransLogLoc = curLoc;\n              }\n            }\n          } catch (IOException se) {\n            // Assume primary crashed\n            message(\"top: indexer lost connection to primary\");\n            try {\n              c.close();\n            } catch (Throwable t) {\n            }\n            curPrimary = null;\n            c = null;\n          }\n\n          if (random().nextInt(sleepChance) == 0) {\n            Thread.sleep(1);\n          }\n\n          if (random().nextInt(100) == 17) {\n            System.out.println(\"Indexer: now pause for a bit...\");\n            Thread.sleep(TestUtil.nextInt(random(), 500, 2000));\n            System.out.println(\"Indexer: done pause for a bit...\");\n          }\n        }\n        if (curPrimary != null) {\n          try {\n            c.out.writeByte(SimplePrimaryNode.CMD_INDEXING_DONE);\n            c.flush();\n            c.in.readByte();\n          } catch (IOException se) {\n            // Assume primary crashed\n            message(\"top: indexer lost connection to primary\");\n            try {\n              c.close();\n            } catch (Throwable t) {\n            }\n            curPrimary = null;\n            c = null;\n          }\n        }\n        System.out.println(\"Indexer: now stop\");\n      } catch (Throwable t) {\n        failed.set(true);\n        stop.set(true);\n        throw new RuntimeException(t);\n      }\n    }\n\n","sourceOld":"    @Override\n    public void run() {\n\n      try {\n        LineFileDocs docs = new LineFileDocs(random());\n        int docCount = 0;\n\n        // How often we do an update/delete vs add:\n        double updatePct = random().nextDouble();\n\n        // Varies how many docs/sec we index:\n        int sleepChance = TestUtil.nextInt(random(), 4, 100);\n\n        message(\"top: indexer: updatePct=\" + updatePct + \" sleepChance=\" + sleepChance);\n\n        long lastTransLogLoc = transLog.getNextLocation();\n        \n        NodeProcess curPrimary = null;\n        Connection c = null;\n\n        while (stop.get() == false) {\n\n          try {\n            while (stop.get() == false && curPrimary == null) {\n              Thread.sleep(10);\n              curPrimary = primary;\n              if (curPrimary != null) {\n                c = new Connection(curPrimary.tcpPort);\n                c.out.writeByte(SimplePrimaryNode.CMD_INDEXING);\n                break;\n              }\n            }\n\n            if (stop.get()) {\n              break;\n            }\n\n            Thread.currentThread().setName(\"indexer p\" + curPrimary.id);\n\n            if (random().nextInt(10) == 7) {\n              // We use the marker docs to check for data loss in search thread:\n              Document doc = new Document();\n              int id = markerUpto.getAndIncrement();\n              String idString = \"m\"+id;\n              doc.add(newStringField(\"docid\", idString, Field.Store.YES));\n              doc.add(newStringField(\"marker\", \"marker\", Field.Store.YES));\n              curPrimary.addOrUpdateDocument(c, doc, false);\n              transLog.addDocument(idString, doc);\n              message(\"index marker=\" + idString + \"; translog is \" + Node.bytesToString(Files.size(transLogPath)));\n            }\n\n            if (docCount > 0 && random().nextDouble() < updatePct) {\n              int randomID = random().nextInt(docCount);\n              String randomIDString = Integer.toString(randomID);\n              if (random().nextBoolean()) {\n                // Replace previous doc\n                Document doc = docs.nextDoc();\n                ((Field) doc.getField(\"docid\")).setStringValue(randomIDString);\n                curPrimary.addOrUpdateDocument(c, doc, true);\n                transLog.updateDocument(randomIDString, doc);\n              } else {\n                // Delete previous doc\n                curPrimary.deleteDocument(c, randomIDString);\n                transLog.deleteDocuments(randomIDString);\n              }\n            } else {\n              // Add new doc:\n              Document doc = docs.nextDoc();\n              String idString = Integer.toString(docCount++);\n              ((Field) doc.getField(\"docid\")).setStringValue(idString);\n              curPrimary.addOrUpdateDocument(c, doc, false);\n              transLog.addDocument(idString, doc);\n\n              if (DO_RANDOM_XLOG_REPLAY && random().nextInt(10) == 7) {\n                long curLoc = transLog.getNextLocation();\n                // randomly replay chunks of translog just to test replay:\n                message(\"now randomly replay translog from \" + lastTransLogLoc + \" to \" + curLoc);\n                transLog.replay(curPrimary, lastTransLogLoc, curLoc);\n                lastTransLogLoc = curLoc;\n              }\n            }\n          } catch (IOException se) {\n            // Assume primary crashed\n            message(\"top: indexer lost connection to primary\");\n            try {\n              c.close();\n            } catch (Throwable t) {\n            }\n            curPrimary = null;\n            c = null;\n          }\n\n          if (random().nextInt(sleepChance) == 0) {\n            Thread.sleep(1);\n          }\n\n          if (random().nextInt(100) == 17) {\n            System.out.println(\"Indexer: now pause for a bit...\");\n            Thread.sleep(TestUtil.nextInt(random(), 500, 2000));\n            System.out.println(\"Indexer: done pause for a bit...\");\n          }\n        }\n        if (curPrimary != null) {\n          try {\n            c.out.writeByte(SimplePrimaryNode.CMD_INDEXING_DONE);\n            c.flush();\n            c.in.readByte();\n          } catch (IOException se) {\n            // Assume primary crashed\n            message(\"top: indexer lost connection to primary\");\n            try {\n              c.close();\n            } catch (Throwable t) {\n            }\n            curPrimary = null;\n            c = null;\n          }\n        }\n        System.out.println(\"Indexer: now stop\");\n      } catch (Throwable t) {\n        failed.set(true);\n        stop.set(true);\n        throw new RuntimeException(t);\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"1baa9aa50ea2e3bb6e5c03f150789720fbcedbc9":["0d49a158012a8ff48f328a4558e4bfcffbaed16f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"0d49a158012a8ff48f328a4558e4bfcffbaed16f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"1baa9aa50ea2e3bb6e5c03f150789720fbcedbc9":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817","0d49a158012a8ff48f328a4558e4bfcffbaed16f"],"0d49a158012a8ff48f328a4558e4bfcffbaed16f":["1baa9aa50ea2e3bb6e5c03f150789720fbcedbc9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["1baa9aa50ea2e3bb6e5c03f150789720fbcedbc9","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}