{"path":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest#test().mjava","commits":[{"id":"61c45e99cf6676da48f19d7511c73712ad39402b","date":1495508331,"type":0,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest#test().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void test() throws Exception {\n    cloudClient.setSoTimeout(clientSoTimeout);\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    \n    boolean testSuccessful = false;\n    try {\n      handle.clear();\n      handle.put(\"timestamp\", SKIPVAL);\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      // make sure we have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n      }      // make sure we again have leaders for each shard\n      \n      waitForRecoveriesToFinish(false);\n      \n      // we cannot do delete by query\n      // as it's not supported for recovery\n      del(\"*:*\");\n      \n      List<StoppableThread> threads = new ArrayList<>();\n      List<StoppableIndexingThread> indexTreads = new ArrayList<>();\n      int threadCount = TEST_NIGHTLY ? 3 : 1;\n      int i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true);\n        threads.add(indexThread);\n        indexTreads.add(indexThread);\n        indexThread.start();\n      }\n      \n      threadCount = 1;\n      i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableSearchThread searchThread = new StoppableSearchThread(cloudClient);\n        threads.add(searchThread);\n        searchThread.start();\n      }\n      \n      if (usually()) {\n        StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n        threads.add(commitThread);\n        commitThread.start();\n      }\n      \n      // TODO: we only do this sometimes so that we can sometimes compare against control,\n      // it's currently hard to know what requests failed when using ConcurrentSolrUpdateServer\n      boolean runFullThrottle = random().nextBoolean();\n      if (runFullThrottle) {\n        FullThrottleStoppableIndexingThread ftIndexThread = \n            new FullThrottleStoppableIndexingThread(controlClient, cloudClient, clients, \"ft1\", true, this.clientSoTimeout);\n        threads.add(ftIndexThread);\n        ftIndexThread.start();\n      }\n      \n      chaosMonkey.startTheMonkey(true, 10000);\n      try {\n        long runLength;\n        if (RUN_LENGTH != -1) {\n          runLength = RUN_LENGTH;\n        } else {\n          int[] runTimes;\n          if (TEST_NIGHTLY) {\n            runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n                30000, 45000, 90000, 120000};\n          } else {\n            runTimes = new int[] {5000, 7000, 15000};\n          }\n          runLength = runTimes[random().nextInt(runTimes.length - 1)];\n        }\n        ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, zkStateReader);\n      } finally {\n        chaosMonkey.stopTheMonkey();\n      }\n\n      // ideally this should go into chaosMonkey\n      restartZk(1000 * (5 + random().nextInt(4)));\n\n      for (StoppableThread indexThread : threads) {\n        indexThread.safeStop();\n      }\n      \n      // start any downed jetties to be sure we still will end up with a leader per shard...\n      \n      // wait for stop...\n      for (StoppableThread indexThread : threads) {\n        indexThread.join();\n      }\n      \n      // try and wait for any replications and what not to finish...\n      \n      ChaosMonkey.wait(2000, DEFAULT_COLLECTION, zkStateReader);\n      \n      // wait until there are no recoveries...\n      waitForThingsToLevelOut(Integer.MAX_VALUE);//Math.round((runLength / 1000.0f / 3.0f)));\n      \n      // make sure we again have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 30000);\n      }\n      \n      commit();\n      \n      // TODO: assert we didnt kill everyone\n      \n      zkStateReader.updateLiveNodes();\n      assertTrue(zkStateReader.getClusterState().getLiveNodes().size() > 0);\n      \n      \n      // we expect full throttle fails, but cloud client should not easily fail\n      for (StoppableThread indexThread : threads) {\n        if (indexThread instanceof StoppableIndexingThread && !(indexThread instanceof FullThrottleStoppableIndexingThread)) {\n          int failCount = ((StoppableIndexingThread) indexThread).getFailCount();\n          assertFalse(\"There were too many update fails (\" + failCount + \" > \" + FAIL_TOLERANCE\n              + \") - we expect it can happen, but shouldn't easily\", failCount > FAIL_TOLERANCE);\n        }\n      }\n      \n      waitForReplicationFromReplicas(DEFAULT_COLLECTION, zkStateReader, new TimeOut(30, TimeUnit.SECONDS));\n//      waitForAllWarmingSearchers();\n      \n      Set<String> addFails = getAddFails(indexTreads);\n      Set<String> deleteFails = getDeleteFails(indexTreads);\n      // full throttle thread can\n      // have request fails\n      checkShardConsistency(!runFullThrottle, true, addFails, deleteFails);      \n      \n      long ctrlDocs = controlClient.query(new SolrQuery(\"*:*\")).getResults()\n      .getNumFound(); \n      \n      // ensure we have added more than 0 docs\n      long cloudClientDocs = cloudClient.query(new SolrQuery(\"*:*\"))\n          .getResults().getNumFound();\n      \n      assertTrue(\"Found \" + ctrlDocs + \" control docs\", cloudClientDocs > 0);\n      \n      if (VERBOSE) System.out.println(\"control docs:\"\n          + controlClient.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound() + \"\\n\\n\");\n      \n      // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n      // sometimes we restart zookeeper as well\n      if (random().nextBoolean()) {\n        restartZk(1000 * (5 + random().nextInt(4)));\n      }\n\n      try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        // We don't really know how many live nodes we have at this point, so \"maxShardsPerNode\" needs to be > 1\n        createCollection(null, \"testcollection\",\n              1, 1, 10, client, null, \"conf1\"); \n      }\n      List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n      numShardsNumReplicas.add(1);\n      numShardsNumReplicas.add(1 + getPullReplicaCount());\n      checkForCollection(\"testcollection\", numShardsNumReplicas, null);\n      \n      testSuccessful = true;\n    } finally {\n      if (!testSuccessful) {\n        logReplicaTypesReplicationInfo(DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n        printLayout();\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["d2f514ff99d806c2911cbc0e81d02d3d756e0ae6","bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e9017cf144952056066919f1ebc7897ff9bd71b1","date":1496757600,"type":0,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest#test().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void test() throws Exception {\n    cloudClient.setSoTimeout(clientSoTimeout);\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    \n    boolean testSuccessful = false;\n    try {\n      handle.clear();\n      handle.put(\"timestamp\", SKIPVAL);\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      // make sure we have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n      }      // make sure we again have leaders for each shard\n      \n      waitForRecoveriesToFinish(false);\n      \n      // we cannot do delete by query\n      // as it's not supported for recovery\n      del(\"*:*\");\n      \n      List<StoppableThread> threads = new ArrayList<>();\n      List<StoppableIndexingThread> indexTreads = new ArrayList<>();\n      int threadCount = TEST_NIGHTLY ? 3 : 1;\n      int i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true);\n        threads.add(indexThread);\n        indexTreads.add(indexThread);\n        indexThread.start();\n      }\n      \n      threadCount = 1;\n      i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableSearchThread searchThread = new StoppableSearchThread(cloudClient);\n        threads.add(searchThread);\n        searchThread.start();\n      }\n      \n      if (usually()) {\n        StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n        threads.add(commitThread);\n        commitThread.start();\n      }\n      \n      // TODO: we only do this sometimes so that we can sometimes compare against control,\n      // it's currently hard to know what requests failed when using ConcurrentSolrUpdateServer\n      boolean runFullThrottle = random().nextBoolean();\n      if (runFullThrottle) {\n        FullThrottleStoppableIndexingThread ftIndexThread = \n            new FullThrottleStoppableIndexingThread(controlClient, cloudClient, clients, \"ft1\", true, this.clientSoTimeout);\n        threads.add(ftIndexThread);\n        ftIndexThread.start();\n      }\n      \n      chaosMonkey.startTheMonkey(true, 10000);\n      try {\n        long runLength;\n        if (RUN_LENGTH != -1) {\n          runLength = RUN_LENGTH;\n        } else {\n          int[] runTimes;\n          if (TEST_NIGHTLY) {\n            runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n                30000, 45000, 90000, 120000};\n          } else {\n            runTimes = new int[] {5000, 7000, 15000};\n          }\n          runLength = runTimes[random().nextInt(runTimes.length - 1)];\n        }\n        ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, zkStateReader);\n      } finally {\n        chaosMonkey.stopTheMonkey();\n      }\n\n      // ideally this should go into chaosMonkey\n      restartZk(1000 * (5 + random().nextInt(4)));\n\n      for (StoppableThread indexThread : threads) {\n        indexThread.safeStop();\n      }\n      \n      // start any downed jetties to be sure we still will end up with a leader per shard...\n      \n      // wait for stop...\n      for (StoppableThread indexThread : threads) {\n        indexThread.join();\n      }\n      \n      // try and wait for any replications and what not to finish...\n      \n      ChaosMonkey.wait(2000, DEFAULT_COLLECTION, zkStateReader);\n      \n      // wait until there are no recoveries...\n      waitForThingsToLevelOut(Integer.MAX_VALUE);//Math.round((runLength / 1000.0f / 3.0f)));\n      \n      // make sure we again have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 30000);\n      }\n      \n      commit();\n      \n      // TODO: assert we didnt kill everyone\n      \n      zkStateReader.updateLiveNodes();\n      assertTrue(zkStateReader.getClusterState().getLiveNodes().size() > 0);\n      \n      \n      // we expect full throttle fails, but cloud client should not easily fail\n      for (StoppableThread indexThread : threads) {\n        if (indexThread instanceof StoppableIndexingThread && !(indexThread instanceof FullThrottleStoppableIndexingThread)) {\n          int failCount = ((StoppableIndexingThread) indexThread).getFailCount();\n          assertFalse(\"There were too many update fails (\" + failCount + \" > \" + FAIL_TOLERANCE\n              + \") - we expect it can happen, but shouldn't easily\", failCount > FAIL_TOLERANCE);\n        }\n      }\n      \n      waitForReplicationFromReplicas(DEFAULT_COLLECTION, zkStateReader, new TimeOut(30, TimeUnit.SECONDS));\n//      waitForAllWarmingSearchers();\n      \n      Set<String> addFails = getAddFails(indexTreads);\n      Set<String> deleteFails = getDeleteFails(indexTreads);\n      // full throttle thread can\n      // have request fails\n      checkShardConsistency(!runFullThrottle, true, addFails, deleteFails);      \n      \n      long ctrlDocs = controlClient.query(new SolrQuery(\"*:*\")).getResults()\n      .getNumFound(); \n      \n      // ensure we have added more than 0 docs\n      long cloudClientDocs = cloudClient.query(new SolrQuery(\"*:*\"))\n          .getResults().getNumFound();\n      \n      assertTrue(\"Found \" + ctrlDocs + \" control docs\", cloudClientDocs > 0);\n      \n      if (VERBOSE) System.out.println(\"control docs:\"\n          + controlClient.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound() + \"\\n\\n\");\n      \n      // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n      // sometimes we restart zookeeper as well\n      if (random().nextBoolean()) {\n        restartZk(1000 * (5 + random().nextInt(4)));\n      }\n\n      try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        // We don't really know how many live nodes we have at this point, so \"maxShardsPerNode\" needs to be > 1\n        createCollection(null, \"testcollection\",\n              1, 1, 10, client, null, \"conf1\"); \n      }\n      List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n      numShardsNumReplicas.add(1);\n      numShardsNumReplicas.add(1 + getPullReplicaCount());\n      checkForCollection(\"testcollection\", numShardsNumReplicas, null);\n      \n      testSuccessful = true;\n    } finally {\n      if (!testSuccessful) {\n        logReplicaTypesReplicationInfo(DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n        printLayout();\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"73a4df49bbf08e66754aaad0861f9627c0276cc2","date":1496792409,"type":3,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    cloudClient.setSoTimeout(clientSoTimeout);\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    \n    boolean testSuccessful = false;\n    try {\n      handle.clear();\n      handle.put(\"timestamp\", SKIPVAL);\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      // make sure we have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n      }      // make sure we again have leaders for each shard\n      \n      waitForRecoveriesToFinish(false);\n      \n      // we cannot do delete by query\n      // as it's not supported for recovery\n      del(\"*:*\");\n      \n      List<StoppableThread> threads = new ArrayList<>();\n      List<StoppableIndexingThread> indexTreads = new ArrayList<>();\n      int threadCount = TEST_NIGHTLY ? 3 : 1;\n      int i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true);\n        threads.add(indexThread);\n        indexTreads.add(indexThread);\n        indexThread.start();\n      }\n      \n      threadCount = 1;\n      i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableSearchThread searchThread = new StoppableSearchThread(cloudClient);\n        threads.add(searchThread);\n        searchThread.start();\n      }\n      \n      if (usually()) {\n        StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n        threads.add(commitThread);\n        commitThread.start();\n      }\n      \n      // TODO: we only do this sometimes so that we can sometimes compare against control,\n      // it's currently hard to know what requests failed when using ConcurrentSolrUpdateServer\n      boolean runFullThrottle = random().nextBoolean();\n      if (runFullThrottle) {\n        FullThrottleStoppableIndexingThread ftIndexThread = \n            new FullThrottleStoppableIndexingThread(controlClient, cloudClient, clients, \"ft1\", true, this.clientSoTimeout);\n        threads.add(ftIndexThread);\n        ftIndexThread.start();\n      }\n      \n      chaosMonkey.startTheMonkey(true, 10000);\n      try {\n        long runLength;\n        if (RUN_LENGTH != -1) {\n          runLength = RUN_LENGTH;\n        } else {\n          int[] runTimes;\n          if (TEST_NIGHTLY) {\n            runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n                30000, 45000, 90000, 120000};\n          } else {\n            runTimes = new int[] {5000, 7000, 15000};\n          }\n          runLength = runTimes[random().nextInt(runTimes.length - 1)];\n        }\n        ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, zkStateReader);\n      } finally {\n        chaosMonkey.stopTheMonkey();\n      }\n\n      // ideally this should go into chaosMonkey\n      restartZk(1000 * (5 + random().nextInt(4)));\n\n      for (StoppableThread indexThread : threads) {\n        indexThread.safeStop();\n      }\n      \n      // start any downed jetties to be sure we still will end up with a leader per shard...\n      \n      // wait for stop...\n      for (StoppableThread indexThread : threads) {\n        indexThread.join();\n      }\n      \n      // try and wait for any replications and what not to finish...\n      \n      ChaosMonkey.wait(2000, DEFAULT_COLLECTION, zkStateReader);\n      \n      // wait until there are no recoveries...\n      waitForThingsToLevelOut(Integer.MAX_VALUE);//Math.round((runLength / 1000.0f / 3.0f)));\n      \n      // make sure we again have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 30000);\n      }\n      \n      commit();\n      \n      // TODO: assert we didnt kill everyone\n      \n      zkStateReader.updateLiveNodes();\n      assertTrue(zkStateReader.getClusterState().getLiveNodes().size() > 0);\n      \n      \n      // we expect full throttle fails, but cloud client should not easily fail\n      for (StoppableThread indexThread : threads) {\n        if (indexThread instanceof StoppableIndexingThread && !(indexThread instanceof FullThrottleStoppableIndexingThread)) {\n          int failCount = ((StoppableIndexingThread) indexThread).getFailCount();\n          assertFalse(\"There were too many update fails (\" + failCount + \" > \" + FAIL_TOLERANCE\n              + \") - we expect it can happen, but shouldn't easily\", failCount > FAIL_TOLERANCE);\n        }\n      }\n      \n      waitForReplicationFromReplicas(DEFAULT_COLLECTION, zkStateReader, new TimeOut(30, TimeUnit.SECONDS));\n//      waitForAllWarmingSearchers();\n      \n      Set<String> addFails = getAddFails(indexTreads);\n      Set<String> deleteFails = getDeleteFails(indexTreads);\n      // full throttle thread can\n      // have request fails\n      checkShardConsistency(!runFullThrottle, true, addFails, deleteFails);      \n      \n      long ctrlDocs = controlClient.query(new SolrQuery(\"*:*\")).getResults()\n      .getNumFound(); \n      \n      // ensure we have added more than 0 docs\n      long cloudClientDocs = cloudClient.query(new SolrQuery(\"*:*\"))\n          .getResults().getNumFound();\n      \n      assertTrue(\"Found \" + ctrlDocs + \" control docs\", cloudClientDocs > 0);\n      \n      log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n      \n      if (VERBOSE) System.out.println(\"control docs:\"\n          + controlClient.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound() + \"\\n\\n\");\n      \n      // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n      // sometimes we restart zookeeper as well\n      if (random().nextBoolean()) {\n        restartZk(1000 * (5 + random().nextInt(4)));\n      }\n\n      try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        // We don't really know how many live nodes we have at this point, so \"maxShardsPerNode\" needs to be > 1\n        createCollection(null, \"testcollection\",\n              1, 1, 10, client, null, \"conf1\"); \n      }\n      List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n      numShardsNumReplicas.add(1);\n      numShardsNumReplicas.add(1 + getPullReplicaCount());\n      checkForCollection(\"testcollection\", numShardsNumReplicas, null);\n      \n      testSuccessful = true;\n    } finally {\n      if (!testSuccessful) {\n        logReplicaTypesReplicationInfo(DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n        printLayout();\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    cloudClient.setSoTimeout(clientSoTimeout);\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    \n    boolean testSuccessful = false;\n    try {\n      handle.clear();\n      handle.put(\"timestamp\", SKIPVAL);\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      // make sure we have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n      }      // make sure we again have leaders for each shard\n      \n      waitForRecoveriesToFinish(false);\n      \n      // we cannot do delete by query\n      // as it's not supported for recovery\n      del(\"*:*\");\n      \n      List<StoppableThread> threads = new ArrayList<>();\n      List<StoppableIndexingThread> indexTreads = new ArrayList<>();\n      int threadCount = TEST_NIGHTLY ? 3 : 1;\n      int i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true);\n        threads.add(indexThread);\n        indexTreads.add(indexThread);\n        indexThread.start();\n      }\n      \n      threadCount = 1;\n      i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableSearchThread searchThread = new StoppableSearchThread(cloudClient);\n        threads.add(searchThread);\n        searchThread.start();\n      }\n      \n      if (usually()) {\n        StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n        threads.add(commitThread);\n        commitThread.start();\n      }\n      \n      // TODO: we only do this sometimes so that we can sometimes compare against control,\n      // it's currently hard to know what requests failed when using ConcurrentSolrUpdateServer\n      boolean runFullThrottle = random().nextBoolean();\n      if (runFullThrottle) {\n        FullThrottleStoppableIndexingThread ftIndexThread = \n            new FullThrottleStoppableIndexingThread(controlClient, cloudClient, clients, \"ft1\", true, this.clientSoTimeout);\n        threads.add(ftIndexThread);\n        ftIndexThread.start();\n      }\n      \n      chaosMonkey.startTheMonkey(true, 10000);\n      try {\n        long runLength;\n        if (RUN_LENGTH != -1) {\n          runLength = RUN_LENGTH;\n        } else {\n          int[] runTimes;\n          if (TEST_NIGHTLY) {\n            runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n                30000, 45000, 90000, 120000};\n          } else {\n            runTimes = new int[] {5000, 7000, 15000};\n          }\n          runLength = runTimes[random().nextInt(runTimes.length - 1)];\n        }\n        ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, zkStateReader);\n      } finally {\n        chaosMonkey.stopTheMonkey();\n      }\n\n      // ideally this should go into chaosMonkey\n      restartZk(1000 * (5 + random().nextInt(4)));\n\n      for (StoppableThread indexThread : threads) {\n        indexThread.safeStop();\n      }\n      \n      // start any downed jetties to be sure we still will end up with a leader per shard...\n      \n      // wait for stop...\n      for (StoppableThread indexThread : threads) {\n        indexThread.join();\n      }\n      \n      // try and wait for any replications and what not to finish...\n      \n      ChaosMonkey.wait(2000, DEFAULT_COLLECTION, zkStateReader);\n      \n      // wait until there are no recoveries...\n      waitForThingsToLevelOut(Integer.MAX_VALUE);//Math.round((runLength / 1000.0f / 3.0f)));\n      \n      // make sure we again have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 30000);\n      }\n      \n      commit();\n      \n      // TODO: assert we didnt kill everyone\n      \n      zkStateReader.updateLiveNodes();\n      assertTrue(zkStateReader.getClusterState().getLiveNodes().size() > 0);\n      \n      \n      // we expect full throttle fails, but cloud client should not easily fail\n      for (StoppableThread indexThread : threads) {\n        if (indexThread instanceof StoppableIndexingThread && !(indexThread instanceof FullThrottleStoppableIndexingThread)) {\n          int failCount = ((StoppableIndexingThread) indexThread).getFailCount();\n          assertFalse(\"There were too many update fails (\" + failCount + \" > \" + FAIL_TOLERANCE\n              + \") - we expect it can happen, but shouldn't easily\", failCount > FAIL_TOLERANCE);\n        }\n      }\n      \n      waitForReplicationFromReplicas(DEFAULT_COLLECTION, zkStateReader, new TimeOut(30, TimeUnit.SECONDS));\n//      waitForAllWarmingSearchers();\n      \n      Set<String> addFails = getAddFails(indexTreads);\n      Set<String> deleteFails = getDeleteFails(indexTreads);\n      // full throttle thread can\n      // have request fails\n      checkShardConsistency(!runFullThrottle, true, addFails, deleteFails);      \n      \n      long ctrlDocs = controlClient.query(new SolrQuery(\"*:*\")).getResults()\n      .getNumFound(); \n      \n      // ensure we have added more than 0 docs\n      long cloudClientDocs = cloudClient.query(new SolrQuery(\"*:*\"))\n          .getResults().getNumFound();\n      \n      assertTrue(\"Found \" + ctrlDocs + \" control docs\", cloudClientDocs > 0);\n      \n      if (VERBOSE) System.out.println(\"control docs:\"\n          + controlClient.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound() + \"\\n\\n\");\n      \n      // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n      // sometimes we restart zookeeper as well\n      if (random().nextBoolean()) {\n        restartZk(1000 * (5 + random().nextInt(4)));\n      }\n\n      try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        // We don't really know how many live nodes we have at this point, so \"maxShardsPerNode\" needs to be > 1\n        createCollection(null, \"testcollection\",\n              1, 1, 10, client, null, \"conf1\"); \n      }\n      List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n      numShardsNumReplicas.add(1);\n      numShardsNumReplicas.add(1 + getPullReplicaCount());\n      checkForCollection(\"testcollection\", numShardsNumReplicas, null);\n      \n      testSuccessful = true;\n    } finally {\n      if (!testSuccessful) {\n        logReplicaTypesReplicationInfo(DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n        printLayout();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f344bb33ca91f48e99c061980115b46fa84fc8f5","date":1496903283,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    cloudClient.setSoTimeout(clientSoTimeout);\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    \n    boolean testSuccessful = false;\n    try {\n      handle.clear();\n      handle.put(\"timestamp\", SKIPVAL);\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      // make sure we have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n      }      // make sure we again have leaders for each shard\n      \n      waitForRecoveriesToFinish(false);\n      \n      // we cannot do delete by query\n      // as it's not supported for recovery\n      del(\"*:*\");\n      \n      List<StoppableThread> threads = new ArrayList<>();\n      List<StoppableIndexingThread> indexTreads = new ArrayList<>();\n      int threadCount = TEST_NIGHTLY ? 3 : 1;\n      int i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true);\n        threads.add(indexThread);\n        indexTreads.add(indexThread);\n        indexThread.start();\n      }\n      \n      threadCount = 1;\n      i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableSearchThread searchThread = new StoppableSearchThread(cloudClient);\n        threads.add(searchThread);\n        searchThread.start();\n      }\n      \n      if (usually()) {\n        StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n        threads.add(commitThread);\n        commitThread.start();\n      }\n      \n      // TODO: we only do this sometimes so that we can sometimes compare against control,\n      // it's currently hard to know what requests failed when using ConcurrentSolrUpdateServer\n      boolean runFullThrottle = random().nextBoolean();\n      if (runFullThrottle) {\n        FullThrottleStoppableIndexingThread ftIndexThread = \n            new FullThrottleStoppableIndexingThread(controlClient, cloudClient, clients, \"ft1\", true, this.clientSoTimeout);\n        threads.add(ftIndexThread);\n        ftIndexThread.start();\n      }\n      \n      chaosMonkey.startTheMonkey(true, 10000);\n      try {\n        long runLength;\n        if (RUN_LENGTH != -1) {\n          runLength = RUN_LENGTH;\n        } else {\n          int[] runTimes;\n          if (TEST_NIGHTLY) {\n            runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n                30000, 45000, 90000, 120000};\n          } else {\n            runTimes = new int[] {5000, 7000, 15000};\n          }\n          runLength = runTimes[random().nextInt(runTimes.length - 1)];\n        }\n        ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, zkStateReader);\n      } finally {\n        chaosMonkey.stopTheMonkey();\n      }\n\n      // ideally this should go into chaosMonkey\n      restartZk(1000 * (5 + random().nextInt(4)));\n\n      for (StoppableThread indexThread : threads) {\n        indexThread.safeStop();\n      }\n      \n      // start any downed jetties to be sure we still will end up with a leader per shard...\n      \n      // wait for stop...\n      for (StoppableThread indexThread : threads) {\n        indexThread.join();\n      }\n      \n      // try and wait for any replications and what not to finish...\n      \n      ChaosMonkey.wait(2000, DEFAULT_COLLECTION, zkStateReader);\n      \n      // wait until there are no recoveries...\n      waitForThingsToLevelOut(Integer.MAX_VALUE);//Math.round((runLength / 1000.0f / 3.0f)));\n      \n      // make sure we again have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 30000);\n      }\n      \n      commit();\n      \n      // TODO: assert we didnt kill everyone\n      \n      zkStateReader.updateLiveNodes();\n      assertTrue(zkStateReader.getClusterState().getLiveNodes().size() > 0);\n      \n      \n      // we expect full throttle fails, but cloud client should not easily fail\n      for (StoppableThread indexThread : threads) {\n        if (indexThread instanceof StoppableIndexingThread && !(indexThread instanceof FullThrottleStoppableIndexingThread)) {\n          int failCount = ((StoppableIndexingThread) indexThread).getFailCount();\n          assertFalse(\"There were too many update fails (\" + failCount + \" > \" + FAIL_TOLERANCE\n              + \") - we expect it can happen, but shouldn't easily\", failCount > FAIL_TOLERANCE);\n        }\n      }\n      \n      waitForReplicationFromReplicas(DEFAULT_COLLECTION, zkStateReader, new TimeOut(30, TimeUnit.SECONDS));\n//      waitForAllWarmingSearchers();\n      \n      Set<String> addFails = getAddFails(indexTreads);\n      Set<String> deleteFails = getDeleteFails(indexTreads);\n      // full throttle thread can\n      // have request fails\n      checkShardConsistency(!runFullThrottle, true, addFails, deleteFails);      \n      \n      long ctrlDocs = controlClient.query(new SolrQuery(\"*:*\")).getResults()\n      .getNumFound(); \n      \n      // ensure we have added more than 0 docs\n      long cloudClientDocs = cloudClient.query(new SolrQuery(\"*:*\"))\n          .getResults().getNumFound();\n      \n      assertTrue(\"Found \" + ctrlDocs + \" control docs\", cloudClientDocs > 0);\n      \n      log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n      \n      if (VERBOSE) System.out.println(\"control docs:\"\n          + controlClient.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound() + \"\\n\\n\");\n      \n      // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n      // sometimes we restart zookeeper as well\n      if (random().nextBoolean()) {\n        restartZk(1000 * (5 + random().nextInt(4)));\n      }\n\n      try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        // We don't really know how many live nodes we have at this point, so \"maxShardsPerNode\" needs to be > 1\n        createCollection(null, \"testcollection\",\n              1, 1, 10, client, null, \"conf1\"); \n      }\n      List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n      numShardsNumReplicas.add(1);\n      numShardsNumReplicas.add(1 + getPullReplicaCount());\n      checkForCollection(\"testcollection\", numShardsNumReplicas, null);\n      \n      testSuccessful = true;\n    } finally {\n      if (!testSuccessful) {\n        logReplicaTypesReplicationInfo(DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n        printLayout();\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    cloudClient.setSoTimeout(clientSoTimeout);\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    \n    boolean testSuccessful = false;\n    try {\n      handle.clear();\n      handle.put(\"timestamp\", SKIPVAL);\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      // make sure we have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n      }      // make sure we again have leaders for each shard\n      \n      waitForRecoveriesToFinish(false);\n      \n      // we cannot do delete by query\n      // as it's not supported for recovery\n      del(\"*:*\");\n      \n      List<StoppableThread> threads = new ArrayList<>();\n      List<StoppableIndexingThread> indexTreads = new ArrayList<>();\n      int threadCount = TEST_NIGHTLY ? 3 : 1;\n      int i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true);\n        threads.add(indexThread);\n        indexTreads.add(indexThread);\n        indexThread.start();\n      }\n      \n      threadCount = 1;\n      i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableSearchThread searchThread = new StoppableSearchThread(cloudClient);\n        threads.add(searchThread);\n        searchThread.start();\n      }\n      \n      if (usually()) {\n        StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n        threads.add(commitThread);\n        commitThread.start();\n      }\n      \n      // TODO: we only do this sometimes so that we can sometimes compare against control,\n      // it's currently hard to know what requests failed when using ConcurrentSolrUpdateServer\n      boolean runFullThrottle = random().nextBoolean();\n      if (runFullThrottle) {\n        FullThrottleStoppableIndexingThread ftIndexThread = \n            new FullThrottleStoppableIndexingThread(controlClient, cloudClient, clients, \"ft1\", true, this.clientSoTimeout);\n        threads.add(ftIndexThread);\n        ftIndexThread.start();\n      }\n      \n      chaosMonkey.startTheMonkey(true, 10000);\n      try {\n        long runLength;\n        if (RUN_LENGTH != -1) {\n          runLength = RUN_LENGTH;\n        } else {\n          int[] runTimes;\n          if (TEST_NIGHTLY) {\n            runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n                30000, 45000, 90000, 120000};\n          } else {\n            runTimes = new int[] {5000, 7000, 15000};\n          }\n          runLength = runTimes[random().nextInt(runTimes.length - 1)];\n        }\n        ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, zkStateReader);\n      } finally {\n        chaosMonkey.stopTheMonkey();\n      }\n\n      // ideally this should go into chaosMonkey\n      restartZk(1000 * (5 + random().nextInt(4)));\n\n      for (StoppableThread indexThread : threads) {\n        indexThread.safeStop();\n      }\n      \n      // start any downed jetties to be sure we still will end up with a leader per shard...\n      \n      // wait for stop...\n      for (StoppableThread indexThread : threads) {\n        indexThread.join();\n      }\n      \n      // try and wait for any replications and what not to finish...\n      \n      ChaosMonkey.wait(2000, DEFAULT_COLLECTION, zkStateReader);\n      \n      // wait until there are no recoveries...\n      waitForThingsToLevelOut(Integer.MAX_VALUE);//Math.round((runLength / 1000.0f / 3.0f)));\n      \n      // make sure we again have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 30000);\n      }\n      \n      commit();\n      \n      // TODO: assert we didnt kill everyone\n      \n      zkStateReader.updateLiveNodes();\n      assertTrue(zkStateReader.getClusterState().getLiveNodes().size() > 0);\n      \n      \n      // we expect full throttle fails, but cloud client should not easily fail\n      for (StoppableThread indexThread : threads) {\n        if (indexThread instanceof StoppableIndexingThread && !(indexThread instanceof FullThrottleStoppableIndexingThread)) {\n          int failCount = ((StoppableIndexingThread) indexThread).getFailCount();\n          assertFalse(\"There were too many update fails (\" + failCount + \" > \" + FAIL_TOLERANCE\n              + \") - we expect it can happen, but shouldn't easily\", failCount > FAIL_TOLERANCE);\n        }\n      }\n      \n      waitForReplicationFromReplicas(DEFAULT_COLLECTION, zkStateReader, new TimeOut(30, TimeUnit.SECONDS));\n//      waitForAllWarmingSearchers();\n      \n      Set<String> addFails = getAddFails(indexTreads);\n      Set<String> deleteFails = getDeleteFails(indexTreads);\n      // full throttle thread can\n      // have request fails\n      checkShardConsistency(!runFullThrottle, true, addFails, deleteFails);      \n      \n      long ctrlDocs = controlClient.query(new SolrQuery(\"*:*\")).getResults()\n      .getNumFound(); \n      \n      // ensure we have added more than 0 docs\n      long cloudClientDocs = cloudClient.query(new SolrQuery(\"*:*\"))\n          .getResults().getNumFound();\n      \n      assertTrue(\"Found \" + ctrlDocs + \" control docs\", cloudClientDocs > 0);\n      \n      if (VERBOSE) System.out.println(\"control docs:\"\n          + controlClient.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound() + \"\\n\\n\");\n      \n      // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n      // sometimes we restart zookeeper as well\n      if (random().nextBoolean()) {\n        restartZk(1000 * (5 + random().nextInt(4)));\n      }\n\n      try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        // We don't really know how many live nodes we have at this point, so \"maxShardsPerNode\" needs to be > 1\n        createCollection(null, \"testcollection\",\n              1, 1, 10, client, null, \"conf1\"); \n      }\n      List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n      numShardsNumReplicas.add(1);\n      numShardsNumReplicas.add(1 + getPullReplicaCount());\n      checkForCollection(\"testcollection\", numShardsNumReplicas, null);\n      \n      testSuccessful = true;\n    } finally {\n      if (!testSuccessful) {\n        logReplicaTypesReplicationInfo(DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n        printLayout();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9","date":1498028748,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    cloudClient.setSoTimeout(clientSoTimeout);\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    \n    boolean testSuccessful = false;\n    try {\n      handle.clear();\n      handle.put(\"timestamp\", SKIPVAL);\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      // make sure we have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n      }      // make sure we again have leaders for each shard\n      \n      waitForRecoveriesToFinish(false);\n      \n      // we cannot do delete by query\n      // as it's not supported for recovery\n      del(\"*:*\");\n      \n      List<StoppableThread> threads = new ArrayList<>();\n      List<StoppableIndexingThread> indexTreads = new ArrayList<>();\n      int threadCount = TEST_NIGHTLY ? 3 : 1;\n      int i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true);\n        threads.add(indexThread);\n        indexTreads.add(indexThread);\n        indexThread.start();\n      }\n      \n      threadCount = 1;\n      i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableSearchThread searchThread = new StoppableSearchThread(cloudClient);\n        threads.add(searchThread);\n        searchThread.start();\n      }\n      \n      if (usually()) {\n        StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n        threads.add(commitThread);\n        commitThread.start();\n      }\n      \n      // TODO: we only do this sometimes so that we can sometimes compare against control,\n      // it's currently hard to know what requests failed when using ConcurrentSolrUpdateServer\n      boolean runFullThrottle = random().nextBoolean();\n      if (runFullThrottle) {\n        FullThrottleStoppableIndexingThread ftIndexThread = \n            new FullThrottleStoppableIndexingThread(controlClient, cloudClient, clients, \"ft1\", true, this.clientSoTimeout);\n        threads.add(ftIndexThread);\n        ftIndexThread.start();\n      }\n      \n      chaosMonkey.startTheMonkey(true, 10000);\n      try {\n        long runLength;\n        if (RUN_LENGTH != -1) {\n          runLength = RUN_LENGTH;\n        } else {\n          int[] runTimes;\n          if (TEST_NIGHTLY) {\n            runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n                30000, 45000, 90000, 120000};\n          } else {\n            runTimes = new int[] {5000, 7000, 15000};\n          }\n          runLength = runTimes[random().nextInt(runTimes.length - 1)];\n        }\n        ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, zkStateReader);\n      } finally {\n        chaosMonkey.stopTheMonkey();\n      }\n\n      // ideally this should go into chaosMonkey\n      restartZk(1000 * (5 + random().nextInt(4)));\n\n      for (StoppableThread indexThread : threads) {\n        indexThread.safeStop();\n      }\n      \n      // start any downed jetties to be sure we still will end up with a leader per shard...\n      \n      // wait for stop...\n      for (StoppableThread indexThread : threads) {\n        indexThread.join();\n      }\n      \n      // try and wait for any replications and what not to finish...\n      \n      ChaosMonkey.wait(2000, DEFAULT_COLLECTION, zkStateReader);\n      \n      // wait until there are no recoveries...\n      waitForThingsToLevelOut(Integer.MAX_VALUE);//Math.round((runLength / 1000.0f / 3.0f)));\n      \n      // make sure we again have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 30000);\n      }\n      \n      commit();\n      \n      // TODO: assert we didnt kill everyone\n      \n      zkStateReader.updateLiveNodes();\n      assertTrue(zkStateReader.getClusterState().getLiveNodes().size() > 0);\n      \n      \n      // we expect full throttle fails, but cloud client should not easily fail\n      for (StoppableThread indexThread : threads) {\n        if (indexThread instanceof StoppableIndexingThread && !(indexThread instanceof FullThrottleStoppableIndexingThread)) {\n          int failCount = ((StoppableIndexingThread) indexThread).getFailCount();\n          assertFalse(\"There were too many update fails (\" + failCount + \" > \" + FAIL_TOLERANCE\n              + \") - we expect it can happen, but shouldn't easily\", failCount > FAIL_TOLERANCE);\n        }\n      }\n      \n      waitForReplicationFromReplicas(DEFAULT_COLLECTION, zkStateReader, new TimeOut(30, TimeUnit.SECONDS));\n//      waitForAllWarmingSearchers();\n      \n      Set<String> addFails = getAddFails(indexTreads);\n      Set<String> deleteFails = getDeleteFails(indexTreads);\n      // full throttle thread can\n      // have request fails\n      checkShardConsistency(!runFullThrottle, true, addFails, deleteFails);      \n      \n      long ctrlDocs = controlClient.query(new SolrQuery(\"*:*\")).getResults()\n      .getNumFound(); \n      \n      // ensure we have added more than 0 docs\n      long cloudClientDocs = cloudClient.query(new SolrQuery(\"*:*\"))\n          .getResults().getNumFound();\n      \n      assertTrue(\"Found \" + ctrlDocs + \" control docs\", cloudClientDocs > 0);\n      \n      log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n      \n      if (VERBOSE) System.out.println(\"control docs:\"\n          + controlClient.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound() + \"\\n\\n\");\n      \n      // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n      // sometimes we restart zookeeper as well\n      if (random().nextBoolean()) {\n        restartZk(1000 * (5 + random().nextInt(4)));\n      }\n\n      try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        // We don't really know how many live nodes we have at this point, so \"maxShardsPerNode\" needs to be > 1\n        createCollection(null, \"testcollection\",\n              1, 1, 10, client, null, \"conf1\"); \n      }\n      List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n      numShardsNumReplicas.add(1);\n      numShardsNumReplicas.add(1 + getPullReplicaCount());\n      checkForCollection(\"testcollection\", numShardsNumReplicas, null);\n      \n      testSuccessful = true;\n    } finally {\n      if (!testSuccessful) {\n        logReplicaTypesReplicationInfo(DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n        printLayout();\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    cloudClient.setSoTimeout(clientSoTimeout);\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    \n    boolean testSuccessful = false;\n    try {\n      handle.clear();\n      handle.put(\"timestamp\", SKIPVAL);\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      // make sure we have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n      }      // make sure we again have leaders for each shard\n      \n      waitForRecoveriesToFinish(false);\n      \n      // we cannot do delete by query\n      // as it's not supported for recovery\n      del(\"*:*\");\n      \n      List<StoppableThread> threads = new ArrayList<>();\n      List<StoppableIndexingThread> indexTreads = new ArrayList<>();\n      int threadCount = TEST_NIGHTLY ? 3 : 1;\n      int i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true);\n        threads.add(indexThread);\n        indexTreads.add(indexThread);\n        indexThread.start();\n      }\n      \n      threadCount = 1;\n      i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableSearchThread searchThread = new StoppableSearchThread(cloudClient);\n        threads.add(searchThread);\n        searchThread.start();\n      }\n      \n      if (usually()) {\n        StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n        threads.add(commitThread);\n        commitThread.start();\n      }\n      \n      // TODO: we only do this sometimes so that we can sometimes compare against control,\n      // it's currently hard to know what requests failed when using ConcurrentSolrUpdateServer\n      boolean runFullThrottle = random().nextBoolean();\n      if (runFullThrottle) {\n        FullThrottleStoppableIndexingThread ftIndexThread = \n            new FullThrottleStoppableIndexingThread(controlClient, cloudClient, clients, \"ft1\", true, this.clientSoTimeout);\n        threads.add(ftIndexThread);\n        ftIndexThread.start();\n      }\n      \n      chaosMonkey.startTheMonkey(true, 10000);\n      try {\n        long runLength;\n        if (RUN_LENGTH != -1) {\n          runLength = RUN_LENGTH;\n        } else {\n          int[] runTimes;\n          if (TEST_NIGHTLY) {\n            runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n                30000, 45000, 90000, 120000};\n          } else {\n            runTimes = new int[] {5000, 7000, 15000};\n          }\n          runLength = runTimes[random().nextInt(runTimes.length - 1)];\n        }\n        ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, zkStateReader);\n      } finally {\n        chaosMonkey.stopTheMonkey();\n      }\n\n      // ideally this should go into chaosMonkey\n      restartZk(1000 * (5 + random().nextInt(4)));\n\n      for (StoppableThread indexThread : threads) {\n        indexThread.safeStop();\n      }\n      \n      // start any downed jetties to be sure we still will end up with a leader per shard...\n      \n      // wait for stop...\n      for (StoppableThread indexThread : threads) {\n        indexThread.join();\n      }\n      \n      // try and wait for any replications and what not to finish...\n      \n      ChaosMonkey.wait(2000, DEFAULT_COLLECTION, zkStateReader);\n      \n      // wait until there are no recoveries...\n      waitForThingsToLevelOut(Integer.MAX_VALUE);//Math.round((runLength / 1000.0f / 3.0f)));\n      \n      // make sure we again have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 30000);\n      }\n      \n      commit();\n      \n      // TODO: assert we didnt kill everyone\n      \n      zkStateReader.updateLiveNodes();\n      assertTrue(zkStateReader.getClusterState().getLiveNodes().size() > 0);\n      \n      \n      // we expect full throttle fails, but cloud client should not easily fail\n      for (StoppableThread indexThread : threads) {\n        if (indexThread instanceof StoppableIndexingThread && !(indexThread instanceof FullThrottleStoppableIndexingThread)) {\n          int failCount = ((StoppableIndexingThread) indexThread).getFailCount();\n          assertFalse(\"There were too many update fails (\" + failCount + \" > \" + FAIL_TOLERANCE\n              + \") - we expect it can happen, but shouldn't easily\", failCount > FAIL_TOLERANCE);\n        }\n      }\n      \n      waitForReplicationFromReplicas(DEFAULT_COLLECTION, zkStateReader, new TimeOut(30, TimeUnit.SECONDS));\n//      waitForAllWarmingSearchers();\n      \n      Set<String> addFails = getAddFails(indexTreads);\n      Set<String> deleteFails = getDeleteFails(indexTreads);\n      // full throttle thread can\n      // have request fails\n      checkShardConsistency(!runFullThrottle, true, addFails, deleteFails);      \n      \n      long ctrlDocs = controlClient.query(new SolrQuery(\"*:*\")).getResults()\n      .getNumFound(); \n      \n      // ensure we have added more than 0 docs\n      long cloudClientDocs = cloudClient.query(new SolrQuery(\"*:*\"))\n          .getResults().getNumFound();\n      \n      assertTrue(\"Found \" + ctrlDocs + \" control docs\", cloudClientDocs > 0);\n      \n      if (VERBOSE) System.out.println(\"control docs:\"\n          + controlClient.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound() + \"\\n\\n\");\n      \n      // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n      // sometimes we restart zookeeper as well\n      if (random().nextBoolean()) {\n        restartZk(1000 * (5 + random().nextInt(4)));\n      }\n\n      try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        // We don't really know how many live nodes we have at this point, so \"maxShardsPerNode\" needs to be > 1\n        createCollection(null, \"testcollection\",\n              1, 1, 10, client, null, \"conf1\"); \n      }\n      List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n      numShardsNumReplicas.add(1);\n      numShardsNumReplicas.add(1 + getPullReplicaCount());\n      checkForCollection(\"testcollection\", numShardsNumReplicas, null);\n      \n      testSuccessful = true;\n    } finally {\n      if (!testSuccessful) {\n        logReplicaTypesReplicationInfo(DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n        printLayout();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    cloudClient.setSoTimeout(clientSoTimeout);\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    \n    boolean testSuccessful = false;\n    try {\n      handle.clear();\n      handle.put(\"timestamp\", SKIPVAL);\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      // make sure we have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n      }      // make sure we again have leaders for each shard\n      \n      waitForRecoveriesToFinish(false);\n      \n      // we cannot do delete by query\n      // as it's not supported for recovery\n      del(\"*:*\");\n      \n      List<StoppableThread> threads = new ArrayList<>();\n      List<StoppableIndexingThread> indexTreads = new ArrayList<>();\n      int threadCount = TEST_NIGHTLY ? 3 : 1;\n      int i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true);\n        threads.add(indexThread);\n        indexTreads.add(indexThread);\n        indexThread.start();\n      }\n      \n      threadCount = 1;\n      i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableSearchThread searchThread = new StoppableSearchThread(cloudClient);\n        threads.add(searchThread);\n        searchThread.start();\n      }\n      \n      if (usually()) {\n        StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n        threads.add(commitThread);\n        commitThread.start();\n      }\n      \n      // TODO: we only do this sometimes so that we can sometimes compare against control,\n      // it's currently hard to know what requests failed when using ConcurrentSolrUpdateServer\n      boolean runFullThrottle = random().nextBoolean();\n      if (runFullThrottle) {\n        FullThrottleStoppableIndexingThread ftIndexThread = \n            new FullThrottleStoppableIndexingThread(controlClient, cloudClient, clients, \"ft1\", true, this.clientSoTimeout);\n        threads.add(ftIndexThread);\n        ftIndexThread.start();\n      }\n      \n      chaosMonkey.startTheMonkey(true, 10000);\n      try {\n        long runLength;\n        if (RUN_LENGTH != -1) {\n          runLength = RUN_LENGTH;\n        } else {\n          int[] runTimes;\n          if (TEST_NIGHTLY) {\n            runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n                30000, 45000, 90000, 120000};\n          } else {\n            runTimes = new int[] {5000, 7000, 15000};\n          }\n          runLength = runTimes[random().nextInt(runTimes.length - 1)];\n        }\n        ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, zkStateReader);\n      } finally {\n        chaosMonkey.stopTheMonkey();\n      }\n\n      // ideally this should go into chaosMonkey\n      restartZk(1000 * (5 + random().nextInt(4)));\n\n      for (StoppableThread indexThread : threads) {\n        indexThread.safeStop();\n      }\n      \n      // start any downed jetties to be sure we still will end up with a leader per shard...\n      \n      // wait for stop...\n      for (StoppableThread indexThread : threads) {\n        indexThread.join();\n      }\n      \n      // try and wait for any replications and what not to finish...\n      \n      ChaosMonkey.wait(2000, DEFAULT_COLLECTION, zkStateReader);\n      \n      // wait until there are no recoveries...\n      waitForThingsToLevelOut(Integer.MAX_VALUE);//Math.round((runLength / 1000.0f / 3.0f)));\n      \n      // make sure we again have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 30000);\n      }\n      \n      commit();\n      \n      // TODO: assert we didnt kill everyone\n      \n      zkStateReader.updateLiveNodes();\n      assertTrue(zkStateReader.getClusterState().getLiveNodes().size() > 0);\n      \n      \n      // we expect full throttle fails, but cloud client should not easily fail\n      for (StoppableThread indexThread : threads) {\n        if (indexThread instanceof StoppableIndexingThread && !(indexThread instanceof FullThrottleStoppableIndexingThread)) {\n          int failCount = ((StoppableIndexingThread) indexThread).getFailCount();\n          assertFalse(\"There were too many update fails (\" + failCount + \" > \" + FAIL_TOLERANCE\n              + \") - we expect it can happen, but shouldn't easily\", failCount > FAIL_TOLERANCE);\n        }\n      }\n      \n      waitForReplicationFromReplicas(DEFAULT_COLLECTION, zkStateReader, new TimeOut(30, TimeUnit.SECONDS));\n//      waitForAllWarmingSearchers();\n      \n      Set<String> addFails = getAddFails(indexTreads);\n      Set<String> deleteFails = getDeleteFails(indexTreads);\n      // full throttle thread can\n      // have request fails\n      checkShardConsistency(!runFullThrottle, true, addFails, deleteFails);      \n      \n      long ctrlDocs = controlClient.query(new SolrQuery(\"*:*\")).getResults()\n      .getNumFound(); \n      \n      // ensure we have added more than 0 docs\n      long cloudClientDocs = cloudClient.query(new SolrQuery(\"*:*\"))\n          .getResults().getNumFound();\n      \n      assertTrue(\"Found \" + ctrlDocs + \" control docs\", cloudClientDocs > 0);\n      \n      log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n      \n      if (VERBOSE) System.out.println(\"control docs:\"\n          + controlClient.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound() + \"\\n\\n\");\n      \n      // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n      // sometimes we restart zookeeper as well\n      if (random().nextBoolean()) {\n        restartZk(1000 * (5 + random().nextInt(4)));\n      }\n\n      try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        // We don't really know how many live nodes we have at this point, so \"maxShardsPerNode\" needs to be > 1\n        createCollection(null, \"testcollection\",\n              1, 1, 10, client, null, \"conf1\"); \n      }\n      List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n      numShardsNumReplicas.add(1);\n      numShardsNumReplicas.add(1 + getPullReplicaCount());\n      checkForCollection(\"testcollection\", numShardsNumReplicas, null);\n      \n      testSuccessful = true;\n    } finally {\n      if (!testSuccessful) {\n        logReplicaTypesReplicationInfo(DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n        printLayout();\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    cloudClient.setSoTimeout(clientSoTimeout);\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    \n    boolean testSuccessful = false;\n    try {\n      handle.clear();\n      handle.put(\"timestamp\", SKIPVAL);\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      // make sure we have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n      }      // make sure we again have leaders for each shard\n      \n      waitForRecoveriesToFinish(false);\n      \n      // we cannot do delete by query\n      // as it's not supported for recovery\n      del(\"*:*\");\n      \n      List<StoppableThread> threads = new ArrayList<>();\n      List<StoppableIndexingThread> indexTreads = new ArrayList<>();\n      int threadCount = TEST_NIGHTLY ? 3 : 1;\n      int i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true);\n        threads.add(indexThread);\n        indexTreads.add(indexThread);\n        indexThread.start();\n      }\n      \n      threadCount = 1;\n      i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableSearchThread searchThread = new StoppableSearchThread(cloudClient);\n        threads.add(searchThread);\n        searchThread.start();\n      }\n      \n      if (usually()) {\n        StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n        threads.add(commitThread);\n        commitThread.start();\n      }\n      \n      // TODO: we only do this sometimes so that we can sometimes compare against control,\n      // it's currently hard to know what requests failed when using ConcurrentSolrUpdateServer\n      boolean runFullThrottle = random().nextBoolean();\n      if (runFullThrottle) {\n        FullThrottleStoppableIndexingThread ftIndexThread = \n            new FullThrottleStoppableIndexingThread(controlClient, cloudClient, clients, \"ft1\", true, this.clientSoTimeout);\n        threads.add(ftIndexThread);\n        ftIndexThread.start();\n      }\n      \n      chaosMonkey.startTheMonkey(true, 10000);\n      try {\n        long runLength;\n        if (RUN_LENGTH != -1) {\n          runLength = RUN_LENGTH;\n        } else {\n          int[] runTimes;\n          if (TEST_NIGHTLY) {\n            runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n                30000, 45000, 90000, 120000};\n          } else {\n            runTimes = new int[] {5000, 7000, 15000};\n          }\n          runLength = runTimes[random().nextInt(runTimes.length - 1)];\n        }\n        ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, zkStateReader);\n      } finally {\n        chaosMonkey.stopTheMonkey();\n      }\n\n      // ideally this should go into chaosMonkey\n      restartZk(1000 * (5 + random().nextInt(4)));\n\n      for (StoppableThread indexThread : threads) {\n        indexThread.safeStop();\n      }\n      \n      // start any downed jetties to be sure we still will end up with a leader per shard...\n      \n      // wait for stop...\n      for (StoppableThread indexThread : threads) {\n        indexThread.join();\n      }\n      \n      // try and wait for any replications and what not to finish...\n      \n      ChaosMonkey.wait(2000, DEFAULT_COLLECTION, zkStateReader);\n      \n      // wait until there are no recoveries...\n      waitForThingsToLevelOut(Integer.MAX_VALUE);//Math.round((runLength / 1000.0f / 3.0f)));\n      \n      // make sure we again have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 30000);\n      }\n      \n      commit();\n      \n      // TODO: assert we didnt kill everyone\n      \n      zkStateReader.updateLiveNodes();\n      assertTrue(zkStateReader.getClusterState().getLiveNodes().size() > 0);\n      \n      \n      // we expect full throttle fails, but cloud client should not easily fail\n      for (StoppableThread indexThread : threads) {\n        if (indexThread instanceof StoppableIndexingThread && !(indexThread instanceof FullThrottleStoppableIndexingThread)) {\n          int failCount = ((StoppableIndexingThread) indexThread).getFailCount();\n          assertFalse(\"There were too many update fails (\" + failCount + \" > \" + FAIL_TOLERANCE\n              + \") - we expect it can happen, but shouldn't easily\", failCount > FAIL_TOLERANCE);\n        }\n      }\n      \n      waitForReplicationFromReplicas(DEFAULT_COLLECTION, zkStateReader, new TimeOut(30, TimeUnit.SECONDS));\n//      waitForAllWarmingSearchers();\n      \n      Set<String> addFails = getAddFails(indexTreads);\n      Set<String> deleteFails = getDeleteFails(indexTreads);\n      // full throttle thread can\n      // have request fails\n      checkShardConsistency(!runFullThrottle, true, addFails, deleteFails);      \n      \n      long ctrlDocs = controlClient.query(new SolrQuery(\"*:*\")).getResults()\n      .getNumFound(); \n      \n      // ensure we have added more than 0 docs\n      long cloudClientDocs = cloudClient.query(new SolrQuery(\"*:*\"))\n          .getResults().getNumFound();\n      \n      assertTrue(\"Found \" + ctrlDocs + \" control docs\", cloudClientDocs > 0);\n      \n      if (VERBOSE) System.out.println(\"control docs:\"\n          + controlClient.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound() + \"\\n\\n\");\n      \n      // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n      // sometimes we restart zookeeper as well\n      if (random().nextBoolean()) {\n        restartZk(1000 * (5 + random().nextInt(4)));\n      }\n\n      try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        // We don't really know how many live nodes we have at this point, so \"maxShardsPerNode\" needs to be > 1\n        createCollection(null, \"testcollection\",\n              1, 1, 10, client, null, \"conf1\"); \n      }\n      List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n      numShardsNumReplicas.add(1);\n      numShardsNumReplicas.add(1 + getPullReplicaCount());\n      checkForCollection(\"testcollection\", numShardsNumReplicas, null);\n      \n      testSuccessful = true;\n    } finally {\n      if (!testSuccessful) {\n        logReplicaTypesReplicationInfo(DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n        printLayout();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"43d1e498704edd2bba13548a189eed4dfccff11b","date":1499143458,"type":3,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    // None of the operations used here are particularly costly, so this should work.\n    // Using this low timeout will also help us catch index stalling.\n    clientSoTimeout = 5000;\n    cloudClient = createCloudClient(DEFAULT_COLLECTION);\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    \n    boolean testSuccessful = false;\n    try {\n      handle.clear();\n      handle.put(\"timestamp\", SKIPVAL);\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      // make sure we have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n      }      // make sure we again have leaders for each shard\n      \n      waitForRecoveriesToFinish(false);\n      \n      // we cannot do delete by query\n      // as it's not supported for recovery\n      del(\"*:*\");\n      \n      List<StoppableThread> threads = new ArrayList<>();\n      List<StoppableIndexingThread> indexTreads = new ArrayList<>();\n      int threadCount = TEST_NIGHTLY ? 3 : 1;\n      int i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true);\n        threads.add(indexThread);\n        indexTreads.add(indexThread);\n        indexThread.start();\n      }\n      \n      threadCount = 1;\n      i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableSearchThread searchThread = new StoppableSearchThread(cloudClient);\n        threads.add(searchThread);\n        searchThread.start();\n      }\n      \n      if (usually()) {\n        StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n        threads.add(commitThread);\n        commitThread.start();\n      }\n      \n      // TODO: we only do this sometimes so that we can sometimes compare against control,\n      // it's currently hard to know what requests failed when using ConcurrentSolrUpdateServer\n      boolean runFullThrottle = random().nextBoolean();\n      if (runFullThrottle) {\n        FullThrottleStoppableIndexingThread ftIndexThread = \n            new FullThrottleStoppableIndexingThread(controlClient, cloudClient, clients, \"ft1\", true, this.clientSoTimeout);\n        threads.add(ftIndexThread);\n        ftIndexThread.start();\n      }\n      \n      chaosMonkey.startTheMonkey(true, 10000);\n      try {\n        long runLength;\n        if (RUN_LENGTH != -1) {\n          runLength = RUN_LENGTH;\n        } else {\n          int[] runTimes;\n          if (TEST_NIGHTLY) {\n            runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n                30000, 45000, 90000, 120000};\n          } else {\n            runTimes = new int[] {5000, 7000, 15000};\n          }\n          runLength = runTimes[random().nextInt(runTimes.length - 1)];\n        }\n        ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, zkStateReader);\n      } finally {\n        chaosMonkey.stopTheMonkey();\n      }\n\n      // ideally this should go into chaosMonkey\n      restartZk(1000 * (5 + random().nextInt(4)));\n\n      for (StoppableThread indexThread : threads) {\n        indexThread.safeStop();\n      }\n      \n      // start any downed jetties to be sure we still will end up with a leader per shard...\n      \n      // wait for stop...\n      for (StoppableThread indexThread : threads) {\n        indexThread.join();\n      }\n      \n      // try and wait for any replications and what not to finish...\n      \n      ChaosMonkey.wait(2000, DEFAULT_COLLECTION, zkStateReader);\n      \n      // wait until there are no recoveries...\n      waitForThingsToLevelOut(Integer.MAX_VALUE);//Math.round((runLength / 1000.0f / 3.0f)));\n      \n      // make sure we again have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 30000);\n      }\n      \n      commit();\n      \n      // TODO: assert we didnt kill everyone\n      \n      zkStateReader.updateLiveNodes();\n      assertTrue(zkStateReader.getClusterState().getLiveNodes().size() > 0);\n      \n      \n      // we expect full throttle fails, but cloud client should not easily fail\n      for (StoppableThread indexThread : threads) {\n        if (indexThread instanceof StoppableIndexingThread && !(indexThread instanceof FullThrottleStoppableIndexingThread)) {\n          int failCount = ((StoppableIndexingThread) indexThread).getFailCount();\n          assertFalse(\"There were too many update fails (\" + failCount + \" > \" + FAIL_TOLERANCE\n              + \") - we expect it can happen, but shouldn't easily\", failCount > FAIL_TOLERANCE);\n        }\n      }\n      \n      waitForReplicationFromReplicas(DEFAULT_COLLECTION, zkStateReader, new TimeOut(30, TimeUnit.SECONDS));\n//      waitForAllWarmingSearchers();\n      \n      Set<String> addFails = getAddFails(indexTreads);\n      Set<String> deleteFails = getDeleteFails(indexTreads);\n      // full throttle thread can\n      // have request fails\n      checkShardConsistency(!runFullThrottle, true, addFails, deleteFails);      \n      \n      long ctrlDocs = controlClient.query(new SolrQuery(\"*:*\")).getResults()\n      .getNumFound(); \n      \n      // ensure we have added more than 0 docs\n      long cloudClientDocs = cloudClient.query(new SolrQuery(\"*:*\"))\n          .getResults().getNumFound();\n      \n      assertTrue(\"Found \" + ctrlDocs + \" control docs\", cloudClientDocs > 0);\n      \n      log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n      \n      if (VERBOSE) System.out.println(\"control docs:\"\n          + controlClient.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound() + \"\\n\\n\");\n      \n      // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n      // sometimes we restart zookeeper as well\n      if (random().nextBoolean()) {\n        restartZk(1000 * (5 + random().nextInt(4)));\n      }\n\n      try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        // We don't really know how many live nodes we have at this point, so \"maxShardsPerNode\" needs to be > 1\n        createCollection(null, \"testcollection\",\n              1, 1, 10, client, null, \"conf1\"); \n      }\n      List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n      numShardsNumReplicas.add(1);\n      numShardsNumReplicas.add(1 + getPullReplicaCount());\n      checkForCollection(\"testcollection\", numShardsNumReplicas, null);\n      \n      testSuccessful = true;\n    } finally {\n      if (!testSuccessful) {\n        logReplicaTypesReplicationInfo(DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n        printLayout();\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    cloudClient.setSoTimeout(clientSoTimeout);\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    \n    boolean testSuccessful = false;\n    try {\n      handle.clear();\n      handle.put(\"timestamp\", SKIPVAL);\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      // make sure we have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n      }      // make sure we again have leaders for each shard\n      \n      waitForRecoveriesToFinish(false);\n      \n      // we cannot do delete by query\n      // as it's not supported for recovery\n      del(\"*:*\");\n      \n      List<StoppableThread> threads = new ArrayList<>();\n      List<StoppableIndexingThread> indexTreads = new ArrayList<>();\n      int threadCount = TEST_NIGHTLY ? 3 : 1;\n      int i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true);\n        threads.add(indexThread);\n        indexTreads.add(indexThread);\n        indexThread.start();\n      }\n      \n      threadCount = 1;\n      i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableSearchThread searchThread = new StoppableSearchThread(cloudClient);\n        threads.add(searchThread);\n        searchThread.start();\n      }\n      \n      if (usually()) {\n        StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n        threads.add(commitThread);\n        commitThread.start();\n      }\n      \n      // TODO: we only do this sometimes so that we can sometimes compare against control,\n      // it's currently hard to know what requests failed when using ConcurrentSolrUpdateServer\n      boolean runFullThrottle = random().nextBoolean();\n      if (runFullThrottle) {\n        FullThrottleStoppableIndexingThread ftIndexThread = \n            new FullThrottleStoppableIndexingThread(controlClient, cloudClient, clients, \"ft1\", true, this.clientSoTimeout);\n        threads.add(ftIndexThread);\n        ftIndexThread.start();\n      }\n      \n      chaosMonkey.startTheMonkey(true, 10000);\n      try {\n        long runLength;\n        if (RUN_LENGTH != -1) {\n          runLength = RUN_LENGTH;\n        } else {\n          int[] runTimes;\n          if (TEST_NIGHTLY) {\n            runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n                30000, 45000, 90000, 120000};\n          } else {\n            runTimes = new int[] {5000, 7000, 15000};\n          }\n          runLength = runTimes[random().nextInt(runTimes.length - 1)];\n        }\n        ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, zkStateReader);\n      } finally {\n        chaosMonkey.stopTheMonkey();\n      }\n\n      // ideally this should go into chaosMonkey\n      restartZk(1000 * (5 + random().nextInt(4)));\n\n      for (StoppableThread indexThread : threads) {\n        indexThread.safeStop();\n      }\n      \n      // start any downed jetties to be sure we still will end up with a leader per shard...\n      \n      // wait for stop...\n      for (StoppableThread indexThread : threads) {\n        indexThread.join();\n      }\n      \n      // try and wait for any replications and what not to finish...\n      \n      ChaosMonkey.wait(2000, DEFAULT_COLLECTION, zkStateReader);\n      \n      // wait until there are no recoveries...\n      waitForThingsToLevelOut(Integer.MAX_VALUE);//Math.round((runLength / 1000.0f / 3.0f)));\n      \n      // make sure we again have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 30000);\n      }\n      \n      commit();\n      \n      // TODO: assert we didnt kill everyone\n      \n      zkStateReader.updateLiveNodes();\n      assertTrue(zkStateReader.getClusterState().getLiveNodes().size() > 0);\n      \n      \n      // we expect full throttle fails, but cloud client should not easily fail\n      for (StoppableThread indexThread : threads) {\n        if (indexThread instanceof StoppableIndexingThread && !(indexThread instanceof FullThrottleStoppableIndexingThread)) {\n          int failCount = ((StoppableIndexingThread) indexThread).getFailCount();\n          assertFalse(\"There were too many update fails (\" + failCount + \" > \" + FAIL_TOLERANCE\n              + \") - we expect it can happen, but shouldn't easily\", failCount > FAIL_TOLERANCE);\n        }\n      }\n      \n      waitForReplicationFromReplicas(DEFAULT_COLLECTION, zkStateReader, new TimeOut(30, TimeUnit.SECONDS));\n//      waitForAllWarmingSearchers();\n      \n      Set<String> addFails = getAddFails(indexTreads);\n      Set<String> deleteFails = getDeleteFails(indexTreads);\n      // full throttle thread can\n      // have request fails\n      checkShardConsistency(!runFullThrottle, true, addFails, deleteFails);      \n      \n      long ctrlDocs = controlClient.query(new SolrQuery(\"*:*\")).getResults()\n      .getNumFound(); \n      \n      // ensure we have added more than 0 docs\n      long cloudClientDocs = cloudClient.query(new SolrQuery(\"*:*\"))\n          .getResults().getNumFound();\n      \n      assertTrue(\"Found \" + ctrlDocs + \" control docs\", cloudClientDocs > 0);\n      \n      log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n      \n      if (VERBOSE) System.out.println(\"control docs:\"\n          + controlClient.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound() + \"\\n\\n\");\n      \n      // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n      // sometimes we restart zookeeper as well\n      if (random().nextBoolean()) {\n        restartZk(1000 * (5 + random().nextInt(4)));\n      }\n\n      try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        // We don't really know how many live nodes we have at this point, so \"maxShardsPerNode\" needs to be > 1\n        createCollection(null, \"testcollection\",\n              1, 1, 10, client, null, \"conf1\"); \n      }\n      List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n      numShardsNumReplicas.add(1);\n      numShardsNumReplicas.add(1 + getPullReplicaCount());\n      checkForCollection(\"testcollection\", numShardsNumReplicas, null);\n      \n      testSuccessful = true;\n    } finally {\n      if (!testSuccessful) {\n        logReplicaTypesReplicationInfo(DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n        printLayout();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2ea161f828a3a7a6eb9410a431aecda6d7ab1065","date":1499213384,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    // None of the operations used here are particularly costly, so this should work.\n    // Using this low timeout will also help us catch index stalling.\n    clientSoTimeout = 5000;\n    cloudClient = createCloudClient(DEFAULT_COLLECTION);\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    \n    boolean testSuccessful = false;\n    try {\n      handle.clear();\n      handle.put(\"timestamp\", SKIPVAL);\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      // make sure we have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n      }      // make sure we again have leaders for each shard\n      \n      waitForRecoveriesToFinish(false);\n      \n      // we cannot do delete by query\n      // as it's not supported for recovery\n      del(\"*:*\");\n      \n      List<StoppableThread> threads = new ArrayList<>();\n      List<StoppableIndexingThread> indexTreads = new ArrayList<>();\n      int threadCount = TEST_NIGHTLY ? 3 : 1;\n      int i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true);\n        threads.add(indexThread);\n        indexTreads.add(indexThread);\n        indexThread.start();\n      }\n      \n      threadCount = 1;\n      i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableSearchThread searchThread = new StoppableSearchThread(cloudClient);\n        threads.add(searchThread);\n        searchThread.start();\n      }\n      \n      if (usually()) {\n        StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n        threads.add(commitThread);\n        commitThread.start();\n      }\n      \n      // TODO: we only do this sometimes so that we can sometimes compare against control,\n      // it's currently hard to know what requests failed when using ConcurrentSolrUpdateServer\n      boolean runFullThrottle = random().nextBoolean();\n      if (runFullThrottle) {\n        FullThrottleStoppableIndexingThread ftIndexThread = \n            new FullThrottleStoppableIndexingThread(controlClient, cloudClient, clients, \"ft1\", true, this.clientSoTimeout);\n        threads.add(ftIndexThread);\n        ftIndexThread.start();\n      }\n      \n      chaosMonkey.startTheMonkey(true, 10000);\n      try {\n        long runLength;\n        if (RUN_LENGTH != -1) {\n          runLength = RUN_LENGTH;\n        } else {\n          int[] runTimes;\n          if (TEST_NIGHTLY) {\n            runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n                30000, 45000, 90000, 120000};\n          } else {\n            runTimes = new int[] {5000, 7000, 15000};\n          }\n          runLength = runTimes[random().nextInt(runTimes.length - 1)];\n        }\n        ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, zkStateReader);\n      } finally {\n        chaosMonkey.stopTheMonkey();\n      }\n\n      // ideally this should go into chaosMonkey\n      restartZk(1000 * (5 + random().nextInt(4)));\n\n      for (StoppableThread indexThread : threads) {\n        indexThread.safeStop();\n      }\n      \n      // start any downed jetties to be sure we still will end up with a leader per shard...\n      \n      // wait for stop...\n      for (StoppableThread indexThread : threads) {\n        indexThread.join();\n      }\n      \n      // try and wait for any replications and what not to finish...\n      \n      ChaosMonkey.wait(2000, DEFAULT_COLLECTION, zkStateReader);\n      \n      // wait until there are no recoveries...\n      waitForThingsToLevelOut(Integer.MAX_VALUE);//Math.round((runLength / 1000.0f / 3.0f)));\n      \n      // make sure we again have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 30000);\n      }\n      \n      commit();\n      \n      // TODO: assert we didnt kill everyone\n      \n      zkStateReader.updateLiveNodes();\n      assertTrue(zkStateReader.getClusterState().getLiveNodes().size() > 0);\n      \n      \n      // we expect full throttle fails, but cloud client should not easily fail\n      for (StoppableThread indexThread : threads) {\n        if (indexThread instanceof StoppableIndexingThread && !(indexThread instanceof FullThrottleStoppableIndexingThread)) {\n          int failCount = ((StoppableIndexingThread) indexThread).getFailCount();\n          assertFalse(\"There were too many update fails (\" + failCount + \" > \" + FAIL_TOLERANCE\n              + \") - we expect it can happen, but shouldn't easily\", failCount > FAIL_TOLERANCE);\n        }\n      }\n      \n      waitForReplicationFromReplicas(DEFAULT_COLLECTION, zkStateReader, new TimeOut(30, TimeUnit.SECONDS));\n//      waitForAllWarmingSearchers();\n      \n      Set<String> addFails = getAddFails(indexTreads);\n      Set<String> deleteFails = getDeleteFails(indexTreads);\n      // full throttle thread can\n      // have request fails\n      checkShardConsistency(!runFullThrottle, true, addFails, deleteFails);      \n      \n      long ctrlDocs = controlClient.query(new SolrQuery(\"*:*\")).getResults()\n      .getNumFound(); \n      \n      // ensure we have added more than 0 docs\n      long cloudClientDocs = cloudClient.query(new SolrQuery(\"*:*\"))\n          .getResults().getNumFound();\n      \n      assertTrue(\"Found \" + ctrlDocs + \" control docs\", cloudClientDocs > 0);\n      \n      log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n      \n      if (VERBOSE) System.out.println(\"control docs:\"\n          + controlClient.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound() + \"\\n\\n\");\n      \n      // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n      // sometimes we restart zookeeper as well\n      if (random().nextBoolean()) {\n        restartZk(1000 * (5 + random().nextInt(4)));\n      }\n\n      try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        // We don't really know how many live nodes we have at this point, so \"maxShardsPerNode\" needs to be > 1\n        createCollection(null, \"testcollection\",\n              1, 1, 10, client, null, \"conf1\"); \n      }\n      List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n      numShardsNumReplicas.add(1);\n      numShardsNumReplicas.add(1 + getPullReplicaCount());\n      checkForCollection(\"testcollection\", numShardsNumReplicas, null);\n      \n      testSuccessful = true;\n    } finally {\n      if (!testSuccessful) {\n        logReplicaTypesReplicationInfo(DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n        printLayout();\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    cloudClient.setSoTimeout(clientSoTimeout);\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    \n    boolean testSuccessful = false;\n    try {\n      handle.clear();\n      handle.put(\"timestamp\", SKIPVAL);\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      // make sure we have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n      }      // make sure we again have leaders for each shard\n      \n      waitForRecoveriesToFinish(false);\n      \n      // we cannot do delete by query\n      // as it's not supported for recovery\n      del(\"*:*\");\n      \n      List<StoppableThread> threads = new ArrayList<>();\n      List<StoppableIndexingThread> indexTreads = new ArrayList<>();\n      int threadCount = TEST_NIGHTLY ? 3 : 1;\n      int i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true);\n        threads.add(indexThread);\n        indexTreads.add(indexThread);\n        indexThread.start();\n      }\n      \n      threadCount = 1;\n      i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableSearchThread searchThread = new StoppableSearchThread(cloudClient);\n        threads.add(searchThread);\n        searchThread.start();\n      }\n      \n      if (usually()) {\n        StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n        threads.add(commitThread);\n        commitThread.start();\n      }\n      \n      // TODO: we only do this sometimes so that we can sometimes compare against control,\n      // it's currently hard to know what requests failed when using ConcurrentSolrUpdateServer\n      boolean runFullThrottle = random().nextBoolean();\n      if (runFullThrottle) {\n        FullThrottleStoppableIndexingThread ftIndexThread = \n            new FullThrottleStoppableIndexingThread(controlClient, cloudClient, clients, \"ft1\", true, this.clientSoTimeout);\n        threads.add(ftIndexThread);\n        ftIndexThread.start();\n      }\n      \n      chaosMonkey.startTheMonkey(true, 10000);\n      try {\n        long runLength;\n        if (RUN_LENGTH != -1) {\n          runLength = RUN_LENGTH;\n        } else {\n          int[] runTimes;\n          if (TEST_NIGHTLY) {\n            runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n                30000, 45000, 90000, 120000};\n          } else {\n            runTimes = new int[] {5000, 7000, 15000};\n          }\n          runLength = runTimes[random().nextInt(runTimes.length - 1)];\n        }\n        ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, zkStateReader);\n      } finally {\n        chaosMonkey.stopTheMonkey();\n      }\n\n      // ideally this should go into chaosMonkey\n      restartZk(1000 * (5 + random().nextInt(4)));\n\n      for (StoppableThread indexThread : threads) {\n        indexThread.safeStop();\n      }\n      \n      // start any downed jetties to be sure we still will end up with a leader per shard...\n      \n      // wait for stop...\n      for (StoppableThread indexThread : threads) {\n        indexThread.join();\n      }\n      \n      // try and wait for any replications and what not to finish...\n      \n      ChaosMonkey.wait(2000, DEFAULT_COLLECTION, zkStateReader);\n      \n      // wait until there are no recoveries...\n      waitForThingsToLevelOut(Integer.MAX_VALUE);//Math.round((runLength / 1000.0f / 3.0f)));\n      \n      // make sure we again have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 30000);\n      }\n      \n      commit();\n      \n      // TODO: assert we didnt kill everyone\n      \n      zkStateReader.updateLiveNodes();\n      assertTrue(zkStateReader.getClusterState().getLiveNodes().size() > 0);\n      \n      \n      // we expect full throttle fails, but cloud client should not easily fail\n      for (StoppableThread indexThread : threads) {\n        if (indexThread instanceof StoppableIndexingThread && !(indexThread instanceof FullThrottleStoppableIndexingThread)) {\n          int failCount = ((StoppableIndexingThread) indexThread).getFailCount();\n          assertFalse(\"There were too many update fails (\" + failCount + \" > \" + FAIL_TOLERANCE\n              + \") - we expect it can happen, but shouldn't easily\", failCount > FAIL_TOLERANCE);\n        }\n      }\n      \n      waitForReplicationFromReplicas(DEFAULT_COLLECTION, zkStateReader, new TimeOut(30, TimeUnit.SECONDS));\n//      waitForAllWarmingSearchers();\n      \n      Set<String> addFails = getAddFails(indexTreads);\n      Set<String> deleteFails = getDeleteFails(indexTreads);\n      // full throttle thread can\n      // have request fails\n      checkShardConsistency(!runFullThrottle, true, addFails, deleteFails);      \n      \n      long ctrlDocs = controlClient.query(new SolrQuery(\"*:*\")).getResults()\n      .getNumFound(); \n      \n      // ensure we have added more than 0 docs\n      long cloudClientDocs = cloudClient.query(new SolrQuery(\"*:*\"))\n          .getResults().getNumFound();\n      \n      assertTrue(\"Found \" + ctrlDocs + \" control docs\", cloudClientDocs > 0);\n      \n      log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n      \n      if (VERBOSE) System.out.println(\"control docs:\"\n          + controlClient.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound() + \"\\n\\n\");\n      \n      // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n      // sometimes we restart zookeeper as well\n      if (random().nextBoolean()) {\n        restartZk(1000 * (5 + random().nextInt(4)));\n      }\n\n      try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        // We don't really know how many live nodes we have at this point, so \"maxShardsPerNode\" needs to be > 1\n        createCollection(null, \"testcollection\",\n              1, 1, 10, client, null, \"conf1\"); \n      }\n      List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n      numShardsNumReplicas.add(1);\n      numShardsNumReplicas.add(1 + getPullReplicaCount());\n      checkForCollection(\"testcollection\", numShardsNumReplicas, null);\n      \n      testSuccessful = true;\n    } finally {\n      if (!testSuccessful) {\n        logReplicaTypesReplicationInfo(DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n        printLayout();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d2f514ff99d806c2911cbc0e81d02d3d756e0ae6","date":1499288484,"type":3,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    // None of the operations used here are particularly costly, so this should work.\n    // Using this low timeout will also help us catch index stalling.\n    clientSoTimeout = 5000;\n    cloudClient = createCloudClient(DEFAULT_COLLECTION);\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    \n    boolean testSuccessful = false;\n    try {\n      handle.clear();\n      handle.put(\"timestamp\", SKIPVAL);\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      // make sure we have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n      }      // make sure we again have leaders for each shard\n      \n      waitForRecoveriesToFinish(false);\n      \n      // we cannot do delete by query\n      // as it's not supported for recovery\n      del(\"*:*\");\n      \n      List<StoppableThread> threads = new ArrayList<>();\n      List<StoppableIndexingThread> indexTreads = new ArrayList<>();\n      int threadCount = TEST_NIGHTLY ? 3 : 1;\n      int i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true);\n        threads.add(indexThread);\n        indexTreads.add(indexThread);\n        indexThread.start();\n      }\n      \n      threadCount = 1;\n      i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableSearchThread searchThread = new StoppableSearchThread(cloudClient);\n        threads.add(searchThread);\n        searchThread.start();\n      }\n      \n      if (usually()) {\n        StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n        threads.add(commitThread);\n        commitThread.start();\n      }\n      \n      // TODO: we only do this sometimes so that we can sometimes compare against control,\n      // it's currently hard to know what requests failed when using ConcurrentSolrUpdateServer\n      boolean runFullThrottle = random().nextBoolean();\n      if (runFullThrottle) {\n        FullThrottleStoppableIndexingThread ftIndexThread = \n            new FullThrottleStoppableIndexingThread(controlClient, cloudClient, clients, \"ft1\", true, this.clientSoTimeout);\n        threads.add(ftIndexThread);\n        ftIndexThread.start();\n      }\n      \n      chaosMonkey.startTheMonkey(true, 10000);\n      try {\n        long runLength;\n        if (RUN_LENGTH != -1) {\n          runLength = RUN_LENGTH;\n        } else {\n          int[] runTimes;\n          if (TEST_NIGHTLY) {\n            runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n                30000, 45000, 90000, 120000};\n          } else {\n            runTimes = new int[] {5000, 7000, 15000};\n          }\n          runLength = runTimes[random().nextInt(runTimes.length - 1)];\n        }\n        ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, zkStateReader);\n      } finally {\n        chaosMonkey.stopTheMonkey();\n      }\n\n      // ideally this should go into chaosMonkey\n      restartZk(1000 * (5 + random().nextInt(4)));\n\n      for (StoppableThread indexThread : threads) {\n        indexThread.safeStop();\n      }\n      \n      // start any downed jetties to be sure we still will end up with a leader per shard...\n      \n      // wait for stop...\n      for (StoppableThread indexThread : threads) {\n        indexThread.join();\n      }\n      \n      // try and wait for any replications and what not to finish...\n      \n      ChaosMonkey.wait(2000, DEFAULT_COLLECTION, zkStateReader);\n      \n      // wait until there are no recoveries...\n      waitForThingsToLevelOut(Integer.MAX_VALUE);//Math.round((runLength / 1000.0f / 3.0f)));\n      \n      // make sure we again have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 30000);\n      }\n      \n      commit();\n      \n      // TODO: assert we didnt kill everyone\n      \n      zkStateReader.updateLiveNodes();\n      assertTrue(zkStateReader.getClusterState().getLiveNodes().size() > 0);\n      \n      \n      // we expect full throttle fails, but cloud client should not easily fail\n      for (StoppableThread indexThread : threads) {\n        if (indexThread instanceof StoppableIndexingThread && !(indexThread instanceof FullThrottleStoppableIndexingThread)) {\n          int failCount = ((StoppableIndexingThread) indexThread).getFailCount();\n          assertFalse(\"There were too many update fails (\" + failCount + \" > \" + FAIL_TOLERANCE\n              + \") - we expect it can happen, but shouldn't easily\", failCount > FAIL_TOLERANCE);\n        }\n      }\n      \n      waitForReplicationFromReplicas(DEFAULT_COLLECTION, zkStateReader, new TimeOut(30, TimeUnit.SECONDS));\n//      waitForAllWarmingSearchers();\n      \n      Set<String> addFails = getAddFails(indexTreads);\n      Set<String> deleteFails = getDeleteFails(indexTreads);\n      // full throttle thread can\n      // have request fails\n      checkShardConsistency(!runFullThrottle, true, addFails, deleteFails);      \n      \n      long ctrlDocs = controlClient.query(new SolrQuery(\"*:*\")).getResults()\n      .getNumFound(); \n      \n      // ensure we have added more than 0 docs\n      long cloudClientDocs = cloudClient.query(new SolrQuery(\"*:*\"))\n          .getResults().getNumFound();\n      \n      assertTrue(\"Found \" + ctrlDocs + \" control docs\", cloudClientDocs > 0);\n      \n      log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n      \n      if (VERBOSE) System.out.println(\"control docs:\"\n          + controlClient.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound() + \"\\n\\n\");\n      \n      // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n      // sometimes we restart zookeeper as well\n      if (random().nextBoolean()) {\n        restartZk(1000 * (5 + random().nextInt(4)));\n      }\n\n      try (CloudSolrClient client = createCloudClient(\"collection1\", 30000)) {\n        // We don't really know how many live nodes we have at this point, so \"maxShardsPerNode\" needs to be > 1\n        createCollection(null, \"testcollection\",\n              1, 1, 10, client, null, \"conf1\"); \n      }\n      List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n      numShardsNumReplicas.add(1);\n      numShardsNumReplicas.add(1 + getPullReplicaCount());\n      checkForCollection(\"testcollection\", numShardsNumReplicas, null);\n      \n      testSuccessful = true;\n    } finally {\n      if (!testSuccessful) {\n        logReplicaTypesReplicationInfo(DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n        printLayout();\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    // None of the operations used here are particularly costly, so this should work.\n    // Using this low timeout will also help us catch index stalling.\n    clientSoTimeout = 5000;\n    cloudClient = createCloudClient(DEFAULT_COLLECTION);\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    \n    boolean testSuccessful = false;\n    try {\n      handle.clear();\n      handle.put(\"timestamp\", SKIPVAL);\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      // make sure we have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n      }      // make sure we again have leaders for each shard\n      \n      waitForRecoveriesToFinish(false);\n      \n      // we cannot do delete by query\n      // as it's not supported for recovery\n      del(\"*:*\");\n      \n      List<StoppableThread> threads = new ArrayList<>();\n      List<StoppableIndexingThread> indexTreads = new ArrayList<>();\n      int threadCount = TEST_NIGHTLY ? 3 : 1;\n      int i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true);\n        threads.add(indexThread);\n        indexTreads.add(indexThread);\n        indexThread.start();\n      }\n      \n      threadCount = 1;\n      i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableSearchThread searchThread = new StoppableSearchThread(cloudClient);\n        threads.add(searchThread);\n        searchThread.start();\n      }\n      \n      if (usually()) {\n        StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n        threads.add(commitThread);\n        commitThread.start();\n      }\n      \n      // TODO: we only do this sometimes so that we can sometimes compare against control,\n      // it's currently hard to know what requests failed when using ConcurrentSolrUpdateServer\n      boolean runFullThrottle = random().nextBoolean();\n      if (runFullThrottle) {\n        FullThrottleStoppableIndexingThread ftIndexThread = \n            new FullThrottleStoppableIndexingThread(controlClient, cloudClient, clients, \"ft1\", true, this.clientSoTimeout);\n        threads.add(ftIndexThread);\n        ftIndexThread.start();\n      }\n      \n      chaosMonkey.startTheMonkey(true, 10000);\n      try {\n        long runLength;\n        if (RUN_LENGTH != -1) {\n          runLength = RUN_LENGTH;\n        } else {\n          int[] runTimes;\n          if (TEST_NIGHTLY) {\n            runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n                30000, 45000, 90000, 120000};\n          } else {\n            runTimes = new int[] {5000, 7000, 15000};\n          }\n          runLength = runTimes[random().nextInt(runTimes.length - 1)];\n        }\n        ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, zkStateReader);\n      } finally {\n        chaosMonkey.stopTheMonkey();\n      }\n\n      // ideally this should go into chaosMonkey\n      restartZk(1000 * (5 + random().nextInt(4)));\n\n      for (StoppableThread indexThread : threads) {\n        indexThread.safeStop();\n      }\n      \n      // start any downed jetties to be sure we still will end up with a leader per shard...\n      \n      // wait for stop...\n      for (StoppableThread indexThread : threads) {\n        indexThread.join();\n      }\n      \n      // try and wait for any replications and what not to finish...\n      \n      ChaosMonkey.wait(2000, DEFAULT_COLLECTION, zkStateReader);\n      \n      // wait until there are no recoveries...\n      waitForThingsToLevelOut(Integer.MAX_VALUE);//Math.round((runLength / 1000.0f / 3.0f)));\n      \n      // make sure we again have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 30000);\n      }\n      \n      commit();\n      \n      // TODO: assert we didnt kill everyone\n      \n      zkStateReader.updateLiveNodes();\n      assertTrue(zkStateReader.getClusterState().getLiveNodes().size() > 0);\n      \n      \n      // we expect full throttle fails, but cloud client should not easily fail\n      for (StoppableThread indexThread : threads) {\n        if (indexThread instanceof StoppableIndexingThread && !(indexThread instanceof FullThrottleStoppableIndexingThread)) {\n          int failCount = ((StoppableIndexingThread) indexThread).getFailCount();\n          assertFalse(\"There were too many update fails (\" + failCount + \" > \" + FAIL_TOLERANCE\n              + \") - we expect it can happen, but shouldn't easily\", failCount > FAIL_TOLERANCE);\n        }\n      }\n      \n      waitForReplicationFromReplicas(DEFAULT_COLLECTION, zkStateReader, new TimeOut(30, TimeUnit.SECONDS));\n//      waitForAllWarmingSearchers();\n      \n      Set<String> addFails = getAddFails(indexTreads);\n      Set<String> deleteFails = getDeleteFails(indexTreads);\n      // full throttle thread can\n      // have request fails\n      checkShardConsistency(!runFullThrottle, true, addFails, deleteFails);      \n      \n      long ctrlDocs = controlClient.query(new SolrQuery(\"*:*\")).getResults()\n      .getNumFound(); \n      \n      // ensure we have added more than 0 docs\n      long cloudClientDocs = cloudClient.query(new SolrQuery(\"*:*\"))\n          .getResults().getNumFound();\n      \n      assertTrue(\"Found \" + ctrlDocs + \" control docs\", cloudClientDocs > 0);\n      \n      log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n      \n      if (VERBOSE) System.out.println(\"control docs:\"\n          + controlClient.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound() + \"\\n\\n\");\n      \n      // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n      // sometimes we restart zookeeper as well\n      if (random().nextBoolean()) {\n        restartZk(1000 * (5 + random().nextInt(4)));\n      }\n\n      try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        // We don't really know how many live nodes we have at this point, so \"maxShardsPerNode\" needs to be > 1\n        createCollection(null, \"testcollection\",\n              1, 1, 10, client, null, \"conf1\"); \n      }\n      List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n      numShardsNumReplicas.add(1);\n      numShardsNumReplicas.add(1 + getPullReplicaCount());\n      checkForCollection(\"testcollection\", numShardsNumReplicas, null);\n      \n      testSuccessful = true;\n    } finally {\n      if (!testSuccessful) {\n        logReplicaTypesReplicationInfo(DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n        printLayout();\n      }\n    }\n  }\n\n","bugFix":["61c45e99cf6676da48f19d7511c73712ad39402b"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e73d8d559120669b47658108d818b637df5456ea","date":1499401413,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    // None of the operations used here are particularly costly, so this should work.\n    // Using this low timeout will also help us catch index stalling.\n    clientSoTimeout = 5000;\n    cloudClient = createCloudClient(DEFAULT_COLLECTION);\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    \n    boolean testSuccessful = false;\n    try {\n      handle.clear();\n      handle.put(\"timestamp\", SKIPVAL);\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      // make sure we have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n      }      // make sure we again have leaders for each shard\n      \n      waitForRecoveriesToFinish(false);\n      \n      // we cannot do delete by query\n      // as it's not supported for recovery\n      del(\"*:*\");\n      \n      List<StoppableThread> threads = new ArrayList<>();\n      List<StoppableIndexingThread> indexTreads = new ArrayList<>();\n      int threadCount = TEST_NIGHTLY ? 3 : 1;\n      int i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true);\n        threads.add(indexThread);\n        indexTreads.add(indexThread);\n        indexThread.start();\n      }\n      \n      threadCount = 1;\n      i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableSearchThread searchThread = new StoppableSearchThread(cloudClient);\n        threads.add(searchThread);\n        searchThread.start();\n      }\n      \n      if (usually()) {\n        StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n        threads.add(commitThread);\n        commitThread.start();\n      }\n      \n      // TODO: we only do this sometimes so that we can sometimes compare against control,\n      // it's currently hard to know what requests failed when using ConcurrentSolrUpdateServer\n      boolean runFullThrottle = random().nextBoolean();\n      if (runFullThrottle) {\n        FullThrottleStoppableIndexingThread ftIndexThread = \n            new FullThrottleStoppableIndexingThread(controlClient, cloudClient, clients, \"ft1\", true, this.clientSoTimeout);\n        threads.add(ftIndexThread);\n        ftIndexThread.start();\n      }\n      \n      chaosMonkey.startTheMonkey(true, 10000);\n      try {\n        long runLength;\n        if (RUN_LENGTH != -1) {\n          runLength = RUN_LENGTH;\n        } else {\n          int[] runTimes;\n          if (TEST_NIGHTLY) {\n            runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n                30000, 45000, 90000, 120000};\n          } else {\n            runTimes = new int[] {5000, 7000, 15000};\n          }\n          runLength = runTimes[random().nextInt(runTimes.length - 1)];\n        }\n        ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, zkStateReader);\n      } finally {\n        chaosMonkey.stopTheMonkey();\n      }\n\n      // ideally this should go into chaosMonkey\n      restartZk(1000 * (5 + random().nextInt(4)));\n\n      for (StoppableThread indexThread : threads) {\n        indexThread.safeStop();\n      }\n      \n      // start any downed jetties to be sure we still will end up with a leader per shard...\n      \n      // wait for stop...\n      for (StoppableThread indexThread : threads) {\n        indexThread.join();\n      }\n      \n      // try and wait for any replications and what not to finish...\n      \n      ChaosMonkey.wait(2000, DEFAULT_COLLECTION, zkStateReader);\n      \n      // wait until there are no recoveries...\n      waitForThingsToLevelOut(Integer.MAX_VALUE);//Math.round((runLength / 1000.0f / 3.0f)));\n      \n      // make sure we again have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 30000);\n      }\n      \n      commit();\n      \n      // TODO: assert we didnt kill everyone\n      \n      zkStateReader.updateLiveNodes();\n      assertTrue(zkStateReader.getClusterState().getLiveNodes().size() > 0);\n      \n      \n      // we expect full throttle fails, but cloud client should not easily fail\n      for (StoppableThread indexThread : threads) {\n        if (indexThread instanceof StoppableIndexingThread && !(indexThread instanceof FullThrottleStoppableIndexingThread)) {\n          int failCount = ((StoppableIndexingThread) indexThread).getFailCount();\n          assertFalse(\"There were too many update fails (\" + failCount + \" > \" + FAIL_TOLERANCE\n              + \") - we expect it can happen, but shouldn't easily\", failCount > FAIL_TOLERANCE);\n        }\n      }\n      \n      waitForReplicationFromReplicas(DEFAULT_COLLECTION, zkStateReader, new TimeOut(30, TimeUnit.SECONDS));\n//      waitForAllWarmingSearchers();\n      \n      Set<String> addFails = getAddFails(indexTreads);\n      Set<String> deleteFails = getDeleteFails(indexTreads);\n      // full throttle thread can\n      // have request fails\n      checkShardConsistency(!runFullThrottle, true, addFails, deleteFails);      \n      \n      long ctrlDocs = controlClient.query(new SolrQuery(\"*:*\")).getResults()\n      .getNumFound(); \n      \n      // ensure we have added more than 0 docs\n      long cloudClientDocs = cloudClient.query(new SolrQuery(\"*:*\"))\n          .getResults().getNumFound();\n      \n      assertTrue(\"Found \" + ctrlDocs + \" control docs\", cloudClientDocs > 0);\n      \n      log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n      \n      if (VERBOSE) System.out.println(\"control docs:\"\n          + controlClient.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound() + \"\\n\\n\");\n      \n      // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n      // sometimes we restart zookeeper as well\n      if (random().nextBoolean()) {\n        restartZk(1000 * (5 + random().nextInt(4)));\n      }\n\n      try (CloudSolrClient client = createCloudClient(\"collection1\", 30000)) {\n        // We don't really know how many live nodes we have at this point, so \"maxShardsPerNode\" needs to be > 1\n        createCollection(null, \"testcollection\",\n              1, 1, 10, client, null, \"conf1\"); \n      }\n      List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n      numShardsNumReplicas.add(1);\n      numShardsNumReplicas.add(1 + getPullReplicaCount());\n      checkForCollection(\"testcollection\", numShardsNumReplicas, null);\n      \n      testSuccessful = true;\n    } finally {\n      if (!testSuccessful) {\n        logReplicaTypesReplicationInfo(DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n        printLayout();\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    // None of the operations used here are particularly costly, so this should work.\n    // Using this low timeout will also help us catch index stalling.\n    clientSoTimeout = 5000;\n    cloudClient = createCloudClient(DEFAULT_COLLECTION);\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    \n    boolean testSuccessful = false;\n    try {\n      handle.clear();\n      handle.put(\"timestamp\", SKIPVAL);\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      // make sure we have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n      }      // make sure we again have leaders for each shard\n      \n      waitForRecoveriesToFinish(false);\n      \n      // we cannot do delete by query\n      // as it's not supported for recovery\n      del(\"*:*\");\n      \n      List<StoppableThread> threads = new ArrayList<>();\n      List<StoppableIndexingThread> indexTreads = new ArrayList<>();\n      int threadCount = TEST_NIGHTLY ? 3 : 1;\n      int i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true);\n        threads.add(indexThread);\n        indexTreads.add(indexThread);\n        indexThread.start();\n      }\n      \n      threadCount = 1;\n      i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableSearchThread searchThread = new StoppableSearchThread(cloudClient);\n        threads.add(searchThread);\n        searchThread.start();\n      }\n      \n      if (usually()) {\n        StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n        threads.add(commitThread);\n        commitThread.start();\n      }\n      \n      // TODO: we only do this sometimes so that we can sometimes compare against control,\n      // it's currently hard to know what requests failed when using ConcurrentSolrUpdateServer\n      boolean runFullThrottle = random().nextBoolean();\n      if (runFullThrottle) {\n        FullThrottleStoppableIndexingThread ftIndexThread = \n            new FullThrottleStoppableIndexingThread(controlClient, cloudClient, clients, \"ft1\", true, this.clientSoTimeout);\n        threads.add(ftIndexThread);\n        ftIndexThread.start();\n      }\n      \n      chaosMonkey.startTheMonkey(true, 10000);\n      try {\n        long runLength;\n        if (RUN_LENGTH != -1) {\n          runLength = RUN_LENGTH;\n        } else {\n          int[] runTimes;\n          if (TEST_NIGHTLY) {\n            runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n                30000, 45000, 90000, 120000};\n          } else {\n            runTimes = new int[] {5000, 7000, 15000};\n          }\n          runLength = runTimes[random().nextInt(runTimes.length - 1)];\n        }\n        ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, zkStateReader);\n      } finally {\n        chaosMonkey.stopTheMonkey();\n      }\n\n      // ideally this should go into chaosMonkey\n      restartZk(1000 * (5 + random().nextInt(4)));\n\n      for (StoppableThread indexThread : threads) {\n        indexThread.safeStop();\n      }\n      \n      // start any downed jetties to be sure we still will end up with a leader per shard...\n      \n      // wait for stop...\n      for (StoppableThread indexThread : threads) {\n        indexThread.join();\n      }\n      \n      // try and wait for any replications and what not to finish...\n      \n      ChaosMonkey.wait(2000, DEFAULT_COLLECTION, zkStateReader);\n      \n      // wait until there are no recoveries...\n      waitForThingsToLevelOut(Integer.MAX_VALUE);//Math.round((runLength / 1000.0f / 3.0f)));\n      \n      // make sure we again have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 30000);\n      }\n      \n      commit();\n      \n      // TODO: assert we didnt kill everyone\n      \n      zkStateReader.updateLiveNodes();\n      assertTrue(zkStateReader.getClusterState().getLiveNodes().size() > 0);\n      \n      \n      // we expect full throttle fails, but cloud client should not easily fail\n      for (StoppableThread indexThread : threads) {\n        if (indexThread instanceof StoppableIndexingThread && !(indexThread instanceof FullThrottleStoppableIndexingThread)) {\n          int failCount = ((StoppableIndexingThread) indexThread).getFailCount();\n          assertFalse(\"There were too many update fails (\" + failCount + \" > \" + FAIL_TOLERANCE\n              + \") - we expect it can happen, but shouldn't easily\", failCount > FAIL_TOLERANCE);\n        }\n      }\n      \n      waitForReplicationFromReplicas(DEFAULT_COLLECTION, zkStateReader, new TimeOut(30, TimeUnit.SECONDS));\n//      waitForAllWarmingSearchers();\n      \n      Set<String> addFails = getAddFails(indexTreads);\n      Set<String> deleteFails = getDeleteFails(indexTreads);\n      // full throttle thread can\n      // have request fails\n      checkShardConsistency(!runFullThrottle, true, addFails, deleteFails);      \n      \n      long ctrlDocs = controlClient.query(new SolrQuery(\"*:*\")).getResults()\n      .getNumFound(); \n      \n      // ensure we have added more than 0 docs\n      long cloudClientDocs = cloudClient.query(new SolrQuery(\"*:*\"))\n          .getResults().getNumFound();\n      \n      assertTrue(\"Found \" + ctrlDocs + \" control docs\", cloudClientDocs > 0);\n      \n      log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n      \n      if (VERBOSE) System.out.println(\"control docs:\"\n          + controlClient.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound() + \"\\n\\n\");\n      \n      // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n      // sometimes we restart zookeeper as well\n      if (random().nextBoolean()) {\n        restartZk(1000 * (5 + random().nextInt(4)));\n      }\n\n      try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        // We don't really know how many live nodes we have at this point, so \"maxShardsPerNode\" needs to be > 1\n        createCollection(null, \"testcollection\",\n              1, 1, 10, client, null, \"conf1\"); \n      }\n      List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n      numShardsNumReplicas.add(1);\n      numShardsNumReplicas.add(1 + getPullReplicaCount());\n      checkForCollection(\"testcollection\", numShardsNumReplicas, null);\n      \n      testSuccessful = true;\n    } finally {\n      if (!testSuccessful) {\n        logReplicaTypesReplicationInfo(DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n        printLayout();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1","date":1513252583,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    // None of the operations used here are particularly costly, so this should work.\n    // Using this low timeout will also help us catch index stalling.\n    clientSoTimeout = 5000;\n    cloudClient = createCloudClient(DEFAULT_COLLECTION);\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    \n    boolean testSuccessful = false;\n    try {\n      handle.clear();\n      handle.put(\"timestamp\", SKIPVAL);\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      // make sure we have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n      }      // make sure we again have leaders for each shard\n      \n      waitForRecoveriesToFinish(false);\n      \n      // we cannot do delete by query\n      // as it's not supported for recovery\n      del(\"*:*\");\n      \n      List<StoppableThread> threads = new ArrayList<>();\n      List<StoppableIndexingThread> indexTreads = new ArrayList<>();\n      int threadCount = TEST_NIGHTLY ? 3 : 1;\n      int i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true);\n        threads.add(indexThread);\n        indexTreads.add(indexThread);\n        indexThread.start();\n      }\n      \n      threadCount = 1;\n      i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableSearchThread searchThread = new StoppableSearchThread(cloudClient);\n        threads.add(searchThread);\n        searchThread.start();\n      }\n      \n      if (usually()) {\n        StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n        threads.add(commitThread);\n        commitThread.start();\n      }\n      \n      // TODO: we only do this sometimes so that we can sometimes compare against control,\n      // it's currently hard to know what requests failed when using ConcurrentSolrUpdateServer\n      boolean runFullThrottle = random().nextBoolean();\n      if (runFullThrottle) {\n        FullThrottleStoppableIndexingThread ftIndexThread = \n            new FullThrottleStoppableIndexingThread(controlClient, cloudClient, clients, \"ft1\", true, this.clientSoTimeout);\n        threads.add(ftIndexThread);\n        ftIndexThread.start();\n      }\n      \n      chaosMonkey.startTheMonkey(true, 10000);\n      try {\n        long runLength;\n        if (RUN_LENGTH != -1) {\n          runLength = RUN_LENGTH;\n        } else {\n          int[] runTimes;\n          if (TEST_NIGHTLY) {\n            runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n                30000, 45000, 90000, 120000};\n          } else {\n            runTimes = new int[] {5000, 7000, 15000};\n          }\n          runLength = runTimes[random().nextInt(runTimes.length - 1)];\n        }\n        ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, zkStateReader);\n      } finally {\n        chaosMonkey.stopTheMonkey();\n      }\n\n      // ideally this should go into chaosMonkey\n      restartZk(1000 * (5 + random().nextInt(4)));\n\n      for (StoppableThread indexThread : threads) {\n        indexThread.safeStop();\n      }\n      \n      // start any downed jetties to be sure we still will end up with a leader per shard...\n      \n      // wait for stop...\n      for (StoppableThread indexThread : threads) {\n        indexThread.join();\n      }\n      \n      // try and wait for any replications and what not to finish...\n      \n      ChaosMonkey.wait(2000, DEFAULT_COLLECTION, zkStateReader);\n      \n      // wait until there are no recoveries...\n      waitForThingsToLevelOut(Integer.MAX_VALUE);//Math.round((runLength / 1000.0f / 3.0f)));\n      \n      // make sure we again have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 30000);\n      }\n      \n      commit();\n      \n      // TODO: assert we didnt kill everyone\n      \n      zkStateReader.updateLiveNodes();\n      assertTrue(zkStateReader.getClusterState().getLiveNodes().size() > 0);\n      \n      \n      // we expect full throttle fails, but cloud client should not easily fail\n      for (StoppableThread indexThread : threads) {\n        if (indexThread instanceof StoppableIndexingThread && !(indexThread instanceof FullThrottleStoppableIndexingThread)) {\n          int failCount = ((StoppableIndexingThread) indexThread).getFailCount();\n          assertFalse(\"There were too many update fails (\" + failCount + \" > \" + FAIL_TOLERANCE\n              + \") - we expect it can happen, but shouldn't easily\", failCount > FAIL_TOLERANCE);\n        }\n      }\n      \n      waitForReplicationFromReplicas(DEFAULT_COLLECTION, zkStateReader, new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME));\n//      waitForAllWarmingSearchers();\n      \n      Set<String> addFails = getAddFails(indexTreads);\n      Set<String> deleteFails = getDeleteFails(indexTreads);\n      // full throttle thread can\n      // have request fails\n      checkShardConsistency(!runFullThrottle, true, addFails, deleteFails);      \n      \n      long ctrlDocs = controlClient.query(new SolrQuery(\"*:*\")).getResults()\n      .getNumFound(); \n      \n      // ensure we have added more than 0 docs\n      long cloudClientDocs = cloudClient.query(new SolrQuery(\"*:*\"))\n          .getResults().getNumFound();\n      \n      assertTrue(\"Found \" + ctrlDocs + \" control docs\", cloudClientDocs > 0);\n      \n      log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n      \n      if (VERBOSE) System.out.println(\"control docs:\"\n          + controlClient.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound() + \"\\n\\n\");\n      \n      // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n      // sometimes we restart zookeeper as well\n      if (random().nextBoolean()) {\n        restartZk(1000 * (5 + random().nextInt(4)));\n      }\n\n      try (CloudSolrClient client = createCloudClient(\"collection1\", 30000)) {\n        // We don't really know how many live nodes we have at this point, so \"maxShardsPerNode\" needs to be > 1\n        createCollection(null, \"testcollection\",\n              1, 1, 10, client, null, \"conf1\"); \n      }\n      List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n      numShardsNumReplicas.add(1);\n      numShardsNumReplicas.add(1 + getPullReplicaCount());\n      checkForCollection(\"testcollection\", numShardsNumReplicas, null);\n      \n      testSuccessful = true;\n    } finally {\n      if (!testSuccessful) {\n        logReplicaTypesReplicationInfo(DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n        printLayout();\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    // None of the operations used here are particularly costly, so this should work.\n    // Using this low timeout will also help us catch index stalling.\n    clientSoTimeout = 5000;\n    cloudClient = createCloudClient(DEFAULT_COLLECTION);\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    \n    boolean testSuccessful = false;\n    try {\n      handle.clear();\n      handle.put(\"timestamp\", SKIPVAL);\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      // make sure we have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n      }      // make sure we again have leaders for each shard\n      \n      waitForRecoveriesToFinish(false);\n      \n      // we cannot do delete by query\n      // as it's not supported for recovery\n      del(\"*:*\");\n      \n      List<StoppableThread> threads = new ArrayList<>();\n      List<StoppableIndexingThread> indexTreads = new ArrayList<>();\n      int threadCount = TEST_NIGHTLY ? 3 : 1;\n      int i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true);\n        threads.add(indexThread);\n        indexTreads.add(indexThread);\n        indexThread.start();\n      }\n      \n      threadCount = 1;\n      i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableSearchThread searchThread = new StoppableSearchThread(cloudClient);\n        threads.add(searchThread);\n        searchThread.start();\n      }\n      \n      if (usually()) {\n        StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n        threads.add(commitThread);\n        commitThread.start();\n      }\n      \n      // TODO: we only do this sometimes so that we can sometimes compare against control,\n      // it's currently hard to know what requests failed when using ConcurrentSolrUpdateServer\n      boolean runFullThrottle = random().nextBoolean();\n      if (runFullThrottle) {\n        FullThrottleStoppableIndexingThread ftIndexThread = \n            new FullThrottleStoppableIndexingThread(controlClient, cloudClient, clients, \"ft1\", true, this.clientSoTimeout);\n        threads.add(ftIndexThread);\n        ftIndexThread.start();\n      }\n      \n      chaosMonkey.startTheMonkey(true, 10000);\n      try {\n        long runLength;\n        if (RUN_LENGTH != -1) {\n          runLength = RUN_LENGTH;\n        } else {\n          int[] runTimes;\n          if (TEST_NIGHTLY) {\n            runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n                30000, 45000, 90000, 120000};\n          } else {\n            runTimes = new int[] {5000, 7000, 15000};\n          }\n          runLength = runTimes[random().nextInt(runTimes.length - 1)];\n        }\n        ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, zkStateReader);\n      } finally {\n        chaosMonkey.stopTheMonkey();\n      }\n\n      // ideally this should go into chaosMonkey\n      restartZk(1000 * (5 + random().nextInt(4)));\n\n      for (StoppableThread indexThread : threads) {\n        indexThread.safeStop();\n      }\n      \n      // start any downed jetties to be sure we still will end up with a leader per shard...\n      \n      // wait for stop...\n      for (StoppableThread indexThread : threads) {\n        indexThread.join();\n      }\n      \n      // try and wait for any replications and what not to finish...\n      \n      ChaosMonkey.wait(2000, DEFAULT_COLLECTION, zkStateReader);\n      \n      // wait until there are no recoveries...\n      waitForThingsToLevelOut(Integer.MAX_VALUE);//Math.round((runLength / 1000.0f / 3.0f)));\n      \n      // make sure we again have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 30000);\n      }\n      \n      commit();\n      \n      // TODO: assert we didnt kill everyone\n      \n      zkStateReader.updateLiveNodes();\n      assertTrue(zkStateReader.getClusterState().getLiveNodes().size() > 0);\n      \n      \n      // we expect full throttle fails, but cloud client should not easily fail\n      for (StoppableThread indexThread : threads) {\n        if (indexThread instanceof StoppableIndexingThread && !(indexThread instanceof FullThrottleStoppableIndexingThread)) {\n          int failCount = ((StoppableIndexingThread) indexThread).getFailCount();\n          assertFalse(\"There were too many update fails (\" + failCount + \" > \" + FAIL_TOLERANCE\n              + \") - we expect it can happen, but shouldn't easily\", failCount > FAIL_TOLERANCE);\n        }\n      }\n      \n      waitForReplicationFromReplicas(DEFAULT_COLLECTION, zkStateReader, new TimeOut(30, TimeUnit.SECONDS));\n//      waitForAllWarmingSearchers();\n      \n      Set<String> addFails = getAddFails(indexTreads);\n      Set<String> deleteFails = getDeleteFails(indexTreads);\n      // full throttle thread can\n      // have request fails\n      checkShardConsistency(!runFullThrottle, true, addFails, deleteFails);      \n      \n      long ctrlDocs = controlClient.query(new SolrQuery(\"*:*\")).getResults()\n      .getNumFound(); \n      \n      // ensure we have added more than 0 docs\n      long cloudClientDocs = cloudClient.query(new SolrQuery(\"*:*\"))\n          .getResults().getNumFound();\n      \n      assertTrue(\"Found \" + ctrlDocs + \" control docs\", cloudClientDocs > 0);\n      \n      log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n      \n      if (VERBOSE) System.out.println(\"control docs:\"\n          + controlClient.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound() + \"\\n\\n\");\n      \n      // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n      // sometimes we restart zookeeper as well\n      if (random().nextBoolean()) {\n        restartZk(1000 * (5 + random().nextInt(4)));\n      }\n\n      try (CloudSolrClient client = createCloudClient(\"collection1\", 30000)) {\n        // We don't really know how many live nodes we have at this point, so \"maxShardsPerNode\" needs to be > 1\n        createCollection(null, \"testcollection\",\n              1, 1, 10, client, null, \"conf1\"); \n      }\n      List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n      numShardsNumReplicas.add(1);\n      numShardsNumReplicas.add(1 + getPullReplicaCount());\n      checkForCollection(\"testcollection\", numShardsNumReplicas, null);\n      \n      testSuccessful = true;\n    } finally {\n      if (!testSuccessful) {\n        logReplicaTypesReplicationInfo(DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n        printLayout();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    // None of the operations used here are particularly costly, so this should work.\n    // Using this low timeout will also help us catch index stalling.\n    clientSoTimeout = 8000;\n\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    \n    boolean testSuccessful = false;\n    try {\n      handle.clear();\n      handle.put(\"timestamp\", SKIPVAL);\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      // make sure we have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n      }      // make sure we again have leaders for each shard\n      \n      waitForRecoveriesToFinish(false);\n\n      del(\"*:*\");\n      \n      List<StoppableThread> threads = new ArrayList<>();\n      List<StoppableIndexingThread> indexTreads = new ArrayList<>();\n      int threadCount = TEST_NIGHTLY ? 3 : 1;\n      int i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, 35, 1, true);\n        threads.add(indexThread);\n        indexTreads.add(indexThread);\n        indexThread.start();\n      }\n      \n      threadCount = 1;\n      i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableSearchThread searchThread = new StoppableSearchThread(cloudClient);\n        threads.add(searchThread);\n        searchThread.start();\n      }\n      \n      if (usually()) {\n        StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n        threads.add(commitThread);\n        commitThread.start();\n      }\n      \n      if (runFullThrottle) {\n        ftIndexThread = \n            new FullThrottleStoppableIndexingThread(cloudClient.getHttpClient(), controlClient, cloudClient, clients, \"ft1\", true, this.clientSoTimeout);\n        ftIndexThread.start();\n      }\n      \n      chaosMonkey.startTheMonkey(true, 10000);\n      try {\n        long runLength;\n        if (RUN_LENGTH != -1) {\n          runLength = RUN_LENGTH;\n        } else {\n          int[] runTimes;\n          if (TEST_NIGHTLY) {\n            runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n                30000, 45000, 90000, 120000};\n          } else {\n            runTimes = new int[] {5000, 7000, 10000};\n          }\n          runLength = runTimes[random().nextInt(runTimes.length - 1)];\n        }\n        ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, zkStateReader);\n      } finally {\n        chaosMonkey.stopTheMonkey();\n      }\n\n      // ideally this should go into chaosMonkey\n      restartZk(1000 * (5 + random().nextInt(4)));\n\n      if (runFullThrottle) {\n        ftIndexThread.safeStop();\n      }\n      \n      for (StoppableThread indexThread : threads) {\n        indexThread.safeStop();\n      }\n      \n      // start any downed jetties to be sure we still will end up with a leader per shard...\n      \n      // wait for stop...\n      for (StoppableThread indexThread : threads) {\n        indexThread.join();\n      }\n      \n      // try and wait for any replications and what not to finish...\n      \n      ChaosMonkey.wait(2000, DEFAULT_COLLECTION, zkStateReader);\n      \n      // wait until there are no recoveries...\n      waitForThingsToLevelOut(Integer.MAX_VALUE);//Math.round((runLength / 1000.0f / 3.0f)));\n      \n      // make sure we again have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 30000);\n      }\n      \n      commit();\n      \n      // TODO: assert we didnt kill everyone\n      \n      zkStateReader.updateLiveNodes();\n      assertTrue(zkStateReader.getClusterState().getLiveNodes().size() > 0);\n      \n      \n      // we expect full throttle fails, but cloud client should not easily fail\n      for (StoppableThread indexThread : threads) {\n        if (indexThread instanceof StoppableIndexingThread && !(indexThread instanceof FullThrottleStoppableIndexingThread)) {\n          int failCount = ((StoppableIndexingThread) indexThread).getFailCount();\n          assertFalse(\"There were too many update fails (\" + failCount + \" > \" + FAIL_TOLERANCE\n              + \") - we expect it can happen, but shouldn't easily\", failCount > FAIL_TOLERANCE);\n        }\n      }\n      \n      waitForReplicationFromReplicas(DEFAULT_COLLECTION, zkStateReader, new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME));\n//      waitForAllWarmingSearchers();\n      \n      Set<String> addFails = getAddFails(indexTreads);\n      Set<String> deleteFails = getDeleteFails(indexTreads);\n      // full throttle thread can\n      // have request fails\n      checkShardConsistency(!runFullThrottle, true, addFails, deleteFails);      \n      \n      long ctrlDocs = controlClient.query(new SolrQuery(\"*:*\")).getResults()\n      .getNumFound(); \n      \n      // ensure we have added more than 0 docs\n      long cloudClientDocs = cloudClient.query(new SolrQuery(\"*:*\"))\n          .getResults().getNumFound();\n      \n      assertTrue(\"Found \" + ctrlDocs + \" control docs\", cloudClientDocs > 0);\n      \n      log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n      \n      if (VERBOSE) System.out.println(\"control docs:\"\n          + controlClient.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound() + \"\\n\\n\");\n      \n      // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n      // sometimes we restart zookeeper as well\n      if (random().nextBoolean()) {\n        restartZk(1000 * (5 + random().nextInt(4)));\n      }\n\n      try (CloudSolrClient client = createCloudClient(\"collection1\", 30000)) {\n        // We don't really know how many live nodes we have at this point, so \"maxShardsPerNode\" needs to be > 1\n        createCollection(null, \"testcollection\",\n              1, 1, 10, client, null, \"conf1\"); \n      }\n      List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n      numShardsNumReplicas.add(1);\n      numShardsNumReplicas.add(1 + getPullReplicaCount());\n      checkForCollection(\"testcollection\", numShardsNumReplicas, null);\n      \n      testSuccessful = true;\n    } finally {\n      if (!testSuccessful) {\n        logReplicaTypesReplicationInfo(DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n        printLayout();\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    // None of the operations used here are particularly costly, so this should work.\n    // Using this low timeout will also help us catch index stalling.\n    clientSoTimeout = 5000;\n    cloudClient = createCloudClient(DEFAULT_COLLECTION);\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    \n    boolean testSuccessful = false;\n    try {\n      handle.clear();\n      handle.put(\"timestamp\", SKIPVAL);\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      // make sure we have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n      }      // make sure we again have leaders for each shard\n      \n      waitForRecoveriesToFinish(false);\n      \n      // we cannot do delete by query\n      // as it's not supported for recovery\n      del(\"*:*\");\n      \n      List<StoppableThread> threads = new ArrayList<>();\n      List<StoppableIndexingThread> indexTreads = new ArrayList<>();\n      int threadCount = TEST_NIGHTLY ? 3 : 1;\n      int i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true);\n        threads.add(indexThread);\n        indexTreads.add(indexThread);\n        indexThread.start();\n      }\n      \n      threadCount = 1;\n      i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableSearchThread searchThread = new StoppableSearchThread(cloudClient);\n        threads.add(searchThread);\n        searchThread.start();\n      }\n      \n      if (usually()) {\n        StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n        threads.add(commitThread);\n        commitThread.start();\n      }\n      \n      // TODO: we only do this sometimes so that we can sometimes compare against control,\n      // it's currently hard to know what requests failed when using ConcurrentSolrUpdateServer\n      boolean runFullThrottle = random().nextBoolean();\n      if (runFullThrottle) {\n        FullThrottleStoppableIndexingThread ftIndexThread = \n            new FullThrottleStoppableIndexingThread(controlClient, cloudClient, clients, \"ft1\", true, this.clientSoTimeout);\n        threads.add(ftIndexThread);\n        ftIndexThread.start();\n      }\n      \n      chaosMonkey.startTheMonkey(true, 10000);\n      try {\n        long runLength;\n        if (RUN_LENGTH != -1) {\n          runLength = RUN_LENGTH;\n        } else {\n          int[] runTimes;\n          if (TEST_NIGHTLY) {\n            runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n                30000, 45000, 90000, 120000};\n          } else {\n            runTimes = new int[] {5000, 7000, 15000};\n          }\n          runLength = runTimes[random().nextInt(runTimes.length - 1)];\n        }\n        ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, zkStateReader);\n      } finally {\n        chaosMonkey.stopTheMonkey();\n      }\n\n      // ideally this should go into chaosMonkey\n      restartZk(1000 * (5 + random().nextInt(4)));\n\n      for (StoppableThread indexThread : threads) {\n        indexThread.safeStop();\n      }\n      \n      // start any downed jetties to be sure we still will end up with a leader per shard...\n      \n      // wait for stop...\n      for (StoppableThread indexThread : threads) {\n        indexThread.join();\n      }\n      \n      // try and wait for any replications and what not to finish...\n      \n      ChaosMonkey.wait(2000, DEFAULT_COLLECTION, zkStateReader);\n      \n      // wait until there are no recoveries...\n      waitForThingsToLevelOut(Integer.MAX_VALUE);//Math.round((runLength / 1000.0f / 3.0f)));\n      \n      // make sure we again have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 30000);\n      }\n      \n      commit();\n      \n      // TODO: assert we didnt kill everyone\n      \n      zkStateReader.updateLiveNodes();\n      assertTrue(zkStateReader.getClusterState().getLiveNodes().size() > 0);\n      \n      \n      // we expect full throttle fails, but cloud client should not easily fail\n      for (StoppableThread indexThread : threads) {\n        if (indexThread instanceof StoppableIndexingThread && !(indexThread instanceof FullThrottleStoppableIndexingThread)) {\n          int failCount = ((StoppableIndexingThread) indexThread).getFailCount();\n          assertFalse(\"There were too many update fails (\" + failCount + \" > \" + FAIL_TOLERANCE\n              + \") - we expect it can happen, but shouldn't easily\", failCount > FAIL_TOLERANCE);\n        }\n      }\n      \n      waitForReplicationFromReplicas(DEFAULT_COLLECTION, zkStateReader, new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME));\n//      waitForAllWarmingSearchers();\n      \n      Set<String> addFails = getAddFails(indexTreads);\n      Set<String> deleteFails = getDeleteFails(indexTreads);\n      // full throttle thread can\n      // have request fails\n      checkShardConsistency(!runFullThrottle, true, addFails, deleteFails);      \n      \n      long ctrlDocs = controlClient.query(new SolrQuery(\"*:*\")).getResults()\n      .getNumFound(); \n      \n      // ensure we have added more than 0 docs\n      long cloudClientDocs = cloudClient.query(new SolrQuery(\"*:*\"))\n          .getResults().getNumFound();\n      \n      assertTrue(\"Found \" + ctrlDocs + \" control docs\", cloudClientDocs > 0);\n      \n      log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n      \n      if (VERBOSE) System.out.println(\"control docs:\"\n          + controlClient.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound() + \"\\n\\n\");\n      \n      // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n      // sometimes we restart zookeeper as well\n      if (random().nextBoolean()) {\n        restartZk(1000 * (5 + random().nextInt(4)));\n      }\n\n      try (CloudSolrClient client = createCloudClient(\"collection1\", 30000)) {\n        // We don't really know how many live nodes we have at this point, so \"maxShardsPerNode\" needs to be > 1\n        createCollection(null, \"testcollection\",\n              1, 1, 10, client, null, \"conf1\"); \n      }\n      List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n      numShardsNumReplicas.add(1);\n      numShardsNumReplicas.add(1 + getPullReplicaCount());\n      checkForCollection(\"testcollection\", numShardsNumReplicas, null);\n      \n      testSuccessful = true;\n    } finally {\n      if (!testSuccessful) {\n        logReplicaTypesReplicationInfo(DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n        printLayout();\n      }\n    }\n  }\n\n","bugFix":["43d1e498704edd2bba13548a189eed4dfccff11b","61c45e99cf6676da48f19d7511c73712ad39402b"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"add1e7dd742ea533ff4318cea83ca0a1f669f662","date":1585262285,"type":3,"author":"Mike Drob","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    // None of the operations used here are particularly costly, so this should work.\n    // Using this low timeout will also help us catch index stalling.\n    clientSoTimeout = 8000;\n\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    \n    boolean testSuccessful = false;\n    try {\n      handle.clear();\n      handle.put(\"timestamp\", SKIPVAL);\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      // make sure we have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n      }      // make sure we again have leaders for each shard\n      \n      waitForRecoveriesToFinish(false);\n\n      del(\"*:*\");\n      \n      List<StoppableThread> threads = new ArrayList<>();\n      List<StoppableIndexingThread> indexTreads = new ArrayList<>();\n      int threadCount = TEST_NIGHTLY ? 3 : 1;\n      int i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, 35, 1, true);\n        threads.add(indexThread);\n        indexTreads.add(indexThread);\n        indexThread.start();\n      }\n      \n      threadCount = 1;\n      i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableSearchThread searchThread = new StoppableSearchThread(cloudClient);\n        threads.add(searchThread);\n        searchThread.start();\n      }\n      \n      if (usually()) {\n        StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n        threads.add(commitThread);\n        commitThread.start();\n      }\n      \n      if (runFullThrottle) {\n        ftIndexThread = \n            new FullThrottleStoppableIndexingThread(cloudClient.getHttpClient(), controlClient, cloudClient, clients, \"ft1\", true, this.clientSoTimeout);\n        ftIndexThread.start();\n      }\n      \n      chaosMonkey.startTheMonkey(true, 10000);\n      try {\n        long runLength;\n        if (RUN_LENGTH != -1) {\n          runLength = RUN_LENGTH;\n        } else {\n          int[] runTimes;\n          if (TEST_NIGHTLY) {\n            runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n                30000, 45000, 90000, 120000};\n          } else {\n            runTimes = new int[] {5000, 7000, 10000};\n          }\n          runLength = runTimes[random().nextInt(runTimes.length - 1)];\n        }\n        ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, zkStateReader);\n      } finally {\n        chaosMonkey.stopTheMonkey();\n      }\n\n      // ideally this should go into chaosMonkey\n      restartZk(1000 * (5 + random().nextInt(4)));\n\n      if (runFullThrottle) {\n        ftIndexThread.safeStop();\n      }\n      \n      for (StoppableThread indexThread : threads) {\n        indexThread.safeStop();\n      }\n      \n      // start any downed jetties to be sure we still will end up with a leader per shard...\n      \n      // wait for stop...\n      for (StoppableThread indexThread : threads) {\n        indexThread.join();\n      }\n      \n      // try and wait for any replications and what not to finish...\n      \n      ChaosMonkey.wait(2000, DEFAULT_COLLECTION, zkStateReader);\n      \n      // wait until there are no recoveries...\n      waitForThingsToLevelOut();\n      \n      // make sure we again have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 30000);\n      }\n      \n      commit();\n      \n      // TODO: assert we didnt kill everyone\n      \n      zkStateReader.updateLiveNodes();\n      assertTrue(zkStateReader.getClusterState().getLiveNodes().size() > 0);\n      \n      \n      // we expect full throttle fails, but cloud client should not easily fail\n      for (StoppableThread indexThread : threads) {\n        if (indexThread instanceof StoppableIndexingThread && !(indexThread instanceof FullThrottleStoppableIndexingThread)) {\n          int failCount = ((StoppableIndexingThread) indexThread).getFailCount();\n          assertFalse(\"There were too many update fails (\" + failCount + \" > \" + FAIL_TOLERANCE\n              + \") - we expect it can happen, but shouldn't easily\", failCount > FAIL_TOLERANCE);\n        }\n      }\n      \n      waitForReplicationFromReplicas(DEFAULT_COLLECTION, zkStateReader, new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME));\n//      waitForAllWarmingSearchers();\n      \n      Set<String> addFails = getAddFails(indexTreads);\n      Set<String> deleteFails = getDeleteFails(indexTreads);\n      // full throttle thread can\n      // have request fails\n      checkShardConsistency(!runFullThrottle, true, addFails, deleteFails);      \n      \n      long ctrlDocs = controlClient.query(new SolrQuery(\"*:*\")).getResults()\n      .getNumFound(); \n      \n      // ensure we have added more than 0 docs\n      long cloudClientDocs = cloudClient.query(new SolrQuery(\"*:*\"))\n          .getResults().getNumFound();\n      \n      assertTrue(\"Found \" + ctrlDocs + \" control docs\", cloudClientDocs > 0);\n      \n      log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n      \n      if (VERBOSE) System.out.println(\"control docs:\"\n          + controlClient.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound() + \"\\n\\n\");\n      \n      // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n      // sometimes we restart zookeeper as well\n      if (random().nextBoolean()) {\n        restartZk(1000 * (5 + random().nextInt(4)));\n      }\n\n      try (CloudSolrClient client = createCloudClient(\"collection1\", 30000)) {\n        // We don't really know how many live nodes we have at this point, so \"maxShardsPerNode\" needs to be > 1\n        createCollection(null, \"testcollection\",\n              1, 1, 10, client, null, \"conf1\"); \n      }\n      List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n      numShardsNumReplicas.add(1);\n      numShardsNumReplicas.add(1 + getPullReplicaCount());\n      checkForCollection(\"testcollection\", numShardsNumReplicas, null);\n      \n      testSuccessful = true;\n    } finally {\n      if (!testSuccessful) {\n        logReplicaTypesReplicationInfo(DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n        printLayout();\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    // None of the operations used here are particularly costly, so this should work.\n    // Using this low timeout will also help us catch index stalling.\n    clientSoTimeout = 8000;\n\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    \n    boolean testSuccessful = false;\n    try {\n      handle.clear();\n      handle.put(\"timestamp\", SKIPVAL);\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      // make sure we have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n      }      // make sure we again have leaders for each shard\n      \n      waitForRecoveriesToFinish(false);\n\n      del(\"*:*\");\n      \n      List<StoppableThread> threads = new ArrayList<>();\n      List<StoppableIndexingThread> indexTreads = new ArrayList<>();\n      int threadCount = TEST_NIGHTLY ? 3 : 1;\n      int i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, 35, 1, true);\n        threads.add(indexThread);\n        indexTreads.add(indexThread);\n        indexThread.start();\n      }\n      \n      threadCount = 1;\n      i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableSearchThread searchThread = new StoppableSearchThread(cloudClient);\n        threads.add(searchThread);\n        searchThread.start();\n      }\n      \n      if (usually()) {\n        StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n        threads.add(commitThread);\n        commitThread.start();\n      }\n      \n      if (runFullThrottle) {\n        ftIndexThread = \n            new FullThrottleStoppableIndexingThread(cloudClient.getHttpClient(), controlClient, cloudClient, clients, \"ft1\", true, this.clientSoTimeout);\n        ftIndexThread.start();\n      }\n      \n      chaosMonkey.startTheMonkey(true, 10000);\n      try {\n        long runLength;\n        if (RUN_LENGTH != -1) {\n          runLength = RUN_LENGTH;\n        } else {\n          int[] runTimes;\n          if (TEST_NIGHTLY) {\n            runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n                30000, 45000, 90000, 120000};\n          } else {\n            runTimes = new int[] {5000, 7000, 10000};\n          }\n          runLength = runTimes[random().nextInt(runTimes.length - 1)];\n        }\n        ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, zkStateReader);\n      } finally {\n        chaosMonkey.stopTheMonkey();\n      }\n\n      // ideally this should go into chaosMonkey\n      restartZk(1000 * (5 + random().nextInt(4)));\n\n      if (runFullThrottle) {\n        ftIndexThread.safeStop();\n      }\n      \n      for (StoppableThread indexThread : threads) {\n        indexThread.safeStop();\n      }\n      \n      // start any downed jetties to be sure we still will end up with a leader per shard...\n      \n      // wait for stop...\n      for (StoppableThread indexThread : threads) {\n        indexThread.join();\n      }\n      \n      // try and wait for any replications and what not to finish...\n      \n      ChaosMonkey.wait(2000, DEFAULT_COLLECTION, zkStateReader);\n      \n      // wait until there are no recoveries...\n      waitForThingsToLevelOut(Integer.MAX_VALUE);//Math.round((runLength / 1000.0f / 3.0f)));\n      \n      // make sure we again have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 30000);\n      }\n      \n      commit();\n      \n      // TODO: assert we didnt kill everyone\n      \n      zkStateReader.updateLiveNodes();\n      assertTrue(zkStateReader.getClusterState().getLiveNodes().size() > 0);\n      \n      \n      // we expect full throttle fails, but cloud client should not easily fail\n      for (StoppableThread indexThread : threads) {\n        if (indexThread instanceof StoppableIndexingThread && !(indexThread instanceof FullThrottleStoppableIndexingThread)) {\n          int failCount = ((StoppableIndexingThread) indexThread).getFailCount();\n          assertFalse(\"There were too many update fails (\" + failCount + \" > \" + FAIL_TOLERANCE\n              + \") - we expect it can happen, but shouldn't easily\", failCount > FAIL_TOLERANCE);\n        }\n      }\n      \n      waitForReplicationFromReplicas(DEFAULT_COLLECTION, zkStateReader, new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME));\n//      waitForAllWarmingSearchers();\n      \n      Set<String> addFails = getAddFails(indexTreads);\n      Set<String> deleteFails = getDeleteFails(indexTreads);\n      // full throttle thread can\n      // have request fails\n      checkShardConsistency(!runFullThrottle, true, addFails, deleteFails);      \n      \n      long ctrlDocs = controlClient.query(new SolrQuery(\"*:*\")).getResults()\n      .getNumFound(); \n      \n      // ensure we have added more than 0 docs\n      long cloudClientDocs = cloudClient.query(new SolrQuery(\"*:*\"))\n          .getResults().getNumFound();\n      \n      assertTrue(\"Found \" + ctrlDocs + \" control docs\", cloudClientDocs > 0);\n      \n      log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n      \n      if (VERBOSE) System.out.println(\"control docs:\"\n          + controlClient.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound() + \"\\n\\n\");\n      \n      // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n      // sometimes we restart zookeeper as well\n      if (random().nextBoolean()) {\n        restartZk(1000 * (5 + random().nextInt(4)));\n      }\n\n      try (CloudSolrClient client = createCloudClient(\"collection1\", 30000)) {\n        // We don't really know how many live nodes we have at this point, so \"maxShardsPerNode\" needs to be > 1\n        createCollection(null, \"testcollection\",\n              1, 1, 10, client, null, \"conf1\"); \n      }\n      List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n      numShardsNumReplicas.add(1);\n      numShardsNumReplicas.add(1 + getPullReplicaCount());\n      checkForCollection(\"testcollection\", numShardsNumReplicas, null);\n      \n      testSuccessful = true;\n    } finally {\n      if (!testSuccessful) {\n        logReplicaTypesReplicationInfo(DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n        printLayout();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a966532d92cf9ba2856f15a8140151bb6b518e4b","date":1588290631,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    // None of the operations used here are particularly costly, so this should work.\n    // Using this low timeout will also help us catch index stalling.\n    clientSoTimeout = 8000;\n\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    \n    boolean testSuccessful = false;\n    try {\n      handle.clear();\n      handle.put(\"timestamp\", SKIPVAL);\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      // make sure we have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n      }      // make sure we again have leaders for each shard\n      \n      waitForRecoveriesToFinish(false);\n\n      del(\"*:*\");\n      \n      List<StoppableThread> threads = new ArrayList<>();\n      List<StoppableIndexingThread> indexTreads = new ArrayList<>();\n      int threadCount = TEST_NIGHTLY ? 3 : 1;\n      int i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, 35, 1, true);\n        threads.add(indexThread);\n        indexTreads.add(indexThread);\n        indexThread.start();\n      }\n      \n      threadCount = 1;\n      i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableSearchThread searchThread = new StoppableSearchThread(cloudClient);\n        threads.add(searchThread);\n        searchThread.start();\n      }\n      \n      if (usually()) {\n        StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n        threads.add(commitThread);\n        commitThread.start();\n      }\n      \n      if (runFullThrottle) {\n        ftIndexThread = \n            new FullThrottleStoppableIndexingThread(cloudClient.getHttpClient(), controlClient, cloudClient, clients, \"ft1\", true, this.clientSoTimeout);\n        ftIndexThread.start();\n      }\n      \n      chaosMonkey.startTheMonkey(true, 10000);\n      try {\n        long runLength;\n        if (RUN_LENGTH != -1) {\n          runLength = RUN_LENGTH;\n        } else {\n          int[] runTimes;\n          if (TEST_NIGHTLY) {\n            runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n                30000, 45000, 90000, 120000};\n          } else {\n            runTimes = new int[] {5000, 7000, 10000};\n          }\n          runLength = runTimes[random().nextInt(runTimes.length - 1)];\n        }\n        ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, zkStateReader);\n      } finally {\n        chaosMonkey.stopTheMonkey();\n      }\n\n      // ideally this should go into chaosMonkey\n      restartZk(1000 * (5 + random().nextInt(4)));\n\n      if (runFullThrottle) {\n        ftIndexThread.safeStop();\n      }\n      \n      for (StoppableThread indexThread : threads) {\n        indexThread.safeStop();\n      }\n      \n      // start any downed jetties to be sure we still will end up with a leader per shard...\n      \n      // wait for stop...\n      for (StoppableThread indexThread : threads) {\n        indexThread.join();\n      }\n      \n      // try and wait for any replications and what not to finish...\n      \n      ChaosMonkey.wait(2000, DEFAULT_COLLECTION, zkStateReader);\n      \n      // wait until there are no recoveries...\n      waitForThingsToLevelOut();\n      \n      // make sure we again have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 30000);\n      }\n      \n      commit();\n      \n      // TODO: assert we didnt kill everyone\n      \n      zkStateReader.updateLiveNodes();\n      assertTrue(zkStateReader.getClusterState().getLiveNodes().size() > 0);\n      \n      \n      // we expect full throttle fails, but cloud client should not easily fail\n      for (StoppableThread indexThread : threads) {\n        if (indexThread instanceof StoppableIndexingThread && !(indexThread instanceof FullThrottleStoppableIndexingThread)) {\n          int failCount = ((StoppableIndexingThread) indexThread).getFailCount();\n          assertFalse(\"There were too many update fails (\" + failCount + \" > \" + FAIL_TOLERANCE\n              + \") - we expect it can happen, but shouldn't easily\", failCount > FAIL_TOLERANCE);\n        }\n      }\n      \n      waitForReplicationFromReplicas(DEFAULT_COLLECTION, zkStateReader, new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME));\n//      waitForAllWarmingSearchers();\n      \n      Set<String> addFails = getAddFails(indexTreads);\n      Set<String> deleteFails = getDeleteFails(indexTreads);\n      // full throttle thread can\n      // have request fails\n      checkShardConsistency(!runFullThrottle, true, addFails, deleteFails);      \n      \n      long ctrlDocs = controlClient.query(new SolrQuery(\"*:*\")).getResults()\n      .getNumFound(); \n      \n      // ensure we have added more than 0 docs\n      long cloudClientDocs = cloudClient.query(new SolrQuery(\"*:*\"))\n          .getResults().getNumFound();\n      \n      assertTrue(\"Found \" + ctrlDocs + \" control docs\", cloudClientDocs > 0);\n\n      if (log.isInfoEnabled()) {\n        log.info(\"collection state: {}\", printClusterStateInfo(DEFAULT_COLLECTION));\n      }\n      \n      if (VERBOSE) System.out.println(\"control docs:\"\n          + controlClient.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound() + \"\\n\\n\");\n      \n      // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n      // sometimes we restart zookeeper as well\n      if (random().nextBoolean()) {\n        restartZk(1000 * (5 + random().nextInt(4)));\n      }\n\n      try (CloudSolrClient client = createCloudClient(\"collection1\", 30000)) {\n        // We don't really know how many live nodes we have at this point, so \"maxShardsPerNode\" needs to be > 1\n        createCollection(null, \"testcollection\",\n              1, 1, 10, client, null, \"conf1\"); \n      }\n      List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n      numShardsNumReplicas.add(1);\n      numShardsNumReplicas.add(1 + getPullReplicaCount());\n      checkForCollection(\"testcollection\", numShardsNumReplicas, null);\n      \n      testSuccessful = true;\n    } finally {\n      if (!testSuccessful) {\n        logReplicaTypesReplicationInfo(DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n        printLayout();\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    // None of the operations used here are particularly costly, so this should work.\n    // Using this low timeout will also help us catch index stalling.\n    clientSoTimeout = 8000;\n\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    \n    boolean testSuccessful = false;\n    try {\n      handle.clear();\n      handle.put(\"timestamp\", SKIPVAL);\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      // make sure we have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n      }      // make sure we again have leaders for each shard\n      \n      waitForRecoveriesToFinish(false);\n\n      del(\"*:*\");\n      \n      List<StoppableThread> threads = new ArrayList<>();\n      List<StoppableIndexingThread> indexTreads = new ArrayList<>();\n      int threadCount = TEST_NIGHTLY ? 3 : 1;\n      int i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, 35, 1, true);\n        threads.add(indexThread);\n        indexTreads.add(indexThread);\n        indexThread.start();\n      }\n      \n      threadCount = 1;\n      i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableSearchThread searchThread = new StoppableSearchThread(cloudClient);\n        threads.add(searchThread);\n        searchThread.start();\n      }\n      \n      if (usually()) {\n        StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n        threads.add(commitThread);\n        commitThread.start();\n      }\n      \n      if (runFullThrottle) {\n        ftIndexThread = \n            new FullThrottleStoppableIndexingThread(cloudClient.getHttpClient(), controlClient, cloudClient, clients, \"ft1\", true, this.clientSoTimeout);\n        ftIndexThread.start();\n      }\n      \n      chaosMonkey.startTheMonkey(true, 10000);\n      try {\n        long runLength;\n        if (RUN_LENGTH != -1) {\n          runLength = RUN_LENGTH;\n        } else {\n          int[] runTimes;\n          if (TEST_NIGHTLY) {\n            runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n                30000, 45000, 90000, 120000};\n          } else {\n            runTimes = new int[] {5000, 7000, 10000};\n          }\n          runLength = runTimes[random().nextInt(runTimes.length - 1)];\n        }\n        ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, zkStateReader);\n      } finally {\n        chaosMonkey.stopTheMonkey();\n      }\n\n      // ideally this should go into chaosMonkey\n      restartZk(1000 * (5 + random().nextInt(4)));\n\n      if (runFullThrottle) {\n        ftIndexThread.safeStop();\n      }\n      \n      for (StoppableThread indexThread : threads) {\n        indexThread.safeStop();\n      }\n      \n      // start any downed jetties to be sure we still will end up with a leader per shard...\n      \n      // wait for stop...\n      for (StoppableThread indexThread : threads) {\n        indexThread.join();\n      }\n      \n      // try and wait for any replications and what not to finish...\n      \n      ChaosMonkey.wait(2000, DEFAULT_COLLECTION, zkStateReader);\n      \n      // wait until there are no recoveries...\n      waitForThingsToLevelOut();\n      \n      // make sure we again have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 30000);\n      }\n      \n      commit();\n      \n      // TODO: assert we didnt kill everyone\n      \n      zkStateReader.updateLiveNodes();\n      assertTrue(zkStateReader.getClusterState().getLiveNodes().size() > 0);\n      \n      \n      // we expect full throttle fails, but cloud client should not easily fail\n      for (StoppableThread indexThread : threads) {\n        if (indexThread instanceof StoppableIndexingThread && !(indexThread instanceof FullThrottleStoppableIndexingThread)) {\n          int failCount = ((StoppableIndexingThread) indexThread).getFailCount();\n          assertFalse(\"There were too many update fails (\" + failCount + \" > \" + FAIL_TOLERANCE\n              + \") - we expect it can happen, but shouldn't easily\", failCount > FAIL_TOLERANCE);\n        }\n      }\n      \n      waitForReplicationFromReplicas(DEFAULT_COLLECTION, zkStateReader, new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME));\n//      waitForAllWarmingSearchers();\n      \n      Set<String> addFails = getAddFails(indexTreads);\n      Set<String> deleteFails = getDeleteFails(indexTreads);\n      // full throttle thread can\n      // have request fails\n      checkShardConsistency(!runFullThrottle, true, addFails, deleteFails);      \n      \n      long ctrlDocs = controlClient.query(new SolrQuery(\"*:*\")).getResults()\n      .getNumFound(); \n      \n      // ensure we have added more than 0 docs\n      long cloudClientDocs = cloudClient.query(new SolrQuery(\"*:*\"))\n          .getResults().getNumFound();\n      \n      assertTrue(\"Found \" + ctrlDocs + \" control docs\", cloudClientDocs > 0);\n      \n      log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n      \n      if (VERBOSE) System.out.println(\"control docs:\"\n          + controlClient.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound() + \"\\n\\n\");\n      \n      // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n      // sometimes we restart zookeeper as well\n      if (random().nextBoolean()) {\n        restartZk(1000 * (5 + random().nextInt(4)));\n      }\n\n      try (CloudSolrClient client = createCloudClient(\"collection1\", 30000)) {\n        // We don't really know how many live nodes we have at this point, so \"maxShardsPerNode\" needs to be > 1\n        createCollection(null, \"testcollection\",\n              1, 1, 10, client, null, \"conf1\"); \n      }\n      List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n      numShardsNumReplicas.add(1);\n      numShardsNumReplicas.add(1 + getPullReplicaCount());\n      checkForCollection(\"testcollection\", numShardsNumReplicas, null);\n      \n      testSuccessful = true;\n    } finally {\n      if (!testSuccessful) {\n        logReplicaTypesReplicationInfo(DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n        printLayout();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e","date":1594223844,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    // None of the operations used here are particularly costly, so this should work.\n    // Using this low timeout will also help us catch index stalling.\n    clientSoTimeout = 8000;\n\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    \n    boolean testSuccessful = false;\n    try {\n      handle.clear();\n      handle.put(\"timestamp\", SKIPVAL);\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      // make sure we have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n      }      // make sure we again have leaders for each shard\n      \n      waitForRecoveriesToFinish(false);\n\n      del(\"*:*\");\n      \n      List<StoppableThread> threads = new ArrayList<>();\n      List<StoppableIndexingThread> indexTreads = new ArrayList<>();\n      int threadCount = TEST_NIGHTLY ? 3 : 1;\n      int i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, 35, 1, true);\n        threads.add(indexThread);\n        indexTreads.add(indexThread);\n        indexThread.start();\n      }\n      \n      threadCount = 1;\n      i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableSearchThread searchThread = new StoppableSearchThread(cloudClient);\n        threads.add(searchThread);\n        searchThread.start();\n      }\n      \n      if (usually()) {\n        StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n        threads.add(commitThread);\n        commitThread.start();\n      }\n      \n      if (runFullThrottle) {\n        ftIndexThread = \n            new FullThrottleStoppableIndexingThread(cloudClient.getHttpClient(), controlClient, cloudClient, clients, \"ft1\", true, this.clientSoTimeout);\n        ftIndexThread.start();\n      }\n      \n      chaosMonkey.startTheMonkey(true, 10000);\n      try {\n        long runLength;\n        if (RUN_LENGTH != -1) {\n          runLength = RUN_LENGTH;\n        } else {\n          int[] runTimes;\n          if (TEST_NIGHTLY) {\n            runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n                30000, 45000, 90000, 120000};\n          } else {\n            runTimes = new int[] {5000, 7000, 10000};\n          }\n          runLength = runTimes[random().nextInt(runTimes.length - 1)];\n        }\n        ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, zkStateReader);\n      } finally {\n        chaosMonkey.stopTheMonkey();\n      }\n\n      // ideally this should go into chaosMonkey\n      restartZk(1000 * (5 + random().nextInt(4)));\n\n      if (runFullThrottle) {\n        ftIndexThread.safeStop();\n      }\n      \n      for (StoppableThread indexThread : threads) {\n        indexThread.safeStop();\n      }\n      \n      // start any downed jetties to be sure we still will end up with a leader per shard...\n      \n      // wait for stop...\n      for (StoppableThread indexThread : threads) {\n        indexThread.join();\n      }\n      \n      // try and wait for any replications and what not to finish...\n      \n      ChaosMonkey.wait(2000, DEFAULT_COLLECTION, zkStateReader);\n      \n      // wait until there are no recoveries...\n      waitForThingsToLevelOut();\n      \n      // make sure we again have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 30000);\n      }\n      \n      commit();\n      \n      // TODO: assert we didnt kill everyone\n      \n      zkStateReader.updateLiveNodes();\n      assertTrue(zkStateReader.getClusterState().getLiveNodes().size() > 0);\n      \n      \n      // we expect full throttle fails, but cloud client should not easily fail\n      for (StoppableThread indexThread : threads) {\n        if (indexThread instanceof StoppableIndexingThread && !(indexThread instanceof FullThrottleStoppableIndexingThread)) {\n          int failCount = ((StoppableIndexingThread) indexThread).getFailCount();\n          assertFalse(\"There were too many update fails (\" + failCount + \" > \" + FAIL_TOLERANCE\n              + \") - we expect it can happen, but shouldn't easily\", failCount > FAIL_TOLERANCE);\n        }\n      }\n      \n      waitForReplicationFromReplicas(DEFAULT_COLLECTION, zkStateReader, new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME));\n//      waitForAllWarmingSearchers();\n      \n      Set<String> addFails = getAddFails(indexTreads);\n      Set<String> deleteFails = getDeleteFails(indexTreads);\n      // full throttle thread can\n      // have request fails\n      checkShardConsistency(!runFullThrottle, true, addFails, deleteFails);      \n      \n      long ctrlDocs = controlClient.query(new SolrQuery(\"*:*\")).getResults()\n      .getNumFound(); \n      \n      // ensure we have added more than 0 docs\n      long cloudClientDocs = cloudClient.query(new SolrQuery(\"*:*\"))\n          .getResults().getNumFound();\n      \n      assertTrue(\"Found \" + ctrlDocs + \" control docs\", cloudClientDocs > 0);\n\n      if (log.isInfoEnabled()) {\n        log.info(\"collection state: {}\", printClusterStateInfo(DEFAULT_COLLECTION));\n      }\n      \n      if (VERBOSE) System.out.println(\"control docs:\"\n          + controlClient.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound() + \"\\n\\n\");\n      \n      // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n      // sometimes we restart zookeeper as well\n      if (random().nextBoolean()) {\n        restartZk(1000 * (5 + random().nextInt(4)));\n      }\n\n      try (CloudSolrClient client = createCloudClient(\"collection1\", 30000)) {\n        createCollection(null, \"testcollection\",\n              1, 1, client, null, \"conf1\");\n      }\n      List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n      numShardsNumReplicas.add(1);\n      numShardsNumReplicas.add(1 + getPullReplicaCount());\n      checkForCollection(\"testcollection\", numShardsNumReplicas, null);\n      \n      testSuccessful = true;\n    } finally {\n      if (!testSuccessful) {\n        logReplicaTypesReplicationInfo(DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n        printLayout();\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    // None of the operations used here are particularly costly, so this should work.\n    // Using this low timeout will also help us catch index stalling.\n    clientSoTimeout = 8000;\n\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    \n    boolean testSuccessful = false;\n    try {\n      handle.clear();\n      handle.put(\"timestamp\", SKIPVAL);\n      ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n      // make sure we have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 10000);\n      }      // make sure we again have leaders for each shard\n      \n      waitForRecoveriesToFinish(false);\n\n      del(\"*:*\");\n      \n      List<StoppableThread> threads = new ArrayList<>();\n      List<StoppableIndexingThread> indexTreads = new ArrayList<>();\n      int threadCount = TEST_NIGHTLY ? 3 : 1;\n      int i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, 35, 1, true);\n        threads.add(indexThread);\n        indexTreads.add(indexThread);\n        indexThread.start();\n      }\n      \n      threadCount = 1;\n      i = 0;\n      for (i = 0; i < threadCount; i++) {\n        StoppableSearchThread searchThread = new StoppableSearchThread(cloudClient);\n        threads.add(searchThread);\n        searchThread.start();\n      }\n      \n      if (usually()) {\n        StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n        threads.add(commitThread);\n        commitThread.start();\n      }\n      \n      if (runFullThrottle) {\n        ftIndexThread = \n            new FullThrottleStoppableIndexingThread(cloudClient.getHttpClient(), controlClient, cloudClient, clients, \"ft1\", true, this.clientSoTimeout);\n        ftIndexThread.start();\n      }\n      \n      chaosMonkey.startTheMonkey(true, 10000);\n      try {\n        long runLength;\n        if (RUN_LENGTH != -1) {\n          runLength = RUN_LENGTH;\n        } else {\n          int[] runTimes;\n          if (TEST_NIGHTLY) {\n            runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n                30000, 45000, 90000, 120000};\n          } else {\n            runTimes = new int[] {5000, 7000, 10000};\n          }\n          runLength = runTimes[random().nextInt(runTimes.length - 1)];\n        }\n        ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, zkStateReader);\n      } finally {\n        chaosMonkey.stopTheMonkey();\n      }\n\n      // ideally this should go into chaosMonkey\n      restartZk(1000 * (5 + random().nextInt(4)));\n\n      if (runFullThrottle) {\n        ftIndexThread.safeStop();\n      }\n      \n      for (StoppableThread indexThread : threads) {\n        indexThread.safeStop();\n      }\n      \n      // start any downed jetties to be sure we still will end up with a leader per shard...\n      \n      // wait for stop...\n      for (StoppableThread indexThread : threads) {\n        indexThread.join();\n      }\n      \n      // try and wait for any replications and what not to finish...\n      \n      ChaosMonkey.wait(2000, DEFAULT_COLLECTION, zkStateReader);\n      \n      // wait until there are no recoveries...\n      waitForThingsToLevelOut();\n      \n      // make sure we again have leaders for each shard\n      for (int j = 1; j < sliceCount; j++) {\n        zkStateReader.getLeaderRetry(DEFAULT_COLLECTION, \"shard\" + j, 30000);\n      }\n      \n      commit();\n      \n      // TODO: assert we didnt kill everyone\n      \n      zkStateReader.updateLiveNodes();\n      assertTrue(zkStateReader.getClusterState().getLiveNodes().size() > 0);\n      \n      \n      // we expect full throttle fails, but cloud client should not easily fail\n      for (StoppableThread indexThread : threads) {\n        if (indexThread instanceof StoppableIndexingThread && !(indexThread instanceof FullThrottleStoppableIndexingThread)) {\n          int failCount = ((StoppableIndexingThread) indexThread).getFailCount();\n          assertFalse(\"There were too many update fails (\" + failCount + \" > \" + FAIL_TOLERANCE\n              + \") - we expect it can happen, but shouldn't easily\", failCount > FAIL_TOLERANCE);\n        }\n      }\n      \n      waitForReplicationFromReplicas(DEFAULT_COLLECTION, zkStateReader, new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME));\n//      waitForAllWarmingSearchers();\n      \n      Set<String> addFails = getAddFails(indexTreads);\n      Set<String> deleteFails = getDeleteFails(indexTreads);\n      // full throttle thread can\n      // have request fails\n      checkShardConsistency(!runFullThrottle, true, addFails, deleteFails);      \n      \n      long ctrlDocs = controlClient.query(new SolrQuery(\"*:*\")).getResults()\n      .getNumFound(); \n      \n      // ensure we have added more than 0 docs\n      long cloudClientDocs = cloudClient.query(new SolrQuery(\"*:*\"))\n          .getResults().getNumFound();\n      \n      assertTrue(\"Found \" + ctrlDocs + \" control docs\", cloudClientDocs > 0);\n\n      if (log.isInfoEnabled()) {\n        log.info(\"collection state: {}\", printClusterStateInfo(DEFAULT_COLLECTION));\n      }\n      \n      if (VERBOSE) System.out.println(\"control docs:\"\n          + controlClient.query(new SolrQuery(\"*:*\")).getResults()\n              .getNumFound() + \"\\n\\n\");\n      \n      // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n      // sometimes we restart zookeeper as well\n      if (random().nextBoolean()) {\n        restartZk(1000 * (5 + random().nextInt(4)));\n      }\n\n      try (CloudSolrClient client = createCloudClient(\"collection1\", 30000)) {\n        // We don't really know how many live nodes we have at this point, so \"maxShardsPerNode\" needs to be > 1\n        createCollection(null, \"testcollection\",\n              1, 1, 10, client, null, \"conf1\"); \n      }\n      List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n      numShardsNumReplicas.add(1);\n      numShardsNumReplicas.add(1 + getPullReplicaCount());\n      checkForCollection(\"testcollection\", numShardsNumReplicas, null);\n      \n      testSuccessful = true;\n    } finally {\n      if (!testSuccessful) {\n        logReplicaTypesReplicationInfo(DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n        printLayout();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"61c45e99cf6676da48f19d7511c73712ad39402b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"f344bb33ca91f48e99c061980115b46fa84fc8f5":["61c45e99cf6676da48f19d7511c73712ad39402b","73a4df49bbf08e66754aaad0861f9627c0276cc2"],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["add1e7dd742ea533ff4318cea83ca0a1f669f662"],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["a966532d92cf9ba2856f15a8140151bb6b518e4b"],"28288370235ed02234a64753cdbf0c6ec096304a":["61c45e99cf6676da48f19d7511c73712ad39402b","f344bb33ca91f48e99c061980115b46fa84fc8f5"],"43d1e498704edd2bba13548a189eed4dfccff11b":["28288370235ed02234a64753cdbf0c6ec096304a"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","61c45e99cf6676da48f19d7511c73712ad39402b"],"d2f514ff99d806c2911cbc0e81d02d3d756e0ae6":["43d1e498704edd2bba13548a189eed4dfccff11b"],"2ea161f828a3a7a6eb9410a431aecda6d7ab1065":["2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9","43d1e498704edd2bba13548a189eed4dfccff11b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"add1e7dd742ea533ff4318cea83ca0a1f669f662":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"e73d8d559120669b47658108d818b637df5456ea":["2ea161f828a3a7a6eb9410a431aecda6d7ab1065","d2f514ff99d806c2911cbc0e81d02d3d756e0ae6"],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["d2f514ff99d806c2911cbc0e81d02d3d756e0ae6"],"73a4df49bbf08e66754aaad0861f9627c0276cc2":["61c45e99cf6676da48f19d7511c73712ad39402b"],"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9":["e9017cf144952056066919f1ebc7897ff9bd71b1","f344bb33ca91f48e99c061980115b46fa84fc8f5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"]},"commit2Childs":{"61c45e99cf6676da48f19d7511c73712ad39402b":["f344bb33ca91f48e99c061980115b46fa84fc8f5","28288370235ed02234a64753cdbf0c6ec096304a","e9017cf144952056066919f1ebc7897ff9bd71b1","73a4df49bbf08e66754aaad0861f9627c0276cc2"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["add1e7dd742ea533ff4318cea83ca0a1f669f662"],"f344bb33ca91f48e99c061980115b46fa84fc8f5":["28288370235ed02234a64753cdbf0c6ec096304a","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9"],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"28288370235ed02234a64753cdbf0c6ec096304a":["43d1e498704edd2bba13548a189eed4dfccff11b"],"43d1e498704edd2bba13548a189eed4dfccff11b":["d2f514ff99d806c2911cbc0e81d02d3d756e0ae6","2ea161f828a3a7a6eb9410a431aecda6d7ab1065"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9"],"d2f514ff99d806c2911cbc0e81d02d3d756e0ae6":["e73d8d559120669b47658108d818b637df5456ea","1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"2ea161f828a3a7a6eb9410a431aecda6d7ab1065":["e73d8d559120669b47658108d818b637df5456ea"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["61c45e99cf6676da48f19d7511c73712ad39402b","e9017cf144952056066919f1ebc7897ff9bd71b1"],"add1e7dd742ea533ff4318cea83ca0a1f669f662":["a966532d92cf9ba2856f15a8140151bb6b518e4b"],"e73d8d559120669b47658108d818b637df5456ea":[],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"73a4df49bbf08e66754aaad0861f9627c0276cc2":["f344bb33ca91f48e99c061980115b46fa84fc8f5"],"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9":["2ea161f828a3a7a6eb9410a431aecda6d7ab1065"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["e73d8d559120669b47658108d818b637df5456ea","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}