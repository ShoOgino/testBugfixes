{"path":"lucene/core/src/java/org/apache/lucene/analysis/Token#clone(char[],int,int,int,int).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/Token#clone(char[],int,int,int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/analysis/Token#clone(char[],int,int,int,int).mjava","sourceNew":"  /** Makes a clone, but replaces the term buffer &\n   * start/end offset in the process.  This is more\n   * efficient than doing a full clone (and then calling\n   * {@link #copyBuffer}) because it saves a wasted copy of the old\n   * termBuffer. */\n  public Token clone(char[] newTermBuffer, int newTermOffset, int newTermLength, int newStartOffset, int newEndOffset) {\n    final Token t = new Token(newTermBuffer, newTermOffset, newTermLength, newStartOffset, newEndOffset);\n    t.positionIncrement = positionIncrement;\n    t.flags = flags;\n    t.type = type;\n    if (payload != null)\n      t.payload = (Payload) payload.clone();\n    return t;\n  }\n\n","sourceOld":"  /** Makes a clone, but replaces the term buffer &\n   * start/end offset in the process.  This is more\n   * efficient than doing a full clone (and then calling\n   * {@link #copyBuffer}) because it saves a wasted copy of the old\n   * termBuffer. */\n  public Token clone(char[] newTermBuffer, int newTermOffset, int newTermLength, int newStartOffset, int newEndOffset) {\n    final Token t = new Token(newTermBuffer, newTermOffset, newTermLength, newStartOffset, newEndOffset);\n    t.positionIncrement = positionIncrement;\n    t.flags = flags;\n    t.type = type;\n    if (payload != null)\n      t.payload = (Payload) payload.clone();\n    return t;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"399d5903979ca52514d2bc7e3a362e1c45885c94","date":1333042474,"type":3,"author":"Ryan McKinley","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/Token#clone(char[],int,int,int,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/Token#clone(char[],int,int,int,int).mjava","sourceNew":"  /** Makes a clone, but replaces the term buffer &\n   * start/end offset in the process.  This is more\n   * efficient than doing a full clone (and then calling\n   * {@link #copyBuffer}) because it saves a wasted copy of the old\n   * termBuffer. */\n  public Token clone(char[] newTermBuffer, int newTermOffset, int newTermLength, int newStartOffset, int newEndOffset) {\n    final Token t = new Token(newTermBuffer, newTermOffset, newTermLength, newStartOffset, newEndOffset);\n    t.positionIncrement = positionIncrement;\n    t.flags = flags;\n    t.type = type;\n    if (payload != null)\n      t.payload = payload.clone();\n    return t;\n  }\n\n","sourceOld":"  /** Makes a clone, but replaces the term buffer &\n   * start/end offset in the process.  This is more\n   * efficient than doing a full clone (and then calling\n   * {@link #copyBuffer}) because it saves a wasted copy of the old\n   * termBuffer. */\n  public Token clone(char[] newTermBuffer, int newTermOffset, int newTermLength, int newStartOffset, int newEndOffset) {\n    final Token t = new Token(newTermBuffer, newTermOffset, newTermLength, newStartOffset, newEndOffset);\n    t.positionIncrement = positionIncrement;\n    t.flags = flags;\n    t.type = type;\n    if (payload != null)\n      t.payload = (Payload) payload.clone();\n    return t;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b01ceb41370c7281988f8a8b6ae62fc15d5d8de1","date":1399070016,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/Token#clone(char[],int,int,int,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/Token#clone(char[],int,int,int,int).mjava","sourceNew":"  /** Makes a clone, but replaces the term buffer &\n   * start/end offset in the process.  This is more\n   * efficient than doing a full clone (and then calling\n   * {@link #copyBuffer}) because it saves a wasted copy of the old\n   * termBuffer. */\n  public Token clone(char[] newTermBuffer, int newTermOffset, int newTermLength, int newStartOffset, int newEndOffset) {\n    final Token t = new Token(newTermBuffer, newTermOffset, newTermLength, newStartOffset, newEndOffset);\n    t.positionIncrement = positionIncrement;\n    t.positionLength = positionLength;\n    t.flags = flags;\n    t.type = type;\n    if (payload != null)\n      t.payload = payload.clone();\n    return t;\n  }\n\n","sourceOld":"  /** Makes a clone, but replaces the term buffer &\n   * start/end offset in the process.  This is more\n   * efficient than doing a full clone (and then calling\n   * {@link #copyBuffer}) because it saves a wasted copy of the old\n   * termBuffer. */\n  public Token clone(char[] newTermBuffer, int newTermOffset, int newTermLength, int newStartOffset, int newEndOffset) {\n    final Token t = new Token(newTermBuffer, newTermOffset, newTermLength, newStartOffset, newEndOffset);\n    t.positionIncrement = positionIncrement;\n    t.flags = flags;\n    t.type = type;\n    if (payload != null)\n      t.payload = payload.clone();\n    return t;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"93124590c6e2a8b45898cbae46f96c3a05d9bce0","date":1399415098,"type":4,"author":"Uwe Schindler","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/Token#clone(char[],int,int,int,int).mjava","sourceNew":null,"sourceOld":"  /** Makes a clone, but replaces the term buffer &\n   * start/end offset in the process.  This is more\n   * efficient than doing a full clone (and then calling\n   * {@link #copyBuffer}) because it saves a wasted copy of the old\n   * termBuffer. */\n  public Token clone(char[] newTermBuffer, int newTermOffset, int newTermLength, int newStartOffset, int newEndOffset) {\n    final Token t = new Token(newTermBuffer, newTermOffset, newTermLength, newStartOffset, newEndOffset);\n    t.positionIncrement = positionIncrement;\n    t.positionLength = positionLength;\n    t.flags = flags;\n    t.type = type;\n    if (payload != null)\n      t.payload = payload.clone();\n    return t;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"93124590c6e2a8b45898cbae46f96c3a05d9bce0":["b01ceb41370c7281988f8a8b6ae62fc15d5d8de1"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"399d5903979ca52514d2bc7e3a362e1c45885c94":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"b01ceb41370c7281988f8a8b6ae62fc15d5d8de1":["399d5903979ca52514d2bc7e3a362e1c45885c94"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["93124590c6e2a8b45898cbae46f96c3a05d9bce0"]},"commit2Childs":{"93124590c6e2a8b45898cbae46f96c3a05d9bce0":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["399d5903979ca52514d2bc7e3a362e1c45885c94"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"399d5903979ca52514d2bc7e3a362e1c45885c94":["b01ceb41370c7281988f8a8b6ae62fc15d5d8de1"],"b01ceb41370c7281988f8a8b6ae62fc15d5d8de1":["93124590c6e2a8b45898cbae46f96c3a05d9bce0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}