{"path":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","commits":[{"id":"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","date":1306767085,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"677ef223addbbe52657b204d45bfd69e2d621712","date":1319729054,"type":3,"author":"Erik Hatcher","isMerge":false,"pathNew":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2e482dd77e4215fccdb2b14a365f859e3b43b931","date":1325056675,"type":3,"author":"Koji Sekiguchi","isMerge":false,"pathNew":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(Metadata.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db36cab313d5b26c5e9f23f828d863efc8b0281b","date":1327501086,"type":3,"author":"Jan Høydahl","isMerge":false,"pathNew":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(Metadata.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(Metadata.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(Metadata.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","date":1327523564,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(Metadata.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(Metadata.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(Metadata.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0d22ac6a4146774c1bc8400160fc0b6150294e92","date":1327528604,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(Metadata.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(Metadata.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(Metadata.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f08557cdb6c60ac7b88a9342c983a20cd236e74f","date":1330954480,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(Metadata.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(Metadata.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","date":1331075828,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(Metadata.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(Metadata.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"042e4d934397657ba04c82b46cc5665076bc5c58","date":1336511170,"type":5,"author":"Ryan McKinley","isMerge":false,"pathNew":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream,UpdateRequestProcessor).mjava","pathOld":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp,\n      ContentStream stream, UpdateRequestProcessor processor) throws Exception {\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0d22ac6a4146774c1bc8400160fc0b6150294e92":["2e482dd77e4215fccdb2b14a365f859e3b43b931","db36cab313d5b26c5e9f23f828d863efc8b0281b"],"db36cab313d5b26c5e9f23f828d863efc8b0281b":["2e482dd77e4215fccdb2b14a365f859e3b43b931"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":["db36cab313d5b26c5e9f23f828d863efc8b0281b","f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"042e4d934397657ba04c82b46cc5665076bc5c58":["f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["db36cab313d5b26c5e9f23f828d863efc8b0281b"],"c26f00b574427b55127e869b935845554afde1fa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","5128b7b3b73fedff05fdc5ea2e6be53c1020bb91"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d":["2e482dd77e4215fccdb2b14a365f859e3b43b931","db36cab313d5b26c5e9f23f828d863efc8b0281b"],"677ef223addbbe52657b204d45bfd69e2d621712":["c26f00b574427b55127e869b935845554afde1fa"],"2e482dd77e4215fccdb2b14a365f859e3b43b931":["677ef223addbbe52657b204d45bfd69e2d621712"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["042e4d934397657ba04c82b46cc5665076bc5c58"]},"commit2Childs":{"0d22ac6a4146774c1bc8400160fc0b6150294e92":[],"db36cab313d5b26c5e9f23f828d863efc8b0281b":["0d22ac6a4146774c1bc8400160fc0b6150294e92","9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","f08557cdb6c60ac7b88a9342c983a20cd236e74f","a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":[],"042e4d934397657ba04c82b46cc5665076bc5c58":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":["c26f00b574427b55127e869b935845554afde1fa"],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","042e4d934397657ba04c82b46cc5665076bc5c58"],"c26f00b574427b55127e869b935845554afde1fa":["677ef223addbbe52657b204d45bfd69e2d621712"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","c26f00b574427b55127e869b935845554afde1fa"],"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d":[],"677ef223addbbe52657b204d45bfd69e2d621712":["2e482dd77e4215fccdb2b14a365f859e3b43b931"],"2e482dd77e4215fccdb2b14a365f859e3b43b931":["0d22ac6a4146774c1bc8400160fc0b6150294e92","db36cab313d5b26c5e9f23f828d863efc8b0281b","a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["0d22ac6a4146774c1bc8400160fc0b6150294e92","9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}