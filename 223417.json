{"path":"lucene/src/test-framework/org/apache/lucene/analysis/MockAnalyzer#createComponents(String,Reader).mjava","commits":[{"id":"53ae89cd75b0acbdfb8890710c6742f3fb80e65d","date":1315806626,"type":1,"author":"Christopher John Male","isMerge":false,"pathNew":"lucene/src/test-framework/org/apache/lucene/analysis/MockAnalyzer#createComponents(String,Reader).mjava","pathOld":"lucene/src/test-framework/org/apache/lucene/analysis/MockAnalyzer#tokenStream(String,Reader).mjava","sourceNew":"  @Override\n  public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n    MockTokenizer tokenizer = new MockTokenizer(reader, runAutomaton, lowerCase);\n    tokenizer.setEnableChecks(enableChecks);\n    TokenFilter filt = new MockTokenFilter(tokenizer, filter, enablePositionIncrements);\n    return new TokenStreamComponents(tokenizer, maybePayload(filt, fieldName));\n  }\n\n","sourceOld":"  @Override\n  public TokenStream tokenStream(String fieldName, Reader reader) {\n    MockTokenizer tokenizer = new MockTokenizer(reader, runAutomaton, lowerCase);\n    tokenizer.setEnableChecks(enableChecks);\n    TokenFilter filt = new MockTokenFilter(tokenizer, filter, enablePositionIncrements);\n    filt = maybePayload(filt, fieldName);\n    return filt;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7b91922b55d15444d554721b352861d028eb8278","date":1320421415,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test-framework/java/org/apache/lucene/analysis/MockAnalyzer#createComponents(String,Reader).mjava","pathOld":"lucene/src/test-framework/org/apache/lucene/analysis/MockAnalyzer#createComponents(String,Reader).mjava","sourceNew":"  @Override\n  public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n    MockTokenizer tokenizer = new MockTokenizer(reader, runAutomaton, lowerCase);\n    tokenizer.setEnableChecks(enableChecks);\n    TokenFilter filt = new MockTokenFilter(tokenizer, filter, enablePositionIncrements);\n    return new TokenStreamComponents(tokenizer, maybePayload(filt, fieldName));\n  }\n\n","sourceOld":"  @Override\n  public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n    MockTokenizer tokenizer = new MockTokenizer(reader, runAutomaton, lowerCase);\n    tokenizer.setEnableChecks(enableChecks);\n    TokenFilter filt = new MockTokenFilter(tokenizer, filter, enablePositionIncrements);\n    return new TokenStreamComponents(tokenizer, maybePayload(filt, fieldName));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"7b91922b55d15444d554721b352861d028eb8278":["53ae89cd75b0acbdfb8890710c6742f3fb80e65d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["7b91922b55d15444d554721b352861d028eb8278"],"53ae89cd75b0acbdfb8890710c6742f3fb80e65d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"7b91922b55d15444d554721b352861d028eb8278":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["53ae89cd75b0acbdfb8890710c6742f3fb80e65d"],"53ae89cd75b0acbdfb8890710c6742f3fb80e65d":["7b91922b55d15444d554721b352861d028eb8278"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}