{"path":"sandbox/contributions/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources#getAnyTokenStream(IndexReader,int,String,Analyzer).mjava","commits":[{"id":"d5a0b529d2a1f873f1f11db833a891b53909a7bc","date":1104492147,"type":0,"author":"Mark Harwood","isMerge":false,"pathNew":"sandbox/contributions/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources#getAnyTokenStream(IndexReader,int,String,Analyzer).mjava","pathOld":"/dev/null","sourceNew":"    /**\n     * A convenience method that tries a number of approaches to getting a token stream.\n     * The cost of finding there are no termVectors in the index is minimal (1000 invocations still \n     * registers 0 ms). So this \"lazy\" (flexible?) approach to coding is probably acceptable\n     * @param reader\n     * @param docId\n     * @param field\n     * @param analyzer\n     * @return null if field not stored correctly \n     * @throws IOException\n     */\n    public static TokenStream getAnyTokenStream(IndexReader reader,int docId, String field,Analyzer analyzer) throws IOException\n    {\n\t\tTokenStream ts=null;\n\n\t\tTermFreqVector tfv=(TermFreqVector) reader.getTermFreqVector(docId,field);\n\t\tif(tfv!=null)\n\t\t{\n\t\t    if(tfv instanceof TermPositionVector)\n\t\t    {\n\t\t        ts=getTokenStream((TermPositionVector) tfv);\n\t\t    }\n\t\t}\n\t\t//No token info stored so fall back to analyzing raw content\n\t\tif(ts==null)\n\t\t{\n\t\t    ts=getTokenStream(reader,docId,field,analyzer);\n\t\t}\n\t\treturn ts;\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"043c298cb215f13ba7b9b81d20760704e8f93d66","date":1107566743,"type":5,"author":"Erik Hatcher","isMerge":false,"pathNew":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources#getAnyTokenStream(IndexReader,int,String,Analyzer).mjava","pathOld":"sandbox/contributions/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources#getAnyTokenStream(IndexReader,int,String,Analyzer).mjava","sourceNew":"    /**\n     * A convenience method that tries a number of approaches to getting a token stream.\n     * The cost of finding there are no termVectors in the index is minimal (1000 invocations still \n     * registers 0 ms). So this \"lazy\" (flexible?) approach to coding is probably acceptable\n     * @param reader\n     * @param docId\n     * @param field\n     * @param analyzer\n     * @return null if field not stored correctly \n     * @throws IOException\n     */\n    public static TokenStream getAnyTokenStream(IndexReader reader,int docId, String field,Analyzer analyzer) throws IOException\n    {\n\t\tTokenStream ts=null;\n\n\t\tTermFreqVector tfv=(TermFreqVector) reader.getTermFreqVector(docId,field);\n\t\tif(tfv!=null)\n\t\t{\n\t\t    if(tfv instanceof TermPositionVector)\n\t\t    {\n\t\t        ts=getTokenStream((TermPositionVector) tfv);\n\t\t    }\n\t\t}\n\t\t//No token info stored so fall back to analyzing raw content\n\t\tif(ts==null)\n\t\t{\n\t\t    ts=getTokenStream(reader,docId,field,analyzer);\n\t\t}\n\t\treturn ts;\n    }\n\n","sourceOld":"    /**\n     * A convenience method that tries a number of approaches to getting a token stream.\n     * The cost of finding there are no termVectors in the index is minimal (1000 invocations still \n     * registers 0 ms). So this \"lazy\" (flexible?) approach to coding is probably acceptable\n     * @param reader\n     * @param docId\n     * @param field\n     * @param analyzer\n     * @return null if field not stored correctly \n     * @throws IOException\n     */\n    public static TokenStream getAnyTokenStream(IndexReader reader,int docId, String field,Analyzer analyzer) throws IOException\n    {\n\t\tTokenStream ts=null;\n\n\t\tTermFreqVector tfv=(TermFreqVector) reader.getTermFreqVector(docId,field);\n\t\tif(tfv!=null)\n\t\t{\n\t\t    if(tfv instanceof TermPositionVector)\n\t\t    {\n\t\t        ts=getTokenStream((TermPositionVector) tfv);\n\t\t    }\n\t\t}\n\t\t//No token info stored so fall back to analyzing raw content\n\t\tif(ts==null)\n\t\t{\n\t\t    ts=getTokenStream(reader,docId,field,analyzer);\n\t\t}\n\t\treturn ts;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"043c298cb215f13ba7b9b81d20760704e8f93d66":["d5a0b529d2a1f873f1f11db833a891b53909a7bc"],"d5a0b529d2a1f873f1f11db833a891b53909a7bc":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["043c298cb215f13ba7b9b81d20760704e8f93d66"]},"commit2Childs":{"043c298cb215f13ba7b9b81d20760704e8f93d66":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d5a0b529d2a1f873f1f11db833a891b53909a7bc":["043c298cb215f13ba7b9b81d20760704e8f93d66"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d5a0b529d2a1f873f1f11db833a891b53909a7bc"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}