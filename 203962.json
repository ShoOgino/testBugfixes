{"path":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHash,TermsHash,FieldInfo).mjava","commits":[{"id":"6c18273ea5b3974d2f30117f46f1ae416c28f727","date":1279708040,"type":1,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHash,TermsHash,FieldInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHashPerThread,TermsHashPerThread,FieldInfo).mjava","sourceNew":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHash termsHash, final TermsHash nextTermsHash, final FieldInfo fieldInfo) {\n    intPool = termsHash.intPool;\n    bytePool = termsHash.bytePool;\n    termBytePool = termsHash.termBytePool;\n    docState = termsHash.docState;\n    this.termsHash = termsHash;\n\n    postingsHash = new int[postingsHashSize];\n    Arrays.fill(postingsHash, -1);\n    bytesUsed(postingsHashSize * RamUsageEstimator.NUM_BYTES_INT);\n\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = termsHash.consumer.addField(this, fieldInfo);\n    initPostingsArray();\n\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    utf8 = termsHash.utf8;\n    this.fieldInfo = fieldInfo;\n    if (nextTermsHash != null)\n      nextPerField = (TermsHashPerField) nextTermsHash.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","sourceOld":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHashPerThread perThread, final TermsHashPerThread nextPerThread, final FieldInfo fieldInfo) {\n    this.perThread = perThread;\n    intPool = perThread.intPool;\n    bytePool = perThread.bytePool;\n    termBytePool = perThread.termBytePool;\n    docState = perThread.docState;\n\n    postingsHash = new int[postingsHashSize];\n    Arrays.fill(postingsHash, -1);\n    bytesUsed(postingsHashSize * RamUsageEstimator.NUM_BYTES_INT);\n\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = perThread.consumer.addField(this, fieldInfo);\n    initPostingsArray();\n\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    utf8 = perThread.utf8;\n    this.fieldInfo = fieldInfo;\n    if (nextPerThread != null)\n      nextPerField = (TermsHashPerField) nextPerThread.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHash,TermsHash,FieldInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHash,TermsHash,FieldInfo).mjava","sourceNew":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHash termsHash, final TermsHash nextTermsHash, final FieldInfo fieldInfo) {\n    intPool = termsHash.intPool;\n    bytePool = termsHash.bytePool;\n    termBytePool = termsHash.termBytePool;\n    docState = termsHash.docState;\n    this.termsHash = termsHash;\n    bytesUsed =  termsHash.trackAllocations?termsHash.docWriter.bytesUsed:new AtomicLong();\n\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = termsHash.consumer.addField(this, fieldInfo);\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts);\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n\n    termBytesRef = termsHash.termBytesRef;\n    this.fieldInfo = fieldInfo;\n    if (nextTermsHash != null)\n      nextPerField = (TermsHashPerField) nextTermsHash.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","sourceOld":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHash termsHash, final TermsHash nextTermsHash, final FieldInfo fieldInfo) {\n    intPool = termsHash.intPool;\n    bytePool = termsHash.bytePool;\n    termBytePool = termsHash.termBytePool;\n    docState = termsHash.docState;\n    this.termsHash = termsHash;\n\n    postingsHash = new int[postingsHashSize];\n    Arrays.fill(postingsHash, -1);\n    bytesUsed(postingsHashSize * RamUsageEstimator.NUM_BYTES_INT);\n\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = termsHash.consumer.addField(this, fieldInfo);\n    initPostingsArray();\n\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    utf8 = termsHash.utf8;\n    this.fieldInfo = fieldInfo;\n    if (nextTermsHash != null)\n      nextPerField = (TermsHashPerField) nextTermsHash.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c0ef0193974807e4bddf5432a6b0287fe4d6c9df","date":1301476645,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHash,TermsHash,FieldInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHash,TermsHash,FieldInfo).mjava","sourceNew":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHash termsHash, final TermsHash nextTermsHash, final FieldInfo fieldInfo) {\n    intPool = termsHash.intPool;\n    bytePool = termsHash.bytePool;\n    termBytePool = termsHash.termBytePool;\n    docState = termsHash.docState;\n    this.termsHash = termsHash;\n    bytesUsed =  termsHash.trackAllocations?termsHash.docWriter.bytesUsed:new AtomicLong();\n\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = termsHash.consumer.addField(this, fieldInfo);\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts);\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    if (nextTermsHash != null)\n      nextPerField = (TermsHashPerField) nextTermsHash.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","sourceOld":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHash termsHash, final TermsHash nextTermsHash, final FieldInfo fieldInfo) {\n    intPool = termsHash.intPool;\n    bytePool = termsHash.bytePool;\n    termBytePool = termsHash.termBytePool;\n    docState = termsHash.docState;\n    this.termsHash = termsHash;\n    bytesUsed =  termsHash.trackAllocations?termsHash.docWriter.bytesUsed:new AtomicLong();\n\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = termsHash.consumer.addField(this, fieldInfo);\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts);\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n\n    termBytesRef = termsHash.termBytesRef;\n    this.fieldInfo = fieldInfo;\n    if (nextTermsHash != null)\n      nextPerField = (TermsHashPerField) nextTermsHash.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d2ed1b9b7b46829fe3199afe9a8bc203f201b175","date":1301491807,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHash,TermsHash,FieldInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHash,TermsHash,FieldInfo).mjava","sourceNew":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHash termsHash, final TermsHash nextTermsHash, final FieldInfo fieldInfo) {\n    intPool = termsHash.intPool;\n    bytePool = termsHash.bytePool;\n    termBytePool = termsHash.termBytePool;\n    docState = termsHash.docState;\n    this.termsHash = termsHash;\n    bytesUsed = termsHash.trackAllocations ? termsHash.docWriter.bytesUsed\n        : new AtomicLong();\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = termsHash.consumer.addField(this, fieldInfo);\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts);\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    if (nextTermsHash != null)\n      nextPerField = (TermsHashPerField) nextTermsHash.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","sourceOld":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHash termsHash, final TermsHash nextTermsHash, final FieldInfo fieldInfo) {\n    intPool = termsHash.intPool;\n    bytePool = termsHash.bytePool;\n    termBytePool = termsHash.termBytePool;\n    docState = termsHash.docState;\n    this.termsHash = termsHash;\n    bytesUsed =  termsHash.trackAllocations?termsHash.docWriter.bytesUsed:new AtomicLong();\n\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = termsHash.consumer.addField(this, fieldInfo);\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts);\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    if (nextTermsHash != null)\n      nextPerField = (TermsHashPerField) nextTermsHash.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b3e06be49006ecac364d39d12b9c9f74882f9b9f","date":1304289513,"type":1,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHash,TermsHash,FieldInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHashPerThread,TermsHashPerThread,FieldInfo).mjava","sourceNew":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHash termsHash, final TermsHash nextTermsHash, final FieldInfo fieldInfo) {\n    intPool = termsHash.intPool;\n    bytePool = termsHash.bytePool;\n    termBytePool = termsHash.termBytePool;\n    docState = termsHash.docState;\n    this.termsHash = termsHash;\n    bytesUsed = termsHash.trackAllocations ? termsHash.docWriter.bytesUsed\n        : new AtomicLong();\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = termsHash.consumer.addField(this, fieldInfo);\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts);\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    if (nextTermsHash != null)\n      nextPerField = (TermsHashPerField) nextTermsHash.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","sourceOld":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHashPerThread perThread, final TermsHashPerThread nextPerThread, final FieldInfo fieldInfo) {\n    this.perThread = perThread;\n    intPool = perThread.intPool;\n    bytePool = perThread.bytePool;\n    termBytePool = perThread.termBytePool;\n    docState = perThread.docState;\n    bytesUsed =  perThread.termsHash.trackAllocations?perThread.termsHash.docWriter.bytesUsed:new AtomicLong();\n\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = perThread.consumer.addField(this, fieldInfo);\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts); \n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    if (nextPerThread != null)\n      nextPerField = (TermsHashPerField) nextPerThread.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHash,TermsHash,FieldInfo).mjava","pathOld":"/dev/null","sourceNew":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHash termsHash, final TermsHash nextTermsHash, final FieldInfo fieldInfo) {\n    intPool = termsHash.intPool;\n    bytePool = termsHash.bytePool;\n    termBytePool = termsHash.termBytePool;\n    docState = termsHash.docState;\n    this.termsHash = termsHash;\n    bytesUsed = termsHash.trackAllocations ? termsHash.docWriter.bytesUsed\n        : new AtomicLong();\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = termsHash.consumer.addField(this, fieldInfo);\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts);\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    if (nextTermsHash != null)\n      nextPerField = (TermsHashPerField) nextTermsHash.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":0,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHash,TermsHash,FieldInfo).mjava","pathOld":"/dev/null","sourceNew":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHash termsHash, final TermsHash nextTermsHash, final FieldInfo fieldInfo) {\n    intPool = termsHash.intPool;\n    bytePool = termsHash.bytePool;\n    termBytePool = termsHash.termBytePool;\n    docState = termsHash.docState;\n    this.termsHash = termsHash;\n    bytesUsed = termsHash.trackAllocations ? termsHash.docWriter.bytesUsed\n        : new AtomicLong();\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = termsHash.consumer.addField(this, fieldInfo);\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts);\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    if (nextTermsHash != null)\n      nextPerField = (TermsHashPerField) nextTermsHash.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"17cc1e690c31c800f83860fbfd0423462962ef01","date":1314789725,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHash,TermsHash,FieldInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHash,TermsHash,FieldInfo).mjava","sourceNew":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHash termsHash, final TermsHash nextTermsHash, final FieldInfo fieldInfo) {\n    intPool = termsHash.intPool;\n    bytePool = termsHash.bytePool;\n    termBytePool = termsHash.termBytePool;\n    docState = termsHash.docState;\n    this.termsHash = termsHash;\n    bytesUsed = termsHash.trackAllocations ? termsHash.docWriter.bytesUsed\n        : Counter.newCounter();\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = termsHash.consumer.addField(this, fieldInfo);\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts);\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    if (nextTermsHash != null)\n      nextPerField = (TermsHashPerField) nextTermsHash.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","sourceOld":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHash termsHash, final TermsHash nextTermsHash, final FieldInfo fieldInfo) {\n    intPool = termsHash.intPool;\n    bytePool = termsHash.bytePool;\n    termBytePool = termsHash.termBytePool;\n    docState = termsHash.docState;\n    this.termsHash = termsHash;\n    bytesUsed = termsHash.trackAllocations ? termsHash.docWriter.bytesUsed\n        : new AtomicLong();\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = termsHash.consumer.addField(this, fieldInfo);\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts);\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    if (nextTermsHash != null)\n      nextPerField = (TermsHashPerField) nextTermsHash.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHash,TermsHash,FieldInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHash,TermsHash,FieldInfo).mjava","sourceNew":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHash termsHash, final TermsHash nextTermsHash, final FieldInfo fieldInfo) {\n    intPool = termsHash.intPool;\n    bytePool = termsHash.bytePool;\n    termBytePool = termsHash.termBytePool;\n    docState = termsHash.docState;\n    this.termsHash = termsHash;\n    bytesUsed = termsHash.trackAllocations ? termsHash.docWriter.bytesUsed\n        : Counter.newCounter();\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = termsHash.consumer.addField(this, fieldInfo);\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts);\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    if (nextTermsHash != null)\n      nextPerField = (TermsHashPerField) nextTermsHash.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","sourceOld":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHash termsHash, final TermsHash nextTermsHash, final FieldInfo fieldInfo) {\n    intPool = termsHash.intPool;\n    bytePool = termsHash.bytePool;\n    termBytePool = termsHash.termBytePool;\n    docState = termsHash.docState;\n    this.termsHash = termsHash;\n    bytesUsed = termsHash.trackAllocations ? termsHash.docWriter.bytesUsed\n        : Counter.newCounter();\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = termsHash.consumer.addField(this, fieldInfo);\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts);\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    if (nextTermsHash != null)\n      nextPerField = (TermsHashPerField) nextTermsHash.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"17cc1e690c31c800f83860fbfd0423462962ef01":["b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"d2ed1b9b7b46829fe3199afe9a8bc203f201b175":["c0ef0193974807e4bddf5432a6b0287fe4d6c9df"],"c0ef0193974807e4bddf5432a6b0287fe4d6c9df":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"6c18273ea5b3974d2f30117f46f1ae416c28f727":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["17cc1e690c31c800f83860fbfd0423462962ef01"],"a3776dccca01c11e7046323cfad46a3b4a471233":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"b3e06be49006ecac364d39d12b9c9f74882f9b9f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","d2ed1b9b7b46829fe3199afe9a8bc203f201b175"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["6c18273ea5b3974d2f30117f46f1ae416c28f727","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"17cc1e690c31c800f83860fbfd0423462962ef01":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"d2ed1b9b7b46829fe3199afe9a8bc203f201b175":["b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"c0ef0193974807e4bddf5432a6b0287fe4d6c9df":["d2ed1b9b7b46829fe3199afe9a8bc203f201b175"],"6c18273ea5b3974d2f30117f46f1ae416c28f727":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a3776dccca01c11e7046323cfad46a3b4a471233":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c0ef0193974807e4bddf5432a6b0287fe4d6c9df","6c18273ea5b3974d2f30117f46f1ae416c28f727","a3776dccca01c11e7046323cfad46a3b4a471233","135621f3a0670a9394eb563224a3b76cc4dddc0f","b3e06be49006ecac364d39d12b9c9f74882f9b9f","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":[],"b3e06be49006ecac364d39d12b9c9f74882f9b9f":["17cc1e690c31c800f83860fbfd0423462962ef01","a3776dccca01c11e7046323cfad46a3b4a471233","135621f3a0670a9394eb563224a3b76cc4dddc0f"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["c0ef0193974807e4bddf5432a6b0287fe4d6c9df"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a3776dccca01c11e7046323cfad46a3b4a471233","135621f3a0670a9394eb563224a3b76cc4dddc0f","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}