{"path":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,int,String).mjava","commits":[{"id":"4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762","date":1297938719,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,int,String).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,Comparator[BytesRef],int,String).mjava","sourceNew":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                          int termsCacheSize, String codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    //this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","sourceOld":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                          Comparator<BytesRef> termComp, int termsCacheSize, String codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    this.termComp = termComp;\n    //this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f1bdbf92da222965b46c0a942c3857ba56e5c638","date":1298297608,"type":1,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,int,String).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,Comparator[BytesRef],int,String).mjava","sourceNew":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                          int termsCacheSize, String codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    //this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","sourceOld":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                          Comparator<BytesRef> termComp, int termsCacheSize, String codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    this.termComp = termComp;\n    //this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":1,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,int,String).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,Comparator[BytesRef],int,String).mjava","sourceNew":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                          int termsCacheSize, String codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    //this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","sourceOld":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                          Comparator<BytesRef> termComp, int termsCacheSize, String codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    this.termComp = termComp;\n    this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d619839baa8ce5503e496b94a9e42ad6f079293f","date":1301309428,"type":4,"author":"Simon Willnauer","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,int,String).mjava","sourceNew":null,"sourceOld":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                          int termsCacheSize, String codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    //this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2e8d7ba2175f47e280231533f7d3016249cea88b","date":1307711934,"type":4,"author":"Simon Willnauer","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,int,String).mjava","sourceNew":null,"sourceOld":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                          int termsCacheSize, String codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    //this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","date":1307729864,"type":4,"author":"Steven Rowe","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,int,String).mjava","sourceNew":null,"sourceOld":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                          int termsCacheSize, String codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    //this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":["4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762","2e8d7ba2175f47e280231533f7d3016249cea88b"],"2e8d7ba2175f47e280231533f7d3016249cea88b":["4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762","d619839baa8ce5503e496b94a9e42ad6f079293f"],"f1bdbf92da222965b46c0a942c3857ba56e5c638":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["f1bdbf92da222965b46c0a942c3857ba56e5c638","4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762"],"4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["2e8d7ba2175f47e280231533f7d3016249cea88b"]},"commit2Childs":{"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":[],"2e8d7ba2175f47e280231533f7d3016249cea88b":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f1bdbf92da222965b46c0a942c3857ba56e5c638":["d619839baa8ce5503e496b94a9e42ad6f079293f"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["2e8d7ba2175f47e280231533f7d3016249cea88b"],"4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","2e8d7ba2175f47e280231533f7d3016249cea88b","f1bdbf92da222965b46c0a942c3857ba56e5c638","d619839baa8ce5503e496b94a9e42ad6f079293f","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["f1bdbf92da222965b46c0a942c3857ba56e5c638","4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","bde51b089eb7f86171eb3406e38a274743f9b7ac","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}