{"path":"modules/analysis/common/src/java/org/apache/lucene/analysis/compound/DictionaryCompoundWordTokenFilter#DictionaryCompoundWordTokenFilter(Version,TokenStream,Set[#],int,int,int,boolean).mjava","commits":[{"id":"1e15bea9339982eec538668b67ae252b28e0003e","date":1319539476,"type":1,"author":"Uwe Schindler","isMerge":false,"pathNew":"modules/analysis/common/src/java/org/apache/lucene/analysis/compound/DictionaryCompoundWordTokenFilter#DictionaryCompoundWordTokenFilter(Version,TokenStream,Set[#],int,int,int,boolean).mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/compound/DictionaryCompoundWordTokenFilter#DictionaryCompoundWordTokenFilter(Version,TokenStream,Set,int,int,int,boolean).mjava","sourceNew":"  /**\n   * Creates a new {@link DictionaryCompoundWordTokenFilter}\n   * \n   * @param matchVersion\n   *          Lucene version to enable correct Unicode 4.0 behavior in the\n   *          dictionaries if Version > 3.0. See <a\n   *          href=\"CompoundWordTokenFilterBase#version\"\n   *          >CompoundWordTokenFilterBase</a> for details.\n   * @param input\n   *          the {@link TokenStream} to process\n   * @param dictionary\n   *          the word dictionary to match against.\n   * @param minWordSize\n   *          only words longer than this get processed\n   * @param minSubwordSize\n   *          only subwords longer than this get to the output stream\n   * @param maxSubwordSize\n   *          only subwords shorter than this get to the output stream\n   * @param onlyLongestMatch\n   *          Add only the longest matching subword to the stream\n   */\n  public DictionaryCompoundWordTokenFilter(Version matchVersion, TokenStream input, Set<?> dictionary,\n      int minWordSize, int minSubwordSize, int maxSubwordSize, boolean onlyLongestMatch) {\n    super(matchVersion, input, dictionary, minWordSize, minSubwordSize, maxSubwordSize, onlyLongestMatch);\n  }\n\n","sourceOld":"  /**\n   * Creates a new {@link DictionaryCompoundWordTokenFilter}\n   * \n   * @param matchVersion\n   *          Lucene version to enable correct Unicode 4.0 behavior in the\n   *          dictionaries if Version > 3.0. See <a\n   *          href=\"CompoundWordTokenFilterBase#version\"\n   *          >CompoundWordTokenFilterBase</a> for details.\n   * @param input\n   *          the {@link TokenStream} to process\n   * @param dictionary\n   *          the word dictionary to match against. If this is a\n   *          {@link org.apache.lucene.analysis.util.CharArraySet CharArraySet} it\n   *          must have set ignoreCase=false and only contain lower case\n   *          strings.\n   * @param minWordSize\n   *          only words longer than this get processed\n   * @param minSubwordSize\n   *          only subwords longer than this get to the output stream\n   * @param maxSubwordSize\n   *          only subwords shorter than this get to the output stream\n   * @param onlyLongestMatch\n   *          Add only the longest matching subword to the stream\n   */\n  public DictionaryCompoundWordTokenFilter(Version matchVersion, TokenStream input, Set dictionary,\n      int minWordSize, int minSubwordSize, int maxSubwordSize, boolean onlyLongestMatch) {\n    super(matchVersion, input, dictionary, minWordSize, minSubwordSize, maxSubwordSize, onlyLongestMatch);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c39363fefe2d7f6a6d50ce8e8b758c17a257c58e","date":1328817590,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/common/src/java/org/apache/lucene/analysis/compound/DictionaryCompoundWordTokenFilter#DictionaryCompoundWordTokenFilter(Version,TokenStream,CharArraySet,int,int,int,boolean).mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/compound/DictionaryCompoundWordTokenFilter#DictionaryCompoundWordTokenFilter(Version,TokenStream,Set[#],int,int,int,boolean).mjava","sourceNew":"  /**\n   * Creates a new {@link DictionaryCompoundWordTokenFilter}\n   * \n   * @param matchVersion\n   *          Lucene version to enable correct Unicode 4.0 behavior in the\n   *          dictionaries if Version > 3.0. See <a\n   *          href=\"CompoundWordTokenFilterBase#version\"\n   *          >CompoundWordTokenFilterBase</a> for details.\n   * @param input\n   *          the {@link TokenStream} to process\n   * @param dictionary\n   *          the word dictionary to match against.\n   * @param minWordSize\n   *          only words longer than this get processed\n   * @param minSubwordSize\n   *          only subwords longer than this get to the output stream\n   * @param maxSubwordSize\n   *          only subwords shorter than this get to the output stream\n   * @param onlyLongestMatch\n   *          Add only the longest matching subword to the stream\n   */\n  public DictionaryCompoundWordTokenFilter(Version matchVersion, TokenStream input, CharArraySet dictionary,\n      int minWordSize, int minSubwordSize, int maxSubwordSize, boolean onlyLongestMatch) {\n    super(matchVersion, input, dictionary, minWordSize, minSubwordSize, maxSubwordSize, onlyLongestMatch);\n  }\n\n","sourceOld":"  /**\n   * Creates a new {@link DictionaryCompoundWordTokenFilter}\n   * \n   * @param matchVersion\n   *          Lucene version to enable correct Unicode 4.0 behavior in the\n   *          dictionaries if Version > 3.0. See <a\n   *          href=\"CompoundWordTokenFilterBase#version\"\n   *          >CompoundWordTokenFilterBase</a> for details.\n   * @param input\n   *          the {@link TokenStream} to process\n   * @param dictionary\n   *          the word dictionary to match against.\n   * @param minWordSize\n   *          only words longer than this get processed\n   * @param minSubwordSize\n   *          only subwords longer than this get to the output stream\n   * @param maxSubwordSize\n   *          only subwords shorter than this get to the output stream\n   * @param onlyLongestMatch\n   *          Add only the longest matching subword to the stream\n   */\n  public DictionaryCompoundWordTokenFilter(Version matchVersion, TokenStream input, Set<?> dictionary,\n      int minWordSize, int minSubwordSize, int maxSubwordSize, boolean onlyLongestMatch) {\n    super(matchVersion, input, dictionary, minWordSize, minSubwordSize, maxSubwordSize, onlyLongestMatch);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"1e15bea9339982eec538668b67ae252b28e0003e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c39363fefe2d7f6a6d50ce8e8b758c17a257c58e":["1e15bea9339982eec538668b67ae252b28e0003e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c39363fefe2d7f6a6d50ce8e8b758c17a257c58e"]},"commit2Childs":{"1e15bea9339982eec538668b67ae252b28e0003e":["c39363fefe2d7f6a6d50ce8e8b758c17a257c58e"],"c39363fefe2d7f6a6d50ce8e8b758c17a257c58e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1e15bea9339982eec538668b67ae252b28e0003e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}