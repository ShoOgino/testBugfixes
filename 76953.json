{"path":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#highlight(String,Set[String],String).mjava","commits":[{"id":"33ba398fa7984fdcb45fd76b87504d5adf7ca5e3","date":1373907993,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#highlight(String,Set[String],String).mjava","pathOld":"/dev/null","sourceNew":"  private String highlight(String text, Set<String> matchedTokens, String prefixToken) throws IOException {\n    TokenStream ts = queryAnalyzer.tokenStream(\"text\", new StringReader(text));\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    ts.reset();\n    StringBuilder sb = new StringBuilder();\n    int upto = 0;\n    while (ts.incrementToken()) {\n      String token = termAtt.toString();\n      int startOffset = offsetAtt.startOffset();\n      int endOffset = offsetAtt.endOffset();\n      if (upto < startOffset) {\n        sb.append(text.substring(upto, startOffset));\n        upto = startOffset;\n      } else if (upto > startOffset) {\n        continue;\n      }\n\n      if (matchedTokens.contains(token)) {\n        // Token matches.\n        addWholeMatch(sb, text.substring(startOffset, endOffset), token);\n        upto = endOffset;\n      } else if (prefixToken != null && token.startsWith(prefixToken)) {\n        addPrefixMatch(sb, text.substring(startOffset, endOffset), token, prefixToken);\n        upto = endOffset;\n      }\n    }\n    ts.end();\n    int endOffset = offsetAtt.endOffset();\n    if (upto < endOffset) {\n      sb.append(text.substring(upto));\n    }\n    ts.close();\n\n    return sb.toString();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":0,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#highlight(String,Set[String],String).mjava","pathOld":"/dev/null","sourceNew":"  private String highlight(String text, Set<String> matchedTokens, String prefixToken) throws IOException {\n    TokenStream ts = queryAnalyzer.tokenStream(\"text\", new StringReader(text));\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    ts.reset();\n    StringBuilder sb = new StringBuilder();\n    int upto = 0;\n    while (ts.incrementToken()) {\n      String token = termAtt.toString();\n      int startOffset = offsetAtt.startOffset();\n      int endOffset = offsetAtt.endOffset();\n      if (upto < startOffset) {\n        sb.append(text.substring(upto, startOffset));\n        upto = startOffset;\n      } else if (upto > startOffset) {\n        continue;\n      }\n\n      if (matchedTokens.contains(token)) {\n        // Token matches.\n        addWholeMatch(sb, text.substring(startOffset, endOffset), token);\n        upto = endOffset;\n      } else if (prefixToken != null && token.startsWith(prefixToken)) {\n        addPrefixMatch(sb, text.substring(startOffset, endOffset), token, prefixToken);\n        upto = endOffset;\n      }\n    }\n    ts.end();\n    int endOffset = offsetAtt.endOffset();\n    if (upto < endOffset) {\n      sb.append(text.substring(upto));\n    }\n    ts.close();\n\n    return sb.toString();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9dbf99ca10e1ef2ffbfeb7119d644bf20b267368","date":1379006067,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#highlight(String,Set[String],String).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#highlight(String,Set[String],String).mjava","sourceNew":"  /** Override this method to customize the Object\n   *  representing a single highlighted suggestions; the\n   *  result is set on each {@link\n   *  LookupResult#highlightKey} member. */\n  protected Object highlight(String text, Set<String> matchedTokens, String prefixToken) throws IOException {\n    TokenStream ts = queryAnalyzer.tokenStream(\"text\", new StringReader(text));\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    ts.reset();\n    StringBuilder sb = new StringBuilder();\n    int upto = 0;\n    while (ts.incrementToken()) {\n      String token = termAtt.toString();\n      int startOffset = offsetAtt.startOffset();\n      int endOffset = offsetAtt.endOffset();\n      if (upto < startOffset) {\n        addNonMatch(sb, text.substring(upto, startOffset));\n        upto = startOffset;\n      } else if (upto > startOffset) {\n        continue;\n      }\n\n      if (matchedTokens.contains(token)) {\n        // Token matches.\n        addWholeMatch(sb, text.substring(startOffset, endOffset), token);\n        upto = endOffset;\n      } else if (prefixToken != null && token.startsWith(prefixToken)) {\n        addPrefixMatch(sb, text.substring(startOffset, endOffset), token, prefixToken);\n        upto = endOffset;\n      }\n    }\n    ts.end();\n    int endOffset = offsetAtt.endOffset();\n    if (upto < endOffset) {\n      addNonMatch(sb, text.substring(upto));\n    }\n    ts.close();\n\n    return sb.toString();\n  }\n\n","sourceOld":"  private String highlight(String text, Set<String> matchedTokens, String prefixToken) throws IOException {\n    TokenStream ts = queryAnalyzer.tokenStream(\"text\", new StringReader(text));\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    ts.reset();\n    StringBuilder sb = new StringBuilder();\n    int upto = 0;\n    while (ts.incrementToken()) {\n      String token = termAtt.toString();\n      int startOffset = offsetAtt.startOffset();\n      int endOffset = offsetAtt.endOffset();\n      if (upto < startOffset) {\n        sb.append(text.substring(upto, startOffset));\n        upto = startOffset;\n      } else if (upto > startOffset) {\n        continue;\n      }\n\n      if (matchedTokens.contains(token)) {\n        // Token matches.\n        addWholeMatch(sb, text.substring(startOffset, endOffset), token);\n        upto = endOffset;\n      } else if (prefixToken != null && token.startsWith(prefixToken)) {\n        addPrefixMatch(sb, text.substring(startOffset, endOffset), token, prefixToken);\n        upto = endOffset;\n      }\n    }\n    ts.end();\n    int endOffset = offsetAtt.endOffset();\n    if (upto < endOffset) {\n      sb.append(text.substring(upto));\n    }\n    ts.close();\n\n    return sb.toString();\n  }\n\n","bugFix":null,"bugIntro":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"782ed6a4b4ba50ec19734fc8db4e570ee193d627","date":1381127065,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#highlight(String,Set[String],String).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#highlight(String,Set[String],String).mjava","sourceNew":"  /** Override this method to customize the Object\n   *  representing a single highlighted suggestions; the\n   *  result is set on each {@link\n   *  LookupResult#highlightKey} member. */\n  protected Object highlight(String text, Set<String> matchedTokens, String prefixToken) throws IOException {\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"text\", new StringReader(text))) {\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      ts.reset();\n      StringBuilder sb = new StringBuilder();\n      int upto = 0;\n      while (ts.incrementToken()) {\n        String token = termAtt.toString();\n        int startOffset = offsetAtt.startOffset();\n        int endOffset = offsetAtt.endOffset();\n        if (upto < startOffset) {\n          addNonMatch(sb, text.substring(upto, startOffset));\n          upto = startOffset;\n        } else if (upto > startOffset) {\n          continue;\n        }\n        \n        if (matchedTokens.contains(token)) {\n          // Token matches.\n          addWholeMatch(sb, text.substring(startOffset, endOffset), token);\n          upto = endOffset;\n        } else if (prefixToken != null && token.startsWith(prefixToken)) {\n          addPrefixMatch(sb, text.substring(startOffset, endOffset), token, prefixToken);\n          upto = endOffset;\n        }\n      }\n      ts.end();\n      int endOffset = offsetAtt.endOffset();\n      if (upto < endOffset) {\n        addNonMatch(sb, text.substring(upto));\n      }\n      return sb.toString();\n    }\n  }\n\n","sourceOld":"  /** Override this method to customize the Object\n   *  representing a single highlighted suggestions; the\n   *  result is set on each {@link\n   *  LookupResult#highlightKey} member. */\n  protected Object highlight(String text, Set<String> matchedTokens, String prefixToken) throws IOException {\n    TokenStream ts = queryAnalyzer.tokenStream(\"text\", new StringReader(text));\n    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    ts.reset();\n    StringBuilder sb = new StringBuilder();\n    int upto = 0;\n    while (ts.incrementToken()) {\n      String token = termAtt.toString();\n      int startOffset = offsetAtt.startOffset();\n      int endOffset = offsetAtt.endOffset();\n      if (upto < startOffset) {\n        addNonMatch(sb, text.substring(upto, startOffset));\n        upto = startOffset;\n      } else if (upto > startOffset) {\n        continue;\n      }\n\n      if (matchedTokens.contains(token)) {\n        // Token matches.\n        addWholeMatch(sb, text.substring(startOffset, endOffset), token);\n        upto = endOffset;\n      } else if (prefixToken != null && token.startsWith(prefixToken)) {\n        addPrefixMatch(sb, text.substring(startOffset, endOffset), token, prefixToken);\n        upto = endOffset;\n      }\n    }\n    ts.end();\n    int endOffset = offsetAtt.endOffset();\n    if (upto < endOffset) {\n      addNonMatch(sb, text.substring(upto));\n    }\n    ts.close();\n\n    return sb.toString();\n  }\n\n","bugFix":["33ba398fa7984fdcb45fd76b87504d5adf7ca5e3","9dbf99ca10e1ef2ffbfeb7119d644bf20b267368"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8ba6ae8e3c153347cbb605024ca7550f5c91b178","date":1420215916,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#highlight(String,Set[String],String).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#highlight(String,Set[String],String).mjava","sourceNew":"  /** Override this method to customize the Object\n   *  representing a single highlighted suggestions; the\n   *  result is set on each {@link\n   *  org.apache.lucene.search.suggest.Lookup.LookupResult#highlightKey} member. */\n  protected Object highlight(String text, Set<String> matchedTokens, String prefixToken) throws IOException {\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"text\", new StringReader(text))) {\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      ts.reset();\n      StringBuilder sb = new StringBuilder();\n      int upto = 0;\n      while (ts.incrementToken()) {\n        String token = termAtt.toString();\n        int startOffset = offsetAtt.startOffset();\n        int endOffset = offsetAtt.endOffset();\n        if (upto < startOffset) {\n          addNonMatch(sb, text.substring(upto, startOffset));\n          upto = startOffset;\n        } else if (upto > startOffset) {\n          continue;\n        }\n        \n        if (matchedTokens.contains(token)) {\n          // Token matches.\n          addWholeMatch(sb, text.substring(startOffset, endOffset), token);\n          upto = endOffset;\n        } else if (prefixToken != null && token.startsWith(prefixToken)) {\n          addPrefixMatch(sb, text.substring(startOffset, endOffset), token, prefixToken);\n          upto = endOffset;\n        }\n      }\n      ts.end();\n      int endOffset = offsetAtt.endOffset();\n      if (upto < endOffset) {\n        addNonMatch(sb, text.substring(upto));\n      }\n      return sb.toString();\n    }\n  }\n\n","sourceOld":"  /** Override this method to customize the Object\n   *  representing a single highlighted suggestions; the\n   *  result is set on each {@link\n   *  LookupResult#highlightKey} member. */\n  protected Object highlight(String text, Set<String> matchedTokens, String prefixToken) throws IOException {\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"text\", new StringReader(text))) {\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n      ts.reset();\n      StringBuilder sb = new StringBuilder();\n      int upto = 0;\n      while (ts.incrementToken()) {\n        String token = termAtt.toString();\n        int startOffset = offsetAtt.startOffset();\n        int endOffset = offsetAtt.endOffset();\n        if (upto < startOffset) {\n          addNonMatch(sb, text.substring(upto, startOffset));\n          upto = startOffset;\n        } else if (upto > startOffset) {\n          continue;\n        }\n        \n        if (matchedTokens.contains(token)) {\n          // Token matches.\n          addWholeMatch(sb, text.substring(startOffset, endOffset), token);\n          upto = endOffset;\n        } else if (prefixToken != null && token.startsWith(prefixToken)) {\n          addPrefixMatch(sb, text.substring(startOffset, endOffset), token, prefixToken);\n          upto = endOffset;\n        }\n      }\n      ts.end();\n      int endOffset = offsetAtt.endOffset();\n      if (upto < endOffset) {\n        addNonMatch(sb, text.substring(upto));\n      }\n      return sb.toString();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"8ba6ae8e3c153347cbb605024ca7550f5c91b178":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","33ba398fa7984fdcb45fd76b87504d5adf7ca5e3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"9dbf99ca10e1ef2ffbfeb7119d644bf20b267368":["33ba398fa7984fdcb45fd76b87504d5adf7ca5e3"],"782ed6a4b4ba50ec19734fc8db4e570ee193d627":["9dbf99ca10e1ef2ffbfeb7119d644bf20b267368"],"33ba398fa7984fdcb45fd76b87504d5adf7ca5e3":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["8ba6ae8e3c153347cbb605024ca7550f5c91b178"]},"commit2Childs":{"8ba6ae8e3c153347cbb605024ca7550f5c91b178":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["37a0f60745e53927c4c876cfe5b5a58170f0646c","33ba398fa7984fdcb45fd76b87504d5adf7ca5e3"],"9dbf99ca10e1ef2ffbfeb7119d644bf20b267368":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"782ed6a4b4ba50ec19734fc8db4e570ee193d627":["8ba6ae8e3c153347cbb605024ca7550f5c91b178"],"33ba398fa7984fdcb45fd76b87504d5adf7ca5e3":["37a0f60745e53927c4c876cfe5b5a58170f0646c","9dbf99ca10e1ef2ffbfeb7119d644bf20b267368"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["37a0f60745e53927c4c876cfe5b5a58170f0646c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}