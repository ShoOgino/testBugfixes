{"path":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],DocumentsWriterDeleteQueue.Node[#],DocumentsWriter.FlushNotifications).mjava","commits":[{"id":"8a428f5314daaabf8eab7c50bdc3bc14e6cd1aa2","date":1588002560,"type":1,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],DocumentsWriterDeleteQueue.Node[#],DocumentsWriter.FlushNotifications).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,DocumentsWriterDeleteQueue.Node[#],DocumentsWriter.FlushNotifications).mjava","sourceNew":"  long updateDocuments(Iterable<? extends Iterable<? extends IndexableField>> docs, DocumentsWriterDeleteQueue.Node<?> deleteNode, DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    try {\n      testPoint(\"DocumentsWriterPerThread addDocuments start\");\n      assert hasHitAbortingException() == false: \"DWPT has hit aborting exception but is still indexing\";\n      if (INFO_VERBOSE && infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", Thread.currentThread().getName() + \" update delTerm=\" + deleteNode + \" docID=\" + docState.docID + \" seg=\" + segmentInfo.name);\n      }\n      final int docsInRamBefore = numDocsInRAM;\n      boolean allDocsIndexed = false;\n      try {\n        for (Iterable<? extends IndexableField> doc : docs) {\n          // Even on exception, the document is still added (but marked\n          // deleted), so we don't need to un-reserve at that point.\n          // Aborting exceptions will actually \"lose\" more than one\n          // document, so the counter will be \"wrong\" in that case, but\n          // it's very hard to fix (we can't easily distinguish aborting\n          // vs non-aborting exceptions):\n          reserveOneDoc();\n          docState.doc = doc;\n          docState.docID = numDocsInRAM;\n          try {\n            consumer.processDocument();\n          } finally {\n            numDocsInRAM++; // we count the doc anyway even in the case of an exception\n          }\n        }\n        allDocsIndexed = true;\n        return finishDocuments(deleteNode, docsInRamBefore);\n      } finally {\n        if (!allDocsIndexed && !aborted) {\n          // the iterator threw an exception that is not aborting\n          // go and mark all docs from this block as deleted\n          deleteLastDocs(numDocsInRAM - docsInRamBefore);\n        }\n        docState.clear();\n      }\n    } finally {\n      maybeAbort(\"updateDocuments\", flushNotifications);\n    }\n  }\n\n","sourceOld":"  public long updateDocuments(Iterable<? extends Iterable<? extends IndexableField>> docs, Analyzer analyzer, DocumentsWriterDeleteQueue.Node<?> deleteNode, DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    try {\n      testPoint(\"DocumentsWriterPerThread addDocuments start\");\n      assert hasHitAbortingException() == false: \"DWPT has hit aborting exception but is still indexing\";\n      docState.analyzer = analyzer;\n      if (INFO_VERBOSE && infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", Thread.currentThread().getName() + \" update delTerm=\" + deleteNode + \" docID=\" + docState.docID + \" seg=\" + segmentInfo.name);\n      }\n      final int docsInRamBefore = numDocsInRAM;\n      boolean allDocsIndexed = false;\n      try {\n        for (Iterable<? extends IndexableField> doc : docs) {\n          // Even on exception, the document is still added (but marked\n          // deleted), so we don't need to un-reserve at that point.\n          // Aborting exceptions will actually \"lose\" more than one\n          // document, so the counter will be \"wrong\" in that case, but\n          // it's very hard to fix (we can't easily distinguish aborting\n          // vs non-aborting exceptions):\n          reserveOneDoc();\n          docState.doc = doc;\n          docState.docID = numDocsInRAM;\n          try {\n            consumer.processDocument();\n          } finally {\n            numDocsInRAM++; // we count the doc anyway even in the case of an exception\n          }\n        }\n        allDocsIndexed = true;\n        return finishDocuments(deleteNode, docsInRamBefore);\n      } finally {\n        if (!allDocsIndexed && !aborted) {\n          // the iterator threw an exception that is not aborting\n          // go and mark all docs from this block as deleted\n          deleteLastDocs(numDocsInRAM - docsInRamBefore);\n        }\n        docState.clear();\n      }\n    } finally {\n      maybeAbort(\"updateDocuments\", flushNotifications);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f97270426d92300e08ac1bd1a4ef499ae02e88b7","date":1592503330,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],DocumentsWriterDeleteQueue.Node[#],DocumentsWriter.FlushNotifications).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],DocumentsWriterDeleteQueue.Node[#],DocumentsWriter.FlushNotifications).mjava","sourceNew":"  long updateDocuments(Iterable<? extends Iterable<? extends IndexableField>> docs, DocumentsWriterDeleteQueue.Node<?> deleteNode, DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    try {\n      testPoint(\"DocumentsWriterPerThread addDocuments start\");\n      assert hasHitAbortingException() == false: \"DWPT has hit aborting exception but is still indexing\";\n      if (INFO_VERBOSE && infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", Thread.currentThread().getName() + \" update delTerm=\" + deleteNode + \" docID=\" + numDocsInRAM + \" seg=\" + segmentInfo.name);\n      }\n      final int docsInRamBefore = numDocsInRAM;\n      boolean allDocsIndexed = false;\n      try {\n        for (Iterable<? extends IndexableField> doc : docs) {\n          // Even on exception, the document is still added (but marked\n          // deleted), so we don't need to un-reserve at that point.\n          // Aborting exceptions will actually \"lose\" more than one\n          // document, so the counter will be \"wrong\" in that case, but\n          // it's very hard to fix (we can't easily distinguish aborting\n          // vs non-aborting exceptions):\n          reserveOneDoc();\n          consumer.processDocument(numDocsInRAM++, doc);\n        }\n        allDocsIndexed = true;\n        return finishDocuments(deleteNode, docsInRamBefore);\n      } finally {\n        if (!allDocsIndexed && !aborted) {\n          // the iterator threw an exception that is not aborting\n          // go and mark all docs from this block as deleted\n          deleteLastDocs(numDocsInRAM - docsInRamBefore);\n        }\n      }\n    } finally {\n      maybeAbort(\"updateDocuments\", flushNotifications);\n    }\n  }\n\n","sourceOld":"  long updateDocuments(Iterable<? extends Iterable<? extends IndexableField>> docs, DocumentsWriterDeleteQueue.Node<?> deleteNode, DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    try {\n      testPoint(\"DocumentsWriterPerThread addDocuments start\");\n      assert hasHitAbortingException() == false: \"DWPT has hit aborting exception but is still indexing\";\n      if (INFO_VERBOSE && infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", Thread.currentThread().getName() + \" update delTerm=\" + deleteNode + \" docID=\" + docState.docID + \" seg=\" + segmentInfo.name);\n      }\n      final int docsInRamBefore = numDocsInRAM;\n      boolean allDocsIndexed = false;\n      try {\n        for (Iterable<? extends IndexableField> doc : docs) {\n          // Even on exception, the document is still added (but marked\n          // deleted), so we don't need to un-reserve at that point.\n          // Aborting exceptions will actually \"lose\" more than one\n          // document, so the counter will be \"wrong\" in that case, but\n          // it's very hard to fix (we can't easily distinguish aborting\n          // vs non-aborting exceptions):\n          reserveOneDoc();\n          docState.doc = doc;\n          docState.docID = numDocsInRAM;\n          try {\n            consumer.processDocument();\n          } finally {\n            numDocsInRAM++; // we count the doc anyway even in the case of an exception\n          }\n        }\n        allDocsIndexed = true;\n        return finishDocuments(deleteNode, docsInRamBefore);\n      } finally {\n        if (!allDocsIndexed && !aborted) {\n          // the iterator threw an exception that is not aborting\n          // go and mark all docs from this block as deleted\n          deleteLastDocs(numDocsInRAM - docsInRamBefore);\n        }\n        docState.clear();\n      }\n    } finally {\n      maybeAbort(\"updateDocuments\", flushNotifications);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"49f1924bd448393fbdfef8b5ebed799f938169d3","date":1600069616,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],DocumentsWriterDeleteQueue.Node[#],DocumentsWriter.FlushNotifications).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],DocumentsWriterDeleteQueue.Node[#],DocumentsWriter.FlushNotifications).mjava","sourceNew":"  long updateDocuments(Iterable<? extends Iterable<? extends IndexableField>> docs, DocumentsWriterDeleteQueue.Node<?> deleteNode, DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    try {\n      testPoint(\"DocumentsWriterPerThread addDocuments start\");\n      assert abortingException == null: \"DWPT has hit aborting exception but is still indexing\";\n      if (INFO_VERBOSE && infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", Thread.currentThread().getName() + \" update delTerm=\" + deleteNode + \" docID=\" + numDocsInRAM + \" seg=\" + segmentInfo.name);\n      }\n      final int docsInRamBefore = numDocsInRAM;\n      boolean allDocsIndexed = false;\n      try {\n        for (Iterable<? extends IndexableField> doc : docs) {\n          // Even on exception, the document is still added (but marked\n          // deleted), so we don't need to un-reserve at that point.\n          // Aborting exceptions will actually \"lose\" more than one\n          // document, so the counter will be \"wrong\" in that case, but\n          // it's very hard to fix (we can't easily distinguish aborting\n          // vs non-aborting exceptions):\n          reserveOneDoc();\n          consumer.processDocument(numDocsInRAM++, doc);\n        }\n        allDocsIndexed = true;\n        return finishDocuments(deleteNode, docsInRamBefore);\n      } finally {\n        if (!allDocsIndexed && !aborted) {\n          // the iterator threw an exception that is not aborting\n          // go and mark all docs from this block as deleted\n          deleteLastDocs(numDocsInRAM - docsInRamBefore);\n        }\n      }\n    } finally {\n      maybeAbort(\"updateDocuments\", flushNotifications);\n    }\n  }\n\n","sourceOld":"  long updateDocuments(Iterable<? extends Iterable<? extends IndexableField>> docs, DocumentsWriterDeleteQueue.Node<?> deleteNode, DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    try {\n      testPoint(\"DocumentsWriterPerThread addDocuments start\");\n      assert hasHitAbortingException() == false: \"DWPT has hit aborting exception but is still indexing\";\n      if (INFO_VERBOSE && infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", Thread.currentThread().getName() + \" update delTerm=\" + deleteNode + \" docID=\" + numDocsInRAM + \" seg=\" + segmentInfo.name);\n      }\n      final int docsInRamBefore = numDocsInRAM;\n      boolean allDocsIndexed = false;\n      try {\n        for (Iterable<? extends IndexableField> doc : docs) {\n          // Even on exception, the document is still added (but marked\n          // deleted), so we don't need to un-reserve at that point.\n          // Aborting exceptions will actually \"lose\" more than one\n          // document, so the counter will be \"wrong\" in that case, but\n          // it's very hard to fix (we can't easily distinguish aborting\n          // vs non-aborting exceptions):\n          reserveOneDoc();\n          consumer.processDocument(numDocsInRAM++, doc);\n        }\n        allDocsIndexed = true;\n        return finishDocuments(deleteNode, docsInRamBefore);\n      } finally {\n        if (!allDocsIndexed && !aborted) {\n          // the iterator threw an exception that is not aborting\n          // go and mark all docs from this block as deleted\n          deleteLastDocs(numDocsInRAM - docsInRamBefore);\n        }\n      }\n    } finally {\n      maybeAbort(\"updateDocuments\", flushNotifications);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0dcf8f79417865e5028d753e669fae06457e8369","date":1600073240,"type":3,"author":"noblepaul","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],DocumentsWriterDeleteQueue.Node[#],DocumentsWriter.FlushNotifications).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],DocumentsWriterDeleteQueue.Node[#],DocumentsWriter.FlushNotifications).mjava","sourceNew":"  long updateDocuments(Iterable<? extends Iterable<? extends IndexableField>> docs, DocumentsWriterDeleteQueue.Node<?> deleteNode, DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    try {\n      testPoint(\"DocumentsWriterPerThread addDocuments start\");\n      assert abortingException == null: \"DWPT has hit aborting exception but is still indexing\";\n      if (INFO_VERBOSE && infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", Thread.currentThread().getName() + \" update delTerm=\" + deleteNode + \" docID=\" + numDocsInRAM + \" seg=\" + segmentInfo.name);\n      }\n      final int docsInRamBefore = numDocsInRAM;\n      boolean allDocsIndexed = false;\n      try {\n        for (Iterable<? extends IndexableField> doc : docs) {\n          // Even on exception, the document is still added (but marked\n          // deleted), so we don't need to un-reserve at that point.\n          // Aborting exceptions will actually \"lose\" more than one\n          // document, so the counter will be \"wrong\" in that case, but\n          // it's very hard to fix (we can't easily distinguish aborting\n          // vs non-aborting exceptions):\n          reserveOneDoc();\n          consumer.processDocument(numDocsInRAM++, doc);\n        }\n        allDocsIndexed = true;\n        return finishDocuments(deleteNode, docsInRamBefore);\n      } finally {\n        if (!allDocsIndexed && !aborted) {\n          // the iterator threw an exception that is not aborting\n          // go and mark all docs from this block as deleted\n          deleteLastDocs(numDocsInRAM - docsInRamBefore);\n        }\n      }\n    } finally {\n      maybeAbort(\"updateDocuments\", flushNotifications);\n    }\n  }\n\n","sourceOld":"  long updateDocuments(Iterable<? extends Iterable<? extends IndexableField>> docs, DocumentsWriterDeleteQueue.Node<?> deleteNode, DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    try {\n      testPoint(\"DocumentsWriterPerThread addDocuments start\");\n      assert hasHitAbortingException() == false: \"DWPT has hit aborting exception but is still indexing\";\n      if (INFO_VERBOSE && infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", Thread.currentThread().getName() + \" update delTerm=\" + deleteNode + \" docID=\" + numDocsInRAM + \" seg=\" + segmentInfo.name);\n      }\n      final int docsInRamBefore = numDocsInRAM;\n      boolean allDocsIndexed = false;\n      try {\n        for (Iterable<? extends IndexableField> doc : docs) {\n          // Even on exception, the document is still added (but marked\n          // deleted), so we don't need to un-reserve at that point.\n          // Aborting exceptions will actually \"lose\" more than one\n          // document, so the counter will be \"wrong\" in that case, but\n          // it's very hard to fix (we can't easily distinguish aborting\n          // vs non-aborting exceptions):\n          reserveOneDoc();\n          consumer.processDocument(numDocsInRAM++, doc);\n        }\n        allDocsIndexed = true;\n        return finishDocuments(deleteNode, docsInRamBefore);\n      } finally {\n        if (!allDocsIndexed && !aborted) {\n          // the iterator threw an exception that is not aborting\n          // go and mark all docs from this block as deleted\n          deleteLastDocs(numDocsInRAM - docsInRamBefore);\n        }\n      }\n    } finally {\n      maybeAbort(\"updateDocuments\", flushNotifications);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7a6f8af01d9b3067b143bbdc0a492720e2af97cf","date":1600157724,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],DocumentsWriterDeleteQueue.Node[#],DocumentsWriter.FlushNotifications).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],DocumentsWriterDeleteQueue.Node[#],DocumentsWriter.FlushNotifications).mjava","sourceNew":"  long updateDocuments(Iterable<? extends Iterable<? extends IndexableField>> docs, DocumentsWriterDeleteQueue.Node<?> deleteNode, DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    try {\n      testPoint(\"DocumentsWriterPerThread addDocuments start\");\n      assert abortingException == null: \"DWPT has hit aborting exception but is still indexing\";\n      if (INFO_VERBOSE && infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", Thread.currentThread().getName() + \" update delTerm=\" + deleteNode + \" docID=\" + numDocsInRAM + \" seg=\" + segmentInfo.name);\n      }\n      final int docsInRamBefore = numDocsInRAM;\n      boolean allDocsIndexed = false;\n      try {\n        for (Iterable<? extends IndexableField> doc : docs) {\n          // Even on exception, the document is still added (but marked\n          // deleted), so we don't need to un-reserve at that point.\n          // Aborting exceptions will actually \"lose\" more than one\n          // document, so the counter will be \"wrong\" in that case, but\n          // it's very hard to fix (we can't easily distinguish aborting\n          // vs non-aborting exceptions):\n          reserveOneDoc();\n          indexingChain.processDocument(numDocsInRAM++, doc);\n        }\n        allDocsIndexed = true;\n        return finishDocuments(deleteNode, docsInRamBefore);\n      } finally {\n        if (!allDocsIndexed && !aborted) {\n          // the iterator threw an exception that is not aborting\n          // go and mark all docs from this block as deleted\n          deleteLastDocs(numDocsInRAM - docsInRamBefore);\n        }\n      }\n    } finally {\n      maybeAbort(\"updateDocuments\", flushNotifications);\n    }\n  }\n\n","sourceOld":"  long updateDocuments(Iterable<? extends Iterable<? extends IndexableField>> docs, DocumentsWriterDeleteQueue.Node<?> deleteNode, DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    try {\n      testPoint(\"DocumentsWriterPerThread addDocuments start\");\n      assert abortingException == null: \"DWPT has hit aborting exception but is still indexing\";\n      if (INFO_VERBOSE && infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", Thread.currentThread().getName() + \" update delTerm=\" + deleteNode + \" docID=\" + numDocsInRAM + \" seg=\" + segmentInfo.name);\n      }\n      final int docsInRamBefore = numDocsInRAM;\n      boolean allDocsIndexed = false;\n      try {\n        for (Iterable<? extends IndexableField> doc : docs) {\n          // Even on exception, the document is still added (but marked\n          // deleted), so we don't need to un-reserve at that point.\n          // Aborting exceptions will actually \"lose\" more than one\n          // document, so the counter will be \"wrong\" in that case, but\n          // it's very hard to fix (we can't easily distinguish aborting\n          // vs non-aborting exceptions):\n          reserveOneDoc();\n          consumer.processDocument(numDocsInRAM++, doc);\n        }\n        allDocsIndexed = true;\n        return finishDocuments(deleteNode, docsInRamBefore);\n      } finally {\n        if (!allDocsIndexed && !aborted) {\n          // the iterator threw an exception that is not aborting\n          // go and mark all docs from this block as deleted\n          deleteLastDocs(numDocsInRAM - docsInRamBefore);\n        }\n      }\n    } finally {\n      maybeAbort(\"updateDocuments\", flushNotifications);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"680b6449f09827f58fe987aff279e014c311d966","date":1600247985,"type":3,"author":"noblepaul","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],DocumentsWriterDeleteQueue.Node[#],DocumentsWriter.FlushNotifications).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],DocumentsWriterDeleteQueue.Node[#],DocumentsWriter.FlushNotifications).mjava","sourceNew":"  long updateDocuments(Iterable<? extends Iterable<? extends IndexableField>> docs, DocumentsWriterDeleteQueue.Node<?> deleteNode, DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    try {\n      testPoint(\"DocumentsWriterPerThread addDocuments start\");\n      assert abortingException == null: \"DWPT has hit aborting exception but is still indexing\";\n      if (INFO_VERBOSE && infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", Thread.currentThread().getName() + \" update delTerm=\" + deleteNode + \" docID=\" + numDocsInRAM + \" seg=\" + segmentInfo.name);\n      }\n      final int docsInRamBefore = numDocsInRAM;\n      boolean allDocsIndexed = false;\n      try {\n        for (Iterable<? extends IndexableField> doc : docs) {\n          // Even on exception, the document is still added (but marked\n          // deleted), so we don't need to un-reserve at that point.\n          // Aborting exceptions will actually \"lose\" more than one\n          // document, so the counter will be \"wrong\" in that case, but\n          // it's very hard to fix (we can't easily distinguish aborting\n          // vs non-aborting exceptions):\n          reserveOneDoc();\n          indexingChain.processDocument(numDocsInRAM++, doc);\n        }\n        allDocsIndexed = true;\n        return finishDocuments(deleteNode, docsInRamBefore);\n      } finally {\n        if (!allDocsIndexed && !aborted) {\n          // the iterator threw an exception that is not aborting\n          // go and mark all docs from this block as deleted\n          deleteLastDocs(numDocsInRAM - docsInRamBefore);\n        }\n      }\n    } finally {\n      maybeAbort(\"updateDocuments\", flushNotifications);\n    }\n  }\n\n","sourceOld":"  long updateDocuments(Iterable<? extends Iterable<? extends IndexableField>> docs, DocumentsWriterDeleteQueue.Node<?> deleteNode, DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    try {\n      testPoint(\"DocumentsWriterPerThread addDocuments start\");\n      assert abortingException == null: \"DWPT has hit aborting exception but is still indexing\";\n      if (INFO_VERBOSE && infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", Thread.currentThread().getName() + \" update delTerm=\" + deleteNode + \" docID=\" + numDocsInRAM + \" seg=\" + segmentInfo.name);\n      }\n      final int docsInRamBefore = numDocsInRAM;\n      boolean allDocsIndexed = false;\n      try {\n        for (Iterable<? extends IndexableField> doc : docs) {\n          // Even on exception, the document is still added (but marked\n          // deleted), so we don't need to un-reserve at that point.\n          // Aborting exceptions will actually \"lose\" more than one\n          // document, so the counter will be \"wrong\" in that case, but\n          // it's very hard to fix (we can't easily distinguish aborting\n          // vs non-aborting exceptions):\n          reserveOneDoc();\n          consumer.processDocument(numDocsInRAM++, doc);\n        }\n        allDocsIndexed = true;\n        return finishDocuments(deleteNode, docsInRamBefore);\n      } finally {\n        if (!allDocsIndexed && !aborted) {\n          // the iterator threw an exception that is not aborting\n          // go and mark all docs from this block as deleted\n          deleteLastDocs(numDocsInRAM - docsInRamBefore);\n        }\n      }\n    } finally {\n      maybeAbort(\"updateDocuments\", flushNotifications);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"49f1924bd448393fbdfef8b5ebed799f938169d3":["f97270426d92300e08ac1bd1a4ef499ae02e88b7"],"680b6449f09827f58fe987aff279e014c311d966":["0dcf8f79417865e5028d753e669fae06457e8369","7a6f8af01d9b3067b143bbdc0a492720e2af97cf"],"7a6f8af01d9b3067b143bbdc0a492720e2af97cf":["49f1924bd448393fbdfef8b5ebed799f938169d3"],"0dcf8f79417865e5028d753e669fae06457e8369":["f97270426d92300e08ac1bd1a4ef499ae02e88b7","49f1924bd448393fbdfef8b5ebed799f938169d3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8a428f5314daaabf8eab7c50bdc3bc14e6cd1aa2":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"f97270426d92300e08ac1bd1a4ef499ae02e88b7":["8a428f5314daaabf8eab7c50bdc3bc14e6cd1aa2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["680b6449f09827f58fe987aff279e014c311d966"]},"commit2Childs":{"49f1924bd448393fbdfef8b5ebed799f938169d3":["7a6f8af01d9b3067b143bbdc0a492720e2af97cf","0dcf8f79417865e5028d753e669fae06457e8369"],"680b6449f09827f58fe987aff279e014c311d966":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"7a6f8af01d9b3067b143bbdc0a492720e2af97cf":["680b6449f09827f58fe987aff279e014c311d966"],"0dcf8f79417865e5028d753e669fae06457e8369":["680b6449f09827f58fe987aff279e014c311d966"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["8a428f5314daaabf8eab7c50bdc3bc14e6cd1aa2"],"8a428f5314daaabf8eab7c50bdc3bc14e6cd1aa2":["f97270426d92300e08ac1bd1a4ef499ae02e88b7"],"f97270426d92300e08ac1bd1a4ef499ae02e88b7":["49f1924bd448393fbdfef8b5ebed799f938169d3","0dcf8f79417865e5028d753e669fae06457e8369"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}