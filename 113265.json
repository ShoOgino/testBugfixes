{"path":"src/test/org/apache/solr/analysis/TestWordDelimiterFilter#testOffsets().mjava","commits":[{"id":"0ccc76b6c713f3e022bca745da888fa20a742772","date":1186761183,"type":0,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/test/org/apache/solr/analysis/TestWordDelimiterFilter#testOffsets().mjava","pathOld":"/dev/null","sourceNew":"  public void testOffsets() throws IOException {\n\n    // test that subwords and catenated subwords have\n    // the correct offsets.\n    WordDelimiterFilter wdf = new WordDelimiterFilter(\n            new TokenStream() {\n              Token t;\n              public Token next() throws IOException {\n                if (t!=null) return null;\n                t = new Token(\"foo-bar\", 5, 12);  // actual\n                return t;\n              }\n            },\n    1,1,0,0,1,1);\n\n    int i=0;\n    for(Token t; (t=wdf.next())!=null;) {\n      if (t.termText().equals(\"foo\")) {\n        assertEquals(5, t.startOffset());\n        assertEquals(8, t.endOffset());\n        i++;\n      }\n      if (t.termText().equals(\"bar\")) {\n        assertEquals(9, t.startOffset());\n        assertEquals(12, t.endOffset());\n        i++;\n      }\n      if (t.termText().equals(\"foobar\")) {\n        assertEquals(5, t.startOffset());\n        assertEquals(12, t.endOffset());\n        i++;\n      }\n    }\n    assertEquals(3,i); // make sure all 3 tokens were generated\n\n    // test that if splitting or catenating a synonym, that the offsets\n    // are not altered (they would be incorrect).\n    wdf = new WordDelimiterFilter(\n            new TokenStream() {\n              Token t;\n              public Token next() throws IOException {\n                if (t!=null) return null;\n                t = new Token(\"foo-bar\", 5, 6);  // a synonym\n                return t;\n              }\n            },\n    1,1,0,0,1,1);\n    for(Token t; (t=wdf.next())!=null;) {\n      assertEquals(5, t.startOffset());\n      assertEquals(6, t.endOffset());\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e0d0e8297e9b3e015826cdb7e42404953c339851","date":1215099614,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/test/org/apache/solr/analysis/TestWordDelimiterFilter#testOffsets().mjava","pathOld":"src/test/org/apache/solr/analysis/TestWordDelimiterFilter#testOffsets().mjava","sourceNew":"  /***\n  public void testPerformance() throws IOException {\n    String s = \"now is the time-for all good men to come to-the aid of their country.\";\n    Token tok = new Token();\n    long start = System.currentTimeMillis();\n    int ret=0;\n    for (int i=0; i<1000000; i++) {\n      StringReader r = new StringReader(s);\n      TokenStream ts = new WhitespaceTokenizer(r);\n      ts = new WordDelimiterFilter(ts, 1,1,1,1,0);\n\n      while (ts.next(tok) != null) ret++;\n    }\n\n    System.out.println(\"ret=\"+ret+\" time=\"+(System.currentTimeMillis()-start));\n  }\n  ***/\n\n\n  public void testOffsets() throws IOException {\n\n    // test that subwords and catenated subwords have\n    // the correct offsets.\n    WordDelimiterFilter wdf = new WordDelimiterFilter(\n            new TokenStream() {\n              Token t;\n              public Token next() throws IOException {\n                if (t!=null) return null;\n                t = new Token(\"foo-bar\", 5, 12);  // actual\n                return t;\n              }\n            },\n    1,1,0,0,1,1,0);\n\n    int i=0;\n    for(Token t; (t=wdf.next())!=null;) {\n      if (t.termText().equals(\"foo\")) {\n        assertEquals(5, t.startOffset());\n        assertEquals(8, t.endOffset());\n        i++;\n      }\n      if (t.termText().equals(\"bar\")) {\n        assertEquals(9, t.startOffset());\n        assertEquals(12, t.endOffset());\n        i++;\n      }\n      if (t.termText().equals(\"foobar\")) {\n        assertEquals(5, t.startOffset());\n        assertEquals(12, t.endOffset());\n        i++;\n      }\n    }\n    assertEquals(3,i); // make sure all 3 tokens were generated\n\n    // test that if splitting or catenating a synonym, that the offsets\n    // are not altered (they would be incorrect).\n    wdf = new WordDelimiterFilter(\n            new TokenStream() {\n              Token t;\n              public Token next() throws IOException {\n                if (t!=null) return null;\n                t = new Token(\"foo-bar\", 5, 6);  // a synonym\n                return t;\n              }\n            },\n    1,1,0,0,1,1,0);\n    for(Token t; (t=wdf.next())!=null;) {\n      assertEquals(5, t.startOffset());\n      assertEquals(6, t.endOffset());\n    }\n  }\n\n","sourceOld":"  public void testOffsets() throws IOException {\n\n    // test that subwords and catenated subwords have\n    // the correct offsets.\n    WordDelimiterFilter wdf = new WordDelimiterFilter(\n            new TokenStream() {\n              Token t;\n              public Token next() throws IOException {\n                if (t!=null) return null;\n                t = new Token(\"foo-bar\", 5, 12);  // actual\n                return t;\n              }\n            },\n    1,1,0,0,1,1);\n\n    int i=0;\n    for(Token t; (t=wdf.next())!=null;) {\n      if (t.termText().equals(\"foo\")) {\n        assertEquals(5, t.startOffset());\n        assertEquals(8, t.endOffset());\n        i++;\n      }\n      if (t.termText().equals(\"bar\")) {\n        assertEquals(9, t.startOffset());\n        assertEquals(12, t.endOffset());\n        i++;\n      }\n      if (t.termText().equals(\"foobar\")) {\n        assertEquals(5, t.startOffset());\n        assertEquals(12, t.endOffset());\n        i++;\n      }\n    }\n    assertEquals(3,i); // make sure all 3 tokens were generated\n\n    // test that if splitting or catenating a synonym, that the offsets\n    // are not altered (they would be incorrect).\n    wdf = new WordDelimiterFilter(\n            new TokenStream() {\n              Token t;\n              public Token next() throws IOException {\n                if (t!=null) return null;\n                t = new Token(\"foo-bar\", 5, 6);  // a synonym\n                return t;\n              }\n            },\n    1,1,0,0,1,1);\n    for(Token t; (t=wdf.next())!=null;) {\n      assertEquals(5, t.startOffset());\n      assertEquals(6, t.endOffset());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c90f01e1c0f11ee52212ab38c6d4393b3be8a646","date":1223059437,"type":3,"author":"Ryan McKinley","isMerge":false,"pathNew":"src/test/org/apache/solr/analysis/TestWordDelimiterFilter#testOffsets().mjava","pathOld":"src/test/org/apache/solr/analysis/TestWordDelimiterFilter#testOffsets().mjava","sourceNew":"  /***\n  public void testPerformance() throws IOException {\n    String s = \"now is the time-for all good men to come to-the aid of their country.\";\n    Token tok = new Token();\n    long start = System.currentTimeMillis();\n    int ret=0;\n    for (int i=0; i<1000000; i++) {\n      StringReader r = new StringReader(s);\n      TokenStream ts = new WhitespaceTokenizer(r);\n      ts = new WordDelimiterFilter(ts, 1,1,1,1,0);\n\n      while (ts.next(tok) != null) ret++;\n    }\n\n    System.out.println(\"ret=\"+ret+\" time=\"+(System.currentTimeMillis()-start));\n  }\n  ***/\n\n\n  public void testOffsets() throws IOException {\n\n    // test that subwords and catenated subwords have\n    // the correct offsets.\n    WordDelimiterFilter wdf = new WordDelimiterFilter(\n            new TokenStream() {\n              Token t;\n              public Token next() throws IOException {\n                if (t!=null) return null;\n                t = new Token(\"foo-bar\", 5, 12);  // actual\n                return t;\n              }\n            },\n    1,1,0,0,1,1,0);\n\n    int i=0;\n    for(Token t; (t=wdf.next())!=null;) {\n      String termText = new String(t.termBuffer(), 0, t.termLength());\n      if (termText.equals(\"foo\")) {\n        assertEquals(5, t.startOffset());\n        assertEquals(8, t.endOffset());\n        i++;\n      }\n      if (termText.equals(\"bar\")) {\n        assertEquals(9, t.startOffset());\n        assertEquals(12, t.endOffset());\n        i++;\n      }\n      if (termText.equals(\"foobar\")) {\n        assertEquals(5, t.startOffset());\n        assertEquals(12, t.endOffset());\n        i++;\n      }\n    }\n    assertEquals(3,i); // make sure all 3 tokens were generated\n\n    // test that if splitting or catenating a synonym, that the offsets\n    // are not altered (they would be incorrect).\n    wdf = new WordDelimiterFilter(\n            new TokenStream() {\n              Token t;\n              public Token next() throws IOException {\n                if (t!=null) return null;\n                t = new Token(\"foo-bar\", 5, 6);  // a synonym\n                return t;\n              }\n            },\n    1,1,0,0,1,1,0);\n    for(Token t; (t=wdf.next())!=null;) {\n      assertEquals(5, t.startOffset());\n      assertEquals(6, t.endOffset());\n    }\n  }\n\n","sourceOld":"  /***\n  public void testPerformance() throws IOException {\n    String s = \"now is the time-for all good men to come to-the aid of their country.\";\n    Token tok = new Token();\n    long start = System.currentTimeMillis();\n    int ret=0;\n    for (int i=0; i<1000000; i++) {\n      StringReader r = new StringReader(s);\n      TokenStream ts = new WhitespaceTokenizer(r);\n      ts = new WordDelimiterFilter(ts, 1,1,1,1,0);\n\n      while (ts.next(tok) != null) ret++;\n    }\n\n    System.out.println(\"ret=\"+ret+\" time=\"+(System.currentTimeMillis()-start));\n  }\n  ***/\n\n\n  public void testOffsets() throws IOException {\n\n    // test that subwords and catenated subwords have\n    // the correct offsets.\n    WordDelimiterFilter wdf = new WordDelimiterFilter(\n            new TokenStream() {\n              Token t;\n              public Token next() throws IOException {\n                if (t!=null) return null;\n                t = new Token(\"foo-bar\", 5, 12);  // actual\n                return t;\n              }\n            },\n    1,1,0,0,1,1,0);\n\n    int i=0;\n    for(Token t; (t=wdf.next())!=null;) {\n      if (t.termText().equals(\"foo\")) {\n        assertEquals(5, t.startOffset());\n        assertEquals(8, t.endOffset());\n        i++;\n      }\n      if (t.termText().equals(\"bar\")) {\n        assertEquals(9, t.startOffset());\n        assertEquals(12, t.endOffset());\n        i++;\n      }\n      if (t.termText().equals(\"foobar\")) {\n        assertEquals(5, t.startOffset());\n        assertEquals(12, t.endOffset());\n        i++;\n      }\n    }\n    assertEquals(3,i); // make sure all 3 tokens were generated\n\n    // test that if splitting or catenating a synonym, that the offsets\n    // are not altered (they would be incorrect).\n    wdf = new WordDelimiterFilter(\n            new TokenStream() {\n              Token t;\n              public Token next() throws IOException {\n                if (t!=null) return null;\n                t = new Token(\"foo-bar\", 5, 6);  // a synonym\n                return t;\n              }\n            },\n    1,1,0,0,1,1,0);\n    for(Token t; (t=wdf.next())!=null;) {\n      assertEquals(5, t.startOffset());\n      assertEquals(6, t.endOffset());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2fd023a662cc25ae7e0ad0f33d71c476a16d0579","date":1261403630,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"src/test/org/apache/solr/analysis/TestWordDelimiterFilter#testOffsets().mjava","pathOld":"src/test/org/apache/solr/analysis/TestWordDelimiterFilter#testOffsets().mjava","sourceNew":"  /***\n  public void testPerformance() throws IOException {\n    String s = \"now is the time-for all good men to come to-the aid of their country.\";\n    Token tok = new Token();\n    long start = System.currentTimeMillis();\n    int ret=0;\n    for (int i=0; i<1000000; i++) {\n      StringReader r = new StringReader(s);\n      TokenStream ts = new WhitespaceTokenizer(r);\n      ts = new WordDelimiterFilter(ts, 1,1,1,1,0);\n\n      while (ts.next(tok) != null) ret++;\n    }\n\n    System.out.println(\"ret=\"+ret+\" time=\"+(System.currentTimeMillis()-start));\n  }\n  ***/\n\n\n  public void testOffsets() throws IOException {\n\n    // test that subwords and catenated subwords have\n    // the correct offsets.\n    WordDelimiterFilter wdf = new WordDelimiterFilter(\n            new SingleTokenTokenStream(new Token(\"foo-bar\", 5, 12)),\n    1,1,0,0,1,1,0);\n\n    assertTokenStreamContents(wdf, \n        new String[] { \"foo\", \"bar\", \"foobar\" },\n        new int[] { 5, 9, 5 }, \n        new int[] { 8, 12, 12 });\n\n    wdf = new WordDelimiterFilter(\n            new SingleTokenTokenStream(new Token(\"foo-bar\", 5, 6)),\n    1,1,0,0,1,1,0);\n    \n    assertTokenStreamContents(wdf,\n        new String[] { \"foo\", \"bar\", \"foobar\" },\n        new int[] { 5, 5, 5 },\n        new int[] { 6, 6, 6 });\n  }\n\n","sourceOld":"  /***\n  public void testPerformance() throws IOException {\n    String s = \"now is the time-for all good men to come to-the aid of their country.\";\n    Token tok = new Token();\n    long start = System.currentTimeMillis();\n    int ret=0;\n    for (int i=0; i<1000000; i++) {\n      StringReader r = new StringReader(s);\n      TokenStream ts = new WhitespaceTokenizer(r);\n      ts = new WordDelimiterFilter(ts, 1,1,1,1,0);\n\n      while (ts.next(tok) != null) ret++;\n    }\n\n    System.out.println(\"ret=\"+ret+\" time=\"+(System.currentTimeMillis()-start));\n  }\n  ***/\n\n\n  public void testOffsets() throws IOException {\n\n    // test that subwords and catenated subwords have\n    // the correct offsets.\n    WordDelimiterFilter wdf = new WordDelimiterFilter(\n            new TokenStream() {\n              Token t;\n              public Token next() throws IOException {\n                if (t!=null) return null;\n                t = new Token(\"foo-bar\", 5, 12);  // actual\n                return t;\n              }\n            },\n    1,1,0,0,1,1,0);\n\n    int i=0;\n    for(Token t; (t=wdf.next())!=null;) {\n      String termText = new String(t.termBuffer(), 0, t.termLength());\n      if (termText.equals(\"foo\")) {\n        assertEquals(5, t.startOffset());\n        assertEquals(8, t.endOffset());\n        i++;\n      }\n      if (termText.equals(\"bar\")) {\n        assertEquals(9, t.startOffset());\n        assertEquals(12, t.endOffset());\n        i++;\n      }\n      if (termText.equals(\"foobar\")) {\n        assertEquals(5, t.startOffset());\n        assertEquals(12, t.endOffset());\n        i++;\n      }\n    }\n    assertEquals(3,i); // make sure all 3 tokens were generated\n\n    // test that if splitting or catenating a synonym, that the offsets\n    // are not altered (they would be incorrect).\n    wdf = new WordDelimiterFilter(\n            new TokenStream() {\n              Token t;\n              public Token next() throws IOException {\n                if (t!=null) return null;\n                t = new Token(\"foo-bar\", 5, 6);  // a synonym\n                return t;\n              }\n            },\n    1,1,0,0,1,1,0);\n    for(Token t; (t=wdf.next())!=null;) {\n      assertEquals(5, t.startOffset());\n      assertEquals(6, t.endOffset());\n    }\n  }\n\n","bugFix":null,"bugIntro":["ad9e3deabce40d9849c1b75ef706bfa79f4f0d1e","c85fa43e6918808743daa7847ba0264373af687f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/analysis/TestWordDelimiterFilter#testOffsets().mjava","pathOld":"src/test/org/apache/solr/analysis/TestWordDelimiterFilter#testOffsets().mjava","sourceNew":"  /***\n  public void testPerformance() throws IOException {\n    String s = \"now is the time-for all good men to come to-the aid of their country.\";\n    Token tok = new Token();\n    long start = System.currentTimeMillis();\n    int ret=0;\n    for (int i=0; i<1000000; i++) {\n      StringReader r = new StringReader(s);\n      TokenStream ts = new WhitespaceTokenizer(r);\n      ts = new WordDelimiterFilter(ts, 1,1,1,1,0);\n\n      while (ts.next(tok) != null) ret++;\n    }\n\n    System.out.println(\"ret=\"+ret+\" time=\"+(System.currentTimeMillis()-start));\n  }\n  ***/\n\n\n  public void testOffsets() throws IOException {\n\n    // test that subwords and catenated subwords have\n    // the correct offsets.\n    WordDelimiterFilter wdf = new WordDelimiterFilter(\n            new SingleTokenTokenStream(new Token(\"foo-bar\", 5, 12)),\n    1,1,0,0,1,1,0);\n\n    assertTokenStreamContents(wdf, \n        new String[] { \"foo\", \"bar\", \"foobar\" },\n        new int[] { 5, 9, 5 }, \n        new int[] { 8, 12, 12 });\n\n    wdf = new WordDelimiterFilter(\n            new SingleTokenTokenStream(new Token(\"foo-bar\", 5, 6)),\n    1,1,0,0,1,1,0);\n    \n    assertTokenStreamContents(wdf,\n        new String[] { \"foo\", \"bar\", \"foobar\" },\n        new int[] { 5, 5, 5 },\n        new int[] { 6, 6, 6 });\n  }\n\n","sourceOld":"  /***\n  public void testPerformance() throws IOException {\n    String s = \"now is the time-for all good men to come to-the aid of their country.\";\n    Token tok = new Token();\n    long start = System.currentTimeMillis();\n    int ret=0;\n    for (int i=0; i<1000000; i++) {\n      StringReader r = new StringReader(s);\n      TokenStream ts = new WhitespaceTokenizer(r);\n      ts = new WordDelimiterFilter(ts, 1,1,1,1,0);\n\n      while (ts.next(tok) != null) ret++;\n    }\n\n    System.out.println(\"ret=\"+ret+\" time=\"+(System.currentTimeMillis()-start));\n  }\n  ***/\n\n\n  public void testOffsets() throws IOException {\n\n    // test that subwords and catenated subwords have\n    // the correct offsets.\n    WordDelimiterFilter wdf = new WordDelimiterFilter(\n            new SingleTokenTokenStream(new Token(\"foo-bar\", 5, 12)),\n    1,1,0,0,1,1,0);\n\n    assertTokenStreamContents(wdf, \n        new String[] { \"foo\", \"bar\", \"foobar\" },\n        new int[] { 5, 9, 5 }, \n        new int[] { 8, 12, 12 });\n\n    wdf = new WordDelimiterFilter(\n            new SingleTokenTokenStream(new Token(\"foo-bar\", 5, 6)),\n    1,1,0,0,1,1,0);\n    \n    assertTokenStreamContents(wdf,\n        new String[] { \"foo\", \"bar\", \"foobar\" },\n        new int[] { 5, 5, 5 },\n        new int[] { 6, 6, 6 });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"c90f01e1c0f11ee52212ab38c6d4393b3be8a646":["e0d0e8297e9b3e015826cdb7e42404953c339851"],"e0d0e8297e9b3e015826cdb7e42404953c339851":["0ccc76b6c713f3e022bca745da888fa20a742772"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"ad94625fb8d088209f46650c8097196fec67f00c":["2fd023a662cc25ae7e0ad0f33d71c476a16d0579"],"2fd023a662cc25ae7e0ad0f33d71c476a16d0579":["c90f01e1c0f11ee52212ab38c6d4393b3be8a646"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"0ccc76b6c713f3e022bca745da888fa20a742772":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"]},"commit2Childs":{"c90f01e1c0f11ee52212ab38c6d4393b3be8a646":["2fd023a662cc25ae7e0ad0f33d71c476a16d0579"],"e0d0e8297e9b3e015826cdb7e42404953c339851":["c90f01e1c0f11ee52212ab38c6d4393b3be8a646"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["0ccc76b6c713f3e022bca745da888fa20a742772"],"ad94625fb8d088209f46650c8097196fec67f00c":[],"2fd023a662cc25ae7e0ad0f33d71c476a16d0579":["ad94625fb8d088209f46650c8097196fec67f00c"],"0ccc76b6c713f3e022bca745da888fa20a742772":["e0d0e8297e9b3e015826cdb7e42404953c339851"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ad94625fb8d088209f46650c8097196fec67f00c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"pathCommit":null}