{"path":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader#getReindexer(Path).mjava","commits":[{"id":"4d9aa91d3fdd25528bac3b2e6115d54fc2f28753","date":1416999434,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader#getReindexer(Path).mjava","pathOld":"/dev/null","sourceNew":"  private ReindexingReader getReindexer(Path root) throws IOException {\n    return new ReindexingReader(root) {\n      @Override\n      protected IndexWriterConfig getIndexWriterConfig() throws IOException {\n        return newIndexWriterConfig();\n      }\n\n      @Override\n      protected Directory openDirectory(Path path) throws IOException {\n        MockDirectoryWrapper dir = newMockFSDirectory(path);\n        dir.setUseSlowOpenClosers(false);\n        dir.setThrottling(Throttling.NEVER);\n        return dir;\n      }\n\n      @Override\n      protected void reindex(long oldSchemaGen, long newSchemaGen, LeafReader reader, Directory parallelDir) throws IOException {\n        IndexWriterConfig iwc = newIndexWriterConfig();\n\n        // The order of our docIDs must precisely matching incoming reader:\n        iwc.setMergePolicy(new LogByteSizeMergePolicy());\n        IndexWriter w = new IndexWriter(parallelDir, iwc);\n        int maxDoc = reader.maxDoc();\n\n        // Slowly parse the stored field into a new doc values field:\n        for(int i=0;i<maxDoc;i++) {\n          // TODO: is this still O(blockSize^2)?\n          StoredDocument oldDoc = reader.document(i);\n          Document newDoc = new Document();\n          long value = Long.parseLong(oldDoc.get(\"text\").split(\" \")[1]);\n          newDoc.add(new NumericDocValuesField(\"number\", value));\n          newDoc.add(new LongField(\"number\", value, Field.Store.NO));\n          w.addDocument(newDoc);\n        }\n\n        if (random().nextBoolean()) {\n          w.forceMerge(1);\n        }\n\n        w.close();\n      }\n\n      @Override\n      protected long getCurrentSchemaGen() {\n        return 0;\n      }\n    };\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f6450c8e5ae2fc3df8d5de3bce074cb72847ae23","date":1417512615,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader#getReindexer(Path).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader#getReindexer(Path).mjava","sourceNew":"  private ReindexingReader getReindexer(Path root) throws IOException {\n    return new ReindexingReader(root) {\n      @Override\n      protected IndexWriterConfig getIndexWriterConfig() throws IOException {\n        IndexWriterConfig iwc = newIndexWriterConfig();\n        TieredMergePolicy tmp = new TieredMergePolicy();\n        // We write tiny docs, so we need tiny floor to avoid O(N^2) merging:\n        tmp.setFloorSegmentMB(.01);\n        iwc.setMergePolicy(tmp);\n        return iwc;\n      }\n\n      @Override\n      protected Directory openDirectory(Path path) throws IOException {\n        MockDirectoryWrapper dir = newMockFSDirectory(path);\n        dir.setUseSlowOpenClosers(false);\n        dir.setThrottling(Throttling.NEVER);\n        return dir;\n      }\n\n      @Override\n      protected void reindex(long oldSchemaGen, long newSchemaGen, LeafReader reader, Directory parallelDir) throws IOException {\n        IndexWriterConfig iwc = newIndexWriterConfig();\n\n        // The order of our docIDs must precisely matching incoming reader:\n        iwc.setMergePolicy(new LogByteSizeMergePolicy());\n        IndexWriter w = new IndexWriter(parallelDir, iwc);\n        int maxDoc = reader.maxDoc();\n\n        // Slowly parse the stored field into a new doc values field:\n        for(int i=0;i<maxDoc;i++) {\n          // TODO: is this still O(blockSize^2)?\n          StoredDocument oldDoc = reader.document(i);\n          Document newDoc = new Document();\n          long value = Long.parseLong(oldDoc.get(\"text\").split(\" \")[1]);\n          newDoc.add(new NumericDocValuesField(\"number\", value));\n          newDoc.add(new LongField(\"number\", value, Field.Store.NO));\n          w.addDocument(newDoc);\n        }\n\n        if (random().nextBoolean()) {\n          w.forceMerge(1);\n        }\n\n        w.close();\n      }\n\n      @Override\n      protected long getCurrentSchemaGen() {\n        return 0;\n      }\n    };\n  }\n\n","sourceOld":"  private ReindexingReader getReindexer(Path root) throws IOException {\n    return new ReindexingReader(root) {\n      @Override\n      protected IndexWriterConfig getIndexWriterConfig() throws IOException {\n        return newIndexWriterConfig();\n      }\n\n      @Override\n      protected Directory openDirectory(Path path) throws IOException {\n        MockDirectoryWrapper dir = newMockFSDirectory(path);\n        dir.setUseSlowOpenClosers(false);\n        dir.setThrottling(Throttling.NEVER);\n        return dir;\n      }\n\n      @Override\n      protected void reindex(long oldSchemaGen, long newSchemaGen, LeafReader reader, Directory parallelDir) throws IOException {\n        IndexWriterConfig iwc = newIndexWriterConfig();\n\n        // The order of our docIDs must precisely matching incoming reader:\n        iwc.setMergePolicy(new LogByteSizeMergePolicy());\n        IndexWriter w = new IndexWriter(parallelDir, iwc);\n        int maxDoc = reader.maxDoc();\n\n        // Slowly parse the stored field into a new doc values field:\n        for(int i=0;i<maxDoc;i++) {\n          // TODO: is this still O(blockSize^2)?\n          StoredDocument oldDoc = reader.document(i);\n          Document newDoc = new Document();\n          long value = Long.parseLong(oldDoc.get(\"text\").split(\" \")[1]);\n          newDoc.add(new NumericDocValuesField(\"number\", value));\n          newDoc.add(new LongField(\"number\", value, Field.Store.NO));\n          w.addDocument(newDoc);\n        }\n\n        if (random().nextBoolean()) {\n          w.forceMerge(1);\n        }\n\n        w.close();\n      }\n\n      @Override\n      protected long getCurrentSchemaGen() {\n        return 0;\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"770342641f7b505eaa8dccdc666158bff2419109","date":1449868421,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader#getReindexer(Path).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader#getReindexer(Path).mjava","sourceNew":"  private ReindexingReader getReindexer(Path root) throws IOException {\n    return new ReindexingReader(root) {\n      @Override\n      protected IndexWriterConfig getIndexWriterConfig() throws IOException {\n        IndexWriterConfig iwc = newIndexWriterConfig();\n        TieredMergePolicy tmp = new TieredMergePolicy();\n        // We write tiny docs, so we need tiny floor to avoid O(N^2) merging:\n        tmp.setFloorSegmentMB(.01);\n        iwc.setMergePolicy(tmp);\n        return iwc;\n      }\n\n      @Override\n      protected Directory openDirectory(Path path) throws IOException {\n        MockDirectoryWrapper dir = newMockFSDirectory(path);\n        dir.setUseSlowOpenClosers(false);\n        dir.setThrottling(Throttling.NEVER);\n        return dir;\n      }\n\n      @Override\n      protected void reindex(long oldSchemaGen, long newSchemaGen, LeafReader reader, Directory parallelDir) throws IOException {\n        IndexWriterConfig iwc = newIndexWriterConfig();\n\n        // The order of our docIDs must precisely matching incoming reader:\n        iwc.setMergePolicy(new LogByteSizeMergePolicy());\n        IndexWriter w = new IndexWriter(parallelDir, iwc);\n        int maxDoc = reader.maxDoc();\n\n        // Slowly parse the stored field into a new doc values field:\n        for(int i=0;i<maxDoc;i++) {\n          // TODO: is this still O(blockSize^2)?\n          StoredDocument oldDoc = reader.document(i);\n          Document newDoc = new Document();\n          long value = Long.parseLong(oldDoc.get(\"text\").split(\" \")[1]);\n          newDoc.add(new NumericDocValuesField(\"number\", value));\n          newDoc.add(new DimensionalLongField(\"number\", value));\n          w.addDocument(newDoc);\n        }\n\n        if (random().nextBoolean()) {\n          w.forceMerge(1);\n        }\n\n        w.close();\n      }\n\n      @Override\n      protected long getCurrentSchemaGen() {\n        return 0;\n      }\n    };\n  }\n\n","sourceOld":"  private ReindexingReader getReindexer(Path root) throws IOException {\n    return new ReindexingReader(root) {\n      @Override\n      protected IndexWriterConfig getIndexWriterConfig() throws IOException {\n        IndexWriterConfig iwc = newIndexWriterConfig();\n        TieredMergePolicy tmp = new TieredMergePolicy();\n        // We write tiny docs, so we need tiny floor to avoid O(N^2) merging:\n        tmp.setFloorSegmentMB(.01);\n        iwc.setMergePolicy(tmp);\n        return iwc;\n      }\n\n      @Override\n      protected Directory openDirectory(Path path) throws IOException {\n        MockDirectoryWrapper dir = newMockFSDirectory(path);\n        dir.setUseSlowOpenClosers(false);\n        dir.setThrottling(Throttling.NEVER);\n        return dir;\n      }\n\n      @Override\n      protected void reindex(long oldSchemaGen, long newSchemaGen, LeafReader reader, Directory parallelDir) throws IOException {\n        IndexWriterConfig iwc = newIndexWriterConfig();\n\n        // The order of our docIDs must precisely matching incoming reader:\n        iwc.setMergePolicy(new LogByteSizeMergePolicy());\n        IndexWriter w = new IndexWriter(parallelDir, iwc);\n        int maxDoc = reader.maxDoc();\n\n        // Slowly parse the stored field into a new doc values field:\n        for(int i=0;i<maxDoc;i++) {\n          // TODO: is this still O(blockSize^2)?\n          StoredDocument oldDoc = reader.document(i);\n          Document newDoc = new Document();\n          long value = Long.parseLong(oldDoc.get(\"text\").split(\" \")[1]);\n          newDoc.add(new NumericDocValuesField(\"number\", value));\n          newDoc.add(new LongField(\"number\", value, Field.Store.NO));\n          w.addDocument(newDoc);\n        }\n\n        if (random().nextBoolean()) {\n          w.forceMerge(1);\n        }\n\n        w.close();\n      }\n\n      @Override\n      protected long getCurrentSchemaGen() {\n        return 0;\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","date":1453060490,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader#getReindexer(Path).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader#getReindexer(Path).mjava","sourceNew":"  private ReindexingReader getReindexer(Path root) throws IOException {\n    return new ReindexingReader(root) {\n      @Override\n      protected IndexWriterConfig getIndexWriterConfig() throws IOException {\n        IndexWriterConfig iwc = newIndexWriterConfig();\n        TieredMergePolicy tmp = new TieredMergePolicy();\n        // We write tiny docs, so we need tiny floor to avoid O(N^2) merging:\n        tmp.setFloorSegmentMB(.01);\n        iwc.setMergePolicy(tmp);\n        return iwc;\n      }\n\n      @Override\n      protected Directory openDirectory(Path path) throws IOException {\n        MockDirectoryWrapper dir = newMockFSDirectory(path);\n        dir.setUseSlowOpenClosers(false);\n        dir.setThrottling(Throttling.NEVER);\n        return dir;\n      }\n\n      @Override\n      protected void reindex(long oldSchemaGen, long newSchemaGen, LeafReader reader, Directory parallelDir) throws IOException {\n        IndexWriterConfig iwc = newIndexWriterConfig();\n\n        // The order of our docIDs must precisely matching incoming reader:\n        iwc.setMergePolicy(new LogByteSizeMergePolicy());\n        IndexWriter w = new IndexWriter(parallelDir, iwc);\n        int maxDoc = reader.maxDoc();\n\n        // Slowly parse the stored field into a new doc values field:\n        for(int i=0;i<maxDoc;i++) {\n          // TODO: is this still O(blockSize^2)?\n          Document oldDoc = reader.document(i);\n          Document newDoc = new Document();\n          long value = Long.parseLong(oldDoc.get(\"text\").split(\" \")[1]);\n          newDoc.add(new NumericDocValuesField(\"number\", value));\n          newDoc.add(new DimensionalLongField(\"number\", value));\n          w.addDocument(newDoc);\n        }\n\n        if (random().nextBoolean()) {\n          w.forceMerge(1);\n        }\n\n        w.close();\n      }\n\n      @Override\n      protected long getCurrentSchemaGen() {\n        return 0;\n      }\n    };\n  }\n\n","sourceOld":"  private ReindexingReader getReindexer(Path root) throws IOException {\n    return new ReindexingReader(root) {\n      @Override\n      protected IndexWriterConfig getIndexWriterConfig() throws IOException {\n        IndexWriterConfig iwc = newIndexWriterConfig();\n        TieredMergePolicy tmp = new TieredMergePolicy();\n        // We write tiny docs, so we need tiny floor to avoid O(N^2) merging:\n        tmp.setFloorSegmentMB(.01);\n        iwc.setMergePolicy(tmp);\n        return iwc;\n      }\n\n      @Override\n      protected Directory openDirectory(Path path) throws IOException {\n        MockDirectoryWrapper dir = newMockFSDirectory(path);\n        dir.setUseSlowOpenClosers(false);\n        dir.setThrottling(Throttling.NEVER);\n        return dir;\n      }\n\n      @Override\n      protected void reindex(long oldSchemaGen, long newSchemaGen, LeafReader reader, Directory parallelDir) throws IOException {\n        IndexWriterConfig iwc = newIndexWriterConfig();\n\n        // The order of our docIDs must precisely matching incoming reader:\n        iwc.setMergePolicy(new LogByteSizeMergePolicy());\n        IndexWriter w = new IndexWriter(parallelDir, iwc);\n        int maxDoc = reader.maxDoc();\n\n        // Slowly parse the stored field into a new doc values field:\n        for(int i=0;i<maxDoc;i++) {\n          // TODO: is this still O(blockSize^2)?\n          StoredDocument oldDoc = reader.document(i);\n          Document newDoc = new Document();\n          long value = Long.parseLong(oldDoc.get(\"text\").split(\" \")[1]);\n          newDoc.add(new NumericDocValuesField(\"number\", value));\n          newDoc.add(new DimensionalLongField(\"number\", value));\n          w.addDocument(newDoc);\n        }\n\n        if (random().nextBoolean()) {\n          w.forceMerge(1);\n        }\n\n        w.close();\n      }\n\n      @Override\n      protected long getCurrentSchemaGen() {\n        return 0;\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cab7a79353f33d1a94cd307bf33aa5148601ebe6","date":1453391888,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader#getReindexer(Path).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader#getReindexer(Path).mjava","sourceNew":"  private ReindexingReader getReindexer(Path root) throws IOException {\n    return new ReindexingReader(root) {\n      @Override\n      protected IndexWriterConfig getIndexWriterConfig() throws IOException {\n        IndexWriterConfig iwc = newIndexWriterConfig();\n        TieredMergePolicy tmp = new TieredMergePolicy();\n        // We write tiny docs, so we need tiny floor to avoid O(N^2) merging:\n        tmp.setFloorSegmentMB(.01);\n        iwc.setMergePolicy(tmp);\n        return iwc;\n      }\n\n      @Override\n      protected Directory openDirectory(Path path) throws IOException {\n        MockDirectoryWrapper dir = newMockFSDirectory(path);\n        dir.setUseSlowOpenClosers(false);\n        dir.setThrottling(Throttling.NEVER);\n        return dir;\n      }\n\n      @Override\n      protected void reindex(long oldSchemaGen, long newSchemaGen, LeafReader reader, Directory parallelDir) throws IOException {\n        IndexWriterConfig iwc = newIndexWriterConfig();\n\n        // The order of our docIDs must precisely matching incoming reader:\n        iwc.setMergePolicy(new LogByteSizeMergePolicy());\n        IndexWriter w = new IndexWriter(parallelDir, iwc);\n        int maxDoc = reader.maxDoc();\n\n        // Slowly parse the stored field into a new doc values field:\n        for(int i=0;i<maxDoc;i++) {\n          // TODO: is this still O(blockSize^2)?\n          Document oldDoc = reader.document(i);\n          Document newDoc = new Document();\n          long value = Long.parseLong(oldDoc.get(\"text\").split(\" \")[1]);\n          newDoc.add(new NumericDocValuesField(\"number\", value));\n          newDoc.add(new LongPoint(\"number\", value));\n          w.addDocument(newDoc);\n        }\n\n        if (random().nextBoolean()) {\n          w.forceMerge(1);\n        }\n\n        w.close();\n      }\n\n      @Override\n      protected long getCurrentSchemaGen() {\n        return 0;\n      }\n    };\n  }\n\n","sourceOld":"  private ReindexingReader getReindexer(Path root) throws IOException {\n    return new ReindexingReader(root) {\n      @Override\n      protected IndexWriterConfig getIndexWriterConfig() throws IOException {\n        IndexWriterConfig iwc = newIndexWriterConfig();\n        TieredMergePolicy tmp = new TieredMergePolicy();\n        // We write tiny docs, so we need tiny floor to avoid O(N^2) merging:\n        tmp.setFloorSegmentMB(.01);\n        iwc.setMergePolicy(tmp);\n        return iwc;\n      }\n\n      @Override\n      protected Directory openDirectory(Path path) throws IOException {\n        MockDirectoryWrapper dir = newMockFSDirectory(path);\n        dir.setUseSlowOpenClosers(false);\n        dir.setThrottling(Throttling.NEVER);\n        return dir;\n      }\n\n      @Override\n      protected void reindex(long oldSchemaGen, long newSchemaGen, LeafReader reader, Directory parallelDir) throws IOException {\n        IndexWriterConfig iwc = newIndexWriterConfig();\n\n        // The order of our docIDs must precisely matching incoming reader:\n        iwc.setMergePolicy(new LogByteSizeMergePolicy());\n        IndexWriter w = new IndexWriter(parallelDir, iwc);\n        int maxDoc = reader.maxDoc();\n\n        // Slowly parse the stored field into a new doc values field:\n        for(int i=0;i<maxDoc;i++) {\n          // TODO: is this still O(blockSize^2)?\n          Document oldDoc = reader.document(i);\n          Document newDoc = new Document();\n          long value = Long.parseLong(oldDoc.get(\"text\").split(\" \")[1]);\n          newDoc.add(new NumericDocValuesField(\"number\", value));\n          newDoc.add(new DimensionalLongField(\"number\", value));\n          w.addDocument(newDoc);\n        }\n\n        if (random().nextBoolean()) {\n          w.forceMerge(1);\n        }\n\n        w.close();\n      }\n\n      @Override\n      protected long getCurrentSchemaGen() {\n        return 0;\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1","date":1457644139,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader#getReindexer(Path).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader#getReindexer(Path).mjava","sourceNew":"  private ReindexingReader getReindexer(Path root) throws IOException {\n    return new ReindexingReader(root) {\n      @Override\n      protected IndexWriterConfig getIndexWriterConfig() throws IOException {\n        IndexWriterConfig iwc = newIndexWriterConfig();\n        TieredMergePolicy tmp = new TieredMergePolicy();\n        // We write tiny docs, so we need tiny floor to avoid O(N^2) merging:\n        tmp.setFloorSegmentMB(.01);\n        iwc.setMergePolicy(tmp);\n        return iwc;\n      }\n\n      @Override\n      protected Directory openDirectory(Path path) throws IOException {\n        MockDirectoryWrapper dir = newMockFSDirectory(path);\n        dir.setUseSlowOpenClosers(false);\n        dir.setThrottling(Throttling.NEVER);\n        return dir;\n      }\n\n      @Override\n      protected void reindex(long oldSchemaGen, long newSchemaGen, LeafReader reader, Directory parallelDir) throws IOException {\n        IndexWriterConfig iwc = newIndexWriterConfig();\n\n        // The order of our docIDs must precisely matching incoming reader:\n        iwc.setMergePolicy(new LogByteSizeMergePolicy());\n        IndexWriter w = new IndexWriter(parallelDir, iwc);\n        int maxDoc = reader.maxDoc();\n\n        // Slowly parse the stored field into a new doc values field:\n        for(int i=0;i<maxDoc;i++) {\n          // TODO: is this still O(blockSize^2)?\n          Document oldDoc = reader.document(i);\n          Document newDoc = new Document();\n          long value = Long.parseLong(oldDoc.get(\"text\").split(\" \")[1]);\n          newDoc.add(new NumericDocValuesField(\"number\", value));\n          newDoc.add(new LongPoint(\"number\", value));\n          w.addDocument(newDoc);\n        }\n\n        w.forceMerge(1);\n\n        w.close();\n      }\n\n      @Override\n      protected long getCurrentSchemaGen() {\n        return 0;\n      }\n    };\n  }\n\n","sourceOld":"  private ReindexingReader getReindexer(Path root) throws IOException {\n    return new ReindexingReader(root) {\n      @Override\n      protected IndexWriterConfig getIndexWriterConfig() throws IOException {\n        IndexWriterConfig iwc = newIndexWriterConfig();\n        TieredMergePolicy tmp = new TieredMergePolicy();\n        // We write tiny docs, so we need tiny floor to avoid O(N^2) merging:\n        tmp.setFloorSegmentMB(.01);\n        iwc.setMergePolicy(tmp);\n        return iwc;\n      }\n\n      @Override\n      protected Directory openDirectory(Path path) throws IOException {\n        MockDirectoryWrapper dir = newMockFSDirectory(path);\n        dir.setUseSlowOpenClosers(false);\n        dir.setThrottling(Throttling.NEVER);\n        return dir;\n      }\n\n      @Override\n      protected void reindex(long oldSchemaGen, long newSchemaGen, LeafReader reader, Directory parallelDir) throws IOException {\n        IndexWriterConfig iwc = newIndexWriterConfig();\n\n        // The order of our docIDs must precisely matching incoming reader:\n        iwc.setMergePolicy(new LogByteSizeMergePolicy());\n        IndexWriter w = new IndexWriter(parallelDir, iwc);\n        int maxDoc = reader.maxDoc();\n\n        // Slowly parse the stored field into a new doc values field:\n        for(int i=0;i<maxDoc;i++) {\n          // TODO: is this still O(blockSize^2)?\n          Document oldDoc = reader.document(i);\n          Document newDoc = new Document();\n          long value = Long.parseLong(oldDoc.get(\"text\").split(\" \")[1]);\n          newDoc.add(new NumericDocValuesField(\"number\", value));\n          newDoc.add(new LongPoint(\"number\", value));\n          w.addDocument(newDoc);\n        }\n\n        if (random().nextBoolean()) {\n          w.forceMerge(1);\n        }\n\n        w.close();\n      }\n\n      @Override\n      protected long getCurrentSchemaGen() {\n        return 0;\n      }\n    };\n  }\n\n","bugFix":["4d9aa91d3fdd25528bac3b2e6115d54fc2f28753"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1":["cab7a79353f33d1a94cd307bf33aa5148601ebe6"],"cab7a79353f33d1a94cd307bf33aa5148601ebe6":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"4d9aa91d3fdd25528bac3b2e6115d54fc2f28753":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"f6450c8e5ae2fc3df8d5de3bce074cb72847ae23":["4d9aa91d3fdd25528bac3b2e6115d54fc2f28753"],"770342641f7b505eaa8dccdc666158bff2419109":["f6450c8e5ae2fc3df8d5de3bce074cb72847ae23"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["770342641f7b505eaa8dccdc666158bff2419109"]},"commit2Childs":{"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cab7a79353f33d1a94cd307bf33aa5148601ebe6":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"4d9aa91d3fdd25528bac3b2e6115d54fc2f28753":["f6450c8e5ae2fc3df8d5de3bce074cb72847ae23"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4d9aa91d3fdd25528bac3b2e6115d54fc2f28753"],"f6450c8e5ae2fc3df8d5de3bce074cb72847ae23":["770342641f7b505eaa8dccdc666158bff2419109"],"770342641f7b505eaa8dccdc666158bff2419109":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["cab7a79353f33d1a94cd307bf33aa5148601ebe6"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}