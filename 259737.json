{"path":"solr/core/src/test/org/apache/solr/cloud/api/collections/TestHdfsCloudBackupRestore#setupClass().mjava","commits":[{"id":"6146c07c0dee1ae1e42926167acd127fed5ef59d","date":1516129420,"type":1,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/TestHdfsCloudBackupRestore#setupClass().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestHdfsCloudBackupRestore#setupClass().mjava","sourceNew":"  @BeforeClass\n  public static void setupClass() throws Exception {\n    dfsCluster = HdfsTestUtil.setupClass(createTempDir().toFile().getAbsolutePath());\n    hdfsUri = HdfsTestUtil.getURI(dfsCluster);\n    try {\n      URI uri = new URI(hdfsUri);\n      Configuration conf = HdfsTestUtil.getClientConfiguration(dfsCluster);\n      conf.setBoolean(\"fs.hdfs.impl.disable.cache\", true);\n      fs = FileSystem.get(uri, conf);\n\n      if (fs instanceof DistributedFileSystem) {\n        // Make sure dfs is not in safe mode\n        while (((DistributedFileSystem) fs).setSafeMode(SafeModeAction.SAFEMODE_GET, true)) {\n          log.warn(\"The NameNode is in SafeMode - Solr will wait 5 seconds and try again.\");\n          try {\n            Thread.sleep(5000);\n          } catch (InterruptedException e) {\n            Thread.interrupted();\n            // continue\n          }\n        }\n      }\n\n      fs.mkdirs(new org.apache.hadoop.fs.Path(\"/backup\"));\n    } catch (IOException | URISyntaxException e) {\n      throw new RuntimeException(e);\n    }\n\n    System.setProperty(\"solr.hdfs.default.backup.path\", \"/backup\");\n    System.setProperty(\"solr.hdfs.home\", hdfsUri + \"/solr\");\n    useFactory(\"solr.StandardDirectoryFactory\");\n\n    configureCluster(NUM_SHARDS)// nodes\n    .addConfig(\"conf1\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-minimal\").resolve(\"conf\"))\n    .withSolrXml(SOLR_XML)\n    .configure();\n  }\n\n","sourceOld":"  @BeforeClass\n  public static void setupClass() throws Exception {\n    dfsCluster = HdfsTestUtil.setupClass(createTempDir().toFile().getAbsolutePath());\n    hdfsUri = HdfsTestUtil.getURI(dfsCluster);\n    try {\n      URI uri = new URI(hdfsUri);\n      Configuration conf = HdfsTestUtil.getClientConfiguration(dfsCluster);\n      conf.setBoolean(\"fs.hdfs.impl.disable.cache\", true);\n      fs = FileSystem.get(uri, conf);\n\n      if (fs instanceof DistributedFileSystem) {\n        // Make sure dfs is not in safe mode\n        while (((DistributedFileSystem) fs).setSafeMode(SafeModeAction.SAFEMODE_GET, true)) {\n          log.warn(\"The NameNode is in SafeMode - Solr will wait 5 seconds and try again.\");\n          try {\n            Thread.sleep(5000);\n          } catch (InterruptedException e) {\n            Thread.interrupted();\n            // continue\n          }\n        }\n      }\n\n      fs.mkdirs(new org.apache.hadoop.fs.Path(\"/backup\"));\n    } catch (IOException | URISyntaxException e) {\n      throw new RuntimeException(e);\n    }\n\n    System.setProperty(\"solr.hdfs.default.backup.path\", \"/backup\");\n    System.setProperty(\"solr.hdfs.home\", hdfsUri + \"/solr\");\n    useFactory(\"solr.StandardDirectoryFactory\");\n\n    configureCluster(NUM_SHARDS)// nodes\n    .addConfig(\"conf1\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-minimal\").resolve(\"conf\"))\n    .withSolrXml(SOLR_XML)\n    .configure();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b94236357aaa22b76c10629851fe4e376e0cea82","date":1516710914,"type":1,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/TestHdfsCloudBackupRestore#setupClass().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestHdfsCloudBackupRestore#setupClass().mjava","sourceNew":"  @BeforeClass\n  public static void setupClass() throws Exception {\n    dfsCluster = HdfsTestUtil.setupClass(createTempDir().toFile().getAbsolutePath());\n    hdfsUri = HdfsTestUtil.getURI(dfsCluster);\n    try {\n      URI uri = new URI(hdfsUri);\n      Configuration conf = HdfsTestUtil.getClientConfiguration(dfsCluster);\n      conf.setBoolean(\"fs.hdfs.impl.disable.cache\", true);\n      fs = FileSystem.get(uri, conf);\n\n      if (fs instanceof DistributedFileSystem) {\n        // Make sure dfs is not in safe mode\n        while (((DistributedFileSystem) fs).setSafeMode(SafeModeAction.SAFEMODE_GET, true)) {\n          log.warn(\"The NameNode is in SafeMode - Solr will wait 5 seconds and try again.\");\n          try {\n            Thread.sleep(5000);\n          } catch (InterruptedException e) {\n            Thread.interrupted();\n            // continue\n          }\n        }\n      }\n\n      fs.mkdirs(new org.apache.hadoop.fs.Path(\"/backup\"));\n    } catch (IOException | URISyntaxException e) {\n      throw new RuntimeException(e);\n    }\n\n    System.setProperty(\"solr.hdfs.default.backup.path\", \"/backup\");\n    System.setProperty(\"solr.hdfs.home\", hdfsUri + \"/solr\");\n    useFactory(\"solr.StandardDirectoryFactory\");\n\n    configureCluster(NUM_SHARDS)// nodes\n    .addConfig(\"conf1\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-minimal\").resolve(\"conf\"))\n    .withSolrXml(SOLR_XML)\n    .configure();\n  }\n\n","sourceOld":"  @BeforeClass\n  public static void setupClass() throws Exception {\n    dfsCluster = HdfsTestUtil.setupClass(createTempDir().toFile().getAbsolutePath());\n    hdfsUri = HdfsTestUtil.getURI(dfsCluster);\n    try {\n      URI uri = new URI(hdfsUri);\n      Configuration conf = HdfsTestUtil.getClientConfiguration(dfsCluster);\n      conf.setBoolean(\"fs.hdfs.impl.disable.cache\", true);\n      fs = FileSystem.get(uri, conf);\n\n      if (fs instanceof DistributedFileSystem) {\n        // Make sure dfs is not in safe mode\n        while (((DistributedFileSystem) fs).setSafeMode(SafeModeAction.SAFEMODE_GET, true)) {\n          log.warn(\"The NameNode is in SafeMode - Solr will wait 5 seconds and try again.\");\n          try {\n            Thread.sleep(5000);\n          } catch (InterruptedException e) {\n            Thread.interrupted();\n            // continue\n          }\n        }\n      }\n\n      fs.mkdirs(new org.apache.hadoop.fs.Path(\"/backup\"));\n    } catch (IOException | URISyntaxException e) {\n      throw new RuntimeException(e);\n    }\n\n    System.setProperty(\"solr.hdfs.default.backup.path\", \"/backup\");\n    System.setProperty(\"solr.hdfs.home\", hdfsUri + \"/solr\");\n    useFactory(\"solr.StandardDirectoryFactory\");\n\n    configureCluster(NUM_SHARDS)// nodes\n    .addConfig(\"conf1\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-minimal\").resolve(\"conf\"))\n    .withSolrXml(SOLR_XML)\n    .configure();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab6131420a270c49b653c969cc1dbbaf7d1b36e7","date":1550697886,"type":3,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/TestHdfsCloudBackupRestore#setupClass().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/api/collections/TestHdfsCloudBackupRestore#setupClass().mjava","sourceNew":"  @BeforeClass\n  public static void setupClass() throws Exception {\n    dfsCluster = HdfsTestUtil.setupClass(createTempDir().toFile().getAbsolutePath());\n    hdfsUri = HdfsTestUtil.getURI(dfsCluster);\n    try {\n      URI uri = new URI(hdfsUri);\n      Configuration conf = HdfsTestUtil.getClientConfiguration(dfsCluster);\n      conf.setBoolean(\"fs.hdfs.impl.disable.cache\", true);\n      fs = FileSystem.get(uri, conf);\n\n      if (fs instanceof DistributedFileSystem) {\n        // Make sure dfs is not in safe mode\n        while (((DistributedFileSystem) fs).setSafeMode(SafeModeAction.SAFEMODE_GET, true)) {\n          log.warn(\"The NameNode is in SafeMode - Solr will wait 5 seconds and try again.\");\n          try {\n            Thread.sleep(5000);\n          } catch (InterruptedException e) {\n            Thread.interrupted();\n            // continue\n          }\n        }\n      }\n\n      fs.mkdirs(new org.apache.hadoop.fs.Path(\"/backup\"));\n    } catch (IOException | URISyntaxException e) {\n      throw new RuntimeException(e);\n    }\n\n    System.setProperty(\"solr.hdfs.default.backup.path\", \"/backup\");\n    System.setProperty(\"solr.hdfs.home\", hdfsUri + \"/solr\");\n    useFactory(\"solr.StandardDirectoryFactory\");\n\n    configureCluster(NUM_SHARDS)// nodes\n    .addConfig(\"conf1\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-minimal\").resolve(\"conf\"))\n    .addConfig(\"confFaulty\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-minimal\").resolve(\"conf\"))\n    .withSolrXml(SOLR_XML)\n    .configure();\n    cluster.getZkClient().delete(ZkConfigManager.CONFIGS_ZKNODE + Path.SEPARATOR + \"confFaulty\" + Path.SEPARATOR + \"solrconfig.xml\", -1, true);\n  }\n\n","sourceOld":"  @BeforeClass\n  public static void setupClass() throws Exception {\n    dfsCluster = HdfsTestUtil.setupClass(createTempDir().toFile().getAbsolutePath());\n    hdfsUri = HdfsTestUtil.getURI(dfsCluster);\n    try {\n      URI uri = new URI(hdfsUri);\n      Configuration conf = HdfsTestUtil.getClientConfiguration(dfsCluster);\n      conf.setBoolean(\"fs.hdfs.impl.disable.cache\", true);\n      fs = FileSystem.get(uri, conf);\n\n      if (fs instanceof DistributedFileSystem) {\n        // Make sure dfs is not in safe mode\n        while (((DistributedFileSystem) fs).setSafeMode(SafeModeAction.SAFEMODE_GET, true)) {\n          log.warn(\"The NameNode is in SafeMode - Solr will wait 5 seconds and try again.\");\n          try {\n            Thread.sleep(5000);\n          } catch (InterruptedException e) {\n            Thread.interrupted();\n            // continue\n          }\n        }\n      }\n\n      fs.mkdirs(new org.apache.hadoop.fs.Path(\"/backup\"));\n    } catch (IOException | URISyntaxException e) {\n      throw new RuntimeException(e);\n    }\n\n    System.setProperty(\"solr.hdfs.default.backup.path\", \"/backup\");\n    System.setProperty(\"solr.hdfs.home\", hdfsUri + \"/solr\");\n    useFactory(\"solr.StandardDirectoryFactory\");\n\n    configureCluster(NUM_SHARDS)// nodes\n    .addConfig(\"conf1\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-minimal\").resolve(\"conf\"))\n    .withSolrXml(SOLR_XML)\n    .configure();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"add53de9835b2cd1a7a80b4e0036afee171c9fdf","date":1552937136,"type":3,"author":"Kevin Risden","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/TestHdfsCloudBackupRestore#setupClass().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/api/collections/TestHdfsCloudBackupRestore#setupClass().mjava","sourceNew":"  @BeforeClass\n  public static void setupClass() throws Exception {\n    dfsCluster = HdfsTestUtil.setupClass(createTempDir().toFile().getAbsolutePath());\n    hdfsUri = HdfsTestUtil.getURI(dfsCluster);\n    try {\n      URI uri = new URI(hdfsUri);\n      Configuration conf = HdfsTestUtil.getClientConfiguration(dfsCluster);\n      fs = FileSystem.get(uri, conf);\n\n      if (fs instanceof DistributedFileSystem) {\n        // Make sure dfs is not in safe mode\n        while (((DistributedFileSystem) fs).setSafeMode(SafeModeAction.SAFEMODE_GET, true)) {\n          log.warn(\"The NameNode is in SafeMode - Solr will wait 5 seconds and try again.\");\n          try {\n            Thread.sleep(5000);\n          } catch (InterruptedException e) {\n            Thread.interrupted();\n            // continue\n          }\n        }\n      }\n\n      fs.mkdirs(new org.apache.hadoop.fs.Path(\"/backup\"));\n    } catch (IOException | URISyntaxException e) {\n      throw new RuntimeException(e);\n    }\n\n    System.setProperty(\"solr.hdfs.default.backup.path\", \"/backup\");\n    System.setProperty(\"solr.hdfs.home\", hdfsUri + \"/solr\");\n    useFactory(\"solr.StandardDirectoryFactory\");\n\n    configureCluster(NUM_SHARDS)// nodes\n    .addConfig(\"conf1\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-minimal\").resolve(\"conf\"))\n    .addConfig(\"confFaulty\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-minimal\").resolve(\"conf\"))\n    .withSolrXml(SOLR_XML)\n    .configure();\n    cluster.getZkClient().delete(ZkConfigManager.CONFIGS_ZKNODE + Path.SEPARATOR + \"confFaulty\" + Path.SEPARATOR + \"solrconfig.xml\", -1, true);\n  }\n\n","sourceOld":"  @BeforeClass\n  public static void setupClass() throws Exception {\n    dfsCluster = HdfsTestUtil.setupClass(createTempDir().toFile().getAbsolutePath());\n    hdfsUri = HdfsTestUtil.getURI(dfsCluster);\n    try {\n      URI uri = new URI(hdfsUri);\n      Configuration conf = HdfsTestUtil.getClientConfiguration(dfsCluster);\n      conf.setBoolean(\"fs.hdfs.impl.disable.cache\", true);\n      fs = FileSystem.get(uri, conf);\n\n      if (fs instanceof DistributedFileSystem) {\n        // Make sure dfs is not in safe mode\n        while (((DistributedFileSystem) fs).setSafeMode(SafeModeAction.SAFEMODE_GET, true)) {\n          log.warn(\"The NameNode is in SafeMode - Solr will wait 5 seconds and try again.\");\n          try {\n            Thread.sleep(5000);\n          } catch (InterruptedException e) {\n            Thread.interrupted();\n            // continue\n          }\n        }\n      }\n\n      fs.mkdirs(new org.apache.hadoop.fs.Path(\"/backup\"));\n    } catch (IOException | URISyntaxException e) {\n      throw new RuntimeException(e);\n    }\n\n    System.setProperty(\"solr.hdfs.default.backup.path\", \"/backup\");\n    System.setProperty(\"solr.hdfs.home\", hdfsUri + \"/solr\");\n    useFactory(\"solr.StandardDirectoryFactory\");\n\n    configureCluster(NUM_SHARDS)// nodes\n    .addConfig(\"conf1\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-minimal\").resolve(\"conf\"))\n    .addConfig(\"confFaulty\", TEST_PATH().resolve(\"configsets\").resolve(\"cloud-minimal\").resolve(\"conf\"))\n    .withSolrXml(SOLR_XML)\n    .configure();\n    cluster.getZkClient().delete(ZkConfigManager.CONFIGS_ZKNODE + Path.SEPARATOR + \"confFaulty\" + Path.SEPARATOR + \"solrconfig.xml\", -1, true);\n  }\n\n","bugFix":["4c623a7f72be34d6c45bee682028c50327d9e4b7"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ab6131420a270c49b653c969cc1dbbaf7d1b36e7":["b94236357aaa22b76c10629851fe4e376e0cea82"],"b94236357aaa22b76c10629851fe4e376e0cea82":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","6146c07c0dee1ae1e42926167acd127fed5ef59d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"6146c07c0dee1ae1e42926167acd127fed5ef59d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["add53de9835b2cd1a7a80b4e0036afee171c9fdf"],"add53de9835b2cd1a7a80b4e0036afee171c9fdf":["ab6131420a270c49b653c969cc1dbbaf7d1b36e7"]},"commit2Childs":{"ab6131420a270c49b653c969cc1dbbaf7d1b36e7":["add53de9835b2cd1a7a80b4e0036afee171c9fdf"],"b94236357aaa22b76c10629851fe4e376e0cea82":["ab6131420a270c49b653c969cc1dbbaf7d1b36e7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b94236357aaa22b76c10629851fe4e376e0cea82","6146c07c0dee1ae1e42926167acd127fed5ef59d"],"6146c07c0dee1ae1e42926167acd127fed5ef59d":["b94236357aaa22b76c10629851fe4e376e0cea82"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"add53de9835b2cd1a7a80b4e0036afee171c9fdf":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}