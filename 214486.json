{"path":"lucene/core/src/java/org/apache/lucene/analysis/Token#Token(char[],int,int,int,int).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/Token#Token(char[],int,int,int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/analysis/Token#Token(char[],int,int,int,int).mjava","sourceNew":"  /**\n   *  Constructs a Token with the given term buffer (offset\n   *  & length), start and end\n   *  offsets\n   * @param startTermBuffer\n   * @param termBufferOffset\n   * @param termBufferLength\n   * @param start\n   * @param end\n   */\n  public Token(char[] startTermBuffer, int termBufferOffset, int termBufferLength, int start, int end) {\n    copyBuffer(startTermBuffer, termBufferOffset, termBufferLength);\n    startOffset = start;\n    endOffset = end;\n  }\n\n","sourceOld":"  /**\n   *  Constructs a Token with the given term buffer (offset\n   *  & length), start and end\n   *  offsets\n   * @param startTermBuffer\n   * @param termBufferOffset\n   * @param termBufferLength\n   * @param start\n   * @param end\n   */\n  public Token(char[] startTermBuffer, int termBufferOffset, int termBufferLength, int start, int end) {\n    copyBuffer(startTermBuffer, termBufferOffset, termBufferLength);\n    startOffset = start;\n    endOffset = end;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cd65a3c65e7917a381c935b0b663d8e783bd9a1e","date":1339372221,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/Token#Token(char[],int,int,int,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/Token#Token(char[],int,int,int,int).mjava","sourceNew":"  /**\n   *  Constructs a Token with the given term buffer (offset\n   *  & length), start and end\n   *  offsets\n   * @param startTermBuffer\n   * @param termBufferOffset\n   * @param termBufferLength\n   * @param start\n   * @param end\n   */\n  public Token(char[] startTermBuffer, int termBufferOffset, int termBufferLength, int start, int end) {\n    checkOffsets(start, end);\n    copyBuffer(startTermBuffer, termBufferOffset, termBufferLength);\n    startOffset = start;\n    endOffset = end;\n  }\n\n","sourceOld":"  /**\n   *  Constructs a Token with the given term buffer (offset\n   *  & length), start and end\n   *  offsets\n   * @param startTermBuffer\n   * @param termBufferOffset\n   * @param termBufferLength\n   * @param start\n   * @param end\n   */\n  public Token(char[] startTermBuffer, int termBufferOffset, int termBufferLength, int start, int end) {\n    copyBuffer(startTermBuffer, termBufferOffset, termBufferLength);\n    startOffset = start;\n    endOffset = end;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"27f7a67b528a360bdc01ea05af57e6459fe42ac0","date":1346299172,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/Token#Token(char[],int,int,int,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/Token#Token(char[],int,int,int,int).mjava","sourceNew":"  /**\n   *  Constructs a Token with the given term buffer (offset\n   *  & length), start and end\n   *  offsets\n   * @param startTermBuffer buffer containing term text\n   * @param termBufferOffset the index in the buffer of the first character\n   * @param termBufferLength number of valid characters in the buffer\n   * @param start start offset in the source text\n   * @param end end offset in the source text\n   */\n  public Token(char[] startTermBuffer, int termBufferOffset, int termBufferLength, int start, int end) {\n    checkOffsets(start, end);\n    copyBuffer(startTermBuffer, termBufferOffset, termBufferLength);\n    startOffset = start;\n    endOffset = end;\n  }\n\n","sourceOld":"  /**\n   *  Constructs a Token with the given term buffer (offset\n   *  & length), start and end\n   *  offsets\n   * @param startTermBuffer\n   * @param termBufferOffset\n   * @param termBufferLength\n   * @param start\n   * @param end\n   */\n  public Token(char[] startTermBuffer, int termBufferOffset, int termBufferLength, int start, int end) {\n    checkOffsets(start, end);\n    copyBuffer(startTermBuffer, termBufferOffset, termBufferLength);\n    startOffset = start;\n    endOffset = end;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"05a14b2611ead08655a2b2bdc61632eb31316e57","date":1346366621,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/Token#Token(char[],int,int,int,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/Token#Token(char[],int,int,int,int).mjava","sourceNew":"  /**\n   *  Constructs a Token with the given term buffer (offset\n   *  & length), start and end\n   *  offsets\n   * @param startTermBuffer buffer containing term text\n   * @param termBufferOffset the index in the buffer of the first character\n   * @param termBufferLength number of valid characters in the buffer\n   * @param start start offset in the source text\n   * @param end end offset in the source text\n   */\n  public Token(char[] startTermBuffer, int termBufferOffset, int termBufferLength, int start, int end) {\n    checkOffsets(start, end);\n    copyBuffer(startTermBuffer, termBufferOffset, termBufferLength);\n    startOffset = start;\n    endOffset = end;\n  }\n\n","sourceOld":"  /**\n   *  Constructs a Token with the given term buffer (offset\n   *  & length), start and end\n   *  offsets\n   * @param startTermBuffer\n   * @param termBufferOffset\n   * @param termBufferLength\n   * @param start\n   * @param end\n   */\n  public Token(char[] startTermBuffer, int termBufferOffset, int termBufferLength, int start, int end) {\n    checkOffsets(start, end);\n    copyBuffer(startTermBuffer, termBufferOffset, termBufferLength);\n    startOffset = start;\n    endOffset = end;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"93124590c6e2a8b45898cbae46f96c3a05d9bce0","date":1399415098,"type":4,"author":"Uwe Schindler","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/Token#Token(char[],int,int,int,int).mjava","sourceNew":null,"sourceOld":"  /**\n   *  Constructs a Token with the given term buffer (offset\n   *  & length), start and end\n   *  offsets\n   * @param startTermBuffer buffer containing term text\n   * @param termBufferOffset the index in the buffer of the first character\n   * @param termBufferLength number of valid characters in the buffer\n   * @param start start offset in the source text\n   * @param end end offset in the source text\n   */\n  public Token(char[] startTermBuffer, int termBufferOffset, int termBufferLength, int start, int end) {\n    checkOffsets(start, end);\n    copyBuffer(startTermBuffer, termBufferOffset, termBufferLength);\n    startOffset = start;\n    endOffset = end;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"93124590c6e2a8b45898cbae46f96c3a05d9bce0":["27f7a67b528a360bdc01ea05af57e6459fe42ac0"],"27f7a67b528a360bdc01ea05af57e6459fe42ac0":["cd65a3c65e7917a381c935b0b663d8e783bd9a1e"],"cd65a3c65e7917a381c935b0b663d8e783bd9a1e":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"05a14b2611ead08655a2b2bdc61632eb31316e57":["cd65a3c65e7917a381c935b0b663d8e783bd9a1e","27f7a67b528a360bdc01ea05af57e6459fe42ac0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["93124590c6e2a8b45898cbae46f96c3a05d9bce0"]},"commit2Childs":{"93124590c6e2a8b45898cbae46f96c3a05d9bce0":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"27f7a67b528a360bdc01ea05af57e6459fe42ac0":["93124590c6e2a8b45898cbae46f96c3a05d9bce0","05a14b2611ead08655a2b2bdc61632eb31316e57"],"cd65a3c65e7917a381c935b0b663d8e783bd9a1e":["27f7a67b528a360bdc01ea05af57e6459fe42ac0","05a14b2611ead08655a2b2bdc61632eb31316e57"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd65a3c65e7917a381c935b0b663d8e783bd9a1e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"05a14b2611ead08655a2b2bdc61632eb31316e57":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["05a14b2611ead08655a2b2bdc61632eb31316e57","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}