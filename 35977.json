{"path":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","commits":[{"id":"47402a40696c1b7bc0524a8857b833c00f4cde3f","date":1363792699,"type":1,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        dataDir = cd.getDataDir();\n        try {\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.normalize(SolrResourceLoader\n                .normalizeDir(cd.getInstanceDir()) + dataDir);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistribuedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        initDirectoryFactory();\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        @Override\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        dataDir = cd.getDataDir();\n        try {\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.normalize(SolrResourceLoader\n                .normalizeDir(cd.getInstanceDir()) + dataDir);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistribuedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (updateHandler == null) {\n        initDeletionPolicy();\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        initDirectoryFactory();\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        @Override\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9cf81bc8c6e4078e236f0e38b3a2d0271854f207","date":1364832963,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        dataDir = cd.getDataDir();\n        try {\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.normalize(SolrResourceLoader\n                .normalizeDir(cd.getInstanceDir()) + dataDir);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        initDirectoryFactory();\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        @Override\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        dataDir = cd.getDataDir();\n        try {\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.normalize(SolrResourceLoader\n                .normalizeDir(cd.getInstanceDir()) + dataDir);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistribuedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        initDirectoryFactory();\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        @Override\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"08970e5b8411182a29412c177eff67ec1110095b","date":1366640815,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        dataDir = cd.getDataDir();\n        try {\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.normalize(SolrResourceLoader\n                .normalizeDir(cd.getInstanceDir()) + dataDir);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        initDirectoryFactory();\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        @Override\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        dataDir = cd.getDataDir();\n        try {\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.normalize(SolrResourceLoader\n                .normalizeDir(cd.getInstanceDir()) + dataDir);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        initDirectoryFactory();\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        @Override\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"41e1b8818332825c60cfbd7efa38294078eae898","date":1369337752,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        dataDir = cd.getDataDir();\n        try {\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.normalize(SolrResourceLoader\n                .normalizeDir(cd.getInstanceDir()) + dataDir);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        initDirectoryFactory();\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        @Override\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n    \n    if (cc != null && cc.isZooKeeperAware() && Slice.CONSTRUCTION.equals(cd.getCloudDescriptor().getShardState())) {\n      // set update log to buffer before publishing the core\n      getUpdateHandler().getUpdateLog().bufferUpdates();\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        dataDir = cd.getDataDir();\n        try {\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.normalize(SolrResourceLoader\n                .normalizeDir(cd.getInstanceDir()) + dataDir);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        initDirectoryFactory();\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        @Override\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"07e5c48260f0b3abf6daef83f4ce8bd72b0be5ce","date":1370818281,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        dataDir = cd.getDataDir();\n        try {\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.normalize(SolrResourceLoader\n                .normalizeDir(cd.getInstanceDir()) + dataDir);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        initDirectoryFactory();\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        @Override\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n    \n    if (cc != null && cc.isZooKeeperAware() && Slice.CONSTRUCTION.equals(cd.getCloudDescriptor().getShardState())) {\n      // set update log to buffer before publishing the core\n      getUpdateHandler().getUpdateLog().bufferUpdates();\n      \n      cd.getCloudDescriptor().setShardState(null);\n      cd.getCloudDescriptor().setShardRange(null);\n      \n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        dataDir = cd.getDataDir();\n        try {\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.normalize(SolrResourceLoader\n                .normalizeDir(cd.getInstanceDir()) + dataDir);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        initDirectoryFactory();\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        @Override\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n    \n    if (cc != null && cc.isZooKeeperAware() && Slice.CONSTRUCTION.equals(cd.getCloudDescriptor().getShardState())) {\n      // set update log to buffer before publishing the core\n      getUpdateHandler().getUpdateLog().bufferUpdates();\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3a540622c5e216f2d96b1199c35603eaff1020e9","date":1370871574,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        dataDir = cd.getDataDir();\n        try {\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.normalize(SolrResourceLoader\n                .normalizeDir(cd.getInstanceDir()) + dataDir);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        initDirectoryFactory();\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        @Override\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n    \n    if (cc != null) {\n      if (cc.cfg != null && cc.cfg instanceof ConfigSolrXml) {\n        writePropFile(cd, cc);\n      }\n    }\n\n    if (cc != null && cc.isZooKeeperAware() && Slice.CONSTRUCTION.equals(cd.getCloudDescriptor().getShardState())) {\n      // set update log to buffer before publishing the core\n      getUpdateHandler().getUpdateLog().bufferUpdates();\n      \n      cd.getCloudDescriptor().setShardState(null);\n      cd.getCloudDescriptor().setShardRange(null);\n      \n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        dataDir = cd.getDataDir();\n        try {\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.normalize(SolrResourceLoader\n                .normalizeDir(cd.getInstanceDir()) + dataDir);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        initDirectoryFactory();\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        @Override\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n    \n    if (cc != null && cc.isZooKeeperAware() && Slice.CONSTRUCTION.equals(cd.getCloudDescriptor().getShardState())) {\n      // set update log to buffer before publishing the core\n      getUpdateHandler().getUpdateLog().bufferUpdates();\n      \n      cd.getCloudDescriptor().setShardState(null);\n      cd.getCloudDescriptor().setShardRange(null);\n      \n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"849494cf2f3a96af5c8c84995108ddd8456fcd04","date":1372277913,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        @Override\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n    \n    if (cc != null) {\n      if (cc.cfg != null && cc.cfg instanceof ConfigSolrXml) {\n        writePropFile(cd, cc);\n      }\n    }\n\n    if (cc != null && cc.isZooKeeperAware() && Slice.CONSTRUCTION.equals(cd.getCloudDescriptor().getShardState())) {\n      // set update log to buffer before publishing the core\n      getUpdateHandler().getUpdateLog().bufferUpdates();\n      \n      cd.getCloudDescriptor().setShardState(null);\n      cd.getCloudDescriptor().setShardRange(null);\n      \n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        dataDir = cd.getDataDir();\n        try {\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.normalize(SolrResourceLoader\n                .normalizeDir(cd.getInstanceDir()) + dataDir);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        initDirectoryFactory();\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        @Override\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n    \n    if (cc != null) {\n      if (cc.cfg != null && cc.cfg instanceof ConfigSolrXml) {\n        writePropFile(cd, cc);\n      }\n    }\n\n    if (cc != null && cc.isZooKeeperAware() && Slice.CONSTRUCTION.equals(cd.getCloudDescriptor().getShardState())) {\n      // set update log to buffer before publishing the core\n      getUpdateHandler().getUpdateLog().bufferUpdates();\n      \n      cd.getCloudDescriptor().setShardState(null);\n      cd.getCloudDescriptor().setShardRange(null);\n      \n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a3b687d77563d946578f099495d70e55c92f3f1d","date":1373111282,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n    \n    if (cc != null) {\n      if (cc.cfg != null && cc.cfg instanceof ConfigSolrXml) {\n        writePropFile(cd, cc);\n      }\n    }\n\n    if (cc != null && cc.isZooKeeperAware() && Slice.CONSTRUCTION.equals(cd.getCloudDescriptor().getShardState())) {\n      // set update log to buffer before publishing the core\n      getUpdateHandler().getUpdateLog().bufferUpdates();\n      \n      cd.getCloudDescriptor().setShardState(null);\n      cd.getCloudDescriptor().setShardRange(null);\n      \n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        @Override\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n    \n    if (cc != null) {\n      if (cc.cfg != null && cc.cfg instanceof ConfigSolrXml) {\n        writePropFile(cd, cc);\n      }\n    }\n\n    if (cc != null && cc.isZooKeeperAware() && Slice.CONSTRUCTION.equals(cd.getCloudDescriptor().getShardState())) {\n      // set update log to buffer before publishing the core\n      getUpdateHandler().getUpdateLog().bufferUpdates();\n      \n      cd.getCloudDescriptor().setShardState(null);\n      cd.getCloudDescriptor().setShardRange(null);\n      \n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6e764e9a107f93be9fa3c922bc6a197b3eec387e","date":1373560501,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware() && Slice.CONSTRUCTION.equals(cd.getCloudDescriptor().getShardState())) {\n      // set update log to buffer before publishing the core\n      getUpdateHandler().getUpdateLog().bufferUpdates();\n      \n      cd.getCloudDescriptor().setShardState(null);\n      cd.getCloudDescriptor().setShardRange(null);\n      \n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n    \n    if (cc != null) {\n      if (cc.cfg != null && cc.cfg instanceof ConfigSolrXml) {\n        writePropFile(cd, cc);\n      }\n    }\n\n    if (cc != null && cc.isZooKeeperAware() && Slice.CONSTRUCTION.equals(cd.getCloudDescriptor().getShardState())) {\n      // set update log to buffer before publishing the core\n      getUpdateHandler().getUpdateLog().bufferUpdates();\n      \n      cd.getCloudDescriptor().setShardState(null);\n      cd.getCloudDescriptor().setShardRange(null);\n      \n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware() && Slice.CONSTRUCTION.equals(cd.getCloudDescriptor().getShardState())) {\n      // set update log to buffer before publishing the core\n      getUpdateHandler().getUpdateLog().bufferUpdates();\n      \n      cd.getCloudDescriptor().setShardState(null);\n      cd.getCloudDescriptor().setShardRange(null);\n      \n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        dataDir = cd.getDataDir();\n        try {\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.normalize(SolrResourceLoader\n                .normalizeDir(cd.getInstanceDir()) + dataDir);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        initDirectoryFactory();\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        @Override\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n    \n    if (cc != null) {\n      if (cc.cfg != null && cc.cfg instanceof ConfigSolrXml) {\n        writePropFile(cd, cc);\n      }\n    }\n\n    if (cc != null && cc.isZooKeeperAware() && Slice.CONSTRUCTION.equals(cd.getCloudDescriptor().getShardState())) {\n      // set update log to buffer before publishing the core\n      getUpdateHandler().getUpdateLog().bufferUpdates();\n      \n      cd.getCloudDescriptor().setShardState(null);\n      cd.getCloudDescriptor().setShardRange(null);\n      \n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"65974810aff303cdaecff3dd789ae9353c1d9134","date":1376496589,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware() && Slice.CONSTRUCTION.equals(cd.getCloudDescriptor().getShardState())) {\n      // set update log to buffer before publishing the core\n      getUpdateHandler().getUpdateLog().bufferUpdates();\n      \n      cd.getCloudDescriptor().setShardState(null);\n      cd.getCloudDescriptor().setShardRange(null);\n      \n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware() && Slice.CONSTRUCTION.equals(cd.getCloudDescriptor().getShardState())) {\n      // set update log to buffer before publishing the core\n      getUpdateHandler().getUpdateLog().bufferUpdates();\n      \n      cd.getCloudDescriptor().setShardState(null);\n      cd.getCloudDescriptor().setShardRange(null);\n      \n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3dffec77fb8f7d0e9ca4869dddd6af94528b4576","date":1377875202,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware() && Slice.CONSTRUCTION.equals(cd.getCloudDescriptor().getShardState())) {\n      // set update log to buffer before publishing the core\n      getUpdateHandler().getUpdateLog().bufferUpdates();\n      \n      cd.getCloudDescriptor().setShardState(null);\n      cd.getCloudDescriptor().setShardRange(null);\n      \n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware() && Slice.CONSTRUCTION.equals(cd.getCloudDescriptor().getShardState())) {\n      // set update log to buffer before publishing the core\n      getUpdateHandler().getUpdateLog().bufferUpdates();\n      \n      cd.getCloudDescriptor().setShardState(null);\n      cd.getCloudDescriptor().setShardRange(null);\n      \n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9f81a0a8d08cc36757b7be45a8c8dcd66ff0360","date":1378833548,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware() && Slice.CONSTRUCTION.equals(cd.getCloudDescriptor().getShardState())) {\n      // set update log to buffer before publishing the core\n      getUpdateHandler().getUpdateLog().bufferUpdates();\n      \n      cd.getCloudDescriptor().setShardState(null);\n      cd.getCloudDescriptor().setShardRange(null);\n      \n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware() && Slice.CONSTRUCTION.equals(cd.getCloudDescriptor().getShardState())) {\n      // set update log to buffer before publishing the core\n      getUpdateHandler().getUpdateLog().bufferUpdates();\n      \n      cd.getCloudDescriptor().setShardState(null);\n      cd.getCloudDescriptor().setShardRange(null);\n      \n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bc841231667f1f315bae6799c068f9aad6543967","date":1381415189,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware() && Slice.CONSTRUCTION.equals(cd.getCloudDescriptor().getShardState())) {\n      // set update log to buffer before publishing the core\n      getUpdateHandler().getUpdateLog().bufferUpdates();\n      \n      cd.getCloudDescriptor().setShardState(null);\n      cd.getCloudDescriptor().setShardRange(null);\n      cd.getCloudDescriptor().setShardParent(null);\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware() && Slice.CONSTRUCTION.equals(cd.getCloudDescriptor().getShardState())) {\n      // set update log to buffer before publishing the core\n      getUpdateHandler().getUpdateLog().bufferUpdates();\n      \n      cd.getCloudDescriptor().setShardState(null);\n      cd.getCloudDescriptor().setShardRange(null);\n      \n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"da888af1ab894358122a22229051215f58cf4d54","date":1384408702,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware() && Slice.CONSTRUCTION.equals(cd.getCloudDescriptor().getShardState())) {\n      // set update log to buffer before publishing the core\n      getUpdateHandler().getUpdateLog().bufferUpdates();\n      \n      cd.getCloudDescriptor().setShardState(null);\n      cd.getCloudDescriptor().setShardRange(null);\n      cd.getCloudDescriptor().setShardParent(null);\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware() && Slice.CONSTRUCTION.equals(cd.getCloudDescriptor().getShardState())) {\n      // set update log to buffer before publishing the core\n      getUpdateHandler().getUpdateLog().bufferUpdates();\n      \n      cd.getCloudDescriptor().setShardState(null);\n      cd.getCloudDescriptor().setShardRange(null);\n      cd.getCloudDescriptor().setShardParent(null);\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f6198fb63e3890bd8fe0da672eba02a8ab6190c8","date":1385449337,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      if (Slice.CONSTRUCTION.equals(cd.getCloudDescriptor().getShardState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n\n        cd.getCloudDescriptor().setShardState(null);\n        cd.getCloudDescriptor().setShardRange(null);\n        cd.getCloudDescriptor().setShardParent(null);\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware() && Slice.CONSTRUCTION.equals(cd.getCloudDescriptor().getShardState())) {\n      // set update log to buffer before publishing the core\n      getUpdateHandler().getUpdateLog().bufferUpdates();\n      \n      cd.getCloudDescriptor().setShardState(null);\n      cd.getCloudDescriptor().setShardRange(null);\n      cd.getCloudDescriptor().setShardParent(null);\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"74f45af4339b0daf7a95c820ab88c1aea74fbce0","date":1387475327,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      if (Slice.CONSTRUCTION.equals(cd.getCloudDescriptor().getShardState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n\n        cd.getCloudDescriptor().setShardState(null);\n        cd.getCloudDescriptor().setShardRange(null);\n        cd.getCloudDescriptor().setShardParent(null);\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware() && Slice.CONSTRUCTION.equals(cd.getCloudDescriptor().getShardState())) {\n      // set update log to buffer before publishing the core\n      getUpdateHandler().getUpdateLog().bufferUpdates();\n      \n      cd.getCloudDescriptor().setShardState(null);\n      cd.getCloudDescriptor().setShardRange(null);\n      cd.getCloudDescriptor().setShardParent(null);\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f56da6f4f15d95f318d2d6ac2a39a9183dfecff2","date":1389633998,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n      close();\n      \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      if (Slice.CONSTRUCTION.equals(cd.getCloudDescriptor().getShardState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n\n        cd.getCloudDescriptor().setShardState(null);\n        cd.getCloudDescriptor().setShardRange(null);\n        cd.getCloudDescriptor().setShardParent(null);\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      if (Slice.CONSTRUCTION.equals(cd.getCloudDescriptor().getShardState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n\n        cd.getCloudDescriptor().setShardState(null);\n        cd.getCloudDescriptor().setShardRange(null);\n        cd.getCloudDescriptor().setShardParent(null);\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"87d54fb06e5d5ca00e6b0db75b52de2013d09ce4","date":1392661838,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n      close();\n      \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n      close();\n      \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      if (Slice.CONSTRUCTION.equals(cd.getCloudDescriptor().getShardState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n\n        cd.getCloudDescriptor().setShardState(null);\n        cd.getCloudDescriptor().setShardRange(null);\n        cd.getCloudDescriptor().setShardParent(null);\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n      close();\n      \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n      close();\n      \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"afb6bf9ce227ab6aac5068547e286ecc958b8b9d","date":1394661169,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Initialize the RestManager\n      restManager = initRestManager();\n            \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n      close();\n      \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n      close();\n      \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ab20a04a303d3d2a5078076f4633e0482d643cc0","date":1398201811,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Initialize the RestManager\n      restManager = initRestManager();\n            \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n      \n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n      \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Initialize the RestManager\n      restManager = initRestManager();\n            \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n      close();\n      \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","bugFix":["19e21d98da803ac6174cb50a880e6289139756ca"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","date":1398844771,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Initialize the RestManager\n      restManager = initRestManager();\n            \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n      \n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n      \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Initialize the RestManager\n      restManager = initRestManager();\n            \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n      close();\n      \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4a9c941a7004ea2e95b10aa67dafa319ff8d8c19","date":1400739326,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Initialize the RestManager\n      restManager = initRestManager();\n            \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n      \n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n      \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Initialize the RestManager\n      restManager = initRestManager();\n            \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n      \n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n      \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b7605579001505896d48b07160075a5c8b8e128e","date":1400758727,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Initialize the RestManager\n      restManager = initRestManager();\n            \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n      \n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n      \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Initialize the RestManager\n      restManager = initRestManager();\n            \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n      \n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n      \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2336740b200d02b6a5fb18b70454dd9aa26f5b47","date":1407004842,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      List<PluginInfo> implicitReqHandlerInfo = new ArrayList<>();\n      UpdateRequestHandler.addImplicits(implicitReqHandlerInfo);\n      reqHandlers.initHandlersFromConfig(solrConfig, implicitReqHandlerInfo);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Initialize the RestManager\n      restManager = initRestManager();\n            \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n      \n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n      \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Initialize the RestManager\n      restManager = initRestManager();\n            \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n      \n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n      \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","bugFix":["d9405f486872f1e416304dfe389741f4ee2f8a4d"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"eb55f6c347c48c2f7a9fb29b2e6dfe819b1a56f9","date":1414167719,"type":3,"author":"Timothy Potter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      List<PluginInfo> implicitReqHandlerInfo = new ArrayList<>();\n      UpdateRequestHandler.addImplicits(implicitReqHandlerInfo);\n      reqHandlers.initHandlersFromConfig(solrConfig, implicitReqHandlerInfo);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Initialize the RestManager\n      restManager = initRestManager();\n            \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n      \n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n      \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      List<PluginInfo> implicitReqHandlerInfo = new ArrayList<>();\n      UpdateRequestHandler.addImplicits(implicitReqHandlerInfo);\n      reqHandlers.initHandlersFromConfig(solrConfig, implicitReqHandlerInfo);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Initialize the RestManager\n      restManager = initRestManager();\n            \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n      \n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n      \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"531fe719c7218235a679452eb3d137bfd8fc6af1","date":1415191086,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      List<PluginInfo> implicitReqHandlerInfo = new ArrayList<>();\n      UpdateRequestHandler.addImplicits(implicitReqHandlerInfo);\n      SolrConfigHandler.addImplicits(implicitReqHandlerInfo);\n\n      reqHandlers.initHandlersFromConfig(solrConfig, implicitReqHandlerInfo);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Initialize the RestManager\n      restManager = initRestManager();\n            \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n      \n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n      \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      List<PluginInfo> implicitReqHandlerInfo = new ArrayList<>();\n      UpdateRequestHandler.addImplicits(implicitReqHandlerInfo);\n      reqHandlers.initHandlersFromConfig(solrConfig, implicitReqHandlerInfo);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Initialize the RestManager\n      restManager = initRestManager();\n            \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n      \n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n      \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e56881a4ebc3438313e3c008a7124ba0f8ecc7bf","date":1416997673,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Initialize the RestManager\n      restManager = initRestManager();\n            \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n      \n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n      \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      List<PluginInfo> implicitReqHandlerInfo = new ArrayList<>();\n      UpdateRequestHandler.addImplicits(implicitReqHandlerInfo);\n      SolrConfigHandler.addImplicits(implicitReqHandlerInfo);\n\n      reqHandlers.initHandlersFromConfig(solrConfig, implicitReqHandlerInfo);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Initialize the RestManager\n      restManager = initRestManager();\n            \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n      \n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n      \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a94e45463a0089149b0d148ae5369140e7f54b8c","date":1419231934,"type":3,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      statsCache = initStatsCache();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Initialize the RestManager\n      restManager = initRestManager();\n            \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n      \n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n      \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Initialize the RestManager\n      restManager = initRestManager();\n            \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n      \n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n      \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","bugFix":null,"bugIntro":["df72a23fb74bebe914e3f3972063a884327c0436"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b5a70f7ff0756e3668447bffbbf8bce8e7c361b9","date":1420028708,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      statsCache = initStatsCache();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Initialize the RestManager\n      restManager = initRestManager();\n            \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n      \n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n      \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      statsCache = initStatsCache();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Initialize the RestManager\n      restManager = initRestManager();\n            \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n      \n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n      \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ac2f1cdbdc54a889e88543cc1d939a931cb96883","date":1420554488,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      statsCache = initStatsCache();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              return indexReaderFactory.newReader(iw, core);\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Initialize the RestManager\n      restManager = initRestManager();\n            \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n      \n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n      \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      statsCache = initStatsCache();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              if(getSolrConfig().nrtMode) {\n                // if in NRT mode, need to open from the previous writer\n                return indexReaderFactory.newReader(iw, core);\n              } else {\n                // if not NRT, need to create a new reader from the directory\n                return indexReaderFactory.newReader(iw.getDirectory(), core);\n              }\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Initialize the RestManager\n      restManager = initRestManager();\n            \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n      \n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n      \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9aea0485ecacb6734c17da2d02569816c23a69c1","date":1425707735,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n\n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory();\n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n\n      initListeners();\n\n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n\n      this.codec = initCodec(solrConfig, schema);\n\n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      memClassLoader = new MemClassLoader(PluginRegistry.RuntimeLib.getLibObjects(this, solrConfig.getPluginInfos(PluginRegistry.RuntimeLib.class.getName())), getResourceLoader());\n      initIndex(prev != null);\n\n      initWriters();\n      qParserPlugins.init(createInstances(QParserPlugin.standardPlugins), this);\n      valueSourceParsers.init(ValueSourceParser.standardValueSourceParsers, this);\n      transformerFactories.init(TransformerFactory.defaultFactories, this);\n      loadSearchComponents();\n\n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n\n      statsCache = initStatsCache();\n\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              return indexReaderFactory.newReader(iw, core);\n            }\n          };\n        }\n      }\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n\n      // Initialize the RestManager\n      restManager = initRestManager();\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n\n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n\n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n\n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      statsCache = initStatsCache();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              return indexReaderFactory.newReader(iw, core);\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Initialize the RestManager\n      restManager = initRestManager();\n            \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n      \n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n      \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n  }\n\n","bugFix":null,"bugIntro":["2679aff35efbec5a5b825d59f006636fda4224d4","bb222a3f9d9421d5c95afce73013fbd8de07ea1f","df72a23fb74bebe914e3f3972063a884327c0436"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"69cad0546debf9ce9d44e309ecfa26760fecd5d8","date":1425846082,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n\n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory();\n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n\n      initListeners();\n\n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n\n      this.codec = initCodec(solrConfig, schema);\n\n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      memClassLoader = new MemClassLoader(PluginBag.RuntimeLib.getLibObjects(this, solrConfig.getPluginInfos(PluginBag.RuntimeLib.class.getName())), getResourceLoader());\n      initIndex(prev != null);\n\n      initWriters();\n      qParserPlugins.init(createInstances(QParserPlugin.standardPlugins), this);\n      valueSourceParsers.init(ValueSourceParser.standardValueSourceParsers, this);\n      transformerFactories.init(TransformerFactory.defaultFactories, this);\n      loadSearchComponents();\n\n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n\n      statsCache = initStatsCache();\n\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              return indexReaderFactory.newReader(iw, core);\n            }\n          };\n        }\n      }\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n\n      // Initialize the RestManager\n      restManager = initRestManager();\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n\n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n\n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n\n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n\n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory();\n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n\n      initListeners();\n\n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n\n      this.codec = initCodec(solrConfig, schema);\n\n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      memClassLoader = new MemClassLoader(PluginRegistry.RuntimeLib.getLibObjects(this, solrConfig.getPluginInfos(PluginRegistry.RuntimeLib.class.getName())), getResourceLoader());\n      initIndex(prev != null);\n\n      initWriters();\n      qParserPlugins.init(createInstances(QParserPlugin.standardPlugins), this);\n      valueSourceParsers.init(ValueSourceParser.standardValueSourceParsers, this);\n      transformerFactories.init(TransformerFactory.defaultFactories, this);\n      loadSearchComponents();\n\n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n\n      statsCache = initStatsCache();\n\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              return indexReaderFactory.newReader(iw, core);\n            }\n          };\n        }\n      }\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n\n      // Initialize the RestManager\n      restManager = initRestManager();\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n\n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n\n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n\n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3ee01ed2bbdbfebcda94054cb39b4fac5f06a3bd","date":1426252395,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n\n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory();\n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n\n      initListeners();\n\n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n\n      this.codec = initCodec(solrConfig, schema);\n\n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      memClassLoader = new MemClassLoader(PluginBag.RuntimeLib.getLibObjects(this, solrConfig.getPluginInfos(PluginBag.RuntimeLib.class.getName())), getResourceLoader());\n      initIndex(prev != null);\n\n      initWriters();\n      qParserPlugins.init(createInstances(QParserPlugin.standardPlugins), this);\n      valueSourceParsers.init(ValueSourceParser.standardValueSourceParsers, this);\n      transformerFactories.init(TransformerFactory.defaultFactories, this);\n      loadSearchComponents();\n      updateProcessors.init(Collections.EMPTY_MAP, this);\n\n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n\n      statsCache = initStatsCache();\n\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              return indexReaderFactory.newReader(iw, core);\n            }\n          };\n        }\n      }\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n\n      // Initialize the RestManager\n      restManager = initRestManager();\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n\n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n\n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n\n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n\n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory();\n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n\n      initListeners();\n\n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n\n      this.codec = initCodec(solrConfig, schema);\n\n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      memClassLoader = new MemClassLoader(PluginBag.RuntimeLib.getLibObjects(this, solrConfig.getPluginInfos(PluginBag.RuntimeLib.class.getName())), getResourceLoader());\n      initIndex(prev != null);\n\n      initWriters();\n      qParserPlugins.init(createInstances(QParserPlugin.standardPlugins), this);\n      valueSourceParsers.init(ValueSourceParser.standardValueSourceParsers, this);\n      transformerFactories.init(TransformerFactory.defaultFactories, this);\n      loadSearchComponents();\n\n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n\n      statsCache = initStatsCache();\n\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              return indexReaderFactory.newReader(iw, core);\n            }\n          };\n        }\n      }\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n\n      // Initialize the RestManager\n      restManager = initRestManager();\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n\n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n\n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n\n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n\n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory();\n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n\n      initListeners();\n\n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n\n      this.codec = initCodec(solrConfig, schema);\n\n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      memClassLoader = new MemClassLoader(PluginBag.RuntimeLib.getLibObjects(this, solrConfig.getPluginInfos(PluginBag.RuntimeLib.class.getName())), getResourceLoader());\n      initIndex(prev != null);\n\n      initWriters();\n      qParserPlugins.init(createInstances(QParserPlugin.standardPlugins), this);\n      valueSourceParsers.init(ValueSourceParser.standardValueSourceParsers, this);\n      transformerFactories.init(TransformerFactory.defaultFactories, this);\n      loadSearchComponents();\n      updateProcessors.init(Collections.EMPTY_MAP, this);\n\n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n\n      statsCache = initStatsCache();\n\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              return indexReaderFactory.newReader(iw, core);\n            }\n          };\n        }\n      }\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n\n      // Initialize the RestManager\n      restManager = initRestManager();\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n\n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n\n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n\n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory(); \n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      statsCache = initStatsCache();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              return indexReaderFactory.newReader(iw, core);\n            }\n          };\n        }\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      // Initialize the RestManager\n      restManager = initRestManager();\n            \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n      \n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n      \n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"65780dd0a70597aa46f16a2a42093215ca237272","date":1427847875,"type":3,"author":"Ryan McKinley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    MDCUtils.setCore(name); // show the core name in the error logs\n    \n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n\n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory();\n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n\n      initListeners();\n\n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n\n      this.codec = initCodec(solrConfig, schema);\n\n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      memClassLoader = new MemClassLoader(PluginBag.RuntimeLib.getLibObjects(this, solrConfig.getPluginInfos(PluginBag.RuntimeLib.class.getName())), getResourceLoader());\n      initIndex(prev != null);\n\n      initWriters();\n      qParserPlugins.init(createInstances(QParserPlugin.standardPlugins), this);\n      valueSourceParsers.init(ValueSourceParser.standardValueSourceParsers, this);\n      transformerFactories.init(TransformerFactory.defaultFactories, this);\n      loadSearchComponents();\n      updateProcessors.init(Collections.EMPTY_MAP, this);\n\n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n\n      statsCache = initStatsCache();\n\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              return indexReaderFactory.newReader(iw, core);\n            }\n          };\n        }\n      }\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n\n      // Initialize the RestManager\n      restManager = initRestManager();\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n\n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n\n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n\n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n\n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory();\n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n\n      initListeners();\n\n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n\n      this.codec = initCodec(solrConfig, schema);\n\n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      memClassLoader = new MemClassLoader(PluginBag.RuntimeLib.getLibObjects(this, solrConfig.getPluginInfos(PluginBag.RuntimeLib.class.getName())), getResourceLoader());\n      initIndex(prev != null);\n\n      initWriters();\n      qParserPlugins.init(createInstances(QParserPlugin.standardPlugins), this);\n      valueSourceParsers.init(ValueSourceParser.standardValueSourceParsers, this);\n      transformerFactories.init(TransformerFactory.defaultFactories, this);\n      loadSearchComponents();\n      updateProcessors.init(Collections.EMPTY_MAP, this);\n\n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n\n      statsCache = initStatsCache();\n\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              return indexReaderFactory.newReader(iw, core);\n            }\n          };\n        }\n      }\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n\n      // Initialize the RestManager\n      restManager = initRestManager();\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n\n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n\n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n\n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fab172655716b96f7e42376116235017a922de3a","date":1427850611,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    MDCUtils.setCore(name); // show the core name in the error logs\n    \n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n\n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory();\n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n\n      initListeners();\n\n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n\n      this.codec = initCodec(solrConfig, schema);\n\n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      memClassLoader = new MemClassLoader(PluginBag.RuntimeLib.getLibObjects(this, solrConfig.getPluginInfos(PluginBag.RuntimeLib.class.getName())), getResourceLoader());\n      initIndex(prev != null);\n\n      initWriters();\n      qParserPlugins.init(createInstances(QParserPlugin.standardPlugins), this);\n      valueSourceParsers.init(ValueSourceParser.standardValueSourceParsers, this);\n      transformerFactories.init(TransformerFactory.defaultFactories, this);\n      loadSearchComponents();\n      updateProcessors.init(Collections.EMPTY_MAP, this);\n\n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n\n      statsCache = initStatsCache();\n\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              return indexReaderFactory.newReader(iw, core);\n            }\n          };\n        }\n      }\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n\n      // Initialize the RestManager\n      restManager = initRestManager();\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n\n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n\n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n\n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n\n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory();\n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n\n      initListeners();\n\n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n\n      this.codec = initCodec(solrConfig, schema);\n\n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      memClassLoader = new MemClassLoader(PluginBag.RuntimeLib.getLibObjects(this, solrConfig.getPluginInfos(PluginBag.RuntimeLib.class.getName())), getResourceLoader());\n      initIndex(prev != null);\n\n      initWriters();\n      qParserPlugins.init(createInstances(QParserPlugin.standardPlugins), this);\n      valueSourceParsers.init(ValueSourceParser.standardValueSourceParsers, this);\n      transformerFactories.init(TransformerFactory.defaultFactories, this);\n      loadSearchComponents();\n      updateProcessors.init(Collections.EMPTY_MAP, this);\n\n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n\n      statsCache = initStatsCache();\n\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              return indexReaderFactory.newReader(iw, core);\n            }\n          };\n        }\n      }\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n\n      // Initialize the RestManager\n      restManager = initRestManager();\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n\n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n\n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n\n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0dcc63c22f7cfe3d3a83aee576d0fc5b403a296","date":1427866967,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    MDCUtils.setCore(name); // show the core name in the error logs\n    \n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n\n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory();\n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n\n      initListeners();\n\n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n\n      this.codec = initCodec(solrConfig, schema);\n\n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      memClassLoader = new MemClassLoader(PluginBag.RuntimeLib.getLibObjects(this, solrConfig.getPluginInfos(PluginBag.RuntimeLib.class.getName())), getResourceLoader());\n      initIndex(prev != null);\n\n      initWriters();\n      qParserPlugins.init(createInstances(QParserPlugin.standardPlugins), this);\n      valueSourceParsers.init(ValueSourceParser.standardValueSourceParsers, this);\n      transformerFactories.init(TransformerFactory.defaultFactories, this);\n      loadSearchComponents();\n      updateProcessors.init(Collections.EMPTY_MAP, this);\n\n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n\n      statsCache = initStatsCache();\n\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              return indexReaderFactory.newReader(iw, core);\n            }\n          };\n        }\n      }\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n\n      // Initialize the RestManager\n      restManager = initRestManager();\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n\n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n\n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n\n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(), \n          cd.getCloudDescriptor().getShardId());\n      if (slice.getState() == Slice.State.CONSTRUCTION) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    MDCUtils.setCore(name); // show the core name in the error logs\n    \n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n\n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory();\n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n\n      initListeners();\n\n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n\n      this.codec = initCodec(solrConfig, schema);\n\n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      memClassLoader = new MemClassLoader(PluginBag.RuntimeLib.getLibObjects(this, solrConfig.getPluginInfos(PluginBag.RuntimeLib.class.getName())), getResourceLoader());\n      initIndex(prev != null);\n\n      initWriters();\n      qParserPlugins.init(createInstances(QParserPlugin.standardPlugins), this);\n      valueSourceParsers.init(ValueSourceParser.standardValueSourceParsers, this);\n      transformerFactories.init(TransformerFactory.defaultFactories, this);\n      loadSearchComponents();\n      updateProcessors.init(Collections.EMPTY_MAP, this);\n\n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n\n      statsCache = initStatsCache();\n\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              return indexReaderFactory.newReader(iw, core);\n            }\n          };\n        }\n      }\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n\n      // Initialize the RestManager\n      restManager = initRestManager();\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n\n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n\n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n\n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0c924d4069ef5a5bc479a493befe0121aada6896","date":1427901860,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    MDCUtils.setCore(name); // show the core name in the error logs\n    \n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n\n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory();\n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n\n      initListeners();\n\n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n\n      this.codec = initCodec(solrConfig, schema);\n\n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      memClassLoader = new MemClassLoader(PluginBag.RuntimeLib.getLibObjects(this, solrConfig.getPluginInfos(PluginBag.RuntimeLib.class.getName())), getResourceLoader());\n      initIndex(prev != null);\n\n      initWriters();\n      qParserPlugins.init(createInstances(QParserPlugin.standardPlugins), this);\n      valueSourceParsers.init(ValueSourceParser.standardValueSourceParsers, this);\n      transformerFactories.init(TransformerFactory.defaultFactories, this);\n      loadSearchComponents();\n      updateProcessors.init(Collections.EMPTY_MAP, this);\n\n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n\n      statsCache = initStatsCache();\n\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              return indexReaderFactory.newReader(iw, core);\n            }\n          };\n        }\n      }\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n\n      // Initialize the RestManager\n      restManager = initRestManager();\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n\n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n\n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n\n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(), \n          cd.getCloudDescriptor().getShardId());\n      if (slice.getState() == Slice.State.CONSTRUCTION) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    MDCUtils.setCore(name); // show the core name in the error logs\n    \n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n\n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory();\n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n\n      initListeners();\n\n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n\n      this.codec = initCodec(solrConfig, schema);\n\n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      memClassLoader = new MemClassLoader(PluginBag.RuntimeLib.getLibObjects(this, solrConfig.getPluginInfos(PluginBag.RuntimeLib.class.getName())), getResourceLoader());\n      initIndex(prev != null);\n\n      initWriters();\n      qParserPlugins.init(createInstances(QParserPlugin.standardPlugins), this);\n      valueSourceParsers.init(ValueSourceParser.standardValueSourceParsers, this);\n      transformerFactories.init(TransformerFactory.defaultFactories, this);\n      loadSearchComponents();\n      updateProcessors.init(Collections.EMPTY_MAP, this);\n\n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n\n      statsCache = initStatsCache();\n\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              return indexReaderFactory.newReader(iw, core);\n            }\n          };\n        }\n      }\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n\n      // Initialize the RestManager\n      restManager = initRestManager();\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n\n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n\n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n\n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),\n          cd.getCloudDescriptor().getShardId());\n      if (Slice.CONSTRUCTION.equals(slice.getState())) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54bb8da55080e4569804e0661b83a3c72cbd8d4d","date":1429691126,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores. If a core with the\n   * same name already exists, it will be stopped and replaced by this one.\n   *\n   * @param dataDir\n   *          the index directory\n   * @param config\n   *          a solr config instance\n   * @param schema\n   *          a solr schema instance\n   *\n   * @since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config,\n      IndexSchema schema, CoreDescriptor coreDescriptor, UpdateHandler updateHandler,\n      IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    checkNotNull(coreDescriptor, \"coreDescriptor cannot be null\");\n    \n    this.coreDescriptor = coreDescriptor;\n    setName(name);\n    MDCUtils.setCore(name); // show the core name in the error logs\n    \n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n\n    if (updateHandler == null) {\n      directoryFactory = initDirectoryFactory();\n      solrCoreState = new DefaultSolrCoreState(directoryFactory);\n    } else {\n      solrCoreState = updateHandler.getSolrCoreState();\n      directoryFactory = solrCoreState.getDirectoryFactory();\n      isReloaded = true;\n    }\n\n    this.dataDir = initDataDir(dataDir, config, coreDescriptor);\n    this.ulogDir = initUpdateLogDir(coreDescriptor);\n\n    log.info(\"[{}] Opening new SolrCore at [{}], dataDir=[{}]\", logid, resourceLoader.getInstanceDir(), dataDir);\n\n    checkVersionFieldExistsInSchema(schema, coreDescriptor);\n\n    // Initialize JMX\n    this.infoRegistry = initInfoRegistry(name, config);\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = initSchema(config, schema);\n\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n\n      initListeners();\n\n      this.solrDelPolicy = initDeletionPolicy(delPolicy);\n\n      this.codec = initCodec(solrConfig, this.schema);\n\n      memClassLoader = new MemClassLoader(PluginBag.RuntimeLib.getLibObjects(this, solrConfig.getPluginInfos(PluginBag.RuntimeLib.class.getName())), getResourceLoader());\n      initIndex(prev != null);\n\n      initWriters();\n      qParserPlugins.init(createInstances(QParserPlugin.standardPlugins), this);\n      valueSourceParsers.init(ValueSourceParser.standardValueSourceParsers, this);\n      transformerFactories.init(TransformerFactory.defaultFactories, this);\n      loadSearchComponents();\n      updateProcessors.init(Collections.emptyMap(), this);\n\n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n\n      statsCache = initStatsCache();\n\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      this.updateHandler = initUpdateHandler(updateHandler);\n      \n      initSearcher(prev);\n\n      // Initialize the RestManager\n      restManager = initRestManager();\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      // release the latch, otherwise we block trying to do the close. This\n      // should be fine, since counting down on a latch of 0 is still fine\n      latch.countDown();\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n\n      try {\n        // close down the searcher and any other resources, if it exists, as this\n        // is not recoverable\n       close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError) t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n\n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n\n    bufferUpdatesIfConstructing(coreDescriptor);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    this.ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    MDCUtils.setCore(name); // show the core name in the error logs\n    \n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n\n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n\n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        try {\n          dataDir = cd.getDataDir();\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.getDataHome(cd);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    String updateLogDir = cd.getUlogDir();\n    if (updateLogDir == null) {\n      updateLogDir = dataDir;\n      if (new File(updateLogDir).isAbsolute() == false) {\n        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;\n      }\n    }\n    ulogDir = updateLogDir;\n\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistributedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    if (schema==null) {\n      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);\n    }\n    this.schema = schema;\n    final SimilarityFactory similarityFactory = schema.getSimilarityFactory();\n    if (similarityFactory instanceof SolrCoreAware) {\n      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below\n      ((SolrCoreAware)similarityFactory).inform(this);\n    }\n\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n\n      initListeners();\n\n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n\n      this.codec = initCodec(solrConfig, schema);\n\n      if (updateHandler == null) {\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      memClassLoader = new MemClassLoader(PluginBag.RuntimeLib.getLibObjects(this, solrConfig.getPluginInfos(PluginBag.RuntimeLib.class.getName())), getResourceLoader());\n      initIndex(prev != null);\n\n      initWriters();\n      qParserPlugins.init(createInstances(QParserPlugin.standardPlugins), this);\n      valueSourceParsers.init(ValueSourceParser.standardValueSourceParsers, this);\n      transformerFactories.init(TransformerFactory.defaultFactories, this);\n      loadSearchComponents();\n      updateProcessors.init(Collections.EMPTY_MAP, this);\n\n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n\n      statsCache = initStatsCache();\n\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          final SolrCore core = this;\n          newReaderCreator = new Callable<DirectoryReader>() {\n            // this is used during a core reload\n\n            @Override\n            public DirectoryReader call() throws Exception {\n              return indexReaderFactory.newReader(iw, core);\n            }\n          };\n        }\n      }\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n\n      // Initialize the RestManager\n      restManager = initRestManager();\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n\n      try {\n       this.close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError)t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n\n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n\n    CoreContainer cc = cd.getCoreContainer();\n\n    if (cc != null && cc.isZooKeeperAware()) {\n      SolrRequestHandler realtimeGetHandler = reqHandlers.get(\"/get\");\n      if (realtimeGetHandler == null) {\n        log.warn(\"WARNING: RealTimeGetHandler is not registered at /get. \" +\n            \"SolrCloud will always use full index replication instead of the more efficient PeerSync method.\");\n      }\n\n      // ZK pre-Register would have already happened so we read slice properties now\n      ClusterState clusterState = cc.getZkController().getClusterState();\n      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(), \n          cd.getCloudDescriptor().getShardId());\n      if (slice.getState() == Slice.State.CONSTRUCTION) {\n        // set update log to buffer before publishing the core\n        getUpdateHandler().getUpdateLog().bufferUpdates();\n      }\n    }\n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n  }\n\n","bugFix":null,"bugIntro":["20eb14adcb76cac6b8ae297eb37caec72e3a2140","96e0d4494fe54b31c7f0151f3a632124ab806351","bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7da173d341edb3a56705e0ee852574c69d83aa6f","date":1430086379,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores. If a core with the\n   * same name already exists, it will be stopped and replaced by this one.\n   *\n   * @param dataDir\n   *          the index directory\n   * @param config\n   *          a solr config instance\n   * @param schema\n   *          a solr schema instance\n   *\n   * @since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config,\n      IndexSchema schema, CoreDescriptor coreDescriptor, UpdateHandler updateHandler,\n      IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    checkNotNull(coreDescriptor, \"coreDescriptor cannot be null\");\n    \n    this.coreDescriptor = coreDescriptor;\n    setName(name);\n    MDCUtils.setCore(name); // show the core name in the error logs\n    \n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n\n    if (updateHandler == null) {\n      directoryFactory = initDirectoryFactory();\n      solrCoreState = new DefaultSolrCoreState(directoryFactory);\n    } else {\n      solrCoreState = updateHandler.getSolrCoreState();\n      directoryFactory = solrCoreState.getDirectoryFactory();\n      isReloaded = true;\n    }\n\n    this.dataDir = initDataDir(dataDir, config, coreDescriptor);\n    this.ulogDir = initUpdateLogDir(coreDescriptor);\n\n    log.info(\"[{}] Opening new SolrCore at [{}], dataDir=[{}]\", logid, resourceLoader.getInstanceDir(), dataDir);\n\n    checkVersionFieldExistsInSchema(schema, coreDescriptor);\n\n    // Initialize JMX\n    this.infoRegistry = initInfoRegistry(name, config);\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = initSchema(config, schema);\n\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n\n      initListeners();\n\n      this.solrDelPolicy = initDeletionPolicy(delPolicy);\n\n      this.codec = initCodec(solrConfig, this.schema);\n\n      memClassLoader = new MemClassLoader(PluginBag.RuntimeLib.getLibObjects(this, solrConfig.getPluginInfos(PluginBag.RuntimeLib.class.getName())), getResourceLoader());\n      initIndex(prev != null);\n\n      initWriters();\n      qParserPlugins.init(createInstances(QParserPlugin.standardPlugins), this);\n      valueSourceParsers.init(ValueSourceParser.standardValueSourceParsers, this);\n      transformerFactories.init(TransformerFactory.defaultFactories, this);\n      loadSearchComponents();\n      updateProcessors.init(Collections.emptyMap(), this);\n\n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n\n      statsCache = initStatsCache();\n\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      this.updateHandler = initUpdateHandler(updateHandler);\n      \n      initSearcher(prev);\n\n      // Initialize the RestManager\n      restManager = initRestManager();\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      // release the latch, otherwise we block trying to do the close. This\n      // should be fine, since counting down on a latch of 0 is still fine\n      latch.countDown();\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n\n      try {\n        // close down the searcher and any other resources, if it exists, as this\n        // is not recoverable\n       close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError) t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n\n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n\n    // Allow the directory factory to register MBeans as well\n    for (SolrInfoMBean bean : directoryFactory.offerMBeans()) {\n      log.debug(\"Registering JMX bean [{}] from directory factory.\", bean.getName());\n      // Not worried about concurrency, so no reason to use putIfAbsent\n      if (infoRegistry.containsKey(bean.getName())){\n        log.info(\"Ignoring JMX bean [{}] due to name conflict.\", bean.getName());\n      } else {\n        infoRegistry.put(bean.getName(), bean);\n      }\n    }\n\n    bufferUpdatesIfConstructing(coreDescriptor);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    this.ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores. If a core with the\n   * same name already exists, it will be stopped and replaced by this one.\n   *\n   * @param dataDir\n   *          the index directory\n   * @param config\n   *          a solr config instance\n   * @param schema\n   *          a solr schema instance\n   *\n   * @since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config,\n      IndexSchema schema, CoreDescriptor coreDescriptor, UpdateHandler updateHandler,\n      IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    checkNotNull(coreDescriptor, \"coreDescriptor cannot be null\");\n    \n    this.coreDescriptor = coreDescriptor;\n    setName(name);\n    MDCUtils.setCore(name); // show the core name in the error logs\n    \n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n\n    if (updateHandler == null) {\n      directoryFactory = initDirectoryFactory();\n      solrCoreState = new DefaultSolrCoreState(directoryFactory);\n    } else {\n      solrCoreState = updateHandler.getSolrCoreState();\n      directoryFactory = solrCoreState.getDirectoryFactory();\n      isReloaded = true;\n    }\n\n    this.dataDir = initDataDir(dataDir, config, coreDescriptor);\n    this.ulogDir = initUpdateLogDir(coreDescriptor);\n\n    log.info(\"[{}] Opening new SolrCore at [{}], dataDir=[{}]\", logid, resourceLoader.getInstanceDir(), dataDir);\n\n    checkVersionFieldExistsInSchema(schema, coreDescriptor);\n\n    // Initialize JMX\n    this.infoRegistry = initInfoRegistry(name, config);\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = initSchema(config, schema);\n\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n\n      initListeners();\n\n      this.solrDelPolicy = initDeletionPolicy(delPolicy);\n\n      this.codec = initCodec(solrConfig, this.schema);\n\n      memClassLoader = new MemClassLoader(PluginBag.RuntimeLib.getLibObjects(this, solrConfig.getPluginInfos(PluginBag.RuntimeLib.class.getName())), getResourceLoader());\n      initIndex(prev != null);\n\n      initWriters();\n      qParserPlugins.init(createInstances(QParserPlugin.standardPlugins), this);\n      valueSourceParsers.init(ValueSourceParser.standardValueSourceParsers, this);\n      transformerFactories.init(TransformerFactory.defaultFactories, this);\n      loadSearchComponents();\n      updateProcessors.init(Collections.emptyMap(), this);\n\n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n\n      statsCache = initStatsCache();\n\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      this.updateHandler = initUpdateHandler(updateHandler);\n      \n      initSearcher(prev);\n\n      // Initialize the RestManager\n      restManager = initRestManager();\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      // release the latch, otherwise we block trying to do the close. This\n      // should be fine, since counting down on a latch of 0 is still fine\n      latch.countDown();\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n\n      try {\n        // close down the searcher and any other resources, if it exists, as this\n        // is not recoverable\n       close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError) t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n\n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n\n    bufferUpdatesIfConstructing(coreDescriptor);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    this.ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9220b7d1848f68bc299608612f8e0139c4036fcf","date":1432485783,"type":3,"author":"Timothy Potter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores. If a core with the\n   * same name already exists, it will be stopped and replaced by this one.\n   *\n   * @param dataDir\n   *          the index directory\n   * @param config\n   *          a solr config instance\n   * @param schema\n   *          a solr schema instance\n   *\n   * @since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config,\n      IndexSchema schema, CoreDescriptor coreDescriptor, UpdateHandler updateHandler,\n      IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    checkNotNull(coreDescriptor, \"coreDescriptor cannot be null\");\n    \n    this.coreDescriptor = coreDescriptor;\n    setName(name);\n    MDCUtils.setCore(name); // show the core name in the error logs\n    \n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n\n    if (updateHandler == null) {\n      directoryFactory = initDirectoryFactory();\n      solrCoreState = new DefaultSolrCoreState(directoryFactory);\n    } else {\n      solrCoreState = updateHandler.getSolrCoreState();\n      directoryFactory = solrCoreState.getDirectoryFactory();\n      isReloaded = true;\n    }\n\n    this.dataDir = initDataDir(dataDir, config, coreDescriptor);\n    this.ulogDir = initUpdateLogDir(coreDescriptor);\n\n    log.info(\"[{}] Opening new SolrCore at [{}], dataDir=[{}]\", logid, resourceLoader.getInstanceDir(), dataDir);\n\n    checkVersionFieldExistsInSchema(schema, coreDescriptor);\n\n    // Initialize JMX\n    this.infoRegistry = initInfoRegistry(name, config);\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = initSchema(config, schema);\n\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n\n      initListeners();\n\n      this.solrDelPolicy = initDeletionPolicy(delPolicy);\n\n      this.codec = initCodec(solrConfig, this.schema);\n\n      memClassLoader = new MemClassLoader(PluginBag.RuntimeLib.getLibObjects(this, solrConfig.getPluginInfos(PluginBag.RuntimeLib.class.getName())), getResourceLoader());\n      initIndex(prev != null);\n\n      initWriters();\n      qParserPlugins.init(createInstances(QParserPlugin.standardPlugins), this);\n      valueSourceParsers.init(ValueSourceParser.standardValueSourceParsers, this);\n      transformerFactories.init(TransformerFactory.defaultFactories, this);\n      loadSearchComponents();\n      updateProcessors.init(Collections.emptyMap(), this);\n\n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n\n      statsCache = initStatsCache();\n\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      this.updateHandler = initUpdateHandler(updateHandler);\n      \n      initSearcher(prev);\n\n      // Initialize the RestManager\n      restManager = initRestManager();\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      // release the latch, otherwise we block trying to do the close. This\n      // should be fine, since counting down on a latch of 0 is still fine\n      latch.countDown();\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n\n      try {\n        // close down the searcher and any other resources, if it exists, as this\n        // is not recoverable\n       close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError) t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n\n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n\n    // Allow the directory factory to register MBeans as well\n    for (SolrInfoMBean bean : directoryFactory.offerMBeans()) {\n      log.debug(\"Registering JMX bean [{}] from directory factory.\", bean.getName());\n      // Not worried about concurrency, so no reason to use putIfAbsent\n      if (infoRegistry.containsKey(bean.getName())){\n        log.info(\"Ignoring JMX bean [{}] due to name conflict.\", bean.getName());\n      } else {\n        infoRegistry.put(bean.getName(), bean);\n      }\n    }\n\n    bufferUpdatesIfConstructing(coreDescriptor);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    this.ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n\n    // seed version buckets with max from index during core initialization\n    if (this.updateHandler != null && this.updateHandler.getUpdateLog() != null) {\n      RefCounted<SolrIndexSearcher> newestSearcher = getRealtimeSearcher();\n      if (newestSearcher != null) {\n        try {\n          this.updateHandler.getUpdateLog().onFirstSearcher(newestSearcher.get());\n        } finally {\n          newestSearcher.decref();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores. If a core with the\n   * same name already exists, it will be stopped and replaced by this one.\n   *\n   * @param dataDir\n   *          the index directory\n   * @param config\n   *          a solr config instance\n   * @param schema\n   *          a solr schema instance\n   *\n   * @since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config,\n      IndexSchema schema, CoreDescriptor coreDescriptor, UpdateHandler updateHandler,\n      IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    checkNotNull(coreDescriptor, \"coreDescriptor cannot be null\");\n    \n    this.coreDescriptor = coreDescriptor;\n    setName(name);\n    MDCUtils.setCore(name); // show the core name in the error logs\n    \n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n\n    if (updateHandler == null) {\n      directoryFactory = initDirectoryFactory();\n      solrCoreState = new DefaultSolrCoreState(directoryFactory);\n    } else {\n      solrCoreState = updateHandler.getSolrCoreState();\n      directoryFactory = solrCoreState.getDirectoryFactory();\n      isReloaded = true;\n    }\n\n    this.dataDir = initDataDir(dataDir, config, coreDescriptor);\n    this.ulogDir = initUpdateLogDir(coreDescriptor);\n\n    log.info(\"[{}] Opening new SolrCore at [{}], dataDir=[{}]\", logid, resourceLoader.getInstanceDir(), dataDir);\n\n    checkVersionFieldExistsInSchema(schema, coreDescriptor);\n\n    // Initialize JMX\n    this.infoRegistry = initInfoRegistry(name, config);\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = initSchema(config, schema);\n\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n\n      initListeners();\n\n      this.solrDelPolicy = initDeletionPolicy(delPolicy);\n\n      this.codec = initCodec(solrConfig, this.schema);\n\n      memClassLoader = new MemClassLoader(PluginBag.RuntimeLib.getLibObjects(this, solrConfig.getPluginInfos(PluginBag.RuntimeLib.class.getName())), getResourceLoader());\n      initIndex(prev != null);\n\n      initWriters();\n      qParserPlugins.init(createInstances(QParserPlugin.standardPlugins), this);\n      valueSourceParsers.init(ValueSourceParser.standardValueSourceParsers, this);\n      transformerFactories.init(TransformerFactory.defaultFactories, this);\n      loadSearchComponents();\n      updateProcessors.init(Collections.emptyMap(), this);\n\n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n\n      statsCache = initStatsCache();\n\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      this.updateHandler = initUpdateHandler(updateHandler);\n      \n      initSearcher(prev);\n\n      // Initialize the RestManager\n      restManager = initRestManager();\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      // release the latch, otherwise we block trying to do the close. This\n      // should be fine, since counting down on a latch of 0 is still fine\n      latch.countDown();\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n\n      try {\n        // close down the searcher and any other resources, if it exists, as this\n        // is not recoverable\n       close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError) t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n\n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n\n    // Allow the directory factory to register MBeans as well\n    for (SolrInfoMBean bean : directoryFactory.offerMBeans()) {\n      log.debug(\"Registering JMX bean [{}] from directory factory.\", bean.getName());\n      // Not worried about concurrency, so no reason to use putIfAbsent\n      if (infoRegistry.containsKey(bean.getName())){\n        log.info(\"Ignoring JMX bean [{}] due to name conflict.\", bean.getName());\n      } else {\n        infoRegistry.put(bean.getName(), bean);\n      }\n    }\n\n    bufferUpdatesIfConstructing(coreDescriptor);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    this.ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n  }\n\n","bugFix":null,"bugIntro":["311a0c9037fb7a2baefb9e262121d8f866e1c56f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"311a0c9037fb7a2baefb9e262121d8f866e1c56f","date":1432733372,"type":3,"author":"Timothy Potter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores. If a core with the\n   * same name already exists, it will be stopped and replaced by this one.\n   *\n   * @param dataDir\n   *          the index directory\n   * @param config\n   *          a solr config instance\n   * @param schema\n   *          a solr schema instance\n   *\n   * @since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config,\n      IndexSchema schema, CoreDescriptor coreDescriptor, UpdateHandler updateHandler,\n      IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    checkNotNull(coreDescriptor, \"coreDescriptor cannot be null\");\n    \n    this.coreDescriptor = coreDescriptor;\n    setName(name);\n    MDCUtils.setCore(name); // show the core name in the error logs\n    \n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n\n    if (updateHandler == null) {\n      directoryFactory = initDirectoryFactory();\n      solrCoreState = new DefaultSolrCoreState(directoryFactory);\n    } else {\n      solrCoreState = updateHandler.getSolrCoreState();\n      directoryFactory = solrCoreState.getDirectoryFactory();\n      isReloaded = true;\n    }\n\n    this.dataDir = initDataDir(dataDir, config, coreDescriptor);\n    this.ulogDir = initUpdateLogDir(coreDescriptor);\n\n    log.info(\"[{}] Opening new SolrCore at [{}], dataDir=[{}]\", logid, resourceLoader.getInstanceDir(), dataDir);\n\n    checkVersionFieldExistsInSchema(schema, coreDescriptor);\n\n    // Initialize JMX\n    this.infoRegistry = initInfoRegistry(name, config);\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = initSchema(config, schema);\n\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n\n      initListeners();\n\n      this.solrDelPolicy = initDeletionPolicy(delPolicy);\n\n      this.codec = initCodec(solrConfig, this.schema);\n\n      memClassLoader = new MemClassLoader(PluginBag.RuntimeLib.getLibObjects(this, solrConfig.getPluginInfos(PluginBag.RuntimeLib.class.getName())), getResourceLoader());\n      initIndex(prev != null);\n\n      initWriters();\n      qParserPlugins.init(createInstances(QParserPlugin.standardPlugins), this);\n      valueSourceParsers.init(ValueSourceParser.standardValueSourceParsers, this);\n      transformerFactories.init(TransformerFactory.defaultFactories, this);\n      loadSearchComponents();\n      updateProcessors.init(Collections.emptyMap(), this);\n\n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n\n      statsCache = initStatsCache();\n\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      this.updateHandler = initUpdateHandler(updateHandler);\n      \n      initSearcher(prev);\n\n      // Initialize the RestManager\n      restManager = initRestManager();\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      // release the latch, otherwise we block trying to do the close. This\n      // should be fine, since counting down on a latch of 0 is still fine\n      latch.countDown();\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n\n      try {\n        // close down the searcher and any other resources, if it exists, as this\n        // is not recoverable\n       close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError) t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n\n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n\n    // Allow the directory factory to register MBeans as well\n    for (SolrInfoMBean bean : directoryFactory.offerMBeans()) {\n      log.debug(\"Registering JMX bean [{}] from directory factory.\", bean.getName());\n      // Not worried about concurrency, so no reason to use putIfAbsent\n      if (infoRegistry.containsKey(bean.getName())){\n        log.info(\"Ignoring JMX bean [{}] due to name conflict.\", bean.getName());\n      } else {\n        infoRegistry.put(bean.getName(), bean);\n      }\n    }\n\n    // seed version buckets with max from index during core initialization ... requires a searcher!\n    seedVersionBucketsWithMaxFromIndex();\n\n    bufferUpdatesIfConstructing(coreDescriptor);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    this.ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores. If a core with the\n   * same name already exists, it will be stopped and replaced by this one.\n   *\n   * @param dataDir\n   *          the index directory\n   * @param config\n   *          a solr config instance\n   * @param schema\n   *          a solr schema instance\n   *\n   * @since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config,\n      IndexSchema schema, CoreDescriptor coreDescriptor, UpdateHandler updateHandler,\n      IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    checkNotNull(coreDescriptor, \"coreDescriptor cannot be null\");\n    \n    this.coreDescriptor = coreDescriptor;\n    setName(name);\n    MDCUtils.setCore(name); // show the core name in the error logs\n    \n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n\n    if (updateHandler == null) {\n      directoryFactory = initDirectoryFactory();\n      solrCoreState = new DefaultSolrCoreState(directoryFactory);\n    } else {\n      solrCoreState = updateHandler.getSolrCoreState();\n      directoryFactory = solrCoreState.getDirectoryFactory();\n      isReloaded = true;\n    }\n\n    this.dataDir = initDataDir(dataDir, config, coreDescriptor);\n    this.ulogDir = initUpdateLogDir(coreDescriptor);\n\n    log.info(\"[{}] Opening new SolrCore at [{}], dataDir=[{}]\", logid, resourceLoader.getInstanceDir(), dataDir);\n\n    checkVersionFieldExistsInSchema(schema, coreDescriptor);\n\n    // Initialize JMX\n    this.infoRegistry = initInfoRegistry(name, config);\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = initSchema(config, schema);\n\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n\n      initListeners();\n\n      this.solrDelPolicy = initDeletionPolicy(delPolicy);\n\n      this.codec = initCodec(solrConfig, this.schema);\n\n      memClassLoader = new MemClassLoader(PluginBag.RuntimeLib.getLibObjects(this, solrConfig.getPluginInfos(PluginBag.RuntimeLib.class.getName())), getResourceLoader());\n      initIndex(prev != null);\n\n      initWriters();\n      qParserPlugins.init(createInstances(QParserPlugin.standardPlugins), this);\n      valueSourceParsers.init(ValueSourceParser.standardValueSourceParsers, this);\n      transformerFactories.init(TransformerFactory.defaultFactories, this);\n      loadSearchComponents();\n      updateProcessors.init(Collections.emptyMap(), this);\n\n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n\n      statsCache = initStatsCache();\n\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      this.updateHandler = initUpdateHandler(updateHandler);\n      \n      initSearcher(prev);\n\n      // Initialize the RestManager\n      restManager = initRestManager();\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      // release the latch, otherwise we block trying to do the close. This\n      // should be fine, since counting down on a latch of 0 is still fine\n      latch.countDown();\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n\n      try {\n        // close down the searcher and any other resources, if it exists, as this\n        // is not recoverable\n       close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError) t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n\n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n\n    // Allow the directory factory to register MBeans as well\n    for (SolrInfoMBean bean : directoryFactory.offerMBeans()) {\n      log.debug(\"Registering JMX bean [{}] from directory factory.\", bean.getName());\n      // Not worried about concurrency, so no reason to use putIfAbsent\n      if (infoRegistry.containsKey(bean.getName())){\n        log.info(\"Ignoring JMX bean [{}] due to name conflict.\", bean.getName());\n      } else {\n        infoRegistry.put(bean.getName(), bean);\n      }\n    }\n\n    bufferUpdatesIfConstructing(coreDescriptor);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    this.ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n\n    // seed version buckets with max from index during core initialization\n    if (this.updateHandler != null && this.updateHandler.getUpdateLog() != null) {\n      RefCounted<SolrIndexSearcher> newestSearcher = getRealtimeSearcher();\n      if (newestSearcher != null) {\n        try {\n          this.updateHandler.getUpdateLog().onFirstSearcher(newestSearcher.get());\n        } finally {\n          newestSearcher.decref();\n        }\n      }\n    }\n  }\n\n","bugFix":["9220b7d1848f68bc299608612f8e0139c4036fcf"],"bugIntro":["877f1e09b9299ce0757f4d83768da944803baf04","bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"439c63ae5d22132fca810a0029a854e97d2c1a3e","date":1432733612,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores. If a core with the\n   * same name already exists, it will be stopped and replaced by this one.\n   *\n   * @param dataDir\n   *          the index directory\n   * @param config\n   *          a solr config instance\n   * @param schema\n   *          a solr schema instance\n   *\n   * @since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config,\n      IndexSchema schema, CoreDescriptor coreDescriptor, UpdateHandler updateHandler,\n      IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    checkNotNull(coreDescriptor, \"coreDescriptor cannot be null\");\n    \n    this.coreDescriptor = coreDescriptor;\n    setName(name);\n    MDCLoggingContext.setCore(this);\n    \n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n\n    if (updateHandler == null) {\n      directoryFactory = initDirectoryFactory();\n      solrCoreState = new DefaultSolrCoreState(directoryFactory);\n    } else {\n      solrCoreState = updateHandler.getSolrCoreState();\n      directoryFactory = solrCoreState.getDirectoryFactory();\n      isReloaded = true;\n    }\n\n    this.dataDir = initDataDir(dataDir, config, coreDescriptor);\n    this.ulogDir = initUpdateLogDir(coreDescriptor);\n\n    log.info(\"[{}] Opening new SolrCore at [{}], dataDir=[{}]\", logid, resourceLoader.getInstanceDir(), dataDir);\n\n    checkVersionFieldExistsInSchema(schema, coreDescriptor);\n\n    // Initialize JMX\n    this.infoRegistry = initInfoRegistry(name, config);\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = initSchema(config, schema);\n\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n\n      initListeners();\n\n      this.solrDelPolicy = initDeletionPolicy(delPolicy);\n\n      this.codec = initCodec(solrConfig, this.schema);\n\n      memClassLoader = new MemClassLoader(PluginBag.RuntimeLib.getLibObjects(this, solrConfig.getPluginInfos(PluginBag.RuntimeLib.class.getName())), getResourceLoader());\n      initIndex(prev != null);\n\n      initWriters();\n      qParserPlugins.init(createInstances(QParserPlugin.standardPlugins), this);\n      valueSourceParsers.init(ValueSourceParser.standardValueSourceParsers, this);\n      transformerFactories.init(TransformerFactory.defaultFactories, this);\n      loadSearchComponents();\n      updateProcessors.init(Collections.emptyMap(), this);\n\n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n\n      statsCache = initStatsCache();\n\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      this.updateHandler = initUpdateHandler(updateHandler);\n      \n      initSearcher(prev);\n\n      // Initialize the RestManager\n      restManager = initRestManager();\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      // release the latch, otherwise we block trying to do the close. This\n      // should be fine, since counting down on a latch of 0 is still fine\n      latch.countDown();\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n\n      try {\n        // close down the searcher and any other resources, if it exists, as this\n        // is not recoverable\n       close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError) t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n\n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n\n    // Allow the directory factory to register MBeans as well\n    for (SolrInfoMBean bean : directoryFactory.offerMBeans()) {\n      log.debug(\"Registering JMX bean [{}] from directory factory.\", bean.getName());\n      // Not worried about concurrency, so no reason to use putIfAbsent\n      if (infoRegistry.containsKey(bean.getName())){\n        log.info(\"Ignoring JMX bean [{}] due to name conflict.\", bean.getName());\n      } else {\n        infoRegistry.put(bean.getName(), bean);\n      }\n    }\n\n    // seed version buckets with max from index during core initialization ... requires a searcher!\n    seedVersionBucketsWithMaxFromIndex();\n\n    bufferUpdatesIfConstructing(coreDescriptor);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    this.ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores. If a core with the\n   * same name already exists, it will be stopped and replaced by this one.\n   *\n   * @param dataDir\n   *          the index directory\n   * @param config\n   *          a solr config instance\n   * @param schema\n   *          a solr schema instance\n   *\n   * @since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config,\n      IndexSchema schema, CoreDescriptor coreDescriptor, UpdateHandler updateHandler,\n      IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    checkNotNull(coreDescriptor, \"coreDescriptor cannot be null\");\n    \n    this.coreDescriptor = coreDescriptor;\n    setName(name);\n    MDCUtils.setCore(name); // show the core name in the error logs\n    \n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n\n    if (updateHandler == null) {\n      directoryFactory = initDirectoryFactory();\n      solrCoreState = new DefaultSolrCoreState(directoryFactory);\n    } else {\n      solrCoreState = updateHandler.getSolrCoreState();\n      directoryFactory = solrCoreState.getDirectoryFactory();\n      isReloaded = true;\n    }\n\n    this.dataDir = initDataDir(dataDir, config, coreDescriptor);\n    this.ulogDir = initUpdateLogDir(coreDescriptor);\n\n    log.info(\"[{}] Opening new SolrCore at [{}], dataDir=[{}]\", logid, resourceLoader.getInstanceDir(), dataDir);\n\n    checkVersionFieldExistsInSchema(schema, coreDescriptor);\n\n    // Initialize JMX\n    this.infoRegistry = initInfoRegistry(name, config);\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = initSchema(config, schema);\n\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n\n      initListeners();\n\n      this.solrDelPolicy = initDeletionPolicy(delPolicy);\n\n      this.codec = initCodec(solrConfig, this.schema);\n\n      memClassLoader = new MemClassLoader(PluginBag.RuntimeLib.getLibObjects(this, solrConfig.getPluginInfos(PluginBag.RuntimeLib.class.getName())), getResourceLoader());\n      initIndex(prev != null);\n\n      initWriters();\n      qParserPlugins.init(createInstances(QParserPlugin.standardPlugins), this);\n      valueSourceParsers.init(ValueSourceParser.standardValueSourceParsers, this);\n      transformerFactories.init(TransformerFactory.defaultFactories, this);\n      loadSearchComponents();\n      updateProcessors.init(Collections.emptyMap(), this);\n\n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n\n      statsCache = initStatsCache();\n\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      this.updateHandler = initUpdateHandler(updateHandler);\n      \n      initSearcher(prev);\n\n      // Initialize the RestManager\n      restManager = initRestManager();\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      // release the latch, otherwise we block trying to do the close. This\n      // should be fine, since counting down on a latch of 0 is still fine\n      latch.countDown();\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n\n      try {\n        // close down the searcher and any other resources, if it exists, as this\n        // is not recoverable\n       close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError) t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n\n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n\n    // Allow the directory factory to register MBeans as well\n    for (SolrInfoMBean bean : directoryFactory.offerMBeans()) {\n      log.debug(\"Registering JMX bean [{}] from directory factory.\", bean.getName());\n      // Not worried about concurrency, so no reason to use putIfAbsent\n      if (infoRegistry.containsKey(bean.getName())){\n        log.info(\"Ignoring JMX bean [{}] due to name conflict.\", bean.getName());\n      } else {\n        infoRegistry.put(bean.getName(), bean);\n      }\n    }\n\n    // seed version buckets with max from index during core initialization ... requires a searcher!\n    seedVersionBucketsWithMaxFromIndex();\n\n    bufferUpdatesIfConstructing(coreDescriptor);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    this.ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"877f1e09b9299ce0757f4d83768da944803baf04","date":1433276115,"type":3,"author":"Timothy Potter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores. If a core with the\n   * same name already exists, it will be stopped and replaced by this one.\n   *\n   * @param dataDir\n   *          the index directory\n   * @param config\n   *          a solr config instance\n   * @param schema\n   *          a solr schema instance\n   *\n   * @since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config,\n      IndexSchema schema, CoreDescriptor coreDescriptor, UpdateHandler updateHandler,\n      IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    checkNotNull(coreDescriptor, \"coreDescriptor cannot be null\");\n    \n    this.coreDescriptor = coreDescriptor;\n    setName(name);\n    MDCLoggingContext.setCore(this);\n    \n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n\n    if (updateHandler == null) {\n      directoryFactory = initDirectoryFactory();\n      solrCoreState = new DefaultSolrCoreState(directoryFactory);\n    } else {\n      solrCoreState = updateHandler.getSolrCoreState();\n      directoryFactory = solrCoreState.getDirectoryFactory();\n      isReloaded = true;\n    }\n\n    this.dataDir = initDataDir(dataDir, config, coreDescriptor);\n    this.ulogDir = initUpdateLogDir(coreDescriptor);\n\n    log.info(\"[{}] Opening new SolrCore at [{}], dataDir=[{}]\", logid, resourceLoader.getInstanceDir(), dataDir);\n\n    checkVersionFieldExistsInSchema(schema, coreDescriptor);\n\n    // Initialize JMX\n    this.infoRegistry = initInfoRegistry(name, config);\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = initSchema(config, schema);\n\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n\n      initListeners();\n\n      this.solrDelPolicy = initDeletionPolicy(delPolicy);\n\n      this.codec = initCodec(solrConfig, this.schema);\n\n      memClassLoader = new MemClassLoader(PluginBag.RuntimeLib.getLibObjects(this, solrConfig.getPluginInfos(PluginBag.RuntimeLib.class.getName())), getResourceLoader());\n      initIndex(prev != null);\n\n      initWriters();\n      qParserPlugins.init(createInstances(QParserPlugin.standardPlugins), this);\n      valueSourceParsers.init(ValueSourceParser.standardValueSourceParsers, this);\n      transformerFactories.init(TransformerFactory.defaultFactories, this);\n      loadSearchComponents();\n      updateProcessors.init(Collections.emptyMap(), this);\n\n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n\n      statsCache = initStatsCache();\n\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      this.updateHandler = initUpdateHandler(updateHandler);\n      \n      initSearcher(prev);\n\n      // Initialize the RestManager\n      restManager = initRestManager();\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      // release the latch, otherwise we block trying to do the close. This\n      // should be fine, since counting down on a latch of 0 is still fine\n      latch.countDown();\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n\n      try {\n        // close down the searcher and any other resources, if it exists, as this\n        // is not recoverable\n       close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError) t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n\n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n\n    // Allow the directory factory to register MBeans as well\n    for (SolrInfoMBean bean : directoryFactory.offerMBeans()) {\n      log.debug(\"Registering JMX bean [{}] from directory factory.\", bean.getName());\n      // Not worried about concurrency, so no reason to use putIfAbsent\n      if (infoRegistry.containsKey(bean.getName())){\n        log.info(\"Ignoring JMX bean [{}] due to name conflict.\", bean.getName());\n      } else {\n        infoRegistry.put(bean.getName(), bean);\n      }\n    }\n\n    // seed version buckets with max from index during core initialization ... requires a searcher!\n    seedVersionBuckets();\n\n    bufferUpdatesIfConstructing(coreDescriptor);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    this.ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores. If a core with the\n   * same name already exists, it will be stopped and replaced by this one.\n   *\n   * @param dataDir\n   *          the index directory\n   * @param config\n   *          a solr config instance\n   * @param schema\n   *          a solr schema instance\n   *\n   * @since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config,\n      IndexSchema schema, CoreDescriptor coreDescriptor, UpdateHandler updateHandler,\n      IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    checkNotNull(coreDescriptor, \"coreDescriptor cannot be null\");\n    \n    this.coreDescriptor = coreDescriptor;\n    setName(name);\n    MDCLoggingContext.setCore(this);\n    \n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n\n    if (updateHandler == null) {\n      directoryFactory = initDirectoryFactory();\n      solrCoreState = new DefaultSolrCoreState(directoryFactory);\n    } else {\n      solrCoreState = updateHandler.getSolrCoreState();\n      directoryFactory = solrCoreState.getDirectoryFactory();\n      isReloaded = true;\n    }\n\n    this.dataDir = initDataDir(dataDir, config, coreDescriptor);\n    this.ulogDir = initUpdateLogDir(coreDescriptor);\n\n    log.info(\"[{}] Opening new SolrCore at [{}], dataDir=[{}]\", logid, resourceLoader.getInstanceDir(), dataDir);\n\n    checkVersionFieldExistsInSchema(schema, coreDescriptor);\n\n    // Initialize JMX\n    this.infoRegistry = initInfoRegistry(name, config);\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = initSchema(config, schema);\n\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n\n      initListeners();\n\n      this.solrDelPolicy = initDeletionPolicy(delPolicy);\n\n      this.codec = initCodec(solrConfig, this.schema);\n\n      memClassLoader = new MemClassLoader(PluginBag.RuntimeLib.getLibObjects(this, solrConfig.getPluginInfos(PluginBag.RuntimeLib.class.getName())), getResourceLoader());\n      initIndex(prev != null);\n\n      initWriters();\n      qParserPlugins.init(createInstances(QParserPlugin.standardPlugins), this);\n      valueSourceParsers.init(ValueSourceParser.standardValueSourceParsers, this);\n      transformerFactories.init(TransformerFactory.defaultFactories, this);\n      loadSearchComponents();\n      updateProcessors.init(Collections.emptyMap(), this);\n\n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n\n      statsCache = initStatsCache();\n\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      this.updateHandler = initUpdateHandler(updateHandler);\n      \n      initSearcher(prev);\n\n      // Initialize the RestManager\n      restManager = initRestManager();\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      // release the latch, otherwise we block trying to do the close. This\n      // should be fine, since counting down on a latch of 0 is still fine\n      latch.countDown();\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n\n      try {\n        // close down the searcher and any other resources, if it exists, as this\n        // is not recoverable\n       close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError) t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n\n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n\n    // Allow the directory factory to register MBeans as well\n    for (SolrInfoMBean bean : directoryFactory.offerMBeans()) {\n      log.debug(\"Registering JMX bean [{}] from directory factory.\", bean.getName());\n      // Not worried about concurrency, so no reason to use putIfAbsent\n      if (infoRegistry.containsKey(bean.getName())){\n        log.info(\"Ignoring JMX bean [{}] due to name conflict.\", bean.getName());\n      } else {\n        infoRegistry.put(bean.getName(), bean);\n      }\n    }\n\n    // seed version buckets with max from index during core initialization ... requires a searcher!\n    seedVersionBucketsWithMaxFromIndex();\n\n    bufferUpdatesIfConstructing(coreDescriptor);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    this.ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n  }\n\n","bugFix":["311a0c9037fb7a2baefb9e262121d8f866e1c56f"],"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6466e433d7f5218e77c8115ed28176855fc3c143","date":1436824910,"type":5,"author":"Gregory Chanan","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,NamedList,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores. If a core with the\n   * same name already exists, it will be stopped and replaced by this one.\n   *\n   * @param dataDir\n   *          the index directory\n   * @param config\n   *          a solr config instance\n   * @param schema\n   *          a solr schema instance\n   *\n   * @since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config,\n      IndexSchema schema, NamedList configSetProperties,\n      CoreDescriptor coreDescriptor, UpdateHandler updateHandler,\n      IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    checkNotNull(coreDescriptor, \"coreDescriptor cannot be null\");\n    \n    this.coreDescriptor = coreDescriptor;\n    setName(name);\n    MDCLoggingContext.setCore(this);\n    \n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    this.configSetProperties = configSetProperties;\n\n    if (updateHandler == null) {\n      directoryFactory = initDirectoryFactory();\n      solrCoreState = new DefaultSolrCoreState(directoryFactory);\n    } else {\n      solrCoreState = updateHandler.getSolrCoreState();\n      directoryFactory = solrCoreState.getDirectoryFactory();\n      isReloaded = true;\n    }\n\n    this.dataDir = initDataDir(dataDir, config, coreDescriptor);\n    this.ulogDir = initUpdateLogDir(coreDescriptor);\n\n    log.info(\"[{}] Opening new SolrCore at [{}], dataDir=[{}]\", logid, resourceLoader.getInstanceDir(), dataDir);\n\n    checkVersionFieldExistsInSchema(schema, coreDescriptor);\n\n    // Initialize JMX\n    this.infoRegistry = initInfoRegistry(name, config);\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = initSchema(config, schema);\n\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n\n      initListeners();\n\n      this.solrDelPolicy = initDeletionPolicy(delPolicy);\n\n      this.codec = initCodec(solrConfig, this.schema);\n\n      memClassLoader = new MemClassLoader(PluginBag.RuntimeLib.getLibObjects(this, solrConfig.getPluginInfos(PluginBag.RuntimeLib.class.getName())), getResourceLoader());\n      initIndex(prev != null);\n\n      initWriters();\n      qParserPlugins.init(createInstances(QParserPlugin.standardPlugins), this);\n      valueSourceParsers.init(ValueSourceParser.standardValueSourceParsers, this);\n      transformerFactories.init(TransformerFactory.defaultFactories, this);\n      loadSearchComponents();\n      updateProcessors.init(Collections.emptyMap(), this);\n\n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n\n      statsCache = initStatsCache();\n\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      this.updateHandler = initUpdateHandler(updateHandler);\n      \n      initSearcher(prev);\n\n      // Initialize the RestManager\n      restManager = initRestManager();\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      // release the latch, otherwise we block trying to do the close. This\n      // should be fine, since counting down on a latch of 0 is still fine\n      latch.countDown();\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n\n      try {\n        // close down the searcher and any other resources, if it exists, as this\n        // is not recoverable\n       close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError) t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n\n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n\n    // Allow the directory factory to register MBeans as well\n    for (SolrInfoMBean bean : directoryFactory.offerMBeans()) {\n      log.debug(\"Registering JMX bean [{}] from directory factory.\", bean.getName());\n      // Not worried about concurrency, so no reason to use putIfAbsent\n      if (infoRegistry.containsKey(bean.getName())){\n        log.info(\"Ignoring JMX bean [{}] due to name conflict.\", bean.getName());\n      } else {\n        infoRegistry.put(bean.getName(), bean);\n      }\n    }\n\n    // seed version buckets with max from index during core initialization ... requires a searcher!\n    seedVersionBuckets();\n\n    bufferUpdatesIfConstructing(coreDescriptor);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    this.ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores. If a core with the\n   * same name already exists, it will be stopped and replaced by this one.\n   *\n   * @param dataDir\n   *          the index directory\n   * @param config\n   *          a solr config instance\n   * @param schema\n   *          a solr schema instance\n   *\n   * @since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config,\n      IndexSchema schema, CoreDescriptor coreDescriptor, UpdateHandler updateHandler,\n      IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    checkNotNull(coreDescriptor, \"coreDescriptor cannot be null\");\n    \n    this.coreDescriptor = coreDescriptor;\n    setName(name);\n    MDCLoggingContext.setCore(this);\n    \n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n\n    if (updateHandler == null) {\n      directoryFactory = initDirectoryFactory();\n      solrCoreState = new DefaultSolrCoreState(directoryFactory);\n    } else {\n      solrCoreState = updateHandler.getSolrCoreState();\n      directoryFactory = solrCoreState.getDirectoryFactory();\n      isReloaded = true;\n    }\n\n    this.dataDir = initDataDir(dataDir, config, coreDescriptor);\n    this.ulogDir = initUpdateLogDir(coreDescriptor);\n\n    log.info(\"[{}] Opening new SolrCore at [{}], dataDir=[{}]\", logid, resourceLoader.getInstanceDir(), dataDir);\n\n    checkVersionFieldExistsInSchema(schema, coreDescriptor);\n\n    // Initialize JMX\n    this.infoRegistry = initInfoRegistry(name, config);\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = initSchema(config, schema);\n\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;\n\n    booleanQueryMaxClauseCount();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n\n      initListeners();\n\n      this.solrDelPolicy = initDeletionPolicy(delPolicy);\n\n      this.codec = initCodec(solrConfig, this.schema);\n\n      memClassLoader = new MemClassLoader(PluginBag.RuntimeLib.getLibObjects(this, solrConfig.getPluginInfos(PluginBag.RuntimeLib.class.getName())), getResourceLoader());\n      initIndex(prev != null);\n\n      initWriters();\n      qParserPlugins.init(createInstances(QParserPlugin.standardPlugins), this);\n      valueSourceParsers.init(ValueSourceParser.standardValueSourceParsers, this);\n      transformerFactories.init(TransformerFactory.defaultFactories, this);\n      loadSearchComponents();\n      updateProcessors.init(Collections.emptyMap(), this);\n\n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n\n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n\n      statsCache = initStatsCache();\n\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      this.updateHandler = initUpdateHandler(updateHandler);\n      \n      initSearcher(prev);\n\n      // Initialize the RestManager\n      restManager = initRestManager();\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      // release the latch, otherwise we block trying to do the close. This\n      // should be fine, since counting down on a latch of 0 is still fine\n      latch.countDown();\n      if (e instanceof OutOfMemoryError) {\n        throw (OutOfMemoryError)e;\n      }\n\n      try {\n        // close down the searcher and any other resources, if it exists, as this\n        // is not recoverable\n       close();\n      } catch (Throwable t) {\n        if (t instanceof OutOfMemoryError) {\n          throw (OutOfMemoryError) t;\n        }\n        log.error(\"Error while closing\", t);\n      }\n\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n\n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n\n    // Allow the directory factory to register MBeans as well\n    for (SolrInfoMBean bean : directoryFactory.offerMBeans()) {\n      log.debug(\"Registering JMX bean [{}] from directory factory.\", bean.getName());\n      // Not worried about concurrency, so no reason to use putIfAbsent\n      if (infoRegistry.containsKey(bean.getName())){\n        log.info(\"Ignoring JMX bean [{}] due to name conflict.\", bean.getName());\n      } else {\n        infoRegistry.put(bean.getName(), bean);\n      }\n    }\n\n    // seed version buckets with max from index during core initialization ... requires a searcher!\n    seedVersionBuckets();\n\n    bufferUpdatesIfConstructing(coreDescriptor);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n\n    this.ruleExpiryLock = new ReentrantLock();\n    registerConfListener();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"2336740b200d02b6a5fb18b70454dd9aa26f5b47":["4a9c941a7004ea2e95b10aa67dafa319ff8d8c19"],"311a0c9037fb7a2baefb9e262121d8f866e1c56f":["9220b7d1848f68bc299608612f8e0139c4036fcf"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["3a540622c5e216f2d96b1199c35603eaff1020e9","6e764e9a107f93be9fa3c922bc6a197b3eec387e"],"07e5c48260f0b3abf6daef83f4ce8bd72b0be5ce":["41e1b8818332825c60cfbd7efa38294078eae898"],"ab20a04a303d3d2a5078076f4633e0482d643cc0":["afb6bf9ce227ab6aac5068547e286ecc958b8b9d"],"4a9c941a7004ea2e95b10aa67dafa319ff8d8c19":["ab20a04a303d3d2a5078076f4633e0482d643cc0"],"0c924d4069ef5a5bc479a493befe0121aada6896":["fab172655716b96f7e42376116235017a922de3a","d0dcc63c22f7cfe3d3a83aee576d0fc5b403a296"],"c9f81a0a8d08cc36757b7be45a8c8dcd66ff0360":["65974810aff303cdaecff3dd789ae9353c1d9134"],"f56da6f4f15d95f318d2d6ac2a39a9183dfecff2":["f6198fb63e3890bd8fe0da672eba02a8ab6190c8"],"fab172655716b96f7e42376116235017a922de3a":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","65780dd0a70597aa46f16a2a42093215ca237272"],"877f1e09b9299ce0757f4d83768da944803baf04":["439c63ae5d22132fca810a0029a854e97d2c1a3e"],"f6198fb63e3890bd8fe0da672eba02a8ab6190c8":["da888af1ab894358122a22229051215f58cf4d54"],"6466e433d7f5218e77c8115ed28176855fc3c143":["877f1e09b9299ce0757f4d83768da944803baf04"],"3ee01ed2bbdbfebcda94054cb39b4fac5f06a3bd":["69cad0546debf9ce9d44e309ecfa26760fecd5d8"],"54bb8da55080e4569804e0661b83a3c72cbd8d4d":["d0dcc63c22f7cfe3d3a83aee576d0fc5b403a296"],"afb6bf9ce227ab6aac5068547e286ecc958b8b9d":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"da888af1ab894358122a22229051215f58cf4d54":["bc841231667f1f315bae6799c068f9aad6543967"],"849494cf2f3a96af5c8c84995108ddd8456fcd04":["3a540622c5e216f2d96b1199c35603eaff1020e9"],"3a540622c5e216f2d96b1199c35603eaff1020e9":["07e5c48260f0b3abf6daef83f4ce8bd72b0be5ce"],"a94e45463a0089149b0d148ae5369140e7f54b8c":["e56881a4ebc3438313e3c008a7124ba0f8ecc7bf"],"9cf81bc8c6e4078e236f0e38b3a2d0271854f207":["47402a40696c1b7bc0524a8857b833c00f4cde3f"],"e56881a4ebc3438313e3c008a7124ba0f8ecc7bf":["531fe719c7218235a679452eb3d137bfd8fc6af1"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":["da888af1ab894358122a22229051215f58cf4d54","f6198fb63e3890bd8fe0da672eba02a8ab6190c8"],"69cad0546debf9ce9d44e309ecfa26760fecd5d8":["9aea0485ecacb6734c17da2d02569816c23a69c1"],"65780dd0a70597aa46f16a2a42093215ca237272":["3ee01ed2bbdbfebcda94054cb39b4fac5f06a3bd"],"47402a40696c1b7bc0524a8857b833c00f4cde3f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"eb55f6c347c48c2f7a9fb29b2e6dfe819b1a56f9":["2336740b200d02b6a5fb18b70454dd9aa26f5b47"],"a3b687d77563d946578f099495d70e55c92f3f1d":["849494cf2f3a96af5c8c84995108ddd8456fcd04"],"9220b7d1848f68bc299608612f8e0139c4036fcf":["7da173d341edb3a56705e0ee852574c69d83aa6f"],"41e1b8818332825c60cfbd7efa38294078eae898":["08970e5b8411182a29412c177eff67ec1110095b"],"d0dcc63c22f7cfe3d3a83aee576d0fc5b403a296":["65780dd0a70597aa46f16a2a42093215ca237272"],"7da173d341edb3a56705e0ee852574c69d83aa6f":["54bb8da55080e4569804e0661b83a3c72cbd8d4d"],"87d54fb06e5d5ca00e6b0db75b52de2013d09ce4":["f56da6f4f15d95f318d2d6ac2a39a9183dfecff2"],"b7605579001505896d48b07160075a5c8b8e128e":["ab20a04a303d3d2a5078076f4633e0482d643cc0","4a9c941a7004ea2e95b10aa67dafa319ff8d8c19"],"439c63ae5d22132fca810a0029a854e97d2c1a3e":["311a0c9037fb7a2baefb9e262121d8f866e1c56f"],"08970e5b8411182a29412c177eff67ec1110095b":["9cf81bc8c6e4078e236f0e38b3a2d0271854f207"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["ac2f1cdbdc54a889e88543cc1d939a931cb96883","3ee01ed2bbdbfebcda94054cb39b4fac5f06a3bd"],"bc841231667f1f315bae6799c068f9aad6543967":["c9f81a0a8d08cc36757b7be45a8c8dcd66ff0360"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"65974810aff303cdaecff3dd789ae9353c1d9134":["6e764e9a107f93be9fa3c922bc6a197b3eec387e"],"6e764e9a107f93be9fa3c922bc6a197b3eec387e":["a3b687d77563d946578f099495d70e55c92f3f1d"],"9aea0485ecacb6734c17da2d02569816c23a69c1":["ac2f1cdbdc54a889e88543cc1d939a931cb96883"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["87d54fb06e5d5ca00e6b0db75b52de2013d09ce4"],"531fe719c7218235a679452eb3d137bfd8fc6af1":["eb55f6c347c48c2f7a9fb29b2e6dfe819b1a56f9"],"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe":["afb6bf9ce227ab6aac5068547e286ecc958b8b9d","ab20a04a303d3d2a5078076f4633e0482d643cc0"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":["37a0f60745e53927c4c876cfe5b5a58170f0646c","65974810aff303cdaecff3dd789ae9353c1d9134"],"ac2f1cdbdc54a889e88543cc1d939a931cb96883":["b5a70f7ff0756e3668447bffbbf8bce8e7c361b9"],"b5a70f7ff0756e3668447bffbbf8bce8e7c361b9":["a94e45463a0089149b0d148ae5369140e7f54b8c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["6466e433d7f5218e77c8115ed28176855fc3c143"]},"commit2Childs":{"2336740b200d02b6a5fb18b70454dd9aa26f5b47":["eb55f6c347c48c2f7a9fb29b2e6dfe819b1a56f9"],"311a0c9037fb7a2baefb9e262121d8f866e1c56f":["439c63ae5d22132fca810a0029a854e97d2c1a3e"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["3dffec77fb8f7d0e9ca4869dddd6af94528b4576"],"07e5c48260f0b3abf6daef83f4ce8bd72b0be5ce":["3a540622c5e216f2d96b1199c35603eaff1020e9"],"ab20a04a303d3d2a5078076f4633e0482d643cc0":["4a9c941a7004ea2e95b10aa67dafa319ff8d8c19","b7605579001505896d48b07160075a5c8b8e128e","c0cd85fde84cb318b4dc97710dcf15e2959a1bbe"],"4a9c941a7004ea2e95b10aa67dafa319ff8d8c19":["2336740b200d02b6a5fb18b70454dd9aa26f5b47","b7605579001505896d48b07160075a5c8b8e128e"],"0c924d4069ef5a5bc479a493befe0121aada6896":[],"c9f81a0a8d08cc36757b7be45a8c8dcd66ff0360":["bc841231667f1f315bae6799c068f9aad6543967"],"fab172655716b96f7e42376116235017a922de3a":["0c924d4069ef5a5bc479a493befe0121aada6896"],"f56da6f4f15d95f318d2d6ac2a39a9183dfecff2":["87d54fb06e5d5ca00e6b0db75b52de2013d09ce4"],"f6198fb63e3890bd8fe0da672eba02a8ab6190c8":["f56da6f4f15d95f318d2d6ac2a39a9183dfecff2","74f45af4339b0daf7a95c820ab88c1aea74fbce0"],"877f1e09b9299ce0757f4d83768da944803baf04":["6466e433d7f5218e77c8115ed28176855fc3c143"],"6466e433d7f5218e77c8115ed28176855fc3c143":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3ee01ed2bbdbfebcda94054cb39b4fac5f06a3bd":["65780dd0a70597aa46f16a2a42093215ca237272","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"54bb8da55080e4569804e0661b83a3c72cbd8d4d":["7da173d341edb3a56705e0ee852574c69d83aa6f"],"afb6bf9ce227ab6aac5068547e286ecc958b8b9d":["ab20a04a303d3d2a5078076f4633e0482d643cc0","c0cd85fde84cb318b4dc97710dcf15e2959a1bbe"],"3a540622c5e216f2d96b1199c35603eaff1020e9":["37a0f60745e53927c4c876cfe5b5a58170f0646c","849494cf2f3a96af5c8c84995108ddd8456fcd04"],"da888af1ab894358122a22229051215f58cf4d54":["f6198fb63e3890bd8fe0da672eba02a8ab6190c8","74f45af4339b0daf7a95c820ab88c1aea74fbce0"],"849494cf2f3a96af5c8c84995108ddd8456fcd04":["a3b687d77563d946578f099495d70e55c92f3f1d"],"a94e45463a0089149b0d148ae5369140e7f54b8c":["b5a70f7ff0756e3668447bffbbf8bce8e7c361b9"],"9cf81bc8c6e4078e236f0e38b3a2d0271854f207":["08970e5b8411182a29412c177eff67ec1110095b"],"e56881a4ebc3438313e3c008a7124ba0f8ecc7bf":["a94e45463a0089149b0d148ae5369140e7f54b8c"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":[],"69cad0546debf9ce9d44e309ecfa26760fecd5d8":["3ee01ed2bbdbfebcda94054cb39b4fac5f06a3bd"],"65780dd0a70597aa46f16a2a42093215ca237272":["fab172655716b96f7e42376116235017a922de3a","d0dcc63c22f7cfe3d3a83aee576d0fc5b403a296"],"47402a40696c1b7bc0524a8857b833c00f4cde3f":["9cf81bc8c6e4078e236f0e38b3a2d0271854f207"],"eb55f6c347c48c2f7a9fb29b2e6dfe819b1a56f9":["531fe719c7218235a679452eb3d137bfd8fc6af1"],"a3b687d77563d946578f099495d70e55c92f3f1d":["6e764e9a107f93be9fa3c922bc6a197b3eec387e"],"9220b7d1848f68bc299608612f8e0139c4036fcf":["311a0c9037fb7a2baefb9e262121d8f866e1c56f"],"41e1b8818332825c60cfbd7efa38294078eae898":["07e5c48260f0b3abf6daef83f4ce8bd72b0be5ce"],"d0dcc63c22f7cfe3d3a83aee576d0fc5b403a296":["0c924d4069ef5a5bc479a493befe0121aada6896","54bb8da55080e4569804e0661b83a3c72cbd8d4d"],"7da173d341edb3a56705e0ee852574c69d83aa6f":["9220b7d1848f68bc299608612f8e0139c4036fcf"],"87d54fb06e5d5ca00e6b0db75b52de2013d09ce4":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"b7605579001505896d48b07160075a5c8b8e128e":[],"439c63ae5d22132fca810a0029a854e97d2c1a3e":["877f1e09b9299ce0757f4d83768da944803baf04"],"08970e5b8411182a29412c177eff67ec1110095b":["41e1b8818332825c60cfbd7efa38294078eae898"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["fab172655716b96f7e42376116235017a922de3a"],"bc841231667f1f315bae6799c068f9aad6543967":["da888af1ab894358122a22229051215f58cf4d54"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["47402a40696c1b7bc0524a8857b833c00f4cde3f"],"65974810aff303cdaecff3dd789ae9353c1d9134":["c9f81a0a8d08cc36757b7be45a8c8dcd66ff0360","3dffec77fb8f7d0e9ca4869dddd6af94528b4576"],"6e764e9a107f93be9fa3c922bc6a197b3eec387e":["37a0f60745e53927c4c876cfe5b5a58170f0646c","65974810aff303cdaecff3dd789ae9353c1d9134"],"9aea0485ecacb6734c17da2d02569816c23a69c1":["69cad0546debf9ce9d44e309ecfa26760fecd5d8"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["afb6bf9ce227ab6aac5068547e286ecc958b8b9d"],"531fe719c7218235a679452eb3d137bfd8fc6af1":["e56881a4ebc3438313e3c008a7124ba0f8ecc7bf"],"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe":[],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":[],"ac2f1cdbdc54a889e88543cc1d939a931cb96883":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","9aea0485ecacb6734c17da2d02569816c23a69c1"],"b5a70f7ff0756e3668447bffbbf8bce8e7c361b9":["ac2f1cdbdc54a889e88543cc1d939a931cb96883"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["0c924d4069ef5a5bc479a493befe0121aada6896","74f45af4339b0daf7a95c820ab88c1aea74fbce0","b7605579001505896d48b07160075a5c8b8e128e","c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","3dffec77fb8f7d0e9ca4869dddd6af94528b4576","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}