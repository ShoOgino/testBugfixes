{"path":"lucene/core/src/test/org/apache/lucene/index/TestPayloadProcessorProvider#populateDocs(Random,Directory,boolean).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPayloadProcessorProvider#populateDocs(Random,Directory,boolean).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPayloadProcessorProvider#populateDocs(Random,Directory,boolean).mjava","sourceNew":"  private void populateDocs(Random random, Directory dir, boolean multipleCommits)\n      throws IOException {\n    IndexWriter writer = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    TokenStream payloadTS1 = new PayloadTokenStream(\"p1\");\n    TokenStream payloadTS2 = new PayloadTokenStream(\"p2\");\n    FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"doc\" + i, customType));\n      doc.add(newField(\"content\", \"doc content \" + i, TextField.TYPE_UNSTORED));\n      doc.add(new TextField(\"p\", payloadTS1));\n      doc.add(new TextField(\"p\", payloadTS2));\n      writer.addDocument(doc);\n      if (multipleCommits && (i % 4 == 0)) {\n        writer.commit();\n      }\n    }\n    writer.close();\n  }\n\n","sourceOld":"  private void populateDocs(Random random, Directory dir, boolean multipleCommits)\n      throws IOException {\n    IndexWriter writer = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    TokenStream payloadTS1 = new PayloadTokenStream(\"p1\");\n    TokenStream payloadTS2 = new PayloadTokenStream(\"p2\");\n    FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"doc\" + i, customType));\n      doc.add(newField(\"content\", \"doc content \" + i, TextField.TYPE_UNSTORED));\n      doc.add(new TextField(\"p\", payloadTS1));\n      doc.add(new TextField(\"p\", payloadTS2));\n      writer.addDocument(doc);\n      if (multipleCommits && (i % 4 == 0)) {\n        writer.commit();\n      }\n    }\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"04f07771a2a7dd3a395700665ed839c3dae2def2","date":1339350139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPayloadProcessorProvider#populateDocs(Random,Directory,boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPayloadProcessorProvider#populateDocs(Random,Directory,boolean).mjava","sourceNew":"  private void populateDocs(Random random, Directory dir, boolean multipleCommits)\n      throws IOException {\n    IndexWriter writer = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    TokenStream payloadTS1 = new PayloadTokenStream(\"p1\");\n    TokenStream payloadTS2 = new PayloadTokenStream(\"p2\");\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"doc\" + i, customType));\n      doc.add(newTextField(\"content\", \"doc content \" + i, Field.Store.NO));\n      doc.add(new TextField(\"p\", payloadTS1));\n      doc.add(new TextField(\"p\", payloadTS2));\n      writer.addDocument(doc);\n      if (multipleCommits && (i % 4 == 0)) {\n        writer.commit();\n      }\n    }\n    writer.close();\n  }\n\n","sourceOld":"  private void populateDocs(Random random, Directory dir, boolean multipleCommits)\n      throws IOException {\n    IndexWriter writer = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    TokenStream payloadTS1 = new PayloadTokenStream(\"p1\");\n    TokenStream payloadTS2 = new PayloadTokenStream(\"p2\");\n    FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"doc\" + i, customType));\n      doc.add(newField(\"content\", \"doc content \" + i, TextField.TYPE_UNSTORED));\n      doc.add(new TextField(\"p\", payloadTS1));\n      doc.add(new TextField(\"p\", payloadTS2));\n      writer.addDocument(doc);\n      if (multipleCommits && (i % 4 == 0)) {\n        writer.commit();\n      }\n    }\n    writer.close();\n  }\n\n","bugFix":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0935c850ea562932997b72c69d93e345f21d7f45","date":1344711506,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPayloadProcessorProvider#populateDocs(Random,Directory,boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPayloadProcessorProvider#populateDocs(Random,Directory,boolean).mjava","sourceNew":"  private void populateDocs(Random random, Directory dir, boolean multipleCommits)\n      throws IOException {\n    IndexWriter writer = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    TokenStream payloadTS1 = new PayloadTokenStream(\"p1\");\n    TokenStream payloadTS2 = new PayloadTokenStream(\"p2\");\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"doc\" + i, customType));\n      doc.add(newTextField(\"content\", \"doc content \" + i, Field.Store.NO));\n      if (random.nextBoolean()) {\n        doc.add(new TextField(\"p\", payloadTS1));\n        doc.add(new TextField(\"p\", payloadTS2));\n      } else {\n        FieldType type = new FieldType(TextField.TYPE_NOT_STORED);\n        type.setStoreTermVectors(true);\n        type.setStoreTermVectorPositions(true);\n        type.setStoreTermVectorPayloads(true);\n        type.setStoreTermVectorOffsets(random.nextBoolean());\n        doc.add(new Field(\"p\", payloadTS1, type));\n        doc.add(new Field(\"p\", payloadTS2, type));\n      }\n      writer.addDocument(doc);\n      if (multipleCommits && (i % 4 == 0)) {\n        writer.commit();\n      }\n    }\n    writer.close();\n  }\n\n","sourceOld":"  private void populateDocs(Random random, Directory dir, boolean multipleCommits)\n      throws IOException {\n    IndexWriter writer = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    TokenStream payloadTS1 = new PayloadTokenStream(\"p1\");\n    TokenStream payloadTS2 = new PayloadTokenStream(\"p2\");\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"doc\" + i, customType));\n      doc.add(newTextField(\"content\", \"doc content \" + i, Field.Store.NO));\n      doc.add(new TextField(\"p\", payloadTS1));\n      doc.add(new TextField(\"p\", payloadTS2));\n      writer.addDocument(doc);\n      if (multipleCommits && (i % 4 == 0)) {\n        writer.commit();\n      }\n    }\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7869f64c874ebf7f317d22c00baf2b6857797a6","date":1344856617,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPayloadProcessorProvider#populateDocs(Random,Directory,boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPayloadProcessorProvider#populateDocs(Random,Directory,boolean).mjava","sourceNew":"  private void populateDocs(Random random, Directory dir, boolean multipleCommits)\n      throws IOException {\n    IndexWriter writer = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    TokenStream payloadTS1 = new PayloadTokenStream(\"p1\");\n    TokenStream payloadTS2 = new PayloadTokenStream(\"p2\");\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"doc\" + i, customType));\n      doc.add(newTextField(\"content\", \"doc content \" + i, Field.Store.NO));\n      if (random.nextBoolean()) {\n        doc.add(new TextField(\"p\", payloadTS1));\n        doc.add(new TextField(\"p\", payloadTS2));\n      } else {\n        FieldType type = new FieldType(TextField.TYPE_NOT_STORED);\n        type.setStoreTermVectors(true);\n        type.setStoreTermVectorPositions(true);\n        type.setStoreTermVectorPayloads(true);\n        type.setStoreTermVectorOffsets(random.nextBoolean());\n        doc.add(new Field(\"p\", payloadTS1, type));\n        doc.add(new Field(\"p\", payloadTS2, type));\n      }\n      writer.addDocument(doc);\n      if (multipleCommits && (i % 4 == 0)) {\n        writer.commit();\n      }\n    }\n    writer.close();\n  }\n\n","sourceOld":"  private void populateDocs(Random random, Directory dir, boolean multipleCommits)\n      throws IOException {\n    IndexWriter writer = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    TokenStream payloadTS1 = new PayloadTokenStream(\"p1\");\n    TokenStream payloadTS2 = new PayloadTokenStream(\"p2\");\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"doc\" + i, customType));\n      doc.add(newTextField(\"content\", \"doc content \" + i, Field.Store.NO));\n      doc.add(new TextField(\"p\", payloadTS1));\n      doc.add(new TextField(\"p\", payloadTS2));\n      writer.addDocument(doc);\n      if (multipleCommits && (i % 4 == 0)) {\n        writer.commit();\n      }\n    }\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9","date":1344867506,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPayloadProcessorProvider#populateDocs(Random,Directory,boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPayloadProcessorProvider#populateDocs(Random,Directory,boolean).mjava","sourceNew":"  private void populateDocs(Random random, Directory dir, boolean multipleCommits)\n      throws IOException {\n    IndexWriter writer = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    TokenStream payloadTS1 = new PayloadTokenStream(\"p1\");\n    TokenStream payloadTS2 = new PayloadTokenStream(\"p2\");\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"doc\" + i, customType));\n      doc.add(newTextField(\"content\", \"doc content \" + i, Field.Store.NO));\n      if (random.nextBoolean()) {\n        doc.add(new TextField(\"p\", payloadTS1));\n        doc.add(new TextField(\"p\", payloadTS2));\n      } else {\n        FieldType type = new FieldType(TextField.TYPE_NOT_STORED);\n        type.setStoreTermVectors(true);\n        type.setStoreTermVectorPositions(true);\n        type.setStoreTermVectorPayloads(true);\n        type.setStoreTermVectorOffsets(random.nextBoolean());\n        doc.add(new Field(\"p\", payloadTS1, type));\n        doc.add(new Field(\"p\", payloadTS2, type));\n      }\n      writer.addDocument(doc);\n      if (multipleCommits && (i % 4 == 0)) {\n        writer.commit();\n      }\n    }\n    writer.close();\n  }\n\n","sourceOld":"  private void populateDocs(Random random, Directory dir, boolean multipleCommits)\n      throws IOException {\n    IndexWriter writer = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    TokenStream payloadTS1 = new PayloadTokenStream(\"p1\");\n    TokenStream payloadTS2 = new PayloadTokenStream(\"p2\");\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"doc\" + i, customType));\n      doc.add(newTextField(\"content\", \"doc content \" + i, Field.Store.NO));\n      doc.add(new TextField(\"p\", payloadTS1));\n      doc.add(new TextField(\"p\", payloadTS2));\n      writer.addDocument(doc);\n      if (multipleCommits && (i % 4 == 0)) {\n        writer.commit();\n      }\n    }\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bc124b3b129ef11a255212f3af482b771c5b3a6c","date":1344947616,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPayloadProcessorProvider#populateDocs(Random,Directory,boolean).mjava","sourceNew":null,"sourceOld":"  private void populateDocs(Random random, Directory dir, boolean multipleCommits)\n      throws IOException {\n    IndexWriter writer = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    TokenStream payloadTS1 = new PayloadTokenStream(\"p1\");\n    TokenStream payloadTS2 = new PayloadTokenStream(\"p2\");\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"doc\" + i, customType));\n      doc.add(newTextField(\"content\", \"doc content \" + i, Field.Store.NO));\n      if (random.nextBoolean()) {\n        doc.add(new TextField(\"p\", payloadTS1));\n        doc.add(new TextField(\"p\", payloadTS2));\n      } else {\n        FieldType type = new FieldType(TextField.TYPE_NOT_STORED);\n        type.setStoreTermVectors(true);\n        type.setStoreTermVectorPositions(true);\n        type.setStoreTermVectorPayloads(true);\n        type.setStoreTermVectorOffsets(random.nextBoolean());\n        doc.add(new Field(\"p\", payloadTS1, type));\n        doc.add(new Field(\"p\", payloadTS2, type));\n      }\n      writer.addDocument(doc);\n      if (multipleCommits && (i % 4 == 0)) {\n        writer.commit();\n      }\n    }\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","date":1345029782,"type":4,"author":"Uwe Schindler","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPayloadProcessorProvider#populateDocs(Random,Directory,boolean).mjava","sourceNew":null,"sourceOld":"  private void populateDocs(Random random, Directory dir, boolean multipleCommits)\n      throws IOException {\n    IndexWriter writer = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    TokenStream payloadTS1 = new PayloadTokenStream(\"p1\");\n    TokenStream payloadTS2 = new PayloadTokenStream(\"p2\");\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"doc\" + i, customType));\n      doc.add(newTextField(\"content\", \"doc content \" + i, Field.Store.NO));\n      if (random.nextBoolean()) {\n        doc.add(new TextField(\"p\", payloadTS1));\n        doc.add(new TextField(\"p\", payloadTS2));\n      } else {\n        FieldType type = new FieldType(TextField.TYPE_NOT_STORED);\n        type.setStoreTermVectors(true);\n        type.setStoreTermVectorPositions(true);\n        type.setStoreTermVectorPayloads(true);\n        type.setStoreTermVectorOffsets(random.nextBoolean());\n        doc.add(new Field(\"p\", payloadTS1, type));\n        doc.add(new Field(\"p\", payloadTS2, type));\n      }\n      writer.addDocument(doc);\n      if (multipleCommits && (i % 4 == 0)) {\n        writer.commit();\n      }\n    }\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3c188105a9aae04f56c24996f98f8333fc825d2e","date":1345031914,"type":4,"author":"Michael McCandless","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPayloadProcessorProvider#populateDocs(Random,Directory,boolean).mjava","sourceNew":null,"sourceOld":"  private void populateDocs(Random random, Directory dir, boolean multipleCommits)\n      throws IOException {\n    IndexWriter writer = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    TokenStream payloadTS1 = new PayloadTokenStream(\"p1\");\n    TokenStream payloadTS2 = new PayloadTokenStream(\"p2\");\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"doc\" + i, customType));\n      doc.add(newTextField(\"content\", \"doc content \" + i, Field.Store.NO));\n      if (random.nextBoolean()) {\n        doc.add(new TextField(\"p\", payloadTS1));\n        doc.add(new TextField(\"p\", payloadTS2));\n      } else {\n        FieldType type = new FieldType(TextField.TYPE_NOT_STORED);\n        type.setStoreTermVectors(true);\n        type.setStoreTermVectorPositions(true);\n        type.setStoreTermVectorPayloads(true);\n        type.setStoreTermVectorOffsets(random.nextBoolean());\n        doc.add(new Field(\"p\", payloadTS1, type));\n        doc.add(new Field(\"p\", payloadTS2, type));\n      }\n      writer.addDocument(doc);\n      if (multipleCommits && (i % 4 == 0)) {\n        writer.commit();\n      }\n    }\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1c93396a1df03720cb20e2c2f513a6fa59b21e4c","date":1345032673,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPayloadProcessorProvider#populateDocs(Random,Directory,boolean).mjava","pathOld":"/dev/null","sourceNew":"  private void populateDocs(Random random, Directory dir, boolean multipleCommits)\n      throws IOException {\n    IndexWriter writer = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    TokenStream payloadTS1 = new PayloadTokenStream(\"p1\");\n    TokenStream payloadTS2 = new PayloadTokenStream(\"p2\");\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"doc\" + i, customType));\n      doc.add(newTextField(\"content\", \"doc content \" + i, Field.Store.NO));\n      if (random.nextBoolean()) {\n        doc.add(new TextField(\"p\", payloadTS1));\n        doc.add(new TextField(\"p\", payloadTS2));\n      } else {\n        FieldType type = new FieldType(TextField.TYPE_NOT_STORED);\n        type.setStoreTermVectors(true);\n        type.setStoreTermVectorPositions(true);\n        type.setStoreTermVectorPayloads(true);\n        type.setStoreTermVectorOffsets(random.nextBoolean());\n        doc.add(new Field(\"p\", payloadTS1, type));\n        doc.add(new Field(\"p\", payloadTS2, type));\n      }\n      writer.addDocument(doc);\n      if (multipleCommits && (i % 4 == 0)) {\n        writer.commit();\n      }\n    }\n    writer.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b05c56a41b733e02a189c48895922b5bd8c7f3d1","date":1345033322,"type":4,"author":"Michael McCandless","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPayloadProcessorProvider#populateDocs(Random,Directory,boolean).mjava","sourceNew":null,"sourceOld":"  private void populateDocs(Random random, Directory dir, boolean multipleCommits)\n      throws IOException {\n    IndexWriter writer = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    TokenStream payloadTS1 = new PayloadTokenStream(\"p1\");\n    TokenStream payloadTS2 = new PayloadTokenStream(\"p2\");\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"id\", \"doc\" + i, customType));\n      doc.add(newTextField(\"content\", \"doc content \" + i, Field.Store.NO));\n      if (random.nextBoolean()) {\n        doc.add(new TextField(\"p\", payloadTS1));\n        doc.add(new TextField(\"p\", payloadTS2));\n      } else {\n        FieldType type = new FieldType(TextField.TYPE_NOT_STORED);\n        type.setStoreTermVectors(true);\n        type.setStoreTermVectorPositions(true);\n        type.setStoreTermVectorPayloads(true);\n        type.setStoreTermVectorOffsets(random.nextBoolean());\n        doc.add(new Field(\"p\", payloadTS1, type));\n        doc.add(new Field(\"p\", payloadTS2, type));\n      }\n      writer.addDocument(doc);\n      if (multipleCommits && (i % 4 == 0)) {\n        writer.commit();\n      }\n    }\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"04f07771a2a7dd3a395700665ed839c3dae2def2":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"c7869f64c874ebf7f317d22c00baf2b6857797a6":["04f07771a2a7dd3a395700665ed839c3dae2def2","0935c850ea562932997b72c69d93e345f21d7f45"],"3c188105a9aae04f56c24996f98f8333fc825d2e":["c7869f64c874ebf7f317d22c00baf2b6857797a6"],"b05c56a41b733e02a189c48895922b5bd8c7f3d1":["1c93396a1df03720cb20e2c2f513a6fa59b21e4c","bc124b3b129ef11a255212f3af482b771c5b3a6c"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1c93396a1df03720cb20e2c2f513a6fa59b21e4c":["3c188105a9aae04f56c24996f98f8333fc825d2e"],"bc124b3b129ef11a255212f3af482b771c5b3a6c":["0935c850ea562932997b72c69d93e345f21d7f45"],"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198":["d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9","bc124b3b129ef11a255212f3af482b771c5b3a6c"],"0935c850ea562932997b72c69d93e345f21d7f45":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9":["04f07771a2a7dd3a395700665ed839c3dae2def2","0935c850ea562932997b72c69d93e345f21d7f45"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["bc124b3b129ef11a255212f3af482b771c5b3a6c"]},"commit2Childs":{"04f07771a2a7dd3a395700665ed839c3dae2def2":["c7869f64c874ebf7f317d22c00baf2b6857797a6","0935c850ea562932997b72c69d93e345f21d7f45","d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9"],"c7869f64c874ebf7f317d22c00baf2b6857797a6":["3c188105a9aae04f56c24996f98f8333fc825d2e"],"3c188105a9aae04f56c24996f98f8333fc825d2e":["1c93396a1df03720cb20e2c2f513a6fa59b21e4c"],"b05c56a41b733e02a189c48895922b5bd8c7f3d1":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"1c93396a1df03720cb20e2c2f513a6fa59b21e4c":["b05c56a41b733e02a189c48895922b5bd8c7f3d1"],"bc124b3b129ef11a255212f3af482b771c5b3a6c":["b05c56a41b733e02a189c48895922b5bd8c7f3d1","c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198":[],"0935c850ea562932997b72c69d93e345f21d7f45":["c7869f64c874ebf7f317d22c00baf2b6857797a6","bc124b3b129ef11a255212f3af482b771c5b3a6c","d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9"],"d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9":["c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b05c56a41b733e02a189c48895922b5bd8c7f3d1","c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}