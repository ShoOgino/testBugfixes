{"path":"lucene/src/test/org/apache/lucene/index/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","commits":[{"id":"905f6760f432211e868cf7d229c8797382853a7a","date":1318620791,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","pathOld":"/dev/null","sourceNew":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    CodecProvider cp = _TestUtil.alwaysCodec(new PulsingCodec(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodecProvider(cp));\n    Document doc = new Document();\n    doc.add(new Field(\"foo\", \"a b b c c c d e f g g h i i j j k\", TextField.TYPE_UNSTORED));\n    iw.addDocument(doc);\n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexReader segment = ir.getSequentialSubReaders()[0];\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator();\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator();\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7b91922b55d15444d554721b352861d028eb8278","date":1320421415,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","sourceNew":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing40PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new Field(\"foo\", \"a b b c c c d e f g g h i i j j k\", TextField.TYPE_UNSTORED));\n    iw.addDocument(doc);\n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexReader segment = ir.getSequentialSubReaders()[0];\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator();\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator();\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    CodecProvider cp = _TestUtil.alwaysCodec(new PulsingCodec(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodecProvider(cp));\n    Document doc = new Document();\n    doc.add(new Field(\"foo\", \"a b b c c c d e f g g h i i j j k\", TextField.TYPE_UNSTORED));\n    iw.addDocument(doc);\n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexReader segment = ir.getSequentialSubReaders()[0];\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator();\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator();\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3cc749c053615f5871f3b95715fe292f34e70a53","date":1321470575,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","sourceNew":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing40PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new Field(\"foo\", \"a b b c c c d e f g g h i i j j k\", TextField.TYPE_UNSTORED));\n    iw.addDocument(doc);\n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexReader segment = ir.getSequentialSubReaders()[0];\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing40PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new Field(\"foo\", \"a b b c c c d e f g g h i i j j k\", TextField.TYPE_UNSTORED));\n    iw.addDocument(doc);\n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexReader segment = ir.getSequentialSubReaders()[0];\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator();\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator();\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"872cff1d3a554e0cd64014cd97f88d3002b0f491","date":1323024658,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","sourceNew":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing40PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new Field(\"foo\", \"a b b c c c d e f g g h i i j j k\", TextField.TYPE_UNSTORED));\n    iw.addDocument(doc);\n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexReader segment = ir.getSequentialSubReaders()[0];\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, false);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing40PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new Field(\"foo\", \"a b b c c c d e f g g h i i j j k\", TextField.TYPE_UNSTORED));\n    iw.addDocument(doc);\n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexReader segment = ir.getSequentialSubReaders()[0];\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["02331260bb246364779cb6f04919ca47900d01bb"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b65b350ca9588f9fc76ce7d6804160d06c45ff42","date":1323026297,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","sourceNew":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing40PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new Field(\"foo\", \"a b b c c c d e f g g h i i j j k\", TextField.TYPE_UNSTORED));\n    iw.addDocument(doc);\n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexReader segment = ir.getSequentialSubReaders()[0];\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, false);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing40PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new Field(\"foo\", \"a b b c c c d e f g g h i i j j k\", TextField.TYPE_UNSTORED));\n    iw.addDocument(doc);\n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexReader segment = ir.getSequentialSubReaders()[0];\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0ae5e3ed1232483b7b8a014f175a5fe43595982","date":1324062192,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","sourceNew":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing40PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new Field(\"foo\", \"a b b c c c d e f g g h i i j j k\", TextField.TYPE_UNSTORED));\n    iw.addDocument(doc);\n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexReader segment = ir.getSequentialSubReaders()[0];\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, false);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing40PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new Field(\"foo\", \"a b b c c c d e f g g h i i j j k\", TextField.TYPE_UNSTORED));\n    iw.addDocument(doc);\n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexReader segment = ir.getSequentialSubReaders()[0];\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, false);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"7b91922b55d15444d554721b352861d028eb8278":["905f6760f432211e868cf7d229c8797382853a7a"],"b65b350ca9588f9fc76ce7d6804160d06c45ff42":["3cc749c053615f5871f3b95715fe292f34e70a53","872cff1d3a554e0cd64014cd97f88d3002b0f491"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cc749c053615f5871f3b95715fe292f34e70a53":["7b91922b55d15444d554721b352861d028eb8278"],"872cff1d3a554e0cd64014cd97f88d3002b0f491":["3cc749c053615f5871f3b95715fe292f34e70a53"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["872cff1d3a554e0cd64014cd97f88d3002b0f491"],"905f6760f432211e868cf7d229c8797382853a7a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"]},"commit2Childs":{"7b91922b55d15444d554721b352861d028eb8278":["3cc749c053615f5871f3b95715fe292f34e70a53"],"b65b350ca9588f9fc76ce7d6804160d06c45ff42":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["905f6760f432211e868cf7d229c8797382853a7a"],"3cc749c053615f5871f3b95715fe292f34e70a53":["b65b350ca9588f9fc76ce7d6804160d06c45ff42","872cff1d3a554e0cd64014cd97f88d3002b0f491"],"872cff1d3a554e0cd64014cd97f88d3002b0f491":["b65b350ca9588f9fc76ce7d6804160d06c45ff42","a0ae5e3ed1232483b7b8a014f175a5fe43595982"],"905f6760f432211e868cf7d229c8797382853a7a":["7b91922b55d15444d554721b352861d028eb8278"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b65b350ca9588f9fc76ce7d6804160d06c45ff42","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}