{"path":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#SegmentReader(SegmentInfoPerCommit,IOContext).mjava","commits":[{"id":"a45bec74b98f6fc05f52770cfb425739e6563960","date":1375119292,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#SegmentReader(SegmentInfoPerCommit,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#SegmentReader(SegmentInfoPerCommit,int,IOContext).mjava","sourceNew":"  /**\n   * Constructs a new SegmentReader with a new core.\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  // TODO: why is this public?\n  public SegmentReader(SegmentInfoPerCommit si, IOContext context) throws IOException {\n    this.si = si;\n    core = new SegmentCoreReaders(this, si.info.dir, si, context);\n    boolean success = false;\n    try {\n      if (si.hasDeletions()) {\n        // NOTE: the bitvector is stored using the regular directory, not cfs\n        liveDocs = si.info.getCodec().liveDocsFormat().readLiveDocs(directory(), si, new IOContext(IOContext.READ, true));\n      } else {\n        assert si.getDelCount() == 0;\n        liveDocs = null;\n      }\n      numDocs = si.info.getDocCount() - si.getDelCount();\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above.  In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        core.decRef();\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Constructs a new SegmentReader with a new core.\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  // TODO: why is this public?\n  public SegmentReader(SegmentInfoPerCommit si, int termInfosIndexDivisor, IOContext context) throws IOException {\n    this.si = si;\n    core = new SegmentCoreReaders(this, si.info.dir, si, context, termInfosIndexDivisor);\n    boolean success = false;\n    try {\n      if (si.hasDeletions()) {\n        // NOTE: the bitvector is stored using the regular directory, not cfs\n        liveDocs = si.info.getCodec().liveDocsFormat().readLiveDocs(directory(), si, new IOContext(IOContext.READ, true));\n      } else {\n        assert si.getDelCount() == 0;\n        liveDocs = null;\n      }\n      numDocs = si.info.getDocCount() - si.getDelCount();\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above.  In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        core.decRef();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":1,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#SegmentReader(SegmentInfoPerCommit,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#SegmentReader(SegmentInfoPerCommit,int,IOContext).mjava","sourceNew":"  /**\n   * Constructs a new SegmentReader with a new core.\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  // TODO: why is this public?\n  public SegmentReader(SegmentInfoPerCommit si, IOContext context) throws IOException {\n    this.si = si;\n    core = new SegmentCoreReaders(this, si.info.dir, si, context);\n    boolean success = false;\n    try {\n      if (si.hasDeletions()) {\n        // NOTE: the bitvector is stored using the regular directory, not cfs\n        liveDocs = si.info.getCodec().liveDocsFormat().readLiveDocs(directory(), si, new IOContext(IOContext.READ, true));\n      } else {\n        assert si.getDelCount() == 0;\n        liveDocs = null;\n      }\n      numDocs = si.info.getDocCount() - si.getDelCount();\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above.  In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        core.decRef();\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Constructs a new SegmentReader with a new core.\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  // TODO: why is this public?\n  public SegmentReader(SegmentInfoPerCommit si, int termInfosIndexDivisor, IOContext context) throws IOException {\n    this.si = si;\n    core = new SegmentCoreReaders(this, si.info.dir, si, context, termInfosIndexDivisor);\n    boolean success = false;\n    try {\n      if (si.hasDeletions()) {\n        // NOTE: the bitvector is stored using the regular directory, not cfs\n        liveDocs = si.info.getCodec().liveDocsFormat().readLiveDocs(directory(), si, new IOContext(IOContext.READ, true));\n      } else {\n        assert si.getDelCount() == 0;\n        liveDocs = null;\n      }\n      numDocs = si.info.getDocCount() - si.getDelCount();\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above.  In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        core.decRef();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"82ffd58510acfc0e2e788a90a10002e689ec9145","date":1379018753,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#SegmentReader(SegmentInfoPerCommit,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#SegmentReader(SegmentInfoPerCommit,IOContext).mjava","sourceNew":"  /**\n   * Constructs a new SegmentReader with a new core.\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  // TODO: why is this public?\n  public SegmentReader(SegmentInfoPerCommit si, IOContext context) throws IOException {\n    this.si = si;\n    core = new SegmentCoreReaders(this, si.info.dir, si, context);\n    boolean success = false;\n    try {\n      if (si.hasDeletions()) {\n        // NOTE: the bitvector is stored using the regular directory, not cfs\n        liveDocs = si.info.getCodec().liveDocsFormat().readLiveDocs(directory(), si, IOContext.READONCE);\n      } else {\n        assert si.getDelCount() == 0;\n        liveDocs = null;\n      }\n      numDocs = si.info.getDocCount() - si.getDelCount();\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above.  In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        core.decRef();\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Constructs a new SegmentReader with a new core.\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  // TODO: why is this public?\n  public SegmentReader(SegmentInfoPerCommit si, IOContext context) throws IOException {\n    this.si = si;\n    core = new SegmentCoreReaders(this, si.info.dir, si, context);\n    boolean success = false;\n    try {\n      if (si.hasDeletions()) {\n        // NOTE: the bitvector is stored using the regular directory, not cfs\n        liveDocs = si.info.getCodec().liveDocsFormat().readLiveDocs(directory(), si, new IOContext(IOContext.READ, true));\n      } else {\n        assert si.getDelCount() == 0;\n        liveDocs = null;\n      }\n      numDocs = si.info.getDocCount() - si.getDelCount();\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above.  In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        core.decRef();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e072d0b1fc19e0533d8ce432eed245196bca6fde","date":1379265112,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#SegmentReader(SegmentInfoPerCommit,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#SegmentReader(SegmentInfoPerCommit,IOContext).mjava","sourceNew":"  /**\n   * Constructs a new SegmentReader with a new core.\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  // TODO: why is this public?\n  public SegmentReader(SegmentInfoPerCommit si, IOContext context) throws IOException {\n    this.si = si;\n    core = new SegmentCoreReaders(this, si.info.dir, si, context);\n    \n    boolean success = false;\n    final Codec codec = si.info.getCodec();\n    try {\n      if (si.hasDeletions()) {\n        // NOTE: the bitvector is stored using the regular directory, not cfs\n        liveDocs = codec.liveDocsFormat().readLiveDocs(directory(), si, IOContext.READONCE);\n      } else {\n        assert si.getDelCount() == 0;\n        liveDocs = null;\n      }\n      numDocs = si.info.getDocCount() - si.getDelCount();\n      \n      if (core.fieldInfos.hasDocValues()) {\n        final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n        final DocValuesFormat dvFormat = codec.docValuesFormat();\n        // initialize the per generation numericDVProducers and put the correct\n        // DVProducer for each field\n        final Map<Long,List<FieldInfo>> genInfos = getGenInfos(si);\n\n        for (Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n          Long gen = e.getKey();\n          List<FieldInfo> infos = e.getValue();\n          RefCount<DocValuesProducer> dvp = genDVProducers.get(gen);\n          if (dvp == null) {\n            dvp = newDocValuesProducer(si, context, dir, dvFormat, gen, infos);\n            assert dvp != null;\n            genDVProducers.put(gen, dvp);\n          }\n          for (FieldInfo fi : infos) {\n            dvProducers.put(fi.name, dvp.get());\n          }\n        }\n      }\n\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above.  In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        doClose();\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Constructs a new SegmentReader with a new core.\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  // TODO: why is this public?\n  public SegmentReader(SegmentInfoPerCommit si, IOContext context) throws IOException {\n    this.si = si;\n    core = new SegmentCoreReaders(this, si.info.dir, si, context);\n    boolean success = false;\n    try {\n      if (si.hasDeletions()) {\n        // NOTE: the bitvector is stored using the regular directory, not cfs\n        liveDocs = si.info.getCodec().liveDocsFormat().readLiveDocs(directory(), si, IOContext.READONCE);\n      } else {\n        assert si.getDelCount() == 0;\n        liveDocs = null;\n      }\n      numDocs = si.info.getDocCount() - si.getDelCount();\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above.  In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        core.decRef();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["0567bdc5c86c94ced64201187cfcef2417d76dda"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"75e4e08ceec867127dcd9913a5ebbc46cf85a28d","date":1379651991,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#SegmentReader(SegmentInfoPerCommit,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#SegmentReader(SegmentInfoPerCommit,IOContext).mjava","sourceNew":"  /**\n   * Constructs a new SegmentReader with a new core.\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  // TODO: why is this public?\n  public SegmentReader(SegmentInfoPerCommit si, IOContext context) throws IOException {\n    this.si = si;\n    core = new SegmentCoreReaders(this, si.info.dir, si, context);\n\n    boolean success = false;\n    final Codec codec = si.info.getCodec();\n    try {\n      if (si.hasDeletions()) {\n        // NOTE: the bitvector is stored using the regular directory, not cfs\n        liveDocs = codec.liveDocsFormat().readLiveDocs(directory(), si, IOContext.READONCE);\n      } else {\n        assert si.getDelCount() == 0;\n        liveDocs = null;\n      }\n      numDocs = si.info.getDocCount() - si.getDelCount();\n      \n      if (core.fieldInfos.hasDocValues()) {\n        final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n        final DocValuesFormat dvFormat = codec.docValuesFormat();\n        // initialize the per generation numericDVProducers and put the correct\n        // DVProducer for each field\n        final Map<Long,List<FieldInfo>> genInfos = getGenInfos(si);\n        \n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.init: new reader: \" + si + \"; gens=\" + genInfos.keySet());\n\n        for (Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n          Long gen = e.getKey();\n          List<FieldInfo> infos = e.getValue();\n          RefCount<DocValuesProducer> dvp = genDVProducers.get(gen);\n          if (dvp == null) {\n            dvp = newDocValuesProducer(si, context, dir, dvFormat, gen, infos);\n            assert dvp != null;\n            genDVProducers.put(gen, dvp);\n          }\n          for (FieldInfo fi : infos) {\n            dvProducers.put(fi.name, dvp.get());\n          }\n        }\n      }\n\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above.  In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        doClose();\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Constructs a new SegmentReader with a new core.\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  // TODO: why is this public?\n  public SegmentReader(SegmentInfoPerCommit si, IOContext context) throws IOException {\n    this.si = si;\n    core = new SegmentCoreReaders(this, si.info.dir, si, context);\n    \n    boolean success = false;\n    final Codec codec = si.info.getCodec();\n    try {\n      if (si.hasDeletions()) {\n        // NOTE: the bitvector is stored using the regular directory, not cfs\n        liveDocs = codec.liveDocsFormat().readLiveDocs(directory(), si, IOContext.READONCE);\n      } else {\n        assert si.getDelCount() == 0;\n        liveDocs = null;\n      }\n      numDocs = si.info.getDocCount() - si.getDelCount();\n      \n      if (core.fieldInfos.hasDocValues()) {\n        final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n        final DocValuesFormat dvFormat = codec.docValuesFormat();\n        // initialize the per generation numericDVProducers and put the correct\n        // DVProducer for each field\n        final Map<Long,List<FieldInfo>> genInfos = getGenInfos(si);\n\n        for (Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n          Long gen = e.getKey();\n          List<FieldInfo> infos = e.getValue();\n          RefCount<DocValuesProducer> dvp = genDVProducers.get(gen);\n          if (dvp == null) {\n            dvp = newDocValuesProducer(si, context, dir, dvFormat, gen, infos);\n            assert dvp != null;\n            genDVProducers.put(gen, dvp);\n          }\n          for (FieldInfo fi : infos) {\n            dvProducers.put(fi.name, dvp.get());\n          }\n        }\n      }\n\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above.  In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        doClose();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8435160e9702b19398118ddf76b61c846612b6a4","date":1380349140,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#SegmentReader(SegmentInfoPerCommit,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#SegmentReader(SegmentInfoPerCommit,IOContext).mjava","sourceNew":"  /**\n   * Constructs a new SegmentReader with a new core.\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  // TODO: why is this public?\n  public SegmentReader(SegmentInfoPerCommit si, IOContext context) throws IOException {\n    this.si = si;\n    // TODO if the segment uses CFS, we may open the CFS file twice: once for\n    // reading the FieldInfos (if they are not gen'd) and second time by\n    // SegmentCoreReaders. We can open the CFS here and pass to SCR, but then it\n    // results in less readable code (resource not closed where it was opened).\n    // Best if we could somehow read FieldInfos in SCR but not keep it there, but\n    // constructors don't allow returning two things...\n    fieldInfos = readFieldInfos(si);\n    core = new SegmentCoreReaders(this, si.info.dir, si, context);\n\n    boolean success = false;\n    final Codec codec = si.info.getCodec();\n    try {\n      if (si.hasDeletions()) {\n        // NOTE: the bitvector is stored using the regular directory, not cfs\n        liveDocs = codec.liveDocsFormat().readLiveDocs(directory(), si, IOContext.READONCE);\n      } else {\n        assert si.getDelCount() == 0;\n        liveDocs = null;\n      }\n      numDocs = si.info.getDocCount() - si.getDelCount();\n      \n      if (fieldInfos.hasDocValues()) {\n        final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n        final DocValuesFormat dvFormat = codec.docValuesFormat();\n        // initialize the per generation numericDVProducers and put the correct\n        // DVProducer for each field\n        final Map<Long,List<FieldInfo>> genInfos = getGenInfos(si);\n        \n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.init: new reader: \" + si + \"; gens=\" + genInfos.keySet());\n\n        for (Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n          Long gen = e.getKey();\n          List<FieldInfo> infos = e.getValue();\n          RefCount<DocValuesProducer> dvp = genDVProducers.get(gen);\n          if (dvp == null) {\n            dvp = newDocValuesProducer(si, context, dir, dvFormat, gen, infos);\n            assert dvp != null;\n            genDVProducers.put(gen, dvp);\n          }\n          for (FieldInfo fi : infos) {\n            dvProducers.put(fi.name, dvp.get());\n          }\n        }\n      }\n\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above.  In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        doClose();\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Constructs a new SegmentReader with a new core.\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  // TODO: why is this public?\n  public SegmentReader(SegmentInfoPerCommit si, IOContext context) throws IOException {\n    this.si = si;\n    core = new SegmentCoreReaders(this, si.info.dir, si, context);\n\n    boolean success = false;\n    final Codec codec = si.info.getCodec();\n    try {\n      if (si.hasDeletions()) {\n        // NOTE: the bitvector is stored using the regular directory, not cfs\n        liveDocs = codec.liveDocsFormat().readLiveDocs(directory(), si, IOContext.READONCE);\n      } else {\n        assert si.getDelCount() == 0;\n        liveDocs = null;\n      }\n      numDocs = si.info.getDocCount() - si.getDelCount();\n      \n      if (core.fieldInfos.hasDocValues()) {\n        final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n        final DocValuesFormat dvFormat = codec.docValuesFormat();\n        // initialize the per generation numericDVProducers and put the correct\n        // DVProducer for each field\n        final Map<Long,List<FieldInfo>> genInfos = getGenInfos(si);\n        \n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.init: new reader: \" + si + \"; gens=\" + genInfos.keySet());\n\n        for (Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n          Long gen = e.getKey();\n          List<FieldInfo> infos = e.getValue();\n          RefCount<DocValuesProducer> dvp = genDVProducers.get(gen);\n          if (dvp == null) {\n            dvp = newDocValuesProducer(si, context, dir, dvFormat, gen, infos);\n            assert dvp != null;\n            genDVProducers.put(gen, dvp);\n          }\n          for (FieldInfo fi : infos) {\n            dvProducers.put(fi.name, dvp.get());\n          }\n        }\n      }\n\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above.  In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        doClose();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2f13fb377f9b5df46af44bf90a2e507a884f2c30","date":1380476222,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#SegmentReader(SegmentInfoPerCommit,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#SegmentReader(SegmentInfoPerCommit,IOContext).mjava","sourceNew":"  /**\n   * Constructs a new SegmentReader with a new core.\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  // TODO: why is this public?\n  public SegmentReader(SegmentInfoPerCommit si, IOContext context) throws IOException {\n    this.si = si;\n    // TODO if the segment uses CFS, we may open the CFS file twice: once for\n    // reading the FieldInfos (if they are not gen'd) and second time by\n    // SegmentCoreReaders. We can open the CFS here and pass to SCR, but then it\n    // results in less readable code (resource not closed where it was opened).\n    // Best if we could somehow read FieldInfos in SCR but not keep it there, but\n    // constructors don't allow returning two things...\n    fieldInfos = readFieldInfos(si);\n    core = new SegmentCoreReaders(this, si.info.dir, si, context);\n\n    boolean success = false;\n    final Codec codec = si.info.getCodec();\n    try {\n      if (si.hasDeletions()) {\n        // NOTE: the bitvector is stored using the regular directory, not cfs\n        liveDocs = codec.liveDocsFormat().readLiveDocs(directory(), si, IOContext.READONCE);\n      } else {\n        assert si.getDelCount() == 0;\n        liveDocs = null;\n      }\n      numDocs = si.info.getDocCount() - si.getDelCount();\n      \n      if (fieldInfos.hasDocValues()) {\n        final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n        final DocValuesFormat dvFormat = codec.docValuesFormat();\n        // initialize the per generation numericDVProducers and put the correct\n        // DVProducer for each field\n        final Map<Long,List<FieldInfo>> genInfos = getGenInfos();\n        \n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.init: new reader: \" + si + \"; gens=\" + genInfos.keySet());\n\n        for (Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n          Long gen = e.getKey();\n          List<FieldInfo> infos = e.getValue();\n          RefCount<DocValuesProducer> dvp = genDVProducers.get(gen);\n          if (dvp == null) {\n            dvp = newDocValuesProducer(si, context, dir, dvFormat, gen, infos);\n            assert dvp != null;\n            genDVProducers.put(gen, dvp);\n          }\n          for (FieldInfo fi : infos) {\n            dvProducers.put(fi.name, dvp.get());\n          }\n        }\n      }\n\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above.  In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        doClose();\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Constructs a new SegmentReader with a new core.\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  // TODO: why is this public?\n  public SegmentReader(SegmentInfoPerCommit si, IOContext context) throws IOException {\n    this.si = si;\n    // TODO if the segment uses CFS, we may open the CFS file twice: once for\n    // reading the FieldInfos (if they are not gen'd) and second time by\n    // SegmentCoreReaders. We can open the CFS here and pass to SCR, but then it\n    // results in less readable code (resource not closed where it was opened).\n    // Best if we could somehow read FieldInfos in SCR but not keep it there, but\n    // constructors don't allow returning two things...\n    fieldInfos = readFieldInfos(si);\n    core = new SegmentCoreReaders(this, si.info.dir, si, context);\n\n    boolean success = false;\n    final Codec codec = si.info.getCodec();\n    try {\n      if (si.hasDeletions()) {\n        // NOTE: the bitvector is stored using the regular directory, not cfs\n        liveDocs = codec.liveDocsFormat().readLiveDocs(directory(), si, IOContext.READONCE);\n      } else {\n        assert si.getDelCount() == 0;\n        liveDocs = null;\n      }\n      numDocs = si.info.getDocCount() - si.getDelCount();\n      \n      if (fieldInfos.hasDocValues()) {\n        final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n        final DocValuesFormat dvFormat = codec.docValuesFormat();\n        // initialize the per generation numericDVProducers and put the correct\n        // DVProducer for each field\n        final Map<Long,List<FieldInfo>> genInfos = getGenInfos(si);\n        \n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.init: new reader: \" + si + \"; gens=\" + genInfos.keySet());\n\n        for (Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n          Long gen = e.getKey();\n          List<FieldInfo> infos = e.getValue();\n          RefCount<DocValuesProducer> dvp = genDVProducers.get(gen);\n          if (dvp == null) {\n            dvp = newDocValuesProducer(si, context, dir, dvFormat, gen, infos);\n            assert dvp != null;\n            genDVProducers.put(gen, dvp);\n          }\n          for (FieldInfo fi : infos) {\n            dvProducers.put(fi.name, dvp.get());\n          }\n        }\n      }\n\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above.  In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        doClose();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ac14bdd59867c398bdb1a9cc50583bd3c93593e5","date":1382646404,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#SegmentReader(SegmentInfoPerCommit,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#SegmentReader(SegmentInfoPerCommit,IOContext).mjava","sourceNew":"  /**\n   * Constructs a new SegmentReader with a new core.\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  // TODO: why is this public?\n  public SegmentReader(SegmentInfoPerCommit si, IOContext context) throws IOException {\n    this.si = si;\n    // TODO if the segment uses CFS, we may open the CFS file twice: once for\n    // reading the FieldInfos (if they are not gen'd) and second time by\n    // SegmentCoreReaders. We can open the CFS here and pass to SCR, but then it\n    // results in less readable code (resource not closed where it was opened).\n    // Best if we could somehow read FieldInfos in SCR but not keep it there, but\n    // constructors don't allow returning two things...\n    fieldInfos = readFieldInfos(si);\n    core = new SegmentCoreReaders(this, si.info.dir, si, context);\n    segDocValues = new SegmentDocValues();\n    \n    boolean success = false;\n    final Codec codec = si.info.getCodec();\n    try {\n      if (si.hasDeletions()) {\n        // NOTE: the bitvector is stored using the regular directory, not cfs\n        liveDocs = codec.liveDocsFormat().readLiveDocs(directory(), si, IOContext.READONCE);\n      } else {\n        assert si.getDelCount() == 0;\n        liveDocs = null;\n      }\n      numDocs = si.info.getDocCount() - si.getDelCount();\n      \n      if (fieldInfos.hasDocValues()) {\n        initDocValuesProducers(codec);\n      }\n\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above.  In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        doClose();\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Constructs a new SegmentReader with a new core.\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  // TODO: why is this public?\n  public SegmentReader(SegmentInfoPerCommit si, IOContext context) throws IOException {\n    this.si = si;\n    // TODO if the segment uses CFS, we may open the CFS file twice: once for\n    // reading the FieldInfos (if they are not gen'd) and second time by\n    // SegmentCoreReaders. We can open the CFS here and pass to SCR, but then it\n    // results in less readable code (resource not closed where it was opened).\n    // Best if we could somehow read FieldInfos in SCR but not keep it there, but\n    // constructors don't allow returning two things...\n    fieldInfos = readFieldInfos(si);\n    core = new SegmentCoreReaders(this, si.info.dir, si, context);\n\n    boolean success = false;\n    final Codec codec = si.info.getCodec();\n    try {\n      if (si.hasDeletions()) {\n        // NOTE: the bitvector is stored using the regular directory, not cfs\n        liveDocs = codec.liveDocsFormat().readLiveDocs(directory(), si, IOContext.READONCE);\n      } else {\n        assert si.getDelCount() == 0;\n        liveDocs = null;\n      }\n      numDocs = si.info.getDocCount() - si.getDelCount();\n      \n      if (fieldInfos.hasDocValues()) {\n        final Directory dir = core.cfsReader != null ? core.cfsReader : si.info.dir;\n        final DocValuesFormat dvFormat = codec.docValuesFormat();\n        // initialize the per generation numericDVProducers and put the correct\n        // DVProducer for each field\n        final Map<Long,List<FieldInfo>> genInfos = getGenInfos();\n        \n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] SR.init: new reader: \" + si + \"; gens=\" + genInfos.keySet());\n\n        for (Entry<Long,List<FieldInfo>> e : genInfos.entrySet()) {\n          Long gen = e.getKey();\n          List<FieldInfo> infos = e.getValue();\n          RefCount<DocValuesProducer> dvp = genDVProducers.get(gen);\n          if (dvp == null) {\n            dvp = newDocValuesProducer(si, context, dir, dvFormat, gen, infos);\n            assert dvp != null;\n            genDVProducers.put(gen, dvp);\n          }\n          for (FieldInfo fi : infos) {\n            dvProducers.put(fi.name, dvp.get());\n          }\n        }\n      }\n\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above.  In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        doClose();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0","date":1383367127,"type":5,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#SegmentReader(SegmentCommitInfo,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentReader#SegmentReader(SegmentInfoPerCommit,IOContext).mjava","sourceNew":"  /**\n   * Constructs a new SegmentReader with a new core.\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  // TODO: why is this public?\n  public SegmentReader(SegmentCommitInfo si, IOContext context) throws IOException {\n    this.si = si;\n    // TODO if the segment uses CFS, we may open the CFS file twice: once for\n    // reading the FieldInfos (if they are not gen'd) and second time by\n    // SegmentCoreReaders. We can open the CFS here and pass to SCR, but then it\n    // results in less readable code (resource not closed where it was opened).\n    // Best if we could somehow read FieldInfos in SCR but not keep it there, but\n    // constructors don't allow returning two things...\n    fieldInfos = readFieldInfos(si);\n    core = new SegmentCoreReaders(this, si.info.dir, si, context);\n    segDocValues = new SegmentDocValues();\n    \n    boolean success = false;\n    final Codec codec = si.info.getCodec();\n    try {\n      if (si.hasDeletions()) {\n        // NOTE: the bitvector is stored using the regular directory, not cfs\n        liveDocs = codec.liveDocsFormat().readLiveDocs(directory(), si, IOContext.READONCE);\n      } else {\n        assert si.getDelCount() == 0;\n        liveDocs = null;\n      }\n      numDocs = si.info.getDocCount() - si.getDelCount();\n      \n      if (fieldInfos.hasDocValues()) {\n        initDocValuesProducers(codec);\n      }\n\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above.  In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        doClose();\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Constructs a new SegmentReader with a new core.\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  // TODO: why is this public?\n  public SegmentReader(SegmentInfoPerCommit si, IOContext context) throws IOException {\n    this.si = si;\n    // TODO if the segment uses CFS, we may open the CFS file twice: once for\n    // reading the FieldInfos (if they are not gen'd) and second time by\n    // SegmentCoreReaders. We can open the CFS here and pass to SCR, but then it\n    // results in less readable code (resource not closed where it was opened).\n    // Best if we could somehow read FieldInfos in SCR but not keep it there, but\n    // constructors don't allow returning two things...\n    fieldInfos = readFieldInfos(si);\n    core = new SegmentCoreReaders(this, si.info.dir, si, context);\n    segDocValues = new SegmentDocValues();\n    \n    boolean success = false;\n    final Codec codec = si.info.getCodec();\n    try {\n      if (si.hasDeletions()) {\n        // NOTE: the bitvector is stored using the regular directory, not cfs\n        liveDocs = codec.liveDocsFormat().readLiveDocs(directory(), si, IOContext.READONCE);\n      } else {\n        assert si.getDelCount() == 0;\n        liveDocs = null;\n      }\n      numDocs = si.info.getDocCount() - si.getDelCount();\n      \n      if (fieldInfos.hasDocValues()) {\n        initDocValuesProducers(codec);\n      }\n\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above.  In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        doClose();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"e072d0b1fc19e0533d8ce432eed245196bca6fde":["82ffd58510acfc0e2e788a90a10002e689ec9145"],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["ac14bdd59867c398bdb1a9cc50583bd3c93593e5"],"75e4e08ceec867127dcd9913a5ebbc46cf85a28d":["e072d0b1fc19e0533d8ce432eed245196bca6fde"],"82ffd58510acfc0e2e788a90a10002e689ec9145":["a45bec74b98f6fc05f52770cfb425739e6563960"],"a45bec74b98f6fc05f52770cfb425739e6563960":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8435160e9702b19398118ddf76b61c846612b6a4":["75e4e08ceec867127dcd9913a5ebbc46cf85a28d"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"2f13fb377f9b5df46af44bf90a2e507a884f2c30":["8435160e9702b19398118ddf76b61c846612b6a4"],"ac14bdd59867c398bdb1a9cc50583bd3c93593e5":["2f13fb377f9b5df46af44bf90a2e507a884f2c30"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"]},"commit2Childs":{"e072d0b1fc19e0533d8ce432eed245196bca6fde":["75e4e08ceec867127dcd9913a5ebbc46cf85a28d"],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"75e4e08ceec867127dcd9913a5ebbc46cf85a28d":["8435160e9702b19398118ddf76b61c846612b6a4"],"82ffd58510acfc0e2e788a90a10002e689ec9145":["e072d0b1fc19e0533d8ce432eed245196bca6fde"],"a45bec74b98f6fc05f52770cfb425739e6563960":["82ffd58510acfc0e2e788a90a10002e689ec9145"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a45bec74b98f6fc05f52770cfb425739e6563960","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee"],"8435160e9702b19398118ddf76b61c846612b6a4":["2f13fb377f9b5df46af44bf90a2e507a884f2c30"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"2f13fb377f9b5df46af44bf90a2e507a884f2c30":["ac14bdd59867c398bdb1a9cc50583bd3c93593e5"],"ac14bdd59867c398bdb1a9cc50583bd3c93593e5":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}