{"path":"lucene/src/test/org/apache/lucene/index/TestSizeBoundedForceMerge#testNumDocsLimit().mjava","commits":[{"id":"d14e8d18c0e3970c20354dbeeb49da11bd587fbd","date":1321041051,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestSizeBoundedForceMerge#testNumDocsLimit().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestSizeBoundedOptimize#testNumDocsLimit().mjava","sourceNew":"  public void testNumDocsLimit() throws Exception {\n    // tests that the max merge docs constraint is applied during forceMerge.\n    Directory dir = new RAMDirectory();\n\n    // Prepare an index w/ several small segments and a large one.\n    IndexWriterConfig conf = newWriterConfig();\n    IndexWriter writer = new IndexWriter(dir, conf);\n\n    addDocs(writer, 3);\n    addDocs(writer, 3);\n    addDocs(writer, 5);\n    addDocs(writer, 3);\n    addDocs(writer, 3);\n    addDocs(writer, 3);\n    addDocs(writer, 3);\n    \n    writer.close();\n\n    conf = newWriterConfig();\n    LogMergePolicy lmp = new LogDocMergePolicy();\n    lmp.setMaxMergeDocs(3);\n    conf.setMergePolicy(lmp);\n    \n    writer = new IndexWriter(dir, conf);\n    writer.forceMerge(1);\n    writer.close();\n\n    // Should only be 3 segments in the index, because one of them exceeds the size limit\n    SegmentInfos sis = new SegmentInfos();\n    sis.read(dir);\n    assertEquals(3, sis.size());\n  }\n\n","sourceOld":"  public void testNumDocsLimit() throws Exception {\n    // tests that the max merge docs constraint is applied during optimize.\n    Directory dir = new RAMDirectory();\n\n    // Prepare an index w/ several small segments and a large one.\n    IndexWriterConfig conf = newWriterConfig();\n    IndexWriter writer = new IndexWriter(dir, conf);\n\n    addDocs(writer, 3);\n    addDocs(writer, 3);\n    addDocs(writer, 5);\n    addDocs(writer, 3);\n    addDocs(writer, 3);\n    addDocs(writer, 3);\n    addDocs(writer, 3);\n    \n    writer.close();\n\n    conf = newWriterConfig();\n    LogMergePolicy lmp = new LogDocMergePolicy();\n    lmp.setMaxMergeDocs(3);\n    conf.setMergePolicy(lmp);\n    \n    writer = new IndexWriter(dir, conf);\n    writer.optimize();\n    writer.close();\n\n    // Should only be 3 segments in the index, because one of them exceeds the size limit\n    SegmentInfos sis = new SegmentInfos();\n    sis.read(dir);\n    assertEquals(3, sis.size());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestSizeBoundedForceMerge#testNumDocsLimit().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestSizeBoundedForceMerge#testNumDocsLimit().mjava","sourceNew":"  public void testNumDocsLimit() throws Exception {\n    // tests that the max merge docs constraint is applied during forceMerge.\n    Directory dir = new RAMDirectory();\n\n    // Prepare an index w/ several small segments and a large one.\n    IndexWriterConfig conf = newWriterConfig();\n    IndexWriter writer = new IndexWriter(dir, conf);\n\n    addDocs(writer, 3);\n    addDocs(writer, 3);\n    addDocs(writer, 5);\n    addDocs(writer, 3);\n    addDocs(writer, 3);\n    addDocs(writer, 3);\n    addDocs(writer, 3);\n    \n    writer.close();\n\n    conf = newWriterConfig();\n    LogMergePolicy lmp = new LogDocMergePolicy();\n    lmp.setMaxMergeDocs(3);\n    conf.setMergePolicy(lmp);\n    \n    writer = new IndexWriter(dir, conf);\n    writer.forceMerge(1);\n    writer.close();\n\n    // Should only be 3 segments in the index, because one of them exceeds the size limit\n    SegmentInfos sis = new SegmentInfos();\n    sis.read(dir);\n    assertEquals(3, sis.size());\n  }\n\n","sourceOld":"  public void testNumDocsLimit() throws Exception {\n    // tests that the max merge docs constraint is applied during forceMerge.\n    Directory dir = new RAMDirectory();\n\n    // Prepare an index w/ several small segments and a large one.\n    IndexWriterConfig conf = newWriterConfig();\n    IndexWriter writer = new IndexWriter(dir, conf);\n\n    addDocs(writer, 3);\n    addDocs(writer, 3);\n    addDocs(writer, 5);\n    addDocs(writer, 3);\n    addDocs(writer, 3);\n    addDocs(writer, 3);\n    addDocs(writer, 3);\n    \n    writer.close();\n\n    conf = newWriterConfig();\n    LogMergePolicy lmp = new LogDocMergePolicy();\n    lmp.setMaxMergeDocs(3);\n    conf.setMergePolicy(lmp);\n    \n    writer = new IndexWriter(dir, conf);\n    writer.forceMerge(1);\n    writer.close();\n\n    // Should only be 3 segments in the index, because one of them exceeds the size limit\n    SegmentInfos sis = new SegmentInfos();\n    sis.read(dir);\n    assertEquals(3, sis.size());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}