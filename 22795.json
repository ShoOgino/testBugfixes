{"path":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xNormsProducer#Lucene3xNormsProducer(Directory,SegmentInfo,FieldInfos,IOContext).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xNormsProducer#Lucene3xNormsProducer(Directory,SegmentInfo,FieldInfos,IOContext).mjava","pathOld":"lucene/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xNormsProducer#Lucene3xNormsProducer(Directory,SegmentInfo,FieldInfos,IOContext).mjava","sourceNew":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene3xNormsProducer(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context) throws IOException {\n    Directory separateNormsDir = info.dir; // separate norms are never inside CFS\n    maxdoc = info.docCount;\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.normsPresent()) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = NORMS_HEADER.length;\n            }\n          }\n          NormsDocValues norm = new NormsDocValues(normInput, normSeek);\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length() : singleNormStream != null ? \"len: \" + singleNormStream.length() + \" expected: \" + nextNormSeek : \"null\";\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(openFiles);\n      }\n    }\n  }\n\n","sourceOld":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene3xNormsProducer(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context) throws IOException {\n    Directory separateNormsDir = info.dir; // separate norms are never inside CFS\n    maxdoc = info.docCount;\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.normsPresent()) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = NORMS_HEADER.length;\n            }\n          }\n          NormsDocValues norm = new NormsDocValues(normInput, normSeek);\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length() : singleNormStream != null ? \"len: \" + singleNormStream.length() + \" expected: \" + nextNormSeek : \"null\";\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(openFiles);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"46818a810eab72123f0e37e6ec5f2d426bd47be1","date":1331482161,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xNormsProducer#Lucene3xNormsProducer(Directory,SegmentInfo,FieldInfos,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xNormsProducer#Lucene3xNormsProducer(Directory,SegmentInfo,FieldInfos,IOContext).mjava","sourceNew":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene3xNormsProducer(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context) throws IOException {\n    Directory separateNormsDir = info.dir; // separate norms are never inside CFS\n    maxdoc = info.docCount;\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.hasNorms()) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = NORMS_HEADER.length;\n            }\n          }\n          NormsDocValues norm = new NormsDocValues(normInput, normSeek);\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length() : singleNormStream != null ? \"len: \" + singleNormStream.length() + \" expected: \" + nextNormSeek : \"null\";\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(openFiles);\n      }\n    }\n  }\n\n","sourceOld":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene3xNormsProducer(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context) throws IOException {\n    Directory separateNormsDir = info.dir; // separate norms are never inside CFS\n    maxdoc = info.docCount;\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.normsPresent()) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = NORMS_HEADER.length;\n            }\n          }\n          NormsDocValues norm = new NormsDocValues(normInput, normSeek);\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length() : singleNormStream != null ? \"len: \" + singleNormStream.length() + \" expected: \" + nextNormSeek : \"null\";\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(openFiles);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"38e3b736c7ca086d61b7dbb841c905ee115490da","date":1331657018,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xNormsProducer#Lucene3xNormsProducer(Directory,SegmentInfo,FieldInfos,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xNormsProducer#Lucene3xNormsProducer(Directory,SegmentInfo,FieldInfos,IOContext).mjava","sourceNew":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene3xNormsProducer(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context) throws IOException {\n    Directory separateNormsDir = info.dir; // separate norms are never inside CFS\n    maxdoc = info.docCount;\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.hasNorms()) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = NORMS_HEADER.length;\n            }\n          }\n          NormsDocValues norm = new NormsDocValues(normInput, normSeek);\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length() : singleNormStream != null ? \"len: \" + singleNormStream.length() + \" expected: \" + nextNormSeek : \"null\";\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(openFiles);\n      }\n    }\n  }\n\n","sourceOld":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene3xNormsProducer(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context) throws IOException {\n    Directory separateNormsDir = info.dir; // separate norms are never inside CFS\n    maxdoc = info.docCount;\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.normsPresent()) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = NORMS_HEADER.length;\n            }\n          }\n          NormsDocValues norm = new NormsDocValues(normInput, normSeek);\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length() : singleNormStream != null ? \"len: \" + singleNormStream.length() + \" expected: \" + nextNormSeek : \"null\";\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(openFiles);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"203d7d3cb7712e10ef33009a63247ae40c302d7a","date":1337798111,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xNormsProducer#Lucene3xNormsProducer(Directory,SegmentInfo,FieldInfos,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xNormsProducer#Lucene3xNormsProducer(Directory,SegmentInfo,FieldInfos,IOContext).mjava","sourceNew":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene3xNormsProducer(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context) throws IOException {\n    Directory separateNormsDir = info.dir; // separate norms are never inside CFS\n    maxdoc = info.getDocCount();\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.hasNorms()) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = NORMS_HEADER.length;\n            }\n          }\n          NormsDocValues norm = new NormsDocValues(normInput, normSeek);\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length() : singleNormStream != null ? \"len: \" + singleNormStream.length() + \" expected: \" + nextNormSeek : \"null\";\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(openFiles);\n      }\n    }\n  }\n\n","sourceOld":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene3xNormsProducer(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context) throws IOException {\n    Directory separateNormsDir = info.dir; // separate norms are never inside CFS\n    maxdoc = info.docCount;\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.hasNorms()) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = NORMS_HEADER.length;\n            }\n          }\n          NormsDocValues norm = new NormsDocValues(normInput, normSeek);\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length() : singleNormStream != null ? \"len: \" + singleNormStream.length() + \" expected: \" + nextNormSeek : \"null\";\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(openFiles);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"764b942fd30efcae6e532c19771f32eeeb0037b2","date":1337868546,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xNormsProducer#Lucene3xNormsProducer(Directory,SegmentInfo,FieldInfos,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xNormsProducer#Lucene3xNormsProducer(Directory,SegmentInfo,FieldInfos,IOContext).mjava","sourceNew":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene3xNormsProducer(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context) throws IOException {\n    Directory separateNormsDir = info.dir; // separate norms are never inside CFS\n    maxdoc = info.getDocCount();\n    String segmentName = info.name;\n    boolean success = false;\n    try {\n      long nextNormSeek = NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.hasNorms()) {\n          String fileName = getNormFilename(info, fi.number);\n          Directory d = hasSeparateNorms(info, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = NORMS_HEADER.length;\n            }\n          }\n          NormsDocValues norm = new NormsDocValues(normInput, normSeek);\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length() : singleNormStream != null ? \"len: \" + singleNormStream.length() + \" expected: \" + nextNormSeek : \"null\";\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(openFiles);\n      }\n    }\n  }\n\n","sourceOld":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene3xNormsProducer(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context) throws IOException {\n    Directory separateNormsDir = info.dir; // separate norms are never inside CFS\n    maxdoc = info.getDocCount();\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.hasNorms()) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = NORMS_HEADER.length;\n            }\n          }\n          NormsDocValues norm = new NormsDocValues(normInput, normSeek);\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length() : singleNormStream != null ? \"len: \" + singleNormStream.length() + \" expected: \" + nextNormSeek : \"null\";\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(openFiles);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"615ddbd81799980d0fdd95e0238e1c498b6f47b0","date":1338233290,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xNormsProducer#Lucene3xNormsProducer(Directory,SegmentInfo,FieldInfos,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xNormsProducer#Lucene3xNormsProducer(Directory,SegmentInfo,FieldInfos,IOContext).mjava","sourceNew":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene3xNormsProducer(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context) throws IOException {\n    Directory separateNormsDir = info.dir; // separate norms are never inside CFS\n    maxdoc = info.getDocCount();\n    String segmentName = info.name;\n    boolean success = false;\n    try {\n      long nextNormSeek = NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.hasNorms()) {\n          String fileName = getNormFilename(info, fi.number);\n          Directory d = hasSeparateNorms(info, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = NORMS_HEADER.length;\n            }\n          }\n          NormsDocValues norm = new NormsDocValues(normInput, normSeek);\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length() : singleNormStream != null ? \"len: \" + singleNormStream.length() + \" expected: \" + nextNormSeek : \"null\";\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(openFiles);\n      }\n    }\n  }\n\n","sourceOld":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene3xNormsProducer(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context) throws IOException {\n    Directory separateNormsDir = info.dir; // separate norms are never inside CFS\n    maxdoc = info.docCount;\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.hasNorms()) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = NORMS_HEADER.length;\n            }\n          }\n          NormsDocValues norm = new NormsDocValues(normInput, normSeek);\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length() : singleNormStream != null ? \"len: \" + singleNormStream.length() + \" expected: \" + nextNormSeek : \"null\";\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(openFiles);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"57ae3024996ccdb3c36c42cb890e1efb37df4ce8","date":1338343651,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xNormsProducer#Lucene3xNormsProducer(Directory,SegmentInfo,FieldInfos,IOContext).mjava","sourceNew":null,"sourceOld":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene3xNormsProducer(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context) throws IOException {\n    Directory separateNormsDir = info.dir; // separate norms are never inside CFS\n    maxdoc = info.getDocCount();\n    String segmentName = info.name;\n    boolean success = false;\n    try {\n      long nextNormSeek = NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.hasNorms()) {\n          String fileName = getNormFilename(info, fi.number);\n          Directory d = hasSeparateNorms(info, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = NORMS_HEADER.length;\n            }\n          }\n          NormsDocValues norm = new NormsDocValues(normInput, normSeek);\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length() : singleNormStream != null ? \"len: \" + singleNormStream.length() + \" expected: \" + nextNormSeek : \"null\";\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(openFiles);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"38e3b736c7ca086d61b7dbb841c905ee115490da":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","46818a810eab72123f0e37e6ec5f2d426bd47be1"],"57ae3024996ccdb3c36c42cb890e1efb37df4ce8":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["46818a810eab72123f0e37e6ec5f2d426bd47be1","764b942fd30efcae6e532c19771f32eeeb0037b2"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"764b942fd30efcae6e532c19771f32eeeb0037b2":["203d7d3cb7712e10ef33009a63247ae40c302d7a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"46818a810eab72123f0e37e6ec5f2d426bd47be1":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"203d7d3cb7712e10ef33009a63247ae40c302d7a":["46818a810eab72123f0e37e6ec5f2d426bd47be1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["57ae3024996ccdb3c36c42cb890e1efb37df4ce8"]},"commit2Childs":{"38e3b736c7ca086d61b7dbb841c905ee115490da":[],"57ae3024996ccdb3c36c42cb890e1efb37df4ce8":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["57ae3024996ccdb3c36c42cb890e1efb37df4ce8"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["38e3b736c7ca086d61b7dbb841c905ee115490da","46818a810eab72123f0e37e6ec5f2d426bd47be1"],"764b942fd30efcae6e532c19771f32eeeb0037b2":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"46818a810eab72123f0e37e6ec5f2d426bd47be1":["38e3b736c7ca086d61b7dbb841c905ee115490da","615ddbd81799980d0fdd95e0238e1c498b6f47b0","203d7d3cb7712e10ef33009a63247ae40c302d7a"],"203d7d3cb7712e10ef33009a63247ae40c302d7a":["764b942fd30efcae6e532c19771f32eeeb0037b2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["38e3b736c7ca086d61b7dbb841c905ee115490da","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}