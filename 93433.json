{"path":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50NormsProducer#loadNorms(NormsEntry).mjava","commits":[{"id":"bc8f80fee115148a0e4a0574560be06b494de821","date":1412069872,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50NormsProducer#loadNorms(NormsEntry).mjava","pathOld":"/dev/null","sourceNew":"  private LoadedNorms loadNorms(NormsEntry entry) throws IOException {\n    LoadedNorms instance = new LoadedNorms();\n    switch(entry.format) {\n      case CONST_COMPRESSED: {\n        final long v = entry.offset;\n        instance.info = Accountables.namedAccountable(\"constant\", 8);\n        instance.ramBytesUsed = 8;\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            return v;\n          }\n        };\n        break;\n      }\n      case UNCOMPRESSED: {\n        data.seek(entry.offset);\n        final byte bytes[] = new byte[entry.count];\n        data.readBytes(bytes, 0, bytes.length);\n        instance.info = Accountables.namedAccountable(\"byte array\", bytes.length);\n        instance.ramBytesUsed = RamUsageEstimator.sizeOf(bytes);\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            return bytes[docID];\n          }\n        };\n        break;\n      }\n      case DELTA_COMPRESSED: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        final BlockPackedReader reader = new BlockPackedReader(data, packedIntsVersion, blockSize, entry.count, false);\n        instance.info = Accountables.namedAccountable(\"delta compressed\", reader);\n        instance.ramBytesUsed = reader.ramBytesUsed();\n        instance.norms = reader;\n        break;\n      }\n      case TABLE_COMPRESSED: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        int size = data.readVInt();\n        if (size > 256) {\n          throw new CorruptIndexException(\"TABLE_COMPRESSED cannot have more than 256 distinct values, got=\" + size, data);\n        }\n        final long decode[] = new long[size];\n        for (int i = 0; i < decode.length; i++) {\n          decode[i] = data.readLong();\n        }\n        final int formatID = data.readVInt();\n        final int bitsPerValue = data.readVInt();\n        final PackedInts.Reader ordsReader = PackedInts.getReaderNoHeader(data, PackedInts.Format.byId(formatID), packedIntsVersion, entry.count, bitsPerValue);\n        instance.info = Accountables.namedAccountable(\"table compressed\", ordsReader);\n        instance.ramBytesUsed = RamUsageEstimator.sizeOf(decode) + ordsReader.ramBytesUsed();\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            return decode[(int)ordsReader.get(docID)];\n          }\n        };\n        break;\n      }\n      case INDIRECT: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        final MonotonicBlockPackedReader live = MonotonicBlockPackedReader.of(data, packedIntsVersion, blockSize, entry.count, false);\n        LoadedNorms nestedInstance = loadNorms(entry.nested);\n        instance.ramBytesUsed = live.ramBytesUsed() + nestedInstance.ramBytesUsed;\n        instance.info = Accountables.namedAccountable(\"indirect -> \" + nestedInstance.info, instance.ramBytesUsed);\n        final NumericDocValues values = nestedInstance.norms;\n        final int upperBound = entry.count-1;\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            int low = 0;\n            int high = upperBound;\n            while (low <= high) {\n              int mid = (low + high) >>> 1;\n              long doc = live.get(mid);\n              \n              if (doc < docID) {\n                low = mid + 1;\n              } else if (doc > docID) {\n                high = mid - 1;\n              } else {\n                return values.get(mid);\n              }\n            }\n            return 0;\n          }\n        };\n        break;\n      }\n      default:\n        throw new AssertionError();\n    }\n    return instance;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9bb9a29a5e71a90295f175df8919802993142c9a","date":1412517673,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50NormsProducer#loadNorms(NormsEntry).mjava","pathOld":"/dev/null","sourceNew":"  private LoadedNorms loadNorms(NormsEntry entry) throws IOException {\n    LoadedNorms instance = new LoadedNorms();\n    switch(entry.format) {\n      case CONST_COMPRESSED: {\n        final long v = entry.offset;\n        instance.info = Accountables.namedAccountable(\"constant\", 8);\n        instance.ramBytesUsed = 8;\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            return v;\n          }\n        };\n        break;\n      }\n      case UNCOMPRESSED: {\n        data.seek(entry.offset);\n        final byte bytes[] = new byte[entry.count];\n        data.readBytes(bytes, 0, bytes.length);\n        instance.info = Accountables.namedAccountable(\"byte array\", bytes.length);\n        instance.ramBytesUsed = RamUsageEstimator.sizeOf(bytes);\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            return bytes[docID];\n          }\n        };\n        break;\n      }\n      case DELTA_COMPRESSED: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        final BlockPackedReader reader = new BlockPackedReader(data, packedIntsVersion, blockSize, entry.count, false);\n        instance.info = Accountables.namedAccountable(\"delta compressed\", reader);\n        instance.ramBytesUsed = reader.ramBytesUsed();\n        instance.norms = reader;\n        break;\n      }\n      case TABLE_COMPRESSED: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        int size = data.readVInt();\n        if (size > 256) {\n          throw new CorruptIndexException(\"TABLE_COMPRESSED cannot have more than 256 distinct values, got=\" + size, data);\n        }\n        final long decode[] = new long[size];\n        for (int i = 0; i < decode.length; i++) {\n          decode[i] = data.readLong();\n        }\n        final int formatID = data.readVInt();\n        final int bitsPerValue = data.readVInt();\n        final PackedInts.Reader ordsReader = PackedInts.getReaderNoHeader(data, PackedInts.Format.byId(formatID), packedIntsVersion, entry.count, bitsPerValue);\n        instance.info = Accountables.namedAccountable(\"table compressed\", ordsReader);\n        instance.ramBytesUsed = RamUsageEstimator.sizeOf(decode) + ordsReader.ramBytesUsed();\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            return decode[(int)ordsReader.get(docID)];\n          }\n        };\n        break;\n      }\n      case INDIRECT: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        final MonotonicBlockPackedReader live = MonotonicBlockPackedReader.of(data, packedIntsVersion, blockSize, entry.count, false);\n        LoadedNorms nestedInstance = loadNorms(entry.nested);\n        instance.ramBytesUsed = live.ramBytesUsed() + nestedInstance.ramBytesUsed;\n        instance.info = Accountables.namedAccountable(\"indirect -> \" + nestedInstance.info, instance.ramBytesUsed);\n        final NumericDocValues values = nestedInstance.norms;\n        final int upperBound = entry.count-1;\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            int low = 0;\n            int high = upperBound;\n            while (low <= high) {\n              int mid = (low + high) >>> 1;\n              long doc = live.get(mid);\n              \n              if (doc < docID) {\n                low = mid + 1;\n              } else if (doc > docID) {\n                high = mid - 1;\n              } else {\n                return values.get(mid);\n              }\n            }\n            return 0;\n          }\n        };\n        break;\n      }\n      default:\n        throw new AssertionError();\n    }\n    return instance;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e15c57be968dbcac6fd3f87af0bd26a8f023e069","date":1413564565,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50NormsProducer#loadNorms(NormsEntry).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50NormsProducer#loadNorms(NormsEntry).mjava","sourceNew":"  private LoadedNorms loadNorms(NormsEntry entry) throws IOException {\n    LoadedNorms instance = new LoadedNorms();\n    switch(entry.format) {\n      case CONST_COMPRESSED: {\n        final long v = entry.offset;\n        instance.info = Accountables.namedAccountable(\"constant\", 8);\n        instance.ramBytesUsed = 8;\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            return v;\n          }\n        };\n        break;\n      }\n      case UNCOMPRESSED: {\n        data.seek(entry.offset);\n        final byte bytes[] = new byte[entry.count];\n        data.readBytes(bytes, 0, bytes.length);\n        instance.info = Accountables.namedAccountable(\"byte array\", bytes.length);\n        instance.ramBytesUsed = RamUsageEstimator.sizeOf(bytes);\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            return bytes[docID];\n          }\n        };\n        break;\n      }\n      case DELTA_COMPRESSED: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        final BlockPackedReader reader = new BlockPackedReader(data, packedIntsVersion, blockSize, entry.count, false);\n        instance.info = Accountables.namedAccountable(\"delta compressed\", reader);\n        instance.ramBytesUsed = reader.ramBytesUsed();\n        instance.norms = reader;\n        break;\n      }\n      case TABLE_COMPRESSED: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        int size = data.readVInt();\n        if (size > 256) {\n          throw new CorruptIndexException(\"TABLE_COMPRESSED cannot have more than 256 distinct values, got=\" + size, data);\n        }\n        final long decode[] = new long[size];\n        for (int i = 0; i < decode.length; i++) {\n          decode[i] = data.readLong();\n        }\n        final int formatID = data.readVInt();\n        final int bitsPerValue = data.readVInt();\n        final PackedInts.Reader ordsReader = PackedInts.getReaderNoHeader(data, PackedInts.Format.byId(formatID), packedIntsVersion, entry.count, bitsPerValue);\n        instance.info = Accountables.namedAccountable(\"table compressed\", ordsReader);\n        instance.ramBytesUsed = RamUsageEstimator.sizeOf(decode) + ordsReader.ramBytesUsed();\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            return decode[(int)ordsReader.get(docID)];\n          }\n        };\n        break;\n      }\n      case INDIRECT: {\n        data.seek(entry.offset);\n        final long common = data.readLong();\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        final MonotonicBlockPackedReader live = MonotonicBlockPackedReader.of(data, packedIntsVersion, blockSize, entry.count, false);\n        LoadedNorms nestedInstance = loadNorms(entry.nested);\n        instance.ramBytesUsed = live.ramBytesUsed() + nestedInstance.ramBytesUsed;\n        instance.info = Accountables.namedAccountable(\"indirect -> \" + nestedInstance.info, instance.ramBytesUsed);\n        final NumericDocValues values = nestedInstance.norms;\n        final int upperBound = entry.count-1;\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            int low = 0;\n            int high = upperBound;\n            while (low <= high) {\n              int mid = (low + high) >>> 1;\n              long doc = live.get(mid);\n              \n              if (doc < docID) {\n                low = mid + 1;\n              } else if (doc > docID) {\n                high = mid - 1;\n              } else {\n                return values.get(mid);\n              }\n            }\n            return common;\n          }\n        };\n        break;\n      }\n      case PATCHED: {\n        data.seek(entry.offset);\n        final long common = data.readLong();\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        MonotonicBlockPackedReader live = MonotonicBlockPackedReader.of(data, packedIntsVersion, blockSize, entry.count, true);\n        final SparseFixedBitSet set = new SparseFixedBitSet(maxDoc);\n        for (int i = 0; i < live.size(); i++) {\n          int doc = (int) live.get(i);\n          set.set(doc);\n        }\n        LoadedNorms nestedInstance = loadNorms(entry.nested);\n        instance.ramBytesUsed = set.ramBytesUsed() + nestedInstance.ramBytesUsed;\n        instance.info = Accountables.namedAccountable(\"patched -> \" + nestedInstance.info, instance.ramBytesUsed);\n        final NumericDocValues values = nestedInstance.norms;\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            if (set.get(docID)) {\n              return values.get(docID);\n            } else {\n              return common;\n            }\n          }\n        };\n        break;\n      }\n      default:\n        throw new AssertionError();\n    }\n    return instance;\n  }\n\n","sourceOld":"  private LoadedNorms loadNorms(NormsEntry entry) throws IOException {\n    LoadedNorms instance = new LoadedNorms();\n    switch(entry.format) {\n      case CONST_COMPRESSED: {\n        final long v = entry.offset;\n        instance.info = Accountables.namedAccountable(\"constant\", 8);\n        instance.ramBytesUsed = 8;\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            return v;\n          }\n        };\n        break;\n      }\n      case UNCOMPRESSED: {\n        data.seek(entry.offset);\n        final byte bytes[] = new byte[entry.count];\n        data.readBytes(bytes, 0, bytes.length);\n        instance.info = Accountables.namedAccountable(\"byte array\", bytes.length);\n        instance.ramBytesUsed = RamUsageEstimator.sizeOf(bytes);\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            return bytes[docID];\n          }\n        };\n        break;\n      }\n      case DELTA_COMPRESSED: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        final BlockPackedReader reader = new BlockPackedReader(data, packedIntsVersion, blockSize, entry.count, false);\n        instance.info = Accountables.namedAccountable(\"delta compressed\", reader);\n        instance.ramBytesUsed = reader.ramBytesUsed();\n        instance.norms = reader;\n        break;\n      }\n      case TABLE_COMPRESSED: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        int size = data.readVInt();\n        if (size > 256) {\n          throw new CorruptIndexException(\"TABLE_COMPRESSED cannot have more than 256 distinct values, got=\" + size, data);\n        }\n        final long decode[] = new long[size];\n        for (int i = 0; i < decode.length; i++) {\n          decode[i] = data.readLong();\n        }\n        final int formatID = data.readVInt();\n        final int bitsPerValue = data.readVInt();\n        final PackedInts.Reader ordsReader = PackedInts.getReaderNoHeader(data, PackedInts.Format.byId(formatID), packedIntsVersion, entry.count, bitsPerValue);\n        instance.info = Accountables.namedAccountable(\"table compressed\", ordsReader);\n        instance.ramBytesUsed = RamUsageEstimator.sizeOf(decode) + ordsReader.ramBytesUsed();\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            return decode[(int)ordsReader.get(docID)];\n          }\n        };\n        break;\n      }\n      case INDIRECT: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        final MonotonicBlockPackedReader live = MonotonicBlockPackedReader.of(data, packedIntsVersion, blockSize, entry.count, false);\n        LoadedNorms nestedInstance = loadNorms(entry.nested);\n        instance.ramBytesUsed = live.ramBytesUsed() + nestedInstance.ramBytesUsed;\n        instance.info = Accountables.namedAccountable(\"indirect -> \" + nestedInstance.info, instance.ramBytesUsed);\n        final NumericDocValues values = nestedInstance.norms;\n        final int upperBound = entry.count-1;\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            int low = 0;\n            int high = upperBound;\n            while (low <= high) {\n              int mid = (low + high) >>> 1;\n              long doc = live.get(mid);\n              \n              if (doc < docID) {\n                low = mid + 1;\n              } else if (doc > docID) {\n                high = mid - 1;\n              } else {\n                return values.get(mid);\n              }\n            }\n            return 0;\n          }\n        };\n        break;\n      }\n      default:\n        throw new AssertionError();\n    }\n    return instance;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db68c63cbfaa8698b9c4475f75ed2b9c9696d238","date":1414118621,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50NormsProducer#loadNorms(NormsEntry).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50NormsProducer#loadNorms(NormsEntry).mjava","sourceNew":"  private LoadedNorms loadNorms(NormsEntry entry) throws IOException {\n    LoadedNorms instance = new LoadedNorms();\n    switch(entry.format) {\n      case CONST_COMPRESSED: {\n        final long v = entry.offset;\n        instance.info = Accountables.namedAccountable(\"constant\", 8);\n        instance.ramBytesUsed = 8;\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            return v;\n          }\n        };\n        break;\n      }\n      case UNCOMPRESSED: {\n        data.seek(entry.offset);\n        final byte bytes[] = new byte[entry.count];\n        data.readBytes(bytes, 0, bytes.length);\n        instance.info = Accountables.namedAccountable(\"byte array\", bytes.length);\n        instance.ramBytesUsed = RamUsageEstimator.sizeOf(bytes);\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            return bytes[docID];\n          }\n        };\n        break;\n      }\n      case DELTA_COMPRESSED: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        final BlockPackedReader reader = new BlockPackedReader(data, packedIntsVersion, blockSize, entry.count, false);\n        instance.info = Accountables.namedAccountable(\"delta compressed\", reader);\n        instance.ramBytesUsed = reader.ramBytesUsed();\n        instance.norms = reader;\n        break;\n      }\n      case TABLE_COMPRESSED: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        int size = data.readVInt();\n        if (size > 256) {\n          throw new CorruptIndexException(\"TABLE_COMPRESSED cannot have more than 256 distinct values, got=\" + size, data);\n        }\n        final long decode[] = new long[size];\n        for (int i = 0; i < decode.length; i++) {\n          decode[i] = data.readLong();\n        }\n        final int formatID = data.readVInt();\n        final int bitsPerValue = data.readVInt();\n        final PackedInts.Reader ordsReader = PackedInts.getReaderNoHeader(data, PackedInts.Format.byId(formatID), packedIntsVersion, entry.count, bitsPerValue);\n        instance.info = Accountables.namedAccountable(\"table compressed\", ordsReader);\n        instance.ramBytesUsed = RamUsageEstimator.sizeOf(decode) + ordsReader.ramBytesUsed();\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            return decode[(int)ordsReader.get(docID)];\n          }\n        };\n        break;\n      }\n      case INDIRECT: {\n        data.seek(entry.offset);\n        final long common = data.readLong();\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        final MonotonicBlockPackedReader live = MonotonicBlockPackedReader.of(data, packedIntsVersion, blockSize, entry.count, false);\n        LoadedNorms nestedInstance = loadNorms(entry.nested);\n        instance.ramBytesUsed = live.ramBytesUsed() + nestedInstance.ramBytesUsed;\n        instance.info = Accountables.namedAccountable(\"indirect -> \" + nestedInstance.info, instance.ramBytesUsed);\n        final NumericDocValues values = nestedInstance.norms;\n        final int upperBound = entry.count-1;\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            int low = 0;\n            int high = upperBound;\n            while (low <= high) {\n              int mid = (low + high) >>> 1;\n              long doc = live.get(mid);\n              \n              if (doc < docID) {\n                low = mid + 1;\n              } else if (doc > docID) {\n                high = mid - 1;\n              } else {\n                return values.get(mid);\n              }\n            }\n            return common;\n          }\n        };\n        break;\n      }\n      case PATCHED: {\n        data.seek(entry.offset);\n        final long common = data.readLong();\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        MonotonicBlockPackedReader live = MonotonicBlockPackedReader.of(data, packedIntsVersion, blockSize, entry.count, true);\n        final SparseFixedBitSet set = new SparseFixedBitSet(maxDoc);\n        for (int i = 0; i < live.size(); i++) {\n          int doc = (int) live.get(i);\n          set.set(doc);\n        }\n        LoadedNorms nestedInstance = loadNorms(entry.nested);\n        instance.ramBytesUsed = set.ramBytesUsed() + nestedInstance.ramBytesUsed;\n        instance.info = Accountables.namedAccountable(\"patched -> \" + nestedInstance.info, instance.ramBytesUsed);\n        final NumericDocValues values = nestedInstance.norms;\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            if (set.get(docID)) {\n              return values.get(docID);\n            } else {\n              return common;\n            }\n          }\n        };\n        break;\n      }\n      default:\n        throw new AssertionError();\n    }\n    return instance;\n  }\n\n","sourceOld":"  private LoadedNorms loadNorms(NormsEntry entry) throws IOException {\n    LoadedNorms instance = new LoadedNorms();\n    switch(entry.format) {\n      case CONST_COMPRESSED: {\n        final long v = entry.offset;\n        instance.info = Accountables.namedAccountable(\"constant\", 8);\n        instance.ramBytesUsed = 8;\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            return v;\n          }\n        };\n        break;\n      }\n      case UNCOMPRESSED: {\n        data.seek(entry.offset);\n        final byte bytes[] = new byte[entry.count];\n        data.readBytes(bytes, 0, bytes.length);\n        instance.info = Accountables.namedAccountable(\"byte array\", bytes.length);\n        instance.ramBytesUsed = RamUsageEstimator.sizeOf(bytes);\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            return bytes[docID];\n          }\n        };\n        break;\n      }\n      case DELTA_COMPRESSED: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        final BlockPackedReader reader = new BlockPackedReader(data, packedIntsVersion, blockSize, entry.count, false);\n        instance.info = Accountables.namedAccountable(\"delta compressed\", reader);\n        instance.ramBytesUsed = reader.ramBytesUsed();\n        instance.norms = reader;\n        break;\n      }\n      case TABLE_COMPRESSED: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        int size = data.readVInt();\n        if (size > 256) {\n          throw new CorruptIndexException(\"TABLE_COMPRESSED cannot have more than 256 distinct values, got=\" + size, data);\n        }\n        final long decode[] = new long[size];\n        for (int i = 0; i < decode.length; i++) {\n          decode[i] = data.readLong();\n        }\n        final int formatID = data.readVInt();\n        final int bitsPerValue = data.readVInt();\n        final PackedInts.Reader ordsReader = PackedInts.getReaderNoHeader(data, PackedInts.Format.byId(formatID), packedIntsVersion, entry.count, bitsPerValue);\n        instance.info = Accountables.namedAccountable(\"table compressed\", ordsReader);\n        instance.ramBytesUsed = RamUsageEstimator.sizeOf(decode) + ordsReader.ramBytesUsed();\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            return decode[(int)ordsReader.get(docID)];\n          }\n        };\n        break;\n      }\n      case INDIRECT: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        final MonotonicBlockPackedReader live = MonotonicBlockPackedReader.of(data, packedIntsVersion, blockSize, entry.count, false);\n        LoadedNorms nestedInstance = loadNorms(entry.nested);\n        instance.ramBytesUsed = live.ramBytesUsed() + nestedInstance.ramBytesUsed;\n        instance.info = Accountables.namedAccountable(\"indirect -> \" + nestedInstance.info, instance.ramBytesUsed);\n        final NumericDocValues values = nestedInstance.norms;\n        final int upperBound = entry.count-1;\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            int low = 0;\n            int high = upperBound;\n            while (low <= high) {\n              int mid = (low + high) >>> 1;\n              long doc = live.get(mid);\n              \n              if (doc < docID) {\n                low = mid + 1;\n              } else if (doc > docID) {\n                high = mid - 1;\n              } else {\n                return values.get(mid);\n              }\n            }\n            return 0;\n          }\n        };\n        break;\n      }\n      default:\n        throw new AssertionError();\n    }\n    return instance;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0c3fae32338d82a0710e1756793faba13dcb598b","date":1414786590,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50NormsProducer#loadNorms(NormsEntry).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50NormsProducer#loadNorms(NormsEntry).mjava","sourceNew":"  private LoadedNorms loadNorms(NormsEntry entry) throws IOException {\n    LoadedNorms instance = new LoadedNorms();\n    switch(entry.format) {\n      case CONST_COMPRESSED: {\n        final long v = entry.offset;\n        instance.info = Accountables.namedAccountable(\"constant\", 8);\n        instance.ramBytesUsed = 8;\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            return v;\n          }\n        };\n        break;\n      }\n      case UNCOMPRESSED: {\n        data.seek(entry.offset);\n        final byte bytes[] = new byte[entry.count];\n        data.readBytes(bytes, 0, bytes.length);\n        instance.info = Accountables.namedAccountable(\"byte array\", bytes.length);\n        instance.ramBytesUsed = RamUsageEstimator.sizeOf(bytes);\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            return bytes[docID];\n          }\n        };\n        break;\n      }\n      case DELTA_COMPRESSED: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        final BlockPackedReader reader = new BlockPackedReader(data, packedIntsVersion, blockSize, entry.count, false);\n        instance.info = Accountables.namedAccountable(\"delta compressed\", reader);\n        instance.ramBytesUsed = reader.ramBytesUsed();\n        instance.norms = reader;\n        break;\n      }\n      case TABLE_COMPRESSED: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        final int formatID = data.readVInt();\n        final int bitsPerValue = data.readVInt();\n        \n        if (bitsPerValue != 1 && bitsPerValue != 2 && bitsPerValue != 4) {\n          throw new CorruptIndexException(\"TABLE_COMPRESSED only supports bpv=1, bpv=2 and bpv=4, got=\" + bitsPerValue, data);\n        }\n        int size = 1 << bitsPerValue;\n        final byte decode[] = new byte[size];\n        final int ordsSize = data.readVInt();\n        for (int i = 0; i < ordsSize; ++i) {\n          decode[i] = data.readByte();\n        }\n        for (int i = ordsSize; i < size; ++i) {\n          decode[i] = 0;\n        }\n\n        final PackedInts.Reader ordsReader = PackedInts.getReaderNoHeader(data, PackedInts.Format.byId(formatID), packedIntsVersion, entry.count, bitsPerValue);\n        instance.info = Accountables.namedAccountable(\"table compressed\", ordsReader);\n        instance.ramBytesUsed = RamUsageEstimator.sizeOf(decode) + ordsReader.ramBytesUsed();\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            return decode[(int)ordsReader.get(docID)];\n          }\n        };\n        break;\n      }\n      case INDIRECT: {\n        data.seek(entry.offset);\n        final long common = data.readLong();\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        final MonotonicBlockPackedReader live = MonotonicBlockPackedReader.of(data, packedIntsVersion, blockSize, entry.count, false);\n        LoadedNorms nestedInstance = loadNorms(entry.nested);\n        instance.ramBytesUsed = live.ramBytesUsed() + nestedInstance.ramBytesUsed;\n        instance.info = Accountables.namedAccountable(\"indirect -> \" + nestedInstance.info, instance.ramBytesUsed);\n        final NumericDocValues values = nestedInstance.norms;\n        final int upperBound = entry.count-1;\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            int low = 0;\n            int high = upperBound;\n            while (low <= high) {\n              int mid = (low + high) >>> 1;\n              long doc = live.get(mid);\n              \n              if (doc < docID) {\n                low = mid + 1;\n              } else if (doc > docID) {\n                high = mid - 1;\n              } else {\n                return values.get(mid);\n              }\n            }\n            return common;\n          }\n        };\n        break;\n      }\n      case PATCHED_BITSET: {\n        data.seek(entry.offset);\n        final long common = data.readLong();\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        MonotonicBlockPackedReader live = MonotonicBlockPackedReader.of(data, packedIntsVersion, blockSize, entry.count, true);\n        final SparseFixedBitSet set = new SparseFixedBitSet(maxDoc);\n        for (int i = 0; i < live.size(); i++) {\n          int doc = (int) live.get(i);\n          set.set(doc);\n        }\n        LoadedNorms nestedInstance = loadNorms(entry.nested);\n        instance.ramBytesUsed = set.ramBytesUsed() + nestedInstance.ramBytesUsed;\n        instance.info = Accountables.namedAccountable(\"patched bitset -> \" + nestedInstance.info, instance.ramBytesUsed);\n        final NumericDocValues values = nestedInstance.norms;\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            if (set.get(docID)) {\n              return values.get(docID);\n            } else {\n              return common;\n            }\n          }\n        };\n        break;\n      }\n      case PATCHED_TABLE: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        final int formatID = data.readVInt();\n        final int bitsPerValue = data.readVInt();\n\n        if (bitsPerValue != 2 && bitsPerValue != 4) {\n          throw new CorruptIndexException(\"PATCHED_TABLE only supports bpv=2 and bpv=4, got=\" + bitsPerValue, data);\n        }\n        final int size = 1 << bitsPerValue;\n        final int ordsSize = data.readVInt();\n        final byte decode[] = new byte[ordsSize];\n        assert ordsSize + 1 == size;\n        for (int i = 0; i < ordsSize; ++i) {\n          decode[i] = data.readByte();\n        }\n        \n        final PackedInts.Reader ordsReader = PackedInts.getReaderNoHeader(data, PackedInts.Format.byId(formatID), packedIntsVersion, entry.count, bitsPerValue);\n        final LoadedNorms nestedInstance = loadNorms(entry.nested);\n        instance.ramBytesUsed = RamUsageEstimator.sizeOf(decode) + ordsReader.ramBytesUsed() + nestedInstance.ramBytesUsed;\n        instance.info = Accountables.namedAccountable(\"patched table -> \" + nestedInstance.info, instance.ramBytesUsed);\n        final NumericDocValues values = nestedInstance.norms;\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            int ord = (int)ordsReader.get(docID);\n            try {\n              // doing a try/catch here eliminates a seemingly unavoidable branch in hotspot...\n              return decode[ord];\n            } catch (IndexOutOfBoundsException e) {\n              return values.get(docID);\n            }\n          }\n        };\n        break;\n      }\n      default:\n        throw new AssertionError();\n    }\n    return instance;\n  }\n\n","sourceOld":"  private LoadedNorms loadNorms(NormsEntry entry) throws IOException {\n    LoadedNorms instance = new LoadedNorms();\n    switch(entry.format) {\n      case CONST_COMPRESSED: {\n        final long v = entry.offset;\n        instance.info = Accountables.namedAccountable(\"constant\", 8);\n        instance.ramBytesUsed = 8;\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            return v;\n          }\n        };\n        break;\n      }\n      case UNCOMPRESSED: {\n        data.seek(entry.offset);\n        final byte bytes[] = new byte[entry.count];\n        data.readBytes(bytes, 0, bytes.length);\n        instance.info = Accountables.namedAccountable(\"byte array\", bytes.length);\n        instance.ramBytesUsed = RamUsageEstimator.sizeOf(bytes);\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            return bytes[docID];\n          }\n        };\n        break;\n      }\n      case DELTA_COMPRESSED: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        final BlockPackedReader reader = new BlockPackedReader(data, packedIntsVersion, blockSize, entry.count, false);\n        instance.info = Accountables.namedAccountable(\"delta compressed\", reader);\n        instance.ramBytesUsed = reader.ramBytesUsed();\n        instance.norms = reader;\n        break;\n      }\n      case TABLE_COMPRESSED: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        int size = data.readVInt();\n        if (size > 256) {\n          throw new CorruptIndexException(\"TABLE_COMPRESSED cannot have more than 256 distinct values, got=\" + size, data);\n        }\n        final long decode[] = new long[size];\n        for (int i = 0; i < decode.length; i++) {\n          decode[i] = data.readLong();\n        }\n        final int formatID = data.readVInt();\n        final int bitsPerValue = data.readVInt();\n        final PackedInts.Reader ordsReader = PackedInts.getReaderNoHeader(data, PackedInts.Format.byId(formatID), packedIntsVersion, entry.count, bitsPerValue);\n        instance.info = Accountables.namedAccountable(\"table compressed\", ordsReader);\n        instance.ramBytesUsed = RamUsageEstimator.sizeOf(decode) + ordsReader.ramBytesUsed();\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            return decode[(int)ordsReader.get(docID)];\n          }\n        };\n        break;\n      }\n      case INDIRECT: {\n        data.seek(entry.offset);\n        final long common = data.readLong();\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        final MonotonicBlockPackedReader live = MonotonicBlockPackedReader.of(data, packedIntsVersion, blockSize, entry.count, false);\n        LoadedNorms nestedInstance = loadNorms(entry.nested);\n        instance.ramBytesUsed = live.ramBytesUsed() + nestedInstance.ramBytesUsed;\n        instance.info = Accountables.namedAccountable(\"indirect -> \" + nestedInstance.info, instance.ramBytesUsed);\n        final NumericDocValues values = nestedInstance.norms;\n        final int upperBound = entry.count-1;\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            int low = 0;\n            int high = upperBound;\n            while (low <= high) {\n              int mid = (low + high) >>> 1;\n              long doc = live.get(mid);\n              \n              if (doc < docID) {\n                low = mid + 1;\n              } else if (doc > docID) {\n                high = mid - 1;\n              } else {\n                return values.get(mid);\n              }\n            }\n            return common;\n          }\n        };\n        break;\n      }\n      case PATCHED: {\n        data.seek(entry.offset);\n        final long common = data.readLong();\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        MonotonicBlockPackedReader live = MonotonicBlockPackedReader.of(data, packedIntsVersion, blockSize, entry.count, true);\n        final SparseFixedBitSet set = new SparseFixedBitSet(maxDoc);\n        for (int i = 0; i < live.size(); i++) {\n          int doc = (int) live.get(i);\n          set.set(doc);\n        }\n        LoadedNorms nestedInstance = loadNorms(entry.nested);\n        instance.ramBytesUsed = set.ramBytesUsed() + nestedInstance.ramBytesUsed;\n        instance.info = Accountables.namedAccountable(\"patched -> \" + nestedInstance.info, instance.ramBytesUsed);\n        final NumericDocValues values = nestedInstance.norms;\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            if (set.get(docID)) {\n              return values.get(docID);\n            } else {\n              return common;\n            }\n          }\n        };\n        break;\n      }\n      default:\n        throw new AssertionError();\n    }\n    return instance;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fca6c8418a91a6d30730ad418791ddf59ec3d07a","date":1418666585,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50NormsProducer#loadNorms(NormsEntry).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50NormsProducer#loadNorms(NormsEntry).mjava","sourceNew":"  private Norms loadNorms(NormsEntry entry) throws IOException {\n    switch(entry.format) {\n      case CONST_COMPRESSED: {\n        final long v = entry.offset;\n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            return v;\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return 8;\n          }\n\n          @Override\n          public String toString() {\n            return \"constant\";\n          }\n        };\n      }\n      case UNCOMPRESSED: {\n        data.seek(entry.offset);\n        final byte bytes[] = new byte[entry.count];\n        data.readBytes(bytes, 0, bytes.length);\n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            return bytes[docID];\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return RamUsageEstimator.sizeOf(bytes);\n          }\n\n          @Override\n          public String toString() {\n            return \"byte array\";\n          }\n        };\n      }\n      case DELTA_COMPRESSED: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        final BlockPackedReader reader = new BlockPackedReader(data, packedIntsVersion, blockSize, entry.count, false);\n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            return reader.get(docID);\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return reader.ramBytesUsed();\n          }\n\n          @Override\n          public Iterable<Accountable> getChildResources() {\n            return Collections.singleton(reader);\n          }\n\n          @Override\n          public String toString() {\n            return \"delta compressed\";\n          }\n        };\n      }\n      case TABLE_COMPRESSED: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        final int formatID = data.readVInt();\n        final int bitsPerValue = data.readVInt();\n        \n        if (bitsPerValue != 1 && bitsPerValue != 2 && bitsPerValue != 4) {\n          throw new CorruptIndexException(\"TABLE_COMPRESSED only supports bpv=1, bpv=2 and bpv=4, got=\" + bitsPerValue, data);\n        }\n        int size = 1 << bitsPerValue;\n        final byte decode[] = new byte[size];\n        final int ordsSize = data.readVInt();\n        for (int i = 0; i < ordsSize; ++i) {\n          decode[i] = data.readByte();\n        }\n        for (int i = ordsSize; i < size; ++i) {\n          decode[i] = 0;\n        }\n\n        final PackedInts.Reader ordsReader = PackedInts.getReaderNoHeader(data, PackedInts.Format.byId(formatID), packedIntsVersion, entry.count, bitsPerValue);\n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            return decode[(int)ordsReader.get(docID)];\n          }\n          \n          @Override\n          public long ramBytesUsed() {\n            return RamUsageEstimator.sizeOf(decode) + ordsReader.ramBytesUsed();\n          }\n\n          @Override\n          public Iterable<Accountable> getChildResources() {\n            return Collections.singleton(ordsReader);\n          }\n\n          @Override\n          public String toString() {\n            return \"table compressed\";\n          }\n        };\n      }\n      case INDIRECT: {\n        data.seek(entry.offset);\n        final long common = data.readLong();\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        final MonotonicBlockPackedReader live = MonotonicBlockPackedReader.of(data, packedIntsVersion, blockSize, entry.count, false);\n        final Norms nestedInstance = loadNorms(entry.nested);\n        final int upperBound = entry.count-1;\n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            int low = 0;\n            int high = upperBound;\n            while (low <= high) {\n              int mid = (low + high) >>> 1;\n              long doc = live.get(mid);\n              \n              if (doc < docID) {\n                low = mid + 1;\n              } else if (doc > docID) {\n                high = mid - 1;\n              } else {\n                return nestedInstance.get(mid);\n              }\n            }\n            return common;\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return live.ramBytesUsed() + nestedInstance.ramBytesUsed();\n          }\n\n          @Override\n          public Iterable<Accountable> getChildResources() {\n            List<Accountable> children = new ArrayList<>();\n            children.add(Accountables.namedAccountable(\"keys\", live));\n            children.add(Accountables.namedAccountable(\"values\", nestedInstance));\n            return Collections.unmodifiableList(children);\n          }\n\n          @Override\n          public String toString() {\n            return \"indirect\";\n          }\n        };\n      }\n      case PATCHED_BITSET: {\n        data.seek(entry.offset);\n        final long common = data.readLong();\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        MonotonicBlockPackedReader live = MonotonicBlockPackedReader.of(data, packedIntsVersion, blockSize, entry.count, true);\n        final SparseFixedBitSet set = new SparseFixedBitSet(maxDoc);\n        for (int i = 0; i < live.size(); i++) {\n          int doc = (int) live.get(i);\n          set.set(doc);\n        }\n        Norms nestedInstance = loadNorms(entry.nested);\n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            if (set.get(docID)) {\n              return nestedInstance.get(docID);\n            } else {\n              return common;\n            }\n          }\n          \n          @Override\n          public long ramBytesUsed() {\n            return set.ramBytesUsed() + nestedInstance.ramBytesUsed();\n          }\n\n          @Override\n          public Iterable<Accountable> getChildResources() {\n            List<Accountable> children = new ArrayList<>();\n            children.add(Accountables.namedAccountable(\"keys\", set));\n            children.add(Accountables.namedAccountable(\"values\", nestedInstance));\n            return Collections.unmodifiableList(children);\n          }\n\n          @Override\n          public String toString() {\n            return \"patched bitset\";\n          }\n        };\n      }\n      case PATCHED_TABLE: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        final int formatID = data.readVInt();\n        final int bitsPerValue = data.readVInt();\n\n        if (bitsPerValue != 2 && bitsPerValue != 4) {\n          throw new CorruptIndexException(\"PATCHED_TABLE only supports bpv=2 and bpv=4, got=\" + bitsPerValue, data);\n        }\n        final int size = 1 << bitsPerValue;\n        final int ordsSize = data.readVInt();\n        final byte decode[] = new byte[ordsSize];\n        assert ordsSize + 1 == size;\n        for (int i = 0; i < ordsSize; ++i) {\n          decode[i] = data.readByte();\n        }\n        \n        final PackedInts.Reader ordsReader = PackedInts.getReaderNoHeader(data, PackedInts.Format.byId(formatID), packedIntsVersion, entry.count, bitsPerValue);\n        final Norms nestedInstance = loadNorms(entry.nested);\n        \n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            int ord = (int)ordsReader.get(docID);\n            try {\n              // doing a try/catch here eliminates a seemingly unavoidable branch in hotspot...\n              return decode[ord];\n            } catch (IndexOutOfBoundsException e) {\n              return nestedInstance.get(docID);\n            }\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return RamUsageEstimator.sizeOf(decode) + ordsReader.ramBytesUsed() + nestedInstance.ramBytesUsed();\n          }\n\n          @Override\n          public Iterable<Accountable> getChildResources() {\n            List<Accountable> children = new ArrayList<>();\n            children.add(Accountables.namedAccountable(\"common\", ordsReader));\n            children.add(Accountables.namedAccountable(\"uncommon\", nestedInstance));\n            return Collections.unmodifiableList(children);\n          }\n\n          @Override\n          public String toString() {\n            return \"patched table\";\n          }\n        };\n      }\n      default:\n        throw new AssertionError();\n    }\n  }\n\n","sourceOld":"  private LoadedNorms loadNorms(NormsEntry entry) throws IOException {\n    LoadedNorms instance = new LoadedNorms();\n    switch(entry.format) {\n      case CONST_COMPRESSED: {\n        final long v = entry.offset;\n        instance.info = Accountables.namedAccountable(\"constant\", 8);\n        instance.ramBytesUsed = 8;\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            return v;\n          }\n        };\n        break;\n      }\n      case UNCOMPRESSED: {\n        data.seek(entry.offset);\n        final byte bytes[] = new byte[entry.count];\n        data.readBytes(bytes, 0, bytes.length);\n        instance.info = Accountables.namedAccountable(\"byte array\", bytes.length);\n        instance.ramBytesUsed = RamUsageEstimator.sizeOf(bytes);\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            return bytes[docID];\n          }\n        };\n        break;\n      }\n      case DELTA_COMPRESSED: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        final BlockPackedReader reader = new BlockPackedReader(data, packedIntsVersion, blockSize, entry.count, false);\n        instance.info = Accountables.namedAccountable(\"delta compressed\", reader);\n        instance.ramBytesUsed = reader.ramBytesUsed();\n        instance.norms = reader;\n        break;\n      }\n      case TABLE_COMPRESSED: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        final int formatID = data.readVInt();\n        final int bitsPerValue = data.readVInt();\n        \n        if (bitsPerValue != 1 && bitsPerValue != 2 && bitsPerValue != 4) {\n          throw new CorruptIndexException(\"TABLE_COMPRESSED only supports bpv=1, bpv=2 and bpv=4, got=\" + bitsPerValue, data);\n        }\n        int size = 1 << bitsPerValue;\n        final byte decode[] = new byte[size];\n        final int ordsSize = data.readVInt();\n        for (int i = 0; i < ordsSize; ++i) {\n          decode[i] = data.readByte();\n        }\n        for (int i = ordsSize; i < size; ++i) {\n          decode[i] = 0;\n        }\n\n        final PackedInts.Reader ordsReader = PackedInts.getReaderNoHeader(data, PackedInts.Format.byId(formatID), packedIntsVersion, entry.count, bitsPerValue);\n        instance.info = Accountables.namedAccountable(\"table compressed\", ordsReader);\n        instance.ramBytesUsed = RamUsageEstimator.sizeOf(decode) + ordsReader.ramBytesUsed();\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            return decode[(int)ordsReader.get(docID)];\n          }\n        };\n        break;\n      }\n      case INDIRECT: {\n        data.seek(entry.offset);\n        final long common = data.readLong();\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        final MonotonicBlockPackedReader live = MonotonicBlockPackedReader.of(data, packedIntsVersion, blockSize, entry.count, false);\n        LoadedNorms nestedInstance = loadNorms(entry.nested);\n        instance.ramBytesUsed = live.ramBytesUsed() + nestedInstance.ramBytesUsed;\n        instance.info = Accountables.namedAccountable(\"indirect -> \" + nestedInstance.info, instance.ramBytesUsed);\n        final NumericDocValues values = nestedInstance.norms;\n        final int upperBound = entry.count-1;\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            int low = 0;\n            int high = upperBound;\n            while (low <= high) {\n              int mid = (low + high) >>> 1;\n              long doc = live.get(mid);\n              \n              if (doc < docID) {\n                low = mid + 1;\n              } else if (doc > docID) {\n                high = mid - 1;\n              } else {\n                return values.get(mid);\n              }\n            }\n            return common;\n          }\n        };\n        break;\n      }\n      case PATCHED_BITSET: {\n        data.seek(entry.offset);\n        final long common = data.readLong();\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        MonotonicBlockPackedReader live = MonotonicBlockPackedReader.of(data, packedIntsVersion, blockSize, entry.count, true);\n        final SparseFixedBitSet set = new SparseFixedBitSet(maxDoc);\n        for (int i = 0; i < live.size(); i++) {\n          int doc = (int) live.get(i);\n          set.set(doc);\n        }\n        LoadedNorms nestedInstance = loadNorms(entry.nested);\n        instance.ramBytesUsed = set.ramBytesUsed() + nestedInstance.ramBytesUsed;\n        instance.info = Accountables.namedAccountable(\"patched bitset -> \" + nestedInstance.info, instance.ramBytesUsed);\n        final NumericDocValues values = nestedInstance.norms;\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            if (set.get(docID)) {\n              return values.get(docID);\n            } else {\n              return common;\n            }\n          }\n        };\n        break;\n      }\n      case PATCHED_TABLE: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        final int formatID = data.readVInt();\n        final int bitsPerValue = data.readVInt();\n\n        if (bitsPerValue != 2 && bitsPerValue != 4) {\n          throw new CorruptIndexException(\"PATCHED_TABLE only supports bpv=2 and bpv=4, got=\" + bitsPerValue, data);\n        }\n        final int size = 1 << bitsPerValue;\n        final int ordsSize = data.readVInt();\n        final byte decode[] = new byte[ordsSize];\n        assert ordsSize + 1 == size;\n        for (int i = 0; i < ordsSize; ++i) {\n          decode[i] = data.readByte();\n        }\n        \n        final PackedInts.Reader ordsReader = PackedInts.getReaderNoHeader(data, PackedInts.Format.byId(formatID), packedIntsVersion, entry.count, bitsPerValue);\n        final LoadedNorms nestedInstance = loadNorms(entry.nested);\n        instance.ramBytesUsed = RamUsageEstimator.sizeOf(decode) + ordsReader.ramBytesUsed() + nestedInstance.ramBytesUsed;\n        instance.info = Accountables.namedAccountable(\"patched table -> \" + nestedInstance.info, instance.ramBytesUsed);\n        final NumericDocValues values = nestedInstance.norms;\n        instance.norms = new NumericDocValues() {\n          @Override\n          public long get(int docID) {\n            int ord = (int)ordsReader.get(docID);\n            try {\n              // doing a try/catch here eliminates a seemingly unavoidable branch in hotspot...\n              return decode[ord];\n            } catch (IndexOutOfBoundsException e) {\n              return values.get(docID);\n            }\n          }\n        };\n        break;\n      }\n      default:\n        throw new AssertionError();\n    }\n    return instance;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8ba6ae8e3c153347cbb605024ca7550f5c91b178","date":1420215916,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50NormsProducer#loadNorms(NormsEntry).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50NormsProducer#loadNorms(NormsEntry).mjava","sourceNew":"  private Norms loadNorms(NormsEntry entry) throws IOException {\n    switch(entry.format) {\n      case CONST_COMPRESSED: {\n        final long v = entry.offset;\n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            return v;\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return 8;\n          }\n\n          @Override\n          public String toString() {\n            return \"constant\";\n          }\n        };\n      }\n      case UNCOMPRESSED: {\n        data.seek(entry.offset);\n        final byte bytes[] = new byte[entry.count];\n        data.readBytes(bytes, 0, bytes.length);\n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            return bytes[docID];\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return RamUsageEstimator.sizeOf(bytes);\n          }\n\n          @Override\n          public String toString() {\n            return \"byte array\";\n          }\n        };\n      }\n      case DELTA_COMPRESSED: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        final BlockPackedReader reader = new BlockPackedReader(data, packedIntsVersion, blockSize, entry.count, false);\n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            return reader.get(docID);\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return reader.ramBytesUsed();\n          }\n\n          @Override\n          public Collection<Accountable> getChildResources() {\n            return Collections.singleton(reader);\n          }\n\n          @Override\n          public String toString() {\n            return \"delta compressed\";\n          }\n        };\n      }\n      case TABLE_COMPRESSED: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        final int formatID = data.readVInt();\n        final int bitsPerValue = data.readVInt();\n        \n        if (bitsPerValue != 1 && bitsPerValue != 2 && bitsPerValue != 4) {\n          throw new CorruptIndexException(\"TABLE_COMPRESSED only supports bpv=1, bpv=2 and bpv=4, got=\" + bitsPerValue, data);\n        }\n        int size = 1 << bitsPerValue;\n        final byte decode[] = new byte[size];\n        final int ordsSize = data.readVInt();\n        for (int i = 0; i < ordsSize; ++i) {\n          decode[i] = data.readByte();\n        }\n        for (int i = ordsSize; i < size; ++i) {\n          decode[i] = 0;\n        }\n\n        final PackedInts.Reader ordsReader = PackedInts.getReaderNoHeader(data, PackedInts.Format.byId(formatID), packedIntsVersion, entry.count, bitsPerValue);\n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            return decode[(int)ordsReader.get(docID)];\n          }\n          \n          @Override\n          public long ramBytesUsed() {\n            return RamUsageEstimator.sizeOf(decode) + ordsReader.ramBytesUsed();\n          }\n\n          @Override\n          public Collection<Accountable> getChildResources() {\n            return Collections.singleton(ordsReader);\n          }\n\n          @Override\n          public String toString() {\n            return \"table compressed\";\n          }\n        };\n      }\n      case INDIRECT: {\n        data.seek(entry.offset);\n        final long common = data.readLong();\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        final MonotonicBlockPackedReader live = MonotonicBlockPackedReader.of(data, packedIntsVersion, blockSize, entry.count, false);\n        final Norms nestedInstance = loadNorms(entry.nested);\n        final int upperBound = entry.count-1;\n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            int low = 0;\n            int high = upperBound;\n            while (low <= high) {\n              int mid = (low + high) >>> 1;\n              long doc = live.get(mid);\n              \n              if (doc < docID) {\n                low = mid + 1;\n              } else if (doc > docID) {\n                high = mid - 1;\n              } else {\n                return nestedInstance.get(mid);\n              }\n            }\n            return common;\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return live.ramBytesUsed() + nestedInstance.ramBytesUsed();\n          }\n\n          @Override\n          public Collection<Accountable> getChildResources() {\n            List<Accountable> children = new ArrayList<>();\n            children.add(Accountables.namedAccountable(\"keys\", live));\n            children.add(Accountables.namedAccountable(\"values\", nestedInstance));\n            return Collections.unmodifiableList(children);\n          }\n\n          @Override\n          public String toString() {\n            return \"indirect\";\n          }\n        };\n      }\n      case PATCHED_BITSET: {\n        data.seek(entry.offset);\n        final long common = data.readLong();\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        MonotonicBlockPackedReader live = MonotonicBlockPackedReader.of(data, packedIntsVersion, blockSize, entry.count, true);\n        final SparseFixedBitSet set = new SparseFixedBitSet(maxDoc);\n        for (int i = 0; i < live.size(); i++) {\n          int doc = (int) live.get(i);\n          set.set(doc);\n        }\n        Norms nestedInstance = loadNorms(entry.nested);\n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            if (set.get(docID)) {\n              return nestedInstance.get(docID);\n            } else {\n              return common;\n            }\n          }\n          \n          @Override\n          public long ramBytesUsed() {\n            return set.ramBytesUsed() + nestedInstance.ramBytesUsed();\n          }\n\n          @Override\n          public Collection<Accountable> getChildResources() {\n            List<Accountable> children = new ArrayList<>();\n            children.add(Accountables.namedAccountable(\"keys\", set));\n            children.add(Accountables.namedAccountable(\"values\", nestedInstance));\n            return Collections.unmodifiableList(children);\n          }\n\n          @Override\n          public String toString() {\n            return \"patched bitset\";\n          }\n        };\n      }\n      case PATCHED_TABLE: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        final int formatID = data.readVInt();\n        final int bitsPerValue = data.readVInt();\n\n        if (bitsPerValue != 2 && bitsPerValue != 4) {\n          throw new CorruptIndexException(\"PATCHED_TABLE only supports bpv=2 and bpv=4, got=\" + bitsPerValue, data);\n        }\n        final int size = 1 << bitsPerValue;\n        final int ordsSize = data.readVInt();\n        final byte decode[] = new byte[ordsSize];\n        assert ordsSize + 1 == size;\n        for (int i = 0; i < ordsSize; ++i) {\n          decode[i] = data.readByte();\n        }\n        \n        final PackedInts.Reader ordsReader = PackedInts.getReaderNoHeader(data, PackedInts.Format.byId(formatID), packedIntsVersion, entry.count, bitsPerValue);\n        final Norms nestedInstance = loadNorms(entry.nested);\n        \n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            int ord = (int)ordsReader.get(docID);\n            try {\n              // doing a try/catch here eliminates a seemingly unavoidable branch in hotspot...\n              return decode[ord];\n            } catch (IndexOutOfBoundsException e) {\n              return nestedInstance.get(docID);\n            }\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return RamUsageEstimator.sizeOf(decode) + ordsReader.ramBytesUsed() + nestedInstance.ramBytesUsed();\n          }\n\n          @Override\n          public Collection<Accountable> getChildResources() {\n            List<Accountable> children = new ArrayList<>();\n            children.add(Accountables.namedAccountable(\"common\", ordsReader));\n            children.add(Accountables.namedAccountable(\"uncommon\", nestedInstance));\n            return Collections.unmodifiableList(children);\n          }\n\n          @Override\n          public String toString() {\n            return \"patched table\";\n          }\n        };\n      }\n      default:\n        throw new AssertionError();\n    }\n  }\n\n","sourceOld":"  private Norms loadNorms(NormsEntry entry) throws IOException {\n    switch(entry.format) {\n      case CONST_COMPRESSED: {\n        final long v = entry.offset;\n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            return v;\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return 8;\n          }\n\n          @Override\n          public String toString() {\n            return \"constant\";\n          }\n        };\n      }\n      case UNCOMPRESSED: {\n        data.seek(entry.offset);\n        final byte bytes[] = new byte[entry.count];\n        data.readBytes(bytes, 0, bytes.length);\n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            return bytes[docID];\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return RamUsageEstimator.sizeOf(bytes);\n          }\n\n          @Override\n          public String toString() {\n            return \"byte array\";\n          }\n        };\n      }\n      case DELTA_COMPRESSED: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        final BlockPackedReader reader = new BlockPackedReader(data, packedIntsVersion, blockSize, entry.count, false);\n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            return reader.get(docID);\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return reader.ramBytesUsed();\n          }\n\n          @Override\n          public Iterable<Accountable> getChildResources() {\n            return Collections.singleton(reader);\n          }\n\n          @Override\n          public String toString() {\n            return \"delta compressed\";\n          }\n        };\n      }\n      case TABLE_COMPRESSED: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        final int formatID = data.readVInt();\n        final int bitsPerValue = data.readVInt();\n        \n        if (bitsPerValue != 1 && bitsPerValue != 2 && bitsPerValue != 4) {\n          throw new CorruptIndexException(\"TABLE_COMPRESSED only supports bpv=1, bpv=2 and bpv=4, got=\" + bitsPerValue, data);\n        }\n        int size = 1 << bitsPerValue;\n        final byte decode[] = new byte[size];\n        final int ordsSize = data.readVInt();\n        for (int i = 0; i < ordsSize; ++i) {\n          decode[i] = data.readByte();\n        }\n        for (int i = ordsSize; i < size; ++i) {\n          decode[i] = 0;\n        }\n\n        final PackedInts.Reader ordsReader = PackedInts.getReaderNoHeader(data, PackedInts.Format.byId(formatID), packedIntsVersion, entry.count, bitsPerValue);\n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            return decode[(int)ordsReader.get(docID)];\n          }\n          \n          @Override\n          public long ramBytesUsed() {\n            return RamUsageEstimator.sizeOf(decode) + ordsReader.ramBytesUsed();\n          }\n\n          @Override\n          public Iterable<Accountable> getChildResources() {\n            return Collections.singleton(ordsReader);\n          }\n\n          @Override\n          public String toString() {\n            return \"table compressed\";\n          }\n        };\n      }\n      case INDIRECT: {\n        data.seek(entry.offset);\n        final long common = data.readLong();\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        final MonotonicBlockPackedReader live = MonotonicBlockPackedReader.of(data, packedIntsVersion, blockSize, entry.count, false);\n        final Norms nestedInstance = loadNorms(entry.nested);\n        final int upperBound = entry.count-1;\n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            int low = 0;\n            int high = upperBound;\n            while (low <= high) {\n              int mid = (low + high) >>> 1;\n              long doc = live.get(mid);\n              \n              if (doc < docID) {\n                low = mid + 1;\n              } else if (doc > docID) {\n                high = mid - 1;\n              } else {\n                return nestedInstance.get(mid);\n              }\n            }\n            return common;\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return live.ramBytesUsed() + nestedInstance.ramBytesUsed();\n          }\n\n          @Override\n          public Iterable<Accountable> getChildResources() {\n            List<Accountable> children = new ArrayList<>();\n            children.add(Accountables.namedAccountable(\"keys\", live));\n            children.add(Accountables.namedAccountable(\"values\", nestedInstance));\n            return Collections.unmodifiableList(children);\n          }\n\n          @Override\n          public String toString() {\n            return \"indirect\";\n          }\n        };\n      }\n      case PATCHED_BITSET: {\n        data.seek(entry.offset);\n        final long common = data.readLong();\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        MonotonicBlockPackedReader live = MonotonicBlockPackedReader.of(data, packedIntsVersion, blockSize, entry.count, true);\n        final SparseFixedBitSet set = new SparseFixedBitSet(maxDoc);\n        for (int i = 0; i < live.size(); i++) {\n          int doc = (int) live.get(i);\n          set.set(doc);\n        }\n        Norms nestedInstance = loadNorms(entry.nested);\n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            if (set.get(docID)) {\n              return nestedInstance.get(docID);\n            } else {\n              return common;\n            }\n          }\n          \n          @Override\n          public long ramBytesUsed() {\n            return set.ramBytesUsed() + nestedInstance.ramBytesUsed();\n          }\n\n          @Override\n          public Iterable<Accountable> getChildResources() {\n            List<Accountable> children = new ArrayList<>();\n            children.add(Accountables.namedAccountable(\"keys\", set));\n            children.add(Accountables.namedAccountable(\"values\", nestedInstance));\n            return Collections.unmodifiableList(children);\n          }\n\n          @Override\n          public String toString() {\n            return \"patched bitset\";\n          }\n        };\n      }\n      case PATCHED_TABLE: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        final int formatID = data.readVInt();\n        final int bitsPerValue = data.readVInt();\n\n        if (bitsPerValue != 2 && bitsPerValue != 4) {\n          throw new CorruptIndexException(\"PATCHED_TABLE only supports bpv=2 and bpv=4, got=\" + bitsPerValue, data);\n        }\n        final int size = 1 << bitsPerValue;\n        final int ordsSize = data.readVInt();\n        final byte decode[] = new byte[ordsSize];\n        assert ordsSize + 1 == size;\n        for (int i = 0; i < ordsSize; ++i) {\n          decode[i] = data.readByte();\n        }\n        \n        final PackedInts.Reader ordsReader = PackedInts.getReaderNoHeader(data, PackedInts.Format.byId(formatID), packedIntsVersion, entry.count, bitsPerValue);\n        final Norms nestedInstance = loadNorms(entry.nested);\n        \n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            int ord = (int)ordsReader.get(docID);\n            try {\n              // doing a try/catch here eliminates a seemingly unavoidable branch in hotspot...\n              return decode[ord];\n            } catch (IndexOutOfBoundsException e) {\n              return nestedInstance.get(docID);\n            }\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return RamUsageEstimator.sizeOf(decode) + ordsReader.ramBytesUsed() + nestedInstance.ramBytesUsed();\n          }\n\n          @Override\n          public Iterable<Accountable> getChildResources() {\n            List<Accountable> children = new ArrayList<>();\n            children.add(Accountables.namedAccountable(\"common\", ordsReader));\n            children.add(Accountables.namedAccountable(\"uncommon\", nestedInstance));\n            return Collections.unmodifiableList(children);\n          }\n\n          @Override\n          public String toString() {\n            return \"patched table\";\n          }\n        };\n      }\n      default:\n        throw new AssertionError();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"96d86741fa6ad3b3a96fbf99f5e41bc74784c5f9","date":1434069165,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene50/Lucene50NormsProducer#loadNorms(NormsEntry).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50NormsProducer#loadNorms(NormsEntry).mjava","sourceNew":"  private Norms loadNorms(NormsEntry entry) throws IOException {\n    switch(entry.format) {\n      case CONST_COMPRESSED: {\n        final long v = entry.offset;\n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            return v;\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return 8;\n          }\n\n          @Override\n          public String toString() {\n            return \"constant\";\n          }\n        };\n      }\n      case UNCOMPRESSED: {\n        data.seek(entry.offset);\n        final byte bytes[] = new byte[entry.count];\n        data.readBytes(bytes, 0, bytes.length);\n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            return bytes[docID];\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return RamUsageEstimator.sizeOf(bytes);\n          }\n\n          @Override\n          public String toString() {\n            return \"byte array\";\n          }\n        };\n      }\n      case DELTA_COMPRESSED: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        final BlockPackedReader reader = new BlockPackedReader(data, packedIntsVersion, blockSize, entry.count, false);\n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            return reader.get(docID);\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return reader.ramBytesUsed();\n          }\n\n          @Override\n          public Collection<Accountable> getChildResources() {\n            return Collections.singleton(reader);\n          }\n\n          @Override\n          public String toString() {\n            return \"delta compressed\";\n          }\n        };\n      }\n      case TABLE_COMPRESSED: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        final int formatID = data.readVInt();\n        final int bitsPerValue = data.readVInt();\n        \n        if (bitsPerValue != 1 && bitsPerValue != 2 && bitsPerValue != 4) {\n          throw new CorruptIndexException(\"TABLE_COMPRESSED only supports bpv=1, bpv=2 and bpv=4, got=\" + bitsPerValue, data);\n        }\n        int size = 1 << bitsPerValue;\n        final byte decode[] = new byte[size];\n        final int ordsSize = data.readVInt();\n        for (int i = 0; i < ordsSize; ++i) {\n          decode[i] = data.readByte();\n        }\n        for (int i = ordsSize; i < size; ++i) {\n          decode[i] = 0;\n        }\n\n        final PackedInts.Reader ordsReader = PackedInts.getReaderNoHeader(data, PackedInts.Format.byId(formatID), packedIntsVersion, entry.count, bitsPerValue);\n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            return decode[(int)ordsReader.get(docID)];\n          }\n          \n          @Override\n          public long ramBytesUsed() {\n            return RamUsageEstimator.sizeOf(decode) + ordsReader.ramBytesUsed();\n          }\n\n          @Override\n          public Collection<Accountable> getChildResources() {\n            return Collections.singleton(ordsReader);\n          }\n\n          @Override\n          public String toString() {\n            return \"table compressed\";\n          }\n        };\n      }\n      case INDIRECT: {\n        data.seek(entry.offset);\n        final long common = data.readLong();\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        final MonotonicBlockPackedReader live = MonotonicBlockPackedReader.of(data, packedIntsVersion, blockSize, entry.count, false);\n        final Norms nestedInstance = loadNorms(entry.nested);\n        final int upperBound = entry.count-1;\n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            int low = 0;\n            int high = upperBound;\n            while (low <= high) {\n              int mid = (low + high) >>> 1;\n              long doc = live.get(mid);\n              \n              if (doc < docID) {\n                low = mid + 1;\n              } else if (doc > docID) {\n                high = mid - 1;\n              } else {\n                return nestedInstance.get(mid);\n              }\n            }\n            return common;\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return live.ramBytesUsed() + nestedInstance.ramBytesUsed();\n          }\n\n          @Override\n          public Collection<Accountable> getChildResources() {\n            List<Accountable> children = new ArrayList<>();\n            children.add(Accountables.namedAccountable(\"keys\", live));\n            children.add(Accountables.namedAccountable(\"values\", nestedInstance));\n            return Collections.unmodifiableList(children);\n          }\n\n          @Override\n          public String toString() {\n            return \"indirect\";\n          }\n        };\n      }\n      case PATCHED_BITSET: {\n        data.seek(entry.offset);\n        final long common = data.readLong();\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        MonotonicBlockPackedReader live = MonotonicBlockPackedReader.of(data, packedIntsVersion, blockSize, entry.count, true);\n        final SparseFixedBitSet set = new SparseFixedBitSet(maxDoc);\n        for (int i = 0; i < live.size(); i++) {\n          int doc = (int) live.get(i);\n          set.set(doc);\n        }\n        Norms nestedInstance = loadNorms(entry.nested);\n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            if (set.get(docID)) {\n              return nestedInstance.get(docID);\n            } else {\n              return common;\n            }\n          }\n          \n          @Override\n          public long ramBytesUsed() {\n            return set.ramBytesUsed() + nestedInstance.ramBytesUsed();\n          }\n\n          @Override\n          public Collection<Accountable> getChildResources() {\n            List<Accountable> children = new ArrayList<>();\n            children.add(Accountables.namedAccountable(\"keys\", set));\n            children.add(Accountables.namedAccountable(\"values\", nestedInstance));\n            return Collections.unmodifiableList(children);\n          }\n\n          @Override\n          public String toString() {\n            return \"patched bitset\";\n          }\n        };\n      }\n      case PATCHED_TABLE: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        final int formatID = data.readVInt();\n        final int bitsPerValue = data.readVInt();\n\n        if (bitsPerValue != 2 && bitsPerValue != 4) {\n          throw new CorruptIndexException(\"PATCHED_TABLE only supports bpv=2 and bpv=4, got=\" + bitsPerValue, data);\n        }\n        final int size = 1 << bitsPerValue;\n        final int ordsSize = data.readVInt();\n        final byte decode[] = new byte[ordsSize];\n        assert ordsSize + 1 == size;\n        for (int i = 0; i < ordsSize; ++i) {\n          decode[i] = data.readByte();\n        }\n        \n        final PackedInts.Reader ordsReader = PackedInts.getReaderNoHeader(data, PackedInts.Format.byId(formatID), packedIntsVersion, entry.count, bitsPerValue);\n        final Norms nestedInstance = loadNorms(entry.nested);\n        \n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            int ord = (int)ordsReader.get(docID);\n            try {\n              // doing a try/catch here eliminates a seemingly unavoidable branch in hotspot...\n              return decode[ord];\n            } catch (IndexOutOfBoundsException e) {\n              return nestedInstance.get(docID);\n            }\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return RamUsageEstimator.sizeOf(decode) + ordsReader.ramBytesUsed() + nestedInstance.ramBytesUsed();\n          }\n\n          @Override\n          public Collection<Accountable> getChildResources() {\n            List<Accountable> children = new ArrayList<>();\n            children.add(Accountables.namedAccountable(\"common\", ordsReader));\n            children.add(Accountables.namedAccountable(\"uncommon\", nestedInstance));\n            return Collections.unmodifiableList(children);\n          }\n\n          @Override\n          public String toString() {\n            return \"patched table\";\n          }\n        };\n      }\n      default:\n        throw new AssertionError();\n    }\n  }\n\n","sourceOld":"  private Norms loadNorms(NormsEntry entry) throws IOException {\n    switch(entry.format) {\n      case CONST_COMPRESSED: {\n        final long v = entry.offset;\n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            return v;\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return 8;\n          }\n\n          @Override\n          public String toString() {\n            return \"constant\";\n          }\n        };\n      }\n      case UNCOMPRESSED: {\n        data.seek(entry.offset);\n        final byte bytes[] = new byte[entry.count];\n        data.readBytes(bytes, 0, bytes.length);\n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            return bytes[docID];\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return RamUsageEstimator.sizeOf(bytes);\n          }\n\n          @Override\n          public String toString() {\n            return \"byte array\";\n          }\n        };\n      }\n      case DELTA_COMPRESSED: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        final BlockPackedReader reader = new BlockPackedReader(data, packedIntsVersion, blockSize, entry.count, false);\n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            return reader.get(docID);\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return reader.ramBytesUsed();\n          }\n\n          @Override\n          public Collection<Accountable> getChildResources() {\n            return Collections.singleton(reader);\n          }\n\n          @Override\n          public String toString() {\n            return \"delta compressed\";\n          }\n        };\n      }\n      case TABLE_COMPRESSED: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        final int formatID = data.readVInt();\n        final int bitsPerValue = data.readVInt();\n        \n        if (bitsPerValue != 1 && bitsPerValue != 2 && bitsPerValue != 4) {\n          throw new CorruptIndexException(\"TABLE_COMPRESSED only supports bpv=1, bpv=2 and bpv=4, got=\" + bitsPerValue, data);\n        }\n        int size = 1 << bitsPerValue;\n        final byte decode[] = new byte[size];\n        final int ordsSize = data.readVInt();\n        for (int i = 0; i < ordsSize; ++i) {\n          decode[i] = data.readByte();\n        }\n        for (int i = ordsSize; i < size; ++i) {\n          decode[i] = 0;\n        }\n\n        final PackedInts.Reader ordsReader = PackedInts.getReaderNoHeader(data, PackedInts.Format.byId(formatID), packedIntsVersion, entry.count, bitsPerValue);\n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            return decode[(int)ordsReader.get(docID)];\n          }\n          \n          @Override\n          public long ramBytesUsed() {\n            return RamUsageEstimator.sizeOf(decode) + ordsReader.ramBytesUsed();\n          }\n\n          @Override\n          public Collection<Accountable> getChildResources() {\n            return Collections.singleton(ordsReader);\n          }\n\n          @Override\n          public String toString() {\n            return \"table compressed\";\n          }\n        };\n      }\n      case INDIRECT: {\n        data.seek(entry.offset);\n        final long common = data.readLong();\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        final MonotonicBlockPackedReader live = MonotonicBlockPackedReader.of(data, packedIntsVersion, blockSize, entry.count, false);\n        final Norms nestedInstance = loadNorms(entry.nested);\n        final int upperBound = entry.count-1;\n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            int low = 0;\n            int high = upperBound;\n            while (low <= high) {\n              int mid = (low + high) >>> 1;\n              long doc = live.get(mid);\n              \n              if (doc < docID) {\n                low = mid + 1;\n              } else if (doc > docID) {\n                high = mid - 1;\n              } else {\n                return nestedInstance.get(mid);\n              }\n            }\n            return common;\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return live.ramBytesUsed() + nestedInstance.ramBytesUsed();\n          }\n\n          @Override\n          public Collection<Accountable> getChildResources() {\n            List<Accountable> children = new ArrayList<>();\n            children.add(Accountables.namedAccountable(\"keys\", live));\n            children.add(Accountables.namedAccountable(\"values\", nestedInstance));\n            return Collections.unmodifiableList(children);\n          }\n\n          @Override\n          public String toString() {\n            return \"indirect\";\n          }\n        };\n      }\n      case PATCHED_BITSET: {\n        data.seek(entry.offset);\n        final long common = data.readLong();\n        int packedIntsVersion = data.readVInt();\n        int blockSize = data.readVInt();\n        MonotonicBlockPackedReader live = MonotonicBlockPackedReader.of(data, packedIntsVersion, blockSize, entry.count, true);\n        final SparseFixedBitSet set = new SparseFixedBitSet(maxDoc);\n        for (int i = 0; i < live.size(); i++) {\n          int doc = (int) live.get(i);\n          set.set(doc);\n        }\n        Norms nestedInstance = loadNorms(entry.nested);\n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            if (set.get(docID)) {\n              return nestedInstance.get(docID);\n            } else {\n              return common;\n            }\n          }\n          \n          @Override\n          public long ramBytesUsed() {\n            return set.ramBytesUsed() + nestedInstance.ramBytesUsed();\n          }\n\n          @Override\n          public Collection<Accountable> getChildResources() {\n            List<Accountable> children = new ArrayList<>();\n            children.add(Accountables.namedAccountable(\"keys\", set));\n            children.add(Accountables.namedAccountable(\"values\", nestedInstance));\n            return Collections.unmodifiableList(children);\n          }\n\n          @Override\n          public String toString() {\n            return \"patched bitset\";\n          }\n        };\n      }\n      case PATCHED_TABLE: {\n        data.seek(entry.offset);\n        int packedIntsVersion = data.readVInt();\n        final int formatID = data.readVInt();\n        final int bitsPerValue = data.readVInt();\n\n        if (bitsPerValue != 2 && bitsPerValue != 4) {\n          throw new CorruptIndexException(\"PATCHED_TABLE only supports bpv=2 and bpv=4, got=\" + bitsPerValue, data);\n        }\n        final int size = 1 << bitsPerValue;\n        final int ordsSize = data.readVInt();\n        final byte decode[] = new byte[ordsSize];\n        assert ordsSize + 1 == size;\n        for (int i = 0; i < ordsSize; ++i) {\n          decode[i] = data.readByte();\n        }\n        \n        final PackedInts.Reader ordsReader = PackedInts.getReaderNoHeader(data, PackedInts.Format.byId(formatID), packedIntsVersion, entry.count, bitsPerValue);\n        final Norms nestedInstance = loadNorms(entry.nested);\n        \n        return new Norms() {\n          @Override\n          public long get(int docID) {\n            int ord = (int)ordsReader.get(docID);\n            try {\n              // doing a try/catch here eliminates a seemingly unavoidable branch in hotspot...\n              return decode[ord];\n            } catch (IndexOutOfBoundsException e) {\n              return nestedInstance.get(docID);\n            }\n          }\n\n          @Override\n          public long ramBytesUsed() {\n            return RamUsageEstimator.sizeOf(decode) + ordsReader.ramBytesUsed() + nestedInstance.ramBytesUsed();\n          }\n\n          @Override\n          public Collection<Accountable> getChildResources() {\n            List<Accountable> children = new ArrayList<>();\n            children.add(Accountables.namedAccountable(\"common\", ordsReader));\n            children.add(Accountables.namedAccountable(\"uncommon\", nestedInstance));\n            return Collections.unmodifiableList(children);\n          }\n\n          @Override\n          public String toString() {\n            return \"patched table\";\n          }\n        };\n      }\n      default:\n        throw new AssertionError();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"8ba6ae8e3c153347cbb605024ca7550f5c91b178":["fca6c8418a91a6d30730ad418791ddf59ec3d07a"],"96d86741fa6ad3b3a96fbf99f5e41bc74784c5f9":["8ba6ae8e3c153347cbb605024ca7550f5c91b178"],"fca6c8418a91a6d30730ad418791ddf59ec3d07a":["0c3fae32338d82a0710e1756793faba13dcb598b"],"bc8f80fee115148a0e4a0574560be06b494de821":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"9bb9a29a5e71a90295f175df8919802993142c9a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","bc8f80fee115148a0e4a0574560be06b494de821"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0c3fae32338d82a0710e1756793faba13dcb598b":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"e15c57be968dbcac6fd3f87af0bd26a8f023e069":["bc8f80fee115148a0e4a0574560be06b494de821"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["9bb9a29a5e71a90295f175df8919802993142c9a","e15c57be968dbcac6fd3f87af0bd26a8f023e069"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["96d86741fa6ad3b3a96fbf99f5e41bc74784c5f9"]},"commit2Childs":{"8ba6ae8e3c153347cbb605024ca7550f5c91b178":["96d86741fa6ad3b3a96fbf99f5e41bc74784c5f9"],"fca6c8418a91a6d30730ad418791ddf59ec3d07a":["8ba6ae8e3c153347cbb605024ca7550f5c91b178"],"96d86741fa6ad3b3a96fbf99f5e41bc74784c5f9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"bc8f80fee115148a0e4a0574560be06b494de821":["9bb9a29a5e71a90295f175df8919802993142c9a","e15c57be968dbcac6fd3f87af0bd26a8f023e069"],"9bb9a29a5e71a90295f175df8919802993142c9a":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["bc8f80fee115148a0e4a0574560be06b494de821","9bb9a29a5e71a90295f175df8919802993142c9a"],"0c3fae32338d82a0710e1756793faba13dcb598b":["fca6c8418a91a6d30730ad418791ddf59ec3d07a"],"e15c57be968dbcac6fd3f87af0bd26a8f023e069":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["0c3fae32338d82a0710e1756793faba13dcb598b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}