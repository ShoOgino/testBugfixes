{"path":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setRAMBufferSizeMB(0.5));\n      int n = atLeast(1);\n      for(int i=0;i<n;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = IndexReader.open(dir);\n      IndexSearcher searcher = new IndexSearcher(reader);\n      int totalHits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1).totalHits;\n      assertEquals(n*100, totalHits);\n      reader.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setRAMBufferSizeMB(0.5));\n      int n = atLeast(1);\n      for(int i=0;i<n;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = IndexReader.open(dir);\n      IndexSearcher searcher = new IndexSearcher(reader);\n      int totalHits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1).totalHits;\n      assertEquals(n*100, totalHits);\n      reader.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setRAMBufferSizeMB(0.5));\n      int n = atLeast(1);\n      for(int i=0;i<n;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random().nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = IndexReader.open(dir);\n      IndexSearcher searcher = new IndexSearcher(reader);\n      int totalHits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1).totalHits;\n      assertEquals(n*100, totalHits);\n      reader.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setRAMBufferSizeMB(0.5));\n      int n = atLeast(1);\n      for(int i=0;i<n;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random.nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = IndexReader.open(dir);\n      IndexSearcher searcher = new IndexSearcher(reader);\n      int totalHits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1).totalHits;\n      assertEquals(n*100, totalHits);\n      reader.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f","date":1338430031,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setRAMBufferSizeMB(0.5));\n      int n = atLeast(1);\n      for(int i=0;i<n;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random().nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = DirectoryReader.open(dir);\n      IndexSearcher searcher = new IndexSearcher(reader);\n      int totalHits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1).totalHits;\n      assertEquals(n*100, totalHits);\n      reader.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setRAMBufferSizeMB(0.5));\n      int n = atLeast(1);\n      for(int i=0;i<n;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random().nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = IndexReader.open(dir);\n      IndexSearcher searcher = new IndexSearcher(reader);\n      int totalHits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1).totalHits;\n      assertEquals(n*100, totalHits);\n      reader.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d19974432be9aed28ee7dca73bdf01d139e763a9","date":1342822166,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setRAMBufferSizeMB(0.5));\n      int n = atLeast(1);\n      for(int i=0;i<n;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random().nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = DirectoryReader.open(dir);\n      IndexSearcher searcher = new IndexSearcher(reader);\n      int totalHits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1).totalHits;\n      assertEquals(n*100, totalHits);\n      reader.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setRAMBufferSizeMB(0.5));\n      int n = atLeast(1);\n      for(int i=0;i<n;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random().nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = DirectoryReader.open(dir);\n      IndexSearcher searcher = new IndexSearcher(reader);\n      int totalHits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1).totalHits;\n      assertEquals(n*100, totalHits);\n      reader.close();\n\n      dir.close();\n    }\n\n","bugFix":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4b51f65902cc2d20ddeb7a5b949aaddf990f31a7","date":1343059585,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setRAMBufferSizeMB(0.5));\n      int n = atLeast(1);\n      for(int i=0;i<n;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random().nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = DirectoryReader.open(dir);\n      IndexSearcher searcher = new IndexSearcher(reader);\n      int totalHits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1).totalHits;\n      assertEquals(n*100, totalHits);\n      reader.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setRAMBufferSizeMB(0.5));\n      int n = atLeast(1);\n      for(int i=0;i<n;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random().nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = DirectoryReader.open(dir);\n      IndexSearcher searcher = new IndexSearcher(reader);\n      int totalHits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1).totalHits;\n      assertEquals(n*100, totalHits);\n      reader.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aba371508186796cc6151d8223a5b4e16d02e26e","date":1343474871,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setRAMBufferSizeMB(0.5));\n      int n = atLeast(1);\n      for(int i=0;i<n;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random().nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = DirectoryReader.open(dir);\n      IndexSearcher searcher = new IndexSearcher(reader);\n      int totalHits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1).totalHits;\n      assertEquals(n*100, totalHits);\n      reader.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      MockDirectoryWrapper dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setRAMBufferSizeMB(0.5));\n      int n = atLeast(1);\n      for(int i=0;i<n;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random().nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = DirectoryReader.open(dir);\n      IndexSearcher searcher = new IndexSearcher(reader);\n      int totalHits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1).totalHits;\n      assertEquals(n*100, totalHits);\n      reader.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3b0e8c39ca08b5a02de6edcd33d6f3b90b865173","date":1365631993,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setRAMBufferSizeMB(0.5));\n      int n = atLeast(1);\n      for(int i=0;i<n;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random().nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = DirectoryReader.open(dir);\n      IndexSearcher searcher = newSearcher(reader);\n      int totalHits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1).totalHits;\n      assertEquals(n*100, totalHits);\n      reader.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setRAMBufferSizeMB(0.5));\n      int n = atLeast(1);\n      for(int i=0;i<n;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random().nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = DirectoryReader.open(dir);\n      IndexSearcher searcher = new IndexSearcher(reader);\n      int totalHits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1).totalHits;\n      assertEquals(n*100, totalHits);\n      reader.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setRAMBufferSizeMB(0.5));\n      int n = atLeast(1);\n      for(int i=0;i<n;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random().nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.shutdown();\n\n      IndexReader reader = DirectoryReader.open(dir);\n      IndexSearcher searcher = newSearcher(reader);\n      int totalHits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1).totalHits;\n      assertEquals(n*100, totalHits);\n      reader.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setRAMBufferSizeMB(0.5));\n      int n = atLeast(1);\n      for(int i=0;i<n;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random().nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = DirectoryReader.open(dir);\n      IndexSearcher searcher = newSearcher(reader);\n      int totalHits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1).totalHits;\n      assertEquals(n*100, totalHits);\n      reader.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                   .setRAMBufferSizeMB(0.5));\n      int n = atLeast(1);\n      for(int i=0;i<n;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random().nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.shutdown();\n\n      IndexReader reader = DirectoryReader.open(dir);\n      IndexSearcher searcher = newSearcher(reader);\n      int totalHits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1).totalHits;\n      assertEquals(n*100, totalHits);\n      reader.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setRAMBufferSizeMB(0.5));\n      int n = atLeast(1);\n      for(int i=0;i<n;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random().nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.shutdown();\n\n      IndexReader reader = DirectoryReader.open(dir);\n      IndexSearcher searcher = newSearcher(reader);\n      int totalHits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1).totalHits;\n      assertEquals(n*100, totalHits);\n      reader.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":"    public void testDiverseDocs() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                   .setRAMBufferSizeMB(0.5));\n      int n = atLeast(1);\n      for(int i=0;i<n;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random().nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = DirectoryReader.open(dir);\n      IndexSearcher searcher = newSearcher(reader);\n      int totalHits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1).totalHits;\n      assertEquals(n*100, totalHits);\n      reader.close();\n\n      dir.close();\n    }\n\n","sourceOld":"    public void testDiverseDocs() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                   .setRAMBufferSizeMB(0.5));\n      int n = atLeast(1);\n      for(int i=0;i<n;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random().nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.shutdown();\n\n      IndexReader reader = DirectoryReader.open(dir);\n      IndexSearcher searcher = newSearcher(reader);\n      int totalHits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1).totalHits;\n      assertEquals(n*100, totalHits);\n      reader.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"57dea9cc0cdda318a986edb0250c26cee1e8bb19","date":1410398087,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testDiverseDocs().mjava","sourceNew":null,"sourceOld":"    public void testDiverseDocs() throws IOException {\n      Directory dir = newDirectory();\n      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                   .setRAMBufferSizeMB(0.5));\n      int n = atLeast(1);\n      for(int i=0;i<n;i++) {\n        // First, docs where every term is unique (heavy on\n        // Posting instances)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          for(int k=0;k<100;k++) {\n            doc.add(newField(\"field\", Integer.toString(random().nextInt()), storedTextType));\n          }\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs (heavy on byte blocks)\n        for(int j=0;j<100;j++) {\n          Document doc = new Document();\n          doc.add(newField(\"field\", \"aaa aaa aaa aaa aaa aaa aaa aaa aaa aaa\", storedTextType));\n          writer.addDocument(doc);\n        }\n\n        // Next, many single term docs where only one term\n        // occurs but the terms are very long (heavy on\n        // char[] arrays)\n        for(int j=0;j<100;j++) {\n          StringBuilder b = new StringBuilder();\n          String x = Integer.toString(j) + \".\";\n          for(int k=0;k<1000;k++)\n            b.append(x);\n          String longTerm = b.toString();\n\n          Document doc = new Document();\n          doc.add(newField(\"field\", longTerm, storedTextType));\n          writer.addDocument(doc);\n        }\n      }\n      writer.close();\n\n      IndexReader reader = DirectoryReader.open(dir);\n      IndexSearcher searcher = newSearcher(reader);\n      int totalHits = searcher.search(new TermQuery(new Term(\"field\", \"aaa\")), null, 1).totalHits;\n      assertEquals(n*100, totalHits);\n      reader.close();\n\n      dir.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3b0e8c39ca08b5a02de6edcd33d6f3b90b865173":["d19974432be9aed28ee7dca73bdf01d139e763a9"],"aba371508186796cc6151d8223a5b4e16d02e26e":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f","d19974432be9aed28ee7dca73bdf01d139e763a9"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"d19974432be9aed28ee7dca73bdf01d139e763a9":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["3b0e8c39ca08b5a02de6edcd33d6f3b90b865173"],"4b51f65902cc2d20ddeb7a5b949aaddf990f31a7":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f","d19974432be9aed28ee7dca73bdf01d139e763a9"],"57dea9cc0cdda318a986edb0250c26cee1e8bb19":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["57dea9cc0cdda318a986edb0250c26cee1e8bb19"]},"commit2Childs":{"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"3b0e8c39ca08b5a02de6edcd33d6f3b90b865173":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"aba371508186796cc6151d8223a5b4e16d02e26e":[],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["aba371508186796cc6151d8223a5b4e16d02e26e","d19974432be9aed28ee7dca73bdf01d139e763a9","4b51f65902cc2d20ddeb7a5b949aaddf990f31a7"],"d19974432be9aed28ee7dca73bdf01d139e763a9":["3b0e8c39ca08b5a02de6edcd33d6f3b90b865173","aba371508186796cc6151d8223a5b4e16d02e26e","4b51f65902cc2d20ddeb7a5b949aaddf990f31a7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["57dea9cc0cdda318a986edb0250c26cee1e8bb19"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"4b51f65902cc2d20ddeb7a5b949aaddf990f31a7":[],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"57dea9cc0cdda318a986edb0250c26cee1e8bb19":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["aba371508186796cc6151d8223a5b4e16d02e26e","4b51f65902cc2d20ddeb7a5b949aaddf990f31a7","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}