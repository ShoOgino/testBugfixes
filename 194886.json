{"path":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMultiSearcher().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMultiSearcher().mjava","pathOld":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMultiSearcher().mjava","sourceNew":"  public void testMultiSearcher() throws Exception {\n    // setup index 1\n    RAMDirectory ramDir1 = new RAMDirectory();\n    IndexWriter writer1 = new IndexWriter(ramDir1, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new StandardAnalyzer(TEST_VERSION_CURRENT)));\n    Document d = new Document();\n    Field f = new Field(FIELD_NAME, \"multiOne\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer1.addDocument(d);\n    writer1.optimize();\n    writer1.close();\n    IndexReader reader1 = IndexReader.open(ramDir1, true);\n\n    // setup index 2\n    RAMDirectory ramDir2 = new RAMDirectory();\n    IndexWriter writer2 = new IndexWriter(ramDir2, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new StandardAnalyzer(TEST_VERSION_CURRENT)));\n    d = new Document();\n    f = new Field(FIELD_NAME, \"multiTwo\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer2.addDocument(d);\n    writer2.optimize();\n    writer2.close();\n    IndexReader reader2 = IndexReader.open(ramDir2, true);\n\n    IndexSearcher searchers[] = new IndexSearcher[2];\n    searchers[0] = new IndexSearcher(ramDir1, true);\n    searchers[1] = new IndexSearcher(ramDir2, true);\n    MultiSearcher multiSearcher = new MultiSearcher(searchers);\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new StandardAnalyzer(TEST_VERSION_CURRENT));\n    parser.setMultiTermRewriteMethod(MultiTermQuery.SCORING_BOOLEAN_QUERY_REWRITE);\n    query = parser.parse(\"multi*\");\n    if (VERBOSE) System.out.println(\"Searching for: \" + query.toString(FIELD_NAME));\n    // at this point the multisearcher calls combine(query[])\n    hits = multiSearcher.search(query, null, 1000);\n\n    // query = QueryParser.parse(\"multi*\", FIELD_NAME, new StandardAnalyzer(TEST_VERSION));\n    Query expandedQueries[] = new Query[2];\n    expandedQueries[0] = query.rewrite(reader1);\n    expandedQueries[1] = query.rewrite(reader2);\n    query = query.combine(expandedQueries);\n\n    // create an instance of the highlighter with the tags used to surround\n    // highlighted text\n    Highlighter highlighter = new Highlighter(this, new QueryTermScorer(query));\n\n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = multiSearcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n      String highlightedText = highlighter.getBestFragment(tokenStream, text);\n      if (VERBOSE) System.out.println(highlightedText);\n    }\n    assertTrue(\"Failed to find correct number of highlights \" + numHighlights + \" found\",\n        numHighlights == 2);\n\n  }\n\n","sourceOld":"  public void testMultiSearcher() throws Exception {\n    // setup index 1\n    RAMDirectory ramDir1 = new RAMDirectory();\n    IndexWriter writer1 = new IndexWriter(ramDir1, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new StandardAnalyzer(TEST_VERSION_CURRENT)));\n    Document d = new Document();\n    Field f = new Field(FIELD_NAME, \"multiOne\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer1.addDocument(d);\n    writer1.optimize();\n    writer1.close();\n    IndexReader reader1 = IndexReader.open(ramDir1, true);\n\n    // setup index 2\n    RAMDirectory ramDir2 = new RAMDirectory();\n    IndexWriter writer2 = new IndexWriter(ramDir2, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new StandardAnalyzer(TEST_VERSION_CURRENT)));\n    d = new Document();\n    f = new Field(FIELD_NAME, \"multiTwo\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer2.addDocument(d);\n    writer2.optimize();\n    writer2.close();\n    IndexReader reader2 = IndexReader.open(ramDir2, true);\n\n    IndexSearcher searchers[] = new IndexSearcher[2];\n    searchers[0] = new IndexSearcher(ramDir1, true);\n    searchers[1] = new IndexSearcher(ramDir2, true);\n    MultiSearcher multiSearcher = new MultiSearcher(searchers);\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new StandardAnalyzer(TEST_VERSION_CURRENT));\n    parser.setMultiTermRewriteMethod(MultiTermQuery.SCORING_BOOLEAN_QUERY_REWRITE);\n    query = parser.parse(\"multi*\");\n    if (VERBOSE) System.out.println(\"Searching for: \" + query.toString(FIELD_NAME));\n    // at this point the multisearcher calls combine(query[])\n    hits = multiSearcher.search(query, null, 1000);\n\n    // query = QueryParser.parse(\"multi*\", FIELD_NAME, new StandardAnalyzer(TEST_VERSION));\n    Query expandedQueries[] = new Query[2];\n    expandedQueries[0] = query.rewrite(reader1);\n    expandedQueries[1] = query.rewrite(reader2);\n    query = query.combine(expandedQueries);\n\n    // create an instance of the highlighter with the tags used to surround\n    // highlighted text\n    Highlighter highlighter = new Highlighter(this, new QueryTermScorer(query));\n\n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = multiSearcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n      String highlightedText = highlighter.getBestFragment(tokenStream, text);\n      if (VERBOSE) System.out.println(highlightedText);\n    }\n    assertTrue(\"Failed to find correct number of highlights \" + numHighlights + \" found\",\n        numHighlights == 2);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7f8e68717c68517265937c911e1ce9f25750247","date":1274071103,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMultiSearcher().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMultiSearcher().mjava","sourceNew":"  public void testMultiSearcher() throws Exception {\n    // setup index 1\n    RAMDirectory ramDir1 = new RAMDirectory();\n    IndexWriter writer1 = new IndexWriter(ramDir1, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));\n    Document d = new Document();\n    Field f = new Field(FIELD_NAME, \"multiOne\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer1.addDocument(d);\n    writer1.optimize();\n    writer1.close();\n    IndexReader reader1 = IndexReader.open(ramDir1, true);\n\n    // setup index 2\n    RAMDirectory ramDir2 = new RAMDirectory();\n    IndexWriter writer2 = new IndexWriter(ramDir2, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));\n    d = new Document();\n    f = new Field(FIELD_NAME, \"multiTwo\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer2.addDocument(d);\n    writer2.optimize();\n    writer2.close();\n    IndexReader reader2 = IndexReader.open(ramDir2, true);\n\n    IndexSearcher searchers[] = new IndexSearcher[2];\n    searchers[0] = new IndexSearcher(ramDir1, true);\n    searchers[1] = new IndexSearcher(ramDir2, true);\n    MultiSearcher multiSearcher = new MultiSearcher(searchers);\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true));\n    parser.setMultiTermRewriteMethod(MultiTermQuery.SCORING_BOOLEAN_QUERY_REWRITE);\n    query = parser.parse(\"multi*\");\n    if (VERBOSE) System.out.println(\"Searching for: \" + query.toString(FIELD_NAME));\n    // at this point the multisearcher calls combine(query[])\n    hits = multiSearcher.search(query, null, 1000);\n\n    // query = QueryParser.parse(\"multi*\", FIELD_NAME, new StandardAnalyzer(TEST_VERSION));\n    Query expandedQueries[] = new Query[2];\n    expandedQueries[0] = query.rewrite(reader1);\n    expandedQueries[1] = query.rewrite(reader2);\n    query = query.combine(expandedQueries);\n\n    // create an instance of the highlighter with the tags used to surround\n    // highlighted text\n    Highlighter highlighter = new Highlighter(this, new QueryTermScorer(query));\n\n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = multiSearcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n      String highlightedText = highlighter.getBestFragment(tokenStream, text);\n      if (VERBOSE) System.out.println(highlightedText);\n    }\n    assertTrue(\"Failed to find correct number of highlights \" + numHighlights + \" found\",\n        numHighlights == 2);\n\n  }\n\n","sourceOld":"  public void testMultiSearcher() throws Exception {\n    // setup index 1\n    RAMDirectory ramDir1 = new RAMDirectory();\n    IndexWriter writer1 = new IndexWriter(ramDir1, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new StandardAnalyzer(TEST_VERSION_CURRENT)));\n    Document d = new Document();\n    Field f = new Field(FIELD_NAME, \"multiOne\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer1.addDocument(d);\n    writer1.optimize();\n    writer1.close();\n    IndexReader reader1 = IndexReader.open(ramDir1, true);\n\n    // setup index 2\n    RAMDirectory ramDir2 = new RAMDirectory();\n    IndexWriter writer2 = new IndexWriter(ramDir2, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new StandardAnalyzer(TEST_VERSION_CURRENT)));\n    d = new Document();\n    f = new Field(FIELD_NAME, \"multiTwo\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer2.addDocument(d);\n    writer2.optimize();\n    writer2.close();\n    IndexReader reader2 = IndexReader.open(ramDir2, true);\n\n    IndexSearcher searchers[] = new IndexSearcher[2];\n    searchers[0] = new IndexSearcher(ramDir1, true);\n    searchers[1] = new IndexSearcher(ramDir2, true);\n    MultiSearcher multiSearcher = new MultiSearcher(searchers);\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new StandardAnalyzer(TEST_VERSION_CURRENT));\n    parser.setMultiTermRewriteMethod(MultiTermQuery.SCORING_BOOLEAN_QUERY_REWRITE);\n    query = parser.parse(\"multi*\");\n    if (VERBOSE) System.out.println(\"Searching for: \" + query.toString(FIELD_NAME));\n    // at this point the multisearcher calls combine(query[])\n    hits = multiSearcher.search(query, null, 1000);\n\n    // query = QueryParser.parse(\"multi*\", FIELD_NAME, new StandardAnalyzer(TEST_VERSION));\n    Query expandedQueries[] = new Query[2];\n    expandedQueries[0] = query.rewrite(reader1);\n    expandedQueries[1] = query.rewrite(reader2);\n    query = query.combine(expandedQueries);\n\n    // create an instance of the highlighter with the tags used to surround\n    // highlighted text\n    Highlighter highlighter = new Highlighter(this, new QueryTermScorer(query));\n\n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = multiSearcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n      String highlightedText = highlighter.getBestFragment(tokenStream, text);\n      if (VERBOSE) System.out.println(highlightedText);\n    }\n    assertTrue(\"Failed to find correct number of highlights \" + numHighlights + \" found\",\n        numHighlights == 2);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c","date":1281477834,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMultiSearcher().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMultiSearcher().mjava","sourceNew":"  public void testMultiSearcher() throws Exception {\n    // setup index 1\n    MockRAMDirectory ramDir1 = new MockRAMDirectory();\n    IndexWriter writer1 = new IndexWriter(ramDir1, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));\n    Document d = new Document();\n    Field f = new Field(FIELD_NAME, \"multiOne\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer1.addDocument(d);\n    writer1.optimize();\n    writer1.close();\n    IndexReader reader1 = IndexReader.open(ramDir1, true);\n\n    // setup index 2\n    MockRAMDirectory ramDir2 = new MockRAMDirectory();\n    IndexWriter writer2 = new IndexWriter(ramDir2, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));\n    d = new Document();\n    f = new Field(FIELD_NAME, \"multiTwo\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer2.addDocument(d);\n    writer2.optimize();\n    writer2.close();\n    IndexReader reader2 = IndexReader.open(ramDir2, true);\n\n    IndexSearcher searchers[] = new IndexSearcher[2];\n    searchers[0] = new IndexSearcher(ramDir1, true);\n    searchers[1] = new IndexSearcher(ramDir2, true);\n    MultiSearcher multiSearcher = new MultiSearcher(searchers);\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true));\n    parser.setMultiTermRewriteMethod(MultiTermQuery.SCORING_BOOLEAN_QUERY_REWRITE);\n    query = parser.parse(\"multi*\");\n    if (VERBOSE) System.out.println(\"Searching for: \" + query.toString(FIELD_NAME));\n    // at this point the multisearcher calls combine(query[])\n    hits = multiSearcher.search(query, null, 1000);\n\n    // query = QueryParser.parse(\"multi*\", FIELD_NAME, new StandardAnalyzer(TEST_VERSION));\n    Query expandedQueries[] = new Query[2];\n    expandedQueries[0] = query.rewrite(reader1);\n    expandedQueries[1] = query.rewrite(reader2);\n    query = query.combine(expandedQueries);\n\n    // create an instance of the highlighter with the tags used to surround\n    // highlighted text\n    Highlighter highlighter = new Highlighter(this, new QueryTermScorer(query));\n\n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = multiSearcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n      String highlightedText = highlighter.getBestFragment(tokenStream, text);\n      if (VERBOSE) System.out.println(highlightedText);\n    }\n    assertTrue(\"Failed to find correct number of highlights \" + numHighlights + \" found\",\n        numHighlights == 2);\n\n  }\n\n","sourceOld":"  public void testMultiSearcher() throws Exception {\n    // setup index 1\n    RAMDirectory ramDir1 = new RAMDirectory();\n    IndexWriter writer1 = new IndexWriter(ramDir1, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));\n    Document d = new Document();\n    Field f = new Field(FIELD_NAME, \"multiOne\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer1.addDocument(d);\n    writer1.optimize();\n    writer1.close();\n    IndexReader reader1 = IndexReader.open(ramDir1, true);\n\n    // setup index 2\n    RAMDirectory ramDir2 = new RAMDirectory();\n    IndexWriter writer2 = new IndexWriter(ramDir2, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));\n    d = new Document();\n    f = new Field(FIELD_NAME, \"multiTwo\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer2.addDocument(d);\n    writer2.optimize();\n    writer2.close();\n    IndexReader reader2 = IndexReader.open(ramDir2, true);\n\n    IndexSearcher searchers[] = new IndexSearcher[2];\n    searchers[0] = new IndexSearcher(ramDir1, true);\n    searchers[1] = new IndexSearcher(ramDir2, true);\n    MultiSearcher multiSearcher = new MultiSearcher(searchers);\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true));\n    parser.setMultiTermRewriteMethod(MultiTermQuery.SCORING_BOOLEAN_QUERY_REWRITE);\n    query = parser.parse(\"multi*\");\n    if (VERBOSE) System.out.println(\"Searching for: \" + query.toString(FIELD_NAME));\n    // at this point the multisearcher calls combine(query[])\n    hits = multiSearcher.search(query, null, 1000);\n\n    // query = QueryParser.parse(\"multi*\", FIELD_NAME, new StandardAnalyzer(TEST_VERSION));\n    Query expandedQueries[] = new Query[2];\n    expandedQueries[0] = query.rewrite(reader1);\n    expandedQueries[1] = query.rewrite(reader2);\n    query = query.combine(expandedQueries);\n\n    // create an instance of the highlighter with the tags used to surround\n    // highlighted text\n    Highlighter highlighter = new Highlighter(this, new QueryTermScorer(query));\n\n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = multiSearcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n      String highlightedText = highlighter.getBestFragment(tokenStream, text);\n      if (VERBOSE) System.out.println(highlightedText);\n    }\n    assertTrue(\"Failed to find correct number of highlights \" + numHighlights + \" found\",\n        numHighlights == 2);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","date":1281646583,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMultiSearcher().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMultiSearcher().mjava","sourceNew":"  public void testMultiSearcher() throws Exception {\n    // setup index 1\n    MockRAMDirectory ramDir1 = newDirectory(random);\n    IndexWriter writer1 = new IndexWriter(ramDir1, newIndexWriterConfig(random,\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));\n    Document d = new Document();\n    Field f = new Field(FIELD_NAME, \"multiOne\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer1.addDocument(d);\n    writer1.optimize();\n    writer1.close();\n    IndexReader reader1 = IndexReader.open(ramDir1, true);\n\n    // setup index 2\n    MockRAMDirectory ramDir2 = newDirectory(random);\n    IndexWriter writer2 = new IndexWriter(ramDir2, newIndexWriterConfig(random,\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));\n    d = new Document();\n    f = new Field(FIELD_NAME, \"multiTwo\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer2.addDocument(d);\n    writer2.optimize();\n    writer2.close();\n    IndexReader reader2 = IndexReader.open(ramDir2, true);\n\n    IndexSearcher searchers[] = new IndexSearcher[2];\n    searchers[0] = new IndexSearcher(ramDir1, true);\n    searchers[1] = new IndexSearcher(ramDir2, true);\n    MultiSearcher multiSearcher = new MultiSearcher(searchers);\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true));\n    parser.setMultiTermRewriteMethod(MultiTermQuery.SCORING_BOOLEAN_QUERY_REWRITE);\n    query = parser.parse(\"multi*\");\n    if (VERBOSE) System.out.println(\"Searching for: \" + query.toString(FIELD_NAME));\n    // at this point the multisearcher calls combine(query[])\n    hits = multiSearcher.search(query, null, 1000);\n\n    // query = QueryParser.parse(\"multi*\", FIELD_NAME, new StandardAnalyzer(TEST_VERSION));\n    Query expandedQueries[] = new Query[2];\n    expandedQueries[0] = query.rewrite(reader1);\n    expandedQueries[1] = query.rewrite(reader2);\n    query = query.combine(expandedQueries);\n\n    // create an instance of the highlighter with the tags used to surround\n    // highlighted text\n    Highlighter highlighter = new Highlighter(this, new QueryTermScorer(query));\n\n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = multiSearcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n      String highlightedText = highlighter.getBestFragment(tokenStream, text);\n      if (VERBOSE) System.out.println(highlightedText);\n    }\n    assertTrue(\"Failed to find correct number of highlights \" + numHighlights + \" found\",\n        numHighlights == 2);\n    reader1.close();\n    reader2.close();\n    searchers[0].close();\n    searchers[1].close();\n    ramDir1.close();\n    ramDir2.close();\n  }\n\n","sourceOld":"  public void testMultiSearcher() throws Exception {\n    // setup index 1\n    MockRAMDirectory ramDir1 = new MockRAMDirectory();\n    IndexWriter writer1 = new IndexWriter(ramDir1, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));\n    Document d = new Document();\n    Field f = new Field(FIELD_NAME, \"multiOne\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer1.addDocument(d);\n    writer1.optimize();\n    writer1.close();\n    IndexReader reader1 = IndexReader.open(ramDir1, true);\n\n    // setup index 2\n    MockRAMDirectory ramDir2 = new MockRAMDirectory();\n    IndexWriter writer2 = new IndexWriter(ramDir2, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));\n    d = new Document();\n    f = new Field(FIELD_NAME, \"multiTwo\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer2.addDocument(d);\n    writer2.optimize();\n    writer2.close();\n    IndexReader reader2 = IndexReader.open(ramDir2, true);\n\n    IndexSearcher searchers[] = new IndexSearcher[2];\n    searchers[0] = new IndexSearcher(ramDir1, true);\n    searchers[1] = new IndexSearcher(ramDir2, true);\n    MultiSearcher multiSearcher = new MultiSearcher(searchers);\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true));\n    parser.setMultiTermRewriteMethod(MultiTermQuery.SCORING_BOOLEAN_QUERY_REWRITE);\n    query = parser.parse(\"multi*\");\n    if (VERBOSE) System.out.println(\"Searching for: \" + query.toString(FIELD_NAME));\n    // at this point the multisearcher calls combine(query[])\n    hits = multiSearcher.search(query, null, 1000);\n\n    // query = QueryParser.parse(\"multi*\", FIELD_NAME, new StandardAnalyzer(TEST_VERSION));\n    Query expandedQueries[] = new Query[2];\n    expandedQueries[0] = query.rewrite(reader1);\n    expandedQueries[1] = query.rewrite(reader2);\n    query = query.combine(expandedQueries);\n\n    // create an instance of the highlighter with the tags used to surround\n    // highlighted text\n    Highlighter highlighter = new Highlighter(this, new QueryTermScorer(query));\n\n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = multiSearcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n      String highlightedText = highlighter.getBestFragment(tokenStream, text);\n      if (VERBOSE) System.out.println(highlightedText);\n    }\n    assertTrue(\"Failed to find correct number of highlights \" + numHighlights + \" found\",\n        numHighlights == 2);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a05409176bd65129d67a785ee70e881e238a9aef","date":1282582843,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMultiSearcher().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMultiSearcher().mjava","sourceNew":"  public void testMultiSearcher() throws Exception {\n    // setup index 1\n    Directory ramDir1 = newDirectory(random);\n    IndexWriter writer1 = new IndexWriter(ramDir1, newIndexWriterConfig(random,\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));\n    Document d = new Document();\n    Field f = new Field(FIELD_NAME, \"multiOne\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer1.addDocument(d);\n    writer1.optimize();\n    writer1.close();\n    IndexReader reader1 = IndexReader.open(ramDir1, true);\n\n    // setup index 2\n    Directory ramDir2 = newDirectory(random);\n    IndexWriter writer2 = new IndexWriter(ramDir2, newIndexWriterConfig(random,\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));\n    d = new Document();\n    f = new Field(FIELD_NAME, \"multiTwo\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer2.addDocument(d);\n    writer2.optimize();\n    writer2.close();\n    IndexReader reader2 = IndexReader.open(ramDir2, true);\n\n    IndexSearcher searchers[] = new IndexSearcher[2];\n    searchers[0] = new IndexSearcher(ramDir1, true);\n    searchers[1] = new IndexSearcher(ramDir2, true);\n    MultiSearcher multiSearcher = new MultiSearcher(searchers);\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true));\n    parser.setMultiTermRewriteMethod(MultiTermQuery.SCORING_BOOLEAN_QUERY_REWRITE);\n    query = parser.parse(\"multi*\");\n    if (VERBOSE) System.out.println(\"Searching for: \" + query.toString(FIELD_NAME));\n    // at this point the multisearcher calls combine(query[])\n    hits = multiSearcher.search(query, null, 1000);\n\n    // query = QueryParser.parse(\"multi*\", FIELD_NAME, new StandardAnalyzer(TEST_VERSION));\n    Query expandedQueries[] = new Query[2];\n    expandedQueries[0] = query.rewrite(reader1);\n    expandedQueries[1] = query.rewrite(reader2);\n    query = query.combine(expandedQueries);\n\n    // create an instance of the highlighter with the tags used to surround\n    // highlighted text\n    Highlighter highlighter = new Highlighter(this, new QueryTermScorer(query));\n\n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = multiSearcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n      String highlightedText = highlighter.getBestFragment(tokenStream, text);\n      if (VERBOSE) System.out.println(highlightedText);\n    }\n    assertTrue(\"Failed to find correct number of highlights \" + numHighlights + \" found\",\n        numHighlights == 2);\n    reader1.close();\n    reader2.close();\n    searchers[0].close();\n    searchers[1].close();\n    ramDir1.close();\n    ramDir2.close();\n  }\n\n","sourceOld":"  public void testMultiSearcher() throws Exception {\n    // setup index 1\n    MockRAMDirectory ramDir1 = newDirectory(random);\n    IndexWriter writer1 = new IndexWriter(ramDir1, newIndexWriterConfig(random,\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));\n    Document d = new Document();\n    Field f = new Field(FIELD_NAME, \"multiOne\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer1.addDocument(d);\n    writer1.optimize();\n    writer1.close();\n    IndexReader reader1 = IndexReader.open(ramDir1, true);\n\n    // setup index 2\n    MockRAMDirectory ramDir2 = newDirectory(random);\n    IndexWriter writer2 = new IndexWriter(ramDir2, newIndexWriterConfig(random,\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));\n    d = new Document();\n    f = new Field(FIELD_NAME, \"multiTwo\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer2.addDocument(d);\n    writer2.optimize();\n    writer2.close();\n    IndexReader reader2 = IndexReader.open(ramDir2, true);\n\n    IndexSearcher searchers[] = new IndexSearcher[2];\n    searchers[0] = new IndexSearcher(ramDir1, true);\n    searchers[1] = new IndexSearcher(ramDir2, true);\n    MultiSearcher multiSearcher = new MultiSearcher(searchers);\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true));\n    parser.setMultiTermRewriteMethod(MultiTermQuery.SCORING_BOOLEAN_QUERY_REWRITE);\n    query = parser.parse(\"multi*\");\n    if (VERBOSE) System.out.println(\"Searching for: \" + query.toString(FIELD_NAME));\n    // at this point the multisearcher calls combine(query[])\n    hits = multiSearcher.search(query, null, 1000);\n\n    // query = QueryParser.parse(\"multi*\", FIELD_NAME, new StandardAnalyzer(TEST_VERSION));\n    Query expandedQueries[] = new Query[2];\n    expandedQueries[0] = query.rewrite(reader1);\n    expandedQueries[1] = query.rewrite(reader2);\n    query = query.combine(expandedQueries);\n\n    // create an instance of the highlighter with the tags used to surround\n    // highlighted text\n    Highlighter highlighter = new Highlighter(this, new QueryTermScorer(query));\n\n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = multiSearcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n      String highlightedText = highlighter.getBestFragment(tokenStream, text);\n      if (VERBOSE) System.out.println(highlightedText);\n    }\n    assertTrue(\"Failed to find correct number of highlights \" + numHighlights + \" found\",\n        numHighlights == 2);\n    reader1.close();\n    reader2.close();\n    searchers[0].close();\n    searchers[1].close();\n    ramDir1.close();\n    ramDir2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f653cfcf159baeaafe5d01682a911e95bba4012","date":1284122058,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMultiSearcher().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMultiSearcher().mjava","sourceNew":"  public void testMultiSearcher() throws Exception {\n    // setup index 1\n    Directory ramDir1 = newDirectory();\n    IndexWriter writer1 = new IndexWriter(ramDir1, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));\n    Document d = new Document();\n    Field f = new Field(FIELD_NAME, \"multiOne\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer1.addDocument(d);\n    writer1.optimize();\n    writer1.close();\n    IndexReader reader1 = IndexReader.open(ramDir1, true);\n\n    // setup index 2\n    Directory ramDir2 = newDirectory();\n    IndexWriter writer2 = new IndexWriter(ramDir2, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));\n    d = new Document();\n    f = new Field(FIELD_NAME, \"multiTwo\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer2.addDocument(d);\n    writer2.optimize();\n    writer2.close();\n    IndexReader reader2 = IndexReader.open(ramDir2, true);\n\n    IndexSearcher searchers[] = new IndexSearcher[2];\n    searchers[0] = new IndexSearcher(ramDir1, true);\n    searchers[1] = new IndexSearcher(ramDir2, true);\n    MultiSearcher multiSearcher = new MultiSearcher(searchers);\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true));\n    parser.setMultiTermRewriteMethod(MultiTermQuery.SCORING_BOOLEAN_QUERY_REWRITE);\n    query = parser.parse(\"multi*\");\n    if (VERBOSE) System.out.println(\"Searching for: \" + query.toString(FIELD_NAME));\n    // at this point the multisearcher calls combine(query[])\n    hits = multiSearcher.search(query, null, 1000);\n\n    // query = QueryParser.parse(\"multi*\", FIELD_NAME, new StandardAnalyzer(TEST_VERSION));\n    Query expandedQueries[] = new Query[2];\n    expandedQueries[0] = query.rewrite(reader1);\n    expandedQueries[1] = query.rewrite(reader2);\n    query = query.combine(expandedQueries);\n\n    // create an instance of the highlighter with the tags used to surround\n    // highlighted text\n    Highlighter highlighter = new Highlighter(this, new QueryTermScorer(query));\n\n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = multiSearcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n      String highlightedText = highlighter.getBestFragment(tokenStream, text);\n      if (VERBOSE) System.out.println(highlightedText);\n    }\n    assertTrue(\"Failed to find correct number of highlights \" + numHighlights + \" found\",\n        numHighlights == 2);\n    reader1.close();\n    reader2.close();\n    searchers[0].close();\n    searchers[1].close();\n    ramDir1.close();\n    ramDir2.close();\n  }\n\n","sourceOld":"  public void testMultiSearcher() throws Exception {\n    // setup index 1\n    Directory ramDir1 = newDirectory(random);\n    IndexWriter writer1 = new IndexWriter(ramDir1, newIndexWriterConfig(random,\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));\n    Document d = new Document();\n    Field f = new Field(FIELD_NAME, \"multiOne\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer1.addDocument(d);\n    writer1.optimize();\n    writer1.close();\n    IndexReader reader1 = IndexReader.open(ramDir1, true);\n\n    // setup index 2\n    Directory ramDir2 = newDirectory(random);\n    IndexWriter writer2 = new IndexWriter(ramDir2, newIndexWriterConfig(random,\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));\n    d = new Document();\n    f = new Field(FIELD_NAME, \"multiTwo\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer2.addDocument(d);\n    writer2.optimize();\n    writer2.close();\n    IndexReader reader2 = IndexReader.open(ramDir2, true);\n\n    IndexSearcher searchers[] = new IndexSearcher[2];\n    searchers[0] = new IndexSearcher(ramDir1, true);\n    searchers[1] = new IndexSearcher(ramDir2, true);\n    MultiSearcher multiSearcher = new MultiSearcher(searchers);\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true));\n    parser.setMultiTermRewriteMethod(MultiTermQuery.SCORING_BOOLEAN_QUERY_REWRITE);\n    query = parser.parse(\"multi*\");\n    if (VERBOSE) System.out.println(\"Searching for: \" + query.toString(FIELD_NAME));\n    // at this point the multisearcher calls combine(query[])\n    hits = multiSearcher.search(query, null, 1000);\n\n    // query = QueryParser.parse(\"multi*\", FIELD_NAME, new StandardAnalyzer(TEST_VERSION));\n    Query expandedQueries[] = new Query[2];\n    expandedQueries[0] = query.rewrite(reader1);\n    expandedQueries[1] = query.rewrite(reader2);\n    query = query.combine(expandedQueries);\n\n    // create an instance of the highlighter with the tags used to surround\n    // highlighted text\n    Highlighter highlighter = new Highlighter(this, new QueryTermScorer(query));\n\n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = multiSearcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n      String highlightedText = highlighter.getBestFragment(tokenStream, text);\n      if (VERBOSE) System.out.println(highlightedText);\n    }\n    assertTrue(\"Failed to find correct number of highlights \" + numHighlights + \" found\",\n        numHighlights == 2);\n    reader1.close();\n    reader2.close();\n    searchers[0].close();\n    searchers[1].close();\n    ramDir1.close();\n    ramDir2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMultiSearcher().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMultiSearcher().mjava","sourceNew":"  public void testMultiSearcher() throws Exception {\n    // setup index 1\n    Directory ramDir1 = newDirectory();\n    IndexWriter writer1 = new IndexWriter(ramDir1, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));\n    Document d = new Document();\n    Field f = new Field(FIELD_NAME, \"multiOne\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer1.addDocument(d);\n    writer1.optimize();\n    writer1.close();\n    IndexReader reader1 = IndexReader.open(ramDir1, true);\n\n    // setup index 2\n    Directory ramDir2 = newDirectory();\n    IndexWriter writer2 = new IndexWriter(ramDir2, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));\n    d = new Document();\n    f = new Field(FIELD_NAME, \"multiTwo\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer2.addDocument(d);\n    writer2.optimize();\n    writer2.close();\n    IndexReader reader2 = IndexReader.open(ramDir2, true);\n\n    IndexSearcher searchers[] = new IndexSearcher[2];\n    searchers[0] = new IndexSearcher(ramDir1, true);\n    searchers[1] = new IndexSearcher(ramDir2, true);\n    MultiSearcher multiSearcher = new MultiSearcher(searchers);\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true));\n    parser.setMultiTermRewriteMethod(MultiTermQuery.SCORING_BOOLEAN_QUERY_REWRITE);\n    query = parser.parse(\"multi*\");\n    if (VERBOSE) System.out.println(\"Searching for: \" + query.toString(FIELD_NAME));\n    // at this point the multisearcher calls combine(query[])\n    hits = multiSearcher.search(query, null, 1000);\n\n    // query = QueryParser.parse(\"multi*\", FIELD_NAME, new StandardAnalyzer(TEST_VERSION));\n    Query expandedQueries[] = new Query[2];\n    expandedQueries[0] = query.rewrite(reader1);\n    expandedQueries[1] = query.rewrite(reader2);\n    query = query.combine(expandedQueries);\n\n    // create an instance of the highlighter with the tags used to surround\n    // highlighted text\n    Highlighter highlighter = new Highlighter(this, new QueryTermScorer(query));\n\n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = multiSearcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n      String highlightedText = highlighter.getBestFragment(tokenStream, text);\n      if (VERBOSE) System.out.println(highlightedText);\n    }\n    assertTrue(\"Failed to find correct number of highlights \" + numHighlights + \" found\",\n        numHighlights == 2);\n    reader1.close();\n    reader2.close();\n    searchers[0].close();\n    searchers[1].close();\n    ramDir1.close();\n    ramDir2.close();\n  }\n\n","sourceOld":"  public void testMultiSearcher() throws Exception {\n    // setup index 1\n    RAMDirectory ramDir1 = new RAMDirectory();\n    IndexWriter writer1 = new IndexWriter(ramDir1, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));\n    Document d = new Document();\n    Field f = new Field(FIELD_NAME, \"multiOne\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer1.addDocument(d);\n    writer1.optimize();\n    writer1.close();\n    IndexReader reader1 = IndexReader.open(ramDir1, true);\n\n    // setup index 2\n    RAMDirectory ramDir2 = new RAMDirectory();\n    IndexWriter writer2 = new IndexWriter(ramDir2, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));\n    d = new Document();\n    f = new Field(FIELD_NAME, \"multiTwo\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer2.addDocument(d);\n    writer2.optimize();\n    writer2.close();\n    IndexReader reader2 = IndexReader.open(ramDir2, true);\n\n    IndexSearcher searchers[] = new IndexSearcher[2];\n    searchers[0] = new IndexSearcher(ramDir1, true);\n    searchers[1] = new IndexSearcher(ramDir2, true);\n    MultiSearcher multiSearcher = new MultiSearcher(searchers);\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true));\n    parser.setMultiTermRewriteMethod(MultiTermQuery.SCORING_BOOLEAN_QUERY_REWRITE);\n    query = parser.parse(\"multi*\");\n    if (VERBOSE) System.out.println(\"Searching for: \" + query.toString(FIELD_NAME));\n    // at this point the multisearcher calls combine(query[])\n    hits = multiSearcher.search(query, null, 1000);\n\n    // query = QueryParser.parse(\"multi*\", FIELD_NAME, new StandardAnalyzer(TEST_VERSION));\n    Query expandedQueries[] = new Query[2];\n    expandedQueries[0] = query.rewrite(reader1);\n    expandedQueries[1] = query.rewrite(reader2);\n    query = query.combine(expandedQueries);\n\n    // create an instance of the highlighter with the tags used to surround\n    // highlighted text\n    Highlighter highlighter = new Highlighter(this, new QueryTermScorer(query));\n\n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = multiSearcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n      String highlightedText = highlighter.getBestFragment(tokenStream, text);\n      if (VERBOSE) System.out.println(highlightedText);\n    }\n    assertTrue(\"Failed to find correct number of highlights \" + numHighlights + \" found\",\n        numHighlights == 2);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8b241ea5e635d896cc0af83cd96ffd0322e0aba7","date":1294226200,"type":4,"author":"Michael McCandless","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMultiSearcher().mjava","sourceNew":null,"sourceOld":"  public void testMultiSearcher() throws Exception {\n    // setup index 1\n    Directory ramDir1 = newDirectory();\n    IndexWriter writer1 = new IndexWriter(ramDir1, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));\n    Document d = new Document();\n    Field f = new Field(FIELD_NAME, \"multiOne\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer1.addDocument(d);\n    writer1.optimize();\n    writer1.close();\n    IndexReader reader1 = IndexReader.open(ramDir1, true);\n\n    // setup index 2\n    Directory ramDir2 = newDirectory();\n    IndexWriter writer2 = new IndexWriter(ramDir2, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));\n    d = new Document();\n    f = new Field(FIELD_NAME, \"multiTwo\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer2.addDocument(d);\n    writer2.optimize();\n    writer2.close();\n    IndexReader reader2 = IndexReader.open(ramDir2, true);\n\n    IndexSearcher searchers[] = new IndexSearcher[2];\n    searchers[0] = new IndexSearcher(ramDir1, true);\n    searchers[1] = new IndexSearcher(ramDir2, true);\n    MultiSearcher multiSearcher = new MultiSearcher(searchers);\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true));\n    parser.setMultiTermRewriteMethod(MultiTermQuery.SCORING_BOOLEAN_QUERY_REWRITE);\n    query = parser.parse(\"multi*\");\n    if (VERBOSE) System.out.println(\"Searching for: \" + query.toString(FIELD_NAME));\n    // at this point the multisearcher calls combine(query[])\n    hits = multiSearcher.search(query, null, 1000);\n\n    // query = QueryParser.parse(\"multi*\", FIELD_NAME, new StandardAnalyzer(TEST_VERSION));\n    Query expandedQueries[] = new Query[2];\n    expandedQueries[0] = query.rewrite(reader1);\n    expandedQueries[1] = query.rewrite(reader2);\n    query = query.combine(expandedQueries);\n\n    // create an instance of the highlighter with the tags used to surround\n    // highlighted text\n    Highlighter highlighter = new Highlighter(this, new QueryTermScorer(query));\n\n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = multiSearcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n      String highlightedText = highlighter.getBestFragment(tokenStream, text);\n      if (VERBOSE) System.out.println(highlightedText);\n    }\n    assertTrue(\"Failed to find correct number of highlights \" + numHighlights + \" found\",\n        numHighlights == 2);\n    reader1.close();\n    reader2.close();\n    searchers[0].close();\n    searchers[1].close();\n    ramDir1.close();\n    ramDir2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70ad682703b8585f5d0a637efec044d57ec05efb","date":1294259117,"type":4,"author":"Simon Willnauer","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMultiSearcher().mjava","sourceNew":null,"sourceOld":"  public void testMultiSearcher() throws Exception {\n    // setup index 1\n    Directory ramDir1 = newDirectory();\n    IndexWriter writer1 = new IndexWriter(ramDir1, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));\n    Document d = new Document();\n    Field f = new Field(FIELD_NAME, \"multiOne\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer1.addDocument(d);\n    writer1.optimize();\n    writer1.close();\n    IndexReader reader1 = IndexReader.open(ramDir1, true);\n\n    // setup index 2\n    Directory ramDir2 = newDirectory();\n    IndexWriter writer2 = new IndexWriter(ramDir2, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));\n    d = new Document();\n    f = new Field(FIELD_NAME, \"multiTwo\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer2.addDocument(d);\n    writer2.optimize();\n    writer2.close();\n    IndexReader reader2 = IndexReader.open(ramDir2, true);\n\n    IndexSearcher searchers[] = new IndexSearcher[2];\n    searchers[0] = new IndexSearcher(ramDir1, true);\n    searchers[1] = new IndexSearcher(ramDir2, true);\n    MultiSearcher multiSearcher = new MultiSearcher(searchers);\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true));\n    parser.setMultiTermRewriteMethod(MultiTermQuery.SCORING_BOOLEAN_QUERY_REWRITE);\n    query = parser.parse(\"multi*\");\n    if (VERBOSE) System.out.println(\"Searching for: \" + query.toString(FIELD_NAME));\n    // at this point the multisearcher calls combine(query[])\n    hits = multiSearcher.search(query, null, 1000);\n\n    // query = QueryParser.parse(\"multi*\", FIELD_NAME, new StandardAnalyzer(TEST_VERSION));\n    Query expandedQueries[] = new Query[2];\n    expandedQueries[0] = query.rewrite(reader1);\n    expandedQueries[1] = query.rewrite(reader2);\n    query = query.combine(expandedQueries);\n\n    // create an instance of the highlighter with the tags used to surround\n    // highlighted text\n    Highlighter highlighter = new Highlighter(this, new QueryTermScorer(query));\n\n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = multiSearcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n      String highlightedText = highlighter.getBestFragment(tokenStream, text);\n      if (VERBOSE) System.out.println(highlightedText);\n    }\n    assertTrue(\"Failed to find correct number of highlights \" + numHighlights + \" found\",\n        numHighlights == 2);\n    reader1.close();\n    reader2.close();\n    searchers[0].close();\n    searchers[1].close();\n    ramDir1.close();\n    ramDir2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":4,"author":"Michael Busch","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMultiSearcher().mjava","sourceNew":null,"sourceOld":"  public void testMultiSearcher() throws Exception {\n    // setup index 1\n    Directory ramDir1 = newDirectory();\n    IndexWriter writer1 = new IndexWriter(ramDir1, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));\n    Document d = new Document();\n    Field f = new Field(FIELD_NAME, \"multiOne\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer1.addDocument(d);\n    writer1.optimize();\n    writer1.close();\n    IndexReader reader1 = IndexReader.open(ramDir1, true);\n\n    // setup index 2\n    Directory ramDir2 = newDirectory();\n    IndexWriter writer2 = new IndexWriter(ramDir2, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));\n    d = new Document();\n    f = new Field(FIELD_NAME, \"multiTwo\", Field.Store.YES, Field.Index.ANALYZED);\n    d.add(f);\n    writer2.addDocument(d);\n    writer2.optimize();\n    writer2.close();\n    IndexReader reader2 = IndexReader.open(ramDir2, true);\n\n    IndexSearcher searchers[] = new IndexSearcher[2];\n    searchers[0] = new IndexSearcher(ramDir1, true);\n    searchers[1] = new IndexSearcher(ramDir2, true);\n    MultiSearcher multiSearcher = new MultiSearcher(searchers);\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true));\n    parser.setMultiTermRewriteMethod(MultiTermQuery.SCORING_BOOLEAN_QUERY_REWRITE);\n    query = parser.parse(\"multi*\");\n    if (VERBOSE) System.out.println(\"Searching for: \" + query.toString(FIELD_NAME));\n    // at this point the multisearcher calls combine(query[])\n    hits = multiSearcher.search(query, null, 1000);\n\n    // query = QueryParser.parse(\"multi*\", FIELD_NAME, new StandardAnalyzer(TEST_VERSION));\n    Query expandedQueries[] = new Query[2];\n    expandedQueries[0] = query.rewrite(reader1);\n    expandedQueries[1] = query.rewrite(reader2);\n    query = query.combine(expandedQueries);\n\n    // create an instance of the highlighter with the tags used to surround\n    // highlighted text\n    Highlighter highlighter = new Highlighter(this, new QueryTermScorer(query));\n\n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = multiSearcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n      String highlightedText = highlighter.getBestFragment(tokenStream, text);\n      if (VERBOSE) System.out.println(highlightedText);\n    }\n    assertTrue(\"Failed to find correct number of highlights \" + numHighlights + \" found\",\n        numHighlights == 2);\n    reader1.close();\n    reader2.close();\n    searchers[0].close();\n    searchers[1].close();\n    ramDir1.close();\n    ramDir2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"70ad682703b8585f5d0a637efec044d57ec05efb":["1f653cfcf159baeaafe5d01682a911e95bba4012","8b241ea5e635d896cc0af83cd96ffd0322e0aba7"],"8b241ea5e635d896cc0af83cd96ffd0322e0aba7":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["a05409176bd65129d67a785ee70e881e238a9aef"],"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c":["c7f8e68717c68517265937c911e1ce9f25750247"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a05409176bd65129d67a785ee70e881e238a9aef":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"c7f8e68717c68517265937c911e1ce9f25750247":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["c7f8e68717c68517265937c911e1ce9f25750247","1f653cfcf159baeaafe5d01682a911e95bba4012"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","8b241ea5e635d896cc0af83cd96ffd0322e0aba7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["8b241ea5e635d896cc0af83cd96ffd0322e0aba7"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"70ad682703b8585f5d0a637efec044d57ec05efb":[],"8b241ea5e635d896cc0af83cd96ffd0322e0aba7":["70ad682703b8585f5d0a637efec044d57ec05efb","868da859b43505d9d2a023bfeae6dd0c795f5295","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["a05409176bd65129d67a785ee70e881e238a9aef"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["70ad682703b8585f5d0a637efec044d57ec05efb","8b241ea5e635d896cc0af83cd96ffd0322e0aba7","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a05409176bd65129d67a785ee70e881e238a9aef":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"c7f8e68717c68517265937c911e1ce9f25750247":["1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["868da859b43505d9d2a023bfeae6dd0c795f5295"],"868da859b43505d9d2a023bfeae6dd0c795f5295":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["c7f8e68717c68517265937c911e1ce9f25750247"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["70ad682703b8585f5d0a637efec044d57ec05efb","868da859b43505d9d2a023bfeae6dd0c795f5295","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}