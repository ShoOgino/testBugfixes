{"path":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/values/SortedBytesMergeUtils#mergeRecords(MergeContext,IndexOutput,List[SortedSourceSlice]).mjava","commits":[{"id":"f9efc72acdea22f5285be0a808f8bba51bb8e367","date":1323217280,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/values/SortedBytesMergeUtils#mergeRecords(MergeContext,IndexOutput,List[SortedSourceSlice]).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/values/SortedBytesMergeUtils#mergeRecords(MergeContext,IndexOutput,List[SortedSourceSlice]).mjava","sourceNew":"  static int mergeRecords(MergeContext ctx, IndexOutput datOut,\n      List<SortedSourceSlice> slices) throws IOException {\n    final RecordMerger merger = new RecordMerger(new MergeQueue(slices.size(),\n        ctx.comp), slices.toArray(new SortedSourceSlice[0]));\n    long[] offsets = ctx.offsets;\n    final boolean recordOffsets = offsets != null;\n    long offset = 0;\n    BytesRef currentMergedBytes;\n    merger.pushTop();\n    while (merger.queue.size() > 0) {\n      merger.pullTop();\n      currentMergedBytes = merger.current;\n      assert ctx.sizePerValues == -1 || ctx.sizePerValues == currentMergedBytes.length : \"size: \"\n          + ctx.sizePerValues + \" spare: \" + currentMergedBytes.length;\n\n      if (recordOffsets) {\n        offset += currentMergedBytes.length;\n        if (merger.currentOrd >= offsets.length) {\n          offsets = ArrayUtil.grow(offsets, merger.currentOrd + 1);\n        }\n        offsets[merger.currentOrd] = offset;\n      }\n      datOut.writeBytes(currentMergedBytes.bytes, currentMergedBytes.offset,\n          currentMergedBytes.length);\n      merger.pushTop();\n    }\n    ctx.offsets = offsets;\n    assert offsets == null || offsets[merger.currentOrd - 1] == offset;\n    return merger.currentOrd;\n  }\n\n","sourceOld":"  static int mergeRecords(MergeContext ctx, IndexOutput datOut,\n      List<SortedSourceSlice> slices) throws IOException {\n    final RecordMerger merger = new RecordMerger(new MergeQueue(slices.size(),\n        ctx.comp), slices.toArray(new SortedSourceSlice[0]));\n    long[] offsets = ctx.offsets;\n    final boolean recordOffsets = offsets != null;\n    long offset = 0;\n    BytesRef currentMergedBytes;\n    merger.pushTop();\n    while (merger.queue.size() > 0) {\n      merger.pullTop();\n      currentMergedBytes = merger.current;\n      assert ctx.sizePerValues == -1 || ctx.sizePerValues == currentMergedBytes.length : \"size: \"\n          + ctx.sizePerValues + \" spare: \" + currentMergedBytes.length;\n\n      if (recordOffsets) {\n        offset += currentMergedBytes.length;\n        if (merger.currentOrd >= offsets.length) {\n          offsets = ArrayUtil.grow(offsets, merger.currentOrd + 1);\n        }\n        offsets[merger.currentOrd] = offset;\n      }\n      datOut.writeBytes(currentMergedBytes.bytes, currentMergedBytes.offset,\n          currentMergedBytes.length);\n      merger.pushTop();\n    }\n    ctx.offsets = offsets;\n    assert offsets == null || offsets[merger.currentOrd - 1] == offset;\n    return merger.currentOrd;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1263e37167e93fb2e178a37536df562455e7a587","date":1323545884,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SortedBytesMergeUtils#mergeRecords(MergeContext,IndexOutput,List[SortedSourceSlice]).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/values/SortedBytesMergeUtils#mergeRecords(MergeContext,IndexOutput,List[SortedSourceSlice]).mjava","sourceNew":"  public static int mergeRecords(MergeContext ctx, IndexOutput datOut,\n      List<SortedSourceSlice> slices) throws IOException {\n    final RecordMerger merger = new RecordMerger(new MergeQueue(slices.size(),\n        ctx.comp), slices.toArray(new SortedSourceSlice[0]));\n    long[] offsets = ctx.offsets;\n    final boolean recordOffsets = offsets != null;\n    long offset = 0;\n    BytesRef currentMergedBytes;\n    merger.pushTop();\n    while (merger.queue.size() > 0) {\n      merger.pullTop();\n      currentMergedBytes = merger.current;\n      assert ctx.sizePerValues == -1 || ctx.sizePerValues == currentMergedBytes.length : \"size: \"\n          + ctx.sizePerValues + \" spare: \" + currentMergedBytes.length;\n\n      if (recordOffsets) {\n        offset += currentMergedBytes.length;\n        if (merger.currentOrd >= offsets.length) {\n          offsets = ArrayUtil.grow(offsets, merger.currentOrd + 1);\n        }\n        offsets[merger.currentOrd] = offset;\n      }\n      datOut.writeBytes(currentMergedBytes.bytes, currentMergedBytes.offset,\n          currentMergedBytes.length);\n      merger.pushTop();\n    }\n    ctx.offsets = offsets;\n    assert offsets == null || offsets[merger.currentOrd - 1] == offset;\n    return merger.currentOrd;\n  }\n\n","sourceOld":"  static int mergeRecords(MergeContext ctx, IndexOutput datOut,\n      List<SortedSourceSlice> slices) throws IOException {\n    final RecordMerger merger = new RecordMerger(new MergeQueue(slices.size(),\n        ctx.comp), slices.toArray(new SortedSourceSlice[0]));\n    long[] offsets = ctx.offsets;\n    final boolean recordOffsets = offsets != null;\n    long offset = 0;\n    BytesRef currentMergedBytes;\n    merger.pushTop();\n    while (merger.queue.size() > 0) {\n      merger.pullTop();\n      currentMergedBytes = merger.current;\n      assert ctx.sizePerValues == -1 || ctx.sizePerValues == currentMergedBytes.length : \"size: \"\n          + ctx.sizePerValues + \" spare: \" + currentMergedBytes.length;\n\n      if (recordOffsets) {\n        offset += currentMergedBytes.length;\n        if (merger.currentOrd >= offsets.length) {\n          offsets = ArrayUtil.grow(offsets, merger.currentOrd + 1);\n        }\n        offsets[merger.currentOrd] = offset;\n      }\n      datOut.writeBytes(currentMergedBytes.bytes, currentMergedBytes.offset,\n          currentMergedBytes.length);\n      merger.pushTop();\n    }\n    ctx.offsets = offsets;\n    assert offsets == null || offsets[merger.currentOrd - 1] == offset;\n    return merger.currentOrd;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"1263e37167e93fb2e178a37536df562455e7a587":["f9efc72acdea22f5285be0a808f8bba51bb8e367"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"f9efc72acdea22f5285be0a808f8bba51bb8e367":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"1263e37167e93fb2e178a37536df562455e7a587":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["f9efc72acdea22f5285be0a808f8bba51bb8e367","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f9efc72acdea22f5285be0a808f8bba51bb8e367":["1263e37167e93fb2e178a37536df562455e7a587"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["1263e37167e93fb2e178a37536df562455e7a587","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}