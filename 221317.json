{"path":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#getOrAddField(String,IndexableFieldType,boolean).mjava","commits":[{"id":"52c7e49be259508735752fba88085255014a6ecf","date":1398706273,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#getOrAddField(String,IndexableFieldType,boolean).mjava","pathOld":"/dev/null","sourceNew":"  /** Returns a previously created {@link PerField},\n   *  absorbing the type information from {@link FieldType},\n   *  and creates a new {@link PerField} if this field name\n   *  wasn't seen yet. */\n  private PerField getOrAddField(String name, IndexableFieldType fieldType, boolean invert) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = name.hashCode() & hashMask;\n    PerField fp = fieldHash[hashPos];\n    while (fp != null && !fp.fieldInfo.name.equals(name)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n      // First time we are seeing this field in this segment\n\n      FieldInfo fi = fieldInfos.addOrUpdate(name, fieldType);\n      \n      fp = new PerField(fi, invert);\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      // At most 50% load factor:\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n\n      if (totalFieldCount > fields.length) {\n        PerField[] newFields = new PerField[ArrayUtil.oversize(totalFieldCount, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(fields, 0, newFields, 0, fields.length);\n        fields = newFields;\n      }\n\n    } else {\n      fp.fieldInfo.update(fieldType);\n\n      if (invert && fp.invertState == null) {\n        fp.setInvertState();\n      }\n    }\n\n    return fp;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3394716f52b34ab259ad5247e7595d9f9db6e935","date":1398791921,"type":0,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#getOrAddField(String,IndexableFieldType,boolean).mjava","pathOld":"/dev/null","sourceNew":"  /** Returns a previously created {@link PerField},\n   *  absorbing the type information from {@link FieldType},\n   *  and creates a new {@link PerField} if this field name\n   *  wasn't seen yet. */\n  private PerField getOrAddField(String name, IndexableFieldType fieldType, boolean invert) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = name.hashCode() & hashMask;\n    PerField fp = fieldHash[hashPos];\n    while (fp != null && !fp.fieldInfo.name.equals(name)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n      // First time we are seeing this field in this segment\n\n      FieldInfo fi = fieldInfos.addOrUpdate(name, fieldType);\n      \n      fp = new PerField(fi, invert);\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      // At most 50% load factor:\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n\n      if (totalFieldCount > fields.length) {\n        PerField[] newFields = new PerField[ArrayUtil.oversize(totalFieldCount, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(fields, 0, newFields, 0, fields.length);\n        fields = newFields;\n      }\n\n    } else {\n      fp.fieldInfo.update(fieldType);\n\n      if (invert && fp.invertState == null) {\n        fp.setInvertState();\n      }\n    }\n\n    return fp;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","date":1398844771,"type":0,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#getOrAddField(String,IndexableFieldType,boolean).mjava","pathOld":"/dev/null","sourceNew":"  /** Returns a previously created {@link PerField},\n   *  absorbing the type information from {@link FieldType},\n   *  and creates a new {@link PerField} if this field name\n   *  wasn't seen yet. */\n  private PerField getOrAddField(String name, IndexableFieldType fieldType, boolean invert) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = name.hashCode() & hashMask;\n    PerField fp = fieldHash[hashPos];\n    while (fp != null && !fp.fieldInfo.name.equals(name)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n      // First time we are seeing this field in this segment\n\n      FieldInfo fi = fieldInfos.addOrUpdate(name, fieldType);\n      \n      fp = new PerField(fi, invert);\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      // At most 50% load factor:\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n\n      if (totalFieldCount > fields.length) {\n        PerField[] newFields = new PerField[ArrayUtil.oversize(totalFieldCount, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(fields, 0, newFields, 0, fields.length);\n        fields = newFields;\n      }\n\n    } else {\n      fp.fieldInfo.update(fieldType);\n\n      if (invert && fp.invertState == null) {\n        fp.setInvertState();\n      }\n    }\n\n    return fp;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eac6ccb51c439bec7f67cb0e299d3cb77b62b87e","date":1415435053,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#getOrAddField(String,IndexableFieldType,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#getOrAddField(String,IndexableFieldType,boolean).mjava","sourceNew":"  /** Returns a previously created {@link PerField},\n   *  absorbing the type information from {@link FieldType},\n   *  and creates a new {@link PerField} if this field name\n   *  wasn't seen yet. */\n  private PerField getOrAddField(String name, IndexableFieldType fieldType, boolean invert) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = name.hashCode() & hashMask;\n    PerField fp = fieldHash[hashPos];\n    while (fp != null && !fp.fieldInfo.name.equals(name)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n      // First time we are seeing this field in this segment\n\n      FieldInfo fi = fieldInfos.getOrAdd(name);\n      // Messy: must set this here because e.g. FreqProxTermsWriterPerField looks at the initial\n      // IndexOptions to decide what arrays it must create).  Then, we also must set it in\n      // PerField.invert to allow for later downgrading of the index options:\n      fi.setIndexOptions(fieldType.indexOptions());\n      \n      fp = new PerField(fi, invert);\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      // At most 50% load factor:\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n\n      if (totalFieldCount > fields.length) {\n        PerField[] newFields = new PerField[ArrayUtil.oversize(totalFieldCount, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(fields, 0, newFields, 0, fields.length);\n        fields = newFields;\n      }\n\n    } else if (invert && fp.invertState == null) {\n      // Messy: must set this here because e.g. FreqProxTermsWriterPerField looks at the initial\n      // IndexOptions to decide what arrays it must create).  Then, we also must set it in\n      // PerField.invert to allow for later downgrading of the index options:\n      fp.fieldInfo.setIndexOptions(fieldType.indexOptions());\n      fp.setInvertState();\n    }\n\n    return fp;\n  }\n\n","sourceOld":"  /** Returns a previously created {@link PerField},\n   *  absorbing the type information from {@link FieldType},\n   *  and creates a new {@link PerField} if this field name\n   *  wasn't seen yet. */\n  private PerField getOrAddField(String name, IndexableFieldType fieldType, boolean invert) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = name.hashCode() & hashMask;\n    PerField fp = fieldHash[hashPos];\n    while (fp != null && !fp.fieldInfo.name.equals(name)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n      // First time we are seeing this field in this segment\n\n      FieldInfo fi = fieldInfos.addOrUpdate(name, fieldType);\n      \n      fp = new PerField(fi, invert);\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      // At most 50% load factor:\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n\n      if (totalFieldCount > fields.length) {\n        PerField[] newFields = new PerField[ArrayUtil.oversize(totalFieldCount, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(fields, 0, newFields, 0, fields.length);\n        fields = newFields;\n      }\n\n    } else {\n      fp.fieldInfo.update(fieldType);\n\n      if (invert && fp.invertState == null) {\n        fp.setInvertState();\n      }\n    }\n\n    return fp;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"615370d2b876c3435773b5174df2e2242ad7981a","date":1495117651,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#getOrAddField(String,IndexableFieldType,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#getOrAddField(String,IndexableFieldType,boolean).mjava","sourceNew":"  /** Returns a previously created {@link PerField},\n   *  absorbing the type information from {@link FieldType},\n   *  and creates a new {@link PerField} if this field name\n   *  wasn't seen yet. */\n  private PerField getOrAddField(String name, IndexableFieldType fieldType, boolean invert) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = name.hashCode() & hashMask;\n    PerField fp = fieldHash[hashPos];\n    while (fp != null && !fp.fieldInfo.name.equals(name)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n      // First time we are seeing this field in this segment\n\n      FieldInfo fi = fieldInfos.getOrAdd(name);\n      // Messy: must set this here because e.g. FreqProxTermsWriterPerField looks at the initial\n      // IndexOptions to decide what arrays it must create).  Then, we also must set it in\n      // PerField.invert to allow for later downgrading of the index options:\n      fi.setIndexOptions(fieldType.indexOptions());\n      \n      fp = new PerField(docWriter.getIndexCreatedVersionMajor(), fi, invert);\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      // At most 50% load factor:\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n\n      if (totalFieldCount > fields.length) {\n        PerField[] newFields = new PerField[ArrayUtil.oversize(totalFieldCount, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(fields, 0, newFields, 0, fields.length);\n        fields = newFields;\n      }\n\n    } else if (invert && fp.invertState == null) {\n      // Messy: must set this here because e.g. FreqProxTermsWriterPerField looks at the initial\n      // IndexOptions to decide what arrays it must create).  Then, we also must set it in\n      // PerField.invert to allow for later downgrading of the index options:\n      fp.fieldInfo.setIndexOptions(fieldType.indexOptions());\n      fp.setInvertState();\n    }\n\n    return fp;\n  }\n\n","sourceOld":"  /** Returns a previously created {@link PerField},\n   *  absorbing the type information from {@link FieldType},\n   *  and creates a new {@link PerField} if this field name\n   *  wasn't seen yet. */\n  private PerField getOrAddField(String name, IndexableFieldType fieldType, boolean invert) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = name.hashCode() & hashMask;\n    PerField fp = fieldHash[hashPos];\n    while (fp != null && !fp.fieldInfo.name.equals(name)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n      // First time we are seeing this field in this segment\n\n      FieldInfo fi = fieldInfos.getOrAdd(name);\n      // Messy: must set this here because e.g. FreqProxTermsWriterPerField looks at the initial\n      // IndexOptions to decide what arrays it must create).  Then, we also must set it in\n      // PerField.invert to allow for later downgrading of the index options:\n      fi.setIndexOptions(fieldType.indexOptions());\n      \n      fp = new PerField(fi, invert);\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      // At most 50% load factor:\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n\n      if (totalFieldCount > fields.length) {\n        PerField[] newFields = new PerField[ArrayUtil.oversize(totalFieldCount, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(fields, 0, newFields, 0, fields.length);\n        fields = newFields;\n      }\n\n    } else if (invert && fp.invertState == null) {\n      // Messy: must set this here because e.g. FreqProxTermsWriterPerField looks at the initial\n      // IndexOptions to decide what arrays it must create).  Then, we also must set it in\n      // PerField.invert to allow for later downgrading of the index options:\n      fp.fieldInfo.setIndexOptions(fieldType.indexOptions());\n      fp.setInvertState();\n    }\n\n    return fp;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e9017cf144952056066919f1ebc7897ff9bd71b1","date":1496757600,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#getOrAddField(String,IndexableFieldType,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#getOrAddField(String,IndexableFieldType,boolean).mjava","sourceNew":"  /** Returns a previously created {@link PerField},\n   *  absorbing the type information from {@link FieldType},\n   *  and creates a new {@link PerField} if this field name\n   *  wasn't seen yet. */\n  private PerField getOrAddField(String name, IndexableFieldType fieldType, boolean invert) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = name.hashCode() & hashMask;\n    PerField fp = fieldHash[hashPos];\n    while (fp != null && !fp.fieldInfo.name.equals(name)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n      // First time we are seeing this field in this segment\n\n      FieldInfo fi = fieldInfos.getOrAdd(name);\n      // Messy: must set this here because e.g. FreqProxTermsWriterPerField looks at the initial\n      // IndexOptions to decide what arrays it must create).  Then, we also must set it in\n      // PerField.invert to allow for later downgrading of the index options:\n      fi.setIndexOptions(fieldType.indexOptions());\n      \n      fp = new PerField(docWriter.getIndexCreatedVersionMajor(), fi, invert);\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      // At most 50% load factor:\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n\n      if (totalFieldCount > fields.length) {\n        PerField[] newFields = new PerField[ArrayUtil.oversize(totalFieldCount, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(fields, 0, newFields, 0, fields.length);\n        fields = newFields;\n      }\n\n    } else if (invert && fp.invertState == null) {\n      // Messy: must set this here because e.g. FreqProxTermsWriterPerField looks at the initial\n      // IndexOptions to decide what arrays it must create).  Then, we also must set it in\n      // PerField.invert to allow for later downgrading of the index options:\n      fp.fieldInfo.setIndexOptions(fieldType.indexOptions());\n      fp.setInvertState();\n    }\n\n    return fp;\n  }\n\n","sourceOld":"  /** Returns a previously created {@link PerField},\n   *  absorbing the type information from {@link FieldType},\n   *  and creates a new {@link PerField} if this field name\n   *  wasn't seen yet. */\n  private PerField getOrAddField(String name, IndexableFieldType fieldType, boolean invert) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = name.hashCode() & hashMask;\n    PerField fp = fieldHash[hashPos];\n    while (fp != null && !fp.fieldInfo.name.equals(name)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n      // First time we are seeing this field in this segment\n\n      FieldInfo fi = fieldInfos.getOrAdd(name);\n      // Messy: must set this here because e.g. FreqProxTermsWriterPerField looks at the initial\n      // IndexOptions to decide what arrays it must create).  Then, we also must set it in\n      // PerField.invert to allow for later downgrading of the index options:\n      fi.setIndexOptions(fieldType.indexOptions());\n      \n      fp = new PerField(fi, invert);\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      // At most 50% load factor:\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n\n      if (totalFieldCount > fields.length) {\n        PerField[] newFields = new PerField[ArrayUtil.oversize(totalFieldCount, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(fields, 0, newFields, 0, fields.length);\n        fields = newFields;\n      }\n\n    } else if (invert && fp.invertState == null) {\n      // Messy: must set this here because e.g. FreqProxTermsWriterPerField looks at the initial\n      // IndexOptions to decide what arrays it must create).  Then, we also must set it in\n      // PerField.invert to allow for later downgrading of the index options:\n      fp.fieldInfo.setIndexOptions(fieldType.indexOptions());\n      fp.setInvertState();\n    }\n\n    return fp;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"165c905a42bedc7c7d1acb37b177498306b7e866","date":1518704038,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#getOrAddField(String,IndexableFieldType,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#getOrAddField(String,IndexableFieldType,boolean).mjava","sourceNew":"  /** Returns a previously created {@link PerField},\n   *  absorbing the type information from {@link FieldType},\n   *  and creates a new {@link PerField} if this field name\n   *  wasn't seen yet. */\n  private PerField getOrAddField(String name, IndexableFieldType fieldType, boolean invert) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = name.hashCode() & hashMask;\n    PerField fp = fieldHash[hashPos];\n    while (fp != null && !fp.fieldInfo.name.equals(name)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n      // First time we are seeing this field in this segment\n\n      FieldInfo fi = fieldInfos.getOrAdd(name);\n      initIndexOptions(fi, fieldType.indexOptions());\n      fp = new PerField(docWriter.getIndexCreatedVersionMajor(), fi, invert);\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      // At most 50% load factor:\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n\n      if (totalFieldCount > fields.length) {\n        PerField[] newFields = new PerField[ArrayUtil.oversize(totalFieldCount, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(fields, 0, newFields, 0, fields.length);\n        fields = newFields;\n      }\n\n    } else if (invert && fp.invertState == null) {\n      initIndexOptions(fp.fieldInfo, fieldType.indexOptions());\n      fp.setInvertState();\n    }\n\n    return fp;\n  }\n\n","sourceOld":"  /** Returns a previously created {@link PerField},\n   *  absorbing the type information from {@link FieldType},\n   *  and creates a new {@link PerField} if this field name\n   *  wasn't seen yet. */\n  private PerField getOrAddField(String name, IndexableFieldType fieldType, boolean invert) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = name.hashCode() & hashMask;\n    PerField fp = fieldHash[hashPos];\n    while (fp != null && !fp.fieldInfo.name.equals(name)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n      // First time we are seeing this field in this segment\n\n      FieldInfo fi = fieldInfos.getOrAdd(name);\n      // Messy: must set this here because e.g. FreqProxTermsWriterPerField looks at the initial\n      // IndexOptions to decide what arrays it must create).  Then, we also must set it in\n      // PerField.invert to allow for later downgrading of the index options:\n      fi.setIndexOptions(fieldType.indexOptions());\n      \n      fp = new PerField(docWriter.getIndexCreatedVersionMajor(), fi, invert);\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      // At most 50% load factor:\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n\n      if (totalFieldCount > fields.length) {\n        PerField[] newFields = new PerField[ArrayUtil.oversize(totalFieldCount, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(fields, 0, newFields, 0, fields.length);\n        fields = newFields;\n      }\n\n    } else if (invert && fp.invertState == null) {\n      // Messy: must set this here because e.g. FreqProxTermsWriterPerField looks at the initial\n      // IndexOptions to decide what arrays it must create).  Then, we also must set it in\n      // PerField.invert to allow for later downgrading of the index options:\n      fp.fieldInfo.setIndexOptions(fieldType.indexOptions());\n      fp.setInvertState();\n    }\n\n    return fp;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1dbcafacd03baeb0f18199de611a1619606073c5","date":1546559081,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#getOrAddField(String,IndexableFieldType,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#getOrAddField(String,IndexableFieldType,boolean).mjava","sourceNew":"  /** Returns a previously created {@link PerField},\n   *  absorbing the type information from {@link FieldType},\n   *  and creates a new {@link PerField} if this field name\n   *  wasn't seen yet. */\n  private PerField getOrAddField(String name, IndexableFieldType fieldType, boolean invert) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = name.hashCode() & hashMask;\n    PerField fp = fieldHash[hashPos];\n    while (fp != null && !fp.fieldInfo.name.equals(name)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n      // First time we are seeing this field in this segment\n\n      FieldInfo fi = fieldInfos.getOrAdd(name);\n      initIndexOptions(fi, fieldType.indexOptions());\n      Map<String, String> attributes = fieldType.getAttributes();\n      if (attributes != null) {\n        attributes.forEach((k, v) -> fi.putAttribute(k, v));\n      }\n\n      fp = new PerField(docWriter.getIndexCreatedVersionMajor(), fi, invert);\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      // At most 50% load factor:\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n\n      if (totalFieldCount > fields.length) {\n        PerField[] newFields = new PerField[ArrayUtil.oversize(totalFieldCount, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(fields, 0, newFields, 0, fields.length);\n        fields = newFields;\n      }\n\n    } else if (invert && fp.invertState == null) {\n      initIndexOptions(fp.fieldInfo, fieldType.indexOptions());\n      fp.setInvertState();\n    }\n\n    return fp;\n  }\n\n","sourceOld":"  /** Returns a previously created {@link PerField},\n   *  absorbing the type information from {@link FieldType},\n   *  and creates a new {@link PerField} if this field name\n   *  wasn't seen yet. */\n  private PerField getOrAddField(String name, IndexableFieldType fieldType, boolean invert) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = name.hashCode() & hashMask;\n    PerField fp = fieldHash[hashPos];\n    while (fp != null && !fp.fieldInfo.name.equals(name)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n      // First time we are seeing this field in this segment\n\n      FieldInfo fi = fieldInfos.getOrAdd(name);\n      initIndexOptions(fi, fieldType.indexOptions());\n      fp = new PerField(docWriter.getIndexCreatedVersionMajor(), fi, invert);\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      // At most 50% load factor:\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n\n      if (totalFieldCount > fields.length) {\n        PerField[] newFields = new PerField[ArrayUtil.oversize(totalFieldCount, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(fields, 0, newFields, 0, fields.length);\n        fields = newFields;\n      }\n\n    } else if (invert && fp.invertState == null) {\n      initIndexOptions(fp.fieldInfo, fieldType.indexOptions());\n      fp.setInvertState();\n    }\n\n    return fp;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f97270426d92300e08ac1bd1a4ef499ae02e88b7","date":1592503330,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#getOrAddField(String,IndexableFieldType,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#getOrAddField(String,IndexableFieldType,boolean).mjava","sourceNew":"  /** Returns a previously created {@link PerField},\n   *  absorbing the type information from {@link FieldType},\n   *  and creates a new {@link PerField} if this field name\n   *  wasn't seen yet. */\n  private PerField getOrAddField(String name, IndexableFieldType fieldType, boolean invert) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = name.hashCode() & hashMask;\n    PerField fp = fieldHash[hashPos];\n    while (fp != null && !fp.fieldInfo.name.equals(name)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n      // First time we are seeing this field in this segment\n\n      FieldInfo fi = fieldInfos.getOrAdd(name);\n      initIndexOptions(fi, fieldType.indexOptions());\n      Map<String, String> attributes = fieldType.getAttributes();\n      if (attributes != null) {\n        attributes.forEach((k, v) -> fi.putAttribute(k, v));\n      }\n\n      LiveIndexWriterConfig indexWriterConfig = docWriter.getIndexWriterConfig();\n      fp = new PerField(docWriter.getIndexCreatedVersionMajor(), fi, invert,\n          indexWriterConfig.getSimilarity(), indexWriterConfig.getInfoStream(), indexWriterConfig.getAnalyzer());\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      // At most 50% load factor:\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n\n      if (totalFieldCount > fields.length) {\n        PerField[] newFields = new PerField[ArrayUtil.oversize(totalFieldCount, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(fields, 0, newFields, 0, fields.length);\n        fields = newFields;\n      }\n\n    } else if (invert && fp.invertState == null) {\n      initIndexOptions(fp.fieldInfo, fieldType.indexOptions());\n      fp.setInvertState();\n    }\n\n    return fp;\n  }\n\n","sourceOld":"  /** Returns a previously created {@link PerField},\n   *  absorbing the type information from {@link FieldType},\n   *  and creates a new {@link PerField} if this field name\n   *  wasn't seen yet. */\n  private PerField getOrAddField(String name, IndexableFieldType fieldType, boolean invert) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = name.hashCode() & hashMask;\n    PerField fp = fieldHash[hashPos];\n    while (fp != null && !fp.fieldInfo.name.equals(name)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n      // First time we are seeing this field in this segment\n\n      FieldInfo fi = fieldInfos.getOrAdd(name);\n      initIndexOptions(fi, fieldType.indexOptions());\n      Map<String, String> attributes = fieldType.getAttributes();\n      if (attributes != null) {\n        attributes.forEach((k, v) -> fi.putAttribute(k, v));\n      }\n\n      fp = new PerField(docWriter.getIndexCreatedVersionMajor(), fi, invert);\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      // At most 50% load factor:\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n\n      if (totalFieldCount > fields.length) {\n        PerField[] newFields = new PerField[ArrayUtil.oversize(totalFieldCount, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(fields, 0, newFields, 0, fields.length);\n        fields = newFields;\n      }\n\n    } else if (invert && fp.invertState == null) {\n      initIndexOptions(fp.fieldInfo, fieldType.indexOptions());\n      fp.setInvertState();\n    }\n\n    return fp;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"49f1924bd448393fbdfef8b5ebed799f938169d3","date":1600069616,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#getOrAddField(String,IndexableFieldType,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#getOrAddField(String,IndexableFieldType,boolean).mjava","sourceNew":"  /** Returns a previously created {@link PerField},\n   *  absorbing the type information from {@link FieldType},\n   *  and creates a new {@link PerField} if this field name\n   *  wasn't seen yet. */\n  private PerField getOrAddField(String name, IndexableFieldType fieldType, boolean invert) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = name.hashCode() & hashMask;\n    PerField fp = fieldHash[hashPos];\n    while (fp != null && !fp.fieldInfo.name.equals(name)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n      // First time we are seeing this field in this segment\n\n      FieldInfo fi = fieldInfos.getOrAdd(name);\n      initIndexOptions(fi, fieldType.indexOptions());\n      Map<String, String> attributes = fieldType.getAttributes();\n      if (attributes != null) {\n        attributes.forEach((k, v) -> fi.putAttribute(k, v));\n      }\n\n      fp = new PerField(indexCreatedVersionMajor, fi, invert,\n          indexWriterConfig.getSimilarity(), indexWriterConfig.getInfoStream(), indexWriterConfig.getAnalyzer());\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      // At most 50% load factor:\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n\n      if (totalFieldCount > fields.length) {\n        PerField[] newFields = new PerField[ArrayUtil.oversize(totalFieldCount, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(fields, 0, newFields, 0, fields.length);\n        fields = newFields;\n      }\n\n    } else if (invert && fp.invertState == null) {\n      initIndexOptions(fp.fieldInfo, fieldType.indexOptions());\n      fp.setInvertState();\n    }\n\n    return fp;\n  }\n\n","sourceOld":"  /** Returns a previously created {@link PerField},\n   *  absorbing the type information from {@link FieldType},\n   *  and creates a new {@link PerField} if this field name\n   *  wasn't seen yet. */\n  private PerField getOrAddField(String name, IndexableFieldType fieldType, boolean invert) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = name.hashCode() & hashMask;\n    PerField fp = fieldHash[hashPos];\n    while (fp != null && !fp.fieldInfo.name.equals(name)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n      // First time we are seeing this field in this segment\n\n      FieldInfo fi = fieldInfos.getOrAdd(name);\n      initIndexOptions(fi, fieldType.indexOptions());\n      Map<String, String> attributes = fieldType.getAttributes();\n      if (attributes != null) {\n        attributes.forEach((k, v) -> fi.putAttribute(k, v));\n      }\n\n      LiveIndexWriterConfig indexWriterConfig = docWriter.getIndexWriterConfig();\n      fp = new PerField(docWriter.getIndexCreatedVersionMajor(), fi, invert,\n          indexWriterConfig.getSimilarity(), indexWriterConfig.getInfoStream(), indexWriterConfig.getAnalyzer());\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      // At most 50% load factor:\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n\n      if (totalFieldCount > fields.length) {\n        PerField[] newFields = new PerField[ArrayUtil.oversize(totalFieldCount, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(fields, 0, newFields, 0, fields.length);\n        fields = newFields;\n      }\n\n    } else if (invert && fp.invertState == null) {\n      initIndexOptions(fp.fieldInfo, fieldType.indexOptions());\n      fp.setInvertState();\n    }\n\n    return fp;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0dcf8f79417865e5028d753e669fae06457e8369","date":1600073240,"type":3,"author":"noblepaul","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#getOrAddField(String,IndexableFieldType,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#getOrAddField(String,IndexableFieldType,boolean).mjava","sourceNew":"  /** Returns a previously created {@link PerField},\n   *  absorbing the type information from {@link FieldType},\n   *  and creates a new {@link PerField} if this field name\n   *  wasn't seen yet. */\n  private PerField getOrAddField(String name, IndexableFieldType fieldType, boolean invert) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = name.hashCode() & hashMask;\n    PerField fp = fieldHash[hashPos];\n    while (fp != null && !fp.fieldInfo.name.equals(name)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n      // First time we are seeing this field in this segment\n\n      FieldInfo fi = fieldInfos.getOrAdd(name);\n      initIndexOptions(fi, fieldType.indexOptions());\n      Map<String, String> attributes = fieldType.getAttributes();\n      if (attributes != null) {\n        attributes.forEach((k, v) -> fi.putAttribute(k, v));\n      }\n\n      fp = new PerField(indexCreatedVersionMajor, fi, invert,\n          indexWriterConfig.getSimilarity(), indexWriterConfig.getInfoStream(), indexWriterConfig.getAnalyzer());\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      // At most 50% load factor:\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n\n      if (totalFieldCount > fields.length) {\n        PerField[] newFields = new PerField[ArrayUtil.oversize(totalFieldCount, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(fields, 0, newFields, 0, fields.length);\n        fields = newFields;\n      }\n\n    } else if (invert && fp.invertState == null) {\n      initIndexOptions(fp.fieldInfo, fieldType.indexOptions());\n      fp.setInvertState();\n    }\n\n    return fp;\n  }\n\n","sourceOld":"  /** Returns a previously created {@link PerField},\n   *  absorbing the type information from {@link FieldType},\n   *  and creates a new {@link PerField} if this field name\n   *  wasn't seen yet. */\n  private PerField getOrAddField(String name, IndexableFieldType fieldType, boolean invert) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = name.hashCode() & hashMask;\n    PerField fp = fieldHash[hashPos];\n    while (fp != null && !fp.fieldInfo.name.equals(name)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n      // First time we are seeing this field in this segment\n\n      FieldInfo fi = fieldInfos.getOrAdd(name);\n      initIndexOptions(fi, fieldType.indexOptions());\n      Map<String, String> attributes = fieldType.getAttributes();\n      if (attributes != null) {\n        attributes.forEach((k, v) -> fi.putAttribute(k, v));\n      }\n\n      LiveIndexWriterConfig indexWriterConfig = docWriter.getIndexWriterConfig();\n      fp = new PerField(docWriter.getIndexCreatedVersionMajor(), fi, invert,\n          indexWriterConfig.getSimilarity(), indexWriterConfig.getInfoStream(), indexWriterConfig.getAnalyzer());\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      // At most 50% load factor:\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n\n      if (totalFieldCount > fields.length) {\n        PerField[] newFields = new PerField[ArrayUtil.oversize(totalFieldCount, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(fields, 0, newFields, 0, fields.length);\n        fields = newFields;\n      }\n\n    } else if (invert && fp.invertState == null) {\n      initIndexOptions(fp.fieldInfo, fieldType.indexOptions());\n      fp.setInvertState();\n    }\n\n    return fp;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7a6f8af01d9b3067b143bbdc0a492720e2af97cf","date":1600157724,"type":5,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexingChain#getOrAddField(String,IndexableFieldType,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#getOrAddField(String,IndexableFieldType,boolean).mjava","sourceNew":"  /** Returns a previously created {@link PerField},\n   *  absorbing the type information from {@link FieldType},\n   *  and creates a new {@link PerField} if this field name\n   *  wasn't seen yet. */\n  private PerField getOrAddField(String name, IndexableFieldType fieldType, boolean invert) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = name.hashCode() & hashMask;\n    PerField fp = fieldHash[hashPos];\n    while (fp != null && !fp.fieldInfo.name.equals(name)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n      // First time we are seeing this field in this segment\n\n      FieldInfo fi = fieldInfos.getOrAdd(name);\n      initIndexOptions(fi, fieldType.indexOptions());\n      Map<String, String> attributes = fieldType.getAttributes();\n      if (attributes != null) {\n        attributes.forEach((k, v) -> fi.putAttribute(k, v));\n      }\n\n      fp = new PerField(indexCreatedVersionMajor, fi, invert,\n          indexWriterConfig.getSimilarity(), indexWriterConfig.getInfoStream(), indexWriterConfig.getAnalyzer());\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      // At most 50% load factor:\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n\n      if (totalFieldCount > fields.length) {\n        PerField[] newFields = new PerField[ArrayUtil.oversize(totalFieldCount, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(fields, 0, newFields, 0, fields.length);\n        fields = newFields;\n      }\n\n    } else if (invert && fp.invertState == null) {\n      initIndexOptions(fp.fieldInfo, fieldType.indexOptions());\n      fp.setInvertState();\n    }\n\n    return fp;\n  }\n\n","sourceOld":"  /** Returns a previously created {@link PerField},\n   *  absorbing the type information from {@link FieldType},\n   *  and creates a new {@link PerField} if this field name\n   *  wasn't seen yet. */\n  private PerField getOrAddField(String name, IndexableFieldType fieldType, boolean invert) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = name.hashCode() & hashMask;\n    PerField fp = fieldHash[hashPos];\n    while (fp != null && !fp.fieldInfo.name.equals(name)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n      // First time we are seeing this field in this segment\n\n      FieldInfo fi = fieldInfos.getOrAdd(name);\n      initIndexOptions(fi, fieldType.indexOptions());\n      Map<String, String> attributes = fieldType.getAttributes();\n      if (attributes != null) {\n        attributes.forEach((k, v) -> fi.putAttribute(k, v));\n      }\n\n      fp = new PerField(indexCreatedVersionMajor, fi, invert,\n          indexWriterConfig.getSimilarity(), indexWriterConfig.getInfoStream(), indexWriterConfig.getAnalyzer());\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      // At most 50% load factor:\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n\n      if (totalFieldCount > fields.length) {\n        PerField[] newFields = new PerField[ArrayUtil.oversize(totalFieldCount, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(fields, 0, newFields, 0, fields.length);\n        fields = newFields;\n      }\n\n    } else if (invert && fp.invertState == null) {\n      initIndexOptions(fp.fieldInfo, fieldType.indexOptions());\n      fp.setInvertState();\n    }\n\n    return fp;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"680b6449f09827f58fe987aff279e014c311d966","date":1600247985,"type":5,"author":"noblepaul","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexingChain#getOrAddField(String,IndexableFieldType,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#getOrAddField(String,IndexableFieldType,boolean).mjava","sourceNew":"  /** Returns a previously created {@link PerField},\n   *  absorbing the type information from {@link FieldType},\n   *  and creates a new {@link PerField} if this field name\n   *  wasn't seen yet. */\n  private PerField getOrAddField(String name, IndexableFieldType fieldType, boolean invert) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = name.hashCode() & hashMask;\n    PerField fp = fieldHash[hashPos];\n    while (fp != null && !fp.fieldInfo.name.equals(name)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n      // First time we are seeing this field in this segment\n\n      FieldInfo fi = fieldInfos.getOrAdd(name);\n      initIndexOptions(fi, fieldType.indexOptions());\n      Map<String, String> attributes = fieldType.getAttributes();\n      if (attributes != null) {\n        attributes.forEach((k, v) -> fi.putAttribute(k, v));\n      }\n\n      fp = new PerField(indexCreatedVersionMajor, fi, invert,\n          indexWriterConfig.getSimilarity(), indexWriterConfig.getInfoStream(), indexWriterConfig.getAnalyzer());\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      // At most 50% load factor:\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n\n      if (totalFieldCount > fields.length) {\n        PerField[] newFields = new PerField[ArrayUtil.oversize(totalFieldCount, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(fields, 0, newFields, 0, fields.length);\n        fields = newFields;\n      }\n\n    } else if (invert && fp.invertState == null) {\n      initIndexOptions(fp.fieldInfo, fieldType.indexOptions());\n      fp.setInvertState();\n    }\n\n    return fp;\n  }\n\n","sourceOld":"  /** Returns a previously created {@link PerField},\n   *  absorbing the type information from {@link FieldType},\n   *  and creates a new {@link PerField} if this field name\n   *  wasn't seen yet. */\n  private PerField getOrAddField(String name, IndexableFieldType fieldType, boolean invert) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = name.hashCode() & hashMask;\n    PerField fp = fieldHash[hashPos];\n    while (fp != null && !fp.fieldInfo.name.equals(name)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n      // First time we are seeing this field in this segment\n\n      FieldInfo fi = fieldInfos.getOrAdd(name);\n      initIndexOptions(fi, fieldType.indexOptions());\n      Map<String, String> attributes = fieldType.getAttributes();\n      if (attributes != null) {\n        attributes.forEach((k, v) -> fi.putAttribute(k, v));\n      }\n\n      fp = new PerField(indexCreatedVersionMajor, fi, invert,\n          indexWriterConfig.getSimilarity(), indexWriterConfig.getInfoStream(), indexWriterConfig.getAnalyzer());\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      // At most 50% load factor:\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n\n      if (totalFieldCount > fields.length) {\n        PerField[] newFields = new PerField[ArrayUtil.oversize(totalFieldCount, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(fields, 0, newFields, 0, fields.length);\n        fields = newFields;\n      }\n\n    } else if (invert && fp.invertState == null) {\n      initIndexOptions(fp.fieldInfo, fieldType.indexOptions());\n      fp.setInvertState();\n    }\n\n    return fp;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"1dbcafacd03baeb0f18199de611a1619606073c5":["165c905a42bedc7c7d1acb37b177498306b7e866"],"49f1924bd448393fbdfef8b5ebed799f938169d3":["f97270426d92300e08ac1bd1a4ef499ae02e88b7"],"7a6f8af01d9b3067b143bbdc0a492720e2af97cf":["49f1924bd448393fbdfef8b5ebed799f938169d3"],"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3394716f52b34ab259ad5247e7595d9f9db6e935"],"0dcf8f79417865e5028d753e669fae06457e8369":["f97270426d92300e08ac1bd1a4ef499ae02e88b7","49f1924bd448393fbdfef8b5ebed799f938169d3"],"3394716f52b34ab259ad5247e7595d9f9db6e935":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","52c7e49be259508735752fba88085255014a6ecf"],"165c905a42bedc7c7d1acb37b177498306b7e866":["615370d2b876c3435773b5174df2e2242ad7981a"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["eac6ccb51c439bec7f67cb0e299d3cb77b62b87e","615370d2b876c3435773b5174df2e2242ad7981a"],"680b6449f09827f58fe987aff279e014c311d966":["0dcf8f79417865e5028d753e669fae06457e8369","7a6f8af01d9b3067b143bbdc0a492720e2af97cf"],"615370d2b876c3435773b5174df2e2242ad7981a":["eac6ccb51c439bec7f67cb0e299d3cb77b62b87e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"eac6ccb51c439bec7f67cb0e299d3cb77b62b87e":["3394716f52b34ab259ad5247e7595d9f9db6e935"],"f97270426d92300e08ac1bd1a4ef499ae02e88b7":["1dbcafacd03baeb0f18199de611a1619606073c5"],"52c7e49be259508735752fba88085255014a6ecf":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["680b6449f09827f58fe987aff279e014c311d966"]},"commit2Childs":{"1dbcafacd03baeb0f18199de611a1619606073c5":["f97270426d92300e08ac1bd1a4ef499ae02e88b7"],"49f1924bd448393fbdfef8b5ebed799f938169d3":["7a6f8af01d9b3067b143bbdc0a492720e2af97cf","0dcf8f79417865e5028d753e669fae06457e8369"],"7a6f8af01d9b3067b143bbdc0a492720e2af97cf":["680b6449f09827f58fe987aff279e014c311d966"],"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe":[],"0dcf8f79417865e5028d753e669fae06457e8369":["680b6449f09827f58fe987aff279e014c311d966"],"3394716f52b34ab259ad5247e7595d9f9db6e935":["c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","eac6ccb51c439bec7f67cb0e299d3cb77b62b87e"],"165c905a42bedc7c7d1acb37b177498306b7e866":["1dbcafacd03baeb0f18199de611a1619606073c5"],"e9017cf144952056066919f1ebc7897ff9bd71b1":[],"680b6449f09827f58fe987aff279e014c311d966":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"615370d2b876c3435773b5174df2e2242ad7981a":["165c905a42bedc7c7d1acb37b177498306b7e866","e9017cf144952056066919f1ebc7897ff9bd71b1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","3394716f52b34ab259ad5247e7595d9f9db6e935","52c7e49be259508735752fba88085255014a6ecf"],"eac6ccb51c439bec7f67cb0e299d3cb77b62b87e":["e9017cf144952056066919f1ebc7897ff9bd71b1","615370d2b876c3435773b5174df2e2242ad7981a"],"f97270426d92300e08ac1bd1a4ef499ae02e88b7":["49f1924bd448393fbdfef8b5ebed799f938169d3","0dcf8f79417865e5028d753e669fae06457e8369"],"52c7e49be259508735752fba88085255014a6ecf":["3394716f52b34ab259ad5247e7595d9f9db6e935"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","e9017cf144952056066919f1ebc7897ff9bd71b1","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}