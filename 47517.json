{"path":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#parse().mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#parse().mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#parse().mjava","sourceNew":"  private void parse() throws IOException {\n    //System.out.println(\"\\nS: parse\");\n\n    assert inputSkipCount == 0;\n\n    int curNextRead = nextRead;\n\n    // Holds the longest match we've seen so far:\n    BytesRef matchOutput = null;\n    int matchInputLength = 0;\n    int matchEndOffset = -1;\n\n    BytesRef pendingOutput = fst.outputs.getNoOutput();\n    fst.getFirstArc(scratchArc);\n\n    assert scratchArc.output == fst.outputs.getNoOutput();\n\n    int tokenCount = 0;\n\n    byToken:\n    while(true) {\n      \n      // Pull next token's chars:\n      final char[] buffer;\n      final int bufferLen;\n      //System.out.println(\"  cycle nextRead=\" + curNextRead + \" nextWrite=\" + nextWrite);\n\n      int inputEndOffset = 0;\n\n      if (curNextRead == nextWrite) {\n\n        // We used up our lookahead buffer of input tokens\n        // -- pull next real input token:\n\n        if (finished) {\n          break;\n        } else  {\n          //System.out.println(\"  input.incrToken\");\n          assert futureInputs[nextWrite].consumed;\n          // Not correct: a syn match whose output is longer\n          // than its input can set future inputs keepOrig\n          // to true:\n          //assert !futureInputs[nextWrite].keepOrig;\n          if (input.incrementToken()) {\n            buffer = termAtt.buffer();\n            bufferLen = termAtt.length();\n            final PendingInput input = futureInputs[nextWrite];\n            lastStartOffset = input.startOffset = offsetAtt.startOffset();\n            lastEndOffset = input.endOffset = offsetAtt.endOffset();\n            inputEndOffset = input.endOffset;\n            //System.out.println(\"  new token=\" + new String(buffer, 0, bufferLen));\n            if (nextRead != nextWrite) {\n              capture();\n            } else {\n              input.consumed = false;\n            }\n\n          } else {\n            // No more input tokens\n            //System.out.println(\"      set end\");\n            finished = true;\n            break;\n          }\n        }\n      } else {\n        // Still in our lookahead\n        buffer = futureInputs[curNextRead].term.chars;\n        bufferLen = futureInputs[curNextRead].term.length;\n        inputEndOffset = futureInputs[curNextRead].endOffset;\n        //System.out.println(\"  old token=\" + new String(buffer, 0, bufferLen));\n      }\n\n      tokenCount++;\n\n      // Run each char in this token through the FST:\n      int bufUpto = 0;\n      while(bufUpto < bufferLen) {\n        final int codePoint = Character.codePointAt(buffer, bufUpto, bufferLen);\n        if (fst.findTargetArc(ignoreCase ? Character.toLowerCase(codePoint) : codePoint, scratchArc, scratchArc, fstReader) == null) {\n          //System.out.println(\"    stop\");\n          break byToken;\n        }\n\n        // Accum the output\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        //System.out.println(\"    char=\" + buffer[bufUpto] + \" output=\" + pendingOutput + \" arc.output=\" + scratchArc.output);\n        bufUpto += Character.charCount(codePoint);\n      }\n\n      // OK, entire token matched; now see if this is a final\n      // state:\n      if (scratchArc.isFinal()) {\n        matchOutput = fst.outputs.add(pendingOutput, scratchArc.nextFinalOutput);\n        matchInputLength = tokenCount;\n        matchEndOffset = inputEndOffset;\n        //System.out.println(\"  found matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      }\n\n      // See if the FST wants to continue matching (ie, needs to\n      // see the next input token):\n      if (fst.findTargetArc(SynonymMap.WORD_SEPARATOR, scratchArc, scratchArc, fstReader) == null) {\n        // No further rules can match here; we're done\n        // searching for matching rules starting at the\n        // current input position.\n        break;\n      } else {\n        // More matching is possible -- accum the output (if\n        // any) of the WORD_SEP arc:\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        if (nextRead == nextWrite) {\n          capture();\n        }\n      }\n\n      curNextRead = rollIncr(curNextRead);\n    }\n\n    if (nextRead == nextWrite && !finished) {\n      //System.out.println(\"  skip write slot=\" + nextWrite);\n      nextWrite = rollIncr(nextWrite);\n    }\n\n    if (matchOutput != null) {\n      //System.out.println(\"  add matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      inputSkipCount = matchInputLength;\n      addOutput(matchOutput, matchInputLength, matchEndOffset);\n    } else if (nextRead != nextWrite) {\n      // Even though we had no match here, we set to 1\n      // because we need to skip current input token before\n      // trying to match again:\n      inputSkipCount = 1;\n    } else {\n      assert finished;\n    }\n\n    //System.out.println(\"  parse done inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n  }\n\n","sourceOld":"  private void parse() throws IOException {\n    //System.out.println(\"\\nS: parse\");\n\n    assert inputSkipCount == 0;\n\n    int curNextRead = nextRead;\n\n    // Holds the longest match we've seen so far:\n    BytesRef matchOutput = null;\n    int matchInputLength = 0;\n    int matchEndOffset = -1;\n\n    BytesRef pendingOutput = fst.outputs.getNoOutput();\n    fst.getFirstArc(scratchArc);\n\n    assert scratchArc.output == fst.outputs.getNoOutput();\n\n    int tokenCount = 0;\n\n    byToken:\n    while(true) {\n      \n      // Pull next token's chars:\n      final char[] buffer;\n      final int bufferLen;\n      //System.out.println(\"  cycle nextRead=\" + curNextRead + \" nextWrite=\" + nextWrite);\n\n      int inputEndOffset = 0;\n\n      if (curNextRead == nextWrite) {\n\n        // We used up our lookahead buffer of input tokens\n        // -- pull next real input token:\n\n        if (finished) {\n          break;\n        } else  {\n          //System.out.println(\"  input.incrToken\");\n          assert futureInputs[nextWrite].consumed;\n          // Not correct: a syn match whose output is longer\n          // than its input can set future inputs keepOrig\n          // to true:\n          //assert !futureInputs[nextWrite].keepOrig;\n          if (input.incrementToken()) {\n            buffer = termAtt.buffer();\n            bufferLen = termAtt.length();\n            final PendingInput input = futureInputs[nextWrite];\n            lastStartOffset = input.startOffset = offsetAtt.startOffset();\n            lastEndOffset = input.endOffset = offsetAtt.endOffset();\n            inputEndOffset = input.endOffset;\n            //System.out.println(\"  new token=\" + new String(buffer, 0, bufferLen));\n            if (nextRead != nextWrite) {\n              capture();\n            } else {\n              input.consumed = false;\n            }\n\n          } else {\n            // No more input tokens\n            //System.out.println(\"      set end\");\n            finished = true;\n            break;\n          }\n        }\n      } else {\n        // Still in our lookahead\n        buffer = futureInputs[curNextRead].term.chars;\n        bufferLen = futureInputs[curNextRead].term.length;\n        inputEndOffset = futureInputs[curNextRead].endOffset;\n        //System.out.println(\"  old token=\" + new String(buffer, 0, bufferLen));\n      }\n\n      tokenCount++;\n\n      // Run each char in this token through the FST:\n      int bufUpto = 0;\n      while(bufUpto < bufferLen) {\n        final int codePoint = Character.codePointAt(buffer, bufUpto, bufferLen);\n        if (fst.findTargetArc(ignoreCase ? Character.toLowerCase(codePoint) : codePoint, scratchArc, scratchArc, fstReader) == null) {\n          //System.out.println(\"    stop\");\n          break byToken;\n        }\n\n        // Accum the output\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        //System.out.println(\"    char=\" + buffer[bufUpto] + \" output=\" + pendingOutput + \" arc.output=\" + scratchArc.output);\n        bufUpto += Character.charCount(codePoint);\n      }\n\n      // OK, entire token matched; now see if this is a final\n      // state:\n      if (scratchArc.isFinal()) {\n        matchOutput = fst.outputs.add(pendingOutput, scratchArc.nextFinalOutput);\n        matchInputLength = tokenCount;\n        matchEndOffset = inputEndOffset;\n        //System.out.println(\"  found matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      }\n\n      // See if the FST wants to continue matching (ie, needs to\n      // see the next input token):\n      if (fst.findTargetArc(SynonymMap.WORD_SEPARATOR, scratchArc, scratchArc, fstReader) == null) {\n        // No further rules can match here; we're done\n        // searching for matching rules starting at the\n        // current input position.\n        break;\n      } else {\n        // More matching is possible -- accum the output (if\n        // any) of the WORD_SEP arc:\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        if (nextRead == nextWrite) {\n          capture();\n        }\n      }\n\n      curNextRead = rollIncr(curNextRead);\n    }\n\n    if (nextRead == nextWrite && !finished) {\n      //System.out.println(\"  skip write slot=\" + nextWrite);\n      nextWrite = rollIncr(nextWrite);\n    }\n\n    if (matchOutput != null) {\n      //System.out.println(\"  add matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      inputSkipCount = matchInputLength;\n      addOutput(matchOutput, matchInputLength, matchEndOffset);\n    } else if (nextRead != nextWrite) {\n      // Even though we had no match here, we set to 1\n      // because we need to skip current input token before\n      // trying to match again:\n      inputSkipCount = 1;\n    } else {\n      assert finished;\n    }\n\n    //System.out.println(\"  parse done inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","date":1407854805,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#parse().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#parse().mjava","sourceNew":"  private void parse() throws IOException {\n    //System.out.println(\"\\nS: parse\");\n\n    assert inputSkipCount == 0;\n\n    int curNextRead = nextRead;\n\n    // Holds the longest match we've seen so far:\n    BytesRef matchOutput = null;\n    int matchInputLength = 0;\n    int matchEndOffset = -1;\n\n    BytesRef pendingOutput = fst.outputs.getNoOutput();\n    fst.getFirstArc(scratchArc);\n\n    assert scratchArc.output == fst.outputs.getNoOutput();\n\n    int tokenCount = 0;\n\n    byToken:\n    while(true) {\n      \n      // Pull next token's chars:\n      final char[] buffer;\n      final int bufferLen;\n      //System.out.println(\"  cycle nextRead=\" + curNextRead + \" nextWrite=\" + nextWrite);\n\n      int inputEndOffset = 0;\n\n      if (curNextRead == nextWrite) {\n\n        // We used up our lookahead buffer of input tokens\n        // -- pull next real input token:\n\n        if (finished) {\n          break;\n        } else  {\n          //System.out.println(\"  input.incrToken\");\n          assert futureInputs[nextWrite].consumed;\n          // Not correct: a syn match whose output is longer\n          // than its input can set future inputs keepOrig\n          // to true:\n          //assert !futureInputs[nextWrite].keepOrig;\n          if (input.incrementToken()) {\n            buffer = termAtt.buffer();\n            bufferLen = termAtt.length();\n            final PendingInput input = futureInputs[nextWrite];\n            lastStartOffset = input.startOffset = offsetAtt.startOffset();\n            lastEndOffset = input.endOffset = offsetAtt.endOffset();\n            inputEndOffset = input.endOffset;\n            //System.out.println(\"  new token=\" + new String(buffer, 0, bufferLen));\n            if (nextRead != nextWrite) {\n              capture();\n            } else {\n              input.consumed = false;\n            }\n\n          } else {\n            // No more input tokens\n            //System.out.println(\"      set end\");\n            finished = true;\n            break;\n          }\n        }\n      } else {\n        // Still in our lookahead\n        buffer = futureInputs[curNextRead].term.chars();\n        bufferLen = futureInputs[curNextRead].term.length();\n        inputEndOffset = futureInputs[curNextRead].endOffset;\n        //System.out.println(\"  old token=\" + new String(buffer, 0, bufferLen));\n      }\n\n      tokenCount++;\n\n      // Run each char in this token through the FST:\n      int bufUpto = 0;\n      while(bufUpto < bufferLen) {\n        final int codePoint = Character.codePointAt(buffer, bufUpto, bufferLen);\n        if (fst.findTargetArc(ignoreCase ? Character.toLowerCase(codePoint) : codePoint, scratchArc, scratchArc, fstReader) == null) {\n          //System.out.println(\"    stop\");\n          break byToken;\n        }\n\n        // Accum the output\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        //System.out.println(\"    char=\" + buffer[bufUpto] + \" output=\" + pendingOutput + \" arc.output=\" + scratchArc.output);\n        bufUpto += Character.charCount(codePoint);\n      }\n\n      // OK, entire token matched; now see if this is a final\n      // state:\n      if (scratchArc.isFinal()) {\n        matchOutput = fst.outputs.add(pendingOutput, scratchArc.nextFinalOutput);\n        matchInputLength = tokenCount;\n        matchEndOffset = inputEndOffset;\n        //System.out.println(\"  found matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      }\n\n      // See if the FST wants to continue matching (ie, needs to\n      // see the next input token):\n      if (fst.findTargetArc(SynonymMap.WORD_SEPARATOR, scratchArc, scratchArc, fstReader) == null) {\n        // No further rules can match here; we're done\n        // searching for matching rules starting at the\n        // current input position.\n        break;\n      } else {\n        // More matching is possible -- accum the output (if\n        // any) of the WORD_SEP arc:\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        if (nextRead == nextWrite) {\n          capture();\n        }\n      }\n\n      curNextRead = rollIncr(curNextRead);\n    }\n\n    if (nextRead == nextWrite && !finished) {\n      //System.out.println(\"  skip write slot=\" + nextWrite);\n      nextWrite = rollIncr(nextWrite);\n    }\n\n    if (matchOutput != null) {\n      //System.out.println(\"  add matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      inputSkipCount = matchInputLength;\n      addOutput(matchOutput, matchInputLength, matchEndOffset);\n    } else if (nextRead != nextWrite) {\n      // Even though we had no match here, we set to 1\n      // because we need to skip current input token before\n      // trying to match again:\n      inputSkipCount = 1;\n    } else {\n      assert finished;\n    }\n\n    //System.out.println(\"  parse done inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n  }\n\n","sourceOld":"  private void parse() throws IOException {\n    //System.out.println(\"\\nS: parse\");\n\n    assert inputSkipCount == 0;\n\n    int curNextRead = nextRead;\n\n    // Holds the longest match we've seen so far:\n    BytesRef matchOutput = null;\n    int matchInputLength = 0;\n    int matchEndOffset = -1;\n\n    BytesRef pendingOutput = fst.outputs.getNoOutput();\n    fst.getFirstArc(scratchArc);\n\n    assert scratchArc.output == fst.outputs.getNoOutput();\n\n    int tokenCount = 0;\n\n    byToken:\n    while(true) {\n      \n      // Pull next token's chars:\n      final char[] buffer;\n      final int bufferLen;\n      //System.out.println(\"  cycle nextRead=\" + curNextRead + \" nextWrite=\" + nextWrite);\n\n      int inputEndOffset = 0;\n\n      if (curNextRead == nextWrite) {\n\n        // We used up our lookahead buffer of input tokens\n        // -- pull next real input token:\n\n        if (finished) {\n          break;\n        } else  {\n          //System.out.println(\"  input.incrToken\");\n          assert futureInputs[nextWrite].consumed;\n          // Not correct: a syn match whose output is longer\n          // than its input can set future inputs keepOrig\n          // to true:\n          //assert !futureInputs[nextWrite].keepOrig;\n          if (input.incrementToken()) {\n            buffer = termAtt.buffer();\n            bufferLen = termAtt.length();\n            final PendingInput input = futureInputs[nextWrite];\n            lastStartOffset = input.startOffset = offsetAtt.startOffset();\n            lastEndOffset = input.endOffset = offsetAtt.endOffset();\n            inputEndOffset = input.endOffset;\n            //System.out.println(\"  new token=\" + new String(buffer, 0, bufferLen));\n            if (nextRead != nextWrite) {\n              capture();\n            } else {\n              input.consumed = false;\n            }\n\n          } else {\n            // No more input tokens\n            //System.out.println(\"      set end\");\n            finished = true;\n            break;\n          }\n        }\n      } else {\n        // Still in our lookahead\n        buffer = futureInputs[curNextRead].term.chars;\n        bufferLen = futureInputs[curNextRead].term.length;\n        inputEndOffset = futureInputs[curNextRead].endOffset;\n        //System.out.println(\"  old token=\" + new String(buffer, 0, bufferLen));\n      }\n\n      tokenCount++;\n\n      // Run each char in this token through the FST:\n      int bufUpto = 0;\n      while(bufUpto < bufferLen) {\n        final int codePoint = Character.codePointAt(buffer, bufUpto, bufferLen);\n        if (fst.findTargetArc(ignoreCase ? Character.toLowerCase(codePoint) : codePoint, scratchArc, scratchArc, fstReader) == null) {\n          //System.out.println(\"    stop\");\n          break byToken;\n        }\n\n        // Accum the output\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        //System.out.println(\"    char=\" + buffer[bufUpto] + \" output=\" + pendingOutput + \" arc.output=\" + scratchArc.output);\n        bufUpto += Character.charCount(codePoint);\n      }\n\n      // OK, entire token matched; now see if this is a final\n      // state:\n      if (scratchArc.isFinal()) {\n        matchOutput = fst.outputs.add(pendingOutput, scratchArc.nextFinalOutput);\n        matchInputLength = tokenCount;\n        matchEndOffset = inputEndOffset;\n        //System.out.println(\"  found matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      }\n\n      // See if the FST wants to continue matching (ie, needs to\n      // see the next input token):\n      if (fst.findTargetArc(SynonymMap.WORD_SEPARATOR, scratchArc, scratchArc, fstReader) == null) {\n        // No further rules can match here; we're done\n        // searching for matching rules starting at the\n        // current input position.\n        break;\n      } else {\n        // More matching is possible -- accum the output (if\n        // any) of the WORD_SEP arc:\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        if (nextRead == nextWrite) {\n          capture();\n        }\n      }\n\n      curNextRead = rollIncr(curNextRead);\n    }\n\n    if (nextRead == nextWrite && !finished) {\n      //System.out.println(\"  skip write slot=\" + nextWrite);\n      nextWrite = rollIncr(nextWrite);\n    }\n\n    if (matchOutput != null) {\n      //System.out.println(\"  add matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      inputSkipCount = matchInputLength;\n      addOutput(matchOutput, matchInputLength, matchEndOffset);\n    } else if (nextRead != nextWrite) {\n      // Even though we had no match here, we set to 1\n      // because we need to skip current input token before\n      // trying to match again:\n      inputSkipCount = 1;\n    } else {\n      assert finished;\n    }\n\n    //System.out.println(\"  parse done inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n  }\n\n","bugFix":["44d6f0ab53c1962856b9f48dedb7a2a6cc18905c"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54204c8a3ca26aeafd273139fc29baf70d0f6786","date":1564170395,"type":3,"author":"Michael Sokolov","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#parse().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#parse().mjava","sourceNew":"  private void parse() throws IOException {\n    //System.out.println(\"\\nS: parse\");\n\n    assert inputSkipCount == 0;\n\n    int curNextRead = nextRead;\n\n    // Holds the longest match we've seen so far:\n    BytesRef matchOutput = null;\n    int matchInputLength = 0;\n    int matchEndOffset = -1;\n\n    BytesRef pendingOutput = fst.outputs.getNoOutput();\n    fst.getFirstArc(scratchArc);\n\n    assert scratchArc.output() == fst.outputs.getNoOutput();\n\n    int tokenCount = 0;\n\n    byToken:\n    while(true) {\n      \n      // Pull next token's chars:\n      final char[] buffer;\n      final int bufferLen;\n      //System.out.println(\"  cycle nextRead=\" + curNextRead + \" nextWrite=\" + nextWrite);\n\n      int inputEndOffset = 0;\n\n      if (curNextRead == nextWrite) {\n\n        // We used up our lookahead buffer of input tokens\n        // -- pull next real input token:\n\n        if (finished) {\n          break;\n        } else  {\n          //System.out.println(\"  input.incrToken\");\n          assert futureInputs[nextWrite].consumed;\n          // Not correct: a syn match whose output is longer\n          // than its input can set future inputs keepOrig\n          // to true:\n          //assert !futureInputs[nextWrite].keepOrig;\n          if (input.incrementToken()) {\n            buffer = termAtt.buffer();\n            bufferLen = termAtt.length();\n            final PendingInput input = futureInputs[nextWrite];\n            lastStartOffset = input.startOffset = offsetAtt.startOffset();\n            lastEndOffset = input.endOffset = offsetAtt.endOffset();\n            inputEndOffset = input.endOffset;\n            //System.out.println(\"  new token=\" + new String(buffer, 0, bufferLen));\n            if (nextRead != nextWrite) {\n              capture();\n            } else {\n              input.consumed = false;\n            }\n\n          } else {\n            // No more input tokens\n            //System.out.println(\"      set end\");\n            finished = true;\n            break;\n          }\n        }\n      } else {\n        // Still in our lookahead\n        buffer = futureInputs[curNextRead].term.chars();\n        bufferLen = futureInputs[curNextRead].term.length();\n        inputEndOffset = futureInputs[curNextRead].endOffset;\n        //System.out.println(\"  old token=\" + new String(buffer, 0, bufferLen));\n      }\n\n      tokenCount++;\n\n      // Run each char in this token through the FST:\n      int bufUpto = 0;\n      while(bufUpto < bufferLen) {\n        final int codePoint = Character.codePointAt(buffer, bufUpto, bufferLen);\n        if (fst.findTargetArc(ignoreCase ? Character.toLowerCase(codePoint) : codePoint, scratchArc, scratchArc, fstReader) == null) {\n          //System.out.println(\"    stop\");\n          break byToken;\n        }\n\n        // Accum the output\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output());\n        //System.out.println(\"    char=\" + buffer[bufUpto] + \" output=\" + pendingOutput + \" arc.output=\" + scratchArc.output);\n        bufUpto += Character.charCount(codePoint);\n      }\n\n      // OK, entire token matched; now see if this is a final\n      // state:\n      if (scratchArc.isFinal()) {\n        matchOutput = fst.outputs.add(pendingOutput, scratchArc.nextFinalOutput());\n        matchInputLength = tokenCount;\n        matchEndOffset = inputEndOffset;\n        //System.out.println(\"  found matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      }\n\n      // See if the FST wants to continue matching (ie, needs to\n      // see the next input token):\n      if (fst.findTargetArc(SynonymMap.WORD_SEPARATOR, scratchArc, scratchArc, fstReader) == null) {\n        // No further rules can match here; we're done\n        // searching for matching rules starting at the\n        // current input position.\n        break;\n      } else {\n        // More matching is possible -- accum the output (if\n        // any) of the WORD_SEP arc:\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output());\n        if (nextRead == nextWrite) {\n          capture();\n        }\n      }\n\n      curNextRead = rollIncr(curNextRead);\n    }\n\n    if (nextRead == nextWrite && !finished) {\n      //System.out.println(\"  skip write slot=\" + nextWrite);\n      nextWrite = rollIncr(nextWrite);\n    }\n\n    if (matchOutput != null) {\n      //System.out.println(\"  add matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      inputSkipCount = matchInputLength;\n      addOutput(matchOutput, matchInputLength, matchEndOffset);\n    } else if (nextRead != nextWrite) {\n      // Even though we had no match here, we set to 1\n      // because we need to skip current input token before\n      // trying to match again:\n      inputSkipCount = 1;\n    } else {\n      assert finished;\n    }\n\n    //System.out.println(\"  parse done inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n  }\n\n","sourceOld":"  private void parse() throws IOException {\n    //System.out.println(\"\\nS: parse\");\n\n    assert inputSkipCount == 0;\n\n    int curNextRead = nextRead;\n\n    // Holds the longest match we've seen so far:\n    BytesRef matchOutput = null;\n    int matchInputLength = 0;\n    int matchEndOffset = -1;\n\n    BytesRef pendingOutput = fst.outputs.getNoOutput();\n    fst.getFirstArc(scratchArc);\n\n    assert scratchArc.output == fst.outputs.getNoOutput();\n\n    int tokenCount = 0;\n\n    byToken:\n    while(true) {\n      \n      // Pull next token's chars:\n      final char[] buffer;\n      final int bufferLen;\n      //System.out.println(\"  cycle nextRead=\" + curNextRead + \" nextWrite=\" + nextWrite);\n\n      int inputEndOffset = 0;\n\n      if (curNextRead == nextWrite) {\n\n        // We used up our lookahead buffer of input tokens\n        // -- pull next real input token:\n\n        if (finished) {\n          break;\n        } else  {\n          //System.out.println(\"  input.incrToken\");\n          assert futureInputs[nextWrite].consumed;\n          // Not correct: a syn match whose output is longer\n          // than its input can set future inputs keepOrig\n          // to true:\n          //assert !futureInputs[nextWrite].keepOrig;\n          if (input.incrementToken()) {\n            buffer = termAtt.buffer();\n            bufferLen = termAtt.length();\n            final PendingInput input = futureInputs[nextWrite];\n            lastStartOffset = input.startOffset = offsetAtt.startOffset();\n            lastEndOffset = input.endOffset = offsetAtt.endOffset();\n            inputEndOffset = input.endOffset;\n            //System.out.println(\"  new token=\" + new String(buffer, 0, bufferLen));\n            if (nextRead != nextWrite) {\n              capture();\n            } else {\n              input.consumed = false;\n            }\n\n          } else {\n            // No more input tokens\n            //System.out.println(\"      set end\");\n            finished = true;\n            break;\n          }\n        }\n      } else {\n        // Still in our lookahead\n        buffer = futureInputs[curNextRead].term.chars();\n        bufferLen = futureInputs[curNextRead].term.length();\n        inputEndOffset = futureInputs[curNextRead].endOffset;\n        //System.out.println(\"  old token=\" + new String(buffer, 0, bufferLen));\n      }\n\n      tokenCount++;\n\n      // Run each char in this token through the FST:\n      int bufUpto = 0;\n      while(bufUpto < bufferLen) {\n        final int codePoint = Character.codePointAt(buffer, bufUpto, bufferLen);\n        if (fst.findTargetArc(ignoreCase ? Character.toLowerCase(codePoint) : codePoint, scratchArc, scratchArc, fstReader) == null) {\n          //System.out.println(\"    stop\");\n          break byToken;\n        }\n\n        // Accum the output\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        //System.out.println(\"    char=\" + buffer[bufUpto] + \" output=\" + pendingOutput + \" arc.output=\" + scratchArc.output);\n        bufUpto += Character.charCount(codePoint);\n      }\n\n      // OK, entire token matched; now see if this is a final\n      // state:\n      if (scratchArc.isFinal()) {\n        matchOutput = fst.outputs.add(pendingOutput, scratchArc.nextFinalOutput);\n        matchInputLength = tokenCount;\n        matchEndOffset = inputEndOffset;\n        //System.out.println(\"  found matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      }\n\n      // See if the FST wants to continue matching (ie, needs to\n      // see the next input token):\n      if (fst.findTargetArc(SynonymMap.WORD_SEPARATOR, scratchArc, scratchArc, fstReader) == null) {\n        // No further rules can match here; we're done\n        // searching for matching rules starting at the\n        // current input position.\n        break;\n      } else {\n        // More matching is possible -- accum the output (if\n        // any) of the WORD_SEP arc:\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        if (nextRead == nextWrite) {\n          capture();\n        }\n      }\n\n      curNextRead = rollIncr(curNextRead);\n    }\n\n    if (nextRead == nextWrite && !finished) {\n      //System.out.println(\"  skip write slot=\" + nextWrite);\n      nextWrite = rollIncr(nextWrite);\n    }\n\n    if (matchOutput != null) {\n      //System.out.println(\"  add matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      inputSkipCount = matchInputLength;\n      addOutput(matchOutput, matchInputLength, matchEndOffset);\n    } else if (nextRead != nextWrite) {\n      // Even though we had no match here, we set to 1\n      // because we need to skip current input token before\n      // trying to match again:\n      inputSkipCount = 1;\n    } else {\n      assert finished;\n    }\n\n    //System.out.println(\"  parse done inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8061ddd97f3352007d927dae445884a6f3d857b","date":1564988276,"type":3,"author":"Atri Sharma","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#parse().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter#parse().mjava","sourceNew":"  private void parse() throws IOException {\n    //System.out.println(\"\\nS: parse\");\n\n    assert inputSkipCount == 0;\n\n    int curNextRead = nextRead;\n\n    // Holds the longest match we've seen so far:\n    BytesRef matchOutput = null;\n    int matchInputLength = 0;\n    int matchEndOffset = -1;\n\n    BytesRef pendingOutput = fst.outputs.getNoOutput();\n    fst.getFirstArc(scratchArc);\n\n    assert scratchArc.output() == fst.outputs.getNoOutput();\n\n    int tokenCount = 0;\n\n    byToken:\n    while(true) {\n      \n      // Pull next token's chars:\n      final char[] buffer;\n      final int bufferLen;\n      //System.out.println(\"  cycle nextRead=\" + curNextRead + \" nextWrite=\" + nextWrite);\n\n      int inputEndOffset = 0;\n\n      if (curNextRead == nextWrite) {\n\n        // We used up our lookahead buffer of input tokens\n        // -- pull next real input token:\n\n        if (finished) {\n          break;\n        } else  {\n          //System.out.println(\"  input.incrToken\");\n          assert futureInputs[nextWrite].consumed;\n          // Not correct: a syn match whose output is longer\n          // than its input can set future inputs keepOrig\n          // to true:\n          //assert !futureInputs[nextWrite].keepOrig;\n          if (input.incrementToken()) {\n            buffer = termAtt.buffer();\n            bufferLen = termAtt.length();\n            final PendingInput input = futureInputs[nextWrite];\n            lastStartOffset = input.startOffset = offsetAtt.startOffset();\n            lastEndOffset = input.endOffset = offsetAtt.endOffset();\n            inputEndOffset = input.endOffset;\n            //System.out.println(\"  new token=\" + new String(buffer, 0, bufferLen));\n            if (nextRead != nextWrite) {\n              capture();\n            } else {\n              input.consumed = false;\n            }\n\n          } else {\n            // No more input tokens\n            //System.out.println(\"      set end\");\n            finished = true;\n            break;\n          }\n        }\n      } else {\n        // Still in our lookahead\n        buffer = futureInputs[curNextRead].term.chars();\n        bufferLen = futureInputs[curNextRead].term.length();\n        inputEndOffset = futureInputs[curNextRead].endOffset;\n        //System.out.println(\"  old token=\" + new String(buffer, 0, bufferLen));\n      }\n\n      tokenCount++;\n\n      // Run each char in this token through the FST:\n      int bufUpto = 0;\n      while(bufUpto < bufferLen) {\n        final int codePoint = Character.codePointAt(buffer, bufUpto, bufferLen);\n        if (fst.findTargetArc(ignoreCase ? Character.toLowerCase(codePoint) : codePoint, scratchArc, scratchArc, fstReader) == null) {\n          //System.out.println(\"    stop\");\n          break byToken;\n        }\n\n        // Accum the output\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output());\n        //System.out.println(\"    char=\" + buffer[bufUpto] + \" output=\" + pendingOutput + \" arc.output=\" + scratchArc.output);\n        bufUpto += Character.charCount(codePoint);\n      }\n\n      // OK, entire token matched; now see if this is a final\n      // state:\n      if (scratchArc.isFinal()) {\n        matchOutput = fst.outputs.add(pendingOutput, scratchArc.nextFinalOutput());\n        matchInputLength = tokenCount;\n        matchEndOffset = inputEndOffset;\n        //System.out.println(\"  found matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      }\n\n      // See if the FST wants to continue matching (ie, needs to\n      // see the next input token):\n      if (fst.findTargetArc(SynonymMap.WORD_SEPARATOR, scratchArc, scratchArc, fstReader) == null) {\n        // No further rules can match here; we're done\n        // searching for matching rules starting at the\n        // current input position.\n        break;\n      } else {\n        // More matching is possible -- accum the output (if\n        // any) of the WORD_SEP arc:\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output());\n        if (nextRead == nextWrite) {\n          capture();\n        }\n      }\n\n      curNextRead = rollIncr(curNextRead);\n    }\n\n    if (nextRead == nextWrite && !finished) {\n      //System.out.println(\"  skip write slot=\" + nextWrite);\n      nextWrite = rollIncr(nextWrite);\n    }\n\n    if (matchOutput != null) {\n      //System.out.println(\"  add matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      inputSkipCount = matchInputLength;\n      addOutput(matchOutput, matchInputLength, matchEndOffset);\n    } else if (nextRead != nextWrite) {\n      // Even though we had no match here, we set to 1\n      // because we need to skip current input token before\n      // trying to match again:\n      inputSkipCount = 1;\n    } else {\n      assert finished;\n    }\n\n    //System.out.println(\"  parse done inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n  }\n\n","sourceOld":"  private void parse() throws IOException {\n    //System.out.println(\"\\nS: parse\");\n\n    assert inputSkipCount == 0;\n\n    int curNextRead = nextRead;\n\n    // Holds the longest match we've seen so far:\n    BytesRef matchOutput = null;\n    int matchInputLength = 0;\n    int matchEndOffset = -1;\n\n    BytesRef pendingOutput = fst.outputs.getNoOutput();\n    fst.getFirstArc(scratchArc);\n\n    assert scratchArc.output == fst.outputs.getNoOutput();\n\n    int tokenCount = 0;\n\n    byToken:\n    while(true) {\n      \n      // Pull next token's chars:\n      final char[] buffer;\n      final int bufferLen;\n      //System.out.println(\"  cycle nextRead=\" + curNextRead + \" nextWrite=\" + nextWrite);\n\n      int inputEndOffset = 0;\n\n      if (curNextRead == nextWrite) {\n\n        // We used up our lookahead buffer of input tokens\n        // -- pull next real input token:\n\n        if (finished) {\n          break;\n        } else  {\n          //System.out.println(\"  input.incrToken\");\n          assert futureInputs[nextWrite].consumed;\n          // Not correct: a syn match whose output is longer\n          // than its input can set future inputs keepOrig\n          // to true:\n          //assert !futureInputs[nextWrite].keepOrig;\n          if (input.incrementToken()) {\n            buffer = termAtt.buffer();\n            bufferLen = termAtt.length();\n            final PendingInput input = futureInputs[nextWrite];\n            lastStartOffset = input.startOffset = offsetAtt.startOffset();\n            lastEndOffset = input.endOffset = offsetAtt.endOffset();\n            inputEndOffset = input.endOffset;\n            //System.out.println(\"  new token=\" + new String(buffer, 0, bufferLen));\n            if (nextRead != nextWrite) {\n              capture();\n            } else {\n              input.consumed = false;\n            }\n\n          } else {\n            // No more input tokens\n            //System.out.println(\"      set end\");\n            finished = true;\n            break;\n          }\n        }\n      } else {\n        // Still in our lookahead\n        buffer = futureInputs[curNextRead].term.chars();\n        bufferLen = futureInputs[curNextRead].term.length();\n        inputEndOffset = futureInputs[curNextRead].endOffset;\n        //System.out.println(\"  old token=\" + new String(buffer, 0, bufferLen));\n      }\n\n      tokenCount++;\n\n      // Run each char in this token through the FST:\n      int bufUpto = 0;\n      while(bufUpto < bufferLen) {\n        final int codePoint = Character.codePointAt(buffer, bufUpto, bufferLen);\n        if (fst.findTargetArc(ignoreCase ? Character.toLowerCase(codePoint) : codePoint, scratchArc, scratchArc, fstReader) == null) {\n          //System.out.println(\"    stop\");\n          break byToken;\n        }\n\n        // Accum the output\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        //System.out.println(\"    char=\" + buffer[bufUpto] + \" output=\" + pendingOutput + \" arc.output=\" + scratchArc.output);\n        bufUpto += Character.charCount(codePoint);\n      }\n\n      // OK, entire token matched; now see if this is a final\n      // state:\n      if (scratchArc.isFinal()) {\n        matchOutput = fst.outputs.add(pendingOutput, scratchArc.nextFinalOutput);\n        matchInputLength = tokenCount;\n        matchEndOffset = inputEndOffset;\n        //System.out.println(\"  found matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      }\n\n      // See if the FST wants to continue matching (ie, needs to\n      // see the next input token):\n      if (fst.findTargetArc(SynonymMap.WORD_SEPARATOR, scratchArc, scratchArc, fstReader) == null) {\n        // No further rules can match here; we're done\n        // searching for matching rules starting at the\n        // current input position.\n        break;\n      } else {\n        // More matching is possible -- accum the output (if\n        // any) of the WORD_SEP arc:\n        pendingOutput = fst.outputs.add(pendingOutput, scratchArc.output);\n        if (nextRead == nextWrite) {\n          capture();\n        }\n      }\n\n      curNextRead = rollIncr(curNextRead);\n    }\n\n    if (nextRead == nextWrite && !finished) {\n      //System.out.println(\"  skip write slot=\" + nextWrite);\n      nextWrite = rollIncr(nextWrite);\n    }\n\n    if (matchOutput != null) {\n      //System.out.println(\"  add matchLength=\" + matchInputLength + \" output=\" + matchOutput);\n      inputSkipCount = matchInputLength;\n      addOutput(matchOutput, matchInputLength, matchEndOffset);\n    } else if (nextRead != nextWrite) {\n      // Even though we had no match here, we set to 1\n      // because we need to skip current input token before\n      // trying to match again:\n      inputSkipCount = 1;\n    } else {\n      assert finished;\n    }\n\n    //System.out.println(\"  parse done inputSkipCount=\" + inputSkipCount + \" nextRead=\" + nextRead + \" nextWrite=\" + nextWrite);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"54204c8a3ca26aeafd273139fc29baf70d0f6786":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"f8061ddd97f3352007d927dae445884a6f3d857b":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","54204c8a3ca26aeafd273139fc29baf70d0f6786"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["54204c8a3ca26aeafd273139fc29baf70d0f6786"]},"commit2Childs":{"54204c8a3ca26aeafd273139fc29baf70d0f6786":["f8061ddd97f3352007d927dae445884a6f3d857b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["54204c8a3ca26aeafd273139fc29baf70d0f6786","f8061ddd97f3352007d927dae445884a6f3d857b"],"f8061ddd97f3352007d927dae445884a6f3d857b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["f8061ddd97f3352007d927dae445884a6f3d857b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}