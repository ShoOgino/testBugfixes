{"path":"solr/core/src/test/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice#initializeAddReplicaPool(Configuration).mjava","commits":[{"id":"44ca189138a5b6e1989d12ab992fab60e235ddc7","date":1549051496,"type":0,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice#initializeAddReplicaPool(Configuration).mjava","pathOld":"/dev/null","sourceNew":"  private synchronized void initializeAddReplicaPool(Configuration conf) {\n    if (addReplicaThreadPool == null) {\n      FsDatasetImpl dataset = (FsDatasetImpl) volume.getDataset();\n      int numberOfBlockPoolSlice = dataset.getVolumeCount()\n          * dataset.getBPServiceCount();\n      int poolsize = Math.max(numberOfBlockPoolSlice,\n          VOLUMES_REPLICA_ADD_THREADPOOL_SIZE);\n      // Default pool sizes is max of (volume * number of bp_service) and\n      // number of processor.\n      int parallelism = conf.getInt(\n          DFSConfigKeys.DFS_DATANODE_VOLUMES_REPLICA_ADD_THREADPOOL_SIZE_KEY,\n          poolsize);\n\n      // Needed for SOLR-9515 and HDFS-14251\n      ForkJoinPool.ForkJoinWorkerThreadFactory threadFactory = new HdfsTestUtil.HDFSForkJoinThreadFactory();\n      addReplicaThreadPool = new ForkJoinPool(parallelism, threadFactory, null, false);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"44ca189138a5b6e1989d12ab992fab60e235ddc7":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["44ca189138a5b6e1989d12ab992fab60e235ddc7"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["44ca189138a5b6e1989d12ab992fab60e235ddc7"],"44ca189138a5b6e1989d12ab992fab60e235ddc7":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}