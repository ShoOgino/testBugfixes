{"path":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,IndexDocument,Analyzer).mjava","commits":[{"id":"33e9fa3b49f4a365a04fdfc8a32dbcd0df798f5a","date":1341524239,"type":1,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,IndexDocument,Analyzer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Iterable[#-extends-IndexableField],Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, IndexDocument doc, Analyzer analyzer)\n      throws IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      boolean anySegmentFlushed = false;\n      try {\n        anySegmentFlushed = docWriter.updateDocument(doc, analyzer, term);\n        success = true;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception updating document\");\n          }\n        }\n      }\n\n      if (anySegmentFlushed) {\n        maybeMerge();\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Iterable<? extends IndexableField> doc, Analyzer analyzer)\n      throws IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      boolean anySegmentFlushed = false;\n      try {\n        anySegmentFlushed = docWriter.updateDocument(doc, analyzer, term);\n        success = true;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception updating document\");\n          }\n        }\n      }\n\n      if (anySegmentFlushed) {\n        maybeMerge();\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1d028314cced5858683a1bb4741423d0f934257b","date":1346596535,"type":1,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,IndexDocument,Analyzer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Iterable[#-extends-IndexableField],Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, IndexDocument doc, Analyzer analyzer)\n      throws IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      boolean anySegmentFlushed = false;\n      try {\n        anySegmentFlushed = docWriter.updateDocument(doc, analyzer, term);\n        success = true;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception updating document\");\n          }\n        }\n      }\n\n      if (anySegmentFlushed) {\n        maybeMerge();\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Iterable<? extends IndexableField> doc, Analyzer analyzer)\n      throws IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      boolean anySegmentFlushed = false;\n      try {\n        anySegmentFlushed = docWriter.updateDocument(doc, analyzer, term);\n        success = true;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception updating document\");\n          }\n        }\n      }\n\n      if (anySegmentFlushed) {\n        maybeMerge();\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"181b1aa5a99534972fbfd5595cdbb38bba5f39ee","date":1350576187,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,IndexDocument,Analyzer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,IndexDocument,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, IndexDocument doc, Analyzer analyzer)\n      throws IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      boolean anySegmentFlushed = false;\n      try {\n        anySegmentFlushed = docWriter.updateDocument(doc, analyzer, term);\n        success = true;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception updating document\");\n          }\n        }\n      }\n\n      if (anySegmentFlushed) {\n        maybeMerge(MergeTrigger.SEGMENT_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, IndexDocument doc, Analyzer analyzer)\n      throws IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      boolean anySegmentFlushed = false;\n      try {\n        anySegmentFlushed = docWriter.updateDocument(doc, analyzer, term);\n        success = true;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception updating document\");\n          }\n        }\n      }\n\n      if (anySegmentFlushed) {\n        maybeMerge();\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"62e52115b56781006682fd92c6938efaf174304d","date":1351014780,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,IndexDocument,Analyzer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,IndexDocument,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, IndexDocument doc, Analyzer analyzer)\n      throws IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      boolean anySegmentFlushed = false;\n      try {\n        anySegmentFlushed = docWriter.updateDocument(doc, analyzer, term);\n        success = true;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception updating document\");\n          }\n        }\n      }\n\n      if (anySegmentFlushed) {\n        maybeMerge(MergeTrigger.SEGMENT_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, IndexDocument doc, Analyzer analyzer)\n      throws IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      boolean anySegmentFlushed = false;\n      try {\n        anySegmentFlushed = docWriter.updateDocument(doc, analyzer, term);\n        success = true;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception updating document\");\n          }\n        }\n      }\n\n      if (anySegmentFlushed) {\n        maybeMerge();\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7af110b00ea8df9429309d83e38e0533d82e144f","date":1376924768,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,IndexDocument,Analyzer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,IndexDocument,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, IndexDocument doc, Analyzer analyzer)\n      throws IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      try {\n        if (docWriter.updateDocument(doc, analyzer, term)) {\n          processEvents(true, false);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception updating document\");\n          }\n        }\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, IndexDocument doc, Analyzer analyzer)\n      throws IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      boolean anySegmentFlushed = false;\n      try {\n        anySegmentFlushed = docWriter.updateDocument(doc, analyzer, term);\n        success = true;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception updating document\");\n          }\n        }\n      }\n\n      if (anySegmentFlushed) {\n        maybeMerge(MergeTrigger.SEGMENT_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"31d4861802ca404d78ca1d15f4550eec415b9199","date":1376947894,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,IndexDocument,Analyzer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,IndexDocument,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, IndexDocument doc, Analyzer analyzer)\n      throws IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      try {\n        if (docWriter.updateDocument(doc, analyzer, term)) {\n          processEvents(true, false);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception updating document\");\n          }\n        }\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, IndexDocument doc, Analyzer analyzer)\n      throws IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      boolean anySegmentFlushed = false;\n      try {\n        anySegmentFlushed = docWriter.updateDocument(doc, analyzer, term);\n        success = true;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception updating document\");\n          }\n        }\n      }\n\n      if (anySegmentFlushed) {\n        maybeMerge(MergeTrigger.SEGMENT_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3dffec77fb8f7d0e9ca4869dddd6af94528b4576","date":1377875202,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,IndexDocument,Analyzer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,IndexDocument,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, IndexDocument doc, Analyzer analyzer)\n      throws IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      try {\n        if (docWriter.updateDocument(doc, analyzer, term)) {\n          processEvents(true, false);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception updating document\");\n          }\n        }\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, IndexDocument doc, Analyzer analyzer)\n      throws IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      boolean anySegmentFlushed = false;\n      try {\n        anySegmentFlushed = docWriter.updateDocument(doc, analyzer, term);\n        success = true;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception updating document\");\n          }\n        }\n      }\n\n      if (anySegmentFlushed) {\n        maybeMerge(MergeTrigger.SEGMENT_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"949847c0040cd70a68222d526cb0da7bf6cbb3c2","date":1410997182,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,IndexDocument,Analyzer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,IndexDocument,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, IndexDocument doc, Analyzer analyzer)\n      throws IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      try {\n        if (docWriter.updateDocument(doc, analyzer, term)) {\n          processEvents(true, false);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception updating document\");\n          }\n        }\n      }\n    } catch (OutOfMemoryError oom) {\n      tragicEvent(oom, \"updateDocument\");\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, IndexDocument doc, Analyzer analyzer)\n      throws IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      try {\n        if (docWriter.updateDocument(doc, analyzer, term)) {\n          processEvents(true, false);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception updating document\");\n          }\n        }\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9299079153fd7895bf3cf6835cf7019af2ba89b3","date":1417813477,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,IndexDocument,Analyzer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,IndexDocument,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, IndexDocument doc, Analyzer analyzer)\n      throws IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      try {\n        if (docWriter.updateDocument(doc, analyzer, term)) {\n          processEvents(true, false);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception updating document\");\n          }\n        }\n      }\n    } catch (AbortingException | OutOfMemoryError tragedy) {\n      tragicEvent(tragedy, \"updateDocument\");\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, IndexDocument doc, Analyzer analyzer)\n      throws IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      try {\n        if (docWriter.updateDocument(doc, analyzer, term)) {\n          processEvents(true, false);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception updating document\");\n          }\n        }\n      }\n    } catch (OutOfMemoryError oom) {\n      tragicEvent(oom, \"updateDocument\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5c1c5aa8e88aa52c9e1cbfc696b611d3a56223c0","date":1422781929,"type":4,"author":"Michael McCandless","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,IndexDocument,Analyzer).mjava","sourceNew":null,"sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, IndexDocument doc, Analyzer analyzer)\n      throws IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      try {\n        if (docWriter.updateDocument(doc, analyzer, term)) {\n          processEvents(true, false);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception updating document\");\n          }\n        }\n      }\n    } catch (AbortingException | OutOfMemoryError tragedy) {\n      tragicEvent(tragedy, \"updateDocument\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7af110b00ea8df9429309d83e38e0533d82e144f":["181b1aa5a99534972fbfd5595cdbb38bba5f39ee"],"1d028314cced5858683a1bb4741423d0f934257b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","33e9fa3b49f4a365a04fdfc8a32dbcd0df798f5a"],"33e9fa3b49f4a365a04fdfc8a32dbcd0df798f5a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"62e52115b56781006682fd92c6938efaf174304d":["1d028314cced5858683a1bb4741423d0f934257b","181b1aa5a99534972fbfd5595cdbb38bba5f39ee"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":["181b1aa5a99534972fbfd5595cdbb38bba5f39ee","7af110b00ea8df9429309d83e38e0533d82e144f"],"31d4861802ca404d78ca1d15f4550eec415b9199":["181b1aa5a99534972fbfd5595cdbb38bba5f39ee","7af110b00ea8df9429309d83e38e0533d82e144f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"181b1aa5a99534972fbfd5595cdbb38bba5f39ee":["1d028314cced5858683a1bb4741423d0f934257b"],"9299079153fd7895bf3cf6835cf7019af2ba89b3":["949847c0040cd70a68222d526cb0da7bf6cbb3c2"],"949847c0040cd70a68222d526cb0da7bf6cbb3c2":["7af110b00ea8df9429309d83e38e0533d82e144f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["5c1c5aa8e88aa52c9e1cbfc696b611d3a56223c0"],"5c1c5aa8e88aa52c9e1cbfc696b611d3a56223c0":["9299079153fd7895bf3cf6835cf7019af2ba89b3"]},"commit2Childs":{"7af110b00ea8df9429309d83e38e0533d82e144f":["3dffec77fb8f7d0e9ca4869dddd6af94528b4576","31d4861802ca404d78ca1d15f4550eec415b9199","949847c0040cd70a68222d526cb0da7bf6cbb3c2"],"1d028314cced5858683a1bb4741423d0f934257b":["62e52115b56781006682fd92c6938efaf174304d","181b1aa5a99534972fbfd5595cdbb38bba5f39ee"],"33e9fa3b49f4a365a04fdfc8a32dbcd0df798f5a":["1d028314cced5858683a1bb4741423d0f934257b"],"62e52115b56781006682fd92c6938efaf174304d":[],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":[],"31d4861802ca404d78ca1d15f4550eec415b9199":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1d028314cced5858683a1bb4741423d0f934257b","33e9fa3b49f4a365a04fdfc8a32dbcd0df798f5a"],"181b1aa5a99534972fbfd5595cdbb38bba5f39ee":["7af110b00ea8df9429309d83e38e0533d82e144f","62e52115b56781006682fd92c6938efaf174304d","3dffec77fb8f7d0e9ca4869dddd6af94528b4576","31d4861802ca404d78ca1d15f4550eec415b9199"],"9299079153fd7895bf3cf6835cf7019af2ba89b3":["5c1c5aa8e88aa52c9e1cbfc696b611d3a56223c0"],"949847c0040cd70a68222d526cb0da7bf6cbb3c2":["9299079153fd7895bf3cf6835cf7019af2ba89b3"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"5c1c5aa8e88aa52c9e1cbfc696b611d3a56223c0":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["62e52115b56781006682fd92c6938efaf174304d","3dffec77fb8f7d0e9ca4869dddd6af94528b4576","31d4861802ca404d78ca1d15f4550eec415b9199","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}