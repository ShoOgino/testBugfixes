{"path":"lucene/src/java/org/apache/lucene/index/TermVectorsReader#get(int,String,TermVectorMapper).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermVectorsReader#get(int,String,TermVectorMapper).mjava","pathOld":"src/java/org/apache/lucene/index/TermVectorsReader#get(int,String,TermVectorMapper).mjava","sourceNew":"  public void get(int docNum, String field, TermVectorMapper mapper) throws IOException {\n    if (tvx != null) {\n      int fieldNumber = fieldInfos.fieldNumber(field);\n      //We need to account for the FORMAT_SIZE at when seeking in the tvx\n      //We don't need to do this in other seeks because we already have the\n      // file pointer\n      //that was written in another file\n      seekTvx(docNum);\n      //System.out.println(\"TVX Pointer: \" + tvx.getFilePointer());\n      long tvdPosition = tvx.readLong();\n\n      tvd.seek(tvdPosition);\n      int fieldCount = tvd.readVInt();\n      //System.out.println(\"Num Fields: \" + fieldCount);\n      // There are only a few fields per document. We opt for a full scan\n      // rather then requiring that they be ordered. We need to read through\n      // all of the fields anyway to get to the tvf pointers.\n      int number = 0;\n      int found = -1;\n      for (int i = 0; i < fieldCount; i++) {\n        if (format >= FORMAT_VERSION)\n          number = tvd.readVInt();\n        else\n          number += tvd.readVInt();\n\n        if (number == fieldNumber)\n          found = i;\n      }\n\n      // This field, although valid in the segment, was not found in this\n      // document\n      if (found != -1) {\n        // Compute position in the tvf file\n        long position;\n        if (format >= FORMAT_VERSION2)\n          position = tvx.readLong();\n        else\n          position = tvd.readVLong();\n        for (int i = 1; i <= found; i++)\n          position += tvd.readVLong();\n\n        mapper.setDocumentNumber(docNum);\n        readTermVector(field, position, mapper);\n      } else {\n        //System.out.println(\"Fieldable not found\");\n      }\n    } else {\n      //System.out.println(\"No tvx file\");\n    }\n  }\n\n","sourceOld":"  public void get(int docNum, String field, TermVectorMapper mapper) throws IOException {\n    if (tvx != null) {\n      int fieldNumber = fieldInfos.fieldNumber(field);\n      //We need to account for the FORMAT_SIZE at when seeking in the tvx\n      //We don't need to do this in other seeks because we already have the\n      // file pointer\n      //that was written in another file\n      seekTvx(docNum);\n      //System.out.println(\"TVX Pointer: \" + tvx.getFilePointer());\n      long tvdPosition = tvx.readLong();\n\n      tvd.seek(tvdPosition);\n      int fieldCount = tvd.readVInt();\n      //System.out.println(\"Num Fields: \" + fieldCount);\n      // There are only a few fields per document. We opt for a full scan\n      // rather then requiring that they be ordered. We need to read through\n      // all of the fields anyway to get to the tvf pointers.\n      int number = 0;\n      int found = -1;\n      for (int i = 0; i < fieldCount; i++) {\n        if (format >= FORMAT_VERSION)\n          number = tvd.readVInt();\n        else\n          number += tvd.readVInt();\n\n        if (number == fieldNumber)\n          found = i;\n      }\n\n      // This field, although valid in the segment, was not found in this\n      // document\n      if (found != -1) {\n        // Compute position in the tvf file\n        long position;\n        if (format >= FORMAT_VERSION2)\n          position = tvx.readLong();\n        else\n          position = tvd.readVLong();\n        for (int i = 1; i <= found; i++)\n          position += tvd.readVLong();\n\n        mapper.setDocumentNumber(docNum);\n        readTermVector(field, position, mapper);\n      } else {\n        //System.out.println(\"Fieldable not found\");\n      }\n    } else {\n      //System.out.println(\"No tvx file\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6267e1ce56c2eec111425690cd04e251b6f14952","date":1275222352,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermVectorsReader#get(int,String,TermVectorMapper).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermVectorsReader#get(int,String,TermVectorMapper).mjava","sourceNew":"  public void get(int docNum, String field, TermVectorMapper mapper) throws IOException {\n    if (tvx != null) {\n      int fieldNumber = fieldInfos.fieldNumber(field);\n      //We need to account for the FORMAT_SIZE at when seeking in the tvx\n      //We don't need to do this in other seeks because we already have the\n      // file pointer\n      //that was written in another file\n      seekTvx(docNum);\n      //System.out.println(\"TVX Pointer: \" + tvx.getFilePointer());\n      long tvdPosition = tvx.readLong();\n\n      tvd.seek(tvdPosition);\n      int fieldCount = tvd.readVInt();\n      //System.out.println(\"Num Fields: \" + fieldCount);\n      // There are only a few fields per document. We opt for a full scan\n      // rather then requiring that they be ordered. We need to read through\n      // all of the fields anyway to get to the tvf pointers.\n      int number = 0;\n      int found = -1;\n      for (int i = 0; i < fieldCount; i++) {\n        number = tvd.readVInt();\n        if (number == fieldNumber)\n          found = i;\n      }\n\n      // This field, although valid in the segment, was not found in this\n      // document\n      if (found != -1) {\n        // Compute position in the tvf file\n        long position = tvx.readLong();\n        for (int i = 1; i <= found; i++)\n          position += tvd.readVLong();\n\n        mapper.setDocumentNumber(docNum);\n        readTermVector(field, position, mapper);\n      } else {\n        //System.out.println(\"Fieldable not found\");\n      }\n    } else {\n      //System.out.println(\"No tvx file\");\n    }\n  }\n\n","sourceOld":"  public void get(int docNum, String field, TermVectorMapper mapper) throws IOException {\n    if (tvx != null) {\n      int fieldNumber = fieldInfos.fieldNumber(field);\n      //We need to account for the FORMAT_SIZE at when seeking in the tvx\n      //We don't need to do this in other seeks because we already have the\n      // file pointer\n      //that was written in another file\n      seekTvx(docNum);\n      //System.out.println(\"TVX Pointer: \" + tvx.getFilePointer());\n      long tvdPosition = tvx.readLong();\n\n      tvd.seek(tvdPosition);\n      int fieldCount = tvd.readVInt();\n      //System.out.println(\"Num Fields: \" + fieldCount);\n      // There are only a few fields per document. We opt for a full scan\n      // rather then requiring that they be ordered. We need to read through\n      // all of the fields anyway to get to the tvf pointers.\n      int number = 0;\n      int found = -1;\n      for (int i = 0; i < fieldCount; i++) {\n        if (format >= FORMAT_VERSION)\n          number = tvd.readVInt();\n        else\n          number += tvd.readVInt();\n\n        if (number == fieldNumber)\n          found = i;\n      }\n\n      // This field, although valid in the segment, was not found in this\n      // document\n      if (found != -1) {\n        // Compute position in the tvf file\n        long position;\n        if (format >= FORMAT_VERSION2)\n          position = tvx.readLong();\n        else\n          position = tvd.readVLong();\n        for (int i = 1; i <= found; i++)\n          position += tvd.readVLong();\n\n        mapper.setDocumentNumber(docNum);\n        readTermVector(field, position, mapper);\n      } else {\n        //System.out.println(\"Fieldable not found\");\n      }\n    } else {\n      //System.out.println(\"No tvx file\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3cc749c053615f5871f3b95715fe292f34e70a53","date":1321470575,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/TermVectorsReader#get(int,String,TermVectorMapper).mjava","sourceNew":null,"sourceOld":"  public void get(int docNum, String field, TermVectorMapper mapper) throws IOException {\n    if (tvx != null) {\n      int fieldNumber = fieldInfos.fieldNumber(field);\n      //We need to account for the FORMAT_SIZE at when seeking in the tvx\n      //We don't need to do this in other seeks because we already have the\n      // file pointer\n      //that was written in another file\n      seekTvx(docNum);\n      //System.out.println(\"TVX Pointer: \" + tvx.getFilePointer());\n      long tvdPosition = tvx.readLong();\n\n      tvd.seek(tvdPosition);\n      int fieldCount = tvd.readVInt();\n      //System.out.println(\"Num Fields: \" + fieldCount);\n      // There are only a few fields per document. We opt for a full scan\n      // rather then requiring that they be ordered. We need to read through\n      // all of the fields anyway to get to the tvf pointers.\n      int number = 0;\n      int found = -1;\n      for (int i = 0; i < fieldCount; i++) {\n        number = tvd.readVInt();\n        if (number == fieldNumber)\n          found = i;\n      }\n\n      // This field, although valid in the segment, was not found in this\n      // document\n      if (found != -1) {\n        // Compute position in the tvf file\n        long position = tvx.readLong();\n        for (int i = 1; i <= found; i++)\n          position += tvd.readVLong();\n\n        mapper.setDocumentNumber(docNum);\n        readTermVector(field, position, mapper);\n      } else {\n        //System.out.println(\"Fieldable not found\");\n      }\n    } else {\n      //System.out.println(\"No tvx file\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"6267e1ce56c2eec111425690cd04e251b6f14952":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cc749c053615f5871f3b95715fe292f34e70a53":["6267e1ce56c2eec111425690cd04e251b6f14952"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3cc749c053615f5871f3b95715fe292f34e70a53"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"6267e1ce56c2eec111425690cd04e251b6f14952":["3cc749c053615f5871f3b95715fe292f34e70a53"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"3cc749c053615f5871f3b95715fe292f34e70a53":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["6267e1ce56c2eec111425690cd04e251b6f14952"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}