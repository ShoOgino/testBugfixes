{"path":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","commits":[{"id":"f09ac0abea5345f77c4cf8d9f0d531da9139debc","date":1311103501,"type":1,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","pathOld":"solr/core/src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass\n          (analyzerName).asSubclass(Analyzer.class);\n        \n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr \n            = clazz.getConstructor(Version.class);\n          final String matchVersionStr \n            = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            schema.getDefaultLuceneMatchVersion() : \n            Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      ( \"[schema.xml] analyzer/charFilter\", false, false ) {\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, \n                       schema.getDefaultLuceneMatchVersion().toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, (NodeList)xpath.evaluate(\"./charFilter\",  node, XPathConstants.NODESET) );\n                            \n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      ( \"[schema.xml] analyzer/tokenizer\", false, false ) {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, \n                     schema.getDefaultLuceneMatchVersion().toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<TokenFilterFactory>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, \n                       schema.getDefaultLuceneMatchVersion().toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass\n          (analyzerName).asSubclass(Analyzer.class);\n\n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr = clazz.getConstructor(Version.class);\n          final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            solrConfig.luceneMatchVersion : Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a7ebf3a5f9e588d0bb564ac30d6dc32056ce9a41","date":1334628185,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","pathOld":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        \n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr \n            = clazz.getConstructor(Version.class);\n          final String matchVersionStr \n            = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            schema.getDefaultLuceneMatchVersion() : \n            Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, \n                       schema.getDefaultLuceneMatchVersion().toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, (NodeList)xpath.evaluate(\"./charFilter\",  node, XPathConstants.NODESET) );\n                            \n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, \n                     schema.getDefaultLuceneMatchVersion().toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<TokenFilterFactory>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, \n                       schema.getDefaultLuceneMatchVersion().toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass\n          (analyzerName).asSubclass(Analyzer.class);\n        \n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr \n            = clazz.getConstructor(Version.class);\n          final String matchVersionStr \n            = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            schema.getDefaultLuceneMatchVersion() : \n            Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      ( \"[schema.xml] analyzer/charFilter\", false, false ) {\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, \n                       schema.getDefaultLuceneMatchVersion().toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, (NodeList)xpath.evaluate(\"./charFilter\",  node, XPathConstants.NODESET) );\n                            \n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      ( \"[schema.xml] analyzer/tokenizer\", false, false ) {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, \n                     schema.getDefaultLuceneMatchVersion().toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<TokenFilterFactory>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, \n                       schema.getDefaultLuceneMatchVersion().toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6d3ad4230a9094e97925f9395cf6db4729284d9","date":1335503918,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","pathOld":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        \n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr \n            = clazz.getConstructor(Version.class);\n          final String matchVersionStr \n            = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            schema.getDefaultLuceneMatchVersion() : \n            Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n          String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n          plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, (NodeList)xpath.evaluate(\"./charFilter\",  node, XPathConstants.NODESET) );\n                            \n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<TokenFilterFactory>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n          String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n          plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        \n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr \n            = clazz.getConstructor(Version.class);\n          final String matchVersionStr \n            = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            schema.getDefaultLuceneMatchVersion() : \n            Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, \n                       schema.getDefaultLuceneMatchVersion().toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, (NodeList)xpath.evaluate(\"./charFilter\",  node, XPathConstants.NODESET) );\n                            \n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, \n                     schema.getDefaultLuceneMatchVersion().toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<TokenFilterFactory>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, \n                       schema.getDefaultLuceneMatchVersion().toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"88b3e8520b7ff30e6ffd93e6c1cda658ebeeaf0c","date":1343141172,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","pathOld":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        \n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr \n            = clazz.getConstructor(Version.class);\n          final String matchVersionStr \n            = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            schema.getDefaultLuceneMatchVersion() : \n            Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<CharFilterFactory>();\n    AnalysisPluginLoader<CharFilterFactory> charFilterLoader =\n      new AnalysisPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected CharFilterFactory createSPI(String name) {\n        return CharFilterFactory.forName(name);\n      }\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n          String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n          plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, (NodeList)xpath.evaluate(\"./charFilter\",  node, XPathConstants.NODESET) );\n                            \n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<TokenizerFactory>(1);\n    AnalysisPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AnalysisPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      \n      @Override\n      protected TokenizerFactory createSPI(String name) {\n        return TokenizerFactory.forName(name);\n      }\n\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<TokenFilterFactory>();\n\n    AnalysisPluginLoader<TokenFilterFactory> filterLoader = \n      new AnalysisPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      \n      @Override\n      protected TokenFilterFactory createSPI(String name) {\n        return TokenFilterFactory.forName(name);\n      }\n\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n          String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n          plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        \n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr \n            = clazz.getConstructor(Version.class);\n          final String matchVersionStr \n            = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            schema.getDefaultLuceneMatchVersion() : \n            Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n          String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n          plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, (NodeList)xpath.evaluate(\"./charFilter\",  node, XPathConstants.NODESET) );\n                            \n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<TokenFilterFactory>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n          String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n          plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6ccf3f2e89c8e02a00051620fa60a11a2c696295","date":1343142072,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","pathOld":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        \n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr \n            = clazz.getConstructor(Version.class);\n          final String matchVersionStr \n            = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            schema.getDefaultLuceneMatchVersion() : \n            Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<CharFilterFactory>();\n    AnalysisPluginLoader<CharFilterFactory> charFilterLoader =\n      new AnalysisPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected Class<? extends CharFilterFactory> lookupSPI(String name) {\n        return CharFilterFactory.lookupClass(name);\n      }\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n          String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n          plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, (NodeList)xpath.evaluate(\"./charFilter\",  node, XPathConstants.NODESET) );\n                            \n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<TokenizerFactory>(1);\n    AnalysisPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AnalysisPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      \n      @Override\n      protected Class<? extends TokenizerFactory> lookupSPI(String name) {\n        return TokenizerFactory.lookupClass(name);\n      }\n\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<TokenFilterFactory>();\n\n    AnalysisPluginLoader<TokenFilterFactory> filterLoader = \n      new AnalysisPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      \n      @Override\n      protected Class<? extends TokenFilterFactory> lookupSPI(String name) {\n        return TokenFilterFactory.lookupClass(name);\n      }\n\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n          String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n          plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        \n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr \n            = clazz.getConstructor(Version.class);\n          final String matchVersionStr \n            = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            schema.getDefaultLuceneMatchVersion() : \n            Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<CharFilterFactory>();\n    AnalysisPluginLoader<CharFilterFactory> charFilterLoader =\n      new AnalysisPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected CharFilterFactory createSPI(String name) {\n        return CharFilterFactory.forName(name);\n      }\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n          String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n          plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, (NodeList)xpath.evaluate(\"./charFilter\",  node, XPathConstants.NODESET) );\n                            \n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<TokenizerFactory>(1);\n    AnalysisPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AnalysisPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      \n      @Override\n      protected TokenizerFactory createSPI(String name) {\n        return TokenizerFactory.forName(name);\n      }\n\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<TokenFilterFactory>();\n\n    AnalysisPluginLoader<TokenFilterFactory> filterLoader = \n      new AnalysisPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      \n      @Override\n      protected TokenFilterFactory createSPI(String name) {\n        return TokenFilterFactory.forName(name);\n      }\n\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n          String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n          plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7bb7d4caf24bc521fa8ac35f463f50724b4a91d8","date":1343155480,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","pathOld":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        \n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr \n            = clazz.getConstructor(Version.class);\n          final String matchVersionStr \n            = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            schema.getDefaultLuceneMatchVersion() : \n            Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n          String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n          plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, (NodeList)xpath.evaluate(\"./charFilter\",  node, XPathConstants.NODESET) );\n                            \n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<TokenFilterFactory>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n          String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n          plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        \n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr \n            = clazz.getConstructor(Version.class);\n          final String matchVersionStr \n            = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            schema.getDefaultLuceneMatchVersion() : \n            Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<CharFilterFactory>();\n    AnalysisPluginLoader<CharFilterFactory> charFilterLoader =\n      new AnalysisPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected Class<? extends CharFilterFactory> lookupSPI(String name) {\n        return CharFilterFactory.lookupClass(name);\n      }\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n          String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n          plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, (NodeList)xpath.evaluate(\"./charFilter\",  node, XPathConstants.NODESET) );\n                            \n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<TokenizerFactory>(1);\n    AnalysisPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AnalysisPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      \n      @Override\n      protected Class<? extends TokenizerFactory> lookupSPI(String name) {\n        return TokenizerFactory.lookupClass(name);\n      }\n\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<TokenFilterFactory>();\n\n    AnalysisPluginLoader<TokenFilterFactory> filterLoader = \n      new AnalysisPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      \n      @Override\n      protected Class<? extends TokenFilterFactory> lookupSPI(String name) {\n        return TokenFilterFactory.lookupClass(name);\n      }\n\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n          String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n          plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"111313ddec6f8f61d5645a3f368ad793c106643b","date":1343671101,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","pathOld":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n\n    // check for all of these up front, so we can error if used in \n    // conjunction with an explicit analyzer class.\n    NodeList charFilterNodes = (NodeList)xpath.evaluate\n      (\"./charFilter\",  node, XPathConstants.NODESET);\n    NodeList tokenizerNodes = (NodeList)xpath.evaluate\n      (\"./tokenizer\", node, XPathConstants.NODESET);\n    NodeList tokenFilterNodes = (NodeList)xpath.evaluate\n      (\"./filter\", node, XPathConstants.NODESET);\n      \n    if (analyzerName != null) {\n\n      // explicitly check for child analysis factories instead of\n      // just any child nodes, because the user might have their\n      // own custom nodes (ie: <description> or something like that)\n      if (0 != charFilterNodes.getLength() ||\n          0 != tokenizerNodes.getLength() ||\n          0 != tokenFilterNodes.getLength()) {\n        throw new SolrException\n        ( SolrException.ErrorCode.SERVER_ERROR,\n          \"Configuration Error: Analyzer class='\" + analyzerName +\n          \"' can not be combined with nested analysis factories\");\n      }\n\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        \n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr \n            = clazz.getConstructor(Version.class);\n          final String matchVersionStr \n            = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            schema.getDefaultLuceneMatchVersion() : \n            Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n          String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n          plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, charFilterNodes );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, tokenizerNodes );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer\");\n    }\n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<TokenFilterFactory>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n          String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n          plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, tokenFilterNodes );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        \n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr \n            = clazz.getConstructor(Version.class);\n          final String matchVersionStr \n            = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            schema.getDefaultLuceneMatchVersion() : \n            Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n          String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n          plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, (NodeList)xpath.evaluate(\"./charFilter\",  node, XPathConstants.NODESET) );\n                            \n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<TokenFilterFactory>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n          String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n          plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","date":1343768312,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","pathOld":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n\n    // check for all of these up front, so we can error if used in \n    // conjunction with an explicit analyzer class.\n    NodeList charFilterNodes = (NodeList)xpath.evaluate\n      (\"./charFilter\",  node, XPathConstants.NODESET);\n    NodeList tokenizerNodes = (NodeList)xpath.evaluate\n      (\"./tokenizer\", node, XPathConstants.NODESET);\n    NodeList tokenFilterNodes = (NodeList)xpath.evaluate\n      (\"./filter\", node, XPathConstants.NODESET);\n      \n    if (analyzerName != null) {\n\n      // explicitly check for child analysis factories instead of\n      // just any child nodes, because the user might have their\n      // own custom nodes (ie: <description> or something like that)\n      if (0 != charFilterNodes.getLength() ||\n          0 != tokenizerNodes.getLength() ||\n          0 != tokenFilterNodes.getLength()) {\n        throw new SolrException\n        ( SolrException.ErrorCode.SERVER_ERROR,\n          \"Configuration Error: Analyzer class='\" + analyzerName +\n          \"' can not be combined with nested analysis factories\");\n      }\n\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        \n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr \n            = clazz.getConstructor(Version.class);\n          final String matchVersionStr \n            = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            schema.getDefaultLuceneMatchVersion() : \n            Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n          String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n          plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, charFilterNodes );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, tokenizerNodes );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer\");\n    }\n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<TokenFilterFactory>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n          String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n          plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, tokenFilterNodes );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        \n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr \n            = clazz.getConstructor(Version.class);\n          final String matchVersionStr \n            = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            schema.getDefaultLuceneMatchVersion() : \n            Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n          String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n          plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, (NodeList)xpath.evaluate(\"./charFilter\",  node, XPathConstants.NODESET) );\n                            \n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<TokenFilterFactory>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n          String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n          plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","pathOld":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n\n    // check for all of these up front, so we can error if used in \n    // conjunction with an explicit analyzer class.\n    NodeList charFilterNodes = (NodeList)xpath.evaluate\n      (\"./charFilter\",  node, XPathConstants.NODESET);\n    NodeList tokenizerNodes = (NodeList)xpath.evaluate\n      (\"./tokenizer\", node, XPathConstants.NODESET);\n    NodeList tokenFilterNodes = (NodeList)xpath.evaluate\n      (\"./filter\", node, XPathConstants.NODESET);\n      \n    if (analyzerName != null) {\n\n      // explicitly check for child analysis factories instead of\n      // just any child nodes, because the user might have their\n      // own custom nodes (ie: <description> or something like that)\n      if (0 != charFilterNodes.getLength() ||\n          0 != tokenizerNodes.getLength() ||\n          0 != tokenFilterNodes.getLength()) {\n        throw new SolrException\n        ( SolrException.ErrorCode.SERVER_ERROR,\n          \"Configuration Error: Analyzer class='\" + analyzerName +\n          \"' can not be combined with nested analysis factories\");\n      }\n\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        \n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr \n            = clazz.getConstructor(Version.class);\n          final String matchVersionStr \n            = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            schema.getDefaultLuceneMatchVersion() : \n            Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n          String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n          plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, charFilterNodes );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, tokenizerNodes );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer\");\n    }\n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<TokenFilterFactory>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n          String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n          plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, tokenFilterNodes );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        \n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr \n            = clazz.getConstructor(Version.class);\n          final String matchVersionStr \n            = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            schema.getDefaultLuceneMatchVersion() : \n            Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n          String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n          plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, (NodeList)xpath.evaluate(\"./charFilter\",  node, XPathConstants.NODESET) );\n                            \n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<TokenFilterFactory>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n          String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n          plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"57da959ec15bb701bd1d1bf3c613b69009ff4bfd","date":1364833800,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","pathOld":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n\n    // check for all of these up front, so we can error if used in \n    // conjunction with an explicit analyzer class.\n    NodeList charFilterNodes = (NodeList)xpath.evaluate\n      (\"./charFilter\",  node, XPathConstants.NODESET);\n    NodeList tokenizerNodes = (NodeList)xpath.evaluate\n      (\"./tokenizer\", node, XPathConstants.NODESET);\n    NodeList tokenFilterNodes = (NodeList)xpath.evaluate\n      (\"./filter\", node, XPathConstants.NODESET);\n      \n    if (analyzerName != null) {\n\n      // explicitly check for child analysis factories instead of\n      // just any child nodes, because the user might have their\n      // own custom nodes (ie: <description> or something like that)\n      if (0 != charFilterNodes.getLength() ||\n          0 != tokenizerNodes.getLength() ||\n          0 != tokenFilterNodes.getLength()) {\n        throw new SolrException\n        ( SolrException.ErrorCode.SERVER_ERROR,\n          \"Configuration Error: Analyzer class='\" + analyzerName +\n          \"' can not be combined with nested analysis factories\");\n      }\n\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        \n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr \n            = clazz.getConstructor(Version.class);\n          final String matchVersionStr \n            = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            schema.getDefaultLuceneMatchVersion() : \n            Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected CharFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, CharFilterFactory.class.getSimpleName()).toString());\n        return loader.newInstance(className, CharFilterFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n      }\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, charFilterNodes );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      \n      @Override\n      protected TokenizerFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenizerFactory.class.getSimpleName()).toString());\n        return loader.newInstance(className, TokenizerFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n      }\n      \n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, tokenizerNodes );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer\");\n    }\n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<TokenFilterFactory>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected TokenFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenFilterFactory.class.getSimpleName()).toString());\n        return loader.newInstance(className, TokenFilterFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n      }\n      \n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, tokenFilterNodes );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n\n    // check for all of these up front, so we can error if used in \n    // conjunction with an explicit analyzer class.\n    NodeList charFilterNodes = (NodeList)xpath.evaluate\n      (\"./charFilter\",  node, XPathConstants.NODESET);\n    NodeList tokenizerNodes = (NodeList)xpath.evaluate\n      (\"./tokenizer\", node, XPathConstants.NODESET);\n    NodeList tokenFilterNodes = (NodeList)xpath.evaluate\n      (\"./filter\", node, XPathConstants.NODESET);\n      \n    if (analyzerName != null) {\n\n      // explicitly check for child analysis factories instead of\n      // just any child nodes, because the user might have their\n      // own custom nodes (ie: <description> or something like that)\n      if (0 != charFilterNodes.getLength() ||\n          0 != tokenizerNodes.getLength() ||\n          0 != tokenFilterNodes.getLength()) {\n        throw new SolrException\n        ( SolrException.ErrorCode.SERVER_ERROR,\n          \"Configuration Error: Analyzer class='\" + analyzerName +\n          \"' can not be combined with nested analysis factories\");\n      }\n\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        \n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr \n            = clazz.getConstructor(Version.class);\n          final String matchVersionStr \n            = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            schema.getDefaultLuceneMatchVersion() : \n            Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n          String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n          plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, charFilterNodes );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, tokenizerNodes );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer\");\n    }\n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<TokenFilterFactory>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n\n          String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n          plugin.setLuceneMatchVersion(parseConfiguredVersion(configuredVersion, plugin.getClass().getSimpleName()));\n\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, tokenFilterNodes );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9b4b4d68085809ae840a099e4620e5a128509279","date":1365633379,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","pathOld":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n\n    // check for all of these up front, so we can error if used in \n    // conjunction with an explicit analyzer class.\n    NodeList charFilterNodes = (NodeList)xpath.evaluate\n      (\"./charFilter\",  node, XPathConstants.NODESET);\n    NodeList tokenizerNodes = (NodeList)xpath.evaluate\n      (\"./tokenizer\", node, XPathConstants.NODESET);\n    NodeList tokenFilterNodes = (NodeList)xpath.evaluate\n      (\"./filter\", node, XPathConstants.NODESET);\n      \n    if (analyzerName != null) {\n\n      // explicitly check for child analysis factories instead of\n      // just any child nodes, because the user might have their\n      // own custom nodes (ie: <description> or something like that)\n      if (0 != charFilterNodes.getLength() ||\n          0 != tokenizerNodes.getLength() ||\n          0 != tokenFilterNodes.getLength()) {\n        throw new SolrException\n        ( SolrException.ErrorCode.SERVER_ERROR,\n          \"Configuration Error: Analyzer class='\" + analyzerName +\n          \"' can not be combined with nested analysis factories\");\n      }\n\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        \n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr \n            = clazz.getConstructor(Version.class);\n          final String matchVersionStr \n            = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            schema.getDefaultLuceneMatchVersion() : \n            Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected CharFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, CharFilterFactory.class.getSimpleName()).toString());\n        CharFilterFactory factory = loader.newInstance(className, CharFilterFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, charFilterNodes );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      \n      @Override\n      protected TokenizerFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenizerFactory.class.getSimpleName()).toString());\n        TokenizerFactory factory = loader.newInstance(className, TokenizerFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, tokenizerNodes );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer\");\n    }\n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<TokenFilterFactory>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected TokenFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenFilterFactory.class.getSimpleName()).toString());\n        TokenFilterFactory factory = loader.newInstance\n            (className, TokenFilterFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, tokenFilterNodes );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n\n    // check for all of these up front, so we can error if used in \n    // conjunction with an explicit analyzer class.\n    NodeList charFilterNodes = (NodeList)xpath.evaluate\n      (\"./charFilter\",  node, XPathConstants.NODESET);\n    NodeList tokenizerNodes = (NodeList)xpath.evaluate\n      (\"./tokenizer\", node, XPathConstants.NODESET);\n    NodeList tokenFilterNodes = (NodeList)xpath.evaluate\n      (\"./filter\", node, XPathConstants.NODESET);\n      \n    if (analyzerName != null) {\n\n      // explicitly check for child analysis factories instead of\n      // just any child nodes, because the user might have their\n      // own custom nodes (ie: <description> or something like that)\n      if (0 != charFilterNodes.getLength() ||\n          0 != tokenizerNodes.getLength() ||\n          0 != tokenFilterNodes.getLength()) {\n        throw new SolrException\n        ( SolrException.ErrorCode.SERVER_ERROR,\n          \"Configuration Error: Analyzer class='\" + analyzerName +\n          \"' can not be combined with nested analysis factories\");\n      }\n\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        \n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr \n            = clazz.getConstructor(Version.class);\n          final String matchVersionStr \n            = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            schema.getDefaultLuceneMatchVersion() : \n            Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected CharFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, CharFilterFactory.class.getSimpleName()).toString());\n        return loader.newInstance(className, CharFilterFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n      }\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, charFilterNodes );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      \n      @Override\n      protected TokenizerFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenizerFactory.class.getSimpleName()).toString());\n        return loader.newInstance(className, TokenizerFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n      }\n      \n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, tokenizerNodes );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer\");\n    }\n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<TokenFilterFactory>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected TokenFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenFilterFactory.class.getSimpleName()).toString());\n        return loader.newInstance(className, TokenFilterFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n      }\n      \n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, tokenFilterNodes );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","pathOld":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n\n    // check for all of these up front, so we can error if used in \n    // conjunction with an explicit analyzer class.\n    NodeList charFilterNodes = (NodeList)xpath.evaluate\n      (\"./charFilter\",  node, XPathConstants.NODESET);\n    NodeList tokenizerNodes = (NodeList)xpath.evaluate\n      (\"./tokenizer\", node, XPathConstants.NODESET);\n    NodeList tokenFilterNodes = (NodeList)xpath.evaluate\n      (\"./filter\", node, XPathConstants.NODESET);\n      \n    if (analyzerName != null) {\n\n      // explicitly check for child analysis factories instead of\n      // just any child nodes, because the user might have their\n      // own custom nodes (ie: <description> or something like that)\n      if (0 != charFilterNodes.getLength() ||\n          0 != tokenizerNodes.getLength() ||\n          0 != tokenFilterNodes.getLength()) {\n        throw new SolrException\n        ( SolrException.ErrorCode.SERVER_ERROR,\n          \"Configuration Error: Analyzer class='\" + analyzerName +\n          \"' can not be combined with nested analysis factories\");\n      }\n\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        \n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr \n            = clazz.getConstructor(Version.class);\n          final String matchVersionStr \n            = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            schema.getDefaultLuceneMatchVersion() : \n            Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected CharFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, CharFilterFactory.class.getSimpleName()).toString());\n        CharFilterFactory factory = loader.newInstance(className, CharFilterFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, charFilterNodes );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      \n      @Override\n      protected TokenizerFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenizerFactory.class.getSimpleName()).toString());\n        TokenizerFactory factory = loader.newInstance(className, TokenizerFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, tokenizerNodes );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer\");\n    }\n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected TokenFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenFilterFactory.class.getSimpleName()).toString());\n        TokenFilterFactory factory = loader.newInstance\n            (className, TokenFilterFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, tokenFilterNodes );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n\n    // check for all of these up front, so we can error if used in \n    // conjunction with an explicit analyzer class.\n    NodeList charFilterNodes = (NodeList)xpath.evaluate\n      (\"./charFilter\",  node, XPathConstants.NODESET);\n    NodeList tokenizerNodes = (NodeList)xpath.evaluate\n      (\"./tokenizer\", node, XPathConstants.NODESET);\n    NodeList tokenFilterNodes = (NodeList)xpath.evaluate\n      (\"./filter\", node, XPathConstants.NODESET);\n      \n    if (analyzerName != null) {\n\n      // explicitly check for child analysis factories instead of\n      // just any child nodes, because the user might have their\n      // own custom nodes (ie: <description> or something like that)\n      if (0 != charFilterNodes.getLength() ||\n          0 != tokenizerNodes.getLength() ||\n          0 != tokenFilterNodes.getLength()) {\n        throw new SolrException\n        ( SolrException.ErrorCode.SERVER_ERROR,\n          \"Configuration Error: Analyzer class='\" + analyzerName +\n          \"' can not be combined with nested analysis factories\");\n      }\n\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        \n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr \n            = clazz.getConstructor(Version.class);\n          final String matchVersionStr \n            = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            schema.getDefaultLuceneMatchVersion() : \n            Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected CharFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, CharFilterFactory.class.getSimpleName()).toString());\n        CharFilterFactory factory = loader.newInstance(className, CharFilterFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, charFilterNodes );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      \n      @Override\n      protected TokenizerFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenizerFactory.class.getSimpleName()).toString());\n        TokenizerFactory factory = loader.newInstance(className, TokenizerFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, tokenizerNodes );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer\");\n    }\n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<TokenFilterFactory>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected TokenFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenFilterFactory.class.getSimpleName()).toString());\n        TokenFilterFactory factory = loader.newInstance\n            (className, TokenFilterFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, tokenFilterNodes );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"379db3ad24c4f0214f30a122265a6d6be003a99d","date":1407537768,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","pathOld":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n\n    // check for all of these up front, so we can error if used in \n    // conjunction with an explicit analyzer class.\n    NodeList charFilterNodes = (NodeList)xpath.evaluate\n      (\"./charFilter\",  node, XPathConstants.NODESET);\n    NodeList tokenizerNodes = (NodeList)xpath.evaluate\n      (\"./tokenizer\", node, XPathConstants.NODESET);\n    NodeList tokenFilterNodes = (NodeList)xpath.evaluate\n      (\"./filter\", node, XPathConstants.NODESET);\n      \n    if (analyzerName != null) {\n\n      // explicitly check for child analysis factories instead of\n      // just any child nodes, because the user might have their\n      // own custom nodes (ie: <description> or something like that)\n      if (0 != charFilterNodes.getLength() ||\n          0 != tokenizerNodes.getLength() ||\n          0 != tokenFilterNodes.getLength()) {\n        throw new SolrException\n        ( SolrException.ErrorCode.SERVER_ERROR,\n          \"Configuration Error: Analyzer class='\" + analyzerName +\n          \"' can not be combined with nested analysis factories\");\n      }\n\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        Analyzer analyzer = clazz.newInstance();\n\n        final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n        final Version luceneMatchVersion = (matchVersionStr == null) ?\n          schema.getDefaultLuceneMatchVersion() :\n          Config.parseLuceneVersionString(matchVersionStr);\n        if (luceneMatchVersion == null) {\n          throw new SolrException\n            ( SolrException.ErrorCode.SERVER_ERROR,\n              \"Configuration Error: Analyzer '\" + clazz.getName() +\n              \"' needs a 'luceneMatchVersion' parameter\");\n        }\n        analyzer.setVersion(luceneMatchVersion);\n        return analyzer;\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected CharFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, CharFilterFactory.class.getSimpleName()).toString());\n        CharFilterFactory factory = loader.newInstance(className, CharFilterFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, charFilterNodes );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      \n      @Override\n      protected TokenizerFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenizerFactory.class.getSimpleName()).toString());\n        TokenizerFactory factory = loader.newInstance(className, TokenizerFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, tokenizerNodes );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer\");\n    }\n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected TokenFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenFilterFactory.class.getSimpleName()).toString());\n        TokenFilterFactory factory = loader.newInstance\n            (className, TokenFilterFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, tokenFilterNodes );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n\n    // check for all of these up front, so we can error if used in \n    // conjunction with an explicit analyzer class.\n    NodeList charFilterNodes = (NodeList)xpath.evaluate\n      (\"./charFilter\",  node, XPathConstants.NODESET);\n    NodeList tokenizerNodes = (NodeList)xpath.evaluate\n      (\"./tokenizer\", node, XPathConstants.NODESET);\n    NodeList tokenFilterNodes = (NodeList)xpath.evaluate\n      (\"./filter\", node, XPathConstants.NODESET);\n      \n    if (analyzerName != null) {\n\n      // explicitly check for child analysis factories instead of\n      // just any child nodes, because the user might have their\n      // own custom nodes (ie: <description> or something like that)\n      if (0 != charFilterNodes.getLength() ||\n          0 != tokenizerNodes.getLength() ||\n          0 != tokenFilterNodes.getLength()) {\n        throw new SolrException\n        ( SolrException.ErrorCode.SERVER_ERROR,\n          \"Configuration Error: Analyzer class='\" + analyzerName +\n          \"' can not be combined with nested analysis factories\");\n      }\n\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        \n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr \n            = clazz.getConstructor(Version.class);\n          final String matchVersionStr \n            = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            schema.getDefaultLuceneMatchVersion() : \n            Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected CharFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, CharFilterFactory.class.getSimpleName()).toString());\n        CharFilterFactory factory = loader.newInstance(className, CharFilterFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, charFilterNodes );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      \n      @Override\n      protected TokenizerFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenizerFactory.class.getSimpleName()).toString());\n        TokenizerFactory factory = loader.newInstance(className, TokenizerFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, tokenizerNodes );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer\");\n    }\n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected TokenFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenFilterFactory.class.getSimpleName()).toString());\n        TokenFilterFactory factory = loader.newInstance\n            (className, TokenFilterFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, tokenFilterNodes );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","bugFix":null,"bugIntro":["73b91012493e4750b9dc169cf1ae8cdd91493b42"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ee622110ba6021d0390037e77574743c1e55348c","date":1546700916,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","pathOld":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n\n    // check for all of these up front, so we can error if used in \n    // conjunction with an explicit analyzer class.\n    NodeList charFilterNodes = (NodeList)xpath.evaluate\n      (\"./charFilter\",  node, XPathConstants.NODESET);\n    NodeList tokenizerNodes = (NodeList)xpath.evaluate\n      (\"./tokenizer\", node, XPathConstants.NODESET);\n    NodeList tokenFilterNodes = (NodeList)xpath.evaluate\n      (\"./filter\", node, XPathConstants.NODESET);\n      \n    if (analyzerName != null) {\n\n      // explicitly check for child analysis factories instead of\n      // just any child nodes, because the user might have their\n      // own custom nodes (ie: <description> or something like that)\n      if (0 != charFilterNodes.getLength() ||\n          0 != tokenizerNodes.getLength() ||\n          0 != tokenFilterNodes.getLength()) {\n        throw new SolrException\n        ( SolrException.ErrorCode.SERVER_ERROR,\n          \"Configuration Error: Analyzer class='\" + analyzerName +\n          \"' can not be combined with nested analysis factories\");\n      }\n\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        Analyzer analyzer = clazz.newInstance();\n\n        final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n        final Version luceneMatchVersion = (matchVersionStr == null) ?\n          schema.getDefaultLuceneMatchVersion() :\n          XmlConfigFile.parseLuceneVersionString(matchVersionStr);\n        if (luceneMatchVersion == null) {\n          throw new SolrException\n            ( SolrException.ErrorCode.SERVER_ERROR,\n              \"Configuration Error: Analyzer '\" + clazz.getName() +\n              \"' needs a 'luceneMatchVersion' parameter\");\n        }\n        analyzer.setVersion(luceneMatchVersion);\n        return analyzer;\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected CharFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, CharFilterFactory.class.getSimpleName()).toString());\n        CharFilterFactory factory = loader.newInstance(className, CharFilterFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, charFilterNodes );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      \n      @Override\n      protected TokenizerFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenizerFactory.class.getSimpleName()).toString());\n        TokenizerFactory factory = loader.newInstance(className, TokenizerFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, tokenizerNodes );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer\");\n    }\n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected TokenFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenFilterFactory.class.getSimpleName()).toString());\n        TokenFilterFactory factory = loader.newInstance\n            (className, TokenFilterFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, tokenFilterNodes );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n\n    // check for all of these up front, so we can error if used in \n    // conjunction with an explicit analyzer class.\n    NodeList charFilterNodes = (NodeList)xpath.evaluate\n      (\"./charFilter\",  node, XPathConstants.NODESET);\n    NodeList tokenizerNodes = (NodeList)xpath.evaluate\n      (\"./tokenizer\", node, XPathConstants.NODESET);\n    NodeList tokenFilterNodes = (NodeList)xpath.evaluate\n      (\"./filter\", node, XPathConstants.NODESET);\n      \n    if (analyzerName != null) {\n\n      // explicitly check for child analysis factories instead of\n      // just any child nodes, because the user might have their\n      // own custom nodes (ie: <description> or something like that)\n      if (0 != charFilterNodes.getLength() ||\n          0 != tokenizerNodes.getLength() ||\n          0 != tokenFilterNodes.getLength()) {\n        throw new SolrException\n        ( SolrException.ErrorCode.SERVER_ERROR,\n          \"Configuration Error: Analyzer class='\" + analyzerName +\n          \"' can not be combined with nested analysis factories\");\n      }\n\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        Analyzer analyzer = clazz.newInstance();\n\n        final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n        final Version luceneMatchVersion = (matchVersionStr == null) ?\n          schema.getDefaultLuceneMatchVersion() :\n          Config.parseLuceneVersionString(matchVersionStr);\n        if (luceneMatchVersion == null) {\n          throw new SolrException\n            ( SolrException.ErrorCode.SERVER_ERROR,\n              \"Configuration Error: Analyzer '\" + clazz.getName() +\n              \"' needs a 'luceneMatchVersion' parameter\");\n        }\n        analyzer.setVersion(luceneMatchVersion);\n        return analyzer;\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected CharFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, CharFilterFactory.class.getSimpleName()).toString());\n        CharFilterFactory factory = loader.newInstance(className, CharFilterFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, charFilterNodes );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      \n      @Override\n      protected TokenizerFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenizerFactory.class.getSimpleName()).toString());\n        TokenizerFactory factory = loader.newInstance(className, TokenizerFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, tokenizerNodes );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer\");\n    }\n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected TokenFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenFilterFactory.class.getSimpleName()).toString());\n        TokenFilterFactory factory = loader.newInstance\n            (className, TokenFilterFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, tokenFilterNodes );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2eb89ed39d48c9dbf1ec6df65ed11f8cf5331e88","date":1546726477,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","pathOld":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n\n    // check for all of these up front, so we can error if used in \n    // conjunction with an explicit analyzer class.\n    NodeList charFilterNodes = (NodeList)xpath.evaluate\n      (\"./charFilter\",  node, XPathConstants.NODESET);\n    NodeList tokenizerNodes = (NodeList)xpath.evaluate\n      (\"./tokenizer\", node, XPathConstants.NODESET);\n    NodeList tokenFilterNodes = (NodeList)xpath.evaluate\n      (\"./filter\", node, XPathConstants.NODESET);\n      \n    if (analyzerName != null) {\n\n      // explicitly check for child analysis factories instead of\n      // just any child nodes, because the user might have their\n      // own custom nodes (ie: <description> or something like that)\n      if (0 != charFilterNodes.getLength() ||\n          0 != tokenizerNodes.getLength() ||\n          0 != tokenFilterNodes.getLength()) {\n        throw new SolrException\n        ( SolrException.ErrorCode.SERVER_ERROR,\n          \"Configuration Error: Analyzer class='\" + analyzerName +\n          \"' can not be combined with nested analysis factories\");\n      }\n\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        Analyzer analyzer = clazz.newInstance();\n\n        final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n        final Version luceneMatchVersion = (matchVersionStr == null) ?\n          schema.getDefaultLuceneMatchVersion() :\n          SolrConfig.parseLuceneVersionString(matchVersionStr);\n        if (luceneMatchVersion == null) {\n          throw new SolrException\n            ( SolrException.ErrorCode.SERVER_ERROR,\n              \"Configuration Error: Analyzer '\" + clazz.getName() +\n              \"' needs a 'luceneMatchVersion' parameter\");\n        }\n        analyzer.setVersion(luceneMatchVersion);\n        return analyzer;\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected CharFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, CharFilterFactory.class.getSimpleName()).toString());\n        CharFilterFactory factory = loader.newInstance(className, CharFilterFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, charFilterNodes );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      \n      @Override\n      protected TokenizerFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenizerFactory.class.getSimpleName()).toString());\n        TokenizerFactory factory = loader.newInstance(className, TokenizerFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, tokenizerNodes );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer\");\n    }\n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected TokenFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenFilterFactory.class.getSimpleName()).toString());\n        TokenFilterFactory factory = loader.newInstance\n            (className, TokenFilterFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, tokenFilterNodes );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n\n    // check for all of these up front, so we can error if used in \n    // conjunction with an explicit analyzer class.\n    NodeList charFilterNodes = (NodeList)xpath.evaluate\n      (\"./charFilter\",  node, XPathConstants.NODESET);\n    NodeList tokenizerNodes = (NodeList)xpath.evaluate\n      (\"./tokenizer\", node, XPathConstants.NODESET);\n    NodeList tokenFilterNodes = (NodeList)xpath.evaluate\n      (\"./filter\", node, XPathConstants.NODESET);\n      \n    if (analyzerName != null) {\n\n      // explicitly check for child analysis factories instead of\n      // just any child nodes, because the user might have their\n      // own custom nodes (ie: <description> or something like that)\n      if (0 != charFilterNodes.getLength() ||\n          0 != tokenizerNodes.getLength() ||\n          0 != tokenFilterNodes.getLength()) {\n        throw new SolrException\n        ( SolrException.ErrorCode.SERVER_ERROR,\n          \"Configuration Error: Analyzer class='\" + analyzerName +\n          \"' can not be combined with nested analysis factories\");\n      }\n\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        Analyzer analyzer = clazz.newInstance();\n\n        final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n        final Version luceneMatchVersion = (matchVersionStr == null) ?\n          schema.getDefaultLuceneMatchVersion() :\n          XmlConfigFile.parseLuceneVersionString(matchVersionStr);\n        if (luceneMatchVersion == null) {\n          throw new SolrException\n            ( SolrException.ErrorCode.SERVER_ERROR,\n              \"Configuration Error: Analyzer '\" + clazz.getName() +\n              \"' needs a 'luceneMatchVersion' parameter\");\n        }\n        analyzer.setVersion(luceneMatchVersion);\n        return analyzer;\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected CharFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, CharFilterFactory.class.getSimpleName()).toString());\n        CharFilterFactory factory = loader.newInstance(className, CharFilterFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, charFilterNodes );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      \n      @Override\n      protected TokenizerFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenizerFactory.class.getSimpleName()).toString());\n        TokenizerFactory factory = loader.newInstance(className, TokenizerFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, tokenizerNodes );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer\");\n    }\n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected TokenFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenFilterFactory.class.getSimpleName()).toString());\n        TokenFilterFactory factory = loader.newInstance\n            (className, TokenFilterFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, tokenFilterNodes );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b88a121b875f9ae2ac50f85cf46dcb680f126357","date":1555416009,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","pathOld":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n\n    // check for all of these up front, so we can error if used in \n    // conjunction with an explicit analyzer class.\n    NodeList charFilterNodes = (NodeList)xpath.evaluate\n      (\"./charFilter\",  node, XPathConstants.NODESET);\n    NodeList tokenizerNodes = (NodeList)xpath.evaluate\n      (\"./tokenizer\", node, XPathConstants.NODESET);\n    NodeList tokenFilterNodes = (NodeList)xpath.evaluate\n      (\"./filter\", node, XPathConstants.NODESET);\n      \n    if (analyzerName != null) {\n\n      // explicitly check for child analysis factories instead of\n      // just any child nodes, because the user might have their\n      // own custom nodes (ie: <description> or something like that)\n      if (0 != charFilterNodes.getLength() ||\n          0 != tokenizerNodes.getLength() ||\n          0 != tokenFilterNodes.getLength()) {\n        throw new SolrException\n        ( SolrException.ErrorCode.SERVER_ERROR,\n          \"Configuration Error: Analyzer class='\" + analyzerName +\n          \"' can not be combined with nested analysis factories\");\n      }\n\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        Analyzer analyzer = clazz.getConstructor().newInstance();\n\n        final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n        final Version luceneMatchVersion = (matchVersionStr == null) ?\n          schema.getDefaultLuceneMatchVersion() :\n          SolrConfig.parseLuceneVersionString(matchVersionStr);\n        if (luceneMatchVersion == null) {\n          throw new SolrException\n            ( SolrException.ErrorCode.SERVER_ERROR,\n              \"Configuration Error: Analyzer '\" + clazz.getName() +\n              \"' needs a 'luceneMatchVersion' parameter\");\n        }\n        analyzer.setVersion(luceneMatchVersion);\n        return analyzer;\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected CharFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, CharFilterFactory.class.getSimpleName()).toString());\n        CharFilterFactory factory = loader.newInstance(className, CharFilterFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, charFilterNodes );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      \n      @Override\n      protected TokenizerFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenizerFactory.class.getSimpleName()).toString());\n        TokenizerFactory factory = loader.newInstance(className, TokenizerFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, tokenizerNodes );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer\");\n    }\n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected TokenFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenFilterFactory.class.getSimpleName()).toString());\n        TokenFilterFactory factory = loader.newInstance\n            (className, TokenFilterFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, tokenFilterNodes );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n\n    // check for all of these up front, so we can error if used in \n    // conjunction with an explicit analyzer class.\n    NodeList charFilterNodes = (NodeList)xpath.evaluate\n      (\"./charFilter\",  node, XPathConstants.NODESET);\n    NodeList tokenizerNodes = (NodeList)xpath.evaluate\n      (\"./tokenizer\", node, XPathConstants.NODESET);\n    NodeList tokenFilterNodes = (NodeList)xpath.evaluate\n      (\"./filter\", node, XPathConstants.NODESET);\n      \n    if (analyzerName != null) {\n\n      // explicitly check for child analysis factories instead of\n      // just any child nodes, because the user might have their\n      // own custom nodes (ie: <description> or something like that)\n      if (0 != charFilterNodes.getLength() ||\n          0 != tokenizerNodes.getLength() ||\n          0 != tokenFilterNodes.getLength()) {\n        throw new SolrException\n        ( SolrException.ErrorCode.SERVER_ERROR,\n          \"Configuration Error: Analyzer class='\" + analyzerName +\n          \"' can not be combined with nested analysis factories\");\n      }\n\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        Analyzer analyzer = clazz.newInstance();\n\n        final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n        final Version luceneMatchVersion = (matchVersionStr == null) ?\n          schema.getDefaultLuceneMatchVersion() :\n          SolrConfig.parseLuceneVersionString(matchVersionStr);\n        if (luceneMatchVersion == null) {\n          throw new SolrException\n            ( SolrException.ErrorCode.SERVER_ERROR,\n              \"Configuration Error: Analyzer '\" + clazz.getName() +\n              \"' needs a 'luceneMatchVersion' parameter\");\n        }\n        analyzer.setVersion(luceneMatchVersion);\n        return analyzer;\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected CharFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, CharFilterFactory.class.getSimpleName()).toString());\n        CharFilterFactory factory = loader.newInstance(className, CharFilterFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, charFilterNodes );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      \n      @Override\n      protected TokenizerFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenizerFactory.class.getSimpleName()).toString());\n        TokenizerFactory factory = loader.newInstance(className, TokenizerFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, tokenizerNodes );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer\");\n    }\n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected TokenFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenFilterFactory.class.getSimpleName()).toString());\n        TokenFilterFactory factory = loader.newInstance\n            (className, TokenFilterFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, tokenFilterNodes );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2c24804758d67429e3055070a9fe970d4f159954","date":1565508925,"type":3,"author":"Tomoko Uchida","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","pathOld":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n\n    // check for all of these up front, so we can error if used in \n    // conjunction with an explicit analyzer class.\n    NodeList charFilterNodes = (NodeList)xpath.evaluate\n      (\"./charFilter\",  node, XPathConstants.NODESET);\n    NodeList tokenizerNodes = (NodeList)xpath.evaluate\n      (\"./tokenizer\", node, XPathConstants.NODESET);\n    NodeList tokenFilterNodes = (NodeList)xpath.evaluate\n      (\"./filter\", node, XPathConstants.NODESET);\n      \n    if (analyzerName != null) {\n\n      // explicitly check for child analysis factories instead of\n      // just any child nodes, because the user might have their\n      // own custom nodes (ie: <description> or something like that)\n      if (0 != charFilterNodes.getLength() ||\n          0 != tokenizerNodes.getLength() ||\n          0 != tokenFilterNodes.getLength()) {\n        throw new SolrException\n        ( SolrException.ErrorCode.SERVER_ERROR,\n          \"Configuration Error: Analyzer class='\" + analyzerName +\n          \"' can not be combined with nested analysis factories\");\n      }\n\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        Analyzer analyzer = clazz.getConstructor().newInstance();\n\n        final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n        final Version luceneMatchVersion = (matchVersionStr == null) ?\n          schema.getDefaultLuceneMatchVersion() :\n          SolrConfig.parseLuceneVersionString(matchVersionStr);\n        if (luceneMatchVersion == null) {\n          throw new SolrException\n            ( SolrException.ErrorCode.SERVER_ERROR,\n              \"Configuration Error: Analyzer '\" + clazz.getName() +\n              \"' needs a 'luceneMatchVersion' parameter\");\n        }\n        analyzer.setVersion(luceneMatchVersion);\n        return analyzer;\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected CharFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, CharFilterFactory.class.getSimpleName()).toString());\n        CharFilterFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = CharFilterFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: \" + name + \" and className: \" + className + \" are specified for charFilter.\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create charFilter: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, CharFilterFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for charFilter.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create charFilter: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, charFilterNodes );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      \n      @Override\n      protected TokenizerFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenizerFactory.class.getSimpleName()).toString());\n        TokenizerFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = TokenizerFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: \" + name + \" and className: \" + className + \" are specified for tokenizer.\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create tokenizer: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, TokenizerFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for tokenizer.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create tokenizer: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, tokenizerNodes );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer\");\n    }\n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected TokenFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenFilterFactory.class.getSimpleName()).toString());\n        TokenFilterFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = TokenFilterFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: \" + name + \" and className: \" + className + \" are specified for tokenFilter.\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create tokenFilter: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, TokenFilterFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for tokenFilter.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create tokenFilter: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, tokenFilterNodes );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n\n    // check for all of these up front, so we can error if used in \n    // conjunction with an explicit analyzer class.\n    NodeList charFilterNodes = (NodeList)xpath.evaluate\n      (\"./charFilter\",  node, XPathConstants.NODESET);\n    NodeList tokenizerNodes = (NodeList)xpath.evaluate\n      (\"./tokenizer\", node, XPathConstants.NODESET);\n    NodeList tokenFilterNodes = (NodeList)xpath.evaluate\n      (\"./filter\", node, XPathConstants.NODESET);\n      \n    if (analyzerName != null) {\n\n      // explicitly check for child analysis factories instead of\n      // just any child nodes, because the user might have their\n      // own custom nodes (ie: <description> or something like that)\n      if (0 != charFilterNodes.getLength() ||\n          0 != tokenizerNodes.getLength() ||\n          0 != tokenFilterNodes.getLength()) {\n        throw new SolrException\n        ( SolrException.ErrorCode.SERVER_ERROR,\n          \"Configuration Error: Analyzer class='\" + analyzerName +\n          \"' can not be combined with nested analysis factories\");\n      }\n\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        Analyzer analyzer = clazz.getConstructor().newInstance();\n\n        final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n        final Version luceneMatchVersion = (matchVersionStr == null) ?\n          schema.getDefaultLuceneMatchVersion() :\n          SolrConfig.parseLuceneVersionString(matchVersionStr);\n        if (luceneMatchVersion == null) {\n          throw new SolrException\n            ( SolrException.ErrorCode.SERVER_ERROR,\n              \"Configuration Error: Analyzer '\" + clazz.getName() +\n              \"' needs a 'luceneMatchVersion' parameter\");\n        }\n        analyzer.setVersion(luceneMatchVersion);\n        return analyzer;\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected CharFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, CharFilterFactory.class.getSimpleName()).toString());\n        CharFilterFactory factory = loader.newInstance(className, CharFilterFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, charFilterNodes );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      \n      @Override\n      protected TokenizerFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenizerFactory.class.getSimpleName()).toString());\n        TokenizerFactory factory = loader.newInstance(className, TokenizerFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, tokenizerNodes );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer\");\n    }\n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected TokenFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenFilterFactory.class.getSimpleName()).toString());\n        TokenFilterFactory factory = loader.newInstance\n            (className, TokenFilterFactory.class, getDefaultPackages(), new Class[] { Map.class }, new Object[] { params });\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, tokenFilterNodes );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"73b91012493e4750b9dc169cf1ae8cdd91493b42","date":1569935879,"type":3,"author":"Thomas Wöckinger","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","pathOld":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n\n    // check for all of these up front, so we can error if used in \n    // conjunction with an explicit analyzer class.\n    NodeList charFilterNodes = (NodeList)xpath.evaluate\n      (\"./charFilter\",  node, XPathConstants.NODESET);\n    NodeList tokenizerNodes = (NodeList)xpath.evaluate\n      (\"./tokenizer\", node, XPathConstants.NODESET);\n    NodeList tokenFilterNodes = (NodeList)xpath.evaluate\n      (\"./filter\", node, XPathConstants.NODESET);\n      \n    if (analyzerName != null) {\n\n      // explicitly check for child analysis factories instead of\n      // just any child nodes, because the user might have their\n      // own custom nodes (ie: <description> or something like that)\n      if (0 != charFilterNodes.getLength() ||\n          0 != tokenizerNodes.getLength() ||\n          0 != tokenFilterNodes.getLength()) {\n        throw new SolrException\n        ( SolrException.ErrorCode.SERVER_ERROR,\n          \"Configuration Error: Analyzer class='\" + analyzerName +\n          \"' can not be combined with nested analysis factories\");\n      }\n\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        Analyzer analyzer = clazz.getConstructor().newInstance();\n\n        final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n        final Version luceneMatchVersion = (matchVersionStr == null) ?\n          schema.getDefaultLuceneMatchVersion() :\n          SolrConfig.parseLuceneVersionString(matchVersionStr);\n        if (luceneMatchVersion == null) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Configuration Error: Analyzer '\" + clazz.getName() +\n                  \"' needs a '\" + IndexSchema.LUCENE_MATCH_VERSION_PARAM + \"' parameter\");\n        }\n        analyzer.setVersion(luceneMatchVersion);\n        return analyzer;\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected CharFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, CharFilterFactory.class.getSimpleName()).toString());\n        CharFilterFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = CharFilterFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: \" + name + \" and className: \" + className + \" are specified for charFilter.\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create charFilter: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, CharFilterFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for charFilter.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create charFilter: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, charFilterNodes );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      \n      @Override\n      protected TokenizerFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenizerFactory.class.getSimpleName()).toString());\n        TokenizerFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = TokenizerFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: \" + name + \" and className: \" + className + \" are specified for tokenizer.\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create tokenizer: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, TokenizerFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for tokenizer.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create tokenizer: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, tokenizerNodes );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer\");\n    }\n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected TokenFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenFilterFactory.class.getSimpleName()).toString());\n        TokenFilterFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = TokenFilterFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: \" + name + \" and className: \" + className + \" are specified for tokenFilter.\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create tokenFilter: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, TokenFilterFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for tokenFilter.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create tokenFilter: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, tokenFilterNodes );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n\n    // check for all of these up front, so we can error if used in \n    // conjunction with an explicit analyzer class.\n    NodeList charFilterNodes = (NodeList)xpath.evaluate\n      (\"./charFilter\",  node, XPathConstants.NODESET);\n    NodeList tokenizerNodes = (NodeList)xpath.evaluate\n      (\"./tokenizer\", node, XPathConstants.NODESET);\n    NodeList tokenFilterNodes = (NodeList)xpath.evaluate\n      (\"./filter\", node, XPathConstants.NODESET);\n      \n    if (analyzerName != null) {\n\n      // explicitly check for child analysis factories instead of\n      // just any child nodes, because the user might have their\n      // own custom nodes (ie: <description> or something like that)\n      if (0 != charFilterNodes.getLength() ||\n          0 != tokenizerNodes.getLength() ||\n          0 != tokenFilterNodes.getLength()) {\n        throw new SolrException\n        ( SolrException.ErrorCode.SERVER_ERROR,\n          \"Configuration Error: Analyzer class='\" + analyzerName +\n          \"' can not be combined with nested analysis factories\");\n      }\n\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        Analyzer analyzer = clazz.getConstructor().newInstance();\n\n        final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n        final Version luceneMatchVersion = (matchVersionStr == null) ?\n          schema.getDefaultLuceneMatchVersion() :\n          SolrConfig.parseLuceneVersionString(matchVersionStr);\n        if (luceneMatchVersion == null) {\n          throw new SolrException\n            ( SolrException.ErrorCode.SERVER_ERROR,\n              \"Configuration Error: Analyzer '\" + clazz.getName() +\n              \"' needs a 'luceneMatchVersion' parameter\");\n        }\n        analyzer.setVersion(luceneMatchVersion);\n        return analyzer;\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected CharFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, CharFilterFactory.class.getSimpleName()).toString());\n        CharFilterFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = CharFilterFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: \" + name + \" and className: \" + className + \" are specified for charFilter.\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create charFilter: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, CharFilterFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for charFilter.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create charFilter: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, charFilterNodes );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      \n      @Override\n      protected TokenizerFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenizerFactory.class.getSimpleName()).toString());\n        TokenizerFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = TokenizerFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: \" + name + \" and className: \" + className + \" are specified for tokenizer.\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create tokenizer: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, TokenizerFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for tokenizer.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create tokenizer: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, tokenizerNodes );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer\");\n    }\n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected TokenFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenFilterFactory.class.getSimpleName()).toString());\n        TokenFilterFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = TokenFilterFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: \" + name + \" and className: \" + className + \" are specified for tokenFilter.\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create tokenFilter: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, TokenFilterFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for tokenFilter.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create tokenFilter: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, tokenFilterNodes );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","bugFix":["379db3ad24c4f0214f30a122265a6d6be003a99d"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b0b597c65628ca9e73913a07e81691f8229bae35","date":1571224353,"type":3,"author":"jimczi","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","pathOld":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n\n    // check for all of these up front, so we can error if used in \n    // conjunction with an explicit analyzer class.\n    NodeList charFilterNodes = (NodeList)xpath.evaluate\n      (\"./charFilter\",  node, XPathConstants.NODESET);\n    NodeList tokenizerNodes = (NodeList)xpath.evaluate\n      (\"./tokenizer\", node, XPathConstants.NODESET);\n    NodeList tokenFilterNodes = (NodeList)xpath.evaluate\n      (\"./filter\", node, XPathConstants.NODESET);\n      \n    if (analyzerName != null) {\n\n      // explicitly check for child analysis factories instead of\n      // just any child nodes, because the user might have their\n      // own custom nodes (ie: <description> or something like that)\n      if (0 != charFilterNodes.getLength() ||\n          0 != tokenizerNodes.getLength() ||\n          0 != tokenFilterNodes.getLength()) {\n        throw new SolrException\n        ( SolrException.ErrorCode.SERVER_ERROR,\n          \"Configuration Error: Analyzer class='\" + analyzerName +\n          \"' can not be combined with nested analysis factories\");\n      }\n\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        Analyzer analyzer = clazz.getConstructor().newInstance();\n\n        final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n        final Version luceneMatchVersion = (matchVersionStr == null) ?\n          schema.getDefaultLuceneMatchVersion() :\n          SolrConfig.parseLuceneVersionString(matchVersionStr);\n        if (luceneMatchVersion == null) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Configuration Error: Analyzer '\" + clazz.getName() +\n                  \"' needs a '\" + IndexSchema.LUCENE_MATCH_VERSION_PARAM + \"' parameter\");\n        }\n        analyzer.setVersion(luceneMatchVersion);\n        return analyzer;\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected CharFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, CharFilterFactory.class.getSimpleName()).toString());\n        CharFilterFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = CharFilterFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: \" + name + \" and className: \" + className + \" are specified for charFilter.\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create charFilter: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, CharFilterFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for charFilter.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create charFilter: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, charFilterNodes );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      \n      @Override\n      protected TokenizerFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenizerFactory.class.getSimpleName()).toString());\n        TokenizerFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = TokenizerFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: \" + name + \" and className: \" + className + \" are specified for tokenizer.\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create tokenizer: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, TokenizerFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for tokenizer.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create tokenizer: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, tokenizerNodes );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer\");\n    }\n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected TokenFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenFilterFactory.class.getSimpleName()).toString());\n        TokenFilterFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = TokenFilterFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: \" + name + \" and className: \" + className + \" are specified for tokenFilter.\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create tokenFilter: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, TokenFilterFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for tokenFilter.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create tokenFilter: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, tokenFilterNodes );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n\n    // check for all of these up front, so we can error if used in \n    // conjunction with an explicit analyzer class.\n    NodeList charFilterNodes = (NodeList)xpath.evaluate\n      (\"./charFilter\",  node, XPathConstants.NODESET);\n    NodeList tokenizerNodes = (NodeList)xpath.evaluate\n      (\"./tokenizer\", node, XPathConstants.NODESET);\n    NodeList tokenFilterNodes = (NodeList)xpath.evaluate\n      (\"./filter\", node, XPathConstants.NODESET);\n      \n    if (analyzerName != null) {\n\n      // explicitly check for child analysis factories instead of\n      // just any child nodes, because the user might have their\n      // own custom nodes (ie: <description> or something like that)\n      if (0 != charFilterNodes.getLength() ||\n          0 != tokenizerNodes.getLength() ||\n          0 != tokenFilterNodes.getLength()) {\n        throw new SolrException\n        ( SolrException.ErrorCode.SERVER_ERROR,\n          \"Configuration Error: Analyzer class='\" + analyzerName +\n          \"' can not be combined with nested analysis factories\");\n      }\n\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        Analyzer analyzer = clazz.getConstructor().newInstance();\n\n        final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n        final Version luceneMatchVersion = (matchVersionStr == null) ?\n          schema.getDefaultLuceneMatchVersion() :\n          SolrConfig.parseLuceneVersionString(matchVersionStr);\n        if (luceneMatchVersion == null) {\n          throw new SolrException\n            ( SolrException.ErrorCode.SERVER_ERROR,\n              \"Configuration Error: Analyzer '\" + clazz.getName() +\n              \"' needs a 'luceneMatchVersion' parameter\");\n        }\n        analyzer.setVersion(luceneMatchVersion);\n        return analyzer;\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected CharFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, CharFilterFactory.class.getSimpleName()).toString());\n        CharFilterFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = CharFilterFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: \" + name + \" and className: \" + className + \" are specified for charFilter.\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create charFilter: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, CharFilterFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for charFilter.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create charFilter: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, charFilterNodes );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      \n      @Override\n      protected TokenizerFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenizerFactory.class.getSimpleName()).toString());\n        TokenizerFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = TokenizerFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: \" + name + \" and className: \" + className + \" are specified for tokenizer.\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create tokenizer: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, TokenizerFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for tokenizer.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create tokenizer: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, tokenizerNodes );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer\");\n    }\n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected TokenFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenFilterFactory.class.getSimpleName()).toString());\n        TokenFilterFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = TokenFilterFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: \" + name + \" and className: \" + className + \" are specified for tokenFilter.\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create tokenFilter: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, TokenFilterFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for tokenFilter.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create tokenFilter: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, tokenFilterNodes );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9df8125ba9193a2e2e285ed92157810b1952a244","date":1587326330,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","pathOld":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n\n    // check for all of these up front, so we can error if used in \n    // conjunction with an explicit analyzer class.\n    NodeList charFilterNodes = (NodeList)xpath.evaluate\n      (\"./charFilter\",  node, XPathConstants.NODESET);\n    NodeList tokenizerNodes = (NodeList)xpath.evaluate\n      (\"./tokenizer\", node, XPathConstants.NODESET);\n    NodeList tokenFilterNodes = (NodeList)xpath.evaluate\n      (\"./filter\", node, XPathConstants.NODESET);\n      \n    if (analyzerName != null) {\n\n      // explicitly check for child analysis factories instead of\n      // just any child nodes, because the user might have their\n      // own custom nodes (ie: <description> or something like that)\n      if (0 != charFilterNodes.getLength() ||\n          0 != tokenizerNodes.getLength() ||\n          0 != tokenFilterNodes.getLength()) {\n        throw new SolrException\n        ( SolrException.ErrorCode.SERVER_ERROR,\n          \"Configuration Error: Analyzer class='\" + analyzerName +\n          \"' can not be combined with nested analysis factories\");\n      }\n\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        Analyzer analyzer = clazz.getConstructor().newInstance();\n\n        final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n        final Version luceneMatchVersion = (matchVersionStr == null) ?\n          schema.getDefaultLuceneMatchVersion() :\n          SolrConfig.parseLuceneVersionString(matchVersionStr);\n        if (luceneMatchVersion == null) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Configuration Error: Analyzer '\" + clazz.getName() +\n                  \"' needs a '\" + IndexSchema.LUCENE_MATCH_VERSION_PARAM + \"' parameter\");\n        }\n        analyzer.setVersion(luceneMatchVersion);\n        return analyzer;\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: {}\", analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected CharFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, CharFilterFactory.class.getSimpleName()).toString());\n        CharFilterFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = CharFilterFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: {} and className: {} are specified for charFilter.\", name, className);\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create charFilter: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, CharFilterFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for charFilter.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create charFilter: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, charFilterNodes );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      \n      @Override\n      protected TokenizerFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenizerFactory.class.getSimpleName()).toString());\n        TokenizerFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = TokenizerFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: {} and className: {} are specified for tokenizer.\", name, className);\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create tokenizer: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, TokenizerFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for tokenizer.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create tokenizer: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, tokenizerNodes );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer\");\n    }\n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected TokenFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenFilterFactory.class.getSimpleName()).toString());\n        TokenFilterFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = TokenFilterFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: {} and className: {} are specified for tokenFilter.\", name, className);\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create tokenFilter: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, TokenFilterFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for tokenFilter.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create tokenFilter: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, tokenFilterNodes );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n\n    // check for all of these up front, so we can error if used in \n    // conjunction with an explicit analyzer class.\n    NodeList charFilterNodes = (NodeList)xpath.evaluate\n      (\"./charFilter\",  node, XPathConstants.NODESET);\n    NodeList tokenizerNodes = (NodeList)xpath.evaluate\n      (\"./tokenizer\", node, XPathConstants.NODESET);\n    NodeList tokenFilterNodes = (NodeList)xpath.evaluate\n      (\"./filter\", node, XPathConstants.NODESET);\n      \n    if (analyzerName != null) {\n\n      // explicitly check for child analysis factories instead of\n      // just any child nodes, because the user might have their\n      // own custom nodes (ie: <description> or something like that)\n      if (0 != charFilterNodes.getLength() ||\n          0 != tokenizerNodes.getLength() ||\n          0 != tokenFilterNodes.getLength()) {\n        throw new SolrException\n        ( SolrException.ErrorCode.SERVER_ERROR,\n          \"Configuration Error: Analyzer class='\" + analyzerName +\n          \"' can not be combined with nested analysis factories\");\n      }\n\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        Analyzer analyzer = clazz.getConstructor().newInstance();\n\n        final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n        final Version luceneMatchVersion = (matchVersionStr == null) ?\n          schema.getDefaultLuceneMatchVersion() :\n          SolrConfig.parseLuceneVersionString(matchVersionStr);\n        if (luceneMatchVersion == null) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Configuration Error: Analyzer '\" + clazz.getName() +\n                  \"' needs a '\" + IndexSchema.LUCENE_MATCH_VERSION_PARAM + \"' parameter\");\n        }\n        analyzer.setVersion(luceneMatchVersion);\n        return analyzer;\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected CharFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, CharFilterFactory.class.getSimpleName()).toString());\n        CharFilterFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = CharFilterFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: \" + name + \" and className: \" + className + \" are specified for charFilter.\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create charFilter: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, CharFilterFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for charFilter.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create charFilter: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, charFilterNodes );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      \n      @Override\n      protected TokenizerFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenizerFactory.class.getSimpleName()).toString());\n        TokenizerFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = TokenizerFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: \" + name + \" and className: \" + className + \" are specified for tokenizer.\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create tokenizer: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, TokenizerFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for tokenizer.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create tokenizer: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, tokenizerNodes );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer\");\n    }\n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected TokenFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenFilterFactory.class.getSimpleName()).toString());\n        TokenFilterFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = TokenFilterFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: \" + name + \" and className: \" + className + \" are specified for tokenFilter.\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create tokenFilter: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, TokenFilterFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for tokenFilter.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create tokenFilter: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, tokenFilterNodes );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"06a8891f085f71282bb3ece1b1732b68f07813a3","date":1591912889,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","pathOld":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n\n    // check for all of these up front, so we can error if used in \n    // conjunction with an explicit analyzer class.\n    NodeList charFilterNodes = (NodeList)xpath.evaluate\n      (\"./charFilter\",  node, XPathConstants.NODESET);\n    NodeList tokenizerNodes = (NodeList)xpath.evaluate\n      (\"./tokenizer\", node, XPathConstants.NODESET);\n    NodeList tokenFilterNodes = (NodeList)xpath.evaluate\n      (\"./filter\", node, XPathConstants.NODESET);\n      \n    if (analyzerName != null) {\n\n      // explicitly check for child analysis factories instead of\n      // just any child nodes, because the user might have their\n      // own custom nodes (ie: <description> or something like that)\n      if (0 != charFilterNodes.getLength() ||\n          0 != tokenizerNodes.getLength() ||\n          0 != tokenFilterNodes.getLength()) {\n        throw new SolrException\n        ( SolrException.ErrorCode.SERVER_ERROR,\n          \"Configuration Error: Analyzer class='\" + analyzerName +\n          \"' can not be combined with nested analysis factories\");\n      }\n\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        Analyzer analyzer = clazz.getConstructor().newInstance();\n\n        final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n        final Version luceneMatchVersion = (matchVersionStr == null) ?\n          schema.getDefaultLuceneMatchVersion() :\n          SolrConfig.parseLuceneVersionString(matchVersionStr);\n        if (luceneMatchVersion == null) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Configuration Error: Analyzer '\" + clazz.getName() +\n                  \"' needs a '\" + IndexSchema.LUCENE_MATCH_VERSION_PARAM + \"' parameter\");\n        }\n        analyzer.setVersion(luceneMatchVersion);\n        return analyzer;\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: {}\", analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      @SuppressWarnings({\"rawtypes\"})\n      protected CharFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, CharFilterFactory.class.getSimpleName()).toString());\n        CharFilterFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = CharFilterFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: {} and className: {} are specified for charFilter.\", name, className);\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create charFilter: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, CharFilterFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for charFilter.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create charFilter: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, charFilterNodes );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      \n      @Override\n      @SuppressWarnings({\"rawtypes\"})\n      protected TokenizerFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenizerFactory.class.getSimpleName()).toString());\n        TokenizerFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = TokenizerFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: {} and className: {} are specified for tokenizer.\", name, className);\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create tokenizer: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, TokenizerFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for tokenizer.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create tokenizer: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, tokenizerNodes );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer\");\n    }\n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      @SuppressWarnings({\"rawtypes\"})\n      protected TokenFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenFilterFactory.class.getSimpleName()).toString());\n        TokenFilterFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = TokenFilterFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: {} and className: {} are specified for tokenFilter.\", name, className);\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create tokenFilter: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, TokenFilterFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for tokenFilter.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create tokenFilter: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, tokenFilterNodes );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n\n    // check for all of these up front, so we can error if used in \n    // conjunction with an explicit analyzer class.\n    NodeList charFilterNodes = (NodeList)xpath.evaluate\n      (\"./charFilter\",  node, XPathConstants.NODESET);\n    NodeList tokenizerNodes = (NodeList)xpath.evaluate\n      (\"./tokenizer\", node, XPathConstants.NODESET);\n    NodeList tokenFilterNodes = (NodeList)xpath.evaluate\n      (\"./filter\", node, XPathConstants.NODESET);\n      \n    if (analyzerName != null) {\n\n      // explicitly check for child analysis factories instead of\n      // just any child nodes, because the user might have their\n      // own custom nodes (ie: <description> or something like that)\n      if (0 != charFilterNodes.getLength() ||\n          0 != tokenizerNodes.getLength() ||\n          0 != tokenFilterNodes.getLength()) {\n        throw new SolrException\n        ( SolrException.ErrorCode.SERVER_ERROR,\n          \"Configuration Error: Analyzer class='\" + analyzerName +\n          \"' can not be combined with nested analysis factories\");\n      }\n\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        Analyzer analyzer = clazz.getConstructor().newInstance();\n\n        final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n        final Version luceneMatchVersion = (matchVersionStr == null) ?\n          schema.getDefaultLuceneMatchVersion() :\n          SolrConfig.parseLuceneVersionString(matchVersionStr);\n        if (luceneMatchVersion == null) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Configuration Error: Analyzer '\" + clazz.getName() +\n                  \"' needs a '\" + IndexSchema.LUCENE_MATCH_VERSION_PARAM + \"' parameter\");\n        }\n        analyzer.setVersion(luceneMatchVersion);\n        return analyzer;\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: {}\", analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      protected CharFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, CharFilterFactory.class.getSimpleName()).toString());\n        CharFilterFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = CharFilterFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: {} and className: {} are specified for charFilter.\", name, className);\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create charFilter: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, CharFilterFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for charFilter.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create charFilter: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, charFilterNodes );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      \n      @Override\n      protected TokenizerFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenizerFactory.class.getSimpleName()).toString());\n        TokenizerFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = TokenizerFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: {} and className: {} are specified for tokenizer.\", name, className);\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create tokenizer: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, TokenizerFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for tokenizer.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create tokenizer: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, tokenizerNodes );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer\");\n    }\n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      protected TokenFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenFilterFactory.class.getSimpleName()).toString());\n        TokenFilterFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = TokenFilterFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: {} and className: {} are specified for tokenFilter.\", name, className);\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create tokenFilter: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, TokenFilterFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for tokenFilter.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create tokenFilter: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, tokenFilterNodes );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b2ed9b72e5fa27a7bd4857f222ca815341979d4a","date":1594879524,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","pathOld":"solr/core/src/java/org/apache/solr/schema/FieldTypePluginLoader#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrClassLoader loader = schema.getSolrClassLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n\n    // check for all of these up front, so we can error if used in \n    // conjunction with an explicit analyzer class.\n    NodeList charFilterNodes = (NodeList)xpath.evaluate\n      (\"./charFilter\",  node, XPathConstants.NODESET);\n    NodeList tokenizerNodes = (NodeList)xpath.evaluate\n      (\"./tokenizer\", node, XPathConstants.NODESET);\n    NodeList tokenFilterNodes = (NodeList)xpath.evaluate\n      (\"./filter\", node, XPathConstants.NODESET);\n      \n    if (analyzerName != null) {\n\n      // explicitly check for child analysis factories instead of\n      // just any child nodes, because the user might have their\n      // own custom nodes (ie: <description> or something like that)\n      if (0 != charFilterNodes.getLength() ||\n          0 != tokenizerNodes.getLength() ||\n          0 != tokenFilterNodes.getLength()) {\n        throw new SolrException\n        ( SolrException.ErrorCode.SERVER_ERROR,\n          \"Configuration Error: Analyzer class='\" + analyzerName +\n          \"' can not be combined with nested analysis factories\");\n      }\n\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        Analyzer analyzer = clazz.getConstructor().newInstance();\n\n        final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n        final Version luceneMatchVersion = (matchVersionStr == null) ?\n          schema.getDefaultLuceneMatchVersion() :\n          SolrConfig.parseLuceneVersionString(matchVersionStr);\n        if (luceneMatchVersion == null) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Configuration Error: Analyzer '\" + clazz.getName() +\n                  \"' needs a '\" + IndexSchema.LUCENE_MATCH_VERSION_PARAM + \"' parameter\");\n        }\n        analyzer.setVersion(luceneMatchVersion);\n        return analyzer;\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: {}\", analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      @SuppressWarnings({\"rawtypes\"})\n      protected CharFilterFactory create(SolrClassLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, CharFilterFactory.class.getSimpleName()).toString());\n        CharFilterFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = CharFilterFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: {} and className: {} are specified for charFilter.\", name, className);\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create charFilter: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, CharFilterFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for charFilter.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create charFilter: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, charFilterNodes );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      \n      @Override\n      @SuppressWarnings({\"rawtypes\"})\n      protected TokenizerFactory create(SolrClassLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenizerFactory.class.getSimpleName()).toString());\n        TokenizerFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = TokenizerFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: {} and className: {} are specified for tokenizer.\", name, className);\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create tokenizer: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, TokenizerFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for tokenizer.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create tokenizer: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, tokenizerNodes );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer\");\n    }\n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      @SuppressWarnings({\"rawtypes\"})\n      protected TokenFilterFactory create(SolrClassLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenFilterFactory.class.getSimpleName()).toString());\n        TokenFilterFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = TokenFilterFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: {} and className: {} are specified for tokenFilter.\", name, className);\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create tokenFilter: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, TokenFilterFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for tokenFilter.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create tokenFilter: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, tokenFilterNodes );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n                                \n    final SolrResourceLoader loader = schema.getResourceLoader();\n\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n    \n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n\n    // check for all of these up front, so we can error if used in \n    // conjunction with an explicit analyzer class.\n    NodeList charFilterNodes = (NodeList)xpath.evaluate\n      (\"./charFilter\",  node, XPathConstants.NODESET);\n    NodeList tokenizerNodes = (NodeList)xpath.evaluate\n      (\"./tokenizer\", node, XPathConstants.NODESET);\n    NodeList tokenFilterNodes = (NodeList)xpath.evaluate\n      (\"./filter\", node, XPathConstants.NODESET);\n      \n    if (analyzerName != null) {\n\n      // explicitly check for child analysis factories instead of\n      // just any child nodes, because the user might have their\n      // own custom nodes (ie: <description> or something like that)\n      if (0 != charFilterNodes.getLength() ||\n          0 != tokenizerNodes.getLength() ||\n          0 != tokenFilterNodes.getLength()) {\n        throw new SolrException\n        ( SolrException.ErrorCode.SERVER_ERROR,\n          \"Configuration Error: Analyzer class='\" + analyzerName +\n          \"' can not be combined with nested analysis factories\");\n      }\n\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass(analyzerName, Analyzer.class);\n        Analyzer analyzer = clazz.getConstructor().newInstance();\n\n        final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n        final Version luceneMatchVersion = (matchVersionStr == null) ?\n          schema.getDefaultLuceneMatchVersion() :\n          SolrConfig.parseLuceneVersionString(matchVersionStr);\n        if (luceneMatchVersion == null) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Configuration Error: Analyzer '\" + clazz.getName() +\n                  \"' needs a '\" + IndexSchema.LUCENE_MATCH_VERSION_PARAM + \"' parameter\");\n        }\n        analyzer.setVersion(luceneMatchVersion);\n        return analyzer;\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: {}\", analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    // Load the CharFilters\n\n    final ArrayList<CharFilterFactory> charFilters \n      = new ArrayList<>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>\n      (\"[schema.xml] analyzer/charFilter\", CharFilterFactory.class, false, false) {\n\n      @Override\n      @SuppressWarnings({\"rawtypes\"})\n      protected CharFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, CharFilterFactory.class.getSimpleName()).toString());\n        CharFilterFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = CharFilterFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: {} and className: {} are specified for charFilter.\", name, className);\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create charFilter: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, CharFilterFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for charFilter.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create charFilter: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, \n                                           CharFilterFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    charFilterLoader.load( loader, charFilterNodes );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n\n    final ArrayList<TokenizerFactory> tokenizers \n      = new ArrayList<>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>\n      (\"[schema.xml] analyzer/tokenizer\", TokenizerFactory.class, false, false) {\n      \n      @Override\n      @SuppressWarnings({\"rawtypes\"})\n      protected TokenizerFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenizerFactory.class.getSimpleName()).toString());\n        TokenizerFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = TokenizerFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: {} and className: {} are specified for tokenizer.\", name, className);\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create tokenizer: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, TokenizerFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for tokenizer.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create tokenizer: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) {\n        return null; // used for map registration\n      }\n    };\n\n    tokenizerLoader.load( loader, tokenizerNodes );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer\");\n    }\n\n    // Load the Filters\n\n    final ArrayList<TokenFilterFactory> filters \n      = new ArrayList<>();\n\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>(\"[schema.xml] analyzer/filter\", TokenFilterFactory.class, false, false)\n    {\n      @Override\n      @SuppressWarnings({\"rawtypes\"})\n      protected TokenFilterFactory create(SolrResourceLoader loader, String name, String className, Node node) throws Exception {\n        final Map<String,String> params = DOMUtil.toMap(node.getAttributes());\n        String configuredVersion = params.remove(LUCENE_MATCH_VERSION_PARAM);\n        params.put(LUCENE_MATCH_VERSION_PARAM, parseConfiguredVersion(configuredVersion, TokenFilterFactory.class.getSimpleName()).toString());\n        TokenFilterFactory factory;\n        if (Objects.nonNull(name)) {\n          factory = TokenFilterFactory.forName(name, params);\n          if (Objects.nonNull(className)) {\n            log.error(\"Both of name: {} and className: {} are specified for tokenFilter.\", name, className);\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Cannot create tokenFilter: Both of name and className are specified.\");\n          }\n        } else if (Objects.nonNull(className)) {\n          factory = loader.newInstance(className, TokenFilterFactory.class, getDefaultPackages(), new Class[]{Map.class}, new Object[]{params});\n        } else {\n          log.error(\"Neither of name or className is specified for tokenFilter.\");\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot create tokenFilter: Neither of name or className is specified.\");\n        }\n        factory.setExplicitLuceneMatchVersion(null != configuredVersion);\n        return factory;\n      }\n      \n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, tokenFilterNodes );\n    \n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n                              tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"88b3e8520b7ff30e6ffd93e6c1cda658ebeeaf0c":["d6d3ad4230a9094e97925f9395cf6db4729284d9"],"ee622110ba6021d0390037e77574743c1e55348c":["379db3ad24c4f0214f30a122265a6d6be003a99d"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["9b4b4d68085809ae840a099e4620e5a128509279"],"111313ddec6f8f61d5645a3f368ad793c106643b":["d6d3ad4230a9094e97925f9395cf6db4729284d9"],"7bb7d4caf24bc521fa8ac35f463f50724b4a91d8":["6ccf3f2e89c8e02a00051620fa60a11a2c696295"],"2eb89ed39d48c9dbf1ec6df65ed11f8cf5331e88":["ee622110ba6021d0390037e77574743c1e55348c"],"9b4b4d68085809ae840a099e4620e5a128509279":["57da959ec15bb701bd1d1bf3c613b69009ff4bfd"],"57da959ec15bb701bd1d1bf3c613b69009ff4bfd":["111313ddec6f8f61d5645a3f368ad793c106643b"],"f09ac0abea5345f77c4cf8d9f0d531da9139debc":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"6ccf3f2e89c8e02a00051620fa60a11a2c696295":["88b3e8520b7ff30e6ffd93e6c1cda658ebeeaf0c"],"b88a121b875f9ae2ac50f85cf46dcb680f126357":["2eb89ed39d48c9dbf1ec6df65ed11f8cf5331e88"],"b2ed9b72e5fa27a7bd4857f222ca815341979d4a":["06a8891f085f71282bb3ece1b1732b68f07813a3"],"2c24804758d67429e3055070a9fe970d4f159954":["b88a121b875f9ae2ac50f85cf46dcb680f126357"],"d6d3ad4230a9094e97925f9395cf6db4729284d9":["a7ebf3a5f9e588d0bb564ac30d6dc32056ce9a41"],"379db3ad24c4f0214f30a122265a6d6be003a99d":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"a7ebf3a5f9e588d0bb564ac30d6dc32056ce9a41":["f09ac0abea5345f77c4cf8d9f0d531da9139debc"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["d6d3ad4230a9094e97925f9395cf6db4729284d9","111313ddec6f8f61d5645a3f368ad793c106643b"],"06a8891f085f71282bb3ece1b1732b68f07813a3":["9df8125ba9193a2e2e285ed92157810b1952a244"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["d6d3ad4230a9094e97925f9395cf6db4729284d9","111313ddec6f8f61d5645a3f368ad793c106643b"],"73b91012493e4750b9dc169cf1ae8cdd91493b42":["2c24804758d67429e3055070a9fe970d4f159954"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b2ed9b72e5fa27a7bd4857f222ca815341979d4a"],"9df8125ba9193a2e2e285ed92157810b1952a244":["73b91012493e4750b9dc169cf1ae8cdd91493b42"],"b0b597c65628ca9e73913a07e81691f8229bae35":["2c24804758d67429e3055070a9fe970d4f159954","73b91012493e4750b9dc169cf1ae8cdd91493b42"]},"commit2Childs":{"88b3e8520b7ff30e6ffd93e6c1cda658ebeeaf0c":["6ccf3f2e89c8e02a00051620fa60a11a2c696295"],"ee622110ba6021d0390037e77574743c1e55348c":["2eb89ed39d48c9dbf1ec6df65ed11f8cf5331e88"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["379db3ad24c4f0214f30a122265a6d6be003a99d"],"111313ddec6f8f61d5645a3f368ad793c106643b":["57da959ec15bb701bd1d1bf3c613b69009ff4bfd","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"7bb7d4caf24bc521fa8ac35f463f50724b4a91d8":[],"2eb89ed39d48c9dbf1ec6df65ed11f8cf5331e88":["b88a121b875f9ae2ac50f85cf46dcb680f126357"],"9b4b4d68085809ae840a099e4620e5a128509279":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"57da959ec15bb701bd1d1bf3c613b69009ff4bfd":["9b4b4d68085809ae840a099e4620e5a128509279"],"6ccf3f2e89c8e02a00051620fa60a11a2c696295":["7bb7d4caf24bc521fa8ac35f463f50724b4a91d8"],"f09ac0abea5345f77c4cf8d9f0d531da9139debc":["a7ebf3a5f9e588d0bb564ac30d6dc32056ce9a41"],"b88a121b875f9ae2ac50f85cf46dcb680f126357":["2c24804758d67429e3055070a9fe970d4f159954"],"b2ed9b72e5fa27a7bd4857f222ca815341979d4a":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"2c24804758d67429e3055070a9fe970d4f159954":["73b91012493e4750b9dc169cf1ae8cdd91493b42","b0b597c65628ca9e73913a07e81691f8229bae35"],"d6d3ad4230a9094e97925f9395cf6db4729284d9":["88b3e8520b7ff30e6ffd93e6c1cda658ebeeaf0c","111313ddec6f8f61d5645a3f368ad793c106643b","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"379db3ad24c4f0214f30a122265a6d6be003a99d":["ee622110ba6021d0390037e77574743c1e55348c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["f09ac0abea5345f77c4cf8d9f0d531da9139debc"],"a7ebf3a5f9e588d0bb564ac30d6dc32056ce9a41":["d6d3ad4230a9094e97925f9395cf6db4729284d9"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":[],"06a8891f085f71282bb3ece1b1732b68f07813a3":["b2ed9b72e5fa27a7bd4857f222ca815341979d4a"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":[],"73b91012493e4750b9dc169cf1ae8cdd91493b42":["9df8125ba9193a2e2e285ed92157810b1952a244","b0b597c65628ca9e73913a07e81691f8229bae35"],"9df8125ba9193a2e2e285ed92157810b1952a244":["06a8891f085f71282bb3ece1b1732b68f07813a3"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"b0b597c65628ca9e73913a07e81691f8229bae35":[]},"heads":["7bb7d4caf24bc521fa8ac35f463f50724b4a91d8","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b","cd5edd1f2b162a5cfa08efd17851a07373a96817","b0b597c65628ca9e73913a07e81691f8229bae35"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}