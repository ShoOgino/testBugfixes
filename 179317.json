{"path":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random, 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      w.addDocument(new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newField(\"id\", \"\"+finalDocCount, StringField.TYPE_STORED);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        });\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null, false);\n            assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n            assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random, 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      w.addDocument(new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newField(\"id\", \"\"+finalDocCount, StringField.TYPE_STORED);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        });\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null, false);\n            assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n            assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f08557cdb6c60ac7b88a9342c983a20cd236e74f","date":1330954480,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random, 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      w.addDocument(new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newField(\"id\", \"\"+finalDocCount, StringField.TYPE_STORED);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        });\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random, 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      w.addDocument(new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newField(\"id\", \"\"+finalDocCount, StringField.TYPE_STORED);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        });\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null, false);\n            assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n            assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","date":1331075828,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random, 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      w.addDocument(new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newField(\"id\", \"\"+finalDocCount, StringField.TYPE_STORED);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        });\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random, 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      w.addDocument(new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newField(\"id\", \"\"+finalDocCount, StringField.TYPE_STORED);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        });\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null, false);\n            assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n            assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d08eba3d52b63561ebf936481ce73e6b6a14aa03","date":1333879759,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random, 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      w.addDocument(new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newField(\"id\", \"\"+finalDocCount, StringField.TYPE_STORED);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        });\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            InvertedFields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random, 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      w.addDocument(new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newField(\"id\", \"\"+finalDocCount, StringField.TYPE_STORED);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        });\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf","date":1333892281,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random, 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      w.addDocument(new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newField(\"id\", \"\"+finalDocCount, StringField.TYPE_STORED);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        });\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random, 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      w.addDocument(new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newField(\"id\", \"\"+finalDocCount, StringField.TYPE_STORED);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        });\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            InvertedFields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      w.addDocument(new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newField(\"id\", \"\"+finalDocCount, StringField.TYPE_STORED);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        });\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random, 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      w.addDocument(new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newField(\"id\", \"\"+finalDocCount, StringField.TYPE_STORED);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        });\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"04f07771a2a7dd3a395700665ed839c3dae2def2","date":1339350139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      w.addDocument(new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        });\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      w.addDocument(new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newField(\"id\", \"\"+finalDocCount, StringField.TYPE_STORED);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        });\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4","date":1341839195,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<? extends IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n                  next = null;\n                  if (fieldUpto > 1) \n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  else \n                    fieldUpto = 2;\n                  \n                  if (next != null && next.fieldType().indexed()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<? extends StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      w.addDocument(new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        });\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a7e4907084808af8fdb14b9809e6dceaccf6867b","date":1343473006,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<? extends IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexed()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<? extends StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<? extends IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n                  next = null;\n                  if (fieldUpto > 1) \n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  else \n                    fieldUpto = 2;\n                  \n                  if (next != null && next.fieldType().indexed()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<? extends StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"322360ac5185a8446d3e0b530b2068bef67cd3d5","date":1343669494,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      w.addDocument(new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        });\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      w.addDocument(new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        });\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","date":1343768312,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      w.addDocument(new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        });\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      w.addDocument(new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        });\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<? extends IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexed()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<? extends StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<? extends IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexed()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<? extends StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1d028314cced5858683a1bb4741423d0f934257b","date":1346596535,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<? extends IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexed()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<? extends StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      w.addDocument(new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        });\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"286d87eabbc79863e93070d6126d558a2ca0fb28","date":1352063339,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexed()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<? extends IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexed()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<? extends StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3b0e8c39ca08b5a02de6edcd33d6f3b90b865173","date":1365631993,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexed()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexed()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexed()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexed()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexed()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.shutdown();\n\n    final IndexSearcher s = newSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexed()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexed()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexed()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.shutdown();\n\n    final IndexSearcher s = newSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3184874f7f3aca850248483485b4995343066875","date":1413876758,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexOptions() != null) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexed()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a22eafe3f72a4c2945eaad9547e6c78816978f4","date":1413956657,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexOptions() != null) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexed()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2bb2842e561df4e8e9ad89010605fc86ac265465","date":1414768208,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexOptions() != IndexOptions.NO) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexOptions() != null) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f95ce1375367b92d411a06175eab3915fe93c6bc","date":1414788502,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexOptions() != IndexOptions.NONE) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexOptions() != IndexOptions.NO) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"51f5280f31484820499077f41fcdfe92d527d9dc","date":1423229122,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexOptions() != IndexOptions.NONE) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            PostingsEnum dpEnum = termsEnum.postings(null, null, PostingsEnum.FLAG_ALL);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.FLAG_ALL);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexOptions() != IndexOptions.NONE) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e73063b92d958076ef4ae8beb5f493e8ccdcecb4","date":1424177215,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexOptions() != IndexOptions.NONE) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            PostingsEnum dpEnum = termsEnum.postings(null, null, PostingsEnum.ALL);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexOptions() != IndexOptions.NONE) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            PostingsEnum dpEnum = termsEnum.postings(null, null, PostingsEnum.FLAG_ALL);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.FLAG_ALL);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82","date":1428522487,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexOptions() != IndexOptions.NONE) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator();\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            PostingsEnum dpEnum = termsEnum.postings(null, null, PostingsEnum.ALL);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexOptions() != IndexOptions.NONE) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            PostingsEnum dpEnum = termsEnum.postings(null, null, PostingsEnum.ALL);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f68d01cf19df971dcdcb05e30247f4ad7ec9747","date":1434611645,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexOptions() != IndexOptions.NONE) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator();\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            PostingsEnum dpEnum = termsEnum.postings(null, null, PostingsEnum.ALL);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery.Builder bq = new BooleanQuery.Builder();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq.build(), 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery.Builder();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq.build(), 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexOptions() != IndexOptions.NONE) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator();\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            PostingsEnum dpEnum = termsEnum.postings(null, null, PostingsEnum.ALL);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f4464508ee83288c8c4585b533f9faaa93aa314","date":1435240759,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexOptions() != IndexOptions.NONE) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator();\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            PostingsEnum dpEnum = termsEnum.postings(null, PostingsEnum.ALL);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery.Builder bq = new BooleanQuery.Builder();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq.build(), 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery.Builder();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq.build(), 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexOptions() != IndexOptions.NONE) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator();\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            PostingsEnum dpEnum = termsEnum.postings(null, null, PostingsEnum.ALL);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.ALL);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery.Builder bq = new BooleanQuery.Builder();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq.build(), 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery.Builder();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq.build(), 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","date":1453060490,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      Iterable<IndexableField> d = new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        };\n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator();\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            PostingsEnum dpEnum = termsEnum.postings(null, PostingsEnum.ALL);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery.Builder bq = new BooleanQuery.Builder();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq.build(), 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery.Builder();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq.build(), 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      IndexDocument d = new IndexDocument() {\n        @Override\n        public Iterable<IndexableField> indexableFields() {\n          return new Iterable<IndexableField>() {\n            @Override\n            public Iterator<IndexableField> iterator() {\n              return new Iterator<IndexableField>() {\n                int fieldUpto = 0;\n                private IndexableField next;\n\n                @Override\n                public boolean hasNext() {\n                  if (fieldUpto >= fieldCount) return false;\n\n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().indexOptions() != IndexOptions.NONE) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public IndexableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n\n        @Override\n        public Iterable<StorableField> storableFields() {\n          return new Iterable<StorableField>() {\n            @Override\n            public Iterator<StorableField> iterator() {\n              return new Iterator<StorableField>() {\n                int fieldUpto = 0;\n                private StorableField next = null;\n\n                @Override\n                public boolean hasNext() {\n\n                  if (fieldUpto == fieldCount) return false;\n                  \n                  next = null;\n                  if (fieldUpto == 0) {\n                    fieldUpto = 1;\n                    next = newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n                  } else {\n                    next = new MyField(finalBaseCount + (fieldUpto++-1));\n                  }\n                  \n                  if (next != null && next.fieldType().stored()) return true;\n                  else return this.hasNext();\n                }\n\n                @Override\n                public StorableField next() {\n                  assert fieldUpto <= fieldCount;\n                  if (next == null && !hasNext()) {\n                    return null;\n                  }\n                  else {\n                    return next;\n                  }\n                }\n\n                @Override\n                public void remove() {\n                  throw new UnsupportedOperationException();\n                }\n              };\n            }\n          };\n        }\n      };\n      \n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final StoredDocument doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          StorableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator();\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            PostingsEnum dpEnum = termsEnum.postings(null, PostingsEnum.ALL);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery.Builder bq = new BooleanQuery.Builder();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq.build(), 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery.Builder();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq.build(), 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"83788ad129a5154d5c6562c4e8ce3db48793aada","date":1532961485,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      Iterable<IndexableField> d = new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        };\n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits.value);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator();\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            PostingsEnum dpEnum = termsEnum.postings(null, PostingsEnum.ALL);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery.Builder bq = new BooleanQuery.Builder();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq.build(), 1);\n          assertEquals(1, hits2.totalHits.value);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery.Builder();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq.build(), 1);\n          assertEquals(1, hits3.totalHits.value);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = TestUtil.nextInt(random(), 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      Iterable<IndexableField> d = new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newStringField(\"id\", \"\"+finalDocCount, Field.Store.YES);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        };\n      w.addDocument(d);\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = newSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator();\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            PostingsEnum dpEnum = termsEnum.postings(null, PostingsEnum.ALL);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);\n            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery.Builder bq = new BooleanQuery.Builder();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq.build(), 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery.Builder();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq.build(), 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"2bb2842e561df4e8e9ad89010605fc86ac265465":["3184874f7f3aca850248483485b4995343066875"],"3b0e8c39ca08b5a02de6edcd33d6f3b90b865173":["286d87eabbc79863e93070d6126d558a2ca0fb28"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"3f68d01cf19df971dcdcb05e30247f4ad7ec9747":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"1d028314cced5858683a1bb4741423d0f934257b":["322360ac5185a8446d3e0b530b2068bef67cd3d5","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf":["d08eba3d52b63561ebf936481ce73e6b6a14aa03"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["6613659748fe4411a7dcf85266e55db1f95f7315"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"322360ac5185a8446d3e0b530b2068bef67cd3d5":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"a7e4907084808af8fdb14b9809e6dceaccf6867b":["8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"286d87eabbc79863e93070d6126d558a2ca0fb28":["1d028314cced5858683a1bb4741423d0f934257b"],"6613659748fe4411a7dcf85266e55db1f95f7315":["3b0e8c39ca08b5a02de6edcd33d6f3b90b865173"],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"d08eba3d52b63561ebf936481ce73e6b6a14aa03":["f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"51f5280f31484820499077f41fcdfe92d527d9dc":["f95ce1375367b92d411a06175eab3915fe93c6bc"],"f95ce1375367b92d411a06175eab3915fe93c6bc":["2bb2842e561df4e8e9ad89010605fc86ac265465"],"3184874f7f3aca850248483485b4995343066875":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["3f68d01cf19df971dcdcb05e30247f4ad7ec9747"],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["51f5280f31484820499077f41fcdfe92d527d9dc"],"0a22eafe3f72a4c2945eaad9547e6c78816978f4":["d0ef034a4f10871667ae75181537775ddcf8ade4","3184874f7f3aca850248483485b4995343066875"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["04f07771a2a7dd3a395700665ed839c3dae2def2","322360ac5185a8446d3e0b530b2068bef67cd3d5"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["a7e4907084808af8fdb14b9809e6dceaccf6867b","322360ac5185a8446d3e0b530b2068bef67cd3d5"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["83788ad129a5154d5c6562c4e8ce3db48793aada"]},"commit2Childs":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["3f68d01cf19df971dcdcb05e30247f4ad7ec9747"],"8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4":["a7e4907084808af8fdb14b9809e6dceaccf6867b"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"2bb2842e561df4e8e9ad89010605fc86ac265465":["f95ce1375367b92d411a06175eab3915fe93c6bc"],"3b0e8c39ca08b5a02de6edcd33d6f3b90b865173":["6613659748fe4411a7dcf85266e55db1f95f7315"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4","322360ac5185a8446d3e0b530b2068bef67cd3d5","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f"],"3f68d01cf19df971dcdcb05e30247f4ad7ec9747":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"1d028314cced5858683a1bb4741423d0f934257b":["286d87eabbc79863e93070d6126d558a2ca0fb28"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"322360ac5185a8446d3e0b530b2068bef67cd3d5":["1d028314cced5858683a1bb4741423d0f934257b","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"a7e4907084808af8fdb14b9809e6dceaccf6867b":["d6f074e73200c07d54f242d3880a8da5a35ff97b"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["83788ad129a5154d5c6562c4e8ce3db48793aada"],"286d87eabbc79863e93070d6126d558a2ca0fb28":["3b0e8c39ca08b5a02de6edcd33d6f3b90b865173"],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","d08eba3d52b63561ebf936481ce73e6b6a14aa03"],"6613659748fe4411a7dcf85266e55db1f95f7315":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"d08eba3d52b63561ebf936481ce73e6b6a14aa03":["e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf"],"51f5280f31484820499077f41fcdfe92d527d9dc":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"3184874f7f3aca850248483485b4995343066875":["2bb2842e561df4e8e9ad89010605fc86ac265465","0a22eafe3f72a4c2945eaad9547e6c78816978f4"],"f95ce1375367b92d411a06175eab3915fe93c6bc":["51f5280f31484820499077f41fcdfe92d527d9dc"],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"0a22eafe3f72a4c2945eaad9547e6c78816978f4":[],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":[],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["1d028314cced5858683a1bb4741423d0f934257b"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["3184874f7f3aca850248483485b4995343066875","0a22eafe3f72a4c2945eaad9547e6c78816978f4"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","0a22eafe3f72a4c2945eaad9547e6c78816978f4","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}