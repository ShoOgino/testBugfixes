{"path":"solr/core/src/java/org/apache/solr/search/SignificantTermsQParserPlugin.SignifcantTermsCollector#finish().mjava","commits":[{"id":"f67c3a1123a063e580a2e6ec51b9eb7c273666ce","date":1487877483,"type":0,"author":"Joel Bernstein","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SignificantTermsQParserPlugin.SignifcantTermsCollector#finish().mjava","pathOld":"/dev/null","sourceNew":"    @Override\n    public void finish() throws IOException {\n      List<String> outTerms = new ArrayList();\n      List<Integer> outFreq = new ArrayList();\n      List<Integer> outQueryFreq = new ArrayList();\n      List<Double> scores = new ArrayList();\n\n      NamedList<Integer> allFreq = new NamedList();\n      NamedList<Integer> allQueryFreq = new NamedList();\n\n      rb.rsp.add(\"numDocs\", numDocs);\n      rb.rsp.add(\"resultCount\", count);\n      rb.rsp.add(\"sterms\", outTerms);\n      rb.rsp.add(\"scores\", scores);\n      rb.rsp.add(\"docFreq\", outFreq);\n      rb.rsp.add(\"queryDocFreq\", outQueryFreq);\n\n      //TODO: Use a priority queue\n      TreeSet<TermWithScore> topTerms = new TreeSet<>();\n\n      Terms terms = MultiFields.getFields(searcher.getIndexReader()).terms(field);\n      TermsEnum termsEnum = terms.iterator();\n      BytesRef term;\n      PostingsEnum postingsEnum = null;\n\n      while ((term = termsEnum.next()) != null) {\n        int docFreq = termsEnum.docFreq();\n        \n        if(minDocs < 1.0) {\n          if((float)docFreq/numDocs < minDocs) {\n            continue;\n          }\n        } else if(docFreq < minDocs) {\n          continue;\n        }\n\n        if(maxDocs < 1.0) {\n          if((float)docFreq/numDocs > maxDocs) {\n            continue;\n          }\n        } else if(docFreq > maxDocs) {\n          continue;\n        }\n\n        if(term.length < minTermLength) {\n          continue;\n        }\n\n        int tf = 0;\n        postingsEnum = termsEnum.postings(postingsEnum);\n\n        POSTINGS:\n        while (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n          int docId = postingsEnum.docID();\n\n          if(docId > highestCollected) {\n            break POSTINGS;\n          }\n\n          if (docs.get(docId)) {\n            ++tf;\n          }\n        }\n\n        if(tf == 0) {\n          continue;\n        }\n\n        float score = (float)Math.log(tf) * (float) (Math.log(((float)(numDocs + 1)) / (docFreq + 1)) + 1.0);\n\n        String t = term.utf8ToString();\n        allFreq.add(t, docFreq);\n        allQueryFreq.add(t, tf);\n\n        if (topTerms.size() < numTerms) {\n          topTerms.add(new TermWithScore(term.utf8ToString(), score));\n        } else  {\n          if (topTerms.first().score < score) {\n            topTerms.pollFirst();\n            topTerms.add(new TermWithScore(term.utf8ToString(), score));\n          }\n        }\n      }\n\n      for (TermWithScore topTerm : topTerms) {\n        outTerms.add(topTerm.term);\n        scores.add(topTerm.score);\n        outFreq.add(allFreq.get(topTerm.term));\n        outQueryFreq.add(allQueryFreq.get(topTerm.term));\n      }\n\n      if (this.delegate instanceof DelegatingCollector) {\n        ((DelegatingCollector) this.delegate).finish();\n      }\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["3185d4c8bb14af74e2ef0bde19f22e33b954b568"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3185d4c8bb14af74e2ef0bde19f22e33b954b568","date":1497065963,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SignificantTermsQParserPlugin.SignifcantTermsCollector#finish().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SignificantTermsQParserPlugin.SignifcantTermsCollector#finish().mjava","sourceNew":"    @Override\n    public void finish() throws IOException {\n      List<String> outTerms = new ArrayList();\n      List<Integer> outFreq = new ArrayList();\n      List<Integer> outQueryFreq = new ArrayList();\n      List<Double> scores = new ArrayList();\n\n      NamedList<Integer> allFreq = new NamedList();\n      NamedList<Integer> allQueryFreq = new NamedList();\n\n      rb.rsp.add(\"numDocs\", numDocs);\n      rb.rsp.add(\"resultCount\", count);\n      rb.rsp.add(\"sterms\", outTerms);\n      rb.rsp.add(\"scores\", scores);\n      rb.rsp.add(\"docFreq\", outFreq);\n      rb.rsp.add(\"queryDocFreq\", outQueryFreq);\n\n      //TODO: Use a priority queue\n      TreeSet<TermWithScore> topTerms = new TreeSet<>();\n\n      Terms terms = ((SolrIndexSearcher)searcher).getSlowAtomicReader().terms(field);\n      TermsEnum termsEnum = terms == null ? TermsEnum.EMPTY : terms.iterator();\n      BytesRef term;\n      PostingsEnum postingsEnum = null;\n\n      while ((term = termsEnum.next()) != null) {\n        int docFreq = termsEnum.docFreq();\n        \n        if(minDocs < 1.0) {\n          if((float)docFreq/numDocs < minDocs) {\n            continue;\n          }\n        } else if(docFreq < minDocs) {\n          continue;\n        }\n\n        if(maxDocs < 1.0) {\n          if((float)docFreq/numDocs > maxDocs) {\n            continue;\n          }\n        } else if(docFreq > maxDocs) {\n          continue;\n        }\n\n        if(term.length < minTermLength) {\n          continue;\n        }\n\n        int tf = 0;\n        postingsEnum = termsEnum.postings(postingsEnum);\n\n        POSTINGS:\n        while (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n          int docId = postingsEnum.docID();\n\n          if(docId > highestCollected) {\n            break POSTINGS;\n          }\n\n          if (docs.get(docId)) {\n            ++tf;\n          }\n        }\n\n        if(tf == 0) {\n          continue;\n        }\n\n        float score = (float)Math.log(tf) * (float) (Math.log(((float)(numDocs + 1)) / (docFreq + 1)) + 1.0);\n\n        String t = term.utf8ToString();\n        allFreq.add(t, docFreq);\n        allQueryFreq.add(t, tf);\n\n        if (topTerms.size() < numTerms) {\n          topTerms.add(new TermWithScore(term.utf8ToString(), score));\n        } else  {\n          if (topTerms.first().score < score) {\n            topTerms.pollFirst();\n            topTerms.add(new TermWithScore(term.utf8ToString(), score));\n          }\n        }\n      }\n\n      for (TermWithScore topTerm : topTerms) {\n        outTerms.add(topTerm.term);\n        scores.add(topTerm.score);\n        outFreq.add(allFreq.get(topTerm.term));\n        outQueryFreq.add(allQueryFreq.get(topTerm.term));\n      }\n\n      if (this.delegate instanceof DelegatingCollector) {\n        ((DelegatingCollector) this.delegate).finish();\n      }\n    }\n\n","sourceOld":"    @Override\n    public void finish() throws IOException {\n      List<String> outTerms = new ArrayList();\n      List<Integer> outFreq = new ArrayList();\n      List<Integer> outQueryFreq = new ArrayList();\n      List<Double> scores = new ArrayList();\n\n      NamedList<Integer> allFreq = new NamedList();\n      NamedList<Integer> allQueryFreq = new NamedList();\n\n      rb.rsp.add(\"numDocs\", numDocs);\n      rb.rsp.add(\"resultCount\", count);\n      rb.rsp.add(\"sterms\", outTerms);\n      rb.rsp.add(\"scores\", scores);\n      rb.rsp.add(\"docFreq\", outFreq);\n      rb.rsp.add(\"queryDocFreq\", outQueryFreq);\n\n      //TODO: Use a priority queue\n      TreeSet<TermWithScore> topTerms = new TreeSet<>();\n\n      Terms terms = MultiFields.getFields(searcher.getIndexReader()).terms(field);\n      TermsEnum termsEnum = terms.iterator();\n      BytesRef term;\n      PostingsEnum postingsEnum = null;\n\n      while ((term = termsEnum.next()) != null) {\n        int docFreq = termsEnum.docFreq();\n        \n        if(minDocs < 1.0) {\n          if((float)docFreq/numDocs < minDocs) {\n            continue;\n          }\n        } else if(docFreq < minDocs) {\n          continue;\n        }\n\n        if(maxDocs < 1.0) {\n          if((float)docFreq/numDocs > maxDocs) {\n            continue;\n          }\n        } else if(docFreq > maxDocs) {\n          continue;\n        }\n\n        if(term.length < minTermLength) {\n          continue;\n        }\n\n        int tf = 0;\n        postingsEnum = termsEnum.postings(postingsEnum);\n\n        POSTINGS:\n        while (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n          int docId = postingsEnum.docID();\n\n          if(docId > highestCollected) {\n            break POSTINGS;\n          }\n\n          if (docs.get(docId)) {\n            ++tf;\n          }\n        }\n\n        if(tf == 0) {\n          continue;\n        }\n\n        float score = (float)Math.log(tf) * (float) (Math.log(((float)(numDocs + 1)) / (docFreq + 1)) + 1.0);\n\n        String t = term.utf8ToString();\n        allFreq.add(t, docFreq);\n        allQueryFreq.add(t, tf);\n\n        if (topTerms.size() < numTerms) {\n          topTerms.add(new TermWithScore(term.utf8ToString(), score));\n        } else  {\n          if (topTerms.first().score < score) {\n            topTerms.pollFirst();\n            topTerms.add(new TermWithScore(term.utf8ToString(), score));\n          }\n        }\n      }\n\n      for (TermWithScore topTerm : topTerms) {\n        outTerms.add(topTerm.term);\n        scores.add(topTerm.score);\n        outFreq.add(allFreq.get(topTerm.term));\n        outQueryFreq.add(allQueryFreq.get(topTerm.term));\n      }\n\n      if (this.delegate instanceof DelegatingCollector) {\n        ((DelegatingCollector) this.delegate).finish();\n      }\n    }\n\n","bugFix":["f67c3a1123a063e580a2e6ec51b9eb7c273666ce"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9","date":1498028748,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/SignificantTermsQParserPlugin.SignifcantTermsCollector#finish().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SignificantTermsQParserPlugin.SignifcantTermsCollector#finish().mjava","sourceNew":"    @Override\n    public void finish() throws IOException {\n      List<String> outTerms = new ArrayList();\n      List<Integer> outFreq = new ArrayList();\n      List<Integer> outQueryFreq = new ArrayList();\n      List<Double> scores = new ArrayList();\n\n      NamedList<Integer> allFreq = new NamedList();\n      NamedList<Integer> allQueryFreq = new NamedList();\n\n      rb.rsp.add(\"numDocs\", numDocs);\n      rb.rsp.add(\"resultCount\", count);\n      rb.rsp.add(\"sterms\", outTerms);\n      rb.rsp.add(\"scores\", scores);\n      rb.rsp.add(\"docFreq\", outFreq);\n      rb.rsp.add(\"queryDocFreq\", outQueryFreq);\n\n      //TODO: Use a priority queue\n      TreeSet<TermWithScore> topTerms = new TreeSet<>();\n\n      Terms terms = ((SolrIndexSearcher)searcher).getSlowAtomicReader().terms(field);\n      TermsEnum termsEnum = terms == null ? TermsEnum.EMPTY : terms.iterator();\n      BytesRef term;\n      PostingsEnum postingsEnum = null;\n\n      while ((term = termsEnum.next()) != null) {\n        int docFreq = termsEnum.docFreq();\n        \n        if(minDocs < 1.0) {\n          if((float)docFreq/numDocs < minDocs) {\n            continue;\n          }\n        } else if(docFreq < minDocs) {\n          continue;\n        }\n\n        if(maxDocs < 1.0) {\n          if((float)docFreq/numDocs > maxDocs) {\n            continue;\n          }\n        } else if(docFreq > maxDocs) {\n          continue;\n        }\n\n        if(term.length < minTermLength) {\n          continue;\n        }\n\n        int tf = 0;\n        postingsEnum = termsEnum.postings(postingsEnum);\n\n        POSTINGS:\n        while (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n          int docId = postingsEnum.docID();\n\n          if(docId > highestCollected) {\n            break POSTINGS;\n          }\n\n          if (docs.get(docId)) {\n            ++tf;\n          }\n        }\n\n        if(tf == 0) {\n          continue;\n        }\n\n        float score = (float)Math.log(tf) * (float) (Math.log(((float)(numDocs + 1)) / (docFreq + 1)) + 1.0);\n\n        String t = term.utf8ToString();\n        allFreq.add(t, docFreq);\n        allQueryFreq.add(t, tf);\n\n        if (topTerms.size() < numTerms) {\n          topTerms.add(new TermWithScore(term.utf8ToString(), score));\n        } else  {\n          if (topTerms.first().score < score) {\n            topTerms.pollFirst();\n            topTerms.add(new TermWithScore(term.utf8ToString(), score));\n          }\n        }\n      }\n\n      for (TermWithScore topTerm : topTerms) {\n        outTerms.add(topTerm.term);\n        scores.add(topTerm.score);\n        outFreq.add(allFreq.get(topTerm.term));\n        outQueryFreq.add(allQueryFreq.get(topTerm.term));\n      }\n\n      if (this.delegate instanceof DelegatingCollector) {\n        ((DelegatingCollector) this.delegate).finish();\n      }\n    }\n\n","sourceOld":"    @Override\n    public void finish() throws IOException {\n      List<String> outTerms = new ArrayList();\n      List<Integer> outFreq = new ArrayList();\n      List<Integer> outQueryFreq = new ArrayList();\n      List<Double> scores = new ArrayList();\n\n      NamedList<Integer> allFreq = new NamedList();\n      NamedList<Integer> allQueryFreq = new NamedList();\n\n      rb.rsp.add(\"numDocs\", numDocs);\n      rb.rsp.add(\"resultCount\", count);\n      rb.rsp.add(\"sterms\", outTerms);\n      rb.rsp.add(\"scores\", scores);\n      rb.rsp.add(\"docFreq\", outFreq);\n      rb.rsp.add(\"queryDocFreq\", outQueryFreq);\n\n      //TODO: Use a priority queue\n      TreeSet<TermWithScore> topTerms = new TreeSet<>();\n\n      Terms terms = MultiFields.getFields(searcher.getIndexReader()).terms(field);\n      TermsEnum termsEnum = terms.iterator();\n      BytesRef term;\n      PostingsEnum postingsEnum = null;\n\n      while ((term = termsEnum.next()) != null) {\n        int docFreq = termsEnum.docFreq();\n        \n        if(minDocs < 1.0) {\n          if((float)docFreq/numDocs < minDocs) {\n            continue;\n          }\n        } else if(docFreq < minDocs) {\n          continue;\n        }\n\n        if(maxDocs < 1.0) {\n          if((float)docFreq/numDocs > maxDocs) {\n            continue;\n          }\n        } else if(docFreq > maxDocs) {\n          continue;\n        }\n\n        if(term.length < minTermLength) {\n          continue;\n        }\n\n        int tf = 0;\n        postingsEnum = termsEnum.postings(postingsEnum);\n\n        POSTINGS:\n        while (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n          int docId = postingsEnum.docID();\n\n          if(docId > highestCollected) {\n            break POSTINGS;\n          }\n\n          if (docs.get(docId)) {\n            ++tf;\n          }\n        }\n\n        if(tf == 0) {\n          continue;\n        }\n\n        float score = (float)Math.log(tf) * (float) (Math.log(((float)(numDocs + 1)) / (docFreq + 1)) + 1.0);\n\n        String t = term.utf8ToString();\n        allFreq.add(t, docFreq);\n        allQueryFreq.add(t, tf);\n\n        if (topTerms.size() < numTerms) {\n          topTerms.add(new TermWithScore(term.utf8ToString(), score));\n        } else  {\n          if (topTerms.first().score < score) {\n            topTerms.pollFirst();\n            topTerms.add(new TermWithScore(term.utf8ToString(), score));\n          }\n        }\n      }\n\n      for (TermWithScore topTerm : topTerms) {\n        outTerms.add(topTerm.term);\n        scores.add(topTerm.score);\n        outFreq.add(allFreq.get(topTerm.term));\n        outQueryFreq.add(allQueryFreq.get(topTerm.term));\n      }\n\n      if (this.delegate instanceof DelegatingCollector) {\n        ((DelegatingCollector) this.delegate).finish();\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/SignificantTermsQParserPlugin.SignifcantTermsCollector#finish().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SignificantTermsQParserPlugin.SignifcantTermsCollector#finish().mjava","sourceNew":"    @Override\n    public void finish() throws IOException {\n      List<String> outTerms = new ArrayList();\n      List<Integer> outFreq = new ArrayList();\n      List<Integer> outQueryFreq = new ArrayList();\n      List<Double> scores = new ArrayList();\n\n      NamedList<Integer> allFreq = new NamedList();\n      NamedList<Integer> allQueryFreq = new NamedList();\n\n      rb.rsp.add(\"numDocs\", numDocs);\n      rb.rsp.add(\"resultCount\", count);\n      rb.rsp.add(\"sterms\", outTerms);\n      rb.rsp.add(\"scores\", scores);\n      rb.rsp.add(\"docFreq\", outFreq);\n      rb.rsp.add(\"queryDocFreq\", outQueryFreq);\n\n      //TODO: Use a priority queue\n      TreeSet<TermWithScore> topTerms = new TreeSet<>();\n\n      Terms terms = ((SolrIndexSearcher)searcher).getSlowAtomicReader().terms(field);\n      TermsEnum termsEnum = terms == null ? TermsEnum.EMPTY : terms.iterator();\n      BytesRef term;\n      PostingsEnum postingsEnum = null;\n\n      while ((term = termsEnum.next()) != null) {\n        int docFreq = termsEnum.docFreq();\n        \n        if(minDocs < 1.0) {\n          if((float)docFreq/numDocs < minDocs) {\n            continue;\n          }\n        } else if(docFreq < minDocs) {\n          continue;\n        }\n\n        if(maxDocs < 1.0) {\n          if((float)docFreq/numDocs > maxDocs) {\n            continue;\n          }\n        } else if(docFreq > maxDocs) {\n          continue;\n        }\n\n        if(term.length < minTermLength) {\n          continue;\n        }\n\n        int tf = 0;\n        postingsEnum = termsEnum.postings(postingsEnum);\n\n        POSTINGS:\n        while (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n          int docId = postingsEnum.docID();\n\n          if(docId > highestCollected) {\n            break POSTINGS;\n          }\n\n          if (docs.get(docId)) {\n            ++tf;\n          }\n        }\n\n        if(tf == 0) {\n          continue;\n        }\n\n        float score = (float)Math.log(tf) * (float) (Math.log(((float)(numDocs + 1)) / (docFreq + 1)) + 1.0);\n\n        String t = term.utf8ToString();\n        allFreq.add(t, docFreq);\n        allQueryFreq.add(t, tf);\n\n        if (topTerms.size() < numTerms) {\n          topTerms.add(new TermWithScore(term.utf8ToString(), score));\n        } else  {\n          if (topTerms.first().score < score) {\n            topTerms.pollFirst();\n            topTerms.add(new TermWithScore(term.utf8ToString(), score));\n          }\n        }\n      }\n\n      for (TermWithScore topTerm : topTerms) {\n        outTerms.add(topTerm.term);\n        scores.add(topTerm.score);\n        outFreq.add(allFreq.get(topTerm.term));\n        outQueryFreq.add(allQueryFreq.get(topTerm.term));\n      }\n\n      if (this.delegate instanceof DelegatingCollector) {\n        ((DelegatingCollector) this.delegate).finish();\n      }\n    }\n\n","sourceOld":"    @Override\n    public void finish() throws IOException {\n      List<String> outTerms = new ArrayList();\n      List<Integer> outFreq = new ArrayList();\n      List<Integer> outQueryFreq = new ArrayList();\n      List<Double> scores = new ArrayList();\n\n      NamedList<Integer> allFreq = new NamedList();\n      NamedList<Integer> allQueryFreq = new NamedList();\n\n      rb.rsp.add(\"numDocs\", numDocs);\n      rb.rsp.add(\"resultCount\", count);\n      rb.rsp.add(\"sterms\", outTerms);\n      rb.rsp.add(\"scores\", scores);\n      rb.rsp.add(\"docFreq\", outFreq);\n      rb.rsp.add(\"queryDocFreq\", outQueryFreq);\n\n      //TODO: Use a priority queue\n      TreeSet<TermWithScore> topTerms = new TreeSet<>();\n\n      Terms terms = MultiFields.getFields(searcher.getIndexReader()).terms(field);\n      TermsEnum termsEnum = terms.iterator();\n      BytesRef term;\n      PostingsEnum postingsEnum = null;\n\n      while ((term = termsEnum.next()) != null) {\n        int docFreq = termsEnum.docFreq();\n        \n        if(minDocs < 1.0) {\n          if((float)docFreq/numDocs < minDocs) {\n            continue;\n          }\n        } else if(docFreq < minDocs) {\n          continue;\n        }\n\n        if(maxDocs < 1.0) {\n          if((float)docFreq/numDocs > maxDocs) {\n            continue;\n          }\n        } else if(docFreq > maxDocs) {\n          continue;\n        }\n\n        if(term.length < minTermLength) {\n          continue;\n        }\n\n        int tf = 0;\n        postingsEnum = termsEnum.postings(postingsEnum);\n\n        POSTINGS:\n        while (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n          int docId = postingsEnum.docID();\n\n          if(docId > highestCollected) {\n            break POSTINGS;\n          }\n\n          if (docs.get(docId)) {\n            ++tf;\n          }\n        }\n\n        if(tf == 0) {\n          continue;\n        }\n\n        float score = (float)Math.log(tf) * (float) (Math.log(((float)(numDocs + 1)) / (docFreq + 1)) + 1.0);\n\n        String t = term.utf8ToString();\n        allFreq.add(t, docFreq);\n        allQueryFreq.add(t, tf);\n\n        if (topTerms.size() < numTerms) {\n          topTerms.add(new TermWithScore(term.utf8ToString(), score));\n        } else  {\n          if (topTerms.first().score < score) {\n            topTerms.pollFirst();\n            topTerms.add(new TermWithScore(term.utf8ToString(), score));\n          }\n        }\n      }\n\n      for (TermWithScore topTerm : topTerms) {\n        outTerms.add(topTerm.term);\n        scores.add(topTerm.score);\n        outFreq.add(allFreq.get(topTerm.term));\n        outQueryFreq.add(allQueryFreq.get(topTerm.term));\n      }\n\n      if (this.delegate instanceof DelegatingCollector) {\n        ((DelegatingCollector) this.delegate).finish();\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2fc04ccb942f468185647160e1de663db1530dd0","date":1532880127,"type":3,"author":"Alexandre Rafalovitch","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SignificantTermsQParserPlugin.SignifcantTermsCollector#finish().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SignificantTermsQParserPlugin.SignifcantTermsCollector#finish().mjava","sourceNew":"    @Override\n    public void finish() throws IOException {\n      List<String> outTerms = new ArrayList();\n      List<Integer> outFreq = new ArrayList();\n      List<Integer> outQueryFreq = new ArrayList();\n      List<Double> scores = new ArrayList();\n\n      NamedList<Integer> allFreq = new NamedList();\n      NamedList<Integer> allQueryFreq = new NamedList();\n\n      LinkedHashMap<String, Object> response = new LinkedHashMap<>();\n\n      rb.rsp.add(\"significantTerms\", response);\n\n      response.put(\"numDocs\", numDocs);\n      response.put(\"sterms\", outTerms);\n      response.put(\"scores\", scores);\n      response.put(\"docFreq\", outFreq);\n      response.put(\"queryDocFreq\", outQueryFreq);\n\n      //TODO: Use a priority queue\n      TreeSet<TermWithScore> topTerms = new TreeSet<>();\n\n      Terms terms = ((SolrIndexSearcher)searcher).getSlowAtomicReader().terms(field);\n      TermsEnum termsEnum = terms == null ? TermsEnum.EMPTY : terms.iterator();\n      BytesRef term;\n      PostingsEnum postingsEnum = null;\n\n      while ((term = termsEnum.next()) != null) {\n        int docFreq = termsEnum.docFreq();\n        \n        if(minDocs < 1.0) {\n          if((float)docFreq/numDocs < minDocs) {\n            continue;\n          }\n        } else if(docFreq < minDocs) {\n          continue;\n        }\n\n        if(maxDocs < 1.0) {\n          if((float)docFreq/numDocs > maxDocs) {\n            continue;\n          }\n        } else if(docFreq > maxDocs) {\n          continue;\n        }\n\n        if(term.length < minTermLength) {\n          continue;\n        }\n\n        int tf = 0;\n        postingsEnum = termsEnum.postings(postingsEnum);\n\n        POSTINGS:\n        while (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n          int docId = postingsEnum.docID();\n\n          if(docId > highestCollected) {\n            break POSTINGS;\n          }\n\n          if (docs.get(docId)) {\n            ++tf;\n          }\n        }\n\n        if(tf == 0) {\n          continue;\n        }\n\n        float score = (float)Math.log(tf) * (float) (Math.log(((float)(numDocs + 1)) / (docFreq + 1)) + 1.0);\n\n        String t = term.utf8ToString();\n        allFreq.add(t, docFreq);\n        allQueryFreq.add(t, tf);\n\n        if (topTerms.size() < numTerms) {\n          topTerms.add(new TermWithScore(term.utf8ToString(), score));\n        } else  {\n          if (topTerms.first().score < score) {\n            topTerms.pollFirst();\n            topTerms.add(new TermWithScore(term.utf8ToString(), score));\n          }\n        }\n      }\n\n      for (TermWithScore topTerm : topTerms) {\n        outTerms.add(topTerm.term);\n        scores.add(topTerm.score);\n        outFreq.add(allFreq.get(topTerm.term));\n        outQueryFreq.add(allQueryFreq.get(topTerm.term));\n      }\n\n      if (this.delegate instanceof DelegatingCollector) {\n        ((DelegatingCollector) this.delegate).finish();\n      }\n    }\n\n","sourceOld":"    @Override\n    public void finish() throws IOException {\n      List<String> outTerms = new ArrayList();\n      List<Integer> outFreq = new ArrayList();\n      List<Integer> outQueryFreq = new ArrayList();\n      List<Double> scores = new ArrayList();\n\n      NamedList<Integer> allFreq = new NamedList();\n      NamedList<Integer> allQueryFreq = new NamedList();\n\n      rb.rsp.add(\"numDocs\", numDocs);\n      rb.rsp.add(\"resultCount\", count);\n      rb.rsp.add(\"sterms\", outTerms);\n      rb.rsp.add(\"scores\", scores);\n      rb.rsp.add(\"docFreq\", outFreq);\n      rb.rsp.add(\"queryDocFreq\", outQueryFreq);\n\n      //TODO: Use a priority queue\n      TreeSet<TermWithScore> topTerms = new TreeSet<>();\n\n      Terms terms = ((SolrIndexSearcher)searcher).getSlowAtomicReader().terms(field);\n      TermsEnum termsEnum = terms == null ? TermsEnum.EMPTY : terms.iterator();\n      BytesRef term;\n      PostingsEnum postingsEnum = null;\n\n      while ((term = termsEnum.next()) != null) {\n        int docFreq = termsEnum.docFreq();\n        \n        if(minDocs < 1.0) {\n          if((float)docFreq/numDocs < minDocs) {\n            continue;\n          }\n        } else if(docFreq < minDocs) {\n          continue;\n        }\n\n        if(maxDocs < 1.0) {\n          if((float)docFreq/numDocs > maxDocs) {\n            continue;\n          }\n        } else if(docFreq > maxDocs) {\n          continue;\n        }\n\n        if(term.length < minTermLength) {\n          continue;\n        }\n\n        int tf = 0;\n        postingsEnum = termsEnum.postings(postingsEnum);\n\n        POSTINGS:\n        while (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n          int docId = postingsEnum.docID();\n\n          if(docId > highestCollected) {\n            break POSTINGS;\n          }\n\n          if (docs.get(docId)) {\n            ++tf;\n          }\n        }\n\n        if(tf == 0) {\n          continue;\n        }\n\n        float score = (float)Math.log(tf) * (float) (Math.log(((float)(numDocs + 1)) / (docFreq + 1)) + 1.0);\n\n        String t = term.utf8ToString();\n        allFreq.add(t, docFreq);\n        allQueryFreq.add(t, tf);\n\n        if (topTerms.size() < numTerms) {\n          topTerms.add(new TermWithScore(term.utf8ToString(), score));\n        } else  {\n          if (topTerms.first().score < score) {\n            topTerms.pollFirst();\n            topTerms.add(new TermWithScore(term.utf8ToString(), score));\n          }\n        }\n      }\n\n      for (TermWithScore topTerm : topTerms) {\n        outTerms.add(topTerm.term);\n        scores.add(topTerm.score);\n        outFreq.add(allFreq.get(topTerm.term));\n        outQueryFreq.add(allQueryFreq.get(topTerm.term));\n      }\n\n      if (this.delegate instanceof DelegatingCollector) {\n        ((DelegatingCollector) this.delegate).finish();\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"50dfd19525c8d73e856dca6edb64b7aea074037f","date":1591579225,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SignificantTermsQParserPlugin.SignifcantTermsCollector#finish().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SignificantTermsQParserPlugin.SignifcantTermsCollector#finish().mjava","sourceNew":"    @Override\n    public void finish() throws IOException {\n      @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n      List<String> outTerms = new ArrayList();\n      @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n      List<Integer> outFreq = new ArrayList();\n      @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n      List<Integer> outQueryFreq = new ArrayList();\n      @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n      List<Double> scores = new ArrayList();\n\n      @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n      NamedList<Integer> allFreq = new NamedList();\n      @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n      NamedList<Integer> allQueryFreq = new NamedList();\n\n      LinkedHashMap<String, Object> response = new LinkedHashMap<>();\n\n      rb.rsp.add(\"significantTerms\", response);\n\n      response.put(\"numDocs\", numDocs);\n      response.put(\"sterms\", outTerms);\n      response.put(\"scores\", scores);\n      response.put(\"docFreq\", outFreq);\n      response.put(\"queryDocFreq\", outQueryFreq);\n\n      //TODO: Use a priority queue\n      TreeSet<TermWithScore> topTerms = new TreeSet<>();\n\n      Terms terms = ((SolrIndexSearcher)searcher).getSlowAtomicReader().terms(field);\n      TermsEnum termsEnum = terms == null ? TermsEnum.EMPTY : terms.iterator();\n      BytesRef term;\n      PostingsEnum postingsEnum = null;\n\n      while ((term = termsEnum.next()) != null) {\n        int docFreq = termsEnum.docFreq();\n        \n        if(minDocs < 1.0) {\n          if((float)docFreq/numDocs < minDocs) {\n            continue;\n          }\n        } else if(docFreq < minDocs) {\n          continue;\n        }\n\n        if(maxDocs < 1.0) {\n          if((float)docFreq/numDocs > maxDocs) {\n            continue;\n          }\n        } else if(docFreq > maxDocs) {\n          continue;\n        }\n\n        if(term.length < minTermLength) {\n          continue;\n        }\n\n        int tf = 0;\n        postingsEnum = termsEnum.postings(postingsEnum);\n\n        POSTINGS:\n        while (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n          int docId = postingsEnum.docID();\n\n          if(docId > highestCollected) {\n            break POSTINGS;\n          }\n\n          if (docs.get(docId)) {\n            ++tf;\n          }\n        }\n\n        if(tf == 0) {\n          continue;\n        }\n\n        float score = (float)Math.log(tf) * (float) (Math.log(((float)(numDocs + 1)) / (docFreq + 1)) + 1.0);\n\n        String t = term.utf8ToString();\n        allFreq.add(t, docFreq);\n        allQueryFreq.add(t, tf);\n\n        if (topTerms.size() < numTerms) {\n          topTerms.add(new TermWithScore(term.utf8ToString(), score));\n        } else  {\n          if (topTerms.first().score < score) {\n            topTerms.pollFirst();\n            topTerms.add(new TermWithScore(term.utf8ToString(), score));\n          }\n        }\n      }\n\n      for (TermWithScore topTerm : topTerms) {\n        outTerms.add(topTerm.term);\n        scores.add(topTerm.score);\n        outFreq.add(allFreq.get(topTerm.term));\n        outQueryFreq.add(allQueryFreq.get(topTerm.term));\n      }\n\n      if (this.delegate instanceof DelegatingCollector) {\n        ((DelegatingCollector) this.delegate).finish();\n      }\n    }\n\n","sourceOld":"    @Override\n    public void finish() throws IOException {\n      List<String> outTerms = new ArrayList();\n      List<Integer> outFreq = new ArrayList();\n      List<Integer> outQueryFreq = new ArrayList();\n      List<Double> scores = new ArrayList();\n\n      NamedList<Integer> allFreq = new NamedList();\n      NamedList<Integer> allQueryFreq = new NamedList();\n\n      LinkedHashMap<String, Object> response = new LinkedHashMap<>();\n\n      rb.rsp.add(\"significantTerms\", response);\n\n      response.put(\"numDocs\", numDocs);\n      response.put(\"sterms\", outTerms);\n      response.put(\"scores\", scores);\n      response.put(\"docFreq\", outFreq);\n      response.put(\"queryDocFreq\", outQueryFreq);\n\n      //TODO: Use a priority queue\n      TreeSet<TermWithScore> topTerms = new TreeSet<>();\n\n      Terms terms = ((SolrIndexSearcher)searcher).getSlowAtomicReader().terms(field);\n      TermsEnum termsEnum = terms == null ? TermsEnum.EMPTY : terms.iterator();\n      BytesRef term;\n      PostingsEnum postingsEnum = null;\n\n      while ((term = termsEnum.next()) != null) {\n        int docFreq = termsEnum.docFreq();\n        \n        if(minDocs < 1.0) {\n          if((float)docFreq/numDocs < minDocs) {\n            continue;\n          }\n        } else if(docFreq < minDocs) {\n          continue;\n        }\n\n        if(maxDocs < 1.0) {\n          if((float)docFreq/numDocs > maxDocs) {\n            continue;\n          }\n        } else if(docFreq > maxDocs) {\n          continue;\n        }\n\n        if(term.length < minTermLength) {\n          continue;\n        }\n\n        int tf = 0;\n        postingsEnum = termsEnum.postings(postingsEnum);\n\n        POSTINGS:\n        while (postingsEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n          int docId = postingsEnum.docID();\n\n          if(docId > highestCollected) {\n            break POSTINGS;\n          }\n\n          if (docs.get(docId)) {\n            ++tf;\n          }\n        }\n\n        if(tf == 0) {\n          continue;\n        }\n\n        float score = (float)Math.log(tf) * (float) (Math.log(((float)(numDocs + 1)) / (docFreq + 1)) + 1.0);\n\n        String t = term.utf8ToString();\n        allFreq.add(t, docFreq);\n        allQueryFreq.add(t, tf);\n\n        if (topTerms.size() < numTerms) {\n          topTerms.add(new TermWithScore(term.utf8ToString(), score));\n        } else  {\n          if (topTerms.first().score < score) {\n            topTerms.pollFirst();\n            topTerms.add(new TermWithScore(term.utf8ToString(), score));\n          }\n        }\n      }\n\n      for (TermWithScore topTerm : topTerms) {\n        outTerms.add(topTerm.term);\n        scores.add(topTerm.score);\n        outFreq.add(allFreq.get(topTerm.term));\n        outQueryFreq.add(allQueryFreq.get(topTerm.term));\n      }\n\n      if (this.delegate instanceof DelegatingCollector) {\n        ((DelegatingCollector) this.delegate).finish();\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3185d4c8bb14af74e2ef0bde19f22e33b954b568":["f67c3a1123a063e580a2e6ec51b9eb7c273666ce"],"50dfd19525c8d73e856dca6edb64b7aea074037f":["2fc04ccb942f468185647160e1de663db1530dd0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"2fc04ccb942f468185647160e1de663db1530dd0":["28288370235ed02234a64753cdbf0c6ec096304a"],"f67c3a1123a063e580a2e6ec51b9eb7c273666ce":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"28288370235ed02234a64753cdbf0c6ec096304a":["f67c3a1123a063e580a2e6ec51b9eb7c273666ce","3185d4c8bb14af74e2ef0bde19f22e33b954b568"],"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9":["f67c3a1123a063e580a2e6ec51b9eb7c273666ce","3185d4c8bb14af74e2ef0bde19f22e33b954b568"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["50dfd19525c8d73e856dca6edb64b7aea074037f"]},"commit2Childs":{"3185d4c8bb14af74e2ef0bde19f22e33b954b568":["28288370235ed02234a64753cdbf0c6ec096304a","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9"],"50dfd19525c8d73e856dca6edb64b7aea074037f":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["f67c3a1123a063e580a2e6ec51b9eb7c273666ce"],"2fc04ccb942f468185647160e1de663db1530dd0":["50dfd19525c8d73e856dca6edb64b7aea074037f"],"f67c3a1123a063e580a2e6ec51b9eb7c273666ce":["3185d4c8bb14af74e2ef0bde19f22e33b954b568","28288370235ed02234a64753cdbf0c6ec096304a","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9"],"28288370235ed02234a64753cdbf0c6ec096304a":["2fc04ccb942f468185647160e1de663db1530dd0"],"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}