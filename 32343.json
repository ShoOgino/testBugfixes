{"path":"lucene/highlighter/src/test/org/apache/lucene/search/matchhighlight/TestMatchRegionRetriever#setup().mjava","commits":[{"id":"2fb36690ce41edd0bebf4e4babc0fa8c9b0f2e5c","date":1597407672,"type":0,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/matchhighlight/TestMatchRegionRetriever#setup().mjava","pathOld":"/dev/null","sourceNew":"  @Before\n  public void setup() {\n    TYPE_STORED_WITH_OFFSETS = new FieldType(TextField.TYPE_STORED);\n    TYPE_STORED_WITH_OFFSETS.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    TYPE_STORED_WITH_OFFSETS.freeze();\n\n    TYPE_STORED_NO_POSITIONS = new FieldType(TextField.TYPE_STORED);\n    TYPE_STORED_NO_POSITIONS.setIndexOptions(IndexOptions.DOCS_AND_FREQS);\n    TYPE_STORED_NO_POSITIONS.freeze();\n\n    Analyzer whitespaceAnalyzer =\n        new Analyzer() {\n          final int offsetGap = RandomizedTest.randomIntBetween(0, 2);\n          final int positionGap = RandomizedTest.randomFrom(new int[]{0, 1, 100});\n\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName) {\n            WhitespaceTokenizer tokenizer =\n                new WhitespaceTokenizer(CharTokenizer.DEFAULT_MAX_WORD_LEN);\n            return new TokenStreamComponents(tokenizer);\n          }\n\n          @Override\n          public int getOffsetGap(String fieldName) {\n            return offsetGap;\n          }\n\n          @Override\n          public int getPositionIncrementGap(String fieldName) {\n            return positionGap;\n          }\n        };\n\n    Map<String, Analyzer> fieldAnalyzers = new HashMap<>();\n    fieldAnalyzers.put(FLD_TEXT_POS, whitespaceAnalyzer);\n    fieldAnalyzers.put(FLD_TEXT_POS_OFFS, whitespaceAnalyzer);\n    fieldAnalyzers.put(FLD_TEXT_POS_OFFS1, whitespaceAnalyzer);\n    fieldAnalyzers.put(FLD_TEXT_POS_OFFS2, whitespaceAnalyzer);\n    fieldAnalyzers.put(FLD_TEXT_NOPOS, whitespaceAnalyzer);\n\n    try {\n      SynonymMap.Builder b = new SynonymMap.Builder();\n      b.add(new CharsRef(\"foo\\u0000bar\"), new CharsRef(\"syn1\"), true);\n      b.add(new CharsRef(\"baz\"), new CharsRef(\"syn2\\u0000syn3\"), true);\n      SynonymMap synonymMap = b.build();\n      Analyzer synonymsAnalyzer =\n          new Analyzer() {\n            @Override\n            protected TokenStreamComponents createComponents(String fieldName) {\n              Tokenizer tokenizer = new WhitespaceTokenizer();\n              TokenStream tokenStream = new SynonymGraphFilter(tokenizer, synonymMap, true);\n              return new TokenStreamComponents(tokenizer, tokenStream);\n            }\n          };\n      fieldAnalyzers.put(FLD_TEXT_SYNONYMS_POS_OFFS, synonymsAnalyzer);\n      fieldAnalyzers.put(FLD_TEXT_SYNONYMS_POS, synonymsAnalyzer);\n    } catch (IOException e) {\n      throw new UncheckedIOException(e);\n    }\n\n    analyzer = new PerFieldAnalyzerWrapper(new MissingAnalyzer(), fieldAnalyzers);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"930e5c340e08514a7f57a54cf65e2f8f1f90c8f0","date":1599736633,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/matchhighlight/TestMatchRegionRetriever#setup().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/matchhighlight/TestMatchRegionRetriever#setup().mjava","sourceNew":"  @Before\n  public void setup() throws IOException {\n    TYPE_STORED_WITH_OFFSETS = new FieldType(TextField.TYPE_STORED);\n    TYPE_STORED_WITH_OFFSETS.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    TYPE_STORED_WITH_OFFSETS.freeze();\n\n    TYPE_STORED_NO_POSITIONS = new FieldType(TextField.TYPE_STORED);\n    TYPE_STORED_NO_POSITIONS.setIndexOptions(IndexOptions.DOCS_AND_FREQS);\n    TYPE_STORED_NO_POSITIONS.freeze();\n\n    final int offsetGap = RandomizedTest.randomIntBetween(0, 2);\n    final int positionGap = RandomizedTest.randomFrom(new int[]{0, 1, 100});\n    Analyzer whitespaceAnalyzer =\n        new AnalyzerWithGaps(offsetGap, positionGap,\n            new WhitespaceAnalyzer(WhitespaceTokenizer.DEFAULT_MAX_WORD_LEN));\n\n    SynonymMap synonymMap = TestMatchHighlighter.buildSynonymMap(new String[][] {\n        {\"foo\\u0000bar\", \"syn1\"},\n        {\"baz\", \"syn2\\u0000syn3\"},\n    });\n\n    Analyzer synonymsAnalyzer =\n        new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName) {\n            Tokenizer tokenizer = new WhitespaceTokenizer();\n            TokenStream tokenStream = new SynonymGraphFilter(tokenizer, synonymMap, true);\n            return new TokenStreamComponents(tokenizer, tokenStream);\n          }\n        };\n\n    Map<String, Analyzer> fieldAnalyzers = new HashMap<>();\n    fieldAnalyzers.put(FLD_TEXT_POS, whitespaceAnalyzer);\n    fieldAnalyzers.put(FLD_TEXT_POS_OFFS, whitespaceAnalyzer);\n    fieldAnalyzers.put(FLD_TEXT_POS_OFFS1, whitespaceAnalyzer);\n    fieldAnalyzers.put(FLD_TEXT_POS_OFFS2, whitespaceAnalyzer);\n    fieldAnalyzers.put(FLD_TEXT_NOPOS, whitespaceAnalyzer);\n    fieldAnalyzers.put(FLD_TEXT_SYNONYMS_POS_OFFS, synonymsAnalyzer);\n    fieldAnalyzers.put(FLD_TEXT_SYNONYMS_POS, synonymsAnalyzer);\n\n    analyzer = new PerFieldAnalyzerWrapper(new MissingAnalyzer(), fieldAnalyzers);\n  }\n\n","sourceOld":"  @Before\n  public void setup() {\n    TYPE_STORED_WITH_OFFSETS = new FieldType(TextField.TYPE_STORED);\n    TYPE_STORED_WITH_OFFSETS.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    TYPE_STORED_WITH_OFFSETS.freeze();\n\n    TYPE_STORED_NO_POSITIONS = new FieldType(TextField.TYPE_STORED);\n    TYPE_STORED_NO_POSITIONS.setIndexOptions(IndexOptions.DOCS_AND_FREQS);\n    TYPE_STORED_NO_POSITIONS.freeze();\n\n    Analyzer whitespaceAnalyzer =\n        new Analyzer() {\n          final int offsetGap = RandomizedTest.randomIntBetween(0, 2);\n          final int positionGap = RandomizedTest.randomFrom(new int[]{0, 1, 100});\n\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName) {\n            WhitespaceTokenizer tokenizer =\n                new WhitespaceTokenizer(CharTokenizer.DEFAULT_MAX_WORD_LEN);\n            return new TokenStreamComponents(tokenizer);\n          }\n\n          @Override\n          public int getOffsetGap(String fieldName) {\n            return offsetGap;\n          }\n\n          @Override\n          public int getPositionIncrementGap(String fieldName) {\n            return positionGap;\n          }\n        };\n\n    Map<String, Analyzer> fieldAnalyzers = new HashMap<>();\n    fieldAnalyzers.put(FLD_TEXT_POS, whitespaceAnalyzer);\n    fieldAnalyzers.put(FLD_TEXT_POS_OFFS, whitespaceAnalyzer);\n    fieldAnalyzers.put(FLD_TEXT_POS_OFFS1, whitespaceAnalyzer);\n    fieldAnalyzers.put(FLD_TEXT_POS_OFFS2, whitespaceAnalyzer);\n    fieldAnalyzers.put(FLD_TEXT_NOPOS, whitespaceAnalyzer);\n\n    try {\n      SynonymMap.Builder b = new SynonymMap.Builder();\n      b.add(new CharsRef(\"foo\\u0000bar\"), new CharsRef(\"syn1\"), true);\n      b.add(new CharsRef(\"baz\"), new CharsRef(\"syn2\\u0000syn3\"), true);\n      SynonymMap synonymMap = b.build();\n      Analyzer synonymsAnalyzer =\n          new Analyzer() {\n            @Override\n            protected TokenStreamComponents createComponents(String fieldName) {\n              Tokenizer tokenizer = new WhitespaceTokenizer();\n              TokenStream tokenStream = new SynonymGraphFilter(tokenizer, synonymMap, true);\n              return new TokenStreamComponents(tokenizer, tokenStream);\n            }\n          };\n      fieldAnalyzers.put(FLD_TEXT_SYNONYMS_POS_OFFS, synonymsAnalyzer);\n      fieldAnalyzers.put(FLD_TEXT_SYNONYMS_POS, synonymsAnalyzer);\n    } catch (IOException e) {\n      throw new UncheckedIOException(e);\n    }\n\n    analyzer = new PerFieldAnalyzerWrapper(new MissingAnalyzer(), fieldAnalyzers);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"2fb36690ce41edd0bebf4e4babc0fa8c9b0f2e5c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"930e5c340e08514a7f57a54cf65e2f8f1f90c8f0":["2fb36690ce41edd0bebf4e4babc0fa8c9b0f2e5c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["930e5c340e08514a7f57a54cf65e2f8f1f90c8f0"]},"commit2Childs":{"2fb36690ce41edd0bebf4e4babc0fa8c9b0f2e5c":["930e5c340e08514a7f57a54cf65e2f8f1f90c8f0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["2fb36690ce41edd0bebf4e4babc0fa8c9b0f2e5c"],"930e5c340e08514a7f57a54cf65e2f8f1f90c8f0":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}