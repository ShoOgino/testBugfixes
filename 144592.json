{"path":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = FSDirectory.open(new File(fullDir(outputDir)));\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", (float) 1.5);\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected;\n      expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_3\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = FSDirectory.open(new File(fullDir(outputDir)));\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", (float) 1.5);\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected;\n      expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_3\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b48e4082e2f39f1eb6f935ea9a1203c5e8d830a9","date":1270985469,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = FSDirectory.open(new File(fullDir(outputDir)));\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", (float) 1.5);\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = FSDirectory.open(new File(fullDir(outputDir)));\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", (float) 1.5);\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected;\n      expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_3\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d8d3f45cdd3ff689aaf7a3aab99e2df31305ac10","date":1270996866,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = FSDirectory.open(new File(fullDir(outputDir)));\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", (float) 1.5);\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected;\n      expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_3\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = FSDirectory.open(new File(fullDir(outputDir)));\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", (float) 1.5);\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":["69a923a22517eb7ff0bad9c6d1a7d45cc0696bd4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"69a923a22517eb7ff0bad9c6d1a7d45cc0696bd4","date":1271167458,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = FSDirectory.open(new File(fullDir(outputDir)));\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", (float) 1.5);\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = FSDirectory.open(new File(fullDir(outputDir)));\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", (float) 1.5);\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected;\n      expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_3\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","bugFix":["d8d3f45cdd3ff689aaf7a3aab99e2df31305ac10"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d572389229127c297dd1fa5ce4758e1cec41e799","date":1273610938,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = FSDirectory.open(new File(fullDir(outputDir)));\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", (float) 1.5);\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = FSDirectory.open(new File(fullDir(outputDir)));\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", (float) 1.5);\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b21422ff1d1d56499dec481f193b402e5e8def5b","date":1281472367,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = FSDirectory.open(new File(fullDir(outputDir)));\n\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(newRandom(), TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(-1).setRAMBufferSizeMB(16.0));\n      ((LogMergePolicy) writer.getMergePolicy()).setUseCompoundFile(true);\n      ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", (float) 1.5);\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = FSDirectory.open(new File(fullDir(outputDir)));\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", (float) 1.5);\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f653cfcf159baeaafe5d01682a911e95bba4012","date":1284122058,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = FSDirectory.open(new File(fullDir(outputDir)));\n\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(-1).setRAMBufferSizeMB(16.0));\n      ((LogMergePolicy) writer.getMergePolicy()).setUseCompoundFile(true);\n      ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", (float) 1.5);\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = FSDirectory.open(new File(fullDir(outputDir)));\n\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(newRandom(), TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(-1).setRAMBufferSizeMB(16.0));\n      ((LogMergePolicy) writer.getMergePolicy()).setUseCompoundFile(true);\n      ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", (float) 1.5);\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4e8cc373c801e54cec75daf9f52792cb4b17f536","date":1291116159,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = FSDirectory.open(new File(fullDir(outputDir)));\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(newLogMergePolicy(true, 10))\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", (float) 1.5);\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = FSDirectory.open(new File(fullDir(outputDir)));\n\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(-1).setRAMBufferSizeMB(16.0));\n      ((LogMergePolicy) writer.getMergePolicy()).setUseCompoundFile(true);\n      ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", (float) 1.5);\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"38a62612cfa4e104080d89d7751a8f1a258ac335","date":1291442315,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = FSDirectory.open(new File(fullDir(outputDir)));\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", (float) 1.5);\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = FSDirectory.open(new File(fullDir(outputDir)));\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(newLogMergePolicy(true, 10))\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", (float) 1.5);\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3bb13258feba31ab676502787ab2e1779f129b7a","date":1291596436,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = FSDirectory.open(new File(fullDir(outputDir)));\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(newLogMergePolicy(true, 10))\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", (float) 1.5);\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = FSDirectory.open(new File(fullDir(outputDir)));\n\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(-1).setRAMBufferSizeMB(16.0));\n      ((LogMergePolicy) writer.getMergePolicy()).setUseCompoundFile(true);\n      ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", (float) 1.5);\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4a69e5860d014751cc9329dfeb441a6d8fd1ed8e","date":1291833341,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = FSDirectory.open(new File(fullDir(outputDir)));\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", (float) 1.5);\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = FSDirectory.open(new File(fullDir(outputDir)));\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(newLogMergePolicy(true, 10))\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", (float) 1.5);\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a13a126d15299d5c1e117ea99ddae6fb0fa3f209","date":1291909583,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(new File(fullDir(outputDir)));\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", (float) 1.5);\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = FSDirectory.open(new File(fullDir(outputDir)));\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", (float) 1.5);\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab5cb6a74aefb78aa0569857970b9151dfe2e787","date":1292842407,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(new File(fullDir(outputDir)));\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", (float) 1.5);\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = FSDirectory.open(new File(fullDir(outputDir)));\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", (float) 1.5);\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(new File(fullDir(outputDir)));\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", (float) 1.5);\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = FSDirectory.open(new File(fullDir(outputDir)));\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", (float) 1.5);\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7a54e23e03b47f3d568ab3020bdd386e4b2f0a05","date":1294877328,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(new File(fullDir(outputDir)));\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", Similarity.getDefault().encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(new File(fullDir(outputDir)));\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", (float) 1.5);\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(new File(fullDir(outputDir)));\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", Similarity.getDefault().encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(new File(fullDir(outputDir)));\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", (float) 1.5);\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd9325c7ff9928fabe81c28553b41fc7aa57dfab","date":1295896411,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(new File(fullDir(outputDir)));\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      SimilarityProvider sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.get(\"content\").encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(new File(fullDir(outputDir)));\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", Similarity.getDefault().encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bb9b72f7c3d7827c64dd4ec580ded81778da361d","date":1295897920,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(new File(fullDir(outputDir)));\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      SimilarityProvider sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.get(\"content\").encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(new File(fullDir(outputDir)));\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", Similarity.getDefault().encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3cdad2c6b6234338031bcc1f24c001a5ad66f714","date":1296866109,"type":3,"author":"Doron Cohen","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      SimilarityProvider sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.get(\"content\").encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(new File(fullDir(outputDir)));\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      SimilarityProvider sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.get(\"content\").encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      SimilarityProvider sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.get(\"content\").encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(new File(fullDir(outputDir)));\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      reader.setNorm(21, \"content\", (float) 1.5);\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b0c7a8f7304b75b1528814c5820fa23a96816c27","date":1298314239,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      SimilarityProvider sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.get(\"content\").encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      SimilarityProvider sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.get(\"content\").encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      SimilarityProvider sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.get(\"content\").encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDir = \"lucene.backwardscompat0.index\";\n    rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(new File(fullDir(outputDir)));\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      SimilarityProvider sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.get(\"content\").encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"14ec33385f6fbb6ce172882d14605790418a5d31","date":1298910796,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      SimilarityProvider sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.get(\"content\").encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      SimilarityProvider sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.get(\"content\").encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a31c91eda919456f5f9237b086174385292f9935","date":1299074041,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      Similarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      SimilarityProvider sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.get(\"content\").encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1224a4027481acce15495b03bce9b48b93b42722","date":1300792329,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      Similarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      Similarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d619839baa8ce5503e496b94a9e42ad6f079293f","date":1301309428,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      Similarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      SimilarityProvider sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.get(\"content\").encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for(int i=0;i<fieldInfos.size();i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = i;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c0ef0193974807e4bddf5432a6b0287fe4d6c9df","date":1301476645,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      Similarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      SimilarityProvider sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.get(\"content\").encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2c5f0cb44df114db4228c8f77861714b5cabaea","date":1302542431,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      Similarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      Similarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"962d04139994fce5193143ef35615499a9a96d78","date":1302693744,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      Similarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      Similarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      Similarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      Similarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      Similarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      Similarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"639c36565ce03aed5b0fce7c9e4448e53a1f7efd","date":1308580104,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      Similarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\", IOContext.READ);\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      Similarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0aab6e810b4b0d3743d6a048be0602801f4b3920","date":1308671625,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      Similarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileDirectory cfsReader = dir.openCompoundInput(\"_0.cfs\", 1024);\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      Similarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2553b00f699380c64959ccb27991289aae87be2e","date":1309290151,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      Similarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileDirectory cfsReader = dir.openCompoundInput(\"_0.cfs\", 1024);\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      Similarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\");\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b6f9be74ca7baaef11857ad002cad40419979516","date":1309449808,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      Similarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\", newIOContext(random));\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      Similarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\", IOContext.READ);\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      Similarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileDirectory cfsReader = dir.openCompoundInput(\"_0.cfs\", newIOContext(random));\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      Similarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileReader cfsReader = new CompoundFileReader(dir, \"_0.cfs\", newIOContext(random));\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f3cee3d20b0c786e6fca20539454262e29edcab","date":1310101685,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      DefaultSimilarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileDirectory cfsReader = dir.openCompoundInput(\"_0.cfs\", 1024);\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      Similarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileDirectory cfsReader = dir.openCompoundInput(\"_0.cfs\", 1024);\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f0b9507caf22f292ac0e5e59f62db4275adf4511","date":1310107283,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      DefaultSimilarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileDirectory cfsReader = dir.openCompoundInput(\"_0.cfs\", 1024);\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      Similarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileDirectory cfsReader = dir.openCompoundInput(\"_0.cfs\", 1024);\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1291e4568eb7d9463d751627596ef14baf4c1603","date":1310112572,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      DefaultSimilarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileDirectory cfsReader = dir.openCompoundInput(\"_0.cfs\", newIOContext(random));\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      Similarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileDirectory cfsReader = dir.openCompoundInput(\"_0.cfs\", newIOContext(random));\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ddc4c914be86e34b54f70023f45a60fa7f04e929","date":1310115160,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      DefaultSimilarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileDirectory cfsReader = dir.openCompoundInput(\"_0.cfs\", newIOContext(random));\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      DefaultSimilarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileDirectory cfsReader = dir.openCompoundInput(\"_0.cfs\", 1024);\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5d004d0e0b3f65bb40da76d476d659d7888270e8","date":1310158940,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      DefaultSimilarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileDirectory cfsReader = dir.openCompoundInput(\"_0.cfs\", newIOContext(random));\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      DefaultSimilarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileDirectory cfsReader = dir.openCompoundInput(\"_0.cfs\", 1024);\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"67aadace85f701c87a4e0721eedcda25d8415a70","date":1314201925,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      DefaultSimilarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileDirectory cfsReader = new CompoundFileDirectory(dir, \"_0.cfs\", newIOContext(random), false);\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      DefaultSimilarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileDirectory cfsReader = dir.openCompoundInput(\"_0.cfs\", newIOContext(random));\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7b91922b55d15444d554721b352861d028eb8278","date":1320421415,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      DefaultSimilarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileDirectory cfsReader = new CompoundFileDirectory(dir, \"_0.cfs\", newIOContext(random), false);\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"_1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      DefaultSimilarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileDirectory cfsReader = new CompoundFileDirectory(dir, \"_0.cfs\", newIOContext(random), false);\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3cc749c053615f5871f3b95715fe292f34e70a53","date":1321470575,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      DefaultSimilarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileDirectory cfsReader = new CompoundFileDirectory(dir, \"_0.cfs\", newIOContext(random), false);\n      FieldInfosReader infosReader = Codec.getDefault().fieldInfosFormat().getFieldInfosReader();\n      FieldInfos fieldInfos = infosReader.read(cfsReader, \"_0\", IOContext.READONCE);\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"_1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      DefaultSimilarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileDirectory cfsReader = new CompoundFileDirectory(dir, \"_0.cfs\", newIOContext(random), false);\n      FieldInfos fieldInfos = new FieldInfos(cfsReader, \"_0.fnm\");\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"_1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"319624eb66a10b717d3e66af448543e7dc5c479d","date":1322741556,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      DefaultSimilarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileDirectory cfsReader = new CompoundFileDirectory(dir, \"_0.cfs\", newIOContext(random), false);\n      FieldInfosReader infosReader = Codec.getDefault().fieldInfosFormat().getFieldInfosReader();\n      FieldInfos fieldInfos = infosReader.read(cfsReader, \"_0\", IOContext.READONCE);\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      DefaultSimilarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileDirectory cfsReader = new CompoundFileDirectory(dir, \"_0.cfs\", newIOContext(random), false);\n      FieldInfosReader infosReader = Codec.getDefault().fieldInfosFormat().getFieldInfosReader();\n      FieldInfos fieldInfos = infosReader.read(cfsReader, \"_0\", IOContext.READONCE);\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\",\n                               \"_1.fnx\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4122a26e1fd0457a340616673a3d3aada370f713","date":1322955654,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      reader.close();\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      DefaultSimilarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileDirectory cfsReader = new CompoundFileDirectory(dir, \"_0.cfs\", newIOContext(random), false);\n      FieldInfosReader infosReader = Codec.getDefault().fieldInfosFormat().getFieldInfosReader();\n      FieldInfos fieldInfos = infosReader.read(cfsReader, \"_0\", IOContext.READONCE);\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"75ec8c9aaa10ac00b30fd4c2465409770c838f7b","date":1323020115,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n            .setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES)\n      );\n      Term searchTerm = new Term(\"id\", \"7\");\n      writer.deleteDocuments(searchTerm);\n      writer.close();\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      reader.close();\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3615ce4a1f785ae1b779244de52c6a7d99227e60","date":1323422019,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n            .setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES)\n      );\n      Term searchTerm = new Term(\"id\", \"7\");\n      writer.deleteDocuments(searchTerm);\n      writer.close();\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      DefaultSimilarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileDirectory cfsReader = new CompoundFileDirectory(dir, \"_0.cfs\", newIOContext(random), false);\n      FieldInfosReader infosReader = Codec.getDefault().fieldInfosFormat().getFieldInfosReader();\n      FieldInfos fieldInfos = infosReader.read(cfsReader, \"_0\", IOContext.READONCE);\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","date":1323437438,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n            .setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES)\n      );\n      Term searchTerm = new Term(\"id\", \"7\");\n      writer.deleteDocuments(searchTerm);\n      writer.close();\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      IndexReader reader = IndexReader.open(dir, false);\n      Term searchTerm = new Term(\"id\", \"7\");\n      int delCount = reader.deleteDocuments(searchTerm);\n      assertEquals(\"didn't delete the right number of documents\", 1, delCount);\n\n      // Set one norm so we get a .s0 file:\n      DefaultSimilarity sim = new DefaultSimilarity();\n      reader.setNorm(21, \"content\", sim.encodeNormValue(1.5f));\n      reader.close();\n\n      // The numbering of fields can vary depending on which\n      // JRE is in use.  On some JREs we see content bound to\n      // field 0; on others, field 1.  So, here we have to\n      // figure out which field number corresponds to\n      // \"content\", and then set our expected file names below\n      // accordingly:\n      CompoundFileDirectory cfsReader = new CompoundFileDirectory(dir, \"_0.cfs\", newIOContext(random), false);\n      FieldInfosReader infosReader = Codec.getDefault().fieldInfosFormat().getFieldInfosReader();\n      FieldInfos fieldInfos = infosReader.read(cfsReader, \"_0\", IOContext.READONCE);\n      int contentFieldIndex = -1;\n      for (FieldInfo fi : fieldInfos) {\n        if (fi.name.equals(\"content\")) {\n          contentFieldIndex = fi.number;\n          break;\n        }\n      }\n      cfsReader.close();\n      assertTrue(\"could not locate the 'content' field number in the _2.cfs segment\", contentFieldIndex != -1);\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"_0_1.s\" + contentFieldIndex,\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f64180a044b69e0741fc7e36a936bc5c462de815","date":1327076129,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n            .setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES)\n      );\n      Term searchTerm = new Term(\"id\", \"7\");\n      writer.deleteDocuments(searchTerm);\n      writer.close();\n\n      // Now verify file names... TODO: fix this test better, we could populate from \n      // separateFiles() or something.\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"segments_2\",\n                               \"segments.gen\"};\n      \n      String[] expectedSimpleText = new String[] {\"_0.cfs\", \"_0.cfe\",\n          \"_0_1.liv\",\n          \"segments_2\",\n          \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(expectedSimpleText);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual) && !Arrays.equals(expectedSimpleText, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) \n            + \"\\n or \" + asString(expectedSimpleText) + \"\\n actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n            .setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES)\n      );\n      Term searchTerm = new Term(\"id\", \"7\");\n      writer.deleteDocuments(searchTerm);\n      writer.close();\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31","date":1327836826,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n            .setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES)\n      );\n      Term searchTerm = new Term(\"id\", \"7\");\n      writer.deleteDocuments(searchTerm);\n      writer.close();\n\n      // Now verify file names... TODO: fix this test better, we could populate from \n      // separateFiles() or something.\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"segments_2\",\n                               \"segments.gen\"};\n      \n      String[] expectedSimpleText = new String[] {\"_0.cfs\", \"_0.cfe\",\n          \"_0_1.liv\",\n          \"segments_2\",\n          \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(expectedSimpleText);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual) && !Arrays.equals(expectedSimpleText, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) \n            + \"\\n or \" + asString(expectedSimpleText) + \"\\n actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n            .setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES)\n      );\n      Term searchTerm = new Term(\"id\", \"7\");\n      writer.deleteDocuments(searchTerm);\n      writer.close();\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd92b8bcc88e969302510acf77bd6970da3994c4","date":1327839530,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n            .setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES)\n      );\n      Term searchTerm = new Term(\"id\", \"7\");\n      writer.deleteDocuments(searchTerm);\n      writer.close();\n\n      // Now verify file names... TODO: fix this test better, we could populate from \n      // separateFiles() or something.\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"segments_2\",\n                               \"segments.gen\"};\n      \n      String[] expectedSimpleText = new String[] {\"_0.cfs\", \"_0.cfe\",\n          \"_0_1.liv\",\n          \"segments_2\",\n          \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(expectedSimpleText);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual) && !Arrays.equals(expectedSimpleText, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) \n            + \"\\n or \" + asString(expectedSimpleText) + \"\\n actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n            .setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES)\n      );\n      Term searchTerm = new Term(\"id\", \"7\");\n      writer.deleteDocuments(searchTerm);\n      writer.close();\n\n      // Now verify file names:\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"segments_2\",\n                               \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) + \"\\n  actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testExactFileNames().mjava","sourceNew":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n            .setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES)\n      );\n      Term searchTerm = new Term(\"id\", \"7\");\n      writer.deleteDocuments(searchTerm);\n      writer.close();\n\n      // Now verify file names... TODO: fix this test better, we could populate from \n      // separateFiles() or something.\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"segments_2\",\n                               \"segments.gen\"};\n      \n      String[] expectedSimpleText = new String[] {\"_0.cfs\", \"_0.cfe\",\n          \"_0_1.liv\",\n          \"segments_2\",\n          \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(expectedSimpleText);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual) && !Arrays.equals(expectedSimpleText, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) \n            + \"\\n or \" + asString(expectedSimpleText) + \"\\n actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","sourceOld":"  public void testExactFileNames() throws IOException {\n\n    String outputDirName = \"lucene.backwardscompat0.index\";\n    File outputDir = _TestUtil.getTempDir(outputDirName);\n    _TestUtil.rmDir(outputDir);\n\n    try {\n      Directory dir = newFSDirectory(outputDir);\n\n      LogMergePolicy mergePolicy = newLogMergePolicy(true, 10);\n      mergePolicy.setNoCFSRatio(1); // This test expects all of its segments to be in CFS\n\n      IndexWriter writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setMaxBufferedDocs(-1).\n              setRAMBufferSizeMB(16.0).\n              setMergePolicy(mergePolicy)\n      );\n      for(int i=0;i<35;i++) {\n        addDoc(writer, i);\n      }\n      assertEquals(\"wrong doc count\", 35, writer.maxDoc());\n      writer.close();\n\n      // Delete one doc so we get a .del file:\n      writer = new IndexWriter(\n          dir,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n            .setMergePolicy(NoMergePolicy.NO_COMPOUND_FILES)\n      );\n      Term searchTerm = new Term(\"id\", \"7\");\n      writer.deleteDocuments(searchTerm);\n      writer.close();\n\n      // Now verify file names... TODO: fix this test better, we could populate from \n      // separateFiles() or something.\n      String[] expected = new String[] {\"_0.cfs\", \"_0.cfe\",\n                               \"_0_1.del\",\n                               \"segments_2\",\n                               \"segments.gen\"};\n      \n      String[] expectedSimpleText = new String[] {\"_0.cfs\", \"_0.cfe\",\n          \"_0_1.liv\",\n          \"segments_2\",\n          \"segments.gen\"};\n\n      String[] actual = dir.listAll();\n      Arrays.sort(expected);\n      Arrays.sort(expectedSimpleText);\n      Arrays.sort(actual);\n      if (!Arrays.equals(expected, actual) && !Arrays.equals(expectedSimpleText, actual)) {\n        fail(\"incorrect filenames in index: expected:\\n    \" + asString(expected) \n            + \"\\n or \" + asString(expectedSimpleText) + \"\\n actual:\\n    \" + asString(actual));\n      }\n      dir.close();\n    } finally {\n      _TestUtil.rmDir(outputDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":["319624eb66a10b717d3e66af448543e7dc5c479d","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["d572389229127c297dd1fa5ce4758e1cec41e799","a13a126d15299d5c1e117ea99ddae6fb0fa3f209"],"fd9325c7ff9928fabe81c28553b41fc7aa57dfab":["7a54e23e03b47f3d568ab3020bdd386e4b2f0a05"],"14ec33385f6fbb6ce172882d14605790418a5d31":["b0c7a8f7304b75b1528814c5820fa23a96816c27"],"f64180a044b69e0741fc7e36a936bc5c462de815":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["b21422ff1d1d56499dec481f193b402e5e8def5b"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["ab5cb6a74aefb78aa0569857970b9151dfe2e787","3cdad2c6b6234338031bcc1f24c001a5ad66f714"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["bb9b72f7c3d7827c64dd4ec580ded81778da361d","b0c7a8f7304b75b1528814c5820fa23a96816c27"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"0f3cee3d20b0c786e6fca20539454262e29edcab":["0aab6e810b4b0d3743d6a048be0602801f4b3920"],"38a62612cfa4e104080d89d7751a8f1a258ac335":["4e8cc373c801e54cec75daf9f52792cb4b17f536"],"0aab6e810b4b0d3743d6a048be0602801f4b3920":["f2c5f0cb44df114db4228c8f77861714b5cabaea"],"3cdad2c6b6234338031bcc1f24c001a5ad66f714":["fd9325c7ff9928fabe81c28553b41fc7aa57dfab"],"d572389229127c297dd1fa5ce4758e1cec41e799":["69a923a22517eb7ff0bad9c6d1a7d45cc0696bd4"],"962d04139994fce5193143ef35615499a9a96d78":["c0ef0193974807e4bddf5432a6b0287fe4d6c9df","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"2553b00f699380c64959ccb27991289aae87be2e":["a3776dccca01c11e7046323cfad46a3b4a471233","0aab6e810b4b0d3743d6a048be0602801f4b3920"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["b6f9be74ca7baaef11857ad002cad40419979516","0aab6e810b4b0d3743d6a048be0602801f4b3920"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["29ef99d61cda9641b6250bf9567329a6e65f901d","1224a4027481acce15495b03bce9b48b93b42722"],"a3776dccca01c11e7046323cfad46a3b4a471233":["1224a4027481acce15495b03bce9b48b93b42722","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["319624eb66a10b717d3e66af448543e7dc5c479d","75ec8c9aaa10ac00b30fd4c2465409770c838f7b"],"c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31":["3615ce4a1f785ae1b779244de52c6a7d99227e60","f64180a044b69e0741fc7e36a936bc5c462de815"],"67aadace85f701c87a4e0721eedcda25d8415a70":["ddc4c914be86e34b54f70023f45a60fa7f04e929"],"b48e4082e2f39f1eb6f935ea9a1203c5e8d830a9":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"75ec8c9aaa10ac00b30fd4c2465409770c838f7b":["4122a26e1fd0457a340616673a3d3aada370f713"],"fd92b8bcc88e969302510acf77bd6970da3994c4":["3615ce4a1f785ae1b779244de52c6a7d99227e60","c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31"],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["f2c5f0cb44df114db4228c8f77861714b5cabaea"],"4a69e5860d014751cc9329dfeb441a6d8fd1ed8e":["3bb13258feba31ab676502787ab2e1779f129b7a"],"bb9b72f7c3d7827c64dd4ec580ded81778da361d":["868da859b43505d9d2a023bfeae6dd0c795f5295","fd9325c7ff9928fabe81c28553b41fc7aa57dfab"],"c0ef0193974807e4bddf5432a6b0287fe4d6c9df":["bde51b089eb7f86171eb3406e38a274743f9b7ac","1224a4027481acce15495b03bce9b48b93b42722"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["1224a4027481acce15495b03bce9b48b93b42722"],"69a923a22517eb7ff0bad9c6d1a7d45cc0696bd4":["d8d3f45cdd3ff689aaf7a3aab99e2df31305ac10"],"f0b9507caf22f292ac0e5e59f62db4275adf4511":["2553b00f699380c64959ccb27991289aae87be2e","0f3cee3d20b0c786e6fca20539454262e29edcab"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b6f9be74ca7baaef11857ad002cad40419979516":["639c36565ce03aed5b0fce7c9e4448e53a1f7efd"],"5d004d0e0b3f65bb40da76d476d659d7888270e8":["f0b9507caf22f292ac0e5e59f62db4275adf4511","ddc4c914be86e34b54f70023f45a60fa7f04e929"],"319624eb66a10b717d3e66af448543e7dc5c479d":["3cc749c053615f5871f3b95715fe292f34e70a53"],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["0f3cee3d20b0c786e6fca20539454262e29edcab","1291e4568eb7d9463d751627596ef14baf4c1603"],"b21422ff1d1d56499dec481f193b402e5e8def5b":["d572389229127c297dd1fa5ce4758e1cec41e799"],"1224a4027481acce15495b03bce9b48b93b42722":["a31c91eda919456f5f9237b086174385292f9935"],"7a54e23e03b47f3d568ab3020bdd386e4b2f0a05":["a13a126d15299d5c1e117ea99ddae6fb0fa3f209"],"a13a126d15299d5c1e117ea99ddae6fb0fa3f209":["38a62612cfa4e104080d89d7751a8f1a258ac335"],"a31c91eda919456f5f9237b086174385292f9935":["14ec33385f6fbb6ce172882d14605790418a5d31"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["d619839baa8ce5503e496b94a9e42ad6f079293f","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"3cc749c053615f5871f3b95715fe292f34e70a53":["7b91922b55d15444d554721b352861d028eb8278"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["4a69e5860d014751cc9329dfeb441a6d8fd1ed8e","a13a126d15299d5c1e117ea99ddae6fb0fa3f209"],"d8d3f45cdd3ff689aaf7a3aab99e2df31305ac10":["b48e4082e2f39f1eb6f935ea9a1203c5e8d830a9"],"7b91922b55d15444d554721b352861d028eb8278":["67aadace85f701c87a4e0721eedcda25d8415a70"],"1291e4568eb7d9463d751627596ef14baf4c1603":["d083e83f225b11e5fdd900e83d26ddb385b6955c","0f3cee3d20b0c786e6fca20539454262e29edcab"],"b0c7a8f7304b75b1528814c5820fa23a96816c27":["3cdad2c6b6234338031bcc1f24c001a5ad66f714"],"4122a26e1fd0457a340616673a3d3aada370f713":["319624eb66a10b717d3e66af448543e7dc5c479d"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","7a54e23e03b47f3d568ab3020bdd386e4b2f0a05"],"3bb13258feba31ab676502787ab2e1779f129b7a":["1f653cfcf159baeaafe5d01682a911e95bba4012","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"4e8cc373c801e54cec75daf9f52792cb4b17f536":["1f653cfcf159baeaafe5d01682a911e95bba4012"]},"commit2Childs":{"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["868da859b43505d9d2a023bfeae6dd0c795f5295"],"fd9325c7ff9928fabe81c28553b41fc7aa57dfab":["3cdad2c6b6234338031bcc1f24c001a5ad66f714","bb9b72f7c3d7827c64dd4ec580ded81778da361d"],"14ec33385f6fbb6ce172882d14605790418a5d31":["a31c91eda919456f5f9237b086174385292f9935"],"f64180a044b69e0741fc7e36a936bc5c462de815":["c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["3bb13258feba31ab676502787ab2e1779f129b7a","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["d619839baa8ce5503e496b94a9e42ad6f079293f"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["c0ef0193974807e4bddf5432a6b0287fe4d6c9df"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["b48e4082e2f39f1eb6f935ea9a1203c5e8d830a9"],"0f3cee3d20b0c786e6fca20539454262e29edcab":["f0b9507caf22f292ac0e5e59f62db4275adf4511","ddc4c914be86e34b54f70023f45a60fa7f04e929","1291e4568eb7d9463d751627596ef14baf4c1603"],"38a62612cfa4e104080d89d7751a8f1a258ac335":["a13a126d15299d5c1e117ea99ddae6fb0fa3f209"],"3cdad2c6b6234338031bcc1f24c001a5ad66f714":["29ef99d61cda9641b6250bf9567329a6e65f901d","b0c7a8f7304b75b1528814c5820fa23a96816c27"],"0aab6e810b4b0d3743d6a048be0602801f4b3920":["0f3cee3d20b0c786e6fca20539454262e29edcab","2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c"],"d572389229127c297dd1fa5ce4758e1cec41e799":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","b21422ff1d1d56499dec481f193b402e5e8def5b"],"962d04139994fce5193143ef35615499a9a96d78":[],"2553b00f699380c64959ccb27991289aae87be2e":["f0b9507caf22f292ac0e5e59f62db4275adf4511"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["1291e4568eb7d9463d751627596ef14baf4c1603"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"a3776dccca01c11e7046323cfad46a3b4a471233":["2553b00f699380c64959ccb27991289aae87be2e"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","f64180a044b69e0741fc7e36a936bc5c462de815","c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31","fd92b8bcc88e969302510acf77bd6970da3994c4"],"c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","fd92b8bcc88e969302510acf77bd6970da3994c4"],"67aadace85f701c87a4e0721eedcda25d8415a70":["7b91922b55d15444d554721b352861d028eb8278"],"75ec8c9aaa10ac00b30fd4c2465409770c838f7b":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"b48e4082e2f39f1eb6f935ea9a1203c5e8d830a9":["d8d3f45cdd3ff689aaf7a3aab99e2df31305ac10"],"fd92b8bcc88e969302510acf77bd6970da3994c4":[],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["b6f9be74ca7baaef11857ad002cad40419979516"],"4a69e5860d014751cc9329dfeb441a6d8fd1ed8e":["ab5cb6a74aefb78aa0569857970b9151dfe2e787"],"bb9b72f7c3d7827c64dd4ec580ded81778da361d":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"c0ef0193974807e4bddf5432a6b0287fe4d6c9df":["962d04139994fce5193143ef35615499a9a96d78"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["0aab6e810b4b0d3743d6a048be0602801f4b3920","962d04139994fce5193143ef35615499a9a96d78","a3776dccca01c11e7046323cfad46a3b4a471233","639c36565ce03aed5b0fce7c9e4448e53a1f7efd","135621f3a0670a9394eb563224a3b76cc4dddc0f"],"69a923a22517eb7ff0bad9c6d1a7d45cc0696bd4":["d572389229127c297dd1fa5ce4758e1cec41e799"],"f0b9507caf22f292ac0e5e59f62db4275adf4511":["5d004d0e0b3f65bb40da76d476d659d7888270e8"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"b6f9be74ca7baaef11857ad002cad40419979516":["d083e83f225b11e5fdd900e83d26ddb385b6955c"],"5d004d0e0b3f65bb40da76d476d659d7888270e8":[],"319624eb66a10b717d3e66af448543e7dc5c479d":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","3615ce4a1f785ae1b779244de52c6a7d99227e60","4122a26e1fd0457a340616673a3d3aada370f713"],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["67aadace85f701c87a4e0721eedcda25d8415a70","5d004d0e0b3f65bb40da76d476d659d7888270e8"],"b21422ff1d1d56499dec481f193b402e5e8def5b":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"1224a4027481acce15495b03bce9b48b93b42722":["d619839baa8ce5503e496b94a9e42ad6f079293f","a3776dccca01c11e7046323cfad46a3b4a471233","c0ef0193974807e4bddf5432a6b0287fe4d6c9df","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"a13a126d15299d5c1e117ea99ddae6fb0fa3f209":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","7a54e23e03b47f3d568ab3020bdd386e4b2f0a05","ab5cb6a74aefb78aa0569857970b9151dfe2e787"],"7a54e23e03b47f3d568ab3020bdd386e4b2f0a05":["fd9325c7ff9928fabe81c28553b41fc7aa57dfab","868da859b43505d9d2a023bfeae6dd0c795f5295"],"a31c91eda919456f5f9237b086174385292f9935":["1224a4027481acce15495b03bce9b48b93b42722"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":[],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["29ef99d61cda9641b6250bf9567329a6e65f901d"],"3cc749c053615f5871f3b95715fe292f34e70a53":["319624eb66a10b717d3e66af448543e7dc5c479d"],"d8d3f45cdd3ff689aaf7a3aab99e2df31305ac10":["69a923a22517eb7ff0bad9c6d1a7d45cc0696bd4"],"1291e4568eb7d9463d751627596ef14baf4c1603":["ddc4c914be86e34b54f70023f45a60fa7f04e929"],"7b91922b55d15444d554721b352861d028eb8278":["3cc749c053615f5871f3b95715fe292f34e70a53"],"b0c7a8f7304b75b1528814c5820fa23a96816c27":["14ec33385f6fbb6ce172882d14605790418a5d31","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"4122a26e1fd0457a340616673a3d3aada370f713":["75ec8c9aaa10ac00b30fd4c2465409770c838f7b"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["bb9b72f7c3d7827c64dd4ec580ded81778da361d"],"3bb13258feba31ab676502787ab2e1779f129b7a":["4a69e5860d014751cc9329dfeb441a6d8fd1ed8e"],"4e8cc373c801e54cec75daf9f52792cb4b17f536":["38a62612cfa4e104080d89d7751a8f1a258ac335","3bb13258feba31ab676502787ab2e1779f129b7a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","962d04139994fce5193143ef35615499a9a96d78","fd92b8bcc88e969302510acf77bd6970da3994c4","5d004d0e0b3f65bb40da76d476d659d7888270e8","135621f3a0670a9394eb563224a3b76cc4dddc0f","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}