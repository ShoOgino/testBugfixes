{"path":"lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#storeTerms(Info,TokenStream,int,int).mjava","commits":[{"id":"acd9883560fd89e6448b2b447302fe543040cd4f","date":1488478696,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#storeTerms(Info,TokenStream,int,int).mjava","pathOld":"lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#storeTerms(Info,TokenStream,float,int,int).mjava","sourceNew":"  private void storeTerms(Info info, TokenStream tokenStream, int positionIncrementGap, int offsetGap) {\n\n    int pos = -1;\n    int offset = 0;\n    if (info.numTokens > 0) {\n      pos = info.lastPosition + positionIncrementGap;\n      offset = info.lastOffset + offsetGap;\n    }\n\n    try (TokenStream stream = tokenStream) {\n      TermToBytesRefAttribute termAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n      PositionIncrementAttribute posIncrAttribute = stream.addAttribute(PositionIncrementAttribute.class);\n      OffsetAttribute offsetAtt = stream.addAttribute(OffsetAttribute.class);\n      PayloadAttribute payloadAtt = storePayloads ? stream.addAttribute(PayloadAttribute.class) : null;\n      stream.reset();\n\n      while (stream.incrementToken()) {\n//        if (DEBUG) System.err.println(\"token='\" + term + \"'\");\n        info.numTokens++;\n        final int posIncr = posIncrAttribute.getPositionIncrement();\n        if (posIncr == 0) {\n          info.numOverlapTokens++;\n        }\n        pos += posIncr;\n        int ord = info.terms.add(termAtt.getBytesRef());\n        if (ord < 0) {\n          ord = (-ord) - 1;\n          postingsWriter.reset(info.sliceArray.end[ord]);\n        } else {\n          info.sliceArray.start[ord] = postingsWriter.startNewSlice();\n        }\n        info.sliceArray.freq[ord]++;\n        info.sumTotalTermFreq++;\n        postingsWriter.writeInt(pos);\n        if (storeOffsets) {\n          postingsWriter.writeInt(offsetAtt.startOffset() + offset);\n          postingsWriter.writeInt(offsetAtt.endOffset() + offset);\n        }\n        if (storePayloads) {\n          final BytesRef payload = payloadAtt.getPayload();\n          final int pIndex;\n          if (payload == null || payload.length == 0) {\n            pIndex = -1;\n          } else {\n            pIndex = payloadsBytesRefs.append(payload);\n          }\n          postingsWriter.writeInt(pIndex);\n        }\n        info.sliceArray.end[ord] = postingsWriter.getCurrentOffset();\n      }\n      stream.end();\n      if (info.numTokens > 0) {\n        info.lastPosition = pos;\n        info.lastOffset = offsetAtt.endOffset() + offset;\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n","sourceOld":"  private void storeTerms(Info info, TokenStream tokenStream, float boost, int positionIncrementGap, int offsetGap) {\n\n    if (boost <= 0.0f) {\n      throw new IllegalArgumentException(\"boost factor must be greater than 0.0\");\n    }\n\n    int pos = -1;\n    int offset = 0;\n    if (info.numTokens == 0) {\n      info.boost = boost;\n    } else if (info.numTokens > 0) {\n      pos = info.lastPosition + positionIncrementGap;\n      offset = info.lastOffset + offsetGap;\n      info.boost *= boost;\n    }\n\n    try (TokenStream stream = tokenStream) {\n      TermToBytesRefAttribute termAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n      PositionIncrementAttribute posIncrAttribute = stream.addAttribute(PositionIncrementAttribute.class);\n      OffsetAttribute offsetAtt = stream.addAttribute(OffsetAttribute.class);\n      PayloadAttribute payloadAtt = storePayloads ? stream.addAttribute(PayloadAttribute.class) : null;\n      stream.reset();\n\n      while (stream.incrementToken()) {\n//        if (DEBUG) System.err.println(\"token='\" + term + \"'\");\n        info.numTokens++;\n        final int posIncr = posIncrAttribute.getPositionIncrement();\n        if (posIncr == 0) {\n          info.numOverlapTokens++;\n        }\n        pos += posIncr;\n        int ord = info.terms.add(termAtt.getBytesRef());\n        if (ord < 0) {\n          ord = (-ord) - 1;\n          postingsWriter.reset(info.sliceArray.end[ord]);\n        } else {\n          info.sliceArray.start[ord] = postingsWriter.startNewSlice();\n        }\n        info.sliceArray.freq[ord]++;\n        info.sumTotalTermFreq++;\n        postingsWriter.writeInt(pos);\n        if (storeOffsets) {\n          postingsWriter.writeInt(offsetAtt.startOffset() + offset);\n          postingsWriter.writeInt(offsetAtt.endOffset() + offset);\n        }\n        if (storePayloads) {\n          final BytesRef payload = payloadAtt.getPayload();\n          final int pIndex;\n          if (payload == null || payload.length == 0) {\n            pIndex = -1;\n          } else {\n            pIndex = payloadsBytesRefs.append(payload);\n          }\n          postingsWriter.writeInt(pIndex);\n        }\n        info.sliceArray.end[ord] = postingsWriter.getCurrentOffset();\n      }\n      stream.end();\n      if (info.numTokens > 0) {\n        info.lastPosition = pos;\n        info.lastOffset = offsetAtt.endOffset() + offset;\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5a4bb2b5569a925d9d26743041864893512a7958","date":1519489313,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#storeTerms(Info,TokenStream,int,int).mjava","pathOld":"lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#storeTerms(Info,TokenStream,int,int).mjava","sourceNew":"  private void storeTerms(Info info, TokenStream tokenStream, int positionIncrementGap, int offsetGap) {\n\n    int pos = -1;\n    int offset = 0;\n    if (info.numTokens > 0) {\n      pos = info.lastPosition + positionIncrementGap;\n      offset = info.lastOffset + offsetGap;\n    }\n\n    try (TokenStream stream = tokenStream) {\n      TermToBytesRefAttribute termAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n      PositionIncrementAttribute posIncrAttribute = stream.addAttribute(PositionIncrementAttribute.class);\n      OffsetAttribute offsetAtt = stream.addAttribute(OffsetAttribute.class);\n      PayloadAttribute payloadAtt = storePayloads ? stream.addAttribute(PayloadAttribute.class) : null;\n      stream.reset();\n\n      while (stream.incrementToken()) {\n//        if (DEBUG) System.err.println(\"token='\" + term + \"'\");\n        info.numTokens++;\n        final int posIncr = posIncrAttribute.getPositionIncrement();\n        if (posIncr == 0) {\n          info.numOverlapTokens++;\n        }\n        pos += posIncr;\n        int ord = info.terms.add(termAtt.getBytesRef());\n        if (ord < 0) {\n          ord = (-ord) - 1;\n          postingsWriter.reset(info.sliceArray.end[ord]);\n        } else {\n          info.sliceArray.start[ord] = postingsWriter.startNewSlice();\n        }\n        info.sliceArray.freq[ord]++;\n        info.maxTermFrequency = Math.max(info.maxTermFrequency, info.sliceArray.freq[ord]);\n        info.sumTotalTermFreq++;\n        postingsWriter.writeInt(pos);\n        if (storeOffsets) {\n          postingsWriter.writeInt(offsetAtt.startOffset() + offset);\n          postingsWriter.writeInt(offsetAtt.endOffset() + offset);\n        }\n        if (storePayloads) {\n          final BytesRef payload = payloadAtt.getPayload();\n          final int pIndex;\n          if (payload == null || payload.length == 0) {\n            pIndex = -1;\n          } else {\n            pIndex = payloadsBytesRefs.append(payload);\n          }\n          postingsWriter.writeInt(pIndex);\n        }\n        info.sliceArray.end[ord] = postingsWriter.getCurrentOffset();\n      }\n      stream.end();\n      if (info.numTokens > 0) {\n        info.lastPosition = pos;\n        info.lastOffset = offsetAtt.endOffset() + offset;\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n","sourceOld":"  private void storeTerms(Info info, TokenStream tokenStream, int positionIncrementGap, int offsetGap) {\n\n    int pos = -1;\n    int offset = 0;\n    if (info.numTokens > 0) {\n      pos = info.lastPosition + positionIncrementGap;\n      offset = info.lastOffset + offsetGap;\n    }\n\n    try (TokenStream stream = tokenStream) {\n      TermToBytesRefAttribute termAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n      PositionIncrementAttribute posIncrAttribute = stream.addAttribute(PositionIncrementAttribute.class);\n      OffsetAttribute offsetAtt = stream.addAttribute(OffsetAttribute.class);\n      PayloadAttribute payloadAtt = storePayloads ? stream.addAttribute(PayloadAttribute.class) : null;\n      stream.reset();\n\n      while (stream.incrementToken()) {\n//        if (DEBUG) System.err.println(\"token='\" + term + \"'\");\n        info.numTokens++;\n        final int posIncr = posIncrAttribute.getPositionIncrement();\n        if (posIncr == 0) {\n          info.numOverlapTokens++;\n        }\n        pos += posIncr;\n        int ord = info.terms.add(termAtt.getBytesRef());\n        if (ord < 0) {\n          ord = (-ord) - 1;\n          postingsWriter.reset(info.sliceArray.end[ord]);\n        } else {\n          info.sliceArray.start[ord] = postingsWriter.startNewSlice();\n        }\n        info.sliceArray.freq[ord]++;\n        info.sumTotalTermFreq++;\n        postingsWriter.writeInt(pos);\n        if (storeOffsets) {\n          postingsWriter.writeInt(offsetAtt.startOffset() + offset);\n          postingsWriter.writeInt(offsetAtt.endOffset() + offset);\n        }\n        if (storePayloads) {\n          final BytesRef payload = payloadAtt.getPayload();\n          final int pIndex;\n          if (payload == null || payload.length == 0) {\n            pIndex = -1;\n          } else {\n            pIndex = payloadsBytesRefs.append(payload);\n          }\n          postingsWriter.writeInt(pIndex);\n        }\n        info.sliceArray.end[ord] = postingsWriter.getCurrentOffset();\n      }\n      stream.end();\n      if (info.numTokens > 0) {\n        info.lastPosition = pos;\n        info.lastOffset = offsetAtt.endOffset() + offset;\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"5a4bb2b5569a925d9d26743041864893512a7958":["acd9883560fd89e6448b2b447302fe543040cd4f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"acd9883560fd89e6448b2b447302fe543040cd4f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["5a4bb2b5569a925d9d26743041864893512a7958"]},"commit2Childs":{"5a4bb2b5569a925d9d26743041864893512a7958":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["acd9883560fd89e6448b2b447302fe543040cd4f"],"acd9883560fd89e6448b2b447302fe543040cd4f":["5a4bb2b5569a925d9d26743041864893512a7958"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}