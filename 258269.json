{"path":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","commits":[{"id":"e166cc9c5f45f78a8dd02332b5ac100221063fd8","date":1421678965,"type":0,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","pathOld":"/dev/null","sourceNew":"  /** Check that the scorer and bulk scorer advance consistently. */\n  public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {\n    Weight weight = searcher.createNormalizedWeight(query);\n    for (LeafReaderContext context : searcher.getIndexReader().leaves()) {\n      final Scorer scorer = weight.scorer(context, context.reader().getLiveDocs());\n      final BulkScorer bulkScorer = weight.bulkScorer(context, context.reader().getLiveDocs());\n      if (scorer == null && bulkScorer == null) {\n        continue;\n      }\n      int upTo = 0;\n      while (true) {\n        final int min = upTo + r.nextInt(5);\n        final int max = min + 1 + r.nextInt(r.nextBoolean() ? 10 : 5000);\n        if (scorer.docID() < min) {\n          scorer.advance(min);\n        }\n        final int next = bulkScorer.score(new LeafCollector() {\n          Scorer scorer2;\n          @Override\n          public void setScorer(Scorer scorer) throws IOException {\n            this.scorer2 = scorer;\n          }\n          @Override\n          public void collect(int doc) throws IOException {\n            assert doc >= min;\n            assert doc < max;\n            Assert.assertEquals(scorer.docID(), doc);\n            Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);\n            scorer.nextDoc();\n          }\n        }, min, max);\n        assert max <= next;\n        assert next <= scorer.docID();\n        upTo = max;\n\n        if (scorer.docID() == DocIdSetIterator.NO_MORE_DOCS) {\n          bulkScorer.score(new LeafCollector() {\n            @Override\n            public void setScorer(Scorer scorer) throws IOException {}\n            \n            @Override\n            public void collect(int doc) throws IOException {\n              // no more matches\n              assert false;\n            }\n          }, upTo, DocIdSetIterator.NO_MORE_DOCS);\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["781239fc84d36be12b84e4d3e2618f5f07a182e3"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"781239fc84d36be12b84e4d3e2618f5f07a182e3","date":1423139668,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","sourceNew":"  /** Check that the scorer and bulk scorer advance consistently. */\n  public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {\n    Weight weight = searcher.createNormalizedWeight(query);\n    for (LeafReaderContext context : searcher.getIndexReader().leaves()) {\n      final Scorer scorer = weight.scorer(context, context.reader().getLiveDocs(), true);\n      final BulkScorer bulkScorer = weight.bulkScorer(context, context.reader().getLiveDocs(), true);\n      if (scorer == null && bulkScorer == null) {\n        continue;\n      }\n      int upTo = 0;\n      while (true) {\n        final int min = upTo + r.nextInt(5);\n        final int max = min + 1 + r.nextInt(r.nextBoolean() ? 10 : 5000);\n        if (scorer.docID() < min) {\n          scorer.advance(min);\n        }\n        final int next = bulkScorer.score(new LeafCollector() {\n          Scorer scorer2;\n          @Override\n          public void setScorer(Scorer scorer) throws IOException {\n            this.scorer2 = scorer;\n          }\n          @Override\n          public void collect(int doc) throws IOException {\n            assert doc >= min;\n            assert doc < max;\n            Assert.assertEquals(scorer.docID(), doc);\n            Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);\n            scorer.nextDoc();\n          }\n        }, min, max);\n        assert max <= next;\n        assert next <= scorer.docID();\n        upTo = max;\n\n        if (scorer.docID() == DocIdSetIterator.NO_MORE_DOCS) {\n          bulkScorer.score(new LeafCollector() {\n            @Override\n            public void setScorer(Scorer scorer) throws IOException {}\n            \n            @Override\n            public void collect(int doc) throws IOException {\n              // no more matches\n              assert false;\n            }\n          }, upTo, DocIdSetIterator.NO_MORE_DOCS);\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /** Check that the scorer and bulk scorer advance consistently. */\n  public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {\n    Weight weight = searcher.createNormalizedWeight(query);\n    for (LeafReaderContext context : searcher.getIndexReader().leaves()) {\n      final Scorer scorer = weight.scorer(context, context.reader().getLiveDocs());\n      final BulkScorer bulkScorer = weight.bulkScorer(context, context.reader().getLiveDocs());\n      if (scorer == null && bulkScorer == null) {\n        continue;\n      }\n      int upTo = 0;\n      while (true) {\n        final int min = upTo + r.nextInt(5);\n        final int max = min + 1 + r.nextInt(r.nextBoolean() ? 10 : 5000);\n        if (scorer.docID() < min) {\n          scorer.advance(min);\n        }\n        final int next = bulkScorer.score(new LeafCollector() {\n          Scorer scorer2;\n          @Override\n          public void setScorer(Scorer scorer) throws IOException {\n            this.scorer2 = scorer;\n          }\n          @Override\n          public void collect(int doc) throws IOException {\n            assert doc >= min;\n            assert doc < max;\n            Assert.assertEquals(scorer.docID(), doc);\n            Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);\n            scorer.nextDoc();\n          }\n        }, min, max);\n        assert max <= next;\n        assert next <= scorer.docID();\n        upTo = max;\n\n        if (scorer.docID() == DocIdSetIterator.NO_MORE_DOCS) {\n          bulkScorer.score(new LeafCollector() {\n            @Override\n            public void setScorer(Scorer scorer) throws IOException {}\n            \n            @Override\n            public void collect(int doc) throws IOException {\n              // no more matches\n              assert false;\n            }\n          }, upTo, DocIdSetIterator.NO_MORE_DOCS);\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":["e166cc9c5f45f78a8dd02332b5ac100221063fd8"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fb17639909a369c1e64866842e5c213440acc17e","date":1423238093,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","sourceNew":"  /** Check that the scorer and bulk scorer advance consistently. */\n  public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {\n    Weight weight = searcher.createNormalizedWeight(query, true);\n    for (LeafReaderContext context : searcher.getIndexReader().leaves()) {\n      final Scorer scorer = weight.scorer(context, context.reader().getLiveDocs());\n      final BulkScorer bulkScorer = weight.bulkScorer(context, context.reader().getLiveDocs());\n      if (scorer == null && bulkScorer == null) {\n        continue;\n      }\n      int upTo = 0;\n      while (true) {\n        final int min = upTo + r.nextInt(5);\n        final int max = min + 1 + r.nextInt(r.nextBoolean() ? 10 : 5000);\n        if (scorer.docID() < min) {\n          scorer.advance(min);\n        }\n        final int next = bulkScorer.score(new LeafCollector() {\n          Scorer scorer2;\n          @Override\n          public void setScorer(Scorer scorer) throws IOException {\n            this.scorer2 = scorer;\n          }\n          @Override\n          public void collect(int doc) throws IOException {\n            assert doc >= min;\n            assert doc < max;\n            Assert.assertEquals(scorer.docID(), doc);\n            Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);\n            scorer.nextDoc();\n          }\n        }, min, max);\n        assert max <= next;\n        assert next <= scorer.docID();\n        upTo = max;\n\n        if (scorer.docID() == DocIdSetIterator.NO_MORE_DOCS) {\n          bulkScorer.score(new LeafCollector() {\n            @Override\n            public void setScorer(Scorer scorer) throws IOException {}\n            \n            @Override\n            public void collect(int doc) throws IOException {\n              // no more matches\n              assert false;\n            }\n          }, upTo, DocIdSetIterator.NO_MORE_DOCS);\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /** Check that the scorer and bulk scorer advance consistently. */\n  public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {\n    Weight weight = searcher.createNormalizedWeight(query);\n    for (LeafReaderContext context : searcher.getIndexReader().leaves()) {\n      final Scorer scorer = weight.scorer(context, context.reader().getLiveDocs(), true);\n      final BulkScorer bulkScorer = weight.bulkScorer(context, context.reader().getLiveDocs(), true);\n      if (scorer == null && bulkScorer == null) {\n        continue;\n      }\n      int upTo = 0;\n      while (true) {\n        final int min = upTo + r.nextInt(5);\n        final int max = min + 1 + r.nextInt(r.nextBoolean() ? 10 : 5000);\n        if (scorer.docID() < min) {\n          scorer.advance(min);\n        }\n        final int next = bulkScorer.score(new LeafCollector() {\n          Scorer scorer2;\n          @Override\n          public void setScorer(Scorer scorer) throws IOException {\n            this.scorer2 = scorer;\n          }\n          @Override\n          public void collect(int doc) throws IOException {\n            assert doc >= min;\n            assert doc < max;\n            Assert.assertEquals(scorer.docID(), doc);\n            Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);\n            scorer.nextDoc();\n          }\n        }, min, max);\n        assert max <= next;\n        assert next <= scorer.docID();\n        upTo = max;\n\n        if (scorer.docID() == DocIdSetIterator.NO_MORE_DOCS) {\n          bulkScorer.score(new LeafCollector() {\n            @Override\n            public void setScorer(Scorer scorer) throws IOException {}\n            \n            @Override\n            public void collect(int doc) throws IOException {\n              // no more matches\n              assert false;\n            }\n          }, upTo, DocIdSetIterator.NO_MORE_DOCS);\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"954e59be3da8dc1b046646ad7af4b466852009d3","date":1423482367,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","sourceNew":"  /** Check that the scorer and bulk scorer advance consistently. */\n  public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {\n    Weight weight = searcher.createNormalizedWeight(query, PostingsEnum.FLAG_FREQS);\n    for (LeafReaderContext context : searcher.getIndexReader().leaves()) {\n      final Scorer scorer = weight.scorer(context, context.reader().getLiveDocs());\n      final BulkScorer bulkScorer = weight.bulkScorer(context, context.reader().getLiveDocs());\n      if (scorer == null && bulkScorer == null) {\n        continue;\n      }\n      int upTo = 0;\n      while (true) {\n        final int min = upTo + r.nextInt(5);\n        final int max = min + 1 + r.nextInt(r.nextBoolean() ? 10 : 5000);\n        if (scorer.docID() < min) {\n          scorer.advance(min);\n        }\n        final int next = bulkScorer.score(new LeafCollector() {\n          Scorer scorer2;\n          @Override\n          public void setScorer(Scorer scorer) throws IOException {\n            this.scorer2 = scorer;\n          }\n          @Override\n          public void collect(int doc) throws IOException {\n            assert doc >= min;\n            assert doc < max;\n            Assert.assertEquals(scorer.docID(), doc);\n            Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);\n            scorer.nextDoc();\n          }\n        }, min, max);\n        assert max <= next;\n        assert next <= scorer.docID();\n        upTo = max;\n\n        if (scorer.docID() == DocIdSetIterator.NO_MORE_DOCS) {\n          bulkScorer.score(new LeafCollector() {\n            @Override\n            public void setScorer(Scorer scorer) throws IOException {}\n            \n            @Override\n            public void collect(int doc) throws IOException {\n              // no more matches\n              assert false;\n            }\n          }, upTo, DocIdSetIterator.NO_MORE_DOCS);\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /** Check that the scorer and bulk scorer advance consistently. */\n  public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {\n    Weight weight = searcher.createNormalizedWeight(query, true);\n    for (LeafReaderContext context : searcher.getIndexReader().leaves()) {\n      final Scorer scorer = weight.scorer(context, context.reader().getLiveDocs());\n      final BulkScorer bulkScorer = weight.bulkScorer(context, context.reader().getLiveDocs());\n      if (scorer == null && bulkScorer == null) {\n        continue;\n      }\n      int upTo = 0;\n      while (true) {\n        final int min = upTo + r.nextInt(5);\n        final int max = min + 1 + r.nextInt(r.nextBoolean() ? 10 : 5000);\n        if (scorer.docID() < min) {\n          scorer.advance(min);\n        }\n        final int next = bulkScorer.score(new LeafCollector() {\n          Scorer scorer2;\n          @Override\n          public void setScorer(Scorer scorer) throws IOException {\n            this.scorer2 = scorer;\n          }\n          @Override\n          public void collect(int doc) throws IOException {\n            assert doc >= min;\n            assert doc < max;\n            Assert.assertEquals(scorer.docID(), doc);\n            Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);\n            scorer.nextDoc();\n          }\n        }, min, max);\n        assert max <= next;\n        assert next <= scorer.docID();\n        upTo = max;\n\n        if (scorer.docID() == DocIdSetIterator.NO_MORE_DOCS) {\n          bulkScorer.score(new LeafCollector() {\n            @Override\n            public void setScorer(Scorer scorer) throws IOException {}\n            \n            @Override\n            public void collect(int doc) throws IOException {\n              // no more matches\n              assert false;\n            }\n          }, upTo, DocIdSetIterator.NO_MORE_DOCS);\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6a47d642ab24da1a811adce4bda9cc52c520ca13","date":1423483323,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","sourceNew":"  /** Check that the scorer and bulk scorer advance consistently. */\n  public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {\n    Weight weight = searcher.createNormalizedWeight(query, true);\n    for (LeafReaderContext context : searcher.getIndexReader().leaves()) {\n      final Scorer scorer = weight.scorer(context, context.reader().getLiveDocs());\n      final BulkScorer bulkScorer = weight.bulkScorer(context, context.reader().getLiveDocs());\n      if (scorer == null && bulkScorer == null) {\n        continue;\n      }\n      int upTo = 0;\n      while (true) {\n        final int min = upTo + r.nextInt(5);\n        final int max = min + 1 + r.nextInt(r.nextBoolean() ? 10 : 5000);\n        if (scorer.docID() < min) {\n          scorer.advance(min);\n        }\n        final int next = bulkScorer.score(new LeafCollector() {\n          Scorer scorer2;\n          @Override\n          public void setScorer(Scorer scorer) throws IOException {\n            this.scorer2 = scorer;\n          }\n          @Override\n          public void collect(int doc) throws IOException {\n            assert doc >= min;\n            assert doc < max;\n            Assert.assertEquals(scorer.docID(), doc);\n            Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);\n            scorer.nextDoc();\n          }\n        }, min, max);\n        assert max <= next;\n        assert next <= scorer.docID();\n        upTo = max;\n\n        if (scorer.docID() == DocIdSetIterator.NO_MORE_DOCS) {\n          bulkScorer.score(new LeafCollector() {\n            @Override\n            public void setScorer(Scorer scorer) throws IOException {}\n            \n            @Override\n            public void collect(int doc) throws IOException {\n              // no more matches\n              assert false;\n            }\n          }, upTo, DocIdSetIterator.NO_MORE_DOCS);\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /** Check that the scorer and bulk scorer advance consistently. */\n  public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {\n    Weight weight = searcher.createNormalizedWeight(query, PostingsEnum.FLAG_FREQS);\n    for (LeafReaderContext context : searcher.getIndexReader().leaves()) {\n      final Scorer scorer = weight.scorer(context, context.reader().getLiveDocs());\n      final BulkScorer bulkScorer = weight.bulkScorer(context, context.reader().getLiveDocs());\n      if (scorer == null && bulkScorer == null) {\n        continue;\n      }\n      int upTo = 0;\n      while (true) {\n        final int min = upTo + r.nextInt(5);\n        final int max = min + 1 + r.nextInt(r.nextBoolean() ? 10 : 5000);\n        if (scorer.docID() < min) {\n          scorer.advance(min);\n        }\n        final int next = bulkScorer.score(new LeafCollector() {\n          Scorer scorer2;\n          @Override\n          public void setScorer(Scorer scorer) throws IOException {\n            this.scorer2 = scorer;\n          }\n          @Override\n          public void collect(int doc) throws IOException {\n            assert doc >= min;\n            assert doc < max;\n            Assert.assertEquals(scorer.docID(), doc);\n            Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);\n            scorer.nextDoc();\n          }\n        }, min, max);\n        assert max <= next;\n        assert next <= scorer.docID();\n        upTo = max;\n\n        if (scorer.docID() == DocIdSetIterator.NO_MORE_DOCS) {\n          bulkScorer.score(new LeafCollector() {\n            @Override\n            public void setScorer(Scorer scorer) throws IOException {}\n            \n            @Override\n            public void collect(int doc) throws IOException {\n              // no more matches\n              assert false;\n            }\n          }, upTo, DocIdSetIterator.NO_MORE_DOCS);\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ac49815905092460136aaebc1233126677405045","date":1430220691,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","sourceNew":"  /** Check that the scorer and bulk scorer advance consistently. */\n  public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {\n    Weight weight = searcher.createNormalizedWeight(query, true);\n    for (LeafReaderContext context : searcher.getIndexReader().leaves()) {\n      final Scorer scorer = weight.scorer(context, context.reader().getLiveDocs());\n      final BulkScorer bulkScorer = weight.bulkScorer(context, context.reader().getLiveDocs());\n      if (scorer == null && bulkScorer == null) {\n        continue;\n      } else if (bulkScorer == null) {\n        // ensure scorer is exhausted (it just didnt return null)\n        assert scorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS;\n        continue;\n      }\n      int upTo = 0;\n      while (true) {\n        final int min = upTo + r.nextInt(5);\n        final int max = min + 1 + r.nextInt(r.nextBoolean() ? 10 : 5000);\n        if (scorer.docID() < min) {\n          scorer.advance(min);\n        }\n        final int next = bulkScorer.score(new LeafCollector() {\n          Scorer scorer2;\n          @Override\n          public void setScorer(Scorer scorer) throws IOException {\n            this.scorer2 = scorer;\n          }\n          @Override\n          public void collect(int doc) throws IOException {\n            assert doc >= min;\n            assert doc < max;\n            Assert.assertEquals(scorer.docID(), doc);\n            Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);\n            scorer.nextDoc();\n          }\n        }, min, max);\n        assert max <= next;\n        assert next <= scorer.docID();\n        upTo = max;\n\n        if (scorer.docID() == DocIdSetIterator.NO_MORE_DOCS) {\n          bulkScorer.score(new LeafCollector() {\n            @Override\n            public void setScorer(Scorer scorer) throws IOException {}\n            \n            @Override\n            public void collect(int doc) throws IOException {\n              // no more matches\n              assert false;\n            }\n          }, upTo, DocIdSetIterator.NO_MORE_DOCS);\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /** Check that the scorer and bulk scorer advance consistently. */\n  public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {\n    Weight weight = searcher.createNormalizedWeight(query, true);\n    for (LeafReaderContext context : searcher.getIndexReader().leaves()) {\n      final Scorer scorer = weight.scorer(context, context.reader().getLiveDocs());\n      final BulkScorer bulkScorer = weight.bulkScorer(context, context.reader().getLiveDocs());\n      if (scorer == null && bulkScorer == null) {\n        continue;\n      }\n      int upTo = 0;\n      while (true) {\n        final int min = upTo + r.nextInt(5);\n        final int max = min + 1 + r.nextInt(r.nextBoolean() ? 10 : 5000);\n        if (scorer.docID() < min) {\n          scorer.advance(min);\n        }\n        final int next = bulkScorer.score(new LeafCollector() {\n          Scorer scorer2;\n          @Override\n          public void setScorer(Scorer scorer) throws IOException {\n            this.scorer2 = scorer;\n          }\n          @Override\n          public void collect(int doc) throws IOException {\n            assert doc >= min;\n            assert doc < max;\n            Assert.assertEquals(scorer.docID(), doc);\n            Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);\n            scorer.nextDoc();\n          }\n        }, min, max);\n        assert max <= next;\n        assert next <= scorer.docID();\n        upTo = max;\n\n        if (scorer.docID() == DocIdSetIterator.NO_MORE_DOCS) {\n          bulkScorer.score(new LeafCollector() {\n            @Override\n            public void setScorer(Scorer scorer) throws IOException {}\n            \n            @Override\n            public void collect(int doc) throws IOException {\n              // no more matches\n              assert false;\n            }\n          }, upTo, DocIdSetIterator.NO_MORE_DOCS);\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f4464508ee83288c8c4585b533f9faaa93aa314","date":1435240759,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","sourceNew":"  /** Check that the scorer and bulk scorer advance consistently. */\n  public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {\n    Weight weight = searcher.createNormalizedWeight(query, true);\n    for (LeafReaderContext context : searcher.getIndexReader().leaves()) {\n      final Scorer scorer = weight.scorer(context);\n      final BulkScorer bulkScorer = weight.bulkScorer(context);\n      if (scorer == null && bulkScorer == null) {\n        continue;\n      } else if (bulkScorer == null) {\n        // ensure scorer is exhausted (it just didnt return null)\n        assert scorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS;\n        continue;\n      }\n      int upTo = 0;\n      while (true) {\n        final int min = upTo + r.nextInt(5);\n        final int max = min + 1 + r.nextInt(r.nextBoolean() ? 10 : 5000);\n        if (scorer.docID() < min) {\n          scorer.advance(min);\n        }\n        final int next = bulkScorer.score(new LeafCollector() {\n          Scorer scorer2;\n          @Override\n          public void setScorer(Scorer scorer) throws IOException {\n            this.scorer2 = scorer;\n          }\n          @Override\n          public void collect(int doc) throws IOException {\n            assert doc >= min;\n            assert doc < max;\n            Assert.assertEquals(scorer.docID(), doc);\n            Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);\n            scorer.nextDoc();\n          }\n        }, null, min, max);\n        assert max <= next;\n        assert next <= scorer.docID();\n        upTo = max;\n\n        if (scorer.docID() == DocIdSetIterator.NO_MORE_DOCS) {\n          bulkScorer.score(new LeafCollector() {\n            @Override\n            public void setScorer(Scorer scorer) throws IOException {}\n            \n            @Override\n            public void collect(int doc) throws IOException {\n              // no more matches\n              assert false;\n            }\n          }, null, upTo, DocIdSetIterator.NO_MORE_DOCS);\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /** Check that the scorer and bulk scorer advance consistently. */\n  public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {\n    Weight weight = searcher.createNormalizedWeight(query, true);\n    for (LeafReaderContext context : searcher.getIndexReader().leaves()) {\n      final Scorer scorer = weight.scorer(context, context.reader().getLiveDocs());\n      final BulkScorer bulkScorer = weight.bulkScorer(context, context.reader().getLiveDocs());\n      if (scorer == null && bulkScorer == null) {\n        continue;\n      } else if (bulkScorer == null) {\n        // ensure scorer is exhausted (it just didnt return null)\n        assert scorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS;\n        continue;\n      }\n      int upTo = 0;\n      while (true) {\n        final int min = upTo + r.nextInt(5);\n        final int max = min + 1 + r.nextInt(r.nextBoolean() ? 10 : 5000);\n        if (scorer.docID() < min) {\n          scorer.advance(min);\n        }\n        final int next = bulkScorer.score(new LeafCollector() {\n          Scorer scorer2;\n          @Override\n          public void setScorer(Scorer scorer) throws IOException {\n            this.scorer2 = scorer;\n          }\n          @Override\n          public void collect(int doc) throws IOException {\n            assert doc >= min;\n            assert doc < max;\n            Assert.assertEquals(scorer.docID(), doc);\n            Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);\n            scorer.nextDoc();\n          }\n        }, min, max);\n        assert max <= next;\n        assert next <= scorer.docID();\n        upTo = max;\n\n        if (scorer.docID() == DocIdSetIterator.NO_MORE_DOCS) {\n          bulkScorer.score(new LeafCollector() {\n            @Override\n            public void setScorer(Scorer scorer) throws IOException {}\n            \n            @Override\n            public void collect(int doc) throws IOException {\n              // no more matches\n              assert false;\n            }\n          }, upTo, DocIdSetIterator.NO_MORE_DOCS);\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7dd748bb245633a8195281556bb0e68a6ea97d18","date":1449755030,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","sourceNew":"  /** Check that the scorer and bulk scorer advance consistently. */\n  public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {\n    Weight weight = searcher.createNormalizedWeight(query, true);\n    for (LeafReaderContext context : searcher.getIndexReader().leaves()) {\n      final Scorer scorer = weight.scorer(context);\n      final BulkScorer bulkScorer = weight.bulkScorer(context);\n      if (scorer == null && bulkScorer == null) {\n        continue;\n      } else if (bulkScorer == null) {\n        // ensure scorer is exhausted (it just didnt return null)\n        assert scorer.iterator().nextDoc() == DocIdSetIterator.NO_MORE_DOCS;\n        continue;\n      }\n      DocIdSetIterator iterator = scorer.iterator();\n      int upTo = 0;\n      while (true) {\n        final int min = upTo + r.nextInt(5);\n        final int max = min + 1 + r.nextInt(r.nextBoolean() ? 10 : 5000);\n        if (scorer.docID() < min) {\n          iterator.advance(min);\n        }\n        final int next = bulkScorer.score(new LeafCollector() {\n          Scorer scorer2;\n          @Override\n          public void setScorer(Scorer scorer) throws IOException {\n            this.scorer2 = scorer;\n          }\n          @Override\n          public void collect(int doc) throws IOException {\n            assert doc >= min;\n            assert doc < max;\n            Assert.assertEquals(scorer.docID(), doc);\n            Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);\n            iterator.nextDoc();\n          }\n        }, null, min, max);\n        assert max <= next;\n        assert next <= scorer.docID();\n        upTo = max;\n\n        if (scorer.docID() == DocIdSetIterator.NO_MORE_DOCS) {\n          bulkScorer.score(new LeafCollector() {\n            @Override\n            public void setScorer(Scorer scorer) throws IOException {}\n            \n            @Override\n            public void collect(int doc) throws IOException {\n              // no more matches\n              assert false;\n            }\n          }, null, upTo, DocIdSetIterator.NO_MORE_DOCS);\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /** Check that the scorer and bulk scorer advance consistently. */\n  public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {\n    Weight weight = searcher.createNormalizedWeight(query, true);\n    for (LeafReaderContext context : searcher.getIndexReader().leaves()) {\n      final Scorer scorer = weight.scorer(context);\n      final BulkScorer bulkScorer = weight.bulkScorer(context);\n      if (scorer == null && bulkScorer == null) {\n        continue;\n      } else if (bulkScorer == null) {\n        // ensure scorer is exhausted (it just didnt return null)\n        assert scorer.nextDoc() == DocIdSetIterator.NO_MORE_DOCS;\n        continue;\n      }\n      int upTo = 0;\n      while (true) {\n        final int min = upTo + r.nextInt(5);\n        final int max = min + 1 + r.nextInt(r.nextBoolean() ? 10 : 5000);\n        if (scorer.docID() < min) {\n          scorer.advance(min);\n        }\n        final int next = bulkScorer.score(new LeafCollector() {\n          Scorer scorer2;\n          @Override\n          public void setScorer(Scorer scorer) throws IOException {\n            this.scorer2 = scorer;\n          }\n          @Override\n          public void collect(int doc) throws IOException {\n            assert doc >= min;\n            assert doc < max;\n            Assert.assertEquals(scorer.docID(), doc);\n            Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);\n            scorer.nextDoc();\n          }\n        }, null, min, max);\n        assert max <= next;\n        assert next <= scorer.docID();\n        upTo = max;\n\n        if (scorer.docID() == DocIdSetIterator.NO_MORE_DOCS) {\n          bulkScorer.score(new LeafCollector() {\n            @Override\n            public void setScorer(Scorer scorer) throws IOException {}\n            \n            @Override\n            public void collect(int doc) throws IOException {\n              // no more matches\n              assert false;\n            }\n          }, null, upTo, DocIdSetIterator.NO_MORE_DOCS);\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0e7bc21595222ae4f75509300fbb7726691f387f","date":1464078795,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","sourceNew":"  /** Check that the scorer and bulk scorer advance consistently. */\n  public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {\n    Weight weight = searcher.createNormalizedWeight(query, true);\n    for (LeafReaderContext context : searcher.getIndexReader().leaves()) {\n      final Scorer scorer = weight.scorer(context);\n      final BulkScorer bulkScorer = weight.bulkScorer(context);\n      if (scorer == null && bulkScorer == null) {\n        continue;\n      } else if (bulkScorer == null) {\n        // ensure scorer is exhausted (it just didnt return null)\n        assert scorer.iterator().nextDoc() == DocIdSetIterator.NO_MORE_DOCS;\n        continue;\n      }\n      DocIdSetIterator iterator = scorer.iterator();\n      int upTo = 0;\n      while (true) {\n        final int min = upTo + r.nextInt(5);\n        final int max = min + 1 + r.nextInt(r.nextBoolean() ? 10 : 5000);\n        if (scorer.docID() < min) {\n          iterator.advance(min);\n        }\n        final int next = bulkScorer.score(new LeafCollector() {\n          Scorer scorer2;\n          @Override\n          public void setScorer(Scorer scorer) throws IOException {\n            this.scorer2 = scorer;\n          }\n          @Override\n          public void collect(int doc) throws IOException {\n            assert doc >= min;\n            assert doc < max;\n            Assert.assertEquals(scorer.docID(), doc);\n            Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);\n            iterator.nextDoc();\n          }\n        }, null, min, max);\n        assert max <= next;\n        assert next <= scorer.docID();\n        upTo = max;\n\n        if (scorer.docID() == DocIdSetIterator.NO_MORE_DOCS) {\n          bulkScorer.score(new LeafCollector() {\n            @Override\n            public void setScorer(Scorer scorer) throws IOException {}\n\n            @Override\n            public void collect(int doc) throws IOException {\n              // no more matches\n              assert false;\n            }\n          }, null, upTo, DocIdSetIterator.NO_MORE_DOCS);\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /** Check that the scorer and bulk scorer advance consistently. */\n  public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {\n    Weight weight = searcher.createNormalizedWeight(query, true);\n    for (LeafReaderContext context : searcher.getIndexReader().leaves()) {\n      final Scorer scorer = weight.scorer(context);\n      final BulkScorer bulkScorer = weight.bulkScorer(context);\n      if (scorer == null && bulkScorer == null) {\n        continue;\n      } else if (bulkScorer == null) {\n        // ensure scorer is exhausted (it just didnt return null)\n        assert scorer.iterator().nextDoc() == DocIdSetIterator.NO_MORE_DOCS;\n        continue;\n      }\n      DocIdSetIterator iterator = scorer.iterator();\n      int upTo = 0;\n      while (true) {\n        final int min = upTo + r.nextInt(5);\n        final int max = min + 1 + r.nextInt(r.nextBoolean() ? 10 : 5000);\n        if (scorer.docID() < min) {\n          iterator.advance(min);\n        }\n        final int next = bulkScorer.score(new LeafCollector() {\n          Scorer scorer2;\n          @Override\n          public void setScorer(Scorer scorer) throws IOException {\n            this.scorer2 = scorer;\n          }\n          @Override\n          public void collect(int doc) throws IOException {\n            assert doc >= min;\n            assert doc < max;\n            Assert.assertEquals(scorer.docID(), doc);\n            Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);\n            iterator.nextDoc();\n          }\n        }, null, min, max);\n        assert max <= next;\n        assert next <= scorer.docID();\n        upTo = max;\n\n        if (scorer.docID() == DocIdSetIterator.NO_MORE_DOCS) {\n          bulkScorer.score(new LeafCollector() {\n            @Override\n            public void setScorer(Scorer scorer) throws IOException {}\n            \n            @Override\n            public void collect(int doc) throws IOException {\n              // no more matches\n              assert false;\n            }\n          }, null, upTo, DocIdSetIterator.NO_MORE_DOCS);\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","sourceNew":"  /** Check that the scorer and bulk scorer advance consistently. */\n  public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {\n    Weight weight = searcher.createNormalizedWeight(query, true);\n    for (LeafReaderContext context : searcher.getIndexReader().leaves()) {\n      final Scorer scorer = weight.scorer(context);\n      final BulkScorer bulkScorer = weight.bulkScorer(context);\n      if (scorer == null && bulkScorer == null) {\n        continue;\n      } else if (bulkScorer == null) {\n        // ensure scorer is exhausted (it just didnt return null)\n        assert scorer.iterator().nextDoc() == DocIdSetIterator.NO_MORE_DOCS;\n        continue;\n      }\n      DocIdSetIterator iterator = scorer.iterator();\n      int upTo = 0;\n      while (true) {\n        final int min = upTo + r.nextInt(5);\n        final int max = min + 1 + r.nextInt(r.nextBoolean() ? 10 : 5000);\n        if (scorer.docID() < min) {\n          iterator.advance(min);\n        }\n        final int next = bulkScorer.score(new LeafCollector() {\n          Scorer scorer2;\n          @Override\n          public void setScorer(Scorer scorer) throws IOException {\n            this.scorer2 = scorer;\n          }\n          @Override\n          public void collect(int doc) throws IOException {\n            assert doc >= min;\n            assert doc < max;\n            Assert.assertEquals(scorer.docID(), doc);\n            Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);\n            iterator.nextDoc();\n          }\n        }, null, min, max);\n        assert max <= next;\n        assert next <= scorer.docID();\n        upTo = max;\n\n        if (scorer.docID() == DocIdSetIterator.NO_MORE_DOCS) {\n          bulkScorer.score(new LeafCollector() {\n            @Override\n            public void setScorer(Scorer scorer) throws IOException {}\n\n            @Override\n            public void collect(int doc) throws IOException {\n              // no more matches\n              assert false;\n            }\n          }, null, upTo, DocIdSetIterator.NO_MORE_DOCS);\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /** Check that the scorer and bulk scorer advance consistently. */\n  public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {\n    Weight weight = searcher.createNormalizedWeight(query, true);\n    for (LeafReaderContext context : searcher.getIndexReader().leaves()) {\n      final Scorer scorer = weight.scorer(context);\n      final BulkScorer bulkScorer = weight.bulkScorer(context);\n      if (scorer == null && bulkScorer == null) {\n        continue;\n      } else if (bulkScorer == null) {\n        // ensure scorer is exhausted (it just didnt return null)\n        assert scorer.iterator().nextDoc() == DocIdSetIterator.NO_MORE_DOCS;\n        continue;\n      }\n      DocIdSetIterator iterator = scorer.iterator();\n      int upTo = 0;\n      while (true) {\n        final int min = upTo + r.nextInt(5);\n        final int max = min + 1 + r.nextInt(r.nextBoolean() ? 10 : 5000);\n        if (scorer.docID() < min) {\n          iterator.advance(min);\n        }\n        final int next = bulkScorer.score(new LeafCollector() {\n          Scorer scorer2;\n          @Override\n          public void setScorer(Scorer scorer) throws IOException {\n            this.scorer2 = scorer;\n          }\n          @Override\n          public void collect(int doc) throws IOException {\n            assert doc >= min;\n            assert doc < max;\n            Assert.assertEquals(scorer.docID(), doc);\n            Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);\n            iterator.nextDoc();\n          }\n        }, null, min, max);\n        assert max <= next;\n        assert next <= scorer.docID();\n        upTo = max;\n\n        if (scorer.docID() == DocIdSetIterator.NO_MORE_DOCS) {\n          bulkScorer.score(new LeafCollector() {\n            @Override\n            public void setScorer(Scorer scorer) throws IOException {}\n            \n            @Override\n            public void collect(int doc) throws IOException {\n              // no more matches\n              assert false;\n            }\n          }, null, upTo, DocIdSetIterator.NO_MORE_DOCS);\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9fc47cb7b4346802411bb432f501ed0673d7119e","date":1512640179,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","sourceNew":"  /** Check that the scorer and bulk scorer advance consistently. */\n  public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {\n    Weight weight = searcher.createNormalizedWeight(query, ScoreMode.COMPLETE);\n    for (LeafReaderContext context : searcher.getIndexReader().leaves()) {\n      final Scorer scorer = weight.scorer(context);\n      final BulkScorer bulkScorer = weight.bulkScorer(context);\n      if (scorer == null && bulkScorer == null) {\n        continue;\n      } else if (bulkScorer == null) {\n        // ensure scorer is exhausted (it just didnt return null)\n        assert scorer.iterator().nextDoc() == DocIdSetIterator.NO_MORE_DOCS;\n        continue;\n      }\n      DocIdSetIterator iterator = scorer.iterator();\n      int upTo = 0;\n      while (true) {\n        final int min = upTo + r.nextInt(5);\n        final int max = min + 1 + r.nextInt(r.nextBoolean() ? 10 : 5000);\n        if (scorer.docID() < min) {\n          iterator.advance(min);\n        }\n        final int next = bulkScorer.score(new LeafCollector() {\n          Scorer scorer2;\n          @Override\n          public void setScorer(Scorer scorer) throws IOException {\n            this.scorer2 = scorer;\n          }\n          @Override\n          public void collect(int doc) throws IOException {\n            assert doc >= min;\n            assert doc < max;\n            Assert.assertEquals(scorer.docID(), doc);\n            Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);\n            iterator.nextDoc();\n          }\n        }, null, min, max);\n        assert max <= next;\n        assert next <= scorer.docID();\n        upTo = max;\n\n        if (scorer.docID() == DocIdSetIterator.NO_MORE_DOCS) {\n          bulkScorer.score(new LeafCollector() {\n            @Override\n            public void setScorer(Scorer scorer) throws IOException {}\n\n            @Override\n            public void collect(int doc) throws IOException {\n              // no more matches\n              assert false;\n            }\n          }, null, upTo, DocIdSetIterator.NO_MORE_DOCS);\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /** Check that the scorer and bulk scorer advance consistently. */\n  public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {\n    Weight weight = searcher.createNormalizedWeight(query, true);\n    for (LeafReaderContext context : searcher.getIndexReader().leaves()) {\n      final Scorer scorer = weight.scorer(context);\n      final BulkScorer bulkScorer = weight.bulkScorer(context);\n      if (scorer == null && bulkScorer == null) {\n        continue;\n      } else if (bulkScorer == null) {\n        // ensure scorer is exhausted (it just didnt return null)\n        assert scorer.iterator().nextDoc() == DocIdSetIterator.NO_MORE_DOCS;\n        continue;\n      }\n      DocIdSetIterator iterator = scorer.iterator();\n      int upTo = 0;\n      while (true) {\n        final int min = upTo + r.nextInt(5);\n        final int max = min + 1 + r.nextInt(r.nextBoolean() ? 10 : 5000);\n        if (scorer.docID() < min) {\n          iterator.advance(min);\n        }\n        final int next = bulkScorer.score(new LeafCollector() {\n          Scorer scorer2;\n          @Override\n          public void setScorer(Scorer scorer) throws IOException {\n            this.scorer2 = scorer;\n          }\n          @Override\n          public void collect(int doc) throws IOException {\n            assert doc >= min;\n            assert doc < max;\n            Assert.assertEquals(scorer.docID(), doc);\n            Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);\n            iterator.nextDoc();\n          }\n        }, null, min, max);\n        assert max <= next;\n        assert next <= scorer.docID();\n        upTo = max;\n\n        if (scorer.docID() == DocIdSetIterator.NO_MORE_DOCS) {\n          bulkScorer.score(new LeafCollector() {\n            @Override\n            public void setScorer(Scorer scorer) throws IOException {}\n\n            @Override\n            public void collect(int doc) throws IOException {\n              // no more matches\n              assert false;\n            }\n          }, null, upTo, DocIdSetIterator.NO_MORE_DOCS);\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"417142ff08fda9cf0b72d5133e63097a166c6458","date":1512729693,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","sourceNew":"  /** Check that the scorer and bulk scorer advance consistently. */\n  public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {\n    Weight weight = searcher.createNormalizedWeight(query, ScoreMode.COMPLETE);\n    for (LeafReaderContext context : searcher.getIndexReader().leaves()) {\n      final Scorer scorer = weight.scorer(context);\n      final BulkScorer bulkScorer = weight.bulkScorer(context);\n      if (scorer == null && bulkScorer == null) {\n        continue;\n      } else if (bulkScorer == null) {\n        // ensure scorer is exhausted (it just didnt return null)\n        assert scorer.iterator().nextDoc() == DocIdSetIterator.NO_MORE_DOCS;\n        continue;\n      }\n      DocIdSetIterator iterator = scorer.iterator();\n      int upTo = 0;\n      while (true) {\n        final int min = upTo + r.nextInt(5);\n        final int max = min + 1 + r.nextInt(r.nextBoolean() ? 10 : 5000);\n        if (scorer.docID() < min) {\n          iterator.advance(min);\n        }\n        final int next = bulkScorer.score(new LeafCollector() {\n          Scorer scorer2;\n          @Override\n          public void setScorer(Scorer scorer) throws IOException {\n            this.scorer2 = scorer;\n          }\n          @Override\n          public void collect(int doc) throws IOException {\n            assert doc >= min;\n            assert doc < max;\n            Assert.assertEquals(scorer.docID(), doc);\n            Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);\n            iterator.nextDoc();\n          }\n        }, null, min, max);\n        assert max <= next;\n        assert next <= scorer.docID();\n        upTo = max;\n\n        if (scorer.docID() == DocIdSetIterator.NO_MORE_DOCS) {\n          bulkScorer.score(new LeafCollector() {\n            @Override\n            public void setScorer(Scorer scorer) throws IOException {}\n\n            @Override\n            public void collect(int doc) throws IOException {\n              // no more matches\n              assert false;\n            }\n          }, null, upTo, DocIdSetIterator.NO_MORE_DOCS);\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /** Check that the scorer and bulk scorer advance consistently. */\n  public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {\n    Weight weight = searcher.createNormalizedWeight(query, true);\n    for (LeafReaderContext context : searcher.getIndexReader().leaves()) {\n      final Scorer scorer = weight.scorer(context);\n      final BulkScorer bulkScorer = weight.bulkScorer(context);\n      if (scorer == null && bulkScorer == null) {\n        continue;\n      } else if (bulkScorer == null) {\n        // ensure scorer is exhausted (it just didnt return null)\n        assert scorer.iterator().nextDoc() == DocIdSetIterator.NO_MORE_DOCS;\n        continue;\n      }\n      DocIdSetIterator iterator = scorer.iterator();\n      int upTo = 0;\n      while (true) {\n        final int min = upTo + r.nextInt(5);\n        final int max = min + 1 + r.nextInt(r.nextBoolean() ? 10 : 5000);\n        if (scorer.docID() < min) {\n          iterator.advance(min);\n        }\n        final int next = bulkScorer.score(new LeafCollector() {\n          Scorer scorer2;\n          @Override\n          public void setScorer(Scorer scorer) throws IOException {\n            this.scorer2 = scorer;\n          }\n          @Override\n          public void collect(int doc) throws IOException {\n            assert doc >= min;\n            assert doc < max;\n            Assert.assertEquals(scorer.docID(), doc);\n            Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);\n            iterator.nextDoc();\n          }\n        }, null, min, max);\n        assert max <= next;\n        assert next <= scorer.docID();\n        upTo = max;\n\n        if (scorer.docID() == DocIdSetIterator.NO_MORE_DOCS) {\n          bulkScorer.score(new LeafCollector() {\n            @Override\n            public void setScorer(Scorer scorer) throws IOException {}\n\n            @Override\n            public void collect(int doc) throws IOException {\n              // no more matches\n              assert false;\n            }\n          }, null, upTo, DocIdSetIterator.NO_MORE_DOCS);\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"475584d5e08a22ad3fc7babefe006d77bc744567","date":1523282824,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","sourceNew":"  /** Check that the scorer and bulk scorer advance consistently. */\n  public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {\n    query = searcher.rewrite(query);\n    Weight weight = searcher.createWeight(query, ScoreMode.COMPLETE, 1);\n    for (LeafReaderContext context : searcher.getIndexReader().leaves()) {\n      final Scorer scorer = weight.scorer(context);\n      final BulkScorer bulkScorer = weight.bulkScorer(context);\n      if (scorer == null && bulkScorer == null) {\n        continue;\n      } else if (bulkScorer == null) {\n        // ensure scorer is exhausted (it just didnt return null)\n        assert scorer.iterator().nextDoc() == DocIdSetIterator.NO_MORE_DOCS;\n        continue;\n      }\n      DocIdSetIterator iterator = scorer.iterator();\n      int upTo = 0;\n      while (true) {\n        final int min = upTo + r.nextInt(5);\n        final int max = min + 1 + r.nextInt(r.nextBoolean() ? 10 : 5000);\n        if (scorer.docID() < min) {\n          iterator.advance(min);\n        }\n        final int next = bulkScorer.score(new LeafCollector() {\n          Scorer scorer2;\n          @Override\n          public void setScorer(Scorer scorer) throws IOException {\n            this.scorer2 = scorer;\n          }\n          @Override\n          public void collect(int doc) throws IOException {\n            assert doc >= min;\n            assert doc < max;\n            Assert.assertEquals(scorer.docID(), doc);\n            Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);\n            iterator.nextDoc();\n          }\n        }, null, min, max);\n        assert max <= next;\n        assert next <= scorer.docID();\n        upTo = max;\n\n        if (scorer.docID() == DocIdSetIterator.NO_MORE_DOCS) {\n          bulkScorer.score(new LeafCollector() {\n            @Override\n            public void setScorer(Scorer scorer) throws IOException {}\n\n            @Override\n            public void collect(int doc) throws IOException {\n              // no more matches\n              assert false;\n            }\n          }, null, upTo, DocIdSetIterator.NO_MORE_DOCS);\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /** Check that the scorer and bulk scorer advance consistently. */\n  public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {\n    Weight weight = searcher.createNormalizedWeight(query, ScoreMode.COMPLETE);\n    for (LeafReaderContext context : searcher.getIndexReader().leaves()) {\n      final Scorer scorer = weight.scorer(context);\n      final BulkScorer bulkScorer = weight.bulkScorer(context);\n      if (scorer == null && bulkScorer == null) {\n        continue;\n      } else if (bulkScorer == null) {\n        // ensure scorer is exhausted (it just didnt return null)\n        assert scorer.iterator().nextDoc() == DocIdSetIterator.NO_MORE_DOCS;\n        continue;\n      }\n      DocIdSetIterator iterator = scorer.iterator();\n      int upTo = 0;\n      while (true) {\n        final int min = upTo + r.nextInt(5);\n        final int max = min + 1 + r.nextInt(r.nextBoolean() ? 10 : 5000);\n        if (scorer.docID() < min) {\n          iterator.advance(min);\n        }\n        final int next = bulkScorer.score(new LeafCollector() {\n          Scorer scorer2;\n          @Override\n          public void setScorer(Scorer scorer) throws IOException {\n            this.scorer2 = scorer;\n          }\n          @Override\n          public void collect(int doc) throws IOException {\n            assert doc >= min;\n            assert doc < max;\n            Assert.assertEquals(scorer.docID(), doc);\n            Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);\n            iterator.nextDoc();\n          }\n        }, null, min, max);\n        assert max <= next;\n        assert next <= scorer.docID();\n        upTo = max;\n\n        if (scorer.docID() == DocIdSetIterator.NO_MORE_DOCS) {\n          bulkScorer.score(new LeafCollector() {\n            @Override\n            public void setScorer(Scorer scorer) throws IOException {}\n\n            @Override\n            public void collect(int doc) throws IOException {\n              // no more matches\n              assert false;\n            }\n          }, null, upTo, DocIdSetIterator.NO_MORE_DOCS);\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d58e44159788900f4a2113b84463dc3fbbf80f20","date":1523319203,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","sourceNew":"  /** Check that the scorer and bulk scorer advance consistently. */\n  public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {\n    query = searcher.rewrite(query);\n    Weight weight = searcher.createWeight(query, ScoreMode.COMPLETE, 1);\n    for (LeafReaderContext context : searcher.getIndexReader().leaves()) {\n      final Scorer scorer = weight.scorer(context);\n      final BulkScorer bulkScorer = weight.bulkScorer(context);\n      if (scorer == null && bulkScorer == null) {\n        continue;\n      } else if (bulkScorer == null) {\n        // ensure scorer is exhausted (it just didnt return null)\n        assert scorer.iterator().nextDoc() == DocIdSetIterator.NO_MORE_DOCS;\n        continue;\n      }\n      DocIdSetIterator iterator = scorer.iterator();\n      int upTo = 0;\n      while (true) {\n        final int min = upTo + r.nextInt(5);\n        final int max = min + 1 + r.nextInt(r.nextBoolean() ? 10 : 5000);\n        if (scorer.docID() < min) {\n          iterator.advance(min);\n        }\n        final int next = bulkScorer.score(new LeafCollector() {\n          Scorer scorer2;\n          @Override\n          public void setScorer(Scorer scorer) throws IOException {\n            this.scorer2 = scorer;\n          }\n          @Override\n          public void collect(int doc) throws IOException {\n            assert doc >= min;\n            assert doc < max;\n            Assert.assertEquals(scorer.docID(), doc);\n            Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);\n            iterator.nextDoc();\n          }\n        }, null, min, max);\n        assert max <= next;\n        assert next <= scorer.docID();\n        upTo = max;\n\n        if (scorer.docID() == DocIdSetIterator.NO_MORE_DOCS) {\n          bulkScorer.score(new LeafCollector() {\n            @Override\n            public void setScorer(Scorer scorer) throws IOException {}\n\n            @Override\n            public void collect(int doc) throws IOException {\n              // no more matches\n              assert false;\n            }\n          }, null, upTo, DocIdSetIterator.NO_MORE_DOCS);\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /** Check that the scorer and bulk scorer advance consistently. */\n  public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {\n    Weight weight = searcher.createNormalizedWeight(query, ScoreMode.COMPLETE);\n    for (LeafReaderContext context : searcher.getIndexReader().leaves()) {\n      final Scorer scorer = weight.scorer(context);\n      final BulkScorer bulkScorer = weight.bulkScorer(context);\n      if (scorer == null && bulkScorer == null) {\n        continue;\n      } else if (bulkScorer == null) {\n        // ensure scorer is exhausted (it just didnt return null)\n        assert scorer.iterator().nextDoc() == DocIdSetIterator.NO_MORE_DOCS;\n        continue;\n      }\n      DocIdSetIterator iterator = scorer.iterator();\n      int upTo = 0;\n      while (true) {\n        final int min = upTo + r.nextInt(5);\n        final int max = min + 1 + r.nextInt(r.nextBoolean() ? 10 : 5000);\n        if (scorer.docID() < min) {\n          iterator.advance(min);\n        }\n        final int next = bulkScorer.score(new LeafCollector() {\n          Scorer scorer2;\n          @Override\n          public void setScorer(Scorer scorer) throws IOException {\n            this.scorer2 = scorer;\n          }\n          @Override\n          public void collect(int doc) throws IOException {\n            assert doc >= min;\n            assert doc < max;\n            Assert.assertEquals(scorer.docID(), doc);\n            Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);\n            iterator.nextDoc();\n          }\n        }, null, min, max);\n        assert max <= next;\n        assert next <= scorer.docID();\n        upTo = max;\n\n        if (scorer.docID() == DocIdSetIterator.NO_MORE_DOCS) {\n          bulkScorer.score(new LeafCollector() {\n            @Override\n            public void setScorer(Scorer scorer) throws IOException {}\n\n            @Override\n            public void collect(int doc) throws IOException {\n              // no more matches\n              assert false;\n            }\n          }, null, upTo, DocIdSetIterator.NO_MORE_DOCS);\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"285244982ce6aa163d1e60a707f0e6e121736ce5","date":1536055304,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","sourceNew":"  /** Check that the scorer and bulk scorer advance consistently. */\n  public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {\n    query = searcher.rewrite(query);\n    Weight weight = searcher.createWeight(query, ScoreMode.COMPLETE, 1);\n    for (LeafReaderContext context : searcher.getIndexReader().leaves()) {\n      final Scorer scorer = weight.scorer(context);\n      final BulkScorer bulkScorer = weight.bulkScorer(context);\n      if (scorer == null && bulkScorer == null) {\n        continue;\n      } else if (bulkScorer == null) {\n        // ensure scorer is exhausted (it just didnt return null)\n        assert scorer.iterator().nextDoc() == DocIdSetIterator.NO_MORE_DOCS;\n        continue;\n      }\n      DocIdSetIterator iterator = scorer.iterator();\n      int upTo = 0;\n      while (true) {\n        final int min = upTo + r.nextInt(5);\n        final int max = min + 1 + r.nextInt(r.nextBoolean() ? 10 : 5000);\n        if (scorer.docID() < min) {\n          iterator.advance(min);\n        }\n        final int next = bulkScorer.score(new LeafCollector() {\n          Scorable scorer2;\n          @Override\n          public void setScorer(Scorable scorer) throws IOException {\n            this.scorer2 = scorer;\n          }\n          @Override\n          public void collect(int doc) throws IOException {\n            assert doc >= min;\n            assert doc < max;\n            Assert.assertEquals(scorer.docID(), doc);\n            Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);\n            iterator.nextDoc();\n          }\n        }, null, min, max);\n        assert max <= next;\n        assert next <= scorer.docID();\n        upTo = max;\n\n        if (scorer.docID() == DocIdSetIterator.NO_MORE_DOCS) {\n          bulkScorer.score(new LeafCollector() {\n            @Override\n            public void setScorer(Scorable scorer) throws IOException {}\n\n            @Override\n            public void collect(int doc) throws IOException {\n              // no more matches\n              assert false;\n            }\n          }, null, upTo, DocIdSetIterator.NO_MORE_DOCS);\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /** Check that the scorer and bulk scorer advance consistently. */\n  public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {\n    query = searcher.rewrite(query);\n    Weight weight = searcher.createWeight(query, ScoreMode.COMPLETE, 1);\n    for (LeafReaderContext context : searcher.getIndexReader().leaves()) {\n      final Scorer scorer = weight.scorer(context);\n      final BulkScorer bulkScorer = weight.bulkScorer(context);\n      if (scorer == null && bulkScorer == null) {\n        continue;\n      } else if (bulkScorer == null) {\n        // ensure scorer is exhausted (it just didnt return null)\n        assert scorer.iterator().nextDoc() == DocIdSetIterator.NO_MORE_DOCS;\n        continue;\n      }\n      DocIdSetIterator iterator = scorer.iterator();\n      int upTo = 0;\n      while (true) {\n        final int min = upTo + r.nextInt(5);\n        final int max = min + 1 + r.nextInt(r.nextBoolean() ? 10 : 5000);\n        if (scorer.docID() < min) {\n          iterator.advance(min);\n        }\n        final int next = bulkScorer.score(new LeafCollector() {\n          Scorer scorer2;\n          @Override\n          public void setScorer(Scorer scorer) throws IOException {\n            this.scorer2 = scorer;\n          }\n          @Override\n          public void collect(int doc) throws IOException {\n            assert doc >= min;\n            assert doc < max;\n            Assert.assertEquals(scorer.docID(), doc);\n            Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);\n            iterator.nextDoc();\n          }\n        }, null, min, max);\n        assert max <= next;\n        assert next <= scorer.docID();\n        upTo = max;\n\n        if (scorer.docID() == DocIdSetIterator.NO_MORE_DOCS) {\n          bulkScorer.score(new LeafCollector() {\n            @Override\n            public void setScorer(Scorer scorer) throws IOException {}\n\n            @Override\n            public void collect(int doc) throws IOException {\n              // no more matches\n              assert false;\n            }\n          }, null, upTo, DocIdSetIterator.NO_MORE_DOCS);\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f95c0e33e58652b2a4d8560c8297dbe86ff5b1f2","date":1591961131,"type":3,"author":"Michael Sokolov","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/search/QueryUtils#checkBulkScorerSkipTo(Random,Query,IndexSearcher).mjava","sourceNew":"  /** Check that the scorer and bulk scorer advance consistently. */\n  public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {\n    query = searcher.rewrite(query);\n    Weight weight = searcher.createWeight(query, ScoreMode.COMPLETE, 1);\n    for (LeafReaderContext context : searcher.getIndexReader().leaves()) {\n      final Scorer scorer = weight.scorer(context);\n      final BulkScorer bulkScorer = weight.bulkScorer(context);\n      if (scorer == null && bulkScorer == null) {\n        continue;\n      } else if (bulkScorer == null) {\n        // ensure scorer is exhausted (it just didnt return null)\n        assert scorer.iterator().nextDoc() == DocIdSetIterator.NO_MORE_DOCS;\n        continue;\n      }\n      DocIdSetIterator iterator = scorer.iterator();\n      int upTo = 0;\n      while (true) {\n        final int min = upTo + r.nextInt(5);\n        final int max = min + 1 + r.nextInt(r.nextBoolean() ? 10 : 5000);\n        if (scorer.docID() < min) {\n          iterator.advance(min);\n        }\n        final int next = bulkScorer.score(new LeafCollector() {\n          Scorable scorer2;\n          @Override\n          public void setScorer(Scorable scorer) throws IOException {\n            this.scorer2 = scorer;\n          }\n          @Override\n          public void collect(int doc) throws IOException {\n            assert doc >= min;\n            assert doc < max;\n            assertEquals(scorer.docID(), doc);\n            assertEquals(scorer.score(), scorer2.score(), 0.01f);\n            iterator.nextDoc();\n          }\n        }, null, min, max);\n        assert max <= next;\n        assert next <= scorer.docID();\n        upTo = max;\n\n        if (scorer.docID() == DocIdSetIterator.NO_MORE_DOCS) {\n          bulkScorer.score(new LeafCollector() {\n            @Override\n            public void setScorer(Scorable scorer) throws IOException {}\n\n            @Override\n            public void collect(int doc) throws IOException {\n              // no more matches\n              assert false;\n            }\n          }, null, upTo, DocIdSetIterator.NO_MORE_DOCS);\n          break;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /** Check that the scorer and bulk scorer advance consistently. */\n  public static void checkBulkScorerSkipTo(Random r, Query query, IndexSearcher searcher) throws IOException {\n    query = searcher.rewrite(query);\n    Weight weight = searcher.createWeight(query, ScoreMode.COMPLETE, 1);\n    for (LeafReaderContext context : searcher.getIndexReader().leaves()) {\n      final Scorer scorer = weight.scorer(context);\n      final BulkScorer bulkScorer = weight.bulkScorer(context);\n      if (scorer == null && bulkScorer == null) {\n        continue;\n      } else if (bulkScorer == null) {\n        // ensure scorer is exhausted (it just didnt return null)\n        assert scorer.iterator().nextDoc() == DocIdSetIterator.NO_MORE_DOCS;\n        continue;\n      }\n      DocIdSetIterator iterator = scorer.iterator();\n      int upTo = 0;\n      while (true) {\n        final int min = upTo + r.nextInt(5);\n        final int max = min + 1 + r.nextInt(r.nextBoolean() ? 10 : 5000);\n        if (scorer.docID() < min) {\n          iterator.advance(min);\n        }\n        final int next = bulkScorer.score(new LeafCollector() {\n          Scorable scorer2;\n          @Override\n          public void setScorer(Scorable scorer) throws IOException {\n            this.scorer2 = scorer;\n          }\n          @Override\n          public void collect(int doc) throws IOException {\n            assert doc >= min;\n            assert doc < max;\n            Assert.assertEquals(scorer.docID(), doc);\n            Assert.assertEquals(scorer.score(), scorer2.score(), 0.01f);\n            iterator.nextDoc();\n          }\n        }, null, min, max);\n        assert max <= next;\n        assert next <= scorer.docID();\n        upTo = max;\n\n        if (scorer.docID() == DocIdSetIterator.NO_MORE_DOCS) {\n          bulkScorer.score(new LeafCollector() {\n            @Override\n            public void setScorer(Scorable scorer) throws IOException {}\n\n            @Override\n            public void collect(int doc) throws IOException {\n              // no more matches\n              assert false;\n            }\n          }, null, upTo, DocIdSetIterator.NO_MORE_DOCS);\n          break;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"6a47d642ab24da1a811adce4bda9cc52c520ca13":["954e59be3da8dc1b046646ad7af4b466852009d3"],"fb17639909a369c1e64866842e5c213440acc17e":["781239fc84d36be12b84e4d3e2618f5f07a182e3"],"475584d5e08a22ad3fc7babefe006d77bc744567":["417142ff08fda9cf0b72d5133e63097a166c6458"],"781239fc84d36be12b84e4d3e2618f5f07a182e3":["e166cc9c5f45f78a8dd02332b5ac100221063fd8"],"954e59be3da8dc1b046646ad7af4b466852009d3":["fb17639909a369c1e64866842e5c213440acc17e"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["7dd748bb245633a8195281556bb0e68a6ea97d18","0e7bc21595222ae4f75509300fbb7726691f387f"],"417142ff08fda9cf0b72d5133e63097a166c6458":["0e7bc21595222ae4f75509300fbb7726691f387f","9fc47cb7b4346802411bb432f501ed0673d7119e"],"d58e44159788900f4a2113b84463dc3fbbf80f20":["417142ff08fda9cf0b72d5133e63097a166c6458","475584d5e08a22ad3fc7babefe006d77bc744567"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["ac49815905092460136aaebc1233126677405045"],"e166cc9c5f45f78a8dd02332b5ac100221063fd8":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"ac49815905092460136aaebc1233126677405045":["6a47d642ab24da1a811adce4bda9cc52c520ca13"],"285244982ce6aa163d1e60a707f0e6e121736ce5":["d58e44159788900f4a2113b84463dc3fbbf80f20"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0e7bc21595222ae4f75509300fbb7726691f387f":["7dd748bb245633a8195281556bb0e68a6ea97d18"],"f95c0e33e58652b2a4d8560c8297dbe86ff5b1f2":["285244982ce6aa163d1e60a707f0e6e121736ce5"],"9fc47cb7b4346802411bb432f501ed0673d7119e":["0e7bc21595222ae4f75509300fbb7726691f387f"],"7dd748bb245633a8195281556bb0e68a6ea97d18":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["f95c0e33e58652b2a4d8560c8297dbe86ff5b1f2"]},"commit2Childs":{"6a47d642ab24da1a811adce4bda9cc52c520ca13":["ac49815905092460136aaebc1233126677405045"],"fb17639909a369c1e64866842e5c213440acc17e":["954e59be3da8dc1b046646ad7af4b466852009d3"],"475584d5e08a22ad3fc7babefe006d77bc744567":["d58e44159788900f4a2113b84463dc3fbbf80f20"],"781239fc84d36be12b84e4d3e2618f5f07a182e3":["fb17639909a369c1e64866842e5c213440acc17e"],"954e59be3da8dc1b046646ad7af4b466852009d3":["6a47d642ab24da1a811adce4bda9cc52c520ca13"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"417142ff08fda9cf0b72d5133e63097a166c6458":["475584d5e08a22ad3fc7babefe006d77bc744567","d58e44159788900f4a2113b84463dc3fbbf80f20"],"d58e44159788900f4a2113b84463dc3fbbf80f20":["285244982ce6aa163d1e60a707f0e6e121736ce5"],"e166cc9c5f45f78a8dd02332b5ac100221063fd8":["781239fc84d36be12b84e4d3e2618f5f07a182e3"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["7dd748bb245633a8195281556bb0e68a6ea97d18"],"ac49815905092460136aaebc1233126677405045":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"285244982ce6aa163d1e60a707f0e6e121736ce5":["f95c0e33e58652b2a4d8560c8297dbe86ff5b1f2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["e166cc9c5f45f78a8dd02332b5ac100221063fd8"],"0e7bc21595222ae4f75509300fbb7726691f387f":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","417142ff08fda9cf0b72d5133e63097a166c6458","9fc47cb7b4346802411bb432f501ed0673d7119e"],"9fc47cb7b4346802411bb432f501ed0673d7119e":["417142ff08fda9cf0b72d5133e63097a166c6458"],"f95c0e33e58652b2a4d8560c8297dbe86ff5b1f2":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"7dd748bb245633a8195281556bb0e68a6ea97d18":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","0e7bc21595222ae4f75509300fbb7726691f387f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}