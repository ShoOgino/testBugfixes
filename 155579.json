{"path":"lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#getSortedSet(FieldInfo).mjava","commits":[{"id":"8106bc60c7452250f84c65cdb43ab6b1d8eb1534","date":1401906364,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SET_SINGLE_VALUED_SORTED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_SET_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["2ffc57bc5131bbdc981a8ebf5d8d99af0cb65dc1"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf","date":1401983689,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SET_SINGLE_VALUED_SORTED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_SET_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SET_SINGLE_VALUED_SORTED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_SET_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2ffc57bc5131bbdc981a8ebf5d8d99af0cb65dc1","date":1402428035,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SET_SINGLE_VALUED_SORTED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_SET_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = ordIndex.get(docID);\n        endOffset = ordIndex.get(docID+1L);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SET_SINGLE_VALUED_SORTED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_SET_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","bugFix":["8106bc60c7452250f84c65cdb43ab6b1d8eb1534"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d14ffaac9c4a4a2c750bf0cd956506802561e062","date":1402602036,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SINGLE_VALUED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = ordIndex.get(docID);\n        endOffset = ordIndex.get(docID+1L);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SET_SINGLE_VALUED_SORTED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_SET_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = ordIndex.get(docID);\n        endOffset = ordIndex.get(docID+1L);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c6f080a2ab37c464dd98db173f6cbf10dc74f211","date":1402946779,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SINGLE_VALUED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = ordIndex.get(docID);\n        endOffset = ordIndex.get(docID+1L);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SET_SINGLE_VALUED_SORTED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_SET_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = ordIndex.get(docID);\n        endOffset = ordIndex.get(docID+1L);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cc45c615dbb82bf79d5f9550286098367874fbf","date":1409571423,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SINGLE_VALUED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = ordIndex.get(docID);\n        endOffset = ordIndex.get(docID+1L);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SINGLE_VALUED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = ordIndex.get(docID);\n        endOffset = ordIndex.get(docID+1L);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"402ad3ddc9da7b70da1b167667a60ece6a1381fb","date":1409656478,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SINGLE_VALUED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = ordIndex.get(docID);\n        endOffset = ordIndex.get(docID+1L);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    SortedSetEntry ss = sortedSets.get(field.number);\n    if (ss.format == SORTED_SINGLE_VALUED) {\n      final SortedDocValues values = getSorted(field);\n      return DocValues.singleton(values);\n    } else if (ss.format != SORTED_WITH_ADDRESSES) {\n      throw new AssertionError();\n    }\n\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new RandomAccessOrds() {\n      long startOffset;\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        startOffset = offset = ordIndex.get(docID);\n        endOffset = ordIndex.get(docID+1L);\n      }\n\n      @Override\n      public BytesRef lookupOrd(long ord) {\n        return binary.get(ord);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n\n      @Override\n      public long ordAt(int index) {\n        return ordinals.get(startOffset + index);\n      }\n\n      @Override\n      public int cardinality() {\n        return (int) (endOffset - startOffset);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf":["8106bc60c7452250f84c65cdb43ab6b1d8eb1534"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4cc45c615dbb82bf79d5f9550286098367874fbf":["d14ffaac9c4a4a2c750bf0cd956506802561e062"],"2ffc57bc5131bbdc981a8ebf5d8d99af0cb65dc1":["53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf"],"8106bc60c7452250f84c65cdb43ab6b1d8eb1534":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c6f080a2ab37c464dd98db173f6cbf10dc74f211":["2ffc57bc5131bbdc981a8ebf5d8d99af0cb65dc1","d14ffaac9c4a4a2c750bf0cd956506802561e062"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"d14ffaac9c4a4a2c750bf0cd956506802561e062":["2ffc57bc5131bbdc981a8ebf5d8d99af0cb65dc1"],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["d14ffaac9c4a4a2c750bf0cd956506802561e062","4cc45c615dbb82bf79d5f9550286098367874fbf"]},"commit2Childs":{"53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf":["2ffc57bc5131bbdc981a8ebf5d8d99af0cb65dc1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["8106bc60c7452250f84c65cdb43ab6b1d8eb1534"],"4cc45c615dbb82bf79d5f9550286098367874fbf":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"2ffc57bc5131bbdc981a8ebf5d8d99af0cb65dc1":["c6f080a2ab37c464dd98db173f6cbf10dc74f211","d14ffaac9c4a4a2c750bf0cd956506802561e062"],"8106bc60c7452250f84c65cdb43ab6b1d8eb1534":["53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf"],"c6f080a2ab37c464dd98db173f6cbf10dc74f211":[],"d14ffaac9c4a4a2c750bf0cd956506802561e062":["4cc45c615dbb82bf79d5f9550286098367874fbf","c6f080a2ab37c464dd98db173f6cbf10dc74f211","402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["c6f080a2ab37c464dd98db173f6cbf10dc74f211","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}