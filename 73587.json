{"path":"solr/core/src/java/org/apache/solr/search/PointMerger.ValueIterator#ValueIterator(SchemaField,List[LeafReaderContext],int,int).mjava","commits":[{"id":"a92ffe0d2961113e5588e614f8dc22b42bf10a95","date":1503304229,"type":0,"author":"Cao Manh Dat","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/PointMerger.ValueIterator#ValueIterator(SchemaField,List[LeafReaderContext],int,int).mjava","pathOld":"/dev/null","sourceNew":"    public ValueIterator(SchemaField field, List<LeafReaderContext> readers, int totalBufferSize, int minSegBufferSize) throws IOException {\n      assert field.getType().isPointField();\n      queue = new PQueue(readers.size());\n      long ndocs = readers.get(readers.size()-1).docBase + readers.get(readers.size()-1).reader().maxDoc();\n      for (LeafReaderContext ctx : readers) {\n        PointValues pv = ctx.reader().getPointValues(field.getName());\n        if (pv == null) continue;\n        BaseSeg seg = null;\n        // int capacity = 2;\n        int capacity = (int)((long)totalBufferSize * ctx.reader().maxDoc() / ndocs);\n        capacity = Math.max(capacity, minSegBufferSize);\n\n        switch (field.getType().getNumberType()) {\n          case INTEGER:\n            seg = new IntSeg(pv, capacity);\n            break;\n          case LONG:\n            seg = new LongSeg(pv, capacity);\n            break;\n          case FLOAT:\n            seg = new FloatSeg(pv, capacity);\n            break;\n          case DOUBLE:\n            seg = new DoubleSeg(pv, capacity);\n            break;\n        }\n        int count = seg.setNextValue();\n        if (count >= 0) {\n          queue.add(seg);\n        }\n      }\n      if (queue.size() > 0) topVal = queue.top().getMutableValue().duplicate();\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2f7ebafe1543d3847a1cb09988cb6c46d48741f8","date":1503180131,"type":0,"author":"yonik","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/PointMerger.ValueIterator#ValueIterator(SchemaField,List[LeafReaderContext],int,int).mjava","pathOld":"/dev/null","sourceNew":"    public ValueIterator(SchemaField field, List<LeafReaderContext> readers, int totalBufferSize, int minSegBufferSize) throws IOException {\n      assert field.getType().isPointField();\n      queue = new PQueue(readers.size());\n      long ndocs = readers.get(readers.size()-1).docBase + readers.get(readers.size()-1).reader().maxDoc();\n      for (LeafReaderContext ctx : readers) {\n        PointValues pv = ctx.reader().getPointValues(field.getName());\n        if (pv == null) continue;\n        BaseSeg seg = null;\n        // int capacity = 2;\n        int capacity = (int)((long)totalBufferSize * ctx.reader().maxDoc() / ndocs);\n        capacity = Math.max(capacity, minSegBufferSize);\n\n        switch (field.getType().getNumberType()) {\n          case INTEGER:\n            seg = new IntSeg(pv, capacity);\n            break;\n          case LONG:\n            seg = new LongSeg(pv, capacity);\n            break;\n          case FLOAT:\n            seg = new FloatSeg(pv, capacity);\n            break;\n          case DOUBLE:\n            seg = new DoubleSeg(pv, capacity);\n            break;\n        }\n        int count = seg.setNextValue();\n        if (count >= 0) {\n          queue.add(seg);\n        }\n      }\n      if (queue.size() > 0) topVal = queue.top().getMutableValue().duplicate();\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3051d6122751c8f6cc1e9cf24592658b59843ec2","date":1503298024,"type":0,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/PointMerger.ValueIterator#ValueIterator(SchemaField,List[LeafReaderContext],int,int).mjava","pathOld":"/dev/null","sourceNew":"    public ValueIterator(SchemaField field, List<LeafReaderContext> readers, int totalBufferSize, int minSegBufferSize) throws IOException {\n      assert field.getType().isPointField();\n      queue = new PQueue(readers.size());\n      long ndocs = readers.get(readers.size()-1).docBase + readers.get(readers.size()-1).reader().maxDoc();\n      for (LeafReaderContext ctx : readers) {\n        PointValues pv = ctx.reader().getPointValues(field.getName());\n        if (pv == null) continue;\n        BaseSeg seg = null;\n        // int capacity = 2;\n        int capacity = (int)((long)totalBufferSize * ctx.reader().maxDoc() / ndocs);\n        capacity = Math.max(capacity, minSegBufferSize);\n\n        switch (field.getType().getNumberType()) {\n          case INTEGER:\n            seg = new IntSeg(pv, capacity);\n            break;\n          case LONG:\n            seg = new LongSeg(pv, capacity);\n            break;\n          case FLOAT:\n            seg = new FloatSeg(pv, capacity);\n            break;\n          case DOUBLE:\n            seg = new DoubleSeg(pv, capacity);\n            break;\n        }\n        int count = seg.setNextValue();\n        if (count >= 0) {\n          queue.add(seg);\n        }\n      }\n      if (queue.size() > 0) topVal = queue.top().getMutableValue().duplicate();\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7b107346d6f511cbb411725ae85fa167de3cc916","date":1518457408,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/PointMerger.ValueIterator#ValueIterator(SchemaField,List[LeafReaderContext],int,int).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/PointMerger.ValueIterator#ValueIterator(SchemaField,List[LeafReaderContext],int,int).mjava","sourceNew":"    public ValueIterator(SchemaField field, List<LeafReaderContext> readers, int totalBufferSize, int minSegBufferSize) throws IOException {\n      assert field.getType().isPointField();\n      queue = new PQueue(readers.size());\n      long ndocs = readers.get(readers.size()-1).docBase + readers.get(readers.size()-1).reader().maxDoc();\n      for (LeafReaderContext ctx : readers) {\n        PointValues pv = ctx.reader().getPointValues(field.getName());\n        if (pv == null) continue;\n        BaseSeg seg = null;\n        // int capacity = 2;\n        int capacity = (int)((long)totalBufferSize * ctx.reader().maxDoc() / ndocs);\n        capacity = Math.max(capacity, minSegBufferSize);\n\n        switch (field.getType().getNumberType()) {\n          case INTEGER:\n            seg = new IntSeg(pv, capacity);\n            break;\n          case LONG:\n            seg = new LongSeg(pv, capacity);\n            break;\n          case FLOAT:\n            seg = new FloatSeg(pv, capacity);\n            break;\n          case DOUBLE:\n            seg = new DoubleSeg(pv, capacity);\n            break;\n          case DATE:\n            break;\n        }\n        int count = seg.setNextValue();\n        if (count >= 0) {\n          queue.add(seg);\n        }\n      }\n      if (queue.size() > 0) topVal = queue.top().getMutableValue().duplicate();\n    }\n\n","sourceOld":"    public ValueIterator(SchemaField field, List<LeafReaderContext> readers, int totalBufferSize, int minSegBufferSize) throws IOException {\n      assert field.getType().isPointField();\n      queue = new PQueue(readers.size());\n      long ndocs = readers.get(readers.size()-1).docBase + readers.get(readers.size()-1).reader().maxDoc();\n      for (LeafReaderContext ctx : readers) {\n        PointValues pv = ctx.reader().getPointValues(field.getName());\n        if (pv == null) continue;\n        BaseSeg seg = null;\n        // int capacity = 2;\n        int capacity = (int)((long)totalBufferSize * ctx.reader().maxDoc() / ndocs);\n        capacity = Math.max(capacity, minSegBufferSize);\n\n        switch (field.getType().getNumberType()) {\n          case INTEGER:\n            seg = new IntSeg(pv, capacity);\n            break;\n          case LONG:\n            seg = new LongSeg(pv, capacity);\n            break;\n          case FLOAT:\n            seg = new FloatSeg(pv, capacity);\n            break;\n          case DOUBLE:\n            seg = new DoubleSeg(pv, capacity);\n            break;\n        }\n        int count = seg.setNextValue();\n        if (count >= 0) {\n          queue.add(seg);\n        }\n      }\n      if (queue.size() > 0) topVal = queue.top().getMutableValue().duplicate();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bfcdec9fcf0409223f35c5ec3bc14094314941b4","date":1518533599,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/PointMerger.ValueIterator#ValueIterator(SchemaField,List[LeafReaderContext],int,int).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/PointMerger.ValueIterator#ValueIterator(SchemaField,List[LeafReaderContext],int,int).mjava","sourceNew":"    public ValueIterator(SchemaField field, List<LeafReaderContext> readers, int totalBufferSize, int minSegBufferSize) throws IOException {\n      assert field.getType().isPointField();\n      queue = new PQueue(readers.size());\n      long ndocs = readers.get(readers.size()-1).docBase + readers.get(readers.size()-1).reader().maxDoc();\n      for (LeafReaderContext ctx : readers) {\n        PointValues pv = ctx.reader().getPointValues(field.getName());\n        if (pv == null) continue;\n        BaseSeg seg = null;\n        // int capacity = 2;\n        int capacity = (int)((long)totalBufferSize * ctx.reader().maxDoc() / ndocs);\n        capacity = Math.max(capacity, minSegBufferSize);\n\n        switch (field.getType().getNumberType()) {\n          case INTEGER:\n            seg = new IntSeg(pv, capacity);\n            break;\n          case LONG:\n            seg = new LongSeg(pv, capacity);\n            break;\n          case FLOAT:\n            seg = new FloatSeg(pv, capacity);\n            break;\n          case DOUBLE:\n            seg = new DoubleSeg(pv, capacity);\n            break;\n          case DATE:\n            break;\n        }\n        int count = seg.setNextValue();\n        if (count >= 0) {\n          queue.add(seg);\n        }\n      }\n      if (queue.size() > 0) topVal = queue.top().getMutableValue().duplicate();\n    }\n\n","sourceOld":"    public ValueIterator(SchemaField field, List<LeafReaderContext> readers, int totalBufferSize, int minSegBufferSize) throws IOException {\n      assert field.getType().isPointField();\n      queue = new PQueue(readers.size());\n      long ndocs = readers.get(readers.size()-1).docBase + readers.get(readers.size()-1).reader().maxDoc();\n      for (LeafReaderContext ctx : readers) {\n        PointValues pv = ctx.reader().getPointValues(field.getName());\n        if (pv == null) continue;\n        BaseSeg seg = null;\n        // int capacity = 2;\n        int capacity = (int)((long)totalBufferSize * ctx.reader().maxDoc() / ndocs);\n        capacity = Math.max(capacity, minSegBufferSize);\n\n        switch (field.getType().getNumberType()) {\n          case INTEGER:\n            seg = new IntSeg(pv, capacity);\n            break;\n          case LONG:\n            seg = new LongSeg(pv, capacity);\n            break;\n          case FLOAT:\n            seg = new FloatSeg(pv, capacity);\n            break;\n          case DOUBLE:\n            seg = new DoubleSeg(pv, capacity);\n            break;\n        }\n        int count = seg.setNextValue();\n        if (count >= 0) {\n          queue.add(seg);\n        }\n      }\n      if (queue.size() > 0) topVal = queue.top().getMutableValue().duplicate();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"09a152fdd1e91e2dc8949c867985ea649b2a0c37","date":1571422557,"type":3,"author":"Munendra S N","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/PointMerger.ValueIterator#ValueIterator(SchemaField,List[LeafReaderContext],int,int).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/PointMerger.ValueIterator#ValueIterator(SchemaField,List[LeafReaderContext],int,int).mjava","sourceNew":"    public ValueIterator(SchemaField field, List<LeafReaderContext> readers, int totalBufferSize, int minSegBufferSize) throws IOException {\n      assert field.getType().isPointField();\n      queue = new PQueue(readers.size());\n      long ndocs = readers.get(readers.size()-1).docBase + readers.get(readers.size()-1).reader().maxDoc();\n      for (LeafReaderContext ctx : readers) {\n        PointValues pv = ctx.reader().getPointValues(field.getName());\n        if (pv == null) continue;\n        BaseSeg seg = null;\n        // int capacity = 2;\n        int capacity = (int)((long)totalBufferSize * ctx.reader().maxDoc() / ndocs);\n        capacity = Math.max(capacity, minSegBufferSize);\n\n        switch (field.getType().getNumberType()) {\n          case INTEGER:\n            seg = new IntSeg(pv, capacity);\n            break;\n          case LONG:\n            seg = new LongSeg(pv, capacity);\n            break;\n          case FLOAT:\n            seg = new FloatSeg(pv, capacity);\n            break;\n          case DOUBLE:\n            seg = new DoubleSeg(pv, capacity);\n            break;\n          case DATE:\n            seg = new DateSeg(pv, capacity);\n            break;\n        }\n        int count = seg.setNextValue();\n        if (count >= 0) {\n          queue.add(seg);\n        }\n      }\n      if (queue.size() > 0) topVal = queue.top().getMutableValue().duplicate();\n    }\n\n","sourceOld":"    public ValueIterator(SchemaField field, List<LeafReaderContext> readers, int totalBufferSize, int minSegBufferSize) throws IOException {\n      assert field.getType().isPointField();\n      queue = new PQueue(readers.size());\n      long ndocs = readers.get(readers.size()-1).docBase + readers.get(readers.size()-1).reader().maxDoc();\n      for (LeafReaderContext ctx : readers) {\n        PointValues pv = ctx.reader().getPointValues(field.getName());\n        if (pv == null) continue;\n        BaseSeg seg = null;\n        // int capacity = 2;\n        int capacity = (int)((long)totalBufferSize * ctx.reader().maxDoc() / ndocs);\n        capacity = Math.max(capacity, minSegBufferSize);\n\n        switch (field.getType().getNumberType()) {\n          case INTEGER:\n            seg = new IntSeg(pv, capacity);\n            break;\n          case LONG:\n            seg = new LongSeg(pv, capacity);\n            break;\n          case FLOAT:\n            seg = new FloatSeg(pv, capacity);\n            break;\n          case DOUBLE:\n            seg = new DoubleSeg(pv, capacity);\n            break;\n          case DATE:\n            break;\n        }\n        int count = seg.setNextValue();\n        if (count >= 0) {\n          queue.add(seg);\n        }\n      }\n      if (queue.size() > 0) topVal = queue.top().getMutableValue().duplicate();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bb65c51348af9263e432c5a93cd98be0ca68ec3a","date":1571891776,"type":3,"author":"Munendra S N","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/PointMerger.ValueIterator#ValueIterator(SchemaField,List[LeafReaderContext],int,int).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/PointMerger.ValueIterator#ValueIterator(SchemaField,List[LeafReaderContext],int,int).mjava","sourceNew":"    public ValueIterator(SchemaField field, List<LeafReaderContext> readers, int totalBufferSize, int minSegBufferSize) throws IOException {\n      assert field.getType().isPointField();\n      queue = new PQueue(readers.size());\n      if (readers.isEmpty()) {\n        return;\n      }\n      long ndocs = readers.get(readers.size()-1).docBase + readers.get(readers.size()-1).reader().maxDoc();\n      for (LeafReaderContext ctx : readers) {\n        PointValues pv = ctx.reader().getPointValues(field.getName());\n        if (pv == null) continue;\n        BaseSeg seg = null;\n        // int capacity = 2;\n        int capacity = (int)((long)totalBufferSize * ctx.reader().maxDoc() / ndocs);\n        capacity = Math.max(capacity, minSegBufferSize);\n\n        switch (field.getType().getNumberType()) {\n          case INTEGER:\n            seg = new IntSeg(pv, capacity);\n            break;\n          case LONG:\n            seg = new LongSeg(pv, capacity);\n            break;\n          case FLOAT:\n            seg = new FloatSeg(pv, capacity);\n            break;\n          case DOUBLE:\n            seg = new DoubleSeg(pv, capacity);\n            break;\n          case DATE:\n            seg = new DateSeg(pv, capacity);\n            break;\n        }\n        int count = seg.setNextValue();\n        if (count >= 0) {\n          queue.add(seg);\n        }\n      }\n      if (queue.size() > 0) topVal = queue.top().getMutableValue().duplicate();\n    }\n\n","sourceOld":"    public ValueIterator(SchemaField field, List<LeafReaderContext> readers, int totalBufferSize, int minSegBufferSize) throws IOException {\n      assert field.getType().isPointField();\n      queue = new PQueue(readers.size());\n      long ndocs = readers.get(readers.size()-1).docBase + readers.get(readers.size()-1).reader().maxDoc();\n      for (LeafReaderContext ctx : readers) {\n        PointValues pv = ctx.reader().getPointValues(field.getName());\n        if (pv == null) continue;\n        BaseSeg seg = null;\n        // int capacity = 2;\n        int capacity = (int)((long)totalBufferSize * ctx.reader().maxDoc() / ndocs);\n        capacity = Math.max(capacity, minSegBufferSize);\n\n        switch (field.getType().getNumberType()) {\n          case INTEGER:\n            seg = new IntSeg(pv, capacity);\n            break;\n          case LONG:\n            seg = new LongSeg(pv, capacity);\n            break;\n          case FLOAT:\n            seg = new FloatSeg(pv, capacity);\n            break;\n          case DOUBLE:\n            seg = new DoubleSeg(pv, capacity);\n            break;\n          case DATE:\n            seg = new DateSeg(pv, capacity);\n            break;\n        }\n        int count = seg.setNextValue();\n        if (count >= 0) {\n          queue.add(seg);\n        }\n      }\n      if (queue.size() > 0) topVal = queue.top().getMutableValue().duplicate();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"09a152fdd1e91e2dc8949c867985ea649b2a0c37":["bfcdec9fcf0409223f35c5ec3bc14094314941b4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"2f7ebafe1543d3847a1cb09988cb6c46d48741f8":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"7b107346d6f511cbb411725ae85fa167de3cc916":["a92ffe0d2961113e5588e614f8dc22b42bf10a95"],"bb65c51348af9263e432c5a93cd98be0ca68ec3a":["09a152fdd1e91e2dc8949c867985ea649b2a0c37"],"3051d6122751c8f6cc1e9cf24592658b59843ec2":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","2f7ebafe1543d3847a1cb09988cb6c46d48741f8"],"a92ffe0d2961113e5588e614f8dc22b42bf10a95":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","2f7ebafe1543d3847a1cb09988cb6c46d48741f8"],"bfcdec9fcf0409223f35c5ec3bc14094314941b4":["a92ffe0d2961113e5588e614f8dc22b42bf10a95","7b107346d6f511cbb411725ae85fa167de3cc916"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["bb65c51348af9263e432c5a93cd98be0ca68ec3a"]},"commit2Childs":{"09a152fdd1e91e2dc8949c867985ea649b2a0c37":["bb65c51348af9263e432c5a93cd98be0ca68ec3a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["2f7ebafe1543d3847a1cb09988cb6c46d48741f8","3051d6122751c8f6cc1e9cf24592658b59843ec2","a92ffe0d2961113e5588e614f8dc22b42bf10a95"],"2f7ebafe1543d3847a1cb09988cb6c46d48741f8":["3051d6122751c8f6cc1e9cf24592658b59843ec2","a92ffe0d2961113e5588e614f8dc22b42bf10a95"],"7b107346d6f511cbb411725ae85fa167de3cc916":["bfcdec9fcf0409223f35c5ec3bc14094314941b4"],"bb65c51348af9263e432c5a93cd98be0ca68ec3a":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3051d6122751c8f6cc1e9cf24592658b59843ec2":[],"bfcdec9fcf0409223f35c5ec3bc14094314941b4":["09a152fdd1e91e2dc8949c867985ea649b2a0c37"],"a92ffe0d2961113e5588e614f8dc22b42bf10a95":["7b107346d6f511cbb411725ae85fa167de3cc916","bfcdec9fcf0409223f35c5ec3bc14094314941b4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["3051d6122751c8f6cc1e9cf24592658b59843ec2","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}