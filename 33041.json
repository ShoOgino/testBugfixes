{"path":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#build().mjava","commits":[{"id":"44d6f0ab53c1962856b9f48dedb7a2a6cc18905c","date":1310389132,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#build().mjava","pathOld":"/dev/null","sourceNew":"    /**\n     * Builds an {@link SynonymMap} and returns it.\n     */\n    public SynonymMap build() throws IOException {\n      ByteSequenceOutputs outputs = ByteSequenceOutputs.getSingleton();\n      // TODO: are we using the best sharing options?\n      org.apache.lucene.util.fst.Builder<BytesRef> builder = \n        new org.apache.lucene.util.fst.Builder<BytesRef>(FST.INPUT_TYPE.BYTE4, 0, 0, true, outputs);\n      \n      BytesRef scratch = new BytesRef(64);\n      ByteArrayDataOutput scratchOutput = new ByteArrayDataOutput();\n\n      final Set<Integer> dedupSet;\n\n      if (dedup) {\n        dedupSet = new HashSet<Integer>();\n      } else {\n        dedupSet = null;\n      }\n\n      final byte[] spare = new byte[5];\n      \n      Set<CharsRef> keys = workingSet.keySet();\n      CharsRef sortedKeys[] = keys.toArray(new CharsRef[keys.size()]);\n      Arrays.sort(sortedKeys, CharsRef.getUTF16SortedAsUTF8Comparator());\n      \n      //System.out.println(\"fmap.build\");\n      for (int keyIdx = 0; keyIdx < sortedKeys.length; keyIdx++) {\n        CharsRef input = sortedKeys[keyIdx];\n        MapEntry output = workingSet.get(input);\n\n        int numEntries = output.ords.size();\n        // output size, assume the worst case\n        int estimatedSize = 5 + numEntries * 5; // numEntries + one ord for each entry\n        \n        scratch.grow(estimatedSize);\n        scratchOutput.reset(scratch.bytes, scratch.offset, scratch.bytes.length);\n        assert scratch.offset == 0;\n\n        // now write our output data:\n        int count = 0;\n        for (int i = 0; i < numEntries; i++) {\n          if (dedupSet != null) {\n            // box once\n            final Integer ent = output.ords.get(i);\n            if (dedupSet.contains(ent)) {\n              continue;\n            }\n            dedupSet.add(ent);\n          }\n          scratchOutput.writeVInt(output.ords.get(i));   \n          count++;\n        }\n\n        final int pos = scratchOutput.getPosition();\n        scratchOutput.writeVInt(count << 1 | (output.includeOrig ? 0 : 1));\n        final int pos2 = scratchOutput.getPosition();\n        final int vIntLen = pos2-pos;\n\n        // Move the count + includeOrig to the front of the byte[]:\n        System.arraycopy(scratch.bytes, pos, spare, 0, vIntLen);\n        System.arraycopy(scratch.bytes, 0, scratch.bytes, vIntLen, pos);\n        System.arraycopy(spare, 0, scratch.bytes, 0, vIntLen);\n\n        if (dedupSet != null) {\n          dedupSet.clear();\n        }\n        \n        scratch.length = scratchOutput.getPosition() - scratch.offset;\n        //System.out.println(\"  add input=\" + input + \" output=\" + scratch + \" offset=\" + scratch.offset + \" length=\" + scratch.length + \" count=\" + count);\n        builder.add(input, new BytesRef(scratch));\n      }\n      \n      FST<BytesRef> fst = builder.finish();\n      return new SynonymMap(fst, words, maxHorizontalContext);\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4f2bf10c11daad40c1e46fabd0d414c19a3e605b","date":1310410393,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#build().mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#build().mjava","sourceNew":"    /**\n     * Builds an {@link SynonymMap} and returns it.\n     */\n    public SynonymMap build() throws IOException {\n      ByteSequenceOutputs outputs = ByteSequenceOutputs.getSingleton();\n      // TODO: are we using the best sharing options?\n      org.apache.lucene.util.fst.Builder<BytesRef> builder = \n        new org.apache.lucene.util.fst.Builder<BytesRef>(FST.INPUT_TYPE.BYTE4, outputs);\n      \n      BytesRef scratch = new BytesRef(64);\n      ByteArrayDataOutput scratchOutput = new ByteArrayDataOutput();\n\n      final Set<Integer> dedupSet;\n\n      if (dedup) {\n        dedupSet = new HashSet<Integer>();\n      } else {\n        dedupSet = null;\n      }\n\n      final byte[] spare = new byte[5];\n      \n      Set<CharsRef> keys = workingSet.keySet();\n      CharsRef sortedKeys[] = keys.toArray(new CharsRef[keys.size()]);\n      Arrays.sort(sortedKeys, CharsRef.getUTF16SortedAsUTF8Comparator());\n      \n      //System.out.println(\"fmap.build\");\n      for (int keyIdx = 0; keyIdx < sortedKeys.length; keyIdx++) {\n        CharsRef input = sortedKeys[keyIdx];\n        MapEntry output = workingSet.get(input);\n\n        int numEntries = output.ords.size();\n        // output size, assume the worst case\n        int estimatedSize = 5 + numEntries * 5; // numEntries + one ord for each entry\n        \n        scratch.grow(estimatedSize);\n        scratchOutput.reset(scratch.bytes, scratch.offset, scratch.bytes.length);\n        assert scratch.offset == 0;\n\n        // now write our output data:\n        int count = 0;\n        for (int i = 0; i < numEntries; i++) {\n          if (dedupSet != null) {\n            // box once\n            final Integer ent = output.ords.get(i);\n            if (dedupSet.contains(ent)) {\n              continue;\n            }\n            dedupSet.add(ent);\n          }\n          scratchOutput.writeVInt(output.ords.get(i));   \n          count++;\n        }\n\n        final int pos = scratchOutput.getPosition();\n        scratchOutput.writeVInt(count << 1 | (output.includeOrig ? 0 : 1));\n        final int pos2 = scratchOutput.getPosition();\n        final int vIntLen = pos2-pos;\n\n        // Move the count + includeOrig to the front of the byte[]:\n        System.arraycopy(scratch.bytes, pos, spare, 0, vIntLen);\n        System.arraycopy(scratch.bytes, 0, scratch.bytes, vIntLen, pos);\n        System.arraycopy(spare, 0, scratch.bytes, 0, vIntLen);\n\n        if (dedupSet != null) {\n          dedupSet.clear();\n        }\n        \n        scratch.length = scratchOutput.getPosition() - scratch.offset;\n        //System.out.println(\"  add input=\" + input + \" output=\" + scratch + \" offset=\" + scratch.offset + \" length=\" + scratch.length + \" count=\" + count);\n        builder.add(input, new BytesRef(scratch));\n      }\n      \n      FST<BytesRef> fst = builder.finish();\n      return new SynonymMap(fst, words, maxHorizontalContext);\n    }\n\n","sourceOld":"    /**\n     * Builds an {@link SynonymMap} and returns it.\n     */\n    public SynonymMap build() throws IOException {\n      ByteSequenceOutputs outputs = ByteSequenceOutputs.getSingleton();\n      // TODO: are we using the best sharing options?\n      org.apache.lucene.util.fst.Builder<BytesRef> builder = \n        new org.apache.lucene.util.fst.Builder<BytesRef>(FST.INPUT_TYPE.BYTE4, 0, 0, true, outputs);\n      \n      BytesRef scratch = new BytesRef(64);\n      ByteArrayDataOutput scratchOutput = new ByteArrayDataOutput();\n\n      final Set<Integer> dedupSet;\n\n      if (dedup) {\n        dedupSet = new HashSet<Integer>();\n      } else {\n        dedupSet = null;\n      }\n\n      final byte[] spare = new byte[5];\n      \n      Set<CharsRef> keys = workingSet.keySet();\n      CharsRef sortedKeys[] = keys.toArray(new CharsRef[keys.size()]);\n      Arrays.sort(sortedKeys, CharsRef.getUTF16SortedAsUTF8Comparator());\n      \n      //System.out.println(\"fmap.build\");\n      for (int keyIdx = 0; keyIdx < sortedKeys.length; keyIdx++) {\n        CharsRef input = sortedKeys[keyIdx];\n        MapEntry output = workingSet.get(input);\n\n        int numEntries = output.ords.size();\n        // output size, assume the worst case\n        int estimatedSize = 5 + numEntries * 5; // numEntries + one ord for each entry\n        \n        scratch.grow(estimatedSize);\n        scratchOutput.reset(scratch.bytes, scratch.offset, scratch.bytes.length);\n        assert scratch.offset == 0;\n\n        // now write our output data:\n        int count = 0;\n        for (int i = 0; i < numEntries; i++) {\n          if (dedupSet != null) {\n            // box once\n            final Integer ent = output.ords.get(i);\n            if (dedupSet.contains(ent)) {\n              continue;\n            }\n            dedupSet.add(ent);\n          }\n          scratchOutput.writeVInt(output.ords.get(i));   \n          count++;\n        }\n\n        final int pos = scratchOutput.getPosition();\n        scratchOutput.writeVInt(count << 1 | (output.includeOrig ? 0 : 1));\n        final int pos2 = scratchOutput.getPosition();\n        final int vIntLen = pos2-pos;\n\n        // Move the count + includeOrig to the front of the byte[]:\n        System.arraycopy(scratch.bytes, pos, spare, 0, vIntLen);\n        System.arraycopy(scratch.bytes, 0, scratch.bytes, vIntLen, pos);\n        System.arraycopy(spare, 0, scratch.bytes, 0, vIntLen);\n\n        if (dedupSet != null) {\n          dedupSet.clear();\n        }\n        \n        scratch.length = scratchOutput.getPosition() - scratch.offset;\n        //System.out.println(\"  add input=\" + input + \" output=\" + scratch + \" offset=\" + scratch.offset + \" length=\" + scratch.length + \" count=\" + count);\n        builder.add(input, new BytesRef(scratch));\n      }\n      \n      FST<BytesRef> fst = builder.finish();\n      return new SynonymMap(fst, words, maxHorizontalContext);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e6e919043fa85ee891123768dd655a98edbbf63c","date":1322225413,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#build().mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#build().mjava","sourceNew":"    /**\n     * Builds an {@link SynonymMap} and returns it.\n     */\n    public SynonymMap build() throws IOException {\n      ByteSequenceOutputs outputs = ByteSequenceOutputs.getSingleton();\n      // TODO: are we using the best sharing options?\n      org.apache.lucene.util.fst.Builder<BytesRef> builder = \n        new org.apache.lucene.util.fst.Builder<BytesRef>(FST.INPUT_TYPE.BYTE4, outputs);\n      \n      BytesRef scratch = new BytesRef(64);\n      ByteArrayDataOutput scratchOutput = new ByteArrayDataOutput();\n\n      final Set<Integer> dedupSet;\n\n      if (dedup) {\n        dedupSet = new HashSet<Integer>();\n      } else {\n        dedupSet = null;\n      }\n\n      final byte[] spare = new byte[5];\n      \n      Set<CharsRef> keys = workingSet.keySet();\n      CharsRef sortedKeys[] = keys.toArray(new CharsRef[keys.size()]);\n      Arrays.sort(sortedKeys, CharsRef.getUTF16SortedAsUTF8Comparator());\n      \n      //System.out.println(\"fmap.build\");\n      for (int keyIdx = 0; keyIdx < sortedKeys.length; keyIdx++) {\n        CharsRef input = sortedKeys[keyIdx];\n        MapEntry output = workingSet.get(input);\n\n        int numEntries = output.ords.size();\n        // output size, assume the worst case\n        int estimatedSize = 5 + numEntries * 5; // numEntries + one ord for each entry\n        \n        scratch.grow(estimatedSize);\n        scratchOutput.reset(scratch.bytes, scratch.offset, scratch.bytes.length);\n        assert scratch.offset == 0;\n\n        // now write our output data:\n        int count = 0;\n        for (int i = 0; i < numEntries; i++) {\n          if (dedupSet != null) {\n            // box once\n            final Integer ent = output.ords.get(i);\n            if (dedupSet.contains(ent)) {\n              continue;\n            }\n            dedupSet.add(ent);\n          }\n          scratchOutput.writeVInt(output.ords.get(i));   \n          count++;\n        }\n\n        final int pos = scratchOutput.getPosition();\n        scratchOutput.writeVInt(count << 1 | (output.includeOrig ? 0 : 1));\n        final int pos2 = scratchOutput.getPosition();\n        final int vIntLen = pos2-pos;\n\n        // Move the count + includeOrig to the front of the byte[]:\n        System.arraycopy(scratch.bytes, pos, spare, 0, vIntLen);\n        System.arraycopy(scratch.bytes, 0, scratch.bytes, vIntLen, pos);\n        System.arraycopy(spare, 0, scratch.bytes, 0, vIntLen);\n\n        if (dedupSet != null) {\n          dedupSet.clear();\n        }\n        \n        scratch.length = scratchOutput.getPosition() - scratch.offset;\n        //System.out.println(\"  add input=\" + input + \" output=\" + scratch + \" offset=\" + scratch.offset + \" length=\" + scratch.length + \" count=\" + count);\n        builder.add(input, BytesRef.deepCopyOf(scratch));\n      }\n      \n      FST<BytesRef> fst = builder.finish();\n      return new SynonymMap(fst, words, maxHorizontalContext);\n    }\n\n","sourceOld":"    /**\n     * Builds an {@link SynonymMap} and returns it.\n     */\n    public SynonymMap build() throws IOException {\n      ByteSequenceOutputs outputs = ByteSequenceOutputs.getSingleton();\n      // TODO: are we using the best sharing options?\n      org.apache.lucene.util.fst.Builder<BytesRef> builder = \n        new org.apache.lucene.util.fst.Builder<BytesRef>(FST.INPUT_TYPE.BYTE4, outputs);\n      \n      BytesRef scratch = new BytesRef(64);\n      ByteArrayDataOutput scratchOutput = new ByteArrayDataOutput();\n\n      final Set<Integer> dedupSet;\n\n      if (dedup) {\n        dedupSet = new HashSet<Integer>();\n      } else {\n        dedupSet = null;\n      }\n\n      final byte[] spare = new byte[5];\n      \n      Set<CharsRef> keys = workingSet.keySet();\n      CharsRef sortedKeys[] = keys.toArray(new CharsRef[keys.size()]);\n      Arrays.sort(sortedKeys, CharsRef.getUTF16SortedAsUTF8Comparator());\n      \n      //System.out.println(\"fmap.build\");\n      for (int keyIdx = 0; keyIdx < sortedKeys.length; keyIdx++) {\n        CharsRef input = sortedKeys[keyIdx];\n        MapEntry output = workingSet.get(input);\n\n        int numEntries = output.ords.size();\n        // output size, assume the worst case\n        int estimatedSize = 5 + numEntries * 5; // numEntries + one ord for each entry\n        \n        scratch.grow(estimatedSize);\n        scratchOutput.reset(scratch.bytes, scratch.offset, scratch.bytes.length);\n        assert scratch.offset == 0;\n\n        // now write our output data:\n        int count = 0;\n        for (int i = 0; i < numEntries; i++) {\n          if (dedupSet != null) {\n            // box once\n            final Integer ent = output.ords.get(i);\n            if (dedupSet.contains(ent)) {\n              continue;\n            }\n            dedupSet.add(ent);\n          }\n          scratchOutput.writeVInt(output.ords.get(i));   \n          count++;\n        }\n\n        final int pos = scratchOutput.getPosition();\n        scratchOutput.writeVInt(count << 1 | (output.includeOrig ? 0 : 1));\n        final int pos2 = scratchOutput.getPosition();\n        final int vIntLen = pos2-pos;\n\n        // Move the count + includeOrig to the front of the byte[]:\n        System.arraycopy(scratch.bytes, pos, spare, 0, vIntLen);\n        System.arraycopy(scratch.bytes, 0, scratch.bytes, vIntLen, pos);\n        System.arraycopy(spare, 0, scratch.bytes, 0, vIntLen);\n\n        if (dedupSet != null) {\n          dedupSet.clear();\n        }\n        \n        scratch.length = scratchOutput.getPosition() - scratch.offset;\n        //System.out.println(\"  add input=\" + input + \" output=\" + scratch + \" offset=\" + scratch.offset + \" length=\" + scratch.length + \" count=\" + count);\n        builder.add(input, new BytesRef(scratch));\n      }\n      \n      FST<BytesRef> fst = builder.finish();\n      return new SynonymMap(fst, words, maxHorizontalContext);\n    }\n\n","bugFix":null,"bugIntro":["1ec890fad2ea96317f4429e0aa0085bb25673641"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1ec890fad2ea96317f4429e0aa0085bb25673641","date":1326669938,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#build().mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#build().mjava","sourceNew":"    /**\n     * Builds an {@link SynonymMap} and returns it.\n     */\n    public SynonymMap build() throws IOException {\n      ByteSequenceOutputs outputs = ByteSequenceOutputs.getSingleton();\n      // TODO: are we using the best sharing options?\n      org.apache.lucene.util.fst.Builder<BytesRef> builder = \n        new org.apache.lucene.util.fst.Builder<BytesRef>(FST.INPUT_TYPE.BYTE4, outputs);\n      \n      BytesRef scratch = new BytesRef(64);\n      ByteArrayDataOutput scratchOutput = new ByteArrayDataOutput();\n\n      final Set<Integer> dedupSet;\n\n      if (dedup) {\n        dedupSet = new HashSet<Integer>();\n      } else {\n        dedupSet = null;\n      }\n\n      final byte[] spare = new byte[5];\n      \n      Set<CharsRef> keys = workingSet.keySet();\n      CharsRef sortedKeys[] = keys.toArray(new CharsRef[keys.size()]);\n      Arrays.sort(sortedKeys, CharsRef.getUTF16SortedAsUTF8Comparator());\n\n      final IntsRef scratchIntsRef = new IntsRef();\n      \n      //System.out.println(\"fmap.build\");\n      for (int keyIdx = 0; keyIdx < sortedKeys.length; keyIdx++) {\n        CharsRef input = sortedKeys[keyIdx];\n        MapEntry output = workingSet.get(input);\n\n        int numEntries = output.ords.size();\n        // output size, assume the worst case\n        int estimatedSize = 5 + numEntries * 5; // numEntries + one ord for each entry\n        \n        scratch.grow(estimatedSize);\n        scratchOutput.reset(scratch.bytes, scratch.offset, scratch.bytes.length);\n        assert scratch.offset == 0;\n\n        // now write our output data:\n        int count = 0;\n        for (int i = 0; i < numEntries; i++) {\n          if (dedupSet != null) {\n            // box once\n            final Integer ent = output.ords.get(i);\n            if (dedupSet.contains(ent)) {\n              continue;\n            }\n            dedupSet.add(ent);\n          }\n          scratchOutput.writeVInt(output.ords.get(i));   \n          count++;\n        }\n\n        final int pos = scratchOutput.getPosition();\n        scratchOutput.writeVInt(count << 1 | (output.includeOrig ? 0 : 1));\n        final int pos2 = scratchOutput.getPosition();\n        final int vIntLen = pos2-pos;\n\n        // Move the count + includeOrig to the front of the byte[]:\n        System.arraycopy(scratch.bytes, pos, spare, 0, vIntLen);\n        System.arraycopy(scratch.bytes, 0, scratch.bytes, vIntLen, pos);\n        System.arraycopy(spare, 0, scratch.bytes, 0, vIntLen);\n\n        if (dedupSet != null) {\n          dedupSet.clear();\n        }\n        \n        scratch.length = scratchOutput.getPosition() - scratch.offset;\n        //System.out.println(\"  add input=\" + input + \" output=\" + scratch + \" offset=\" + scratch.offset + \" length=\" + scratch.length + \" count=\" + count);\n        builder.add(Util.toUTF32(input, scratchIntsRef), BytesRef.deepCopyOf(scratch));\n      }\n      \n      FST<BytesRef> fst = builder.finish();\n      return new SynonymMap(fst, words, maxHorizontalContext);\n    }\n\n","sourceOld":"    /**\n     * Builds an {@link SynonymMap} and returns it.\n     */\n    public SynonymMap build() throws IOException {\n      ByteSequenceOutputs outputs = ByteSequenceOutputs.getSingleton();\n      // TODO: are we using the best sharing options?\n      org.apache.lucene.util.fst.Builder<BytesRef> builder = \n        new org.apache.lucene.util.fst.Builder<BytesRef>(FST.INPUT_TYPE.BYTE4, outputs);\n      \n      BytesRef scratch = new BytesRef(64);\n      ByteArrayDataOutput scratchOutput = new ByteArrayDataOutput();\n\n      final Set<Integer> dedupSet;\n\n      if (dedup) {\n        dedupSet = new HashSet<Integer>();\n      } else {\n        dedupSet = null;\n      }\n\n      final byte[] spare = new byte[5];\n      \n      Set<CharsRef> keys = workingSet.keySet();\n      CharsRef sortedKeys[] = keys.toArray(new CharsRef[keys.size()]);\n      Arrays.sort(sortedKeys, CharsRef.getUTF16SortedAsUTF8Comparator());\n      \n      //System.out.println(\"fmap.build\");\n      for (int keyIdx = 0; keyIdx < sortedKeys.length; keyIdx++) {\n        CharsRef input = sortedKeys[keyIdx];\n        MapEntry output = workingSet.get(input);\n\n        int numEntries = output.ords.size();\n        // output size, assume the worst case\n        int estimatedSize = 5 + numEntries * 5; // numEntries + one ord for each entry\n        \n        scratch.grow(estimatedSize);\n        scratchOutput.reset(scratch.bytes, scratch.offset, scratch.bytes.length);\n        assert scratch.offset == 0;\n\n        // now write our output data:\n        int count = 0;\n        for (int i = 0; i < numEntries; i++) {\n          if (dedupSet != null) {\n            // box once\n            final Integer ent = output.ords.get(i);\n            if (dedupSet.contains(ent)) {\n              continue;\n            }\n            dedupSet.add(ent);\n          }\n          scratchOutput.writeVInt(output.ords.get(i));   \n          count++;\n        }\n\n        final int pos = scratchOutput.getPosition();\n        scratchOutput.writeVInt(count << 1 | (output.includeOrig ? 0 : 1));\n        final int pos2 = scratchOutput.getPosition();\n        final int vIntLen = pos2-pos;\n\n        // Move the count + includeOrig to the front of the byte[]:\n        System.arraycopy(scratch.bytes, pos, spare, 0, vIntLen);\n        System.arraycopy(scratch.bytes, 0, scratch.bytes, vIntLen, pos);\n        System.arraycopy(spare, 0, scratch.bytes, 0, vIntLen);\n\n        if (dedupSet != null) {\n          dedupSet.clear();\n        }\n        \n        scratch.length = scratchOutput.getPosition() - scratch.offset;\n        //System.out.println(\"  add input=\" + input + \" output=\" + scratch + \" offset=\" + scratch.offset + \" length=\" + scratch.length + \" count=\" + count);\n        builder.add(input, BytesRef.deepCopyOf(scratch));\n      }\n      \n      FST<BytesRef> fst = builder.finish();\n      return new SynonymMap(fst, words, maxHorizontalContext);\n    }\n\n","bugFix":["e6e919043fa85ee891123768dd655a98edbbf63c"],"bugIntro":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#build().mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#build().mjava","sourceNew":"    /**\n     * Builds an {@link SynonymMap} and returns it.\n     */\n    public SynonymMap build() throws IOException {\n      ByteSequenceOutputs outputs = ByteSequenceOutputs.getSingleton();\n      // TODO: are we using the best sharing options?\n      org.apache.lucene.util.fst.Builder<BytesRef> builder = \n        new org.apache.lucene.util.fst.Builder<BytesRef>(FST.INPUT_TYPE.BYTE4, outputs);\n      \n      BytesRef scratch = new BytesRef(64);\n      ByteArrayDataOutput scratchOutput = new ByteArrayDataOutput();\n\n      final Set<Integer> dedupSet;\n\n      if (dedup) {\n        dedupSet = new HashSet<Integer>();\n      } else {\n        dedupSet = null;\n      }\n\n      final byte[] spare = new byte[5];\n      \n      Set<CharsRef> keys = workingSet.keySet();\n      CharsRef sortedKeys[] = keys.toArray(new CharsRef[keys.size()]);\n      Arrays.sort(sortedKeys, CharsRef.getUTF16SortedAsUTF8Comparator());\n\n      final IntsRef scratchIntsRef = new IntsRef();\n      \n      //System.out.println(\"fmap.build\");\n      for (int keyIdx = 0; keyIdx < sortedKeys.length; keyIdx++) {\n        CharsRef input = sortedKeys[keyIdx];\n        MapEntry output = workingSet.get(input);\n\n        int numEntries = output.ords.size();\n        // output size, assume the worst case\n        int estimatedSize = 5 + numEntries * 5; // numEntries + one ord for each entry\n        \n        scratch.grow(estimatedSize);\n        scratchOutput.reset(scratch.bytes, scratch.offset, scratch.bytes.length);\n        assert scratch.offset == 0;\n\n        // now write our output data:\n        int count = 0;\n        for (int i = 0; i < numEntries; i++) {\n          if (dedupSet != null) {\n            // box once\n            final Integer ent = output.ords.get(i);\n            if (dedupSet.contains(ent)) {\n              continue;\n            }\n            dedupSet.add(ent);\n          }\n          scratchOutput.writeVInt(output.ords.get(i));   \n          count++;\n        }\n\n        final int pos = scratchOutput.getPosition();\n        scratchOutput.writeVInt(count << 1 | (output.includeOrig ? 0 : 1));\n        final int pos2 = scratchOutput.getPosition();\n        final int vIntLen = pos2-pos;\n\n        // Move the count + includeOrig to the front of the byte[]:\n        System.arraycopy(scratch.bytes, pos, spare, 0, vIntLen);\n        System.arraycopy(scratch.bytes, 0, scratch.bytes, vIntLen, pos);\n        System.arraycopy(spare, 0, scratch.bytes, 0, vIntLen);\n\n        if (dedupSet != null) {\n          dedupSet.clear();\n        }\n        \n        scratch.length = scratchOutput.getPosition() - scratch.offset;\n        //System.out.println(\"  add input=\" + input + \" output=\" + scratch + \" offset=\" + scratch.offset + \" length=\" + scratch.length + \" count=\" + count);\n        builder.add(Util.toUTF32(input, scratchIntsRef), BytesRef.deepCopyOf(scratch));\n      }\n      \n      FST<BytesRef> fst = builder.finish();\n      return new SynonymMap(fst, words, maxHorizontalContext);\n    }\n\n","sourceOld":"    /**\n     * Builds an {@link SynonymMap} and returns it.\n     */\n    public SynonymMap build() throws IOException {\n      ByteSequenceOutputs outputs = ByteSequenceOutputs.getSingleton();\n      // TODO: are we using the best sharing options?\n      org.apache.lucene.util.fst.Builder<BytesRef> builder = \n        new org.apache.lucene.util.fst.Builder<BytesRef>(FST.INPUT_TYPE.BYTE4, outputs);\n      \n      BytesRef scratch = new BytesRef(64);\n      ByteArrayDataOutput scratchOutput = new ByteArrayDataOutput();\n\n      final Set<Integer> dedupSet;\n\n      if (dedup) {\n        dedupSet = new HashSet<Integer>();\n      } else {\n        dedupSet = null;\n      }\n\n      final byte[] spare = new byte[5];\n      \n      Set<CharsRef> keys = workingSet.keySet();\n      CharsRef sortedKeys[] = keys.toArray(new CharsRef[keys.size()]);\n      Arrays.sort(sortedKeys, CharsRef.getUTF16SortedAsUTF8Comparator());\n\n      final IntsRef scratchIntsRef = new IntsRef();\n      \n      //System.out.println(\"fmap.build\");\n      for (int keyIdx = 0; keyIdx < sortedKeys.length; keyIdx++) {\n        CharsRef input = sortedKeys[keyIdx];\n        MapEntry output = workingSet.get(input);\n\n        int numEntries = output.ords.size();\n        // output size, assume the worst case\n        int estimatedSize = 5 + numEntries * 5; // numEntries + one ord for each entry\n        \n        scratch.grow(estimatedSize);\n        scratchOutput.reset(scratch.bytes, scratch.offset, scratch.bytes.length);\n        assert scratch.offset == 0;\n\n        // now write our output data:\n        int count = 0;\n        for (int i = 0; i < numEntries; i++) {\n          if (dedupSet != null) {\n            // box once\n            final Integer ent = output.ords.get(i);\n            if (dedupSet.contains(ent)) {\n              continue;\n            }\n            dedupSet.add(ent);\n          }\n          scratchOutput.writeVInt(output.ords.get(i));   \n          count++;\n        }\n\n        final int pos = scratchOutput.getPosition();\n        scratchOutput.writeVInt(count << 1 | (output.includeOrig ? 0 : 1));\n        final int pos2 = scratchOutput.getPosition();\n        final int vIntLen = pos2-pos;\n\n        // Move the count + includeOrig to the front of the byte[]:\n        System.arraycopy(scratch.bytes, pos, spare, 0, vIntLen);\n        System.arraycopy(scratch.bytes, 0, scratch.bytes, vIntLen, pos);\n        System.arraycopy(spare, 0, scratch.bytes, 0, vIntLen);\n\n        if (dedupSet != null) {\n          dedupSet.clear();\n        }\n        \n        scratch.length = scratchOutput.getPosition() - scratch.offset;\n        //System.out.println(\"  add input=\" + input + \" output=\" + scratch + \" offset=\" + scratch.offset + \" length=\" + scratch.length + \" count=\" + count);\n        builder.add(Util.toUTF32(input, scratchIntsRef), BytesRef.deepCopyOf(scratch));\n      }\n      \n      FST<BytesRef> fst = builder.finish();\n      return new SynonymMap(fst, words, maxHorizontalContext);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["1ec890fad2ea96317f4429e0aa0085bb25673641"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4f2bf10c11daad40c1e46fabd0d414c19a3e605b":["44d6f0ab53c1962856b9f48dedb7a2a6cc18905c"],"44d6f0ab53c1962856b9f48dedb7a2a6cc18905c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"e6e919043fa85ee891123768dd655a98edbbf63c":["4f2bf10c11daad40c1e46fabd0d414c19a3e605b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"1ec890fad2ea96317f4429e0aa0085bb25673641":["e6e919043fa85ee891123768dd655a98edbbf63c"]},"commit2Childs":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["44d6f0ab53c1962856b9f48dedb7a2a6cc18905c"],"4f2bf10c11daad40c1e46fabd0d414c19a3e605b":["e6e919043fa85ee891123768dd655a98edbbf63c"],"44d6f0ab53c1962856b9f48dedb7a2a6cc18905c":["4f2bf10c11daad40c1e46fabd0d414c19a3e605b"],"e6e919043fa85ee891123768dd655a98edbbf63c":["1ec890fad2ea96317f4429e0aa0085bb25673641"],"1ec890fad2ea96317f4429e0aa0085bb25673641":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}