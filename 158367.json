{"path":"lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesConsumer#addTermsDict(FieldInfo,Iterable[BytesRef]).mjava","commits":[{"id":"8106bc60c7452250f84c65cdb43ab6b1d8eb1534","date":1401906364,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesConsumer#addTermsDict(FieldInfo,Iterable[BytesRef]).mjava","pathOld":"/dev/null","sourceNew":"  /** expert: writes a value dictionary for a sorted/sortedset field */\n  protected void addTermsDict(FieldInfo field, final Iterable<BytesRef> values) throws IOException {\n    // first check if its a \"fixed-length\" terms dict\n    int minLength = Integer.MAX_VALUE;\n    int maxLength = Integer.MIN_VALUE;\n    for (BytesRef v : values) {\n      minLength = Math.min(minLength, v.length);\n      maxLength = Math.max(maxLength, v.length);\n    }\n    if (minLength == maxLength) {\n      // no index needed: direct addressing by mult\n      addBinaryField(field, values);\n    } else {\n      // header\n      meta.writeVInt(field.number);\n      meta.writeByte(Lucene49DocValuesFormat.BINARY);\n      meta.writeVInt(BINARY_PREFIX_COMPRESSED);\n      meta.writeLong(-1L);\n      // now write the bytes: sharing prefixes within a block\n      final long startFP = data.getFilePointer();\n      // currently, we have to store the delta from expected for every 1/nth term\n      // we could avoid this, but its not much and less overall RAM than the previous approach!\n      RAMOutputStream addressBuffer = new RAMOutputStream();\n      MonotonicBlockPackedWriter termAddresses = new MonotonicBlockPackedWriter(addressBuffer, BLOCK_SIZE);\n      BytesRef lastTerm = new BytesRef();\n      long count = 0;\n      for (BytesRef v : values) {\n        if (count % ADDRESS_INTERVAL == 0) {\n          termAddresses.add(data.getFilePointer() - startFP);\n          // force the first term in a block to be abs-encoded\n          lastTerm.length = 0;\n        }\n        \n        // prefix-code\n        int sharedPrefix = StringHelper.bytesDifference(lastTerm, v);\n        data.writeVInt(sharedPrefix);\n        data.writeVInt(v.length - sharedPrefix);\n        data.writeBytes(v.bytes, v.offset + sharedPrefix, v.length - sharedPrefix);\n        lastTerm.copyBytes(v);\n        count++;\n      }\n      final long indexStartFP = data.getFilePointer();\n      // write addresses of indexed terms\n      termAddresses.finish();\n      addressBuffer.writeTo(data);\n      addressBuffer = null;\n      termAddresses = null;\n      meta.writeVInt(minLength);\n      meta.writeVInt(maxLength);\n      meta.writeVLong(count);\n      meta.writeLong(startFP);\n      meta.writeVInt(ADDRESS_INTERVAL);\n      meta.writeLong(indexStartFP);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      meta.writeVInt(BLOCK_SIZE);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6ae889c32f4f301251f60804d7082a520e0594c6","date":1402924441,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesConsumer#addTermsDict(FieldInfo,Iterable[BytesRef]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesConsumer#addTermsDict(FieldInfo,Iterable[BytesRef]).mjava","sourceNew":"  /** expert: writes a value dictionary for a sorted/sortedset field */\n  private void addTermsDict(FieldInfo field, final Iterable<BytesRef> values) throws IOException {\n    // first check if its a \"fixed-length\" terms dict\n    int minLength = Integer.MAX_VALUE;\n    int maxLength = Integer.MIN_VALUE;\n    for (BytesRef v : values) {\n      minLength = Math.min(minLength, v.length);\n      maxLength = Math.max(maxLength, v.length);\n    }\n    if (minLength == maxLength) {\n      // no index needed: direct addressing by mult\n      addBinaryField(field, values);\n    } else {\n      // header\n      meta.writeVInt(field.number);\n      meta.writeByte(Lucene49DocValuesFormat.BINARY);\n      meta.writeVInt(BINARY_PREFIX_COMPRESSED);\n      meta.writeLong(-1L);\n      // now write the bytes: sharing prefixes within a block\n      final long startFP = data.getFilePointer();\n      // currently, we have to store the delta from expected for every 1/nth term\n      // we could avoid this, but its not much and less overall RAM than the previous approach!\n      RAMOutputStream addressBuffer = new RAMOutputStream();\n      MonotonicBlockPackedWriter termAddresses = new MonotonicBlockPackedWriter(addressBuffer, BLOCK_SIZE);\n      BytesRef lastTerm = new BytesRef();\n      long count = 0;\n      for (BytesRef v : values) {\n        if (count % ADDRESS_INTERVAL == 0) {\n          termAddresses.add(data.getFilePointer() - startFP);\n          // force the first term in a block to be abs-encoded\n          lastTerm.length = 0;\n        }\n        \n        // prefix-code\n        int sharedPrefix = StringHelper.bytesDifference(lastTerm, v);\n        data.writeVInt(sharedPrefix);\n        data.writeVInt(v.length - sharedPrefix);\n        data.writeBytes(v.bytes, v.offset + sharedPrefix, v.length - sharedPrefix);\n        lastTerm.copyBytes(v);\n        count++;\n      }\n      final long indexStartFP = data.getFilePointer();\n      // write addresses of indexed terms\n      termAddresses.finish();\n      addressBuffer.writeTo(data);\n      addressBuffer = null;\n      termAddresses = null;\n      meta.writeVInt(minLength);\n      meta.writeVInt(maxLength);\n      meta.writeVLong(count);\n      meta.writeLong(startFP);\n      meta.writeVInt(ADDRESS_INTERVAL);\n      meta.writeLong(indexStartFP);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      meta.writeVInt(BLOCK_SIZE);\n    }\n  }\n\n","sourceOld":"  /** expert: writes a value dictionary for a sorted/sortedset field */\n  protected void addTermsDict(FieldInfo field, final Iterable<BytesRef> values) throws IOException {\n    // first check if its a \"fixed-length\" terms dict\n    int minLength = Integer.MAX_VALUE;\n    int maxLength = Integer.MIN_VALUE;\n    for (BytesRef v : values) {\n      minLength = Math.min(minLength, v.length);\n      maxLength = Math.max(maxLength, v.length);\n    }\n    if (minLength == maxLength) {\n      // no index needed: direct addressing by mult\n      addBinaryField(field, values);\n    } else {\n      // header\n      meta.writeVInt(field.number);\n      meta.writeByte(Lucene49DocValuesFormat.BINARY);\n      meta.writeVInt(BINARY_PREFIX_COMPRESSED);\n      meta.writeLong(-1L);\n      // now write the bytes: sharing prefixes within a block\n      final long startFP = data.getFilePointer();\n      // currently, we have to store the delta from expected for every 1/nth term\n      // we could avoid this, but its not much and less overall RAM than the previous approach!\n      RAMOutputStream addressBuffer = new RAMOutputStream();\n      MonotonicBlockPackedWriter termAddresses = new MonotonicBlockPackedWriter(addressBuffer, BLOCK_SIZE);\n      BytesRef lastTerm = new BytesRef();\n      long count = 0;\n      for (BytesRef v : values) {\n        if (count % ADDRESS_INTERVAL == 0) {\n          termAddresses.add(data.getFilePointer() - startFP);\n          // force the first term in a block to be abs-encoded\n          lastTerm.length = 0;\n        }\n        \n        // prefix-code\n        int sharedPrefix = StringHelper.bytesDifference(lastTerm, v);\n        data.writeVInt(sharedPrefix);\n        data.writeVInt(v.length - sharedPrefix);\n        data.writeBytes(v.bytes, v.offset + sharedPrefix, v.length - sharedPrefix);\n        lastTerm.copyBytes(v);\n        count++;\n      }\n      final long indexStartFP = data.getFilePointer();\n      // write addresses of indexed terms\n      termAddresses.finish();\n      addressBuffer.writeTo(data);\n      addressBuffer = null;\n      termAddresses = null;\n      meta.writeVInt(minLength);\n      meta.writeVInt(maxLength);\n      meta.writeVLong(count);\n      meta.writeLong(startFP);\n      meta.writeVInt(ADDRESS_INTERVAL);\n      meta.writeLong(indexStartFP);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      meta.writeVInt(BLOCK_SIZE);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c6f080a2ab37c464dd98db173f6cbf10dc74f211","date":1402946779,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesConsumer#addTermsDict(FieldInfo,Iterable[BytesRef]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesConsumer#addTermsDict(FieldInfo,Iterable[BytesRef]).mjava","sourceNew":"  /** expert: writes a value dictionary for a sorted/sortedset field */\n  private void addTermsDict(FieldInfo field, final Iterable<BytesRef> values) throws IOException {\n    // first check if its a \"fixed-length\" terms dict\n    int minLength = Integer.MAX_VALUE;\n    int maxLength = Integer.MIN_VALUE;\n    for (BytesRef v : values) {\n      minLength = Math.min(minLength, v.length);\n      maxLength = Math.max(maxLength, v.length);\n    }\n    if (minLength == maxLength) {\n      // no index needed: direct addressing by mult\n      addBinaryField(field, values);\n    } else {\n      // header\n      meta.writeVInt(field.number);\n      meta.writeByte(Lucene49DocValuesFormat.BINARY);\n      meta.writeVInt(BINARY_PREFIX_COMPRESSED);\n      meta.writeLong(-1L);\n      // now write the bytes: sharing prefixes within a block\n      final long startFP = data.getFilePointer();\n      // currently, we have to store the delta from expected for every 1/nth term\n      // we could avoid this, but its not much and less overall RAM than the previous approach!\n      RAMOutputStream addressBuffer = new RAMOutputStream();\n      MonotonicBlockPackedWriter termAddresses = new MonotonicBlockPackedWriter(addressBuffer, BLOCK_SIZE);\n      BytesRef lastTerm = new BytesRef();\n      long count = 0;\n      for (BytesRef v : values) {\n        if (count % ADDRESS_INTERVAL == 0) {\n          termAddresses.add(data.getFilePointer() - startFP);\n          // force the first term in a block to be abs-encoded\n          lastTerm.length = 0;\n        }\n        \n        // prefix-code\n        int sharedPrefix = StringHelper.bytesDifference(lastTerm, v);\n        data.writeVInt(sharedPrefix);\n        data.writeVInt(v.length - sharedPrefix);\n        data.writeBytes(v.bytes, v.offset + sharedPrefix, v.length - sharedPrefix);\n        lastTerm.copyBytes(v);\n        count++;\n      }\n      final long indexStartFP = data.getFilePointer();\n      // write addresses of indexed terms\n      termAddresses.finish();\n      addressBuffer.writeTo(data);\n      addressBuffer = null;\n      termAddresses = null;\n      meta.writeVInt(minLength);\n      meta.writeVInt(maxLength);\n      meta.writeVLong(count);\n      meta.writeLong(startFP);\n      meta.writeVInt(ADDRESS_INTERVAL);\n      meta.writeLong(indexStartFP);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      meta.writeVInt(BLOCK_SIZE);\n    }\n  }\n\n","sourceOld":"  /** expert: writes a value dictionary for a sorted/sortedset field */\n  protected void addTermsDict(FieldInfo field, final Iterable<BytesRef> values) throws IOException {\n    // first check if its a \"fixed-length\" terms dict\n    int minLength = Integer.MAX_VALUE;\n    int maxLength = Integer.MIN_VALUE;\n    for (BytesRef v : values) {\n      minLength = Math.min(minLength, v.length);\n      maxLength = Math.max(maxLength, v.length);\n    }\n    if (minLength == maxLength) {\n      // no index needed: direct addressing by mult\n      addBinaryField(field, values);\n    } else {\n      // header\n      meta.writeVInt(field.number);\n      meta.writeByte(Lucene49DocValuesFormat.BINARY);\n      meta.writeVInt(BINARY_PREFIX_COMPRESSED);\n      meta.writeLong(-1L);\n      // now write the bytes: sharing prefixes within a block\n      final long startFP = data.getFilePointer();\n      // currently, we have to store the delta from expected for every 1/nth term\n      // we could avoid this, but its not much and less overall RAM than the previous approach!\n      RAMOutputStream addressBuffer = new RAMOutputStream();\n      MonotonicBlockPackedWriter termAddresses = new MonotonicBlockPackedWriter(addressBuffer, BLOCK_SIZE);\n      BytesRef lastTerm = new BytesRef();\n      long count = 0;\n      for (BytesRef v : values) {\n        if (count % ADDRESS_INTERVAL == 0) {\n          termAddresses.add(data.getFilePointer() - startFP);\n          // force the first term in a block to be abs-encoded\n          lastTerm.length = 0;\n        }\n        \n        // prefix-code\n        int sharedPrefix = StringHelper.bytesDifference(lastTerm, v);\n        data.writeVInt(sharedPrefix);\n        data.writeVInt(v.length - sharedPrefix);\n        data.writeBytes(v.bytes, v.offset + sharedPrefix, v.length - sharedPrefix);\n        lastTerm.copyBytes(v);\n        count++;\n      }\n      final long indexStartFP = data.getFilePointer();\n      // write addresses of indexed terms\n      termAddresses.finish();\n      addressBuffer.writeTo(data);\n      addressBuffer = null;\n      termAddresses = null;\n      meta.writeVInt(minLength);\n      meta.writeVInt(maxLength);\n      meta.writeVLong(count);\n      meta.writeLong(startFP);\n      meta.writeVInt(ADDRESS_INTERVAL);\n      meta.writeLong(indexStartFP);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      meta.writeVInt(BLOCK_SIZE);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b2f1e6929ec3acd5593810e4906147f47aa7a869","date":1405805539,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesConsumer#addTermsDict(FieldInfo,Iterable[BytesRef]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesConsumer#addTermsDict(FieldInfo,Iterable[BytesRef]).mjava","sourceNew":"  /** expert: writes a value dictionary for a sorted/sortedset field */\n  private void addTermsDict(FieldInfo field, final Iterable<BytesRef> values) throws IOException {\n    // first check if its a \"fixed-length\" terms dict\n    int minLength = Integer.MAX_VALUE;\n    int maxLength = Integer.MIN_VALUE;\n    for (BytesRef v : values) {\n      minLength = Math.min(minLength, v.length);\n      maxLength = Math.max(maxLength, v.length);\n    }\n    if (minLength == maxLength) {\n      // no index needed: direct addressing by mult\n      addBinaryField(field, values);\n    } else {\n      // header\n      meta.writeVInt(field.number);\n      meta.writeByte(Lucene49DocValuesFormat.BINARY);\n      meta.writeVInt(BINARY_PREFIX_COMPRESSED);\n      meta.writeLong(-1L);\n      // now write the bytes: sharing prefixes within a block\n      final long startFP = data.getFilePointer();\n      // currently, we have to store the delta from expected for every 1/nth term\n      // we could avoid this, but its not much and less overall RAM than the previous approach!\n      RAMOutputStream addressBuffer = new RAMOutputStream();\n      MonotonicBlockPackedWriter termAddresses = new MonotonicBlockPackedWriter(addressBuffer, BLOCK_SIZE);\n      BytesRef lastTerm = new BytesRef(Math.max(0, maxLength));\n      long count = 0;\n      for (BytesRef v : values) {\n        if (count % ADDRESS_INTERVAL == 0) {\n          termAddresses.add(data.getFilePointer() - startFP);\n          // force the first term in a block to be abs-encoded\n          lastTerm.length = 0;\n        }\n        \n        // prefix-code\n        int sharedPrefix = StringHelper.bytesDifference(lastTerm, v);\n        data.writeVInt(sharedPrefix);\n        data.writeVInt(v.length - sharedPrefix);\n        data.writeBytes(v.bytes, v.offset + sharedPrefix, v.length - sharedPrefix);\n        lastTerm.copyBytes(v);\n        count++;\n      }\n      final long indexStartFP = data.getFilePointer();\n      // write addresses of indexed terms\n      termAddresses.finish();\n      addressBuffer.writeTo(data);\n      addressBuffer = null;\n      termAddresses = null;\n      meta.writeVInt(minLength);\n      meta.writeVInt(maxLength);\n      meta.writeVLong(count);\n      meta.writeLong(startFP);\n      meta.writeVInt(ADDRESS_INTERVAL);\n      meta.writeLong(indexStartFP);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      meta.writeVInt(BLOCK_SIZE);\n    }\n  }\n\n","sourceOld":"  /** expert: writes a value dictionary for a sorted/sortedset field */\n  private void addTermsDict(FieldInfo field, final Iterable<BytesRef> values) throws IOException {\n    // first check if its a \"fixed-length\" terms dict\n    int minLength = Integer.MAX_VALUE;\n    int maxLength = Integer.MIN_VALUE;\n    for (BytesRef v : values) {\n      minLength = Math.min(minLength, v.length);\n      maxLength = Math.max(maxLength, v.length);\n    }\n    if (minLength == maxLength) {\n      // no index needed: direct addressing by mult\n      addBinaryField(field, values);\n    } else {\n      // header\n      meta.writeVInt(field.number);\n      meta.writeByte(Lucene49DocValuesFormat.BINARY);\n      meta.writeVInt(BINARY_PREFIX_COMPRESSED);\n      meta.writeLong(-1L);\n      // now write the bytes: sharing prefixes within a block\n      final long startFP = data.getFilePointer();\n      // currently, we have to store the delta from expected for every 1/nth term\n      // we could avoid this, but its not much and less overall RAM than the previous approach!\n      RAMOutputStream addressBuffer = new RAMOutputStream();\n      MonotonicBlockPackedWriter termAddresses = new MonotonicBlockPackedWriter(addressBuffer, BLOCK_SIZE);\n      BytesRef lastTerm = new BytesRef();\n      long count = 0;\n      for (BytesRef v : values) {\n        if (count % ADDRESS_INTERVAL == 0) {\n          termAddresses.add(data.getFilePointer() - startFP);\n          // force the first term in a block to be abs-encoded\n          lastTerm.length = 0;\n        }\n        \n        // prefix-code\n        int sharedPrefix = StringHelper.bytesDifference(lastTerm, v);\n        data.writeVInt(sharedPrefix);\n        data.writeVInt(v.length - sharedPrefix);\n        data.writeBytes(v.bytes, v.offset + sharedPrefix, v.length - sharedPrefix);\n        lastTerm.copyBytes(v);\n        count++;\n      }\n      final long indexStartFP = data.getFilePointer();\n      // write addresses of indexed terms\n      termAddresses.finish();\n      addressBuffer.writeTo(data);\n      addressBuffer = null;\n      termAddresses = null;\n      meta.writeVInt(minLength);\n      meta.writeVInt(maxLength);\n      meta.writeVLong(count);\n      meta.writeLong(startFP);\n      meta.writeVInt(ADDRESS_INTERVAL);\n      meta.writeLong(indexStartFP);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      meta.writeVInt(BLOCK_SIZE);\n    }\n  }\n\n","bugFix":null,"bugIntro":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","date":1407854805,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesConsumer#addTermsDict(FieldInfo,Iterable[BytesRef]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesConsumer#addTermsDict(FieldInfo,Iterable[BytesRef]).mjava","sourceNew":"  /** expert: writes a value dictionary for a sorted/sortedset field */\n  private void addTermsDict(FieldInfo field, final Iterable<BytesRef> values) throws IOException {\n    // first check if its a \"fixed-length\" terms dict\n    int minLength = Integer.MAX_VALUE;\n    int maxLength = Integer.MIN_VALUE;\n    for (BytesRef v : values) {\n      minLength = Math.min(minLength, v.length);\n      maxLength = Math.max(maxLength, v.length);\n    }\n    if (minLength == maxLength) {\n      // no index needed: direct addressing by mult\n      addBinaryField(field, values);\n    } else {\n      // header\n      meta.writeVInt(field.number);\n      meta.writeByte(Lucene49DocValuesFormat.BINARY);\n      meta.writeVInt(BINARY_PREFIX_COMPRESSED);\n      meta.writeLong(-1L);\n      // now write the bytes: sharing prefixes within a block\n      final long startFP = data.getFilePointer();\n      // currently, we have to store the delta from expected for every 1/nth term\n      // we could avoid this, but its not much and less overall RAM than the previous approach!\n      RAMOutputStream addressBuffer = new RAMOutputStream();\n      MonotonicBlockPackedWriter termAddresses = new MonotonicBlockPackedWriter(addressBuffer, BLOCK_SIZE);\n      BytesRefBuilder lastTerm = new BytesRefBuilder();\n      lastTerm.grow(Math.max(0, maxLength));\n      long count = 0;\n      for (BytesRef v : values) {\n        if (count % ADDRESS_INTERVAL == 0) {\n          termAddresses.add(data.getFilePointer() - startFP);\n          // force the first term in a block to be abs-encoded\n          lastTerm.clear();\n        }\n        \n        // prefix-code\n        int sharedPrefix = StringHelper.bytesDifference(lastTerm.get(), v);\n        data.writeVInt(sharedPrefix);\n        data.writeVInt(v.length - sharedPrefix);\n        data.writeBytes(v.bytes, v.offset + sharedPrefix, v.length - sharedPrefix);\n        lastTerm.copyBytes(v);\n        count++;\n      }\n      final long indexStartFP = data.getFilePointer();\n      // write addresses of indexed terms\n      termAddresses.finish();\n      addressBuffer.writeTo(data);\n      addressBuffer = null;\n      termAddresses = null;\n      meta.writeVInt(minLength);\n      meta.writeVInt(maxLength);\n      meta.writeVLong(count);\n      meta.writeLong(startFP);\n      meta.writeVInt(ADDRESS_INTERVAL);\n      meta.writeLong(indexStartFP);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      meta.writeVInt(BLOCK_SIZE);\n    }\n  }\n\n","sourceOld":"  /** expert: writes a value dictionary for a sorted/sortedset field */\n  private void addTermsDict(FieldInfo field, final Iterable<BytesRef> values) throws IOException {\n    // first check if its a \"fixed-length\" terms dict\n    int minLength = Integer.MAX_VALUE;\n    int maxLength = Integer.MIN_VALUE;\n    for (BytesRef v : values) {\n      minLength = Math.min(minLength, v.length);\n      maxLength = Math.max(maxLength, v.length);\n    }\n    if (minLength == maxLength) {\n      // no index needed: direct addressing by mult\n      addBinaryField(field, values);\n    } else {\n      // header\n      meta.writeVInt(field.number);\n      meta.writeByte(Lucene49DocValuesFormat.BINARY);\n      meta.writeVInt(BINARY_PREFIX_COMPRESSED);\n      meta.writeLong(-1L);\n      // now write the bytes: sharing prefixes within a block\n      final long startFP = data.getFilePointer();\n      // currently, we have to store the delta from expected for every 1/nth term\n      // we could avoid this, but its not much and less overall RAM than the previous approach!\n      RAMOutputStream addressBuffer = new RAMOutputStream();\n      MonotonicBlockPackedWriter termAddresses = new MonotonicBlockPackedWriter(addressBuffer, BLOCK_SIZE);\n      BytesRef lastTerm = new BytesRef(Math.max(0, maxLength));\n      long count = 0;\n      for (BytesRef v : values) {\n        if (count % ADDRESS_INTERVAL == 0) {\n          termAddresses.add(data.getFilePointer() - startFP);\n          // force the first term in a block to be abs-encoded\n          lastTerm.length = 0;\n        }\n        \n        // prefix-code\n        int sharedPrefix = StringHelper.bytesDifference(lastTerm, v);\n        data.writeVInt(sharedPrefix);\n        data.writeVInt(v.length - sharedPrefix);\n        data.writeBytes(v.bytes, v.offset + sharedPrefix, v.length - sharedPrefix);\n        lastTerm.copyBytes(v);\n        count++;\n      }\n      final long indexStartFP = data.getFilePointer();\n      // write addresses of indexed terms\n      termAddresses.finish();\n      addressBuffer.writeTo(data);\n      addressBuffer = null;\n      termAddresses = null;\n      meta.writeVInt(minLength);\n      meta.writeVInt(maxLength);\n      meta.writeVLong(count);\n      meta.writeLong(startFP);\n      meta.writeVInt(ADDRESS_INTERVAL);\n      meta.writeLong(indexStartFP);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      meta.writeVInt(BLOCK_SIZE);\n    }\n  }\n\n","bugFix":["8106bc60c7452250f84c65cdb43ab6b1d8eb1534","b2f1e6929ec3acd5593810e4906147f47aa7a869"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cc45c615dbb82bf79d5f9550286098367874fbf","date":1409571423,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesConsumer#addTermsDict(FieldInfo,Iterable[BytesRef]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesConsumer#addTermsDict(FieldInfo,Iterable[BytesRef]).mjava","sourceNew":"  /** expert: writes a value dictionary for a sorted/sortedset field */\n  private void addTermsDict(FieldInfo field, final Iterable<BytesRef> values) throws IOException {\n    // first check if its a \"fixed-length\" terms dict\n    int minLength = Integer.MAX_VALUE;\n    int maxLength = Integer.MIN_VALUE;\n    for (BytesRef v : values) {\n      minLength = Math.min(minLength, v.length);\n      maxLength = Math.max(maxLength, v.length);\n    }\n    if (minLength == maxLength) {\n      // no index needed: direct addressing by mult\n      addBinaryField(field, values);\n    } else {\n      // header\n      meta.writeVInt(field.number);\n      meta.writeByte(Lucene49DocValuesFormat.BINARY);\n      meta.writeVInt(BINARY_PREFIX_COMPRESSED);\n      meta.writeLong(-1L);\n      // now write the bytes: sharing prefixes within a block\n      final long startFP = data.getFilePointer();\n      // currently, we have to store the delta from expected for every 1/nth term\n      // we could avoid this, but its not much and less overall RAM than the previous approach!\n      RAMOutputStream addressBuffer = new RAMOutputStream();\n      MonotonicBlockPackedWriter termAddresses = new MonotonicBlockPackedWriter(addressBuffer, BLOCK_SIZE);\n      BytesRefBuilder lastTerm = new BytesRefBuilder();\n      lastTerm.grow(Math.max(0, maxLength));\n      long count = 0;\n      for (BytesRef v : values) {\n        if (count % ADDRESS_INTERVAL == 0) {\n          termAddresses.add(data.getFilePointer() - startFP);\n          // force the first term in a block to be abs-encoded\n          lastTerm.clear();\n        }\n        \n        // prefix-code\n        int sharedPrefix = StringHelper.bytesDifference(lastTerm.get(), v);\n        data.writeVInt(sharedPrefix);\n        data.writeVInt(v.length - sharedPrefix);\n        data.writeBytes(v.bytes, v.offset + sharedPrefix, v.length - sharedPrefix);\n        lastTerm.copyBytes(v);\n        count++;\n      }\n      final long indexStartFP = data.getFilePointer();\n      // write addresses of indexed terms\n      termAddresses.finish();\n      addressBuffer.writeTo(data);\n      addressBuffer = null;\n      termAddresses = null;\n      meta.writeVInt(minLength);\n      meta.writeVInt(maxLength);\n      meta.writeVLong(count);\n      meta.writeLong(startFP);\n      meta.writeVInt(ADDRESS_INTERVAL);\n      meta.writeLong(indexStartFP);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      meta.writeVInt(BLOCK_SIZE);\n    }\n  }\n\n","sourceOld":"  /** expert: writes a value dictionary for a sorted/sortedset field */\n  private void addTermsDict(FieldInfo field, final Iterable<BytesRef> values) throws IOException {\n    // first check if its a \"fixed-length\" terms dict\n    int minLength = Integer.MAX_VALUE;\n    int maxLength = Integer.MIN_VALUE;\n    for (BytesRef v : values) {\n      minLength = Math.min(minLength, v.length);\n      maxLength = Math.max(maxLength, v.length);\n    }\n    if (minLength == maxLength) {\n      // no index needed: direct addressing by mult\n      addBinaryField(field, values);\n    } else {\n      // header\n      meta.writeVInt(field.number);\n      meta.writeByte(Lucene49DocValuesFormat.BINARY);\n      meta.writeVInt(BINARY_PREFIX_COMPRESSED);\n      meta.writeLong(-1L);\n      // now write the bytes: sharing prefixes within a block\n      final long startFP = data.getFilePointer();\n      // currently, we have to store the delta from expected for every 1/nth term\n      // we could avoid this, but its not much and less overall RAM than the previous approach!\n      RAMOutputStream addressBuffer = new RAMOutputStream();\n      MonotonicBlockPackedWriter termAddresses = new MonotonicBlockPackedWriter(addressBuffer, BLOCK_SIZE);\n      BytesRefBuilder lastTerm = new BytesRefBuilder();\n      lastTerm.grow(Math.max(0, maxLength));\n      long count = 0;\n      for (BytesRef v : values) {\n        if (count % ADDRESS_INTERVAL == 0) {\n          termAddresses.add(data.getFilePointer() - startFP);\n          // force the first term in a block to be abs-encoded\n          lastTerm.clear();\n        }\n        \n        // prefix-code\n        int sharedPrefix = StringHelper.bytesDifference(lastTerm.get(), v);\n        data.writeVInt(sharedPrefix);\n        data.writeVInt(v.length - sharedPrefix);\n        data.writeBytes(v.bytes, v.offset + sharedPrefix, v.length - sharedPrefix);\n        lastTerm.copyBytes(v);\n        count++;\n      }\n      final long indexStartFP = data.getFilePointer();\n      // write addresses of indexed terms\n      termAddresses.finish();\n      addressBuffer.writeTo(data);\n      addressBuffer = null;\n      termAddresses = null;\n      meta.writeVInt(minLength);\n      meta.writeVInt(maxLength);\n      meta.writeVLong(count);\n      meta.writeLong(startFP);\n      meta.writeVInt(ADDRESS_INTERVAL);\n      meta.writeLong(indexStartFP);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      meta.writeVInt(BLOCK_SIZE);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"402ad3ddc9da7b70da1b167667a60ece6a1381fb","date":1409656478,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesConsumer#addTermsDict(FieldInfo,Iterable[BytesRef]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene49/Lucene49DocValuesConsumer#addTermsDict(FieldInfo,Iterable[BytesRef]).mjava","sourceNew":"  /** expert: writes a value dictionary for a sorted/sortedset field */\n  private void addTermsDict(FieldInfo field, final Iterable<BytesRef> values) throws IOException {\n    // first check if its a \"fixed-length\" terms dict\n    int minLength = Integer.MAX_VALUE;\n    int maxLength = Integer.MIN_VALUE;\n    for (BytesRef v : values) {\n      minLength = Math.min(minLength, v.length);\n      maxLength = Math.max(maxLength, v.length);\n    }\n    if (minLength == maxLength) {\n      // no index needed: direct addressing by mult\n      addBinaryField(field, values);\n    } else {\n      // header\n      meta.writeVInt(field.number);\n      meta.writeByte(Lucene49DocValuesFormat.BINARY);\n      meta.writeVInt(BINARY_PREFIX_COMPRESSED);\n      meta.writeLong(-1L);\n      // now write the bytes: sharing prefixes within a block\n      final long startFP = data.getFilePointer();\n      // currently, we have to store the delta from expected for every 1/nth term\n      // we could avoid this, but its not much and less overall RAM than the previous approach!\n      RAMOutputStream addressBuffer = new RAMOutputStream();\n      MonotonicBlockPackedWriter termAddresses = new MonotonicBlockPackedWriter(addressBuffer, BLOCK_SIZE);\n      BytesRefBuilder lastTerm = new BytesRefBuilder();\n      lastTerm.grow(Math.max(0, maxLength));\n      long count = 0;\n      for (BytesRef v : values) {\n        if (count % ADDRESS_INTERVAL == 0) {\n          termAddresses.add(data.getFilePointer() - startFP);\n          // force the first term in a block to be abs-encoded\n          lastTerm.clear();\n        }\n        \n        // prefix-code\n        int sharedPrefix = StringHelper.bytesDifference(lastTerm.get(), v);\n        data.writeVInt(sharedPrefix);\n        data.writeVInt(v.length - sharedPrefix);\n        data.writeBytes(v.bytes, v.offset + sharedPrefix, v.length - sharedPrefix);\n        lastTerm.copyBytes(v);\n        count++;\n      }\n      final long indexStartFP = data.getFilePointer();\n      // write addresses of indexed terms\n      termAddresses.finish();\n      addressBuffer.writeTo(data);\n      addressBuffer = null;\n      termAddresses = null;\n      meta.writeVInt(minLength);\n      meta.writeVInt(maxLength);\n      meta.writeVLong(count);\n      meta.writeLong(startFP);\n      meta.writeVInt(ADDRESS_INTERVAL);\n      meta.writeLong(indexStartFP);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      meta.writeVInt(BLOCK_SIZE);\n    }\n  }\n\n","sourceOld":"  /** expert: writes a value dictionary for a sorted/sortedset field */\n  private void addTermsDict(FieldInfo field, final Iterable<BytesRef> values) throws IOException {\n    // first check if its a \"fixed-length\" terms dict\n    int minLength = Integer.MAX_VALUE;\n    int maxLength = Integer.MIN_VALUE;\n    for (BytesRef v : values) {\n      minLength = Math.min(minLength, v.length);\n      maxLength = Math.max(maxLength, v.length);\n    }\n    if (minLength == maxLength) {\n      // no index needed: direct addressing by mult\n      addBinaryField(field, values);\n    } else {\n      // header\n      meta.writeVInt(field.number);\n      meta.writeByte(Lucene49DocValuesFormat.BINARY);\n      meta.writeVInt(BINARY_PREFIX_COMPRESSED);\n      meta.writeLong(-1L);\n      // now write the bytes: sharing prefixes within a block\n      final long startFP = data.getFilePointer();\n      // currently, we have to store the delta from expected for every 1/nth term\n      // we could avoid this, but its not much and less overall RAM than the previous approach!\n      RAMOutputStream addressBuffer = new RAMOutputStream();\n      MonotonicBlockPackedWriter termAddresses = new MonotonicBlockPackedWriter(addressBuffer, BLOCK_SIZE);\n      BytesRefBuilder lastTerm = new BytesRefBuilder();\n      lastTerm.grow(Math.max(0, maxLength));\n      long count = 0;\n      for (BytesRef v : values) {\n        if (count % ADDRESS_INTERVAL == 0) {\n          termAddresses.add(data.getFilePointer() - startFP);\n          // force the first term in a block to be abs-encoded\n          lastTerm.clear();\n        }\n        \n        // prefix-code\n        int sharedPrefix = StringHelper.bytesDifference(lastTerm.get(), v);\n        data.writeVInt(sharedPrefix);\n        data.writeVInt(v.length - sharedPrefix);\n        data.writeBytes(v.bytes, v.offset + sharedPrefix, v.length - sharedPrefix);\n        lastTerm.copyBytes(v);\n        count++;\n      }\n      final long indexStartFP = data.getFilePointer();\n      // write addresses of indexed terms\n      termAddresses.finish();\n      addressBuffer.writeTo(data);\n      addressBuffer = null;\n      termAddresses = null;\n      meta.writeVInt(minLength);\n      meta.writeVInt(maxLength);\n      meta.writeVLong(count);\n      meta.writeLong(startFP);\n      meta.writeVInt(ADDRESS_INTERVAL);\n      meta.writeLong(indexStartFP);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      meta.writeVInt(BLOCK_SIZE);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b2f1e6929ec3acd5593810e4906147f47aa7a869":["6ae889c32f4f301251f60804d7082a520e0594c6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4cc45c615dbb82bf79d5f9550286098367874fbf":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"8106bc60c7452250f84c65cdb43ab6b1d8eb1534":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["b2f1e6929ec3acd5593810e4906147f47aa7a869"],"6ae889c32f4f301251f60804d7082a520e0594c6":["8106bc60c7452250f84c65cdb43ab6b1d8eb1534"],"c6f080a2ab37c464dd98db173f6cbf10dc74f211":["8106bc60c7452250f84c65cdb43ab6b1d8eb1534","6ae889c32f4f301251f60804d7082a520e0594c6"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","4cc45c615dbb82bf79d5f9550286098367874fbf"]},"commit2Childs":{"b2f1e6929ec3acd5593810e4906147f47aa7a869":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["8106bc60c7452250f84c65cdb43ab6b1d8eb1534"],"4cc45c615dbb82bf79d5f9550286098367874fbf":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"8106bc60c7452250f84c65cdb43ab6b1d8eb1534":["6ae889c32f4f301251f60804d7082a520e0594c6","c6f080a2ab37c464dd98db173f6cbf10dc74f211"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["4cc45c615dbb82bf79d5f9550286098367874fbf","402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"6ae889c32f4f301251f60804d7082a520e0594c6":["b2f1e6929ec3acd5593810e4906147f47aa7a869","c6f080a2ab37c464dd98db173f6cbf10dc74f211"],"c6f080a2ab37c464dd98db173f6cbf10dc74f211":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["c6f080a2ab37c464dd98db173f6cbf10dc74f211","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}