{"path":"modules/facet/src/examples/org/apache/lucene/facet/example/adaptive/AdaptiveSearcher#searchWithFacets(Directory,Directory).mjava","commits":[{"id":"89f15687f60bd49cd3d9de427e85c17fd9397d61","date":1309381327,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"modules/facet/src/examples/org/apache/lucene/facet/example/adaptive/AdaptiveSearcher#searchWithFacets(Directory,Directory).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Search with facets through the {@link AdaptiveFacetsAccumulator} \n   * @param indexDir Directory of the search index.\n   * @param taxoDir Directory of the taxonomy index.\n   * @throws Exception on error (no detailed exception handling here for sample simplicity\n   * @return facet results\n   */\n  public static List<FacetResult> searchWithFacets (Directory indexDir, Directory taxoDir) throws Exception {\n    // prepare index reader and taxonomy.\n    TaxonomyReader taxo = new LuceneTaxonomyReader(taxoDir);\n    IndexReader indexReader = IndexReader.open(indexDir);\n    \n    // prepare searcher to search against\n    IndexSearcher searcher = new IndexSearcher(indexReader);\n    \n    // faceted search is working in 2 steps: \n    // 1. collect matching documents\n    // 2. aggregate facets for collected documents and\n    //    generate the requested faceted results from the aggregated facets\n    \n    // step 1: collect matching documents into a collector\n    Query q = new TermQuery(new Term(SimpleUtils.TEXT,\"white\"));\n    ExampleUtils.log(\"Query: \"+q);\n    \n    // regular collector for scoring matched documents\n    TopScoreDocCollector topDocsCollector = TopScoreDocCollector.create(10, true); \n    \n    // docids collector for guiding facets accumulation (scoring disabled)\n    ScoredDocIdCollector docIdsCollecor = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n    \n    // Faceted search parameters indicate which facets are we interested in \n    FacetSearchParams facetSearchParams = new FacetSearchParams();\n    facetSearchParams.addFacetRequest(new CountFacetRequest(new CategoryPath(\"root\",\"a\"), 10));\n    \n    // search, into both collectors. note: in case only facets accumulation \n    // is required, the topDocCollector part can be totally discarded\n    searcher.search(q, MultiCollector.wrap(topDocsCollector, docIdsCollecor));\n        \n    // Obtain facets results and print them\n    AdaptiveFacetsAccumulator accumulator = new AdaptiveFacetsAccumulator(facetSearchParams, indexReader, taxo);\n    List<FacetResult> res = accumulator.accumulate(docIdsCollecor.getScoredDocIDs());\n    \n    int i = 0;\n    for (FacetResult facetResult : res) {\n      ExampleUtils.log(\"Res \"+(i++)+\": \"+facetResult);\n    }\n    \n    // we're done, close the index reader and the taxonomy.\n    indexReader.close();\n    taxo.close();\n    \n    return res;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"817d8435e9135b756f08ce6710ab0baac51bdf88","date":1309986993,"type":0,"author":"Steven Rowe","isMerge":true,"pathNew":"modules/facet/src/examples/org/apache/lucene/facet/example/adaptive/AdaptiveSearcher#searchWithFacets(Directory,Directory).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Search with facets through the {@link AdaptiveFacetsAccumulator} \n   * @param indexDir Directory of the search index.\n   * @param taxoDir Directory of the taxonomy index.\n   * @throws Exception on error (no detailed exception handling here for sample simplicity\n   * @return facet results\n   */\n  public static List<FacetResult> searchWithFacets (Directory indexDir, Directory taxoDir) throws Exception {\n    // prepare index reader and taxonomy.\n    TaxonomyReader taxo = new LuceneTaxonomyReader(taxoDir);\n    IndexReader indexReader = IndexReader.open(indexDir);\n    \n    // prepare searcher to search against\n    IndexSearcher searcher = new IndexSearcher(indexReader);\n    \n    // faceted search is working in 2 steps: \n    // 1. collect matching documents\n    // 2. aggregate facets for collected documents and\n    //    generate the requested faceted results from the aggregated facets\n    \n    // step 1: collect matching documents into a collector\n    Query q = new TermQuery(new Term(SimpleUtils.TEXT,\"white\"));\n    ExampleUtils.log(\"Query: \"+q);\n    \n    // regular collector for scoring matched documents\n    TopScoreDocCollector topDocsCollector = TopScoreDocCollector.create(10, true); \n    \n    // docids collector for guiding facets accumulation (scoring disabled)\n    ScoredDocIdCollector docIdsCollecor = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n    \n    // Faceted search parameters indicate which facets are we interested in \n    FacetSearchParams facetSearchParams = new FacetSearchParams();\n    facetSearchParams.addFacetRequest(new CountFacetRequest(new CategoryPath(\"root\",\"a\"), 10));\n    \n    // search, into both collectors. note: in case only facets accumulation \n    // is required, the topDocCollector part can be totally discarded\n    searcher.search(q, MultiCollector.wrap(topDocsCollector, docIdsCollecor));\n        \n    // Obtain facets results and print them\n    AdaptiveFacetsAccumulator accumulator = new AdaptiveFacetsAccumulator(facetSearchParams, indexReader, taxo);\n    List<FacetResult> res = accumulator.accumulate(docIdsCollecor.getScoredDocIDs());\n    \n    int i = 0;\n    for (FacetResult facetResult : res) {\n      ExampleUtils.log(\"Res \"+(i++)+\": \"+facetResult);\n    }\n    \n    // we're done, close the index reader and the taxonomy.\n    indexReader.close();\n    taxo.close();\n    \n    return res;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"modules/facet/src/examples/org/apache/lucene/facet/example/adaptive/AdaptiveSearcher#searchWithFacets(Directory,Directory).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Search with facets through the {@link AdaptiveFacetsAccumulator} \n   * @param indexDir Directory of the search index.\n   * @param taxoDir Directory of the taxonomy index.\n   * @throws Exception on error (no detailed exception handling here for sample simplicity\n   * @return facet results\n   */\n  public static List<FacetResult> searchWithFacets (Directory indexDir, Directory taxoDir) throws Exception {\n    // prepare index reader and taxonomy.\n    TaxonomyReader taxo = new LuceneTaxonomyReader(taxoDir);\n    IndexReader indexReader = IndexReader.open(indexDir);\n    \n    // prepare searcher to search against\n    IndexSearcher searcher = new IndexSearcher(indexReader);\n    \n    // faceted search is working in 2 steps: \n    // 1. collect matching documents\n    // 2. aggregate facets for collected documents and\n    //    generate the requested faceted results from the aggregated facets\n    \n    // step 1: collect matching documents into a collector\n    Query q = new TermQuery(new Term(SimpleUtils.TEXT,\"white\"));\n    ExampleUtils.log(\"Query: \"+q);\n    \n    // regular collector for scoring matched documents\n    TopScoreDocCollector topDocsCollector = TopScoreDocCollector.create(10, true); \n    \n    // docids collector for guiding facets accumulation (scoring disabled)\n    ScoredDocIdCollector docIdsCollecor = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n    \n    // Faceted search parameters indicate which facets are we interested in \n    FacetSearchParams facetSearchParams = new FacetSearchParams();\n    facetSearchParams.addFacetRequest(new CountFacetRequest(new CategoryPath(\"root\",\"a\"), 10));\n    \n    // search, into both collectors. note: in case only facets accumulation \n    // is required, the topDocCollector part can be totally discarded\n    searcher.search(q, MultiCollector.wrap(topDocsCollector, docIdsCollecor));\n        \n    // Obtain facets results and print them\n    AdaptiveFacetsAccumulator accumulator = new AdaptiveFacetsAccumulator(facetSearchParams, indexReader, taxo);\n    List<FacetResult> res = accumulator.accumulate(docIdsCollecor.getScoredDocIDs());\n    \n    int i = 0;\n    for (FacetResult facetResult : res) {\n      ExampleUtils.log(\"Res \"+(i++)+\": \"+facetResult);\n    }\n    \n    // we're done, close the index reader and the taxonomy.\n    indexReader.close();\n    taxo.close();\n    \n    return res;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ea469eab8fd0f3032f4fcde1c644a721e8309d3b","date":1320301582,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"modules/facet/src/examples/org/apache/lucene/facet/example/adaptive/AdaptiveSearcher#searchWithFacets(Directory,Directory).mjava","pathOld":"modules/facet/src/examples/org/apache/lucene/facet/example/adaptive/AdaptiveSearcher#searchWithFacets(Directory,Directory).mjava","sourceNew":"  /**\n   * Search with facets through the {@link AdaptiveFacetsAccumulator} \n   * @param indexDir Directory of the search index.\n   * @param taxoDir Directory of the taxonomy index.\n   * @throws Exception on error (no detailed exception handling here for sample simplicity\n   * @return facet results\n   */\n  public static List<FacetResult> searchWithFacets (Directory indexDir, Directory taxoDir) throws Exception {\n    // prepare index reader and taxonomy.\n    TaxonomyReader taxo = new DirectoryTaxonomyReader(taxoDir);\n    IndexReader indexReader = IndexReader.open(indexDir);\n    \n    // prepare searcher to search against\n    IndexSearcher searcher = new IndexSearcher(indexReader);\n    \n    // faceted search is working in 2 steps: \n    // 1. collect matching documents\n    // 2. aggregate facets for collected documents and\n    //    generate the requested faceted results from the aggregated facets\n    \n    // step 1: collect matching documents into a collector\n    Query q = new TermQuery(new Term(SimpleUtils.TEXT,\"white\"));\n    ExampleUtils.log(\"Query: \"+q);\n    \n    // regular collector for scoring matched documents\n    TopScoreDocCollector topDocsCollector = TopScoreDocCollector.create(10, true); \n    \n    // docids collector for guiding facets accumulation (scoring disabled)\n    ScoredDocIdCollector docIdsCollecor = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n    \n    // Faceted search parameters indicate which facets are we interested in \n    FacetSearchParams facetSearchParams = new FacetSearchParams();\n    facetSearchParams.addFacetRequest(new CountFacetRequest(new CategoryPath(\"root\",\"a\"), 10));\n    \n    // search, into both collectors. note: in case only facets accumulation \n    // is required, the topDocCollector part can be totally discarded\n    searcher.search(q, MultiCollector.wrap(topDocsCollector, docIdsCollecor));\n        \n    // Obtain facets results and print them\n    AdaptiveFacetsAccumulator accumulator = new AdaptiveFacetsAccumulator(facetSearchParams, indexReader, taxo);\n    List<FacetResult> res = accumulator.accumulate(docIdsCollecor.getScoredDocIDs());\n    \n    int i = 0;\n    for (FacetResult facetResult : res) {\n      ExampleUtils.log(\"Res \"+(i++)+\": \"+facetResult);\n    }\n    \n    // we're done, close the index reader and the taxonomy.\n    indexReader.close();\n    taxo.close();\n    \n    return res;\n  }\n\n","sourceOld":"  /**\n   * Search with facets through the {@link AdaptiveFacetsAccumulator} \n   * @param indexDir Directory of the search index.\n   * @param taxoDir Directory of the taxonomy index.\n   * @throws Exception on error (no detailed exception handling here for sample simplicity\n   * @return facet results\n   */\n  public static List<FacetResult> searchWithFacets (Directory indexDir, Directory taxoDir) throws Exception {\n    // prepare index reader and taxonomy.\n    TaxonomyReader taxo = new LuceneTaxonomyReader(taxoDir);\n    IndexReader indexReader = IndexReader.open(indexDir);\n    \n    // prepare searcher to search against\n    IndexSearcher searcher = new IndexSearcher(indexReader);\n    \n    // faceted search is working in 2 steps: \n    // 1. collect matching documents\n    // 2. aggregate facets for collected documents and\n    //    generate the requested faceted results from the aggregated facets\n    \n    // step 1: collect matching documents into a collector\n    Query q = new TermQuery(new Term(SimpleUtils.TEXT,\"white\"));\n    ExampleUtils.log(\"Query: \"+q);\n    \n    // regular collector for scoring matched documents\n    TopScoreDocCollector topDocsCollector = TopScoreDocCollector.create(10, true); \n    \n    // docids collector for guiding facets accumulation (scoring disabled)\n    ScoredDocIdCollector docIdsCollecor = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n    \n    // Faceted search parameters indicate which facets are we interested in \n    FacetSearchParams facetSearchParams = new FacetSearchParams();\n    facetSearchParams.addFacetRequest(new CountFacetRequest(new CategoryPath(\"root\",\"a\"), 10));\n    \n    // search, into both collectors. note: in case only facets accumulation \n    // is required, the topDocCollector part can be totally discarded\n    searcher.search(q, MultiCollector.wrap(topDocsCollector, docIdsCollecor));\n        \n    // Obtain facets results and print them\n    AdaptiveFacetsAccumulator accumulator = new AdaptiveFacetsAccumulator(facetSearchParams, indexReader, taxo);\n    List<FacetResult> res = accumulator.accumulate(docIdsCollecor.getScoredDocIDs());\n    \n    int i = 0;\n    for (FacetResult facetResult : res) {\n      ExampleUtils.log(\"Res \"+(i++)+\": \"+facetResult);\n    }\n    \n    // we're done, close the index reader and the taxonomy.\n    indexReader.close();\n    taxo.close();\n    \n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/facet/src/examples/org/apache/lucene/facet/example/adaptive/AdaptiveSearcher#searchWithFacets(Directory,Directory).mjava","pathOld":"modules/facet/src/examples/org/apache/lucene/facet/example/adaptive/AdaptiveSearcher#searchWithFacets(Directory,Directory).mjava","sourceNew":"  /**\n   * Search with facets through the {@link AdaptiveFacetsAccumulator} \n   * @param indexDir Directory of the search index.\n   * @param taxoDir Directory of the taxonomy index.\n   * @throws Exception on error (no detailed exception handling here for sample simplicity\n   * @return facet results\n   */\n  public static List<FacetResult> searchWithFacets (Directory indexDir, Directory taxoDir) throws Exception {\n    // prepare index reader and taxonomy.\n    TaxonomyReader taxo = new DirectoryTaxonomyReader(taxoDir);\n    IndexReader indexReader = IndexReader.open(indexDir);\n    \n    // prepare searcher to search against\n    IndexSearcher searcher = new IndexSearcher(indexReader);\n    \n    // faceted search is working in 2 steps: \n    // 1. collect matching documents\n    // 2. aggregate facets for collected documents and\n    //    generate the requested faceted results from the aggregated facets\n    \n    // step 1: collect matching documents into a collector\n    Query q = new TermQuery(new Term(SimpleUtils.TEXT,\"white\"));\n    ExampleUtils.log(\"Query: \"+q);\n    \n    // regular collector for scoring matched documents\n    TopScoreDocCollector topDocsCollector = TopScoreDocCollector.create(10, true); \n    \n    // docids collector for guiding facets accumulation (scoring disabled)\n    ScoredDocIdCollector docIdsCollecor = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n    \n    // Faceted search parameters indicate which facets are we interested in \n    FacetSearchParams facetSearchParams = new FacetSearchParams();\n    facetSearchParams.addFacetRequest(new CountFacetRequest(new CategoryPath(\"root\",\"a\"), 10));\n    \n    // search, into both collectors. note: in case only facets accumulation \n    // is required, the topDocCollector part can be totally discarded\n    searcher.search(q, MultiCollector.wrap(topDocsCollector, docIdsCollecor));\n        \n    // Obtain facets results and print them\n    AdaptiveFacetsAccumulator accumulator = new AdaptiveFacetsAccumulator(facetSearchParams, indexReader, taxo);\n    List<FacetResult> res = accumulator.accumulate(docIdsCollecor.getScoredDocIDs());\n    \n    int i = 0;\n    for (FacetResult facetResult : res) {\n      ExampleUtils.log(\"Res \"+(i++)+\": \"+facetResult);\n    }\n    \n    // we're done, close the index reader and the taxonomy.\n    indexReader.close();\n    taxo.close();\n    \n    return res;\n  }\n\n","sourceOld":"  /**\n   * Search with facets through the {@link AdaptiveFacetsAccumulator} \n   * @param indexDir Directory of the search index.\n   * @param taxoDir Directory of the taxonomy index.\n   * @throws Exception on error (no detailed exception handling here for sample simplicity\n   * @return facet results\n   */\n  public static List<FacetResult> searchWithFacets (Directory indexDir, Directory taxoDir) throws Exception {\n    // prepare index reader and taxonomy.\n    TaxonomyReader taxo = new DirectoryTaxonomyReader(taxoDir);\n    IndexReader indexReader = IndexReader.open(indexDir);\n    \n    // prepare searcher to search against\n    IndexSearcher searcher = new IndexSearcher(indexReader);\n    \n    // faceted search is working in 2 steps: \n    // 1. collect matching documents\n    // 2. aggregate facets for collected documents and\n    //    generate the requested faceted results from the aggregated facets\n    \n    // step 1: collect matching documents into a collector\n    Query q = new TermQuery(new Term(SimpleUtils.TEXT,\"white\"));\n    ExampleUtils.log(\"Query: \"+q);\n    \n    // regular collector for scoring matched documents\n    TopScoreDocCollector topDocsCollector = TopScoreDocCollector.create(10, true); \n    \n    // docids collector for guiding facets accumulation (scoring disabled)\n    ScoredDocIdCollector docIdsCollecor = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n    \n    // Faceted search parameters indicate which facets are we interested in \n    FacetSearchParams facetSearchParams = new FacetSearchParams();\n    facetSearchParams.addFacetRequest(new CountFacetRequest(new CategoryPath(\"root\",\"a\"), 10));\n    \n    // search, into both collectors. note: in case only facets accumulation \n    // is required, the topDocCollector part can be totally discarded\n    searcher.search(q, MultiCollector.wrap(topDocsCollector, docIdsCollecor));\n        \n    // Obtain facets results and print them\n    AdaptiveFacetsAccumulator accumulator = new AdaptiveFacetsAccumulator(facetSearchParams, indexReader, taxo);\n    List<FacetResult> res = accumulator.accumulate(docIdsCollecor.getScoredDocIDs());\n    \n    int i = 0;\n    for (FacetResult facetResult : res) {\n      ExampleUtils.log(\"Res \"+(i++)+\": \"+facetResult);\n    }\n    \n    // we're done, close the index reader and the taxonomy.\n    indexReader.close();\n    taxo.close();\n    \n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["ea469eab8fd0f3032f4fcde1c644a721e8309d3b"],"ea469eab8fd0f3032f4fcde1c644a721e8309d3b":["89f15687f60bd49cd3d9de427e85c17fd9397d61"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","89f15687f60bd49cd3d9de427e85c17fd9397d61"],"89f15687f60bd49cd3d9de427e85c17fd9397d61":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"817d8435e9135b756f08ce6710ab0baac51bdf88":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","89f15687f60bd49cd3d9de427e85c17fd9397d61"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b89678825b68eccaf09e6ab71675fc0b0af1e099"]},"commit2Childs":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ea469eab8fd0f3032f4fcde1c644a721e8309d3b":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d083e83f225b11e5fdd900e83d26ddb385b6955c","89f15687f60bd49cd3d9de427e85c17fd9397d61","817d8435e9135b756f08ce6710ab0baac51bdf88"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"89f15687f60bd49cd3d9de427e85c17fd9397d61":["ea469eab8fd0f3032f4fcde1c644a721e8309d3b","d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88"],"817d8435e9135b756f08ce6710ab0baac51bdf88":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}