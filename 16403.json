{"path":"lucene/codecs/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","commits":[{"id":"3e45d45bc3730ddd1341f4eb6025f33b8482e6e2","date":1346834651,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","sourceNew":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random(), new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random()));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    StoredDocument doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null);\n    assertTrue(de.advance(0) != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random(), new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random()));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    StoredDocument doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null);\n    assertTrue(de.advance(0) != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c07e72dcefb3ffccf3decb8ec1ef8c02de176b0c","date":1348768066,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","sourceNew":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random(), new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    StoredDocument doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null);\n    assertTrue(de.advance(0) != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random(), new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random()));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    StoredDocument doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null);\n    assertTrue(de.advance(0) != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5bfcba4bd0c8918a6db1993d4e7818f08cc2a827","date":1349788355,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","sourceNew":null,"sourceOld":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random(), new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    StoredDocument doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null);\n    assertTrue(de.advance(0) != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3e45d45bc3730ddd1341f4eb6025f33b8482e6e2":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"c07e72dcefb3ffccf3decb8ec1ef8c02de176b0c":["3e45d45bc3730ddd1341f4eb6025f33b8482e6e2"],"5bfcba4bd0c8918a6db1993d4e7818f08cc2a827":["c07e72dcefb3ffccf3decb8ec1ef8c02de176b0c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["5bfcba4bd0c8918a6db1993d4e7818f08cc2a827"]},"commit2Childs":{"3e45d45bc3730ddd1341f4eb6025f33b8482e6e2":["c07e72dcefb3ffccf3decb8ec1ef8c02de176b0c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3e45d45bc3730ddd1341f4eb6025f33b8482e6e2"],"c07e72dcefb3ffccf3decb8ec1ef8c02de176b0c":["5bfcba4bd0c8918a6db1993d4e7818f08cc2a827"],"5bfcba4bd0c8918a6db1993d4e7818f08cc2a827":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}