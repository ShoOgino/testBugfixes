{"path":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i), longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i), longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"be20f9fed1d3edcb1c84abcc39df87a90fab22df","date":1275590285,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i), longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i), longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n  }\n\n","bugFix":null,"bugIntro":["d4d69c535930b5cce125cff868d40f6373dc27d4","87d6f9603307ae2ad642fb01deedf031320fd0c3"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e9069c2e665572658f846820b6cb8ad53de19df0","date":1276611358,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i), longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i), longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5f4e87790277826a2aea119328600dfb07761f32","date":1279827275,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i), longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i), longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"25833e37398c5210d7bddaca9d14de45e194439a","date":1294165371,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i), longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    for (int i = 0; i < 100 * RANDOM_MULTIPLIER; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seek(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i), longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"70ad682703b8585f5d0a637efec044d57ec05efb","date":1294259117,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i), longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    for (int i = 0; i < 100 * RANDOM_MULTIPLIER; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seek(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i), longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i), longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    for (int i = 0; i < 100 * RANDOM_MULTIPLIER; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seek(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i), longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b1add9ddc0005b07550d4350720aac22dc9886b3","date":1295549635,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    for (int i = 0; i < 100 * RANDOM_MULTIPLIER; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seek(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i), longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    for (int i = 0; i < 100 * RANDOM_MULTIPLIER; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seek(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e79a6d080bdd5b2a8f56342cf571b5476de04180","date":1295638686,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    for (int i = 0; i < 100 * RANDOM_MULTIPLIER; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seek(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i), longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    for (int i = 0; i < 100 * RANDOM_MULTIPLIER; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seek(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    for (int i = 0; i < 100 * RANDOM_MULTIPLIER; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seek(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i), longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    for (int i = 0; i < 100 * RANDOM_MULTIPLIER; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seek(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f83af14a2a8131b14d7aee6274c740334e0363d3","date":1307579822,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seek(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    for (int i = 0; i < 100 * RANDOM_MULTIPLIER; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seek(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"77cf4379b2824f6ea34b091c495d6e95c38ff9e2","date":1307610475,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seek(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    for (int i = 0; i < 100 * RANDOM_MULTIPLIER; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seek(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","date":1307729864,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seek(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    for (int i = 0; i < 100 * RANDOM_MULTIPLIER; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seek(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd9cc9d77712aba3662f24632df7539ab75e3667","date":1309095238,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seek(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2553b00f699380c64959ccb27991289aae87be2e","date":1309290151,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seek(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seek(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4b9c530f0c3eb63ee033b10be793c129a67dc918","date":1313516656,"type":3,"author":"Martijn van Groningen","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(\"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(\"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk < buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"938800c4bb3199c67e61d8d0a9fb3699ab09a7d2","date":1313569916,"type":3,"author":"Martijn van Groningen","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(\"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(\"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(\"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(\"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk < buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"382fe3a6ca9745891afebda9b9a57cc158305545","date":1320952430,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random.nextBoolean()));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random.nextBoolean()));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random.nextBoolean()));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random.nextBoolean()));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random.nextBoolean()));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random.nextBoolean()));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(\"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(\"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\");\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\"));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\"));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\");\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\"));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\");\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\"));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\");\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\"));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\");\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\"));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(\"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(\"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":["8c146731a64debc22c115bbf11ee1a060aa7ea02","8c146731a64debc22c115bbf11ee1a060aa7ea02","8c146731a64debc22c115bbf11ee1a060aa7ea02"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random.nextBoolean()));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random.nextBoolean()));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random.nextBoolean()));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random.nextBoolean()));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random.nextBoolean()));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random.nextBoolean()));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(\"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(\"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random.nextBoolean()));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random.nextBoolean()));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random.nextBoolean()));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random.nextBoolean()));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random.nextBoolean()));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random.nextBoolean()));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(\"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(\"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":["b1add9ddc0005b07550d4350720aac22dc9886b3","f83af14a2a8131b14d7aee6274c740334e0363d3"],"4b9c530f0c3eb63ee033b10be793c129a67dc918":["fd9cc9d77712aba3662f24632df7539ab75e3667"],"f83af14a2a8131b14d7aee6274c740334e0363d3":["b1add9ddc0005b07550d4350720aac22dc9886b3"],"be20f9fed1d3edcb1c84abcc39df87a90fab22df":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"70ad682703b8585f5d0a637efec044d57ec05efb":["e9069c2e665572658f846820b6cb8ad53de19df0","25833e37398c5210d7bddaca9d14de45e194439a"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["382fe3a6ca9745891afebda9b9a57cc158305545"],"5f4e87790277826a2aea119328600dfb07761f32":["be20f9fed1d3edcb1c84abcc39df87a90fab22df","e9069c2e665572658f846820b6cb8ad53de19df0"],"b1add9ddc0005b07550d4350720aac22dc9886b3":["25833e37398c5210d7bddaca9d14de45e194439a"],"2553b00f699380c64959ccb27991289aae87be2e":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","fd9cc9d77712aba3662f24632df7539ab75e3667"],"382fe3a6ca9745891afebda9b9a57cc158305545":["938800c4bb3199c67e61d8d0a9fb3699ab09a7d2"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["f83af14a2a8131b14d7aee6274c740334e0363d3","fd9cc9d77712aba3662f24632df7539ab75e3667"],"e79a6d080bdd5b2a8f56342cf571b5476de04180":["868da859b43505d9d2a023bfeae6dd0c795f5295","b1add9ddc0005b07550d4350720aac22dc9886b3"],"e9069c2e665572658f846820b6cb8ad53de19df0":["be20f9fed1d3edcb1c84abcc39df87a90fab22df"],"938800c4bb3199c67e61d8d0a9fb3699ab09a7d2":["4b9c530f0c3eb63ee033b10be793c129a67dc918"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["70ad682703b8585f5d0a637efec044d57ec05efb","b1add9ddc0005b07550d4350720aac22dc9886b3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":["29ef99d61cda9641b6250bf9567329a6e65f901d","f83af14a2a8131b14d7aee6274c740334e0363d3"],"fd9cc9d77712aba3662f24632df7539ab75e3667":["f83af14a2a8131b14d7aee6274c740334e0363d3"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["5f4e87790277826a2aea119328600dfb07761f32","25833e37398c5210d7bddaca9d14de45e194439a"],"25833e37398c5210d7bddaca9d14de45e194439a":["e9069c2e665572658f846820b6cb8ad53de19df0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":["2553b00f699380c64959ccb27991289aae87be2e"],"f83af14a2a8131b14d7aee6274c740334e0363d3":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","d083e83f225b11e5fdd900e83d26ddb385b6955c","77cf4379b2824f6ea34b091c495d6e95c38ff9e2","fd9cc9d77712aba3662f24632df7539ab75e3667"],"4b9c530f0c3eb63ee033b10be793c129a67dc918":["938800c4bb3199c67e61d8d0a9fb3699ab09a7d2"],"be20f9fed1d3edcb1c84abcc39df87a90fab22df":["5f4e87790277826a2aea119328600dfb07761f32","e9069c2e665572658f846820b6cb8ad53de19df0"],"70ad682703b8585f5d0a637efec044d57ec05efb":["29ef99d61cda9641b6250bf9567329a6e65f901d"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"5f4e87790277826a2aea119328600dfb07761f32":["868da859b43505d9d2a023bfeae6dd0c795f5295"],"b1add9ddc0005b07550d4350720aac22dc9886b3":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","f83af14a2a8131b14d7aee6274c740334e0363d3","e79a6d080bdd5b2a8f56342cf571b5476de04180","29ef99d61cda9641b6250bf9567329a6e65f901d"],"2553b00f699380c64959ccb27991289aae87be2e":[],"382fe3a6ca9745891afebda9b9a57cc158305545":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"e79a6d080bdd5b2a8f56342cf571b5476de04180":[],"e9069c2e665572658f846820b6cb8ad53de19df0":["70ad682703b8585f5d0a637efec044d57ec05efb","5f4e87790277826a2aea119328600dfb07761f32","25833e37398c5210d7bddaca9d14de45e194439a"],"938800c4bb3199c67e61d8d0a9fb3699ab09a7d2":["382fe3a6ca9745891afebda9b9a57cc158305545"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["77cf4379b2824f6ea34b091c495d6e95c38ff9e2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":[],"fd9cc9d77712aba3662f24632df7539ab75e3667":["4b9c530f0c3eb63ee033b10be793c129a67dc918","2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["e79a6d080bdd5b2a8f56342cf571b5476de04180"],"25833e37398c5210d7bddaca9d14de45e194439a":["70ad682703b8585f5d0a637efec044d57ec05efb","b1add9ddc0005b07550d4350720aac22dc9886b3","868da859b43505d9d2a023bfeae6dd0c795f5295"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["be20f9fed1d3edcb1c84abcc39df87a90fab22df"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c","e79a6d080bdd5b2a8f56342cf571b5476de04180","77cf4379b2824f6ea34b091c495d6e95c38ff9e2","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}