{"path":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,int,CodecProvider,boolean).mjava","commits":[{"id":"eb378f8bdee16a26810e086303a4a86b4930ea12","date":1296410797,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,int,CodecProvider,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,int,CodecProvider).mjava","sourceNew":"  // Used by near real-time search\n  DirectoryReader(IndexWriter writer, SegmentInfos infos, int termInfosIndexDivisor, CodecProvider codecs, boolean applyAllDeletes) throws IOException {\n    this.directory = writer.getDirectory();\n    this.readOnly = true;\n    this.applyAllDeletes = applyAllDeletes;       // saved for reopen\n\n    segmentInfos = (SegmentInfos) infos.clone();// make sure we clone otherwise we share mutable state with IW\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = writer.getReaderFinishedListeners();\n\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n    SegmentReader[] readers = new SegmentReader[numSegments];\n    final Directory dir = writer.getDirectory();\n\n    for (int i=0;i<numSegments;i++) {\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(i);\n        assert info.dir == dir;\n        readers[i] = writer.readerPool.getReadOnlyClone(info, true, termInfosIndexDivisor);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i--;i>=0;i--) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    this.writer = writer;\n\n    initialize(readers);\n  }\n\n","sourceOld":"  // Used by near real-time search\n  DirectoryReader(IndexWriter writer, SegmentInfos infos, int termInfosIndexDivisor, CodecProvider codecs) throws IOException {\n    this.directory = writer.getDirectory();\n    this.readOnly = true;\n    segmentInfos = (SegmentInfos) infos.clone();// make sure we clone otherwise we share mutable state with IW\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = writer.getReaderFinishedListeners();\n\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n    SegmentReader[] readers = new SegmentReader[numSegments];\n    final Directory dir = writer.getDirectory();\n\n    for (int i=0;i<numSegments;i++) {\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(i);\n        assert info.dir == dir;\n        readers[i] = writer.readerPool.getReadOnlyClone(info, true, termInfosIndexDivisor);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i--;i>=0;i--) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    this.writer = writer;\n\n    initialize(readers);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,int,CodecProvider,boolean).mjava","pathOld":"/dev/null","sourceNew":"  // Used by near real-time search\n  DirectoryReader(IndexWriter writer, SegmentInfos infos, int termInfosIndexDivisor, CodecProvider codecs, boolean applyAllDeletes) throws IOException {\n    this.directory = writer.getDirectory();\n    this.readOnly = true;\n    this.applyAllDeletes = applyAllDeletes;       // saved for reopen\n\n    segmentInfos = (SegmentInfos) infos.clone();// make sure we clone otherwise we share mutable state with IW\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = writer.getReaderFinishedListeners();\n\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n    SegmentReader[] readers = new SegmentReader[numSegments];\n    final Directory dir = writer.getDirectory();\n\n    for (int i=0;i<numSegments;i++) {\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(i);\n        assert info.dir == dir;\n        readers[i] = writer.readerPool.getReadOnlyClone(info, true, termInfosIndexDivisor);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i--;i>=0;i--) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    this.writer = writer;\n\n    initialize(readers);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3","date":1297940445,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,int,CodecProvider,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,int,CodecProvider,boolean).mjava","sourceNew":"  // Used by near real-time search\n  DirectoryReader(IndexWriter writer, SegmentInfos infos, int termInfosIndexDivisor, CodecProvider codecs, boolean applyAllDeletes) throws IOException {\n    this.directory = writer.getDirectory();\n    this.readOnly = true;\n    this.applyAllDeletes = applyAllDeletes;       // saved for reopen\n\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = writer.getReaderFinishedListeners();\n\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n\n    List<SegmentReader> readers = new ArrayList<SegmentReader>();\n    final Directory dir = writer.getDirectory();\n\n    segmentInfos = (SegmentInfos) infos.clone();\n    int infosUpto = 0;\n    for (int i=0;i<numSegments;i++) {\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(i);\n        assert info.dir == dir;\n        final SegmentReader reader = writer.readerPool.getReadOnlyClone(info, true, termInfosIndexDivisor);\n        if (reader.numDocs() > 0 || writer.getKeepFullyDeletedSegments()) {\n          reader.readerFinishedListeners = readerFinishedListeners;\n          readers.add(reader);\n          infosUpto++;\n        } else {\n          reader.close();\n          segmentInfos.remove(infosUpto);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(SegmentReader reader : readers) {\n            try {\n              reader.close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    this.writer = writer;\n\n    initialize(readers.toArray(new SegmentReader[readers.size()]));\n  }\n\n","sourceOld":"  // Used by near real-time search\n  DirectoryReader(IndexWriter writer, SegmentInfos infos, int termInfosIndexDivisor, CodecProvider codecs, boolean applyAllDeletes) throws IOException {\n    this.directory = writer.getDirectory();\n    this.readOnly = true;\n    this.applyAllDeletes = applyAllDeletes;       // saved for reopen\n\n    segmentInfos = (SegmentInfos) infos.clone();// make sure we clone otherwise we share mutable state with IW\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = writer.getReaderFinishedListeners();\n\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n    SegmentReader[] readers = new SegmentReader[numSegments];\n    final Directory dir = writer.getDirectory();\n\n    for (int i=0;i<numSegments;i++) {\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(i);\n        assert info.dir == dir;\n        readers[i] = writer.readerPool.getReadOnlyClone(info, true, termInfosIndexDivisor);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i--;i>=0;i--) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    this.writer = writer;\n\n    initialize(readers);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f1bdbf92da222965b46c0a942c3857ba56e5c638","date":1298297608,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,int,CodecProvider,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,int,CodecProvider,boolean).mjava","sourceNew":"  // Used by near real-time search\n  DirectoryReader(IndexWriter writer, SegmentInfos infos, int termInfosIndexDivisor, CodecProvider codecs, boolean applyAllDeletes) throws IOException {\n    this.directory = writer.getDirectory();\n    this.readOnly = true;\n    this.applyAllDeletes = applyAllDeletes;       // saved for reopen\n\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = writer.getReaderFinishedListeners();\n\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n\n    List<SegmentReader> readers = new ArrayList<SegmentReader>();\n    final Directory dir = writer.getDirectory();\n\n    segmentInfos = (SegmentInfos) infos.clone();\n    int infosUpto = 0;\n    for (int i=0;i<numSegments;i++) {\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(i);\n        assert info.dir == dir;\n        final SegmentReader reader = writer.readerPool.getReadOnlyClone(info, true, termInfosIndexDivisor);\n        if (reader.numDocs() > 0 || writer.getKeepFullyDeletedSegments()) {\n          reader.readerFinishedListeners = readerFinishedListeners;\n          readers.add(reader);\n          infosUpto++;\n        } else {\n          reader.close();\n          segmentInfos.remove(infosUpto);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(SegmentReader reader : readers) {\n            try {\n              reader.close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    this.writer = writer;\n\n    initialize(readers.toArray(new SegmentReader[readers.size()]));\n  }\n\n","sourceOld":"  // Used by near real-time search\n  DirectoryReader(IndexWriter writer, SegmentInfos infos, int termInfosIndexDivisor, CodecProvider codecs, boolean applyAllDeletes) throws IOException {\n    this.directory = writer.getDirectory();\n    this.readOnly = true;\n    this.applyAllDeletes = applyAllDeletes;       // saved for reopen\n\n    segmentInfos = (SegmentInfos) infos.clone();// make sure we clone otherwise we share mutable state with IW\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = writer.getReaderFinishedListeners();\n\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n    SegmentReader[] readers = new SegmentReader[numSegments];\n    final Directory dir = writer.getDirectory();\n\n    for (int i=0;i<numSegments;i++) {\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(i);\n        assert info.dir == dir;\n        readers[i] = writer.readerPool.getReadOnlyClone(info, true, termInfosIndexDivisor);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i--;i>=0;i--) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    this.writer = writer;\n\n    initialize(readers);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":1,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,int,CodecProvider,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,int,CodecProvider).mjava","sourceNew":"  // Used by near real-time search\n  DirectoryReader(IndexWriter writer, SegmentInfos infos, int termInfosIndexDivisor, CodecProvider codecs, boolean applyAllDeletes) throws IOException {\n    this.directory = writer.getDirectory();\n    this.readOnly = true;\n    this.applyAllDeletes = applyAllDeletes;       // saved for reopen\n\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = writer.getReaderFinishedListeners();\n\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n\n    List<SegmentReader> readers = new ArrayList<SegmentReader>();\n    final Directory dir = writer.getDirectory();\n\n    segmentInfos = (SegmentInfos) infos.clone();\n    int infosUpto = 0;\n    for (int i=0;i<numSegments;i++) {\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(i);\n        assert info.dir == dir;\n        final SegmentReader reader = writer.readerPool.getReadOnlyClone(info, true, termInfosIndexDivisor);\n        if (reader.numDocs() > 0 || writer.getKeepFullyDeletedSegments()) {\n          reader.readerFinishedListeners = readerFinishedListeners;\n          readers.add(reader);\n          infosUpto++;\n        } else {\n          reader.close();\n          segmentInfos.remove(infosUpto);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(SegmentReader reader : readers) {\n            try {\n              reader.close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    this.writer = writer;\n\n    initialize(readers.toArray(new SegmentReader[readers.size()]));\n  }\n\n","sourceOld":"  // Used by near real-time search\n  DirectoryReader(IndexWriter writer, SegmentInfos infos, int termInfosIndexDivisor, CodecProvider codecs) throws IOException {\n    this.directory = writer.getDirectory();\n    this.readOnly = true;\n    segmentInfos = (SegmentInfos) infos.clone();// make sure we clone otherwise we share mutable state with IW\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n    SegmentReader[] readers = new SegmentReader[numSegments];\n    final Directory dir = writer.getDirectory();\n\n    for (int i=0;i<numSegments;i++) {\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(i);\n        assert info.dir == dir;\n        readers[i] = writer.readerPool.getReadOnlyClone(info, true, termInfosIndexDivisor);\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i--;i>=0;i--) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    this.writer = writer;\n\n    initialize(readers);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"639c36565ce03aed5b0fce7c9e4448e53a1f7efd","date":1308580104,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,int,CodecProvider,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,int,CodecProvider,boolean).mjava","sourceNew":"  // Used by near real-time search\n  DirectoryReader(IndexWriter writer, SegmentInfos infos, int termInfosIndexDivisor, CodecProvider codecs, boolean applyAllDeletes) throws IOException {\n    this.directory = writer.getDirectory();\n    this.readOnly = true;\n    this.applyAllDeletes = applyAllDeletes;       // saved for reopen\n\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = writer.getReaderFinishedListeners();\n\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n\n    List<SegmentReader> readers = new ArrayList<SegmentReader>();\n    final Directory dir = writer.getDirectory();\n\n    segmentInfos = (SegmentInfos) infos.clone();\n    int infosUpto = 0;\n    for (int i=0;i<numSegments;i++) {\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(i);\n        assert info.dir == dir;\n        final SegmentReader reader = writer.readerPool.getReadOnlyClone(info, true, termInfosIndexDivisor,\n                                                                        IOContext.READ);\n        if (reader.numDocs() > 0 || writer.getKeepFullyDeletedSegments()) {\n          reader.readerFinishedListeners = readerFinishedListeners;\n          readers.add(reader);\n          infosUpto++;\n        } else {\n          reader.close();\n          segmentInfos.remove(infosUpto);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(SegmentReader reader : readers) {\n            try {\n              reader.close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    this.writer = writer;\n\n    initialize(readers.toArray(new SegmentReader[readers.size()]));\n  }\n\n","sourceOld":"  // Used by near real-time search\n  DirectoryReader(IndexWriter writer, SegmentInfos infos, int termInfosIndexDivisor, CodecProvider codecs, boolean applyAllDeletes) throws IOException {\n    this.directory = writer.getDirectory();\n    this.readOnly = true;\n    this.applyAllDeletes = applyAllDeletes;       // saved for reopen\n\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = writer.getReaderFinishedListeners();\n\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n\n    List<SegmentReader> readers = new ArrayList<SegmentReader>();\n    final Directory dir = writer.getDirectory();\n\n    segmentInfos = (SegmentInfos) infos.clone();\n    int infosUpto = 0;\n    for (int i=0;i<numSegments;i++) {\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(i);\n        assert info.dir == dir;\n        final SegmentReader reader = writer.readerPool.getReadOnlyClone(info, true, termInfosIndexDivisor);\n        if (reader.numDocs() > 0 || writer.getKeepFullyDeletedSegments()) {\n          reader.readerFinishedListeners = readerFinishedListeners;\n          readers.add(reader);\n          infosUpto++;\n        } else {\n          reader.close();\n          segmentInfos.remove(infosUpto);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(SegmentReader reader : readers) {\n            try {\n              reader.close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    this.writer = writer;\n\n    initialize(readers.toArray(new SegmentReader[readers.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ddc4c914be86e34b54f70023f45a60fa7f04e929","date":1310115160,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,int,CodecProvider,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,int,CodecProvider,boolean).mjava","sourceNew":"  // Used by near real-time search\n  DirectoryReader(IndexWriter writer, SegmentInfos infos, int termInfosIndexDivisor, CodecProvider codecs, boolean applyAllDeletes) throws IOException {\n    this.directory = writer.getDirectory();\n    this.readOnly = true;\n    this.applyAllDeletes = applyAllDeletes;       // saved for reopen\n\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = writer.getReaderFinishedListeners();\n\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n\n    List<SegmentReader> readers = new ArrayList<SegmentReader>();\n    final Directory dir = writer.getDirectory();\n\n    segmentInfos = (SegmentInfos) infos.clone();\n    int infosUpto = 0;\n    for (int i=0;i<numSegments;i++) {\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(i);\n        assert info.dir == dir;\n        final SegmentReader reader = writer.readerPool.getReadOnlyClone(info, true, termInfosIndexDivisor,\n                                                                        IOContext.READ);\n        if (reader.numDocs() > 0 || writer.getKeepFullyDeletedSegments()) {\n          reader.readerFinishedListeners = readerFinishedListeners;\n          readers.add(reader);\n          infosUpto++;\n        } else {\n          reader.close();\n          segmentInfos.remove(infosUpto);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(SegmentReader reader : readers) {\n            try {\n              reader.close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    this.writer = writer;\n\n    initialize(readers.toArray(new SegmentReader[readers.size()]));\n  }\n\n","sourceOld":"  // Used by near real-time search\n  DirectoryReader(IndexWriter writer, SegmentInfos infos, int termInfosIndexDivisor, CodecProvider codecs, boolean applyAllDeletes) throws IOException {\n    this.directory = writer.getDirectory();\n    this.readOnly = true;\n    this.applyAllDeletes = applyAllDeletes;       // saved for reopen\n\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = writer.getReaderFinishedListeners();\n\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n\n    List<SegmentReader> readers = new ArrayList<SegmentReader>();\n    final Directory dir = writer.getDirectory();\n\n    segmentInfos = (SegmentInfos) infos.clone();\n    int infosUpto = 0;\n    for (int i=0;i<numSegments;i++) {\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(i);\n        assert info.dir == dir;\n        final SegmentReader reader = writer.readerPool.getReadOnlyClone(info, true, termInfosIndexDivisor);\n        if (reader.numDocs() > 0 || writer.getKeepFullyDeletedSegments()) {\n          reader.readerFinishedListeners = readerFinishedListeners;\n          readers.add(reader);\n          infosUpto++;\n        } else {\n          reader.close();\n          segmentInfos.remove(infosUpto);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(SegmentReader reader : readers) {\n            try {\n              reader.close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    this.writer = writer;\n\n    initialize(readers.toArray(new SegmentReader[readers.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5d004d0e0b3f65bb40da76d476d659d7888270e8","date":1310158940,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,int,CodecProvider,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,int,CodecProvider,boolean).mjava","sourceNew":"  // Used by near real-time search\n  DirectoryReader(IndexWriter writer, SegmentInfos infos, int termInfosIndexDivisor, CodecProvider codecs, boolean applyAllDeletes) throws IOException {\n    this.directory = writer.getDirectory();\n    this.readOnly = true;\n    this.applyAllDeletes = applyAllDeletes;       // saved for reopen\n\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = writer.getReaderFinishedListeners();\n\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n\n    List<SegmentReader> readers = new ArrayList<SegmentReader>();\n    final Directory dir = writer.getDirectory();\n\n    segmentInfos = (SegmentInfos) infos.clone();\n    int infosUpto = 0;\n    for (int i=0;i<numSegments;i++) {\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(i);\n        assert info.dir == dir;\n        final SegmentReader reader = writer.readerPool.getReadOnlyClone(info, true, termInfosIndexDivisor,\n                                                                        IOContext.READ);\n        if (reader.numDocs() > 0 || writer.getKeepFullyDeletedSegments()) {\n          reader.readerFinishedListeners = readerFinishedListeners;\n          readers.add(reader);\n          infosUpto++;\n        } else {\n          reader.close();\n          segmentInfos.remove(infosUpto);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(SegmentReader reader : readers) {\n            try {\n              reader.close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    this.writer = writer;\n\n    initialize(readers.toArray(new SegmentReader[readers.size()]));\n  }\n\n","sourceOld":"  // Used by near real-time search\n  DirectoryReader(IndexWriter writer, SegmentInfos infos, int termInfosIndexDivisor, CodecProvider codecs, boolean applyAllDeletes) throws IOException {\n    this.directory = writer.getDirectory();\n    this.readOnly = true;\n    this.applyAllDeletes = applyAllDeletes;       // saved for reopen\n\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = writer.getReaderFinishedListeners();\n\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n\n    List<SegmentReader> readers = new ArrayList<SegmentReader>();\n    final Directory dir = writer.getDirectory();\n\n    segmentInfos = (SegmentInfos) infos.clone();\n    int infosUpto = 0;\n    for (int i=0;i<numSegments;i++) {\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(i);\n        assert info.dir == dir;\n        final SegmentReader reader = writer.readerPool.getReadOnlyClone(info, true, termInfosIndexDivisor);\n        if (reader.numDocs() > 0 || writer.getKeepFullyDeletedSegments()) {\n          reader.readerFinishedListeners = readerFinishedListeners;\n          readers.add(reader);\n          infosUpto++;\n        } else {\n          reader.close();\n          segmentInfos.remove(infosUpto);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(SegmentReader reader : readers) {\n            try {\n              reader.close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    this.writer = writer;\n\n    initialize(readers.toArray(new SegmentReader[readers.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0061262413ecc163d6eebba1b5c43ab91a0c2dc5","date":1311195279,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,CodecProvider,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,int,CodecProvider,boolean).mjava","sourceNew":"  // Used by near real-time search\n  DirectoryReader(IndexWriter writer, SegmentInfos infos, CodecProvider codecs, boolean applyAllDeletes) throws IOException {\n    this.directory = writer.getDirectory();\n    this.readOnly = true;\n    this.applyAllDeletes = applyAllDeletes;       // saved for reopen\n\n    this.termInfosIndexDivisor = writer.getConfig().getReaderTermsIndexDivisor();\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = writer.getReaderFinishedListeners();\n\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n\n    List<SegmentReader> readers = new ArrayList<SegmentReader>();\n    final Directory dir = writer.getDirectory();\n\n    segmentInfos = (SegmentInfos) infos.clone();\n    int infosUpto = 0;\n    for (int i=0;i<numSegments;i++) {\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(i);\n        assert info.dir == dir;\n        final SegmentReader reader = writer.readerPool.getReadOnlyClone(info, IOContext.READ);\n        if (reader.numDocs() > 0 || writer.getKeepFullyDeletedSegments()) {\n          reader.readerFinishedListeners = readerFinishedListeners;\n          readers.add(reader);\n          infosUpto++;\n        } else {\n          reader.close();\n          segmentInfos.remove(infosUpto);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(SegmentReader reader : readers) {\n            try {\n              reader.close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    this.writer = writer;\n\n    initialize(readers.toArray(new SegmentReader[readers.size()]));\n  }\n\n","sourceOld":"  // Used by near real-time search\n  DirectoryReader(IndexWriter writer, SegmentInfos infos, int termInfosIndexDivisor, CodecProvider codecs, boolean applyAllDeletes) throws IOException {\n    this.directory = writer.getDirectory();\n    this.readOnly = true;\n    this.applyAllDeletes = applyAllDeletes;       // saved for reopen\n\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = writer.getReaderFinishedListeners();\n\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n\n    List<SegmentReader> readers = new ArrayList<SegmentReader>();\n    final Directory dir = writer.getDirectory();\n\n    segmentInfos = (SegmentInfos) infos.clone();\n    int infosUpto = 0;\n    for (int i=0;i<numSegments;i++) {\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(i);\n        assert info.dir == dir;\n        final SegmentReader reader = writer.readerPool.getReadOnlyClone(info, true, termInfosIndexDivisor,\n                                                                        IOContext.READ);\n        if (reader.numDocs() > 0 || writer.getKeepFullyDeletedSegments()) {\n          reader.readerFinishedListeners = readerFinishedListeners;\n          readers.add(reader);\n          infosUpto++;\n        } else {\n          reader.close();\n          segmentInfos.remove(infosUpto);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(SegmentReader reader : readers) {\n            try {\n              reader.close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    this.writer = writer;\n\n    initialize(readers.toArray(new SegmentReader[readers.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3":["eb378f8bdee16a26810e086303a4a86b4930ea12"],"0061262413ecc163d6eebba1b5c43ab91a0c2dc5":["ddc4c914be86e34b54f70023f45a60fa7f04e929"],"f1bdbf92da222965b46c0a942c3857ba56e5c638":["29ef99d61cda9641b6250bf9567329a6e65f901d","e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","eb378f8bdee16a26810e086303a4a86b4930ea12"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3"],"5d004d0e0b3f65bb40da76d476d659d7888270e8":["e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3","ddc4c914be86e34b54f70023f45a60fa7f04e929"],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3","639c36565ce03aed5b0fce7c9e4448e53a1f7efd"],"eb378f8bdee16a26810e086303a4a86b4930ea12":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["0061262413ecc163d6eebba1b5c43ab91a0c2dc5"]},"commit2Childs":{"e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3":["f1bdbf92da222965b46c0a942c3857ba56e5c638","639c36565ce03aed5b0fce7c9e4448e53a1f7efd","5d004d0e0b3f65bb40da76d476d659d7888270e8","ddc4c914be86e34b54f70023f45a60fa7f04e929","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"0061262413ecc163d6eebba1b5c43ab91a0c2dc5":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f1bdbf92da222965b46c0a942c3857ba56e5c638":[],"29ef99d61cda9641b6250bf9567329a6e65f901d":["f1bdbf92da222965b46c0a942c3857ba56e5c638"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["29ef99d61cda9641b6250bf9567329a6e65f901d","eb378f8bdee16a26810e086303a4a86b4930ea12","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["ddc4c914be86e34b54f70023f45a60fa7f04e929"],"5d004d0e0b3f65bb40da76d476d659d7888270e8":[],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["0061262413ecc163d6eebba1b5c43ab91a0c2dc5","5d004d0e0b3f65bb40da76d476d659d7888270e8"],"eb378f8bdee16a26810e086303a4a86b4930ea12":["e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3","29ef99d61cda9641b6250bf9567329a6e65f901d"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["f1bdbf92da222965b46c0a942c3857ba56e5c638","5d004d0e0b3f65bb40da76d476d659d7888270e8","bde51b089eb7f86171eb3406e38a274743f9b7ac","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}