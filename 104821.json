{"path":"src/test/org/apache/lucene/index/TestIndexWriter#xxxtestMergeCompressedFields().mjava","commits":[{"id":"3215ae1377fc1ca1790921d75dd39cb764743b85","date":1237371771,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestIndexWriter#xxxtestMergeCompressedFields().mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexWriter#testMergeCompressedFields().mjava","sourceNew":"  // LUCENE-1374\n  public void xxxtestMergeCompressedFields() throws IOException {\n    File indexDir = new File(System.getProperty(\"tempDir\"), \"mergecompressedfields\");\n    Directory dir = FSDirectory.getDirectory(indexDir);\n    try {\n      for(int i=0;i<5;i++) {\n        // Must make a new writer & doc each time, w/\n        // different fields, so bulk merge of stored fields\n        // cannot run:\n        IndexWriter w = new IndexWriter(dir, new WhitespaceAnalyzer(), i==0, IndexWriter.MaxFieldLength.UNLIMITED);\n        try {\n          w.setMergeFactor(5);\n          w.setMergeScheduler(new SerialMergeScheduler());\n          Document doc = new Document();\n          doc.add(new Field(\"test1\", \"this is some data that will be compressed this this this\", Field.Store.COMPRESS, Field.Index.NO));\n          doc.add(new Field(\"test2\", new byte[20], Field.Store.COMPRESS));\n          doc.add(new Field(\"field\" + i, \"random field\", Field.Store.NO, Field.Index.ANALYZED));\n          w.addDocument(doc);\n        } finally {\n          w.close();\n        }\n      }\n\n      byte[] cmp = new byte[20];\n\n      IndexReader r = IndexReader.open(dir);\n      try {\n        for(int i=0;i<5;i++) {\n          Document doc = r.document(i);\n          assertEquals(\"this is some data that will be compressed this this this\", doc.getField(\"test1\").stringValue());\n          byte[] b = doc.getField(\"test2\").binaryValue();\n          assertTrue(Arrays.equals(b, cmp));\n        }\n      } finally {\n        r.close();\n      }\n    } finally {\n      dir.close();\n      _TestUtil.rmDir(indexDir);\n    }\n  }\n\n","sourceOld":"  // LUCENE-1374\n  public void testMergeCompressedFields() throws IOException {\n    File indexDir = new File(System.getProperty(\"tempDir\"), \"mergecompressedfields\");\n    Directory dir = FSDirectory.getDirectory(indexDir);\n    try {\n      for(int i=0;i<5;i++) {\n        // Must make a new writer & doc each time, w/\n        // different fields, so bulk merge of stored fields\n        // cannot run:\n        IndexWriter w = new IndexWriter(dir, new WhitespaceAnalyzer(), i==0, IndexWriter.MaxFieldLength.UNLIMITED);\n        try {\n          w.setMergeFactor(5);\n          w.setMergeScheduler(new SerialMergeScheduler());\n          Document doc = new Document();\n          doc.add(new Field(\"test1\", \"this is some data that will be compressed this this this\", Field.Store.COMPRESS, Field.Index.NO));\n          doc.add(new Field(\"test2\", new byte[20], Field.Store.COMPRESS));\n          doc.add(new Field(\"field\" + i, \"random field\", Field.Store.NO, Field.Index.ANALYZED));\n          w.addDocument(doc);\n        } finally {\n          w.close();\n        }\n      }\n\n      byte[] cmp = new byte[20];\n\n      IndexReader r = IndexReader.open(dir);\n      try {\n        for(int i=0;i<5;i++) {\n          Document doc = r.document(i);\n          assertEquals(\"this is some data that will be compressed this this this\", doc.getField(\"test1\").stringValue());\n          byte[] b = doc.getField(\"test2\").binaryValue();\n          assertTrue(Arrays.equals(b, cmp));\n        }\n      } finally {\n        r.close();\n      }\n    } finally {\n      dir.close();\n      _TestUtil.rmDir(indexDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"09c482d1e63332617181729a225b215c452d8a79","date":1237396006,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestIndexWriter#testMergeCompressedFields().mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexWriter#xxxtestMergeCompressedFields().mjava","sourceNew":"  // LUCENE-1374\n  public void testMergeCompressedFields() throws IOException {\n    File indexDir = new File(System.getProperty(\"tempDir\"), \"mergecompressedfields\");\n    Directory dir = FSDirectory.getDirectory(indexDir);\n    try {\n      for(int i=0;i<5;i++) {\n        // Must make a new writer & doc each time, w/\n        // different fields, so bulk merge of stored fields\n        // cannot run:\n        IndexWriter w = new IndexWriter(dir, new WhitespaceAnalyzer(), i==0, IndexWriter.MaxFieldLength.UNLIMITED);\n        try {\n          w.setMergeFactor(5);\n          w.setMergeScheduler(new SerialMergeScheduler());\n          Document doc = new Document();\n          doc.add(new Field(\"test1\", \"this is some data that will be compressed this this this\", Field.Store.COMPRESS, Field.Index.NO));\n          doc.add(new Field(\"test2\", new byte[20], Field.Store.COMPRESS));\n          doc.add(new Field(\"field\" + i, \"random field\", Field.Store.NO, Field.Index.ANALYZED));\n          w.addDocument(doc);\n        } finally {\n          w.close();\n        }\n      }\n\n      byte[] cmp = new byte[20];\n\n      IndexReader r = IndexReader.open(dir);\n      try {\n        for(int i=0;i<5;i++) {\n          Document doc = r.document(i);\n          assertEquals(\"this is some data that will be compressed this this this\", doc.getField(\"test1\").stringValue());\n          byte[] b = doc.getField(\"test2\").binaryValue();\n          assertTrue(Arrays.equals(b, cmp));\n        }\n      } finally {\n        r.close();\n      }\n    } finally {\n      dir.close();\n      _TestUtil.rmDir(indexDir);\n    }\n  }\n\n","sourceOld":"  // LUCENE-1374\n  public void xxxtestMergeCompressedFields() throws IOException {\n    File indexDir = new File(System.getProperty(\"tempDir\"), \"mergecompressedfields\");\n    Directory dir = FSDirectory.getDirectory(indexDir);\n    try {\n      for(int i=0;i<5;i++) {\n        // Must make a new writer & doc each time, w/\n        // different fields, so bulk merge of stored fields\n        // cannot run:\n        IndexWriter w = new IndexWriter(dir, new WhitespaceAnalyzer(), i==0, IndexWriter.MaxFieldLength.UNLIMITED);\n        try {\n          w.setMergeFactor(5);\n          w.setMergeScheduler(new SerialMergeScheduler());\n          Document doc = new Document();\n          doc.add(new Field(\"test1\", \"this is some data that will be compressed this this this\", Field.Store.COMPRESS, Field.Index.NO));\n          doc.add(new Field(\"test2\", new byte[20], Field.Store.COMPRESS));\n          doc.add(new Field(\"field\" + i, \"random field\", Field.Store.NO, Field.Index.ANALYZED));\n          w.addDocument(doc);\n        } finally {\n          w.close();\n        }\n      }\n\n      byte[] cmp = new byte[20];\n\n      IndexReader r = IndexReader.open(dir);\n      try {\n        for(int i=0;i<5;i++) {\n          Document doc = r.document(i);\n          assertEquals(\"this is some data that will be compressed this this this\", doc.getField(\"test1\").stringValue());\n          byte[] b = doc.getField(\"test2\").binaryValue();\n          assertTrue(Arrays.equals(b, cmp));\n        }\n      } finally {\n        r.close();\n      }\n    } finally {\n      dir.close();\n      _TestUtil.rmDir(indexDir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3215ae1377fc1ca1790921d75dd39cb764743b85":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"09c482d1e63332617181729a225b215c452d8a79":["3215ae1377fc1ca1790921d75dd39cb764743b85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["09c482d1e63332617181729a225b215c452d8a79"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3215ae1377fc1ca1790921d75dd39cb764743b85"],"3215ae1377fc1ca1790921d75dd39cb764743b85":["09c482d1e63332617181729a225b215c452d8a79"],"09c482d1e63332617181729a225b215c452d8a79":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}