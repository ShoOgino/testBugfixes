{"path":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","pathOld":"contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","sourceNew":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (sourceIndexReader.hasDeletions() && sourceIndexReader.isDeleted(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, sourceIndexReader.norms(fieldName));\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    TermEnum termEnum = sourceIndexReader.terms();\n    while (termEnum.next()) {\n      if (fields == null || fields.contains(termEnum.term().field())) { // todo skipto if not using field\n        InstantiatedTerm instantiatedTerm = new InstantiatedTerm(termEnum.term().field(), termEnum.term().text());\n        getTermsByFieldAndText().get(termEnum.term().field()).put(termEnum.term().text(), instantiatedTerm);\n        instantiatedTerm.setTermIndex(terms.size());\n        terms.add(instantiatedTerm);\n        instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termEnum.docFreq()]);\n      }\n    }\n    termEnum.close();\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      TermPositions termPositions = sourceIndexReader.termPositions(term.getTerm());\n      int position = 0;\n      while (termPositions.next()) {\n        InstantiatedDocument document = documentsByNumber[termPositions.doc()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.isPayloadAvailable()) {\n            payloads[i] = new byte[termPositions.getPayloadLength()];\n            termPositions.getPayload(payloads[i], 0);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i];\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (sourceIndexReader.hasDeletions() && sourceIndexReader.isDeleted(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, sourceIndexReader.norms(fieldName));\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    TermEnum termEnum = sourceIndexReader.terms();\n    while (termEnum.next()) {\n      if (fields == null || fields.contains(termEnum.term().field())) { // todo skipto if not using field\n        InstantiatedTerm instantiatedTerm = new InstantiatedTerm(termEnum.term().field(), termEnum.term().text());\n        getTermsByFieldAndText().get(termEnum.term().field()).put(termEnum.term().text(), instantiatedTerm);\n        instantiatedTerm.setTermIndex(terms.size());\n        terms.add(instantiatedTerm);\n        instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termEnum.docFreq()]);\n      }\n    }\n    termEnum.close();\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      TermPositions termPositions = sourceIndexReader.termPositions(term.getTerm());\n      int position = 0;\n      while (termPositions.next()) {\n        InstantiatedDocument document = documentsByNumber[termPositions.doc()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.isPayloadAvailable()) {\n            payloads[i] = new byte[termPositions.getPayloadLength()];\n            termPositions.getPayload(payloads[i], 0);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i];\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28427ef110c4c5bf5b4057731b83110bd1e13724","date":1276701452,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","pathOld":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","sourceNew":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (sourceIndexReader.hasDeletions() && sourceIndexReader.isDeleted(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, sourceIndexReader.norms(fieldName));\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getDeletedDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i];\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (sourceIndexReader.hasDeletions() && sourceIndexReader.isDeleted(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, sourceIndexReader.norms(fieldName));\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    TermEnum termEnum = sourceIndexReader.terms();\n    while (termEnum.next()) {\n      if (fields == null || fields.contains(termEnum.term().field())) { // todo skipto if not using field\n        InstantiatedTerm instantiatedTerm = new InstantiatedTerm(termEnum.term().field(), termEnum.term().text());\n        getTermsByFieldAndText().get(termEnum.term().field()).put(termEnum.term().text(), instantiatedTerm);\n        instantiatedTerm.setTermIndex(terms.size());\n        terms.add(instantiatedTerm);\n        instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termEnum.docFreq()]);\n      }\n    }\n    termEnum.close();\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      TermPositions termPositions = sourceIndexReader.termPositions(term.getTerm());\n      int position = 0;\n      while (termPositions.next()) {\n        InstantiatedDocument document = documentsByNumber[termPositions.doc()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.isPayloadAvailable()) {\n            payloads[i] = new byte[termPositions.getPayloadLength()];\n            termPositions.getPayload(payloads[i], 0);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i];\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4f29ba80b723649f5feb7e37afe1a558dd2c1304","date":1278318805,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","pathOld":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","sourceNew":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (sourceIndexReader.hasDeletions() && sourceIndexReader.isDeleted(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, sourceIndexReader.norms(fieldName));\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getDeletedDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (sourceIndexReader.hasDeletions() && sourceIndexReader.isDeleted(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, sourceIndexReader.norms(fieldName));\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getDeletedDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i];\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5f4e87790277826a2aea119328600dfb07761f32","date":1279827275,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","pathOld":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","sourceNew":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (sourceIndexReader.hasDeletions() && sourceIndexReader.isDeleted(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, sourceIndexReader.norms(fieldName));\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getDeletedDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (sourceIndexReader.hasDeletions() && sourceIndexReader.isDeleted(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, sourceIndexReader.norms(fieldName));\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    TermEnum termEnum = sourceIndexReader.terms();\n    while (termEnum.next()) {\n      if (fields == null || fields.contains(termEnum.term().field())) { // todo skipto if not using field\n        InstantiatedTerm instantiatedTerm = new InstantiatedTerm(termEnum.term().field(), termEnum.term().text());\n        getTermsByFieldAndText().get(termEnum.term().field()).put(termEnum.term().text(), instantiatedTerm);\n        instantiatedTerm.setTermIndex(terms.size());\n        terms.add(instantiatedTerm);\n        instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termEnum.docFreq()]);\n      }\n    }\n    termEnum.close();\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      TermPositions termPositions = sourceIndexReader.termPositions(term.getTerm());\n      int position = 0;\n      while (termPositions.next()) {\n        InstantiatedDocument document = documentsByNumber[termPositions.doc()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.isPayloadAvailable()) {\n            payloads[i] = new byte[termPositions.getPayloadLength()];\n            termPositions.getPayload(payloads[i], 0);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i];\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"406e7055a3e99d3fa6ce49a555a51dd18b321806","date":1282520243,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","pathOld":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","sourceNew":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits delDocs = MultiFields.getDeletedDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (delDocs != null && delDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, sourceIndexReader.norms(fieldName));\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getDeletedDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (sourceIndexReader.hasDeletions() && sourceIndexReader.isDeleted(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, sourceIndexReader.norms(fieldName));\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getDeletedDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":["c41356c8a19fd7493940c7a1d798ede2fe03ddf8"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","pathOld":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","sourceNew":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits delDocs = MultiFields.getDeletedDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (delDocs != null && delDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, sourceIndexReader.norms(fieldName));\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getDeletedDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (sourceIndexReader.hasDeletions() && sourceIndexReader.isDeleted(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, sourceIndexReader.norms(fieldName));\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getDeletedDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b0d06946f61921459f43309f86ed621ebe67eebe","date":1294182697,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","pathOld":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","sourceNew":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits delDocs = MultiFields.getDeletedDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (delDocs != null && delDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        byte norms[] = MultiNorms.norms(sourceIndexReader, fieldName);\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, norms);\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getDeletedDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits delDocs = MultiFields.getDeletedDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (delDocs != null && delDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, sourceIndexReader.norms(fieldName));\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getDeletedDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70ad682703b8585f5d0a637efec044d57ec05efb","date":1294259117,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","pathOld":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","sourceNew":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits delDocs = MultiFields.getDeletedDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (delDocs != null && delDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        byte norms[] = MultiNorms.norms(sourceIndexReader, fieldName);\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, norms);\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getDeletedDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits delDocs = MultiFields.getDeletedDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (delDocs != null && delDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, sourceIndexReader.norms(fieldName));\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getDeletedDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","pathOld":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","sourceNew":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits delDocs = MultiFields.getDeletedDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (delDocs != null && delDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        byte norms[] = MultiNorms.norms(sourceIndexReader, fieldName);\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, norms);\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getDeletedDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits delDocs = MultiFields.getDeletedDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (delDocs != null && delDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, sourceIndexReader.norms(fieldName));\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getDeletedDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6ecd298fdc085e7eba27afa7fae58df1ba1a2808","date":1295102557,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","pathOld":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","sourceNew":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits delDocs = MultiFields.getDeletedDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (delDocs != null && delDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        byte norms[] = MultiNorms.norms(sourceIndexReader, fieldName);\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, norms);\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            final long totalTermFreq = termsEnum.totalTermFreq();\n            if (totalTermFreq != -1) {\n              instantiatedTerm.addPositionsCount(totalTermFreq);\n            }\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getDeletedDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits delDocs = MultiFields.getDeletedDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (delDocs != null && delDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        byte norms[] = MultiNorms.norms(sourceIndexReader, fieldName);\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, norms);\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getDeletedDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"16843358872ed92ba92888ab99df297550b9a36a","date":1295144724,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","pathOld":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","sourceNew":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits delDocs = MultiFields.getDeletedDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (delDocs != null && delDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        byte norms[] = MultiNorms.norms(sourceIndexReader, fieldName);\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, norms);\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            final long totalTermFreq = termsEnum.totalTermFreq();\n            if (totalTermFreq != -1) {\n              instantiatedTerm.addPositionsCount(totalTermFreq);\n            }\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getDeletedDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits delDocs = MultiFields.getDeletedDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (delDocs != null && delDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        byte norms[] = MultiNorms.norms(sourceIndexReader, fieldName);\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, norms);\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getDeletedDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","pathOld":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","sourceNew":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits delDocs = MultiFields.getDeletedDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (delDocs != null && delDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        byte norms[] = MultiNorms.norms(sourceIndexReader, fieldName);\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, norms);\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            final long totalTermFreq = termsEnum.totalTermFreq();\n            if (totalTermFreq != -1) {\n              instantiatedTerm.addPositionsCount(totalTermFreq);\n            }\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getDeletedDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits delDocs = MultiFields.getDeletedDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (delDocs != null && delDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        byte norms[] = MultiNorms.norms(sourceIndexReader, fieldName);\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, norms);\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getDeletedDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a1b3a24d5d9b47345473ff564f5cc127a7b526b4","date":1306277076,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","pathOld":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","sourceNew":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits delDocs = MultiFields.getDeletedDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (delDocs != null && delDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        byte norms[] = MultiNorms.norms(sourceIndexReader, fieldName);\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, norms);\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      final CharsRef spare = new CharsRef();\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToChars(spare).toString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            final long totalTermFreq = termsEnum.totalTermFreq();\n            if (totalTermFreq != -1) {\n              instantiatedTerm.addPositionsCount(totalTermFreq);\n            }\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getDeletedDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits delDocs = MultiFields.getDeletedDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (delDocs != null && delDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        byte norms[] = MultiNorms.norms(sourceIndexReader, fieldName);\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, norms);\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            final long totalTermFreq = termsEnum.totalTermFreq();\n            if (totalTermFreq != -1) {\n              instantiatedTerm.addPositionsCount(totalTermFreq);\n            }\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getDeletedDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","date":1306767085,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","pathOld":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","sourceNew":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits delDocs = MultiFields.getDeletedDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (delDocs != null && delDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        byte norms[] = MultiNorms.norms(sourceIndexReader, fieldName);\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, norms);\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      final CharsRef spare = new CharsRef();\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToChars(spare).toString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            final long totalTermFreq = termsEnum.totalTermFreq();\n            if (totalTermFreq != -1) {\n              instantiatedTerm.addPositionsCount(totalTermFreq);\n            }\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getDeletedDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits delDocs = MultiFields.getDeletedDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (delDocs != null && delDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        byte norms[] = MultiNorms.norms(sourceIndexReader, fieldName);\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, norms);\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            final long totalTermFreq = termsEnum.totalTermFreq();\n            if (totalTermFreq != -1) {\n              instantiatedTerm.addPositionsCount(totalTermFreq);\n            }\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getDeletedDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2e10cb22a8bdb44339e282925a29182bb2f3174d","date":1306841137,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","pathOld":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","sourceNew":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits delDocs = MultiFields.getDeletedDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (delDocs != null && delDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        byte norms[] = MultiNorms.norms(sourceIndexReader, fieldName);\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, norms);\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      final CharsRef spare = new CharsRef();\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToChars(spare).toString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            final long totalTermFreq = termsEnum.totalTermFreq();\n            if (totalTermFreq != -1) {\n              instantiatedTerm.addPositionsCount(totalTermFreq);\n            }\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getDeletedDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits delDocs = MultiFields.getDeletedDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (delDocs != null && delDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        byte norms[] = MultiNorms.norms(sourceIndexReader, fieldName);\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, norms);\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            final long totalTermFreq = termsEnum.totalTermFreq();\n            if (totalTermFreq != -1) {\n              instantiatedTerm.addPositionsCount(totalTermFreq);\n            }\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getDeletedDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb","date":1309960478,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","pathOld":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","sourceNew":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits liveDocs = MultiFields.getLiveDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (liveDocs != null && !liveDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        byte norms[] = MultiNorms.norms(sourceIndexReader, fieldName);\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, norms);\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      final CharsRef spare = new CharsRef();\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToChars(spare).toString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            final long totalTermFreq = termsEnum.totalTermFreq();\n            if (totalTermFreq != -1) {\n              instantiatedTerm.addPositionsCount(totalTermFreq);\n            }\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getLiveDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits delDocs = MultiFields.getDeletedDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (delDocs != null && delDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        byte norms[] = MultiNorms.norms(sourceIndexReader, fieldName);\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, norms);\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      final CharsRef spare = new CharsRef();\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToChars(spare).toString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            final long totalTermFreq = termsEnum.totalTermFreq();\n            if (totalTermFreq != -1) {\n              instantiatedTerm.addPositionsCount(totalTermFreq);\n            }\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getDeletedDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"817d8435e9135b756f08ce6710ab0baac51bdf88","date":1309986993,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","pathOld":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","sourceNew":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits liveDocs = MultiFields.getLiveDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (liveDocs != null && !liveDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        byte norms[] = MultiNorms.norms(sourceIndexReader, fieldName);\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, norms);\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      final CharsRef spare = new CharsRef();\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToChars(spare).toString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            final long totalTermFreq = termsEnum.totalTermFreq();\n            if (totalTermFreq != -1) {\n              instantiatedTerm.addPositionsCount(totalTermFreq);\n            }\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getLiveDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits delDocs = MultiFields.getDeletedDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (delDocs != null && delDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        byte norms[] = MultiNorms.norms(sourceIndexReader, fieldName);\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, norms);\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      final CharsRef spare = new CharsRef();\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToChars(spare).toString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            final long totalTermFreq = termsEnum.totalTermFreq();\n            if (totalTermFreq != -1) {\n              instantiatedTerm.addPositionsCount(totalTermFreq);\n            }\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getDeletedDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","pathOld":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","sourceNew":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits liveDocs = MultiFields.getLiveDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (liveDocs != null && !liveDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        byte norms[] = MultiNorms.norms(sourceIndexReader, fieldName);\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, norms);\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      final CharsRef spare = new CharsRef();\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToChars(spare).toString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            final long totalTermFreq = termsEnum.totalTermFreq();\n            if (totalTermFreq != -1) {\n              instantiatedTerm.addPositionsCount(totalTermFreq);\n            }\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getLiveDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits delDocs = MultiFields.getDeletedDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (delDocs != null && delDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        byte norms[] = MultiNorms.norms(sourceIndexReader, fieldName);\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, norms);\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      final CharsRef spare = new CharsRef();\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToChars(spare).toString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            final long totalTermFreq = termsEnum.totalTermFreq();\n            if (totalTermFreq != -1) {\n              instantiatedTerm.addPositionsCount(totalTermFreq);\n            }\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getDeletedDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","pathOld":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","sourceNew":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits liveDocs = MultiFields.getLiveDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (liveDocs != null && !liveDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (IndexableField field : sourceDocument) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (IndexableField field : document.getDocument()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.storeTermVectors()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        byte norms[] = MultiNorms.norms(sourceIndexReader, fieldName);\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, norms);\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      final CharsRef spare = new CharsRef();\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToChars(spare).toString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            final long totalTermFreq = termsEnum.totalTermFreq();\n            if (totalTermFreq != -1) {\n              instantiatedTerm.addPositionsCount(totalTermFreq);\n            }\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getLiveDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (IndexableField field : document.getDocument()) {\n        if (field.storeTermVectors() && field.storeTermVectorOffsets()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits liveDocs = MultiFields.getLiveDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (liveDocs != null && !liveDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (Fieldable field : sourceDocument.getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (Fieldable field : document.getDocument().getFields()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.isTermVectorStored()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        byte norms[] = MultiNorms.norms(sourceIndexReader, fieldName);\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, norms);\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      final CharsRef spare = new CharsRef();\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToChars(spare).toString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            final long totalTermFreq = termsEnum.totalTermFreq();\n            if (totalTermFreq != -1) {\n              instantiatedTerm.addPositionsCount(totalTermFreq);\n            }\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getLiveDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (Fieldable field : document.getDocument().getFields()) {\n        if (field.isTermVectorStored() && field.isStoreOffsetWithTermVector()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6eb141f80638abdb6ffaa5149877f36ea39b6ad5","date":1315714072,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","pathOld":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","sourceNew":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits liveDocs = MultiFields.getLiveDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (liveDocs != null && !liveDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (IndexableField field : sourceDocument) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (IndexableField field : document.getDocument()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.fieldType().storeTermVectors()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        byte norms[] = MultiNorms.norms(sourceIndexReader, fieldName);\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, norms);\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      final CharsRef spare = new CharsRef();\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToChars(spare).toString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            final long totalTermFreq = termsEnum.totalTermFreq();\n            if (totalTermFreq != -1) {\n              instantiatedTerm.addPositionsCount(totalTermFreq);\n            }\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getLiveDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (IndexableField field : document.getDocument()) {\n        if (field.fieldType().storeTermVectors() && field.fieldType().storeTermVectorOffsets()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits liveDocs = MultiFields.getLiveDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (liveDocs != null && !liveDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (IndexableField field : sourceDocument) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (IndexableField field : document.getDocument()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.storeTermVectors()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        byte norms[] = MultiNorms.norms(sourceIndexReader, fieldName);\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, norms);\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      final CharsRef spare = new CharsRef();\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToChars(spare).toString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            final long totalTermFreq = termsEnum.totalTermFreq();\n            if (totalTermFreq != -1) {\n              instantiatedTerm.addPositionsCount(totalTermFreq);\n            }\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getLiveDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (IndexableField field : document.getDocument()) {\n        if (field.storeTermVectors() && field.storeTermVectorOffsets()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d14e8d18c0e3970c20354dbeeb49da11bd587fbd","date":1321041051,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","pathOld":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","sourceNew":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not single-segment, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (sourceIndexReader.getSequentialSubReaders().length != 1) {\n      System.out.println((\"Source index has more than one segment.\"));      \n      //throw new IOException(\"Source index has more than one segment.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits liveDocs = MultiFields.getLiveDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (liveDocs != null && !liveDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (IndexableField field : sourceDocument) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (IndexableField field : document.getDocument()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.fieldType().storeTermVectors()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        byte norms[] = MultiNorms.norms(sourceIndexReader, fieldName);\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, norms);\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      final CharsRef spare = new CharsRef();\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToChars(spare).toString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            final long totalTermFreq = termsEnum.totalTermFreq();\n            if (totalTermFreq != -1) {\n              instantiatedTerm.addPositionsCount(totalTermFreq);\n            }\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getLiveDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (IndexableField field : document.getDocument()) {\n        if (field.fieldType().storeTermVectors() && field.fieldType().storeTermVectorOffsets()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not optimized, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (!sourceIndexReader.isOptimized()) {\n      System.out.println((\"Source index is not optimized.\"));      \n      //throw new IOException(\"Source index is not optimized.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits liveDocs = MultiFields.getLiveDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (liveDocs != null && !liveDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (IndexableField field : sourceDocument) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (IndexableField field : document.getDocument()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.fieldType().storeTermVectors()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        byte norms[] = MultiNorms.norms(sourceIndexReader, fieldName);\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, norms);\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      final CharsRef spare = new CharsRef();\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToChars(spare).toString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            final long totalTermFreq = termsEnum.totalTermFreq();\n            if (totalTermFreq != -1) {\n              instantiatedTerm.addPositionsCount(totalTermFreq);\n            }\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getLiveDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (IndexableField field : document.getDocument()) {\n        if (field.fieldType().storeTermVectors() && field.fieldType().storeTermVectorOffsets()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3cc749c053615f5871f3b95715fe292f34e70a53","date":1321470575,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndex#InstantiatedIndex(IndexReader,Set[String]).mjava","sourceNew":null,"sourceOld":"  /**\n   * Creates a new instantiated index that looks just like the index in a specific state as represented by a reader.\n   *\n   * @param sourceIndexReader the source index this new instantiated index will be copied from.\n   * @param fields fields to be added, or null for all\n   * @throws IOException if the source index is not single-segment, or when accessing the source.\n   */\n  public InstantiatedIndex(IndexReader sourceIndexReader, Set<String> fields) throws IOException {\n\n    if (sourceIndexReader.getSequentialSubReaders().length != 1) {\n      System.out.println((\"Source index has more than one segment.\"));      \n      //throw new IOException(\"Source index has more than one segment.\");\n    }\n\n\n    initialize();\n\n    Collection<String> allFieldNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.ALL);\n        \n    // load field options\n\n    Collection<String> indexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED);\n    for (String name : indexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = true;\n    }\n    Collection<String> indexedNoVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_NO_TERMVECTOR);\n    for (String name : indexedNoVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = false;\n      setting.indexed = true;\n    }\n    Collection<String> indexedVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR);\n    for (String name : indexedVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n      setting.indexed = true;\n    }\n    Collection<String> payloadNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS);\n    for (String name : payloadNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePayloads = true;\n    }\n    Collection<String> termVecNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR);\n    for (String name : termVecNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeTermVector = true;\n    }\n    Collection<String> termVecOffsetNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET);\n    for (String name : termVecOffsetNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n    }\n    Collection<String> termVecPosNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION);\n    for (String name : termVecPosNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> termVecPosOffNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET);\n    for (String name : termVecPosOffNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.storeOffsetWithTermVector = true;\n      setting.storePositionWithTermVector = true;\n    }\n    Collection<String> unindexedNames = sourceIndexReader.getFieldNames(IndexReader.FieldOption.UNINDEXED);\n    for (String name : unindexedNames) {\n      FieldSetting setting = fieldSettings.get(name, true);\n      setting.indexed = false;\n    }\n\n\n    documentsByNumber = new InstantiatedDocument[sourceIndexReader.maxDoc()];\n\n    if (sourceIndexReader.hasDeletions()) {\n      deletedDocuments = new BitVector(sourceIndexReader.maxDoc());\n    }\n\n    // create documents\n    final Bits liveDocs = MultiFields.getLiveDocs(sourceIndexReader);\n    for (int i = 0; i < sourceIndexReader.maxDoc(); i++) {\n      if (liveDocs != null && !liveDocs.get(i)) {\n        deletedDocuments.set(i);\n      } else {\n        InstantiatedDocument document = new InstantiatedDocument();\n        // copy stored fields from source reader\n        Document sourceDocument = sourceIndexReader.document(i);\n        for (IndexableField field : sourceDocument) {\n          if (fields == null || fields.contains(field.name())) {\n            document.getDocument().add(field);\n          }\n        }\n        document.setDocumentNumber(i);\n        documentsByNumber[i] = document;\n        for (IndexableField field : document.getDocument()) {\n          if (fields == null || fields.contains(field.name())) {\n            if (field.fieldType().storeTermVectors()) {\n              if (document.getVectorSpace() == null) {\n                document.setVectorSpace(new HashMap<String, List<InstantiatedTermDocumentInformation>>());\n              }\n              document.getVectorSpace().put(field.name(), new ArrayList<InstantiatedTermDocumentInformation>());\n            }\n          }\n        }\n      }\n    }\n\n    // create norms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        byte norms[] = MultiNorms.norms(sourceIndexReader, fieldName);\n        getNormsByFieldNameAndDocumentNumber().put(fieldName, norms);\n      }\n    }\n\n    // create terms\n    for (String fieldName : allFieldNames) {\n      if (fields == null || fields.contains(fieldName)) {\n        getTermsByFieldAndText().put(fieldName, new HashMap<String, InstantiatedTerm>(5000));\n      }\n    }\n    List<InstantiatedTerm> terms = new ArrayList<InstantiatedTerm>(5000 * getTermsByFieldAndText().size());\n    Fields fieldsC = MultiFields.getFields(sourceIndexReader);\n    if (fieldsC != null) {\n      FieldsEnum fieldsEnum = fieldsC.iterator();\n      String field;\n      final CharsRef spare = new CharsRef();\n      while((field = fieldsEnum.next()) != null) {\n        if (fields == null || fields.contains(field)) {\n          TermsEnum termsEnum = fieldsEnum.terms();\n          BytesRef text;\n          while((text = termsEnum.next()) != null) {\n            String termText = text.utf8ToChars(spare).toString();\n            InstantiatedTerm instantiatedTerm = new InstantiatedTerm(field, termText);\n            final long totalTermFreq = termsEnum.totalTermFreq();\n            if (totalTermFreq != -1) {\n              instantiatedTerm.addPositionsCount(totalTermFreq);\n            }\n            getTermsByFieldAndText().get(field).put(termText, instantiatedTerm);\n            instantiatedTerm.setTermIndex(terms.size());\n            terms.add(instantiatedTerm);\n            instantiatedTerm.setAssociatedDocuments(new InstantiatedTermDocumentInformation[termsEnum.docFreq()]);\n          }\n        }\n      }\n    }\n    orderedTerms = terms.toArray(new InstantiatedTerm[terms.size()]);\n\n    // create term-document informations\n    for (InstantiatedTerm term : orderedTerms) {\n      DocsAndPositionsEnum termPositions = MultiFields.getTermPositionsEnum(sourceIndexReader,\n                                                                            MultiFields.getLiveDocs(sourceIndexReader),\n                                                                            term.getTerm().field(),\n                                                                            new BytesRef(term.getTerm().text()));\n      int position = 0;\n      while (termPositions.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n        InstantiatedDocument document = documentsByNumber[termPositions.docID()];\n\n        byte[][] payloads = new byte[termPositions.freq()][];\n        int[] positions = new int[termPositions.freq()];\n        for (int i = 0; i < termPositions.freq(); i++) {\n          positions[i] = termPositions.nextPosition();\n\n          if (termPositions.hasPayload()) {\n            BytesRef br = termPositions.getPayload();\n            payloads[i] = new byte[br.length];\n            System.arraycopy(br.bytes, br.offset, payloads[i], 0, br.length);\n          }\n        }\n\n        InstantiatedTermDocumentInformation termDocumentInformation = new InstantiatedTermDocumentInformation(term, document, positions, payloads);\n        term.getAssociatedDocuments()[position++] = termDocumentInformation;\n\n        if (document.getVectorSpace() != null\n            && document.getVectorSpace().containsKey(term.field())) {\n          document.getVectorSpace().get(term.field()).add(termDocumentInformation);\n        }\n\n//        termDocumentInformation.setIndexFromTerm(indexFromTerm++);\n      }\n    }\n\n    // load offsets to term-document informations\n    for (InstantiatedDocument document : getDocumentsByNumber()) {\n      if (document == null) {\n        continue; // deleted\n      }\n      for (IndexableField field : document.getDocument()) {\n        if (field.fieldType().storeTermVectors() && field.fieldType().storeTermVectorOffsets()) {\n          TermPositionVector termPositionVector = (TermPositionVector) sourceIndexReader.getTermFreqVector(document.getDocumentNumber(), field.name());\n          if (termPositionVector != null) {\n            for (int i = 0; i < termPositionVector.getTerms().length; i++) {\n              String token = termPositionVector.getTerms()[i].utf8ToString();\n              InstantiatedTerm term = findTerm(field.name(), token);\n              InstantiatedTermDocumentInformation termDocumentInformation = term.getAssociatedDocument(document.getDocumentNumber());\n              termDocumentInformation.setTermOffsets(termPositionVector.getOffsets(i));\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"70ad682703b8585f5d0a637efec044d57ec05efb":["406e7055a3e99d3fa6ce49a555a51dd18b321806","b0d06946f61921459f43309f86ed621ebe67eebe"],"4f29ba80b723649f5feb7e37afe1a558dd2c1304":["28427ef110c4c5bf5b4057731b83110bd1e13724"],"b0d06946f61921459f43309f86ed621ebe67eebe":["406e7055a3e99d3fa6ce49a555a51dd18b321806"],"6eb141f80638abdb6ffaa5149877f36ea39b6ad5":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb":["a1b3a24d5d9b47345473ff564f5cc127a7b526b4"],"16843358872ed92ba92888ab99df297550b9a36a":["868da859b43505d9d2a023bfeae6dd0c795f5295","6ecd298fdc085e7eba27afa7fae58df1ba1a2808"],"3cc749c053615f5871f3b95715fe292f34e70a53":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["6eb141f80638abdb6ffaa5149877f36ea39b6ad5"],"5f4e87790277826a2aea119328600dfb07761f32":["9454a6510e2db155fb01faa5c049b06ece95fab9","4f29ba80b723649f5feb7e37afe1a558dd2c1304"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["5f4e87790277826a2aea119328600dfb07761f32","406e7055a3e99d3fa6ce49a555a51dd18b321806"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["a1b3a24d5d9b47345473ff564f5cc127a7b526b4","e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"817d8435e9135b756f08ce6710ab0baac51bdf88":["5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":["6ecd298fdc085e7eba27afa7fae58df1ba1a2808","a1b3a24d5d9b47345473ff564f5cc127a7b526b4"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["70ad682703b8585f5d0a637efec044d57ec05efb","6ecd298fdc085e7eba27afa7fae58df1ba1a2808"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"28427ef110c4c5bf5b4057731b83110bd1e13724":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"a1b3a24d5d9b47345473ff564f5cc127a7b526b4":["6ecd298fdc085e7eba27afa7fae58df1ba1a2808"],"406e7055a3e99d3fa6ce49a555a51dd18b321806":["4f29ba80b723649f5feb7e37afe1a558dd2c1304"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","b0d06946f61921459f43309f86ed621ebe67eebe"],"6ecd298fdc085e7eba27afa7fae58df1ba1a2808":["b0d06946f61921459f43309f86ed621ebe67eebe"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3cc749c053615f5871f3b95715fe292f34e70a53"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"2e10cb22a8bdb44339e282925a29182bb2f3174d":["29ef99d61cda9641b6250bf9567329a6e65f901d","a1b3a24d5d9b47345473ff564f5cc127a7b526b4"]},"commit2Childs":{"70ad682703b8585f5d0a637efec044d57ec05efb":["29ef99d61cda9641b6250bf9567329a6e65f901d"],"4f29ba80b723649f5feb7e37afe1a558dd2c1304":["5f4e87790277826a2aea119328600dfb07761f32","406e7055a3e99d3fa6ce49a555a51dd18b321806"],"b0d06946f61921459f43309f86ed621ebe67eebe":["70ad682703b8585f5d0a637efec044d57ec05efb","868da859b43505d9d2a023bfeae6dd0c795f5295","6ecd298fdc085e7eba27afa7fae58df1ba1a2808"],"6eb141f80638abdb6ffaa5149877f36ea39b6ad5":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"],"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb":["d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88","1509f151d7692d84fae414b2b799ac06ba60fcb4"],"16843358872ed92ba92888ab99df297550b9a36a":[],"3cc749c053615f5871f3b95715fe292f34e70a53":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["3cc749c053615f5871f3b95715fe292f34e70a53"],"5f4e87790277826a2aea119328600dfb07761f32":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["868da859b43505d9d2a023bfeae6dd0c795f5295"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"817d8435e9135b756f08ce6710ab0baac51bdf88":[],"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":["817d8435e9135b756f08ce6710ab0baac51bdf88"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["2e10cb22a8bdb44339e282925a29182bb2f3174d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"28427ef110c4c5bf5b4057731b83110bd1e13724":["4f29ba80b723649f5feb7e37afe1a558dd2c1304"],"406e7055a3e99d3fa6ce49a555a51dd18b321806":["70ad682703b8585f5d0a637efec044d57ec05efb","b0d06946f61921459f43309f86ed621ebe67eebe","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["6eb141f80638abdb6ffaa5149877f36ea39b6ad5"],"a1b3a24d5d9b47345473ff564f5cc127a7b526b4":["e7bd246bb7bc35ac22edfee9157e034dfc4e65eb","d083e83f225b11e5fdd900e83d26ddb385b6955c","5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","2e10cb22a8bdb44339e282925a29182bb2f3174d"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["16843358872ed92ba92888ab99df297550b9a36a"],"6ecd298fdc085e7eba27afa7fae58df1ba1a2808":["16843358872ed92ba92888ab99df297550b9a36a","5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","29ef99d61cda9641b6250bf9567329a6e65f901d","a1b3a24d5d9b47345473ff564f5cc127a7b526b4"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["5f4e87790277826a2aea119328600dfb07761f32","28427ef110c4c5bf5b4057731b83110bd1e13724"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"2e10cb22a8bdb44339e282925a29182bb2f3174d":[]},"heads":["16843358872ed92ba92888ab99df297550b9a36a","d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88","cd5edd1f2b162a5cfa08efd17851a07373a96817","2e10cb22a8bdb44339e282925a29182bb2f3174d"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}