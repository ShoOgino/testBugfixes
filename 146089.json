{"path":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testQueryScorerHits().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testQueryScorerHits().mjava","pathOld":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testQueryScorerHits().mjava","sourceNew":"  public void testQueryScorerHits() throws Exception {\n    Analyzer analyzer = new SimpleAnalyzer(TEST_VERSION_CURRENT);\n    QueryParser qp = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, analyzer);\n    query = qp.parse(\"\\\"very long\\\"\");\n    searcher = new IndexSearcher(ramDir, true);\n    TopDocs hits = searcher.search(query, 10);\n    \n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document doc = searcher.doc(hits.scoreDocs[i].doc);\n      String storedField = doc.get(FIELD_NAME);\n\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher\n          .getIndexReader(), hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n\n      highlighter.setTextFragmenter(fragmenter);\n\n      String fragment = highlighter.getBestFragment(stream, storedField);\n\n      if (VERBOSE) System.out.println(fragment);\n    }\n  }\n\n","sourceOld":"  public void testQueryScorerHits() throws Exception {\n    Analyzer analyzer = new SimpleAnalyzer(TEST_VERSION_CURRENT);\n    QueryParser qp = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, analyzer);\n    query = qp.parse(\"\\\"very long\\\"\");\n    searcher = new IndexSearcher(ramDir, true);\n    TopDocs hits = searcher.search(query, 10);\n    \n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document doc = searcher.doc(hits.scoreDocs[i].doc);\n      String storedField = doc.get(FIELD_NAME);\n\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher\n          .getIndexReader(), hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n\n      highlighter.setTextFragmenter(fragmenter);\n\n      String fragment = highlighter.getBestFragment(stream, storedField);\n\n      if (VERBOSE) System.out.println(fragment);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7f8e68717c68517265937c911e1ce9f25750247","date":1274071103,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testQueryScorerHits().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testQueryScorerHits().mjava","sourceNew":"  public void testQueryScorerHits() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(MockTokenizer.SIMPLE, true);\n    QueryParser qp = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, analyzer);\n    query = qp.parse(\"\\\"very long\\\"\");\n    searcher = new IndexSearcher(ramDir, true);\n    TopDocs hits = searcher.search(query, 10);\n    \n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document doc = searcher.doc(hits.scoreDocs[i].doc);\n      String storedField = doc.get(FIELD_NAME);\n\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher\n          .getIndexReader(), hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n\n      highlighter.setTextFragmenter(fragmenter);\n\n      String fragment = highlighter.getBestFragment(stream, storedField);\n\n      if (VERBOSE) System.out.println(fragment);\n    }\n  }\n\n","sourceOld":"  public void testQueryScorerHits() throws Exception {\n    Analyzer analyzer = new SimpleAnalyzer(TEST_VERSION_CURRENT);\n    QueryParser qp = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, analyzer);\n    query = qp.parse(\"\\\"very long\\\"\");\n    searcher = new IndexSearcher(ramDir, true);\n    TopDocs hits = searcher.search(query, 10);\n    \n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document doc = searcher.doc(hits.scoreDocs[i].doc);\n      String storedField = doc.get(FIELD_NAME);\n\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher\n          .getIndexReader(), hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n\n      highlighter.setTextFragmenter(fragmenter);\n\n      String fragment = highlighter.getBestFragment(stream, storedField);\n\n      if (VERBOSE) System.out.println(fragment);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","date":1281646583,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testQueryScorerHits().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testQueryScorerHits().mjava","sourceNew":"  public void testQueryScorerHits() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(MockTokenizer.SIMPLE, true);\n    QueryParser qp = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, analyzer);\n    query = qp.parse(\"\\\"very long\\\"\");\n    searcher = new IndexSearcher(ramDir, true);\n    TopDocs hits = searcher.search(query, 10);\n    \n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document doc = searcher.doc(hits.scoreDocs[i].doc);\n      String storedField = doc.get(FIELD_NAME);\n\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher\n          .getIndexReader(), hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n\n      highlighter.setTextFragmenter(fragmenter);\n\n      String fragment = highlighter.getBestFragment(stream, storedField);\n\n      if (VERBOSE) System.out.println(fragment);\n    }\n    searcher.close();\n  }\n\n","sourceOld":"  public void testQueryScorerHits() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(MockTokenizer.SIMPLE, true);\n    QueryParser qp = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, analyzer);\n    query = qp.parse(\"\\\"very long\\\"\");\n    searcher = new IndexSearcher(ramDir, true);\n    TopDocs hits = searcher.search(query, 10);\n    \n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document doc = searcher.doc(hits.scoreDocs[i].doc);\n      String storedField = doc.get(FIELD_NAME);\n\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher\n          .getIndexReader(), hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n\n      highlighter.setTextFragmenter(fragmenter);\n\n      String fragment = highlighter.getBestFragment(stream, storedField);\n\n      if (VERBOSE) System.out.println(fragment);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testQueryScorerHits().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testQueryScorerHits().mjava","sourceNew":"  public void testQueryScorerHits() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(MockTokenizer.SIMPLE, true);\n    QueryParser qp = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, analyzer);\n    query = qp.parse(\"\\\"very long\\\"\");\n    searcher = new IndexSearcher(ramDir, true);\n    TopDocs hits = searcher.search(query, 10);\n    \n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document doc = searcher.doc(hits.scoreDocs[i].doc);\n      String storedField = doc.get(FIELD_NAME);\n\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher\n          .getIndexReader(), hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n\n      highlighter.setTextFragmenter(fragmenter);\n\n      String fragment = highlighter.getBestFragment(stream, storedField);\n\n      if (VERBOSE) System.out.println(fragment);\n    }\n    searcher.close();\n  }\n\n","sourceOld":"  public void testQueryScorerHits() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(MockTokenizer.SIMPLE, true);\n    QueryParser qp = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, analyzer);\n    query = qp.parse(\"\\\"very long\\\"\");\n    searcher = new IndexSearcher(ramDir, true);\n    TopDocs hits = searcher.search(query, 10);\n    \n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document doc = searcher.doc(hits.scoreDocs[i].doc);\n      String storedField = doc.get(FIELD_NAME);\n\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher\n          .getIndexReader(), hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n\n      highlighter.setTextFragmenter(fragmenter);\n\n      String fragment = highlighter.getBestFragment(stream, storedField);\n\n      if (VERBOSE) System.out.println(fragment);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2c5f0cb44df114db4228c8f77861714b5cabaea","date":1302542431,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testQueryScorerHits().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testQueryScorerHits().mjava","sourceNew":"  public void testQueryScorerHits() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random, MockTokenizer.SIMPLE, true);\n    QueryParser qp = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, analyzer);\n    query = qp.parse(\"\\\"very long\\\"\");\n    searcher = new IndexSearcher(ramDir, true);\n    TopDocs hits = searcher.search(query, 10);\n    \n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document doc = searcher.doc(hits.scoreDocs[i].doc);\n      String storedField = doc.get(FIELD_NAME);\n\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher\n          .getIndexReader(), hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n\n      highlighter.setTextFragmenter(fragmenter);\n\n      String fragment = highlighter.getBestFragment(stream, storedField);\n\n      if (VERBOSE) System.out.println(fragment);\n    }\n    searcher.close();\n  }\n\n","sourceOld":"  public void testQueryScorerHits() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(MockTokenizer.SIMPLE, true);\n    QueryParser qp = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, analyzer);\n    query = qp.parse(\"\\\"very long\\\"\");\n    searcher = new IndexSearcher(ramDir, true);\n    TopDocs hits = searcher.search(query, 10);\n    \n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document doc = searcher.doc(hits.scoreDocs[i].doc);\n      String storedField = doc.get(FIELD_NAME);\n\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher\n          .getIndexReader(), hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n\n      highlighter.setTextFragmenter(fragmenter);\n\n      String fragment = highlighter.getBestFragment(stream, storedField);\n\n      if (VERBOSE) System.out.println(fragment);\n    }\n    searcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"962d04139994fce5193143ef35615499a9a96d78","date":1302693744,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testQueryScorerHits().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testQueryScorerHits().mjava","sourceNew":"  public void testQueryScorerHits() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random, MockTokenizer.SIMPLE, true);\n    QueryParser qp = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, analyzer);\n    query = qp.parse(\"\\\"very long\\\"\");\n    searcher = new IndexSearcher(ramDir, true);\n    TopDocs hits = searcher.search(query, 10);\n    \n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document doc = searcher.doc(hits.scoreDocs[i].doc);\n      String storedField = doc.get(FIELD_NAME);\n\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher\n          .getIndexReader(), hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n\n      highlighter.setTextFragmenter(fragmenter);\n\n      String fragment = highlighter.getBestFragment(stream, storedField);\n\n      if (VERBOSE) System.out.println(fragment);\n    }\n    searcher.close();\n  }\n\n","sourceOld":"  public void testQueryScorerHits() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(MockTokenizer.SIMPLE, true);\n    QueryParser qp = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, analyzer);\n    query = qp.parse(\"\\\"very long\\\"\");\n    searcher = new IndexSearcher(ramDir, true);\n    TopDocs hits = searcher.search(query, 10);\n    \n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document doc = searcher.doc(hits.scoreDocs[i].doc);\n      String storedField = doc.get(FIELD_NAME);\n\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher\n          .getIndexReader(), hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n\n      highlighter.setTextFragmenter(fragmenter);\n\n      String fragment = highlighter.getBestFragment(stream, storedField);\n\n      if (VERBOSE) System.out.println(fragment);\n    }\n    searcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testQueryScorerHits().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testQueryScorerHits().mjava","sourceNew":"  public void testQueryScorerHits() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random, MockTokenizer.SIMPLE, true);\n    QueryParser qp = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, analyzer);\n    query = qp.parse(\"\\\"very long\\\"\");\n    searcher = new IndexSearcher(ramDir, true);\n    TopDocs hits = searcher.search(query, 10);\n    \n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document doc = searcher.doc(hits.scoreDocs[i].doc);\n      String storedField = doc.get(FIELD_NAME);\n\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher\n          .getIndexReader(), hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n\n      highlighter.setTextFragmenter(fragmenter);\n\n      String fragment = highlighter.getBestFragment(stream, storedField);\n\n      if (VERBOSE) System.out.println(fragment);\n    }\n    searcher.close();\n  }\n\n","sourceOld":"  public void testQueryScorerHits() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(MockTokenizer.SIMPLE, true);\n    QueryParser qp = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, analyzer);\n    query = qp.parse(\"\\\"very long\\\"\");\n    searcher = new IndexSearcher(ramDir, true);\n    TopDocs hits = searcher.search(query, 10);\n    \n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document doc = searcher.doc(hits.scoreDocs[i].doc);\n      String storedField = doc.get(FIELD_NAME);\n\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher\n          .getIndexReader(), hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n\n      highlighter.setTextFragmenter(fragmenter);\n\n      String fragment = highlighter.getBestFragment(stream, storedField);\n\n      if (VERBOSE) System.out.println(fragment);\n    }\n    searcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testQueryScorerHits().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testQueryScorerHits().mjava","sourceNew":"  public void testQueryScorerHits() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random, MockTokenizer.SIMPLE, true);\n    QueryParser qp = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, analyzer);\n    query = qp.parse(\"\\\"very long\\\"\");\n    searcher = new IndexSearcher(ramDir, true);\n    TopDocs hits = searcher.search(query, 10);\n    \n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document doc = searcher.doc(hits.scoreDocs[i].doc);\n      String storedField = doc.get(FIELD_NAME);\n\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher\n          .getIndexReader(), hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n\n      highlighter.setTextFragmenter(fragmenter);\n\n      String fragment = highlighter.getBestFragment(stream, storedField);\n\n      if (VERBOSE) System.out.println(fragment);\n    }\n    searcher.close();\n  }\n\n","sourceOld":"  public void testQueryScorerHits() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(MockTokenizer.SIMPLE, true);\n    QueryParser qp = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, analyzer);\n    query = qp.parse(\"\\\"very long\\\"\");\n    searcher = new IndexSearcher(ramDir, true);\n    TopDocs hits = searcher.search(query, 10);\n    \n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document doc = searcher.doc(hits.scoreDocs[i].doc);\n      String storedField = doc.get(FIELD_NAME);\n\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher\n          .getIndexReader(), hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n\n      highlighter.setTextFragmenter(fragmenter);\n\n      String fragment = highlighter.getBestFragment(stream, storedField);\n\n      if (VERBOSE) System.out.println(fragment);\n    }\n    searcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"dfd4d352ddf04b37253ad97ce1aad1448253f0f7","date":1310173878,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testQueryScorerHits().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testQueryScorerHits().mjava","sourceNew":"  public void testQueryScorerHits() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random, MockTokenizer.SIMPLE, true);\n\n    PhraseQuery phraseQuery = new PhraseQuery();\n    phraseQuery.add(new Term(FIELD_NAME, \"very\"));\n    phraseQuery.add(new Term(FIELD_NAME, \"long\"));\n\n    query = phraseQuery;\n    searcher = new IndexSearcher(ramDir, true);\n    TopDocs hits = searcher.search(query, 10);\n    \n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document doc = searcher.doc(hits.scoreDocs[i].doc);\n      String storedField = doc.get(FIELD_NAME);\n\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher\n          .getIndexReader(), hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n\n      highlighter.setTextFragmenter(fragmenter);\n\n      String fragment = highlighter.getBestFragment(stream, storedField);\n\n      if (VERBOSE) System.out.println(fragment);\n    }\n    searcher.close();\n  }\n\n","sourceOld":"  public void testQueryScorerHits() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random, MockTokenizer.SIMPLE, true);\n    QueryParser qp = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, analyzer);\n    query = qp.parse(\"\\\"very long\\\"\");\n    searcher = new IndexSearcher(ramDir, true);\n    TopDocs hits = searcher.search(query, 10);\n    \n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document doc = searcher.doc(hits.scoreDocs[i].doc);\n      String storedField = doc.get(FIELD_NAME);\n\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher\n          .getIndexReader(), hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n\n      highlighter.setTextFragmenter(fragmenter);\n\n      String fragment = highlighter.getBestFragment(stream, storedField);\n\n      if (VERBOSE) System.out.println(fragment);\n    }\n    searcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"63639dd66fd5bd9b90bc24dd596ae01575f27cc4","date":1310237454,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testQueryScorerHits().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testQueryScorerHits().mjava","sourceNew":"  public void testQueryScorerHits() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random, MockTokenizer.SIMPLE, true);\n\n    PhraseQuery phraseQuery = new PhraseQuery();\n    phraseQuery.add(new Term(FIELD_NAME, \"very\"));\n    phraseQuery.add(new Term(FIELD_NAME, \"long\"));\n\n    query = phraseQuery;\n    searcher = new IndexSearcher(ramDir, true);\n    TopDocs hits = searcher.search(query, 10);\n    \n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document doc = searcher.doc(hits.scoreDocs[i].doc);\n      String storedField = doc.get(FIELD_NAME);\n\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher\n          .getIndexReader(), hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n\n      highlighter.setTextFragmenter(fragmenter);\n\n      String fragment = highlighter.getBestFragment(stream, storedField);\n\n      if (VERBOSE) System.out.println(fragment);\n    }\n    searcher.close();\n  }\n\n","sourceOld":"  public void testQueryScorerHits() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random, MockTokenizer.SIMPLE, true);\n    QueryParser qp = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, analyzer);\n    query = qp.parse(\"\\\"very long\\\"\");\n    searcher = new IndexSearcher(ramDir, true);\n    TopDocs hits = searcher.search(query, 10);\n    \n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document doc = searcher.doc(hits.scoreDocs[i].doc);\n      String storedField = doc.get(FIELD_NAME);\n\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher\n          .getIndexReader(), hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n\n      highlighter.setTextFragmenter(fragmenter);\n\n      String fragment = highlighter.getBestFragment(stream, storedField);\n\n      if (VERBOSE) System.out.println(fragment);\n    }\n    searcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3a0403b45dfe384fae4a1b6e96c3265d000c498","date":1321445981,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testQueryScorerHits().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testQueryScorerHits().mjava","sourceNew":"  public void testQueryScorerHits() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random, MockTokenizer.SIMPLE, true);\n\n    PhraseQuery phraseQuery = new PhraseQuery();\n    phraseQuery.add(new Term(FIELD_NAME, \"very\"));\n    phraseQuery.add(new Term(FIELD_NAME, \"long\"));\n\n    query = phraseQuery;\n    searcher = new IndexSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    \n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document doc = searcher.doc(hits.scoreDocs[i].doc);\n      String storedField = doc.get(FIELD_NAME);\n\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher\n          .getIndexReader(), hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n\n      highlighter.setTextFragmenter(fragmenter);\n\n      String fragment = highlighter.getBestFragment(stream, storedField);\n\n      if (VERBOSE) System.out.println(fragment);\n    }\n    searcher.close();\n  }\n\n","sourceOld":"  public void testQueryScorerHits() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random, MockTokenizer.SIMPLE, true);\n\n    PhraseQuery phraseQuery = new PhraseQuery();\n    phraseQuery.add(new Term(FIELD_NAME, \"very\"));\n    phraseQuery.add(new Term(FIELD_NAME, \"long\"));\n\n    query = phraseQuery;\n    searcher = new IndexSearcher(ramDir, true);\n    TopDocs hits = searcher.search(query, 10);\n    \n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document doc = searcher.doc(hits.scoreDocs[i].doc);\n      String storedField = doc.get(FIELD_NAME);\n\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher\n          .getIndexReader(), hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n\n      highlighter.setTextFragmenter(fragmenter);\n\n      String fragment = highlighter.getBestFragment(stream, storedField);\n\n      if (VERBOSE) System.out.println(fragment);\n    }\n    searcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0e7c2454a6a8237bfd0e953f5b940838408c9055","date":1323649300,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testQueryScorerHits().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testQueryScorerHits().mjava","sourceNew":"  public void testQueryScorerHits() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random, MockTokenizer.SIMPLE, true);\n\n    PhraseQuery phraseQuery = new PhraseQuery();\n    phraseQuery.add(new Term(FIELD_NAME, \"very\"));\n    phraseQuery.add(new Term(FIELD_NAME, \"long\"));\n\n    query = phraseQuery;\n    searcher = new IndexSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    \n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document doc = searcher.doc(hits.scoreDocs[i].doc);\n      String storedField = doc.get(FIELD_NAME);\n\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher\n          .getIndexReader(), hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n\n      highlighter.setTextFragmenter(fragmenter);\n\n      String fragment = highlighter.getBestFragment(stream, storedField);\n\n      if (VERBOSE) System.out.println(fragment);\n    }\n  }\n\n","sourceOld":"  public void testQueryScorerHits() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random, MockTokenizer.SIMPLE, true);\n\n    PhraseQuery phraseQuery = new PhraseQuery();\n    phraseQuery.add(new Term(FIELD_NAME, \"very\"));\n    phraseQuery.add(new Term(FIELD_NAME, \"long\"));\n\n    query = phraseQuery;\n    searcher = new IndexSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    \n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document doc = searcher.doc(hits.scoreDocs[i].doc);\n      String storedField = doc.get(FIELD_NAME);\n\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher\n          .getIndexReader(), hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n\n      highlighter.setTextFragmenter(fragmenter);\n\n      String fragment = highlighter.getBestFragment(stream, storedField);\n\n      if (VERBOSE) System.out.println(fragment);\n    }\n    searcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","date":1323720782,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testQueryScorerHits().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testQueryScorerHits().mjava","sourceNew":"  public void testQueryScorerHits() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random, MockTokenizer.SIMPLE, true);\n\n    PhraseQuery phraseQuery = new PhraseQuery();\n    phraseQuery.add(new Term(FIELD_NAME, \"very\"));\n    phraseQuery.add(new Term(FIELD_NAME, \"long\"));\n\n    query = phraseQuery;\n    searcher = new IndexSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    \n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document doc = searcher.doc(hits.scoreDocs[i].doc);\n      String storedField = doc.get(FIELD_NAME);\n\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher\n          .getIndexReader(), hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n\n      highlighter.setTextFragmenter(fragmenter);\n\n      String fragment = highlighter.getBestFragment(stream, storedField);\n\n      if (VERBOSE) System.out.println(fragment);\n    }\n  }\n\n","sourceOld":"  public void testQueryScorerHits() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random, MockTokenizer.SIMPLE, true);\n\n    PhraseQuery phraseQuery = new PhraseQuery();\n    phraseQuery.add(new Term(FIELD_NAME, \"very\"));\n    phraseQuery.add(new Term(FIELD_NAME, \"long\"));\n\n    query = phraseQuery;\n    searcher = new IndexSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    \n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document doc = searcher.doc(hits.scoreDocs[i].doc);\n      String storedField = doc.get(FIELD_NAME);\n\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher\n          .getIndexReader(), hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n\n      highlighter.setTextFragmenter(fragmenter);\n\n      String fragment = highlighter.getBestFragment(stream, storedField);\n\n      if (VERBOSE) System.out.println(fragment);\n    }\n    searcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testQueryScorerHits().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testQueryScorerHits().mjava","sourceNew":"  public void testQueryScorerHits() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n\n    PhraseQuery phraseQuery = new PhraseQuery();\n    phraseQuery.add(new Term(FIELD_NAME, \"very\"));\n    phraseQuery.add(new Term(FIELD_NAME, \"long\"));\n\n    query = phraseQuery;\n    searcher = new IndexSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    \n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document doc = searcher.doc(hits.scoreDocs[i].doc);\n      String storedField = doc.get(FIELD_NAME);\n\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher\n          .getIndexReader(), hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n\n      highlighter.setTextFragmenter(fragmenter);\n\n      String fragment = highlighter.getBestFragment(stream, storedField);\n\n      if (VERBOSE) System.out.println(fragment);\n    }\n  }\n\n","sourceOld":"  public void testQueryScorerHits() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random, MockTokenizer.SIMPLE, true);\n\n    PhraseQuery phraseQuery = new PhraseQuery();\n    phraseQuery.add(new Term(FIELD_NAME, \"very\"));\n    phraseQuery.add(new Term(FIELD_NAME, \"long\"));\n\n    query = phraseQuery;\n    searcher = new IndexSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    \n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document doc = searcher.doc(hits.scoreDocs[i].doc);\n      String storedField = doc.get(FIELD_NAME);\n\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher\n          .getIndexReader(), hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n\n      highlighter.setTextFragmenter(fragmenter);\n\n      String fragment = highlighter.getBestFragment(stream, storedField);\n\n      if (VERBOSE) System.out.println(fragment);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testQueryScorerHits().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testQueryScorerHits().mjava","sourceNew":"  public void testQueryScorerHits() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n\n    PhraseQuery phraseQuery = new PhraseQuery();\n    phraseQuery.add(new Term(FIELD_NAME, \"very\"));\n    phraseQuery.add(new Term(FIELD_NAME, \"long\"));\n\n    query = phraseQuery;\n    searcher = new IndexSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    \n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document doc = searcher.doc(hits.scoreDocs[i].doc);\n      String storedField = doc.get(FIELD_NAME);\n\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher\n          .getIndexReader(), hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n\n      highlighter.setTextFragmenter(fragmenter);\n\n      String fragment = highlighter.getBestFragment(stream, storedField);\n\n      if (VERBOSE) System.out.println(fragment);\n    }\n  }\n\n","sourceOld":"  public void testQueryScorerHits() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n\n    PhraseQuery phraseQuery = new PhraseQuery();\n    phraseQuery.add(new Term(FIELD_NAME, \"very\"));\n    phraseQuery.add(new Term(FIELD_NAME, \"long\"));\n\n    query = phraseQuery;\n    searcher = new IndexSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    \n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      Document doc = searcher.doc(hits.scoreDocs[i].doc);\n      String storedField = doc.get(FIELD_NAME);\n\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher\n          .getIndexReader(), hits.scoreDocs[i].doc, FIELD_NAME, doc, analyzer);\n\n      Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n\n      highlighter.setTextFragmenter(fragmenter);\n\n      String fragment = highlighter.getBestFragment(stream, storedField);\n\n      if (VERBOSE) System.out.println(fragment);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"dfd4d352ddf04b37253ad97ce1aad1448253f0f7":["f2c5f0cb44df114db4228c8f77861714b5cabaea"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["c7f8e68717c68517265937c911e1ce9f25750247"],"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c":["a3a0403b45dfe384fae4a1b6e96c3265d000c498","0e7c2454a6a8237bfd0e953f5b940838408c9055"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"c7f8e68717c68517265937c911e1ce9f25750247":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"962d04139994fce5193143ef35615499a9a96d78":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["c7f8e68717c68517265937c911e1ce9f25750247","ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"63639dd66fd5bd9b90bc24dd596ae01575f27cc4":["a3776dccca01c11e7046323cfad46a3b4a471233","dfd4d352ddf04b37253ad97ce1aad1448253f0f7"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"0e7c2454a6a8237bfd0e953f5b940838408c9055":["a3a0403b45dfe384fae4a1b6e96c3265d000c498"],"a3776dccca01c11e7046323cfad46a3b4a471233":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a3a0403b45dfe384fae4a1b6e96c3265d000c498":["dfd4d352ddf04b37253ad97ce1aad1448253f0f7"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["0e7c2454a6a8237bfd0e953f5b940838408c9055"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"dfd4d352ddf04b37253ad97ce1aad1448253f0f7":["63639dd66fd5bd9b90bc24dd596ae01575f27cc4","a3a0403b45dfe384fae4a1b6e96c3265d000c498"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["135621f3a0670a9394eb563224a3b76cc4dddc0f","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","f2c5f0cb44df114db4228c8f77861714b5cabaea","a3776dccca01c11e7046323cfad46a3b4a471233"],"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c":[],"135621f3a0670a9394eb563224a3b76cc4dddc0f":[],"c7f8e68717c68517265937c911e1ce9f25750247":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"962d04139994fce5193143ef35615499a9a96d78":[],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["962d04139994fce5193143ef35615499a9a96d78"],"63639dd66fd5bd9b90bc24dd596ae01575f27cc4":[],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["dfd4d352ddf04b37253ad97ce1aad1448253f0f7","135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","a3776dccca01c11e7046323cfad46a3b4a471233"],"0e7c2454a6a8237bfd0e953f5b940838408c9055":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"a3776dccca01c11e7046323cfad46a3b4a471233":["63639dd66fd5bd9b90bc24dd596ae01575f27cc4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a3a0403b45dfe384fae4a1b6e96c3265d000c498":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","0e7c2454a6a8237bfd0e953f5b940838408c9055"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["c7f8e68717c68517265937c911e1ce9f25750247"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","63639dd66fd5bd9b90bc24dd596ae01575f27cc4","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}