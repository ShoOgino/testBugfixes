{"path":"solr/core/src/java/org/apache/solr/response/transform/ChildDocTransformer#transform(SolrDocument,int).mjava","commits":[{"id":"44e1477dd67ee1fbc72871f23fb51369bb42cadd","date":1535551329,"type":0,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/response/transform/ChildDocTransformer#transform(SolrDocument,int).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void transform(SolrDocument rootDoc, int rootDocId) {\n    // note: this algorithm works if both if we have have _nest_path_  and also if we don't!\n\n    try {\n\n      // lookup what the *previous* rootDocId is, and figure which segment this is\n      final SolrIndexSearcher searcher = context.getSearcher();\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final int seg = ReaderUtil.subIndex(rootDocId, leaves);\n      final LeafReaderContext leafReaderContext = leaves.get(seg);\n      final int segBaseId = leafReaderContext.docBase;\n      final int segRootId = rootDocId - segBaseId;\n      final BitSet segParentsBitSet = parentsFilter.getBitSet(leafReaderContext);\n\n      final int segPrevRootId = segRootId==0? -1: segParentsBitSet.prevSetBit(segRootId - 1); // can return -1 and that's okay\n\n      if (segPrevRootId == (segRootId - 1)) {\n        // doc has no children, return fast\n        return;\n      }\n\n      // we'll need this soon...\n      final SortedDocValues segPathDocValues = DocValues.getSorted(leafReaderContext.reader(), NEST_PATH_FIELD_NAME);\n      // passing a different SortedDocValues obj since the child documents which come after are of smaller docIDs,\n      // and the iterator can not be reversed.\n      // The root doc is the input document to be transformed, and is not necessarily the root doc of the block of docs.\n      final String rootDocPath = getPathByDocId(segRootId, DocValues.getSorted(leafReaderContext.reader(), NEST_PATH_FIELD_NAME));\n\n      // the key in the Map is the document's ancestors key (one above the parent), while the key in the intermediate\n      // MultiMap is the direct child document's key(of the parent document)\n      final Map<String, Multimap<String, SolrDocument>> pendingParentPathsToChildren = new HashMap<>();\n\n      final int firstChildId = segBaseId + segPrevRootId + 1;\n      int matches = 0;\n      // Loop each child ID up to the parent (exclusive).\n      for (int docId = firstChildId; docId < rootDocId; ++docId) {\n\n        // get the path.  (note will default to ANON_CHILD_KEY if schema is not nested or empty string if blank)\n        final String fullDocPath = getPathByDocId(docId - segBaseId, segPathDocValues);\n\n        if (isNestedSchema && !fullDocPath.startsWith(rootDocPath)) {\n          // is not a descendant of the transformed doc; return fast.\n          continue;\n        }\n\n        // Is this doc a direct ancestor of another doc we've seen?\n        boolean isAncestor = pendingParentPathsToChildren.containsKey(fullDocPath);\n\n        // Do we need to do anything with this doc (either ancestor or matched the child query)\n        if (isAncestor || childDocSet == null || childDocSet.exists(docId)) {\n\n          // If we reached the limit, only add if it's an ancestor\n          if (limit != -1 && matches >= limit && !isAncestor) {\n            continue;\n          }\n          ++matches; // note: includes ancestors that are not necessarily in childDocSet\n\n          // load the doc\n          SolrDocument doc = searcher.getDocFetcher().solrDoc(docId, childReturnFields);\n\n          if (isAncestor) {\n            // if this path has pending child docs, add them.\n            addChildrenToParent(doc, pendingParentPathsToChildren.remove(fullDocPath)); // no longer pending\n          }\n\n          // get parent path\n          String parentDocPath = getParentPath(fullDocPath);\n          String lastPath = getLastPath(fullDocPath);\n          // put into pending:\n          // trim path if the doc was inside array, see trimPathIfArrayDoc()\n          // e.g. toppings#1/ingredients#1 -> outer map key toppings#1\n          // -> inner MultiMap key ingredients\n          // or lonely#/lonelyGrandChild# -> outer map key lonely#\n          // -> inner MultiMap key lonelyGrandChild#\n          pendingParentPathsToChildren.computeIfAbsent(parentDocPath, x -> ArrayListMultimap.create())\n              .put(trimLastPoundIfArray(lastPath), doc); // multimap add (won't replace)\n        }\n      }\n\n      if (pendingParentPathsToChildren.isEmpty()) {\n        // no child docs matched the child filter; return fast.\n        return;\n      }\n\n      // only children of parent remain\n      assert pendingParentPathsToChildren.keySet().size() == 1;\n\n      // size == 1, so get the last remaining entry\n      addChildrenToParent(rootDoc, pendingParentPathsToChildren.values().iterator().next());\n\n    } catch (IOException e) {\n      //TODO DWS: reconsider this unusual error handling approach; shouldn't we rethrow?\n      log.warn(\"Could not fetch child documents\", e);\n      rootDoc.put(getName(), \"Could not fetch child documents\");\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"373ea6b2f051d2a56e8e78a5da11de7aa52ed399","date":1536159014,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/response/transform/ChildDocTransformer#transform(SolrDocument,int).mjava","pathOld":"solr/core/src/java/org/apache/solr/response/transform/ChildDocTransformer#transform(SolrDocument,int).mjava","sourceNew":"  @Override\n  public void transform(SolrDocument rootDoc, int rootDocId) {\n    // note: this algorithm works if both if we have have _nest_path_  and also if we don't!\n\n    try {\n\n      // lookup what the *previous* rootDocId is, and figure which segment this is\n      final SolrIndexSearcher searcher = context.getSearcher();\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final int seg = ReaderUtil.subIndex(rootDocId, leaves);\n      final LeafReaderContext leafReaderContext = leaves.get(seg);\n      final int segBaseId = leafReaderContext.docBase;\n      final int segRootId = rootDocId - segBaseId;\n      final BitSet segParentsBitSet = parentsFilter.getBitSet(leafReaderContext);\n\n      final int segPrevRootId = segRootId==0? -1: segParentsBitSet.prevSetBit(segRootId - 1); // can return -1 and that's okay\n\n      if (segPrevRootId == (segRootId - 1)) {\n        // doc has no children, return fast\n        return;\n      }\n\n      // we'll need this soon...\n      final SortedDocValues segPathDocValues = DocValues.getSorted(leafReaderContext.reader(), NEST_PATH_FIELD_NAME);\n      // passing a different SortedDocValues obj since the child documents which come after are of smaller docIDs,\n      // and the iterator can not be reversed.\n      // The root doc is the input document to be transformed, and is not necessarily the root doc of the block of docs.\n      final String rootDocPath = getPathByDocId(segRootId, DocValues.getSorted(leafReaderContext.reader(), NEST_PATH_FIELD_NAME));\n\n      // the key in the Map is the document's ancestors key (one above the parent), while the key in the intermediate\n      // MultiMap is the direct child document's key(of the parent document)\n      final Map<String, Multimap<String, SolrDocument>> pendingParentPathsToChildren = new HashMap<>();\n\n      final int firstChildId = segBaseId + segPrevRootId + 1;\n      int matches = 0;\n      // Loop each child ID up to the parent (exclusive).\n      for (int docId = firstChildId; docId < rootDocId; ++docId) {\n\n        // get the path.  (note will default to ANON_CHILD_KEY if schema is not nested or empty string if blank)\n        final String fullDocPath = getPathByDocId(docId - segBaseId, segPathDocValues);\n\n        if (isNestedSchema && !fullDocPath.startsWith(rootDocPath)) {\n          // is not a descendant of the transformed doc; return fast.\n          continue;\n        }\n\n        // Is this doc a direct ancestor of another doc we've seen?\n        boolean isAncestor = pendingParentPathsToChildren.containsKey(fullDocPath);\n\n        // Do we need to do anything with this doc (either ancestor or matched the child query)\n        if (isAncestor || childDocSet == null || childDocSet.exists(docId)) {\n\n          // If we reached the limit, only add if it's an ancestor\n          if (limit != -1 && matches >= limit && !isAncestor) {\n            continue;\n          }\n          ++matches; // note: includes ancestors that are not necessarily in childDocSet\n\n          // load the doc\n          SolrDocument doc = searcher.getDocFetcher().solrDoc(docId, childReturnFields);\n          if(childReturnFields.getTransformer() != null) {\n            if(childReturnFields.getTransformer().context == null) {\n              childReturnFields.getTransformer().setContext(context);\n            }\n            childReturnFields.getTransformer().transform(doc, docId);\n          }\n\n          if (isAncestor) {\n            // if this path has pending child docs, add them.\n            addChildrenToParent(doc, pendingParentPathsToChildren.remove(fullDocPath)); // no longer pending\n          }\n\n          // get parent path\n          String parentDocPath = getParentPath(fullDocPath);\n          String lastPath = getLastPath(fullDocPath);\n          // put into pending:\n          // trim path if the doc was inside array, see trimPathIfArrayDoc()\n          // e.g. toppings#1/ingredients#1 -> outer map key toppings#1\n          // -> inner MultiMap key ingredients\n          // or lonely#/lonelyGrandChild# -> outer map key lonely#\n          // -> inner MultiMap key lonelyGrandChild#\n          pendingParentPathsToChildren.computeIfAbsent(parentDocPath, x -> ArrayListMultimap.create())\n              .put(trimLastPoundIfArray(lastPath), doc); // multimap add (won't replace)\n        }\n      }\n\n      if (pendingParentPathsToChildren.isEmpty()) {\n        // no child docs matched the child filter; return fast.\n        return;\n      }\n\n      // only children of parent remain\n      assert pendingParentPathsToChildren.keySet().size() == 1;\n\n      // size == 1, so get the last remaining entry\n      addChildrenToParent(rootDoc, pendingParentPathsToChildren.values().iterator().next());\n\n    } catch (IOException e) {\n      //TODO DWS: reconsider this unusual error handling approach; shouldn't we rethrow?\n      log.warn(\"Could not fetch child documents\", e);\n      rootDoc.put(getName(), \"Could not fetch child documents\");\n    }\n  }\n\n","sourceOld":"  @Override\n  public void transform(SolrDocument rootDoc, int rootDocId) {\n    // note: this algorithm works if both if we have have _nest_path_  and also if we don't!\n\n    try {\n\n      // lookup what the *previous* rootDocId is, and figure which segment this is\n      final SolrIndexSearcher searcher = context.getSearcher();\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final int seg = ReaderUtil.subIndex(rootDocId, leaves);\n      final LeafReaderContext leafReaderContext = leaves.get(seg);\n      final int segBaseId = leafReaderContext.docBase;\n      final int segRootId = rootDocId - segBaseId;\n      final BitSet segParentsBitSet = parentsFilter.getBitSet(leafReaderContext);\n\n      final int segPrevRootId = segRootId==0? -1: segParentsBitSet.prevSetBit(segRootId - 1); // can return -1 and that's okay\n\n      if (segPrevRootId == (segRootId - 1)) {\n        // doc has no children, return fast\n        return;\n      }\n\n      // we'll need this soon...\n      final SortedDocValues segPathDocValues = DocValues.getSorted(leafReaderContext.reader(), NEST_PATH_FIELD_NAME);\n      // passing a different SortedDocValues obj since the child documents which come after are of smaller docIDs,\n      // and the iterator can not be reversed.\n      // The root doc is the input document to be transformed, and is not necessarily the root doc of the block of docs.\n      final String rootDocPath = getPathByDocId(segRootId, DocValues.getSorted(leafReaderContext.reader(), NEST_PATH_FIELD_NAME));\n\n      // the key in the Map is the document's ancestors key (one above the parent), while the key in the intermediate\n      // MultiMap is the direct child document's key(of the parent document)\n      final Map<String, Multimap<String, SolrDocument>> pendingParentPathsToChildren = new HashMap<>();\n\n      final int firstChildId = segBaseId + segPrevRootId + 1;\n      int matches = 0;\n      // Loop each child ID up to the parent (exclusive).\n      for (int docId = firstChildId; docId < rootDocId; ++docId) {\n\n        // get the path.  (note will default to ANON_CHILD_KEY if schema is not nested or empty string if blank)\n        final String fullDocPath = getPathByDocId(docId - segBaseId, segPathDocValues);\n\n        if (isNestedSchema && !fullDocPath.startsWith(rootDocPath)) {\n          // is not a descendant of the transformed doc; return fast.\n          continue;\n        }\n\n        // Is this doc a direct ancestor of another doc we've seen?\n        boolean isAncestor = pendingParentPathsToChildren.containsKey(fullDocPath);\n\n        // Do we need to do anything with this doc (either ancestor or matched the child query)\n        if (isAncestor || childDocSet == null || childDocSet.exists(docId)) {\n\n          // If we reached the limit, only add if it's an ancestor\n          if (limit != -1 && matches >= limit && !isAncestor) {\n            continue;\n          }\n          ++matches; // note: includes ancestors that are not necessarily in childDocSet\n\n          // load the doc\n          SolrDocument doc = searcher.getDocFetcher().solrDoc(docId, childReturnFields);\n\n          if (isAncestor) {\n            // if this path has pending child docs, add them.\n            addChildrenToParent(doc, pendingParentPathsToChildren.remove(fullDocPath)); // no longer pending\n          }\n\n          // get parent path\n          String parentDocPath = getParentPath(fullDocPath);\n          String lastPath = getLastPath(fullDocPath);\n          // put into pending:\n          // trim path if the doc was inside array, see trimPathIfArrayDoc()\n          // e.g. toppings#1/ingredients#1 -> outer map key toppings#1\n          // -> inner MultiMap key ingredients\n          // or lonely#/lonelyGrandChild# -> outer map key lonely#\n          // -> inner MultiMap key lonelyGrandChild#\n          pendingParentPathsToChildren.computeIfAbsent(parentDocPath, x -> ArrayListMultimap.create())\n              .put(trimLastPoundIfArray(lastPath), doc); // multimap add (won't replace)\n        }\n      }\n\n      if (pendingParentPathsToChildren.isEmpty()) {\n        // no child docs matched the child filter; return fast.\n        return;\n      }\n\n      // only children of parent remain\n      assert pendingParentPathsToChildren.keySet().size() == 1;\n\n      // size == 1, so get the last remaining entry\n      addChildrenToParent(rootDoc, pendingParentPathsToChildren.values().iterator().next());\n\n    } catch (IOException e) {\n      //TODO DWS: reconsider this unusual error handling approach; shouldn't we rethrow?\n      log.warn(\"Could not fetch child documents\", e);\n      rootDoc.put(getName(), \"Could not fetch child documents\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4ebb1536e19c5444665867a1657edcb497771adf","date":1584507748,"type":3,"author":"Munendra S N","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/response/transform/ChildDocTransformer#transform(SolrDocument,int).mjava","pathOld":"solr/core/src/java/org/apache/solr/response/transform/ChildDocTransformer#transform(SolrDocument,int).mjava","sourceNew":"  @Override\n  public void transform(SolrDocument rootDoc, int rootDocId) {\n    // note: this algorithm works if both if we have have _nest_path_  and also if we don't!\n\n    try {\n\n      // lookup what the *previous* rootDocId is, and figure which segment this is\n      final SolrIndexSearcher searcher = context.getSearcher();\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final int seg = ReaderUtil.subIndex(rootDocId, leaves);\n      final LeafReaderContext leafReaderContext = leaves.get(seg);\n      final int segBaseId = leafReaderContext.docBase;\n      final int segRootId = rootDocId - segBaseId;\n      final BitSet segParentsBitSet = parentsFilter.getBitSet(leafReaderContext);\n\n      if (segParentsBitSet == null) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n            \"Parent filter '\" + parentsFilter + \"' doesn't match any parent documents\");\n      }\n\n      final int segPrevRootId = segRootId==0? -1: segParentsBitSet.prevSetBit(segRootId - 1); // can return -1 and that's okay\n\n      if (segPrevRootId == (segRootId - 1)) {\n        // doc has no children, return fast\n        return;\n      }\n\n      // we'll need this soon...\n      final SortedDocValues segPathDocValues = DocValues.getSorted(leafReaderContext.reader(), NEST_PATH_FIELD_NAME);\n      // passing a different SortedDocValues obj since the child documents which come after are of smaller docIDs,\n      // and the iterator can not be reversed.\n      // The root doc is the input document to be transformed, and is not necessarily the root doc of the block of docs.\n      final String rootDocPath = getPathByDocId(segRootId, DocValues.getSorted(leafReaderContext.reader(), NEST_PATH_FIELD_NAME));\n\n      // the key in the Map is the document's ancestors key (one above the parent), while the key in the intermediate\n      // MultiMap is the direct child document's key(of the parent document)\n      final Map<String, Multimap<String, SolrDocument>> pendingParentPathsToChildren = new HashMap<>();\n\n      final int firstChildId = segBaseId + segPrevRootId + 1;\n      int matches = 0;\n      // Loop each child ID up to the parent (exclusive).\n      for (int docId = firstChildId; docId < rootDocId; ++docId) {\n\n        // get the path.  (note will default to ANON_CHILD_KEY if schema is not nested or empty string if blank)\n        final String fullDocPath = getPathByDocId(docId - segBaseId, segPathDocValues);\n\n        if (isNestedSchema && !fullDocPath.startsWith(rootDocPath)) {\n          // is not a descendant of the transformed doc; return fast.\n          continue;\n        }\n\n        // Is this doc a direct ancestor of another doc we've seen?\n        boolean isAncestor = pendingParentPathsToChildren.containsKey(fullDocPath);\n\n        // Do we need to do anything with this doc (either ancestor or matched the child query)\n        if (isAncestor || childDocSet == null || childDocSet.exists(docId)) {\n\n          // If we reached the limit, only add if it's an ancestor\n          if (limit != -1 && matches >= limit && !isAncestor) {\n            continue;\n          }\n          ++matches; // note: includes ancestors that are not necessarily in childDocSet\n\n          // load the doc\n          SolrDocument doc = searcher.getDocFetcher().solrDoc(docId, childReturnFields);\n          if(childReturnFields.getTransformer() != null) {\n            if(childReturnFields.getTransformer().context == null) {\n              childReturnFields.getTransformer().setContext(context);\n            }\n            childReturnFields.getTransformer().transform(doc, docId);\n          }\n\n          if (isAncestor) {\n            // if this path has pending child docs, add them.\n            addChildrenToParent(doc, pendingParentPathsToChildren.remove(fullDocPath)); // no longer pending\n          }\n\n          // get parent path\n          String parentDocPath = getParentPath(fullDocPath);\n          String lastPath = getLastPath(fullDocPath);\n          // put into pending:\n          // trim path if the doc was inside array, see trimPathIfArrayDoc()\n          // e.g. toppings#1/ingredients#1 -> outer map key toppings#1\n          // -> inner MultiMap key ingredients\n          // or lonely#/lonelyGrandChild# -> outer map key lonely#\n          // -> inner MultiMap key lonelyGrandChild#\n          pendingParentPathsToChildren.computeIfAbsent(parentDocPath, x -> ArrayListMultimap.create())\n              .put(trimLastPoundIfArray(lastPath), doc); // multimap add (won't replace)\n        }\n      }\n\n      if (pendingParentPathsToChildren.isEmpty()) {\n        // no child docs matched the child filter; return fast.\n        return;\n      }\n\n      // only children of parent remain\n      assert pendingParentPathsToChildren.keySet().size() == 1;\n\n      // size == 1, so get the last remaining entry\n      addChildrenToParent(rootDoc, pendingParentPathsToChildren.values().iterator().next());\n\n    } catch (IOException e) {\n      //TODO DWS: reconsider this unusual error handling approach; shouldn't we rethrow?\n      log.warn(\"Could not fetch child documents\", e);\n      rootDoc.put(getName(), \"Could not fetch child documents\");\n    }\n  }\n\n","sourceOld":"  @Override\n  public void transform(SolrDocument rootDoc, int rootDocId) {\n    // note: this algorithm works if both if we have have _nest_path_  and also if we don't!\n\n    try {\n\n      // lookup what the *previous* rootDocId is, and figure which segment this is\n      final SolrIndexSearcher searcher = context.getSearcher();\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final int seg = ReaderUtil.subIndex(rootDocId, leaves);\n      final LeafReaderContext leafReaderContext = leaves.get(seg);\n      final int segBaseId = leafReaderContext.docBase;\n      final int segRootId = rootDocId - segBaseId;\n      final BitSet segParentsBitSet = parentsFilter.getBitSet(leafReaderContext);\n\n      final int segPrevRootId = segRootId==0? -1: segParentsBitSet.prevSetBit(segRootId - 1); // can return -1 and that's okay\n\n      if (segPrevRootId == (segRootId - 1)) {\n        // doc has no children, return fast\n        return;\n      }\n\n      // we'll need this soon...\n      final SortedDocValues segPathDocValues = DocValues.getSorted(leafReaderContext.reader(), NEST_PATH_FIELD_NAME);\n      // passing a different SortedDocValues obj since the child documents which come after are of smaller docIDs,\n      // and the iterator can not be reversed.\n      // The root doc is the input document to be transformed, and is not necessarily the root doc of the block of docs.\n      final String rootDocPath = getPathByDocId(segRootId, DocValues.getSorted(leafReaderContext.reader(), NEST_PATH_FIELD_NAME));\n\n      // the key in the Map is the document's ancestors key (one above the parent), while the key in the intermediate\n      // MultiMap is the direct child document's key(of the parent document)\n      final Map<String, Multimap<String, SolrDocument>> pendingParentPathsToChildren = new HashMap<>();\n\n      final int firstChildId = segBaseId + segPrevRootId + 1;\n      int matches = 0;\n      // Loop each child ID up to the parent (exclusive).\n      for (int docId = firstChildId; docId < rootDocId; ++docId) {\n\n        // get the path.  (note will default to ANON_CHILD_KEY if schema is not nested or empty string if blank)\n        final String fullDocPath = getPathByDocId(docId - segBaseId, segPathDocValues);\n\n        if (isNestedSchema && !fullDocPath.startsWith(rootDocPath)) {\n          // is not a descendant of the transformed doc; return fast.\n          continue;\n        }\n\n        // Is this doc a direct ancestor of another doc we've seen?\n        boolean isAncestor = pendingParentPathsToChildren.containsKey(fullDocPath);\n\n        // Do we need to do anything with this doc (either ancestor or matched the child query)\n        if (isAncestor || childDocSet == null || childDocSet.exists(docId)) {\n\n          // If we reached the limit, only add if it's an ancestor\n          if (limit != -1 && matches >= limit && !isAncestor) {\n            continue;\n          }\n          ++matches; // note: includes ancestors that are not necessarily in childDocSet\n\n          // load the doc\n          SolrDocument doc = searcher.getDocFetcher().solrDoc(docId, childReturnFields);\n          if(childReturnFields.getTransformer() != null) {\n            if(childReturnFields.getTransformer().context == null) {\n              childReturnFields.getTransformer().setContext(context);\n            }\n            childReturnFields.getTransformer().transform(doc, docId);\n          }\n\n          if (isAncestor) {\n            // if this path has pending child docs, add them.\n            addChildrenToParent(doc, pendingParentPathsToChildren.remove(fullDocPath)); // no longer pending\n          }\n\n          // get parent path\n          String parentDocPath = getParentPath(fullDocPath);\n          String lastPath = getLastPath(fullDocPath);\n          // put into pending:\n          // trim path if the doc was inside array, see trimPathIfArrayDoc()\n          // e.g. toppings#1/ingredients#1 -> outer map key toppings#1\n          // -> inner MultiMap key ingredients\n          // or lonely#/lonelyGrandChild# -> outer map key lonely#\n          // -> inner MultiMap key lonelyGrandChild#\n          pendingParentPathsToChildren.computeIfAbsent(parentDocPath, x -> ArrayListMultimap.create())\n              .put(trimLastPoundIfArray(lastPath), doc); // multimap add (won't replace)\n        }\n      }\n\n      if (pendingParentPathsToChildren.isEmpty()) {\n        // no child docs matched the child filter; return fast.\n        return;\n      }\n\n      // only children of parent remain\n      assert pendingParentPathsToChildren.keySet().size() == 1;\n\n      // size == 1, so get the last remaining entry\n      addChildrenToParent(rootDoc, pendingParentPathsToChildren.values().iterator().next());\n\n    } catch (IOException e) {\n      //TODO DWS: reconsider this unusual error handling approach; shouldn't we rethrow?\n      log.warn(\"Could not fetch child documents\", e);\n      rootDoc.put(getName(), \"Could not fetch child documents\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4ebb1536e19c5444665867a1657edcb497771adf":["373ea6b2f051d2a56e8e78a5da11de7aa52ed399"],"373ea6b2f051d2a56e8e78a5da11de7aa52ed399":["44e1477dd67ee1fbc72871f23fb51369bb42cadd"],"44e1477dd67ee1fbc72871f23fb51369bb42cadd":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["4ebb1536e19c5444665867a1657edcb497771adf"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["44e1477dd67ee1fbc72871f23fb51369bb42cadd"],"4ebb1536e19c5444665867a1657edcb497771adf":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"373ea6b2f051d2a56e8e78a5da11de7aa52ed399":["4ebb1536e19c5444665867a1657edcb497771adf"],"44e1477dd67ee1fbc72871f23fb51369bb42cadd":["373ea6b2f051d2a56e8e78a5da11de7aa52ed399"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}