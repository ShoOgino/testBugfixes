{"path":"lucene/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","pathOld":"lucene/contrib/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","sourceNew":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new Field(\"path\", file.getPath(), StringField.TYPE_STORED);\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a LongField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          doc.add(new LongField(\"modified\", file.lastModified()));\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new TextField(\"contents\", new BufferedReader(new InputStreamReader(fis, \"UTF-8\"))));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new Field(\"path\", file.getPath(), StringField.TYPE_STORED);\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a LongField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          doc.add(new LongField(\"modified\", file.lastModified()));\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new TextField(\"contents\", new BufferedReader(new InputStreamReader(fis, \"UTF-8\"))));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"04f07771a2a7dd3a395700665ed839c3dae2def2","date":1339350139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","pathOld":"lucene/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","sourceNew":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new StringField(\"path\", file.getPath(), Field.Store.YES);\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a LongField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          doc.add(new LongField(\"modified\", file.lastModified(), Field.Store.NO));\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new TextField(\"contents\", new BufferedReader(new InputStreamReader(fis, \"UTF-8\")), Field.Store.NO));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new Field(\"path\", file.getPath(), StringField.TYPE_STORED);\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a LongField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          doc.add(new LongField(\"modified\", file.lastModified()));\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new TextField(\"contents\", new BufferedReader(new InputStreamReader(fis, \"UTF-8\"))));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","bugFix":["a78a90fc9701e511308346ea29f4f5e548bb39fe","1509f151d7692d84fae414b2b799ac06ba60fcb4","7e4db59c6b6c10e25322cfb41c4c19d78b4298bd"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a3635dad24b0681f0088f2ef680456482cdb451","date":1344025573,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","pathOld":"lucene/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","sourceNew":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new StringField(\"path\", file.getPath(), Field.Store.YES);\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a LongField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          doc.add(new LongField(\"modified\", file.lastModified(), Field.Store.NO));\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new TextField(\"contents\", new BufferedReader(new InputStreamReader(fis, \"UTF-8\"))));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new StringField(\"path\", file.getPath(), Field.Store.YES);\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a LongField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          doc.add(new LongField(\"modified\", file.lastModified(), Field.Store.NO));\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new TextField(\"contents\", new BufferedReader(new InputStreamReader(fis, \"UTF-8\")), Field.Store.NO));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8fd5be977c105554c6a7b68afcdbc511439723ab","date":1344115570,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","pathOld":"lucene/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","sourceNew":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new StringField(\"path\", file.getPath(), Field.Store.YES);\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a LongField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          doc.add(new LongField(\"modified\", file.lastModified(), Field.Store.NO));\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new TextField(\"contents\", new BufferedReader(new InputStreamReader(fis, \"UTF-8\"))));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new StringField(\"path\", file.getPath(), Field.Store.YES);\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a LongField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          doc.add(new LongField(\"modified\", file.lastModified(), Field.Store.NO));\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new TextField(\"contents\", new BufferedReader(new InputStreamReader(fis, \"UTF-8\")), Field.Store.NO));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","pathOld":"lucene/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","sourceNew":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new StringField(\"path\", file.getPath(), Field.Store.YES);\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a LongField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          doc.add(new LongField(\"modified\", file.lastModified(), Field.Store.NO));\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new TextField(\"contents\", new BufferedReader(new InputStreamReader(fis, \"UTF-8\"))));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new StringField(\"path\", file.getPath(), Field.Store.YES);\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a LongField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          doc.add(new LongField(\"modified\", file.lastModified(), Field.Store.NO));\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new TextField(\"contents\", new BufferedReader(new InputStreamReader(fis, \"UTF-8\")), Field.Store.NO));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069","date":1348430063,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","pathOld":"lucene/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","sourceNew":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException If there is a low-level I/O error\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new StringField(\"path\", file.getPath(), Field.Store.YES);\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a LongField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          doc.add(new LongField(\"modified\", file.lastModified(), Field.Store.NO));\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new TextField(\"contents\", new BufferedReader(new InputStreamReader(fis, \"UTF-8\"))));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new StringField(\"path\", file.getPath(), Field.Store.YES);\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a LongField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          doc.add(new LongField(\"modified\", file.lastModified(), Field.Store.NO));\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new TextField(\"contents\", new BufferedReader(new InputStreamReader(fis, \"UTF-8\"))));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7d89d7e4e5101347833eea558851bf4209218619","date":1396265641,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","pathOld":"lucene/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","sourceNew":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException If there is a low-level I/O error\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new StringField(\"path\", file.getPath(), Field.Store.YES);\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a LongField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          doc.add(new LongField(\"modified\", file.lastModified(), Field.Store.NO));\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new TextField(\"contents\", new BufferedReader(new InputStreamReader(fis, StandardCharsets.UTF_8))));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException If there is a low-level I/O error\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new StringField(\"path\", file.getPath(), Field.Store.YES);\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a LongField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          doc.add(new LongField(\"modified\", file.lastModified(), Field.Store.NO));\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new TextField(\"contents\", new BufferedReader(new InputStreamReader(fis, \"UTF-8\"))));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5eb2511ababf862ea11e10761c70ee560cd84510","date":1396607225,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","pathOld":"lucene/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","sourceNew":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException If there is a low-level I/O error\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new StringField(\"path\", file.getPath(), Field.Store.YES);\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a LongField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          doc.add(new LongField(\"modified\", file.lastModified(), Field.Store.NO));\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new TextField(\"contents\", new BufferedReader(new InputStreamReader(fis, StandardCharsets.UTF_8))));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException If there is a low-level I/O error\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new StringField(\"path\", file.getPath(), Field.Store.YES);\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a LongField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          doc.add(new LongField(\"modified\", file.lastModified(), Field.Store.NO));\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new TextField(\"contents\", new BufferedReader(new InputStreamReader(fis, \"UTF-8\"))));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f4abec28b874149a7223e32cc7a01704c27790de","date":1410644789,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/demo/src/java/org/apache/lucene/demo/IndexFiles#indexDocs(IndexWriter,File).mjava","sourceNew":null,"sourceOld":"  /**\n   * Indexes the given file using the given writer, or if a directory is given,\n   * recurses over files and directories found under the given directory.\n   * \n   * NOTE: This method indexes one document per input file.  This is slow.  For good\n   * throughput, put multiple documents into your input file(s).  An example of this is\n   * in the benchmark module, which can create \"line doc\" files, one document per line,\n   * using the\n   * <a href=\"../../../../../contrib-benchmark/org/apache/lucene/benchmark/byTask/tasks/WriteLineDocTask.html\"\n   * >WriteLineDocTask</a>.\n   *  \n   * @param writer Writer to the index where the given file/dir info will be stored\n   * @param file The file to index, or the directory to recurse into to find files to index\n   * @throws IOException If there is a low-level I/O error\n   */\n  static void indexDocs(IndexWriter writer, File file)\n    throws IOException {\n    // do not try to index files that cannot be read\n    if (file.canRead()) {\n      if (file.isDirectory()) {\n        String[] files = file.list();\n        // an IO error could occur\n        if (files != null) {\n          for (int i = 0; i < files.length; i++) {\n            indexDocs(writer, new File(file, files[i]));\n          }\n        }\n      } else {\n\n        FileInputStream fis;\n        try {\n          fis = new FileInputStream(file);\n        } catch (FileNotFoundException fnfe) {\n          // at least on windows, some temporary files raise this exception with an \"access denied\" message\n          // checking if the file can be read doesn't help\n          return;\n        }\n\n        try {\n\n          // make a new, empty document\n          Document doc = new Document();\n\n          // Add the path of the file as a field named \"path\".  Use a\n          // field that is indexed (i.e. searchable), but don't tokenize \n          // the field into separate words and don't index term frequency\n          // or positional information:\n          Field pathField = new StringField(\"path\", file.getPath(), Field.Store.YES);\n          doc.add(pathField);\n\n          // Add the last modified date of the file a field named \"modified\".\n          // Use a LongField that is indexed (i.e. efficiently filterable with\n          // NumericRangeFilter).  This indexes to milli-second resolution, which\n          // is often too fine.  You could instead create a number based on\n          // year/month/day/hour/minutes/seconds, down the resolution you require.\n          // For example the long value 2011021714 would mean\n          // February 17, 2011, 2-3 PM.\n          doc.add(new LongField(\"modified\", file.lastModified(), Field.Store.NO));\n\n          // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n          // so that the text of the file is tokenized and indexed, but not stored.\n          // Note that FileReader expects the file to be in UTF-8 encoding.\n          // If that's not the case searching for special characters will fail.\n          doc.add(new TextField(\"contents\", new BufferedReader(new InputStreamReader(fis, StandardCharsets.UTF_8))));\n\n          if (writer.getConfig().getOpenMode() == OpenMode.CREATE) {\n            // New index, so we just add the document (no old document can be there):\n            System.out.println(\"adding \" + file);\n            writer.addDocument(doc);\n          } else {\n            // Existing index (an old copy of this document may have been indexed) so \n            // we use updateDocument instead to replace the old one matching the exact \n            // path, if present:\n            System.out.println(\"updating \" + file);\n            writer.updateDocument(new Term(\"path\", file.getPath()), doc);\n          }\n          \n        } finally {\n          fis.close();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069":["3a3635dad24b0681f0088f2ef680456482cdb451"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"5eb2511ababf862ea11e10761c70ee560cd84510":["c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069","7d89d7e4e5101347833eea558851bf4209218619"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["04f07771a2a7dd3a395700665ed839c3dae2def2","3a3635dad24b0681f0088f2ef680456482cdb451"],"8fd5be977c105554c6a7b68afcdbc511439723ab":["04f07771a2a7dd3a395700665ed839c3dae2def2","3a3635dad24b0681f0088f2ef680456482cdb451"],"f4abec28b874149a7223e32cc7a01704c27790de":["7d89d7e4e5101347833eea558851bf4209218619"],"7d89d7e4e5101347833eea558851bf4209218619":["c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069"],"3a3635dad24b0681f0088f2ef680456482cdb451":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["f4abec28b874149a7223e32cc7a01704c27790de"]},"commit2Childs":{"c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069":["5eb2511ababf862ea11e10761c70ee560cd84510","7d89d7e4e5101347833eea558851bf4209218619"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["d6f074e73200c07d54f242d3880a8da5a35ff97b","8fd5be977c105554c6a7b68afcdbc511439723ab","3a3635dad24b0681f0088f2ef680456482cdb451"],"5eb2511ababf862ea11e10761c70ee560cd84510":[],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":[],"8fd5be977c105554c6a7b68afcdbc511439723ab":[],"7d89d7e4e5101347833eea558851bf4209218619":["5eb2511ababf862ea11e10761c70ee560cd84510","f4abec28b874149a7223e32cc7a01704c27790de"],"f4abec28b874149a7223e32cc7a01704c27790de":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3a3635dad24b0681f0088f2ef680456482cdb451":["c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069","d6f074e73200c07d54f242d3880a8da5a35ff97b","8fd5be977c105554c6a7b68afcdbc511439723ab"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["5eb2511ababf862ea11e10761c70ee560cd84510","d6f074e73200c07d54f242d3880a8da5a35ff97b","8fd5be977c105554c6a7b68afcdbc511439723ab","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}