{"path":"lucene/core/src/test/org/apache/lucene/index/TestReaderPool#testUpdate().mjava","commits":[{"id":"1926100d9b67becc9701c54266fee3ba7878a5f0","date":1524472150,"type":0,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestReaderPool#testUpdate().mjava","pathOld":"/dev/null","sourceNew":"  public void testUpdate() throws IOException {\n    Directory directory = newDirectory();\n    FieldInfos.FieldNumbers fieldNumbers = buildIndex(directory);\n    StandardDirectoryReader reader = (StandardDirectoryReader) DirectoryReader.open(directory);\n    SegmentInfos segmentInfos = reader.segmentInfos.clone();\n    ReaderPool pool = new ReaderPool(directory, directory, segmentInfos, fieldNumbers, () -> 0l,\n        new NullInfoStream(), null, null);\n    int id = random().nextInt(10);\n    if (random().nextBoolean()) {\n      pool.enableReaderPooling();\n    }\n    for (SegmentCommitInfo commitInfo : segmentInfos) {\n      ReadersAndUpdates readersAndUpdates = pool.get(commitInfo, true);\n      SegmentReader readOnlyClone = readersAndUpdates.getReadOnlyClone(IOContext.READ);\n      PostingsEnum postings = readOnlyClone.postings(new Term(\"id\", \"\" + id));\n      boolean expectUpdate = false;\n      int doc = -1;\n      if (postings != null && postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        NumericDocValuesFieldUpdates number = new NumericDocValuesFieldUpdates(0, \"number\", commitInfo.info.maxDoc());\n        number.add(doc = postings.docID(), 1000l);\n        number.finish();\n        readersAndUpdates.addDVUpdate(number);\n        expectUpdate = true;\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n        assertTrue(pool.anyDocValuesChanges());\n      } else {\n        assertFalse(pool.anyDocValuesChanges());\n      }\n      readOnlyClone.close();\n      boolean writtenToDisk;\n      if (pool.isReaderPoolingEnabled()) {\n        if (random().nextBoolean()) {\n          writtenToDisk = pool.writeAllDocValuesUpdates();\n          assertFalse(readersAndUpdates.isMerging());\n        } else if (random().nextBoolean()) {\n          writtenToDisk = pool.commit(segmentInfos);\n          assertFalse(readersAndUpdates.isMerging());\n        } else {\n          writtenToDisk = pool.writeDocValuesUpdatesForMerge(Collections.singletonList(commitInfo));\n          assertTrue(readersAndUpdates.isMerging());\n        }\n        assertFalse(pool.release(readersAndUpdates, random().nextBoolean()));\n      } else {\n        if (random().nextBoolean()) {\n          writtenToDisk = pool.release(readersAndUpdates, random().nextBoolean());\n          assertFalse(readersAndUpdates.isMerging());\n        } else {\n          writtenToDisk = pool.writeDocValuesUpdatesForMerge(Collections.singletonList(commitInfo));\n          assertTrue(readersAndUpdates.isMerging());\n          assertFalse(pool.release(readersAndUpdates, random().nextBoolean()));\n        }\n      }\n      assertFalse(pool.anyDocValuesChanges());\n      assertEquals(expectUpdate, writtenToDisk);\n      if (expectUpdate) {\n        readersAndUpdates = pool.get(commitInfo, true);\n        SegmentReader updatedReader = readersAndUpdates.getReadOnlyClone(IOContext.READ);\n        assertNotSame(-1, doc);\n        NumericDocValues number = updatedReader.getNumericDocValues(\"number\");\n        assertEquals(doc, number.advance(doc));\n        assertEquals(1000l, number.longValue());\n       readersAndUpdates.release(updatedReader);\n       assertFalse(pool.release(readersAndUpdates, random().nextBoolean()));\n      }\n    }\n    IOUtils.close(pool, reader, directory);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"763da4a9605e47013078edc323b9d4b608f0f9e0","date":1555353576,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestReaderPool#testUpdate().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestReaderPool#testUpdate().mjava","sourceNew":"  public void testUpdate() throws IOException {\n    Directory directory = newDirectory();\n    FieldInfos.FieldNumbers fieldNumbers = buildIndex(directory);\n    StandardDirectoryReader reader = (StandardDirectoryReader) DirectoryReader.open(directory);\n    SegmentInfos segmentInfos = reader.segmentInfos.clone();\n    ReaderPool pool = new ReaderPool(directory, directory, segmentInfos, fieldNumbers, () -> 0l,\n        new NullInfoStream(), null, null, Collections.emptyMap());\n    int id = random().nextInt(10);\n    if (random().nextBoolean()) {\n      pool.enableReaderPooling();\n    }\n    for (SegmentCommitInfo commitInfo : segmentInfos) {\n      ReadersAndUpdates readersAndUpdates = pool.get(commitInfo, true);\n      SegmentReader readOnlyClone = readersAndUpdates.getReadOnlyClone(IOContext.READ);\n      PostingsEnum postings = readOnlyClone.postings(new Term(\"id\", \"\" + id));\n      boolean expectUpdate = false;\n      int doc = -1;\n      if (postings != null && postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        NumericDocValuesFieldUpdates number = new NumericDocValuesFieldUpdates(0, \"number\", commitInfo.info.maxDoc());\n        number.add(doc = postings.docID(), 1000l);\n        number.finish();\n        readersAndUpdates.addDVUpdate(number);\n        expectUpdate = true;\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n        assertTrue(pool.anyDocValuesChanges());\n      } else {\n        assertFalse(pool.anyDocValuesChanges());\n      }\n      readOnlyClone.close();\n      boolean writtenToDisk;\n      if (pool.isReaderPoolingEnabled()) {\n        if (random().nextBoolean()) {\n          writtenToDisk = pool.writeAllDocValuesUpdates();\n          assertFalse(readersAndUpdates.isMerging());\n        } else if (random().nextBoolean()) {\n          writtenToDisk = pool.commit(segmentInfos);\n          assertFalse(readersAndUpdates.isMerging());\n        } else {\n          writtenToDisk = pool.writeDocValuesUpdatesForMerge(Collections.singletonList(commitInfo));\n          assertTrue(readersAndUpdates.isMerging());\n        }\n        assertFalse(pool.release(readersAndUpdates, random().nextBoolean()));\n      } else {\n        if (random().nextBoolean()) {\n          writtenToDisk = pool.release(readersAndUpdates, random().nextBoolean());\n          assertFalse(readersAndUpdates.isMerging());\n        } else {\n          writtenToDisk = pool.writeDocValuesUpdatesForMerge(Collections.singletonList(commitInfo));\n          assertTrue(readersAndUpdates.isMerging());\n          assertFalse(pool.release(readersAndUpdates, random().nextBoolean()));\n        }\n      }\n      assertFalse(pool.anyDocValuesChanges());\n      assertEquals(expectUpdate, writtenToDisk);\n      if (expectUpdate) {\n        readersAndUpdates = pool.get(commitInfo, true);\n        SegmentReader updatedReader = readersAndUpdates.getReadOnlyClone(IOContext.READ);\n        assertNotSame(-1, doc);\n        NumericDocValues number = updatedReader.getNumericDocValues(\"number\");\n        assertEquals(doc, number.advance(doc));\n        assertEquals(1000l, number.longValue());\n       readersAndUpdates.release(updatedReader);\n       assertFalse(pool.release(readersAndUpdates, random().nextBoolean()));\n      }\n    }\n    IOUtils.close(pool, reader, directory);\n  }\n\n","sourceOld":"  public void testUpdate() throws IOException {\n    Directory directory = newDirectory();\n    FieldInfos.FieldNumbers fieldNumbers = buildIndex(directory);\n    StandardDirectoryReader reader = (StandardDirectoryReader) DirectoryReader.open(directory);\n    SegmentInfos segmentInfos = reader.segmentInfos.clone();\n    ReaderPool pool = new ReaderPool(directory, directory, segmentInfos, fieldNumbers, () -> 0l,\n        new NullInfoStream(), null, null);\n    int id = random().nextInt(10);\n    if (random().nextBoolean()) {\n      pool.enableReaderPooling();\n    }\n    for (SegmentCommitInfo commitInfo : segmentInfos) {\n      ReadersAndUpdates readersAndUpdates = pool.get(commitInfo, true);\n      SegmentReader readOnlyClone = readersAndUpdates.getReadOnlyClone(IOContext.READ);\n      PostingsEnum postings = readOnlyClone.postings(new Term(\"id\", \"\" + id));\n      boolean expectUpdate = false;\n      int doc = -1;\n      if (postings != null && postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        NumericDocValuesFieldUpdates number = new NumericDocValuesFieldUpdates(0, \"number\", commitInfo.info.maxDoc());\n        number.add(doc = postings.docID(), 1000l);\n        number.finish();\n        readersAndUpdates.addDVUpdate(number);\n        expectUpdate = true;\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n        assertTrue(pool.anyDocValuesChanges());\n      } else {\n        assertFalse(pool.anyDocValuesChanges());\n      }\n      readOnlyClone.close();\n      boolean writtenToDisk;\n      if (pool.isReaderPoolingEnabled()) {\n        if (random().nextBoolean()) {\n          writtenToDisk = pool.writeAllDocValuesUpdates();\n          assertFalse(readersAndUpdates.isMerging());\n        } else if (random().nextBoolean()) {\n          writtenToDisk = pool.commit(segmentInfos);\n          assertFalse(readersAndUpdates.isMerging());\n        } else {\n          writtenToDisk = pool.writeDocValuesUpdatesForMerge(Collections.singletonList(commitInfo));\n          assertTrue(readersAndUpdates.isMerging());\n        }\n        assertFalse(pool.release(readersAndUpdates, random().nextBoolean()));\n      } else {\n        if (random().nextBoolean()) {\n          writtenToDisk = pool.release(readersAndUpdates, random().nextBoolean());\n          assertFalse(readersAndUpdates.isMerging());\n        } else {\n          writtenToDisk = pool.writeDocValuesUpdatesForMerge(Collections.singletonList(commitInfo));\n          assertTrue(readersAndUpdates.isMerging());\n          assertFalse(pool.release(readersAndUpdates, random().nextBoolean()));\n        }\n      }\n      assertFalse(pool.anyDocValuesChanges());\n      assertEquals(expectUpdate, writtenToDisk);\n      if (expectUpdate) {\n        readersAndUpdates = pool.get(commitInfo, true);\n        SegmentReader updatedReader = readersAndUpdates.getReadOnlyClone(IOContext.READ);\n        assertNotSame(-1, doc);\n        NumericDocValues number = updatedReader.getNumericDocValues(\"number\");\n        assertEquals(doc, number.advance(doc));\n        assertEquals(1000l, number.longValue());\n       readersAndUpdates.release(updatedReader);\n       assertFalse(pool.release(readersAndUpdates, random().nextBoolean()));\n      }\n    }\n    IOUtils.close(pool, reader, directory);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a4e83191a3e02851a0b67e5335e6922f3e9ea86d","date":1583489709,"type":3,"author":"Bruno Roustant","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestReaderPool#testUpdate().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestReaderPool#testUpdate().mjava","sourceNew":"  public void testUpdate() throws IOException {\n    Directory directory = newDirectory();\n    FieldInfos.FieldNumbers fieldNumbers = buildIndex(directory);\n    StandardDirectoryReader reader = (StandardDirectoryReader) DirectoryReader.open(directory);\n    SegmentInfos segmentInfos = reader.segmentInfos.clone();\n    ReaderPool pool = new ReaderPool(directory, directory, segmentInfos, fieldNumbers, () -> 0l,\n        new NullInfoStream(), null, null);\n    int id = random().nextInt(10);\n    if (random().nextBoolean()) {\n      pool.enableReaderPooling();\n    }\n    for (SegmentCommitInfo commitInfo : segmentInfos) {\n      ReadersAndUpdates readersAndUpdates = pool.get(commitInfo, true);\n      SegmentReader readOnlyClone = readersAndUpdates.getReadOnlyClone(IOContext.READ);\n      PostingsEnum postings = readOnlyClone.postings(new Term(\"id\", \"\" + id));\n      boolean expectUpdate = false;\n      int doc = -1;\n      if (postings != null && postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        NumericDocValuesFieldUpdates number = new NumericDocValuesFieldUpdates(0, \"number\", commitInfo.info.maxDoc());\n        number.add(doc = postings.docID(), 1000l);\n        number.finish();\n        readersAndUpdates.addDVUpdate(number);\n        expectUpdate = true;\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n        assertTrue(pool.anyDocValuesChanges());\n      } else {\n        assertFalse(pool.anyDocValuesChanges());\n      }\n      readOnlyClone.close();\n      boolean writtenToDisk;\n      if (pool.isReaderPoolingEnabled()) {\n        if (random().nextBoolean()) {\n          writtenToDisk = pool.writeAllDocValuesUpdates();\n          assertFalse(readersAndUpdates.isMerging());\n        } else if (random().nextBoolean()) {\n          writtenToDisk = pool.commit(segmentInfos);\n          assertFalse(readersAndUpdates.isMerging());\n        } else {\n          writtenToDisk = pool.writeDocValuesUpdatesForMerge(Collections.singletonList(commitInfo));\n          assertTrue(readersAndUpdates.isMerging());\n        }\n        assertFalse(pool.release(readersAndUpdates, random().nextBoolean()));\n      } else {\n        if (random().nextBoolean()) {\n          writtenToDisk = pool.release(readersAndUpdates, random().nextBoolean());\n          assertFalse(readersAndUpdates.isMerging());\n        } else {\n          writtenToDisk = pool.writeDocValuesUpdatesForMerge(Collections.singletonList(commitInfo));\n          assertTrue(readersAndUpdates.isMerging());\n          assertFalse(pool.release(readersAndUpdates, random().nextBoolean()));\n        }\n      }\n      assertFalse(pool.anyDocValuesChanges());\n      assertEquals(expectUpdate, writtenToDisk);\n      if (expectUpdate) {\n        readersAndUpdates = pool.get(commitInfo, true);\n        SegmentReader updatedReader = readersAndUpdates.getReadOnlyClone(IOContext.READ);\n        assertNotSame(-1, doc);\n        NumericDocValues number = updatedReader.getNumericDocValues(\"number\");\n        assertEquals(doc, number.advance(doc));\n        assertEquals(1000l, number.longValue());\n       readersAndUpdates.release(updatedReader);\n       assertFalse(pool.release(readersAndUpdates, random().nextBoolean()));\n      }\n    }\n    IOUtils.close(pool, reader, directory);\n  }\n\n","sourceOld":"  public void testUpdate() throws IOException {\n    Directory directory = newDirectory();\n    FieldInfos.FieldNumbers fieldNumbers = buildIndex(directory);\n    StandardDirectoryReader reader = (StandardDirectoryReader) DirectoryReader.open(directory);\n    SegmentInfos segmentInfos = reader.segmentInfos.clone();\n    ReaderPool pool = new ReaderPool(directory, directory, segmentInfos, fieldNumbers, () -> 0l,\n        new NullInfoStream(), null, null, Collections.emptyMap());\n    int id = random().nextInt(10);\n    if (random().nextBoolean()) {\n      pool.enableReaderPooling();\n    }\n    for (SegmentCommitInfo commitInfo : segmentInfos) {\n      ReadersAndUpdates readersAndUpdates = pool.get(commitInfo, true);\n      SegmentReader readOnlyClone = readersAndUpdates.getReadOnlyClone(IOContext.READ);\n      PostingsEnum postings = readOnlyClone.postings(new Term(\"id\", \"\" + id));\n      boolean expectUpdate = false;\n      int doc = -1;\n      if (postings != null && postings.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n        NumericDocValuesFieldUpdates number = new NumericDocValuesFieldUpdates(0, \"number\", commitInfo.info.maxDoc());\n        number.add(doc = postings.docID(), 1000l);\n        number.finish();\n        readersAndUpdates.addDVUpdate(number);\n        expectUpdate = true;\n        assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n        assertTrue(pool.anyDocValuesChanges());\n      } else {\n        assertFalse(pool.anyDocValuesChanges());\n      }\n      readOnlyClone.close();\n      boolean writtenToDisk;\n      if (pool.isReaderPoolingEnabled()) {\n        if (random().nextBoolean()) {\n          writtenToDisk = pool.writeAllDocValuesUpdates();\n          assertFalse(readersAndUpdates.isMerging());\n        } else if (random().nextBoolean()) {\n          writtenToDisk = pool.commit(segmentInfos);\n          assertFalse(readersAndUpdates.isMerging());\n        } else {\n          writtenToDisk = pool.writeDocValuesUpdatesForMerge(Collections.singletonList(commitInfo));\n          assertTrue(readersAndUpdates.isMerging());\n        }\n        assertFalse(pool.release(readersAndUpdates, random().nextBoolean()));\n      } else {\n        if (random().nextBoolean()) {\n          writtenToDisk = pool.release(readersAndUpdates, random().nextBoolean());\n          assertFalse(readersAndUpdates.isMerging());\n        } else {\n          writtenToDisk = pool.writeDocValuesUpdatesForMerge(Collections.singletonList(commitInfo));\n          assertTrue(readersAndUpdates.isMerging());\n          assertFalse(pool.release(readersAndUpdates, random().nextBoolean()));\n        }\n      }\n      assertFalse(pool.anyDocValuesChanges());\n      assertEquals(expectUpdate, writtenToDisk);\n      if (expectUpdate) {\n        readersAndUpdates = pool.get(commitInfo, true);\n        SegmentReader updatedReader = readersAndUpdates.getReadOnlyClone(IOContext.READ);\n        assertNotSame(-1, doc);\n        NumericDocValues number = updatedReader.getNumericDocValues(\"number\");\n        assertEquals(doc, number.advance(doc));\n        assertEquals(1000l, number.longValue());\n       readersAndUpdates.release(updatedReader);\n       assertFalse(pool.release(readersAndUpdates, random().nextBoolean()));\n      }\n    }\n    IOUtils.close(pool, reader, directory);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"763da4a9605e47013078edc323b9d4b608f0f9e0":["1926100d9b67becc9701c54266fee3ba7878a5f0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1926100d9b67becc9701c54266fee3ba7878a5f0":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a4e83191a3e02851a0b67e5335e6922f3e9ea86d"],"a4e83191a3e02851a0b67e5335e6922f3e9ea86d":["763da4a9605e47013078edc323b9d4b608f0f9e0"]},"commit2Childs":{"763da4a9605e47013078edc323b9d4b608f0f9e0":["a4e83191a3e02851a0b67e5335e6922f3e9ea86d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1926100d9b67becc9701c54266fee3ba7878a5f0"],"1926100d9b67becc9701c54266fee3ba7878a5f0":["763da4a9605e47013078edc323b9d4b608f0f9e0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"a4e83191a3e02851a0b67e5335e6922f3e9ea86d":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}