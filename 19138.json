{"path":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","commits":[{"id":"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","date":1306767085,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","pathOld":"solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","sourceNew":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Map<String, Map<String, Object>> deltaSet = new HashMap<String, Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    String pk = entity.getPk();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      Object pkValue = row.get(pk);\n      if (pkValue == null) {\n        pk = findMatchingPkColumn(pk, row);\n        pkValue = row.get(pk);\n      }\n\n      deltaSet.put(pkValue.toString(), row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      deletedSet.add(row);\n      \n      Object pkValue = row.get(pk);\n      if (pkValue == null) {\n        pk = findMatchingPkColumn(pk, row);\n        pkValue = row.get(pk);\n      }\n\n      // Remove deleted rows from the delta rows\n      String deletedRowPk = pkValue.toString();\n      if (deltaSet.containsKey(deletedRowPk)) {\n        deltaSet.remove(deletedRowPk);\n      }\n\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet.values());\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    // Do not use entity.isDocRoot here because one of descendant entities may set rootEntity=\"true\"\n    return entity.parentEntity == null ?\n        myModifiedPks : new HashSet<Map<String, Object>>(parentKeyList);\n  }\n\n","sourceOld":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Map<String, Map<String, Object>> deltaSet = new HashMap<String, Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    String pk = entity.getPk();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      Object pkValue = row.get(pk);\n      if (pkValue == null) {\n        pk = findMatchingPkColumn(pk, row);\n        pkValue = row.get(pk);\n      }\n\n      deltaSet.put(pkValue.toString(), row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      deletedSet.add(row);\n      \n      Object pkValue = row.get(pk);\n      if (pkValue == null) {\n        pk = findMatchingPkColumn(pk, row);\n        pkValue = row.get(pk);\n      }\n\n      // Remove deleted rows from the delta rows\n      String deletedRowPk = pkValue.toString();\n      if (deltaSet.containsKey(deletedRowPk)) {\n        deltaSet.remove(deletedRowPk);\n      }\n\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet.values());\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    // Do not use entity.isDocRoot here because one of descendant entities may set rootEntity=\"true\"\n    return entity.parentEntity == null ?\n        myModifiedPks : new HashSet<Map<String, Object>>(parentKeyList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","pathOld":"solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","sourceNew":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Map<String, Map<String, Object>> deltaSet = new HashMap<String, Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    String pk = entity.getPk();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      Object pkValue = row.get(pk);\n      if (pkValue == null) {\n        pk = findMatchingPkColumn(pk, row);\n        pkValue = row.get(pk);\n      }\n\n      deltaSet.put(pkValue.toString(), row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      deletedSet.add(row);\n      \n      Object pkValue = row.get(pk);\n      if (pkValue == null) {\n        pk = findMatchingPkColumn(pk, row);\n        pkValue = row.get(pk);\n      }\n\n      // Remove deleted rows from the delta rows\n      String deletedRowPk = pkValue.toString();\n      if (deltaSet.containsKey(deletedRowPk)) {\n        deltaSet.remove(deletedRowPk);\n      }\n\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet.values());\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    // Do not use entity.isDocRoot here because one of descendant entities may set rootEntity=\"true\"\n    return entity.parentEntity == null ?\n        myModifiedPks : new HashSet<Map<String, Object>>(parentKeyList);\n  }\n\n","sourceOld":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Map<String, Map<String, Object>> deltaSet = new HashMap<String, Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    String pk = entity.getPk();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      Object pkValue = row.get(pk);\n      if (pkValue == null) {\n        pk = findMatchingPkColumn(pk, row);\n        pkValue = row.get(pk);\n      }\n\n      deltaSet.put(pkValue.toString(), row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      deletedSet.add(row);\n      \n      Object pkValue = row.get(pk);\n      if (pkValue == null) {\n        pk = findMatchingPkColumn(pk, row);\n        pkValue = row.get(pk);\n      }\n\n      // Remove deleted rows from the delta rows\n      String deletedRowPk = pkValue.toString();\n      if (deltaSet.containsKey(deletedRowPk)) {\n        deltaSet.remove(deletedRowPk);\n      }\n\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet.values());\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    // Do not use entity.isDocRoot here because one of descendant entities may set rootEntity=\"true\"\n    return entity.parentEntity == null ?\n        myModifiedPks : new HashSet<Map<String, Object>>(parentKeyList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4ebea96bbe279c4a8dc0cd5cd1f987cc9b33436c","date":1335805170,"type":5,"author":"James Dyer","isMerge":false,"pathNew":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(EntityProcessorWrapper,VariableResolverImpl,Set[Map[String,Object]]).mjava","pathOld":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","sourceNew":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(EntityProcessorWrapper epw, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    ContextImpl context1 = new ContextImpl(epw, resolver, null, Context.FIND_DELTA, session, null, this);\n    epw.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n   \n\n    for (EntityProcessorWrapper childEpw : epw.getChildren()) {\n      //this ensures that we start from the leaf nodes\n      myModifiedPks.addAll(collectDelta(childEpw, resolver, deletedRows));\n      //someone called abort\n      if (stop.get())\n        return new HashSet();\n    }\n    \n    // identifying the modified rows for this entity\n    Map<String, Map<String, Object>> deltaSet = new HashMap<String, Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + epw.getEntity().getName());\n    //get the modified rows in this entity\n    String pk = epw.getEntity().getPk();\n    while (true) {\n      Map<String, Object> row = epw.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      Object pkValue = row.get(pk);\n      if (pkValue == null) {\n        pk = findMatchingPkColumn(pk, row);\n        pkValue = row.get(pk);\n      }\n\n      deltaSet.put(pkValue.toString(), row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = epw.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      deletedSet.add(row);\n      \n      Object pkValue = row.get(pk);\n      if (pkValue == null) {\n        pk = findMatchingPkColumn(pk, row);\n        pkValue = row.get(pk);\n      }\n\n      // Remove deleted rows from the delta rows\n      String deletedRowPk = pkValue.toString();\n      if (deltaSet.containsKey(deletedRowPk)) {\n        deltaSet.remove(deletedRowPk);\n      }\n\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + epw.getEntity().getName() + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + epw.getEntity().getName() + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet.values());\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (epw.getEntity().getParentEntity() != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(epw.getEntity().getName(), row), epw.getEntity().getName(), epw, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(epw.getEntity().getName(), row), epw.getEntity().getName(), epw, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + epw.getEntity().getName());\n    if (epw.getEntity().isDocRoot())\n      deletedRows.addAll(deletedSet);\n\n    // Do not use entity.isDocRoot here because one of descendant entities may set rootEntity=\"true\"\n    return epw.getEntity().getParentEntity() == null ?\n        myModifiedPks : new HashSet<Map<String, Object>>(parentKeyList);\n  }\n\n","sourceOld":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Map<String, Map<String, Object>> deltaSet = new HashMap<String, Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    String pk = entity.getPk();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      Object pkValue = row.get(pk);\n      if (pkValue == null) {\n        pk = findMatchingPkColumn(pk, row);\n        pkValue = row.get(pk);\n      }\n\n      deltaSet.put(pkValue.toString(), row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      deletedSet.add(row);\n      \n      Object pkValue = row.get(pk);\n      if (pkValue == null) {\n        pk = findMatchingPkColumn(pk, row);\n        pkValue = row.get(pk);\n      }\n\n      // Remove deleted rows from the delta rows\n      String deletedRowPk = pkValue.toString();\n      if (deltaSet.containsKey(deletedRowPk)) {\n        deltaSet.remove(deletedRowPk);\n      }\n\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet.values());\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    // Do not use entity.isDocRoot here because one of descendant entities may set rootEntity=\"true\"\n    return entity.parentEntity == null ?\n        myModifiedPks : new HashSet<Map<String, Object>>(parentKeyList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"4ebea96bbe279c4a8dc0cd5cd1f987cc9b33436c":["c26f00b574427b55127e869b935845554afde1fa"],"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c26f00b574427b55127e869b935845554afde1fa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","5128b7b3b73fedff05fdc5ea2e6be53c1020bb91"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["4ebea96bbe279c4a8dc0cd5cd1f987cc9b33436c"]},"commit2Childs":{"4ebea96bbe279c4a8dc0cd5cd1f987cc9b33436c":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":["c26f00b574427b55127e869b935845554afde1fa"],"c26f00b574427b55127e869b935845554afde1fa":["4ebea96bbe279c4a8dc0cd5cd1f987cc9b33436c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","c26f00b574427b55127e869b935845554afde1fa"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}