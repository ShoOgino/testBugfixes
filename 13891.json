{"path":"lucene/codecs/src/java/org/apache/lucene/codecs/uniformsplit/UniformSplitTermsReader#UniformSplitTermsReader(PostingsReaderBase,SegmentReadState,BlockDecoder,boolean,FieldMetadata.Serializer,String,int,int,String,String).mjava","commits":[{"id":"97ee06ea0335fd2077527d81c4c993c86e06f0da","date":1583768142,"type":1,"author":"Bruno Roustant","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/uniformsplit/UniformSplitTermsReader#UniformSplitTermsReader(PostingsReaderBase,SegmentReadState,BlockDecoder,boolean,FieldMetadata.Serializer,String,int,int,String,String).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/uniformsplit/UniformSplitTermsReader#UniformSplitTermsReader(PostingsReaderBase,SegmentReadState,BlockDecoder,FieldMetadata.Serializer,String,int,int,String,String).mjava","sourceNew":"  /**\n   * @see #UniformSplitTermsReader(PostingsReaderBase, SegmentReadState, BlockDecoder, boolean)\n   */\n  protected UniformSplitTermsReader(PostingsReaderBase postingsReader, SegmentReadState state, BlockDecoder blockDecoder,\n                                    boolean dictionaryOnHeap, FieldMetadata.Serializer fieldMetadataReader,\n                                    String codecName, int versionStart, int versionCurrent,\n                                    String termsBlocksExtension, String dictionaryExtension) throws IOException {\n     IndexInput dictionaryInput = null;\n     IndexInput blockInput = null;\n     boolean success = false;\n     try {\n       this.postingsReader = postingsReader;\n       String segmentName = state.segmentInfo.name;\n       String termsName = IndexFileNames.segmentFileName(segmentName, state.segmentSuffix, termsBlocksExtension);\n       blockInput = state.directory.openInput(termsName, state.context);\n\n       int version = CodecUtil.checkIndexHeader(blockInput, codecName, versionStart,\n           versionCurrent, state.segmentInfo.getId(), state.segmentSuffix);\n       String indexName = IndexFileNames.segmentFileName(segmentName, state.segmentSuffix, dictionaryExtension);\n       dictionaryInput = state.directory.openInput(indexName, state.context);\n\n       CodecUtil.checkIndexHeader(dictionaryInput, codecName, version, version, state.segmentInfo.getId(), state.segmentSuffix);\n       CodecUtil.checksumEntireFile(dictionaryInput);\n\n       postingsReader.init(blockInput, state);\n       CodecUtil.retrieveChecksum(blockInput);\n\n       seekFieldsMetadata(blockInput);\n       Collection<FieldMetadata> fieldMetadataCollection = parseFieldsMetadata(blockInput, state.fieldInfos, fieldMetadataReader, state.segmentInfo.maxDoc());\n\n       fieldToTermsMap = new HashMap<>();\n       this.blockInput = blockInput;\n       this.dictionaryInput = dictionaryInput;\n\n       fillFieldMap(postingsReader, state, blockDecoder, dictionaryOnHeap, dictionaryInput, blockInput, fieldMetadataCollection, state.fieldInfos);\n\n       List<String> fieldNames = new ArrayList<>(fieldToTermsMap.keySet());\n       Collections.sort(fieldNames);\n       sortedFieldNames = Collections.unmodifiableList(fieldNames);\n\n       success = true;\n     } finally {\n       if (!success) {\n         IOUtils.closeWhileHandlingException(blockInput, dictionaryInput);\n       }\n     }\n   }\n\n","sourceOld":"  /**\n   * @param blockDecoder Optional block decoder, may be null if none.\n   *                     It can be used for decompression or decryption.\n   */\n  protected UniformSplitTermsReader(PostingsReaderBase postingsReader, SegmentReadState state,\n                                    BlockDecoder blockDecoder, FieldMetadata.Serializer fieldMetadataReader,\n                                     String codecName, int versionStart, int versionCurrent,\n                                    String termsBlocksExtension, String dictionaryExtension) throws IOException {\n     IndexInput dictionaryInput = null;\n     IndexInput blockInput = null;\n     boolean success = false;\n     try {\n       this.postingsReader = postingsReader;\n       String segmentName = state.segmentInfo.name;\n       String termsName = IndexFileNames.segmentFileName(segmentName, state.segmentSuffix, termsBlocksExtension);\n       blockInput = state.directory.openInput(termsName, state.context);\n\n       int version = CodecUtil.checkIndexHeader(blockInput, codecName, versionStart,\n           versionCurrent, state.segmentInfo.getId(), state.segmentSuffix);\n       String indexName = IndexFileNames.segmentFileName(segmentName, state.segmentSuffix, dictionaryExtension);\n       dictionaryInput = state.directory.openInput(indexName, state.context);\n\n       CodecUtil.checkIndexHeader(dictionaryInput, codecName, version, version, state.segmentInfo.getId(), state.segmentSuffix);\n       CodecUtil.checksumEntireFile(dictionaryInput);\n\n       postingsReader.init(blockInput, state);\n       CodecUtil.retrieveChecksum(blockInput);\n\n       seekFieldsMetadata(blockInput);\n       Collection<FieldMetadata> fieldMetadataCollection = parseFieldsMetadata(blockInput, state.fieldInfos, fieldMetadataReader, state.segmentInfo.maxDoc());\n\n       fieldToTermsMap = new HashMap<>();\n       this.blockInput = blockInput;\n       this.dictionaryInput = dictionaryInput;\n\n       fillFieldMap(postingsReader, blockDecoder, dictionaryInput, blockInput, fieldMetadataCollection, state.fieldInfos);\n\n       List<String> fieldNames = new ArrayList<>(fieldToTermsMap.keySet());\n       Collections.sort(fieldNames);\n       sortedFieldNames = Collections.unmodifiableList(fieldNames);\n\n       success = true;\n     } finally {\n       if (!success) {\n         IOUtils.closeWhileHandlingException(blockInput, dictionaryInput);\n       }\n     }\n   }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5bf19e0585c61e03c645ac979e97c192529637d6","date":1591892388,"type":3,"author":"Bruno Roustant","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/uniformsplit/UniformSplitTermsReader#UniformSplitTermsReader(PostingsReaderBase,SegmentReadState,BlockDecoder,boolean,FieldMetadata.Serializer,String,int,int,String,String).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/uniformsplit/UniformSplitTermsReader#UniformSplitTermsReader(PostingsReaderBase,SegmentReadState,BlockDecoder,boolean,FieldMetadata.Serializer,String,int,int,String,String).mjava","sourceNew":"  /**\n   * @see #UniformSplitTermsReader(PostingsReaderBase, SegmentReadState, BlockDecoder, boolean)\n   */\n  protected UniformSplitTermsReader(PostingsReaderBase postingsReader, SegmentReadState state, BlockDecoder blockDecoder,\n                                    boolean dictionaryOnHeap, FieldMetadata.Serializer fieldMetadataReader,\n                                    String codecName, int versionStart, int versionCurrent,\n                                    String termsBlocksExtension, String dictionaryExtension) throws IOException {\n     IndexInput dictionaryInput = null;\n     IndexInput blockInput = null;\n     boolean success = false;\n     try {\n       this.postingsReader = postingsReader;\n       String segmentName = state.segmentInfo.name;\n       String termsName = IndexFileNames.segmentFileName(segmentName, state.segmentSuffix, termsBlocksExtension);\n       blockInput = state.directory.openInput(termsName, state.context);\n\n       version = CodecUtil.checkIndexHeader(blockInput, codecName, versionStart,\n           versionCurrent, state.segmentInfo.getId(), state.segmentSuffix);\n       String indexName = IndexFileNames.segmentFileName(segmentName, state.segmentSuffix, dictionaryExtension);\n       dictionaryInput = state.directory.openInput(indexName, state.context);\n\n       CodecUtil.checkIndexHeader(dictionaryInput, codecName, version, version, state.segmentInfo.getId(), state.segmentSuffix);\n       CodecUtil.checksumEntireFile(dictionaryInput);\n\n       postingsReader.init(blockInput, state);\n       CodecUtil.retrieveChecksum(blockInput);\n\n       seekFieldsMetadata(blockInput);\n       Collection<FieldMetadata> fieldMetadataCollection =\n           readFieldsMetadata(blockInput, blockDecoder, state.fieldInfos, fieldMetadataReader, state.segmentInfo.maxDoc());\n\n       fieldToTermsMap = new HashMap<>();\n       this.blockInput = blockInput;\n       this.dictionaryInput = dictionaryInput;\n\n       fillFieldMap(postingsReader, state, blockDecoder, dictionaryOnHeap, dictionaryInput, blockInput, fieldMetadataCollection, state.fieldInfos);\n\n       List<String> fieldNames = new ArrayList<>(fieldToTermsMap.keySet());\n       Collections.sort(fieldNames);\n       sortedFieldNames = Collections.unmodifiableList(fieldNames);\n\n       success = true;\n     } finally {\n       if (!success) {\n         IOUtils.closeWhileHandlingException(blockInput, dictionaryInput);\n       }\n     }\n   }\n\n","sourceOld":"  /**\n   * @see #UniformSplitTermsReader(PostingsReaderBase, SegmentReadState, BlockDecoder, boolean)\n   */\n  protected UniformSplitTermsReader(PostingsReaderBase postingsReader, SegmentReadState state, BlockDecoder blockDecoder,\n                                    boolean dictionaryOnHeap, FieldMetadata.Serializer fieldMetadataReader,\n                                    String codecName, int versionStart, int versionCurrent,\n                                    String termsBlocksExtension, String dictionaryExtension) throws IOException {\n     IndexInput dictionaryInput = null;\n     IndexInput blockInput = null;\n     boolean success = false;\n     try {\n       this.postingsReader = postingsReader;\n       String segmentName = state.segmentInfo.name;\n       String termsName = IndexFileNames.segmentFileName(segmentName, state.segmentSuffix, termsBlocksExtension);\n       blockInput = state.directory.openInput(termsName, state.context);\n\n       int version = CodecUtil.checkIndexHeader(blockInput, codecName, versionStart,\n           versionCurrent, state.segmentInfo.getId(), state.segmentSuffix);\n       String indexName = IndexFileNames.segmentFileName(segmentName, state.segmentSuffix, dictionaryExtension);\n       dictionaryInput = state.directory.openInput(indexName, state.context);\n\n       CodecUtil.checkIndexHeader(dictionaryInput, codecName, version, version, state.segmentInfo.getId(), state.segmentSuffix);\n       CodecUtil.checksumEntireFile(dictionaryInput);\n\n       postingsReader.init(blockInput, state);\n       CodecUtil.retrieveChecksum(blockInput);\n\n       seekFieldsMetadata(blockInput);\n       Collection<FieldMetadata> fieldMetadataCollection = parseFieldsMetadata(blockInput, state.fieldInfos, fieldMetadataReader, state.segmentInfo.maxDoc());\n\n       fieldToTermsMap = new HashMap<>();\n       this.blockInput = blockInput;\n       this.dictionaryInput = dictionaryInput;\n\n       fillFieldMap(postingsReader, state, blockDecoder, dictionaryOnHeap, dictionaryInput, blockInput, fieldMetadataCollection, state.fieldInfos);\n\n       List<String> fieldNames = new ArrayList<>(fieldToTermsMap.keySet());\n       Collections.sort(fieldNames);\n       sortedFieldNames = Collections.unmodifiableList(fieldNames);\n\n       success = true;\n     } finally {\n       if (!success) {\n         IOUtils.closeWhileHandlingException(blockInput, dictionaryInput);\n       }\n     }\n   }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"97ee06ea0335fd2077527d81c4c993c86e06f0da":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"5bf19e0585c61e03c645ac979e97c192529637d6":["97ee06ea0335fd2077527d81c4c993c86e06f0da"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["5bf19e0585c61e03c645ac979e97c192529637d6"]},"commit2Childs":{"97ee06ea0335fd2077527d81c4c993c86e06f0da":["5bf19e0585c61e03c645ac979e97c192529637d6"],"5bf19e0585c61e03c645ac979e97c192529637d6":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["97ee06ea0335fd2077527d81c4c993c86e06f0da"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}