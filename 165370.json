{"path":"lucene/src/test/org/apache/lucene/codecs/lucene3x/TestSurrogates#testSurrogatesOrder().mjava","commits":[{"id":"a0ae5e3ed1232483b7b8a014f175a5fe43595982","date":1324062192,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/codecs/lucene3x/TestSurrogates#testSurrogatesOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/lucene3x/TestSurrogates#testSurrogatesOrder().mjava","sourceNew":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer(random)).setCodec(new PreFlexRWCodec()));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = atLeast(1000);\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, StringField.TYPE_UNSTORED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer(random)).setCodec(new PreFlexRWCodec()));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = atLeast(1000);\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, StringField.TYPE_UNSTORED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8be580b58bcc650d428f3f22de81cadcf51d650a","date":1325279655,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/codecs/lucene3x/TestSurrogates#testSurrogatesOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/codecs/lucene3x/TestSurrogates#testSurrogatesOrder().mjava","sourceNew":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer(random)).setCodec(new PreFlexRWCodec()));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = atLeast(200);\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, StringField.TYPE_UNSTORED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer(random)).setCodec(new PreFlexRWCodec()));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = atLeast(1000);\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, StringField.TYPE_UNSTORED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene3x/TestSurrogates#testSurrogatesOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/codecs/lucene3x/TestSurrogates#testSurrogatesOrder().mjava","sourceNew":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer(random)).setCodec(new PreFlexRWCodec()));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = atLeast(200);\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, StringField.TYPE_UNSTORED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer(random)).setCodec(new PreFlexRWCodec()));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = atLeast(200);\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, StringField.TYPE_UNSTORED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["8be580b58bcc650d428f3f22de81cadcf51d650a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8be580b58bcc650d428f3f22de81cadcf51d650a":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"],"8be580b58bcc650d428f3f22de81cadcf51d650a":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["8be580b58bcc650d428f3f22de81cadcf51d650a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}