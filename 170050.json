{"path":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testDeleteStream().mjava","commits":[{"id":"140a95988ddfbe87c2376f5fed6acae475ea11fc","date":1580924964,"type":0,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testDeleteStream().mjava","pathOld":"/dev/null","sourceNew":"  public void testDeleteStream() throws Exception {\n    final String url = cluster.getJettySolrRunners().get(0).getBaseUrl().toString() + \"/\" + COLLECTIONORALIAS;\n    final SolrClient client = cluster.getSolrClient();\n    \n    { final UpdateRequest req = new UpdateRequest();\n      for (int i = 0; i < 20; i++) {\n        req.add(id, \"doc_\"+i, \"deletable_s\", \"yup\");\n      }\n      assertEquals(0, req.commit(cluster.getSolrClient(), COLLECTIONORALIAS).getStatus());\n    }\n\n    // fetch the _version_ param assigned each doc to test optimistic concurrency later...\n    final Map<String,Long> versions = new HashMap<>();  \n    { final QueryResponse allDocs = client.query(COLLECTIONORALIAS, params(\"q\",\"deletable_s:yup\",\n                                                                           \"rows\",\"100\"));\n      assertEquals(20L, allDocs.getResults().getNumFound());\n      for (SolrDocument doc : allDocs.getResults()) {\n        versions.put(doc.getFirstValue(\"id\").toString(), (Long) doc.getFirstValue(\"_version_\"));\n      }\n    }\n                 \n    { // trivially delete 1 doc\n      final String expr\n        = \"commit(\"+COLLECTIONORALIAS+\",waitSearcher=true,     \"\n        + \"       delete(\"+COLLECTIONORALIAS+\",batchSize=10,   \"\n        + \"              tuple(id=doc_2)))                     \"\n        ;\n      final SolrStream stream = new SolrStream(url, params(\"qt\", \"/stream\", \"expr\", expr));\n      \n      final List<Tuple> tuples = getTuples(stream);\n      assertEquals(1, tuples.size());\n      assertEquals(1L, tuples.get(0).get(\"totalIndexed\"));\n      \n      assertEquals(20L - 1L,\n                   client.query(COLLECTIONORALIAS,\n                                params(\"q\",\"deletable_s:yup\")).getResults().getNumFound());\n    }\n\n    { // delete 5 docs, spread across 3 batches (2 + 2 + 1)\n      final String expr\n        = \"commit(\"+COLLECTIONORALIAS+\",waitSearcher=true,          \"\n        + \"       delete(\"+COLLECTIONORALIAS+\",batchSize=2,list(    \" // NOTE: batch size\n        + \"               tuple(id=doc_3),                          \"\n        + \"               tuple(id=doc_11),                         \"\n        + \"               tuple(id=doc_7),                          \"\n        + \"               tuple(id=doc_17),                         \"\n        + \"               tuple(id=doc_15),                         \"\n        + \"              ) ) )                                      \"\n        ;\n      final SolrStream stream = new SolrStream(url, params(\"qt\", \"/stream\", \"expr\", expr));\n      \n      final List<Tuple> tuples = getTuples(stream);\n      assertEquals(3, tuples.size());\n      assertEquals(2L, tuples.get(0).get(\"totalIndexed\"));\n      assertEquals(4L, tuples.get(1).get(\"totalIndexed\"));\n      assertEquals(5L, tuples.get(2).get(\"totalIndexed\"));\n      \n      assertEquals(20L - 1L - 5L,\n                   client.query(COLLECTIONORALIAS,\n                                params(\"q\",\"deletable_s:yup\")).getResults().getNumFound());\n    }\n\n    { // attempt to delete 2 docs, one with correct version, one with \"stale\" version that should fail\n      // but config uses TolerantUpdateProcessorFactory so batch should still be ok...\n      //\n      // It would be nice it there was a more explicit, targetted, option for update() and delete() to\n      // ensure that even if one \"batch\" fails it continues with other batches.\n      // See TODO in UpdateStream\n\n      final long v13_ok = versions.get(\"doc_13\").longValue();\n      final long v10_bad = versions.get(\"doc_10\").longValue() - 42L;\n      final String expr\n        = \"commit(\"+COLLECTIONORALIAS+\",waitSearcher=true,            \"\n        + \"       delete(\"+COLLECTIONORALIAS+\",batchSize=10,list(     \"\n        + \"               tuple(id=doc_10,_version_=\"+v10_bad+\"),     \"\n        + \"               tuple(id=doc_13,_version_=\"+v13_ok+\"),      \"\n        + \"              ) ) )                                        \"\n        ;\n      final SolrStream stream = new SolrStream(url, params(\"qt\", \"/stream\", \"expr\", expr));\n      \n      final List<Tuple> tuples = getTuples(stream);\n      assertEquals(1, tuples.size());\n      assertEquals(2L, tuples.get(0).get(\"totalIndexed\"));\n\n      // should still be in the index due to version conflict...\n      assertEquals(1L, client.query(COLLECTIONORALIAS,\n                                    params(\"q\",\"id:doc_10\")).getResults().getNumFound());\n      // should not be in the index due to successful delete...\n      assertEquals(0L, client.query(COLLECTIONORALIAS,\n                                    params(\"q\",\"id:doc_13\")).getResults().getNumFound());\n      \n      assertEquals(20L - 1L - 5L - 1L,\n                   client.query(COLLECTIONORALIAS,\n                                params(\"q\",\"deletable_s:yup\")).getResults().getNumFound());\n    }\n\n    { // by using pruneVersionField=true we should be able to ignore optimistic concurrency constraints,\n      // and delete docs even if the stream we are wrapping returns _version_ values that are no\n      // longer valid...\n      final long v10_bad = versions.get(\"doc_10\").longValue() - 42L;\n      final String expr\n        = \"commit(\"+COLLECTIONORALIAS+\",waitSearcher=true,            \"\n        + \"       delete(\"+COLLECTIONORALIAS+\",batchSize=10,          \"\n        + \"              pruneVersionField=true, list(                \"\n        + \"               tuple(id=doc_10,_version_=\"+v10_bad+\"),     \"\n        + \"              ) ) )                                        \"\n        ;\n      final SolrStream stream = new SolrStream(url, params(\"qt\", \"/stream\", \"expr\", expr));\n      \n      final List<Tuple> tuples = getTuples(stream);\n      assertEquals(1, tuples.size());\n      assertEquals(1L, tuples.get(0).get(\"totalIndexed\"));\n\n      // _version_should have been ignored and doc deleted anyway...\n      assertEquals(0L, client.query(COLLECTIONORALIAS,\n                                    params(\"q\",\"id:doc_10\")).getResults().getNumFound());\n      \n      assertEquals(20L - 1L - 5L - 1L - 1L,\n                   client.query(COLLECTIONORALIAS,\n                                params(\"q\",\"deletable_s:yup\")).getResults().getNumFound());\n    }\n\n    { // now test a \"realistic\" DBQ type situation, confirm all (remaining) matching docs deleted...\n      final String expr\n        = \"commit(\"+COLLECTIONORALIAS+\",waitSearcher=true,                \"\n        + \"       delete(\"+COLLECTIONORALIAS+\",batchSize=99,              \"\n        + \"              search(\"+COLLECTIONORALIAS+\",qt=\\\"/export\\\",     \"\n        + \"                     q=\\\"deletable_s:yup\\\",                    \"\n        + \"                     sort=\\\"id asc\\\",fl=\\\"id,_version_\\\"       \"\n        + \"              ) ) )                                            \"\n        ;\n      final SolrStream stream = new SolrStream(url, params(\"qt\", \"/stream\", \"expr\", expr));\n      \n      final List<Tuple> tuples = getTuples(stream);\n      assertEquals(1, tuples.size());\n      assertEquals(20L - 1L - 5L - 1L - 1L,\n                   tuples.get(0).get(\"totalIndexed\"));\n\n      // shouldn't be anything left...\n      assertEquals(0L,\n                   client.query(COLLECTIONORALIAS,\n                                params(\"q\",\"deletable_s:yup\")).getResults().getNumFound());\n      \n    }\n    \n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"140a95988ddfbe87c2376f5fed6acae475ea11fc":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["140a95988ddfbe87c2376f5fed6acae475ea11fc"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["140a95988ddfbe87c2376f5fed6acae475ea11fc"],"140a95988ddfbe87c2376f5fed6acae475ea11fc":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}