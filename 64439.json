{"path":"lucene/core/src/java/org/apache/lucene/codecs/PushFieldsConsumer#write(Fields).mjava","commits":[{"id":"519bac5f6a2dc1779d2fe8e51d9e1762ec94b4a5","date":1379624229,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/PushFieldsConsumer#write(Fields).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public final void write(Fields fields) throws IOException {\n\n    boolean success = false;\n    try {\n      for(String field : fields) { // for all fields\n        FieldInfo fieldInfo = writeState.fieldInfos.fieldInfo(field);\n        IndexOptions indexOptions = fieldInfo.getIndexOptions();\n        TermsConsumer termsConsumer = addField(fieldInfo);\n\n        Terms terms = fields.terms(field);\n        if (terms != null) {\n\n          // Holds all docs that have this field:\n          FixedBitSet visitedDocs = new FixedBitSet(writeState.segmentInfo.getDocCount());\n\n          boolean hasFreq = indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS) >= 0;\n          boolean hasPositions = indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n          assert hasPositions == terms.hasPositions();\n          boolean hasOffsets = indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n          assert hasOffsets == terms.hasOffsets();\n          boolean hasPayloads = fieldInfo.hasPayloads();\n\n          long sumTotalTermFreq = 0;\n          long sumDocFreq = 0;\n\n          int flags = 0;\n          if (hasPositions == false) {\n            if (hasFreq) {\n              flags = flags | DocsEnum.FLAG_FREQS;\n            }\n          } else {\n            if (hasPayloads) {\n              flags = flags | DocsAndPositionsEnum.FLAG_PAYLOADS;\n            }\n            if (hasOffsets) {\n              flags = flags | DocsAndPositionsEnum.FLAG_OFFSETS;\n            }\n          }\n\n          DocsEnum docsEnum = null;\n          DocsAndPositionsEnum docsAndPositionsEnum = null;\n          TermsEnum termsEnum = terms.iterator(null);\n\n          while (true) { // for all terms in this field\n            BytesRef term = termsEnum.next();\n            if (term == null) {\n              break;\n            }\n            if (hasPositions) {\n              docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum, flags);\n              docsEnum = docsAndPositionsEnum;\n            } else {\n              docsEnum = termsEnum.docs(null, docsEnum, flags);\n              docsAndPositionsEnum = null;\n            }\n            assert docsEnum != null;\n\n            PostingsConsumer postingsConsumer = termsConsumer.startTerm(term);\n\n            // How many documents have this term:\n            int docFreq = 0;\n\n            // How many times this term occurs:\n            long totalTermFreq = 0;\n\n            while(true) { // for all docs in this field+term\n              int doc = docsEnum.nextDoc();\n              if (doc == DocsEnum.NO_MORE_DOCS) {\n                break;\n              }\n              docFreq++;\n              visitedDocs.set(doc);\n              if (hasFreq) {\n                int freq = docsEnum.freq();\n                postingsConsumer.startDoc(doc, freq);\n                totalTermFreq += freq;\n\n                if (hasPositions) {\n                  for(int i=0;i<freq;i++) { // for all positions in this field+term + doc\n                    int pos = docsAndPositionsEnum.nextPosition();\n                    BytesRef payload = docsAndPositionsEnum.getPayload();\n                    if (hasOffsets) {\n                      postingsConsumer.addPosition(pos, payload, docsAndPositionsEnum.startOffset(), docsAndPositionsEnum.endOffset());\n                    } else {\n                      postingsConsumer.addPosition(pos, payload, -1, -1);\n                    }\n                  }\n                }\n              } else {\n                postingsConsumer.startDoc(doc, -1);\n              }\n              postingsConsumer.finishDoc();\n            }\n\n            if (docFreq > 0) {\n              termsConsumer.finishTerm(term, new TermStats(docFreq, hasFreq ? totalTermFreq : -1));\n              sumTotalTermFreq += totalTermFreq;\n              sumDocFreq += docFreq;\n            }\n          }\n\n          termsConsumer.finish(hasFreq ? sumTotalTermFreq : -1, sumDocFreq, visitedDocs.cardinality());\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(this);\n      } else {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fa80a35d7c4b2b1e83082b275e3e8328ab93db52","date":1381766157,"type":4,"author":"Michael McCandless","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/PushFieldsConsumer#write(Fields).mjava","sourceNew":null,"sourceOld":"  @Override\n  public final void write(Fields fields) throws IOException {\n\n    boolean success = false;\n    try {\n      for(String field : fields) { // for all fields\n        FieldInfo fieldInfo = writeState.fieldInfos.fieldInfo(field);\n        IndexOptions indexOptions = fieldInfo.getIndexOptions();\n        TermsConsumer termsConsumer = addField(fieldInfo);\n\n        Terms terms = fields.terms(field);\n        if (terms != null) {\n\n          // Holds all docs that have this field:\n          FixedBitSet visitedDocs = new FixedBitSet(writeState.segmentInfo.getDocCount());\n\n          boolean hasFreq = indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS) >= 0;\n          boolean hasPositions = indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n          assert hasPositions == terms.hasPositions();\n          boolean hasOffsets = indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n          assert hasOffsets == terms.hasOffsets();\n          boolean hasPayloads = fieldInfo.hasPayloads();\n\n          long sumTotalTermFreq = 0;\n          long sumDocFreq = 0;\n\n          int flags = 0;\n          if (hasPositions == false) {\n            if (hasFreq) {\n              flags = flags | DocsEnum.FLAG_FREQS;\n            }\n          } else {\n            if (hasPayloads) {\n              flags = flags | DocsAndPositionsEnum.FLAG_PAYLOADS;\n            }\n            if (hasOffsets) {\n              flags = flags | DocsAndPositionsEnum.FLAG_OFFSETS;\n            }\n          }\n\n          DocsEnum docsEnum = null;\n          DocsAndPositionsEnum docsAndPositionsEnum = null;\n          TermsEnum termsEnum = terms.iterator(null);\n\n          while (true) { // for all terms in this field\n            BytesRef term = termsEnum.next();\n            if (term == null) {\n              break;\n            }\n            if (hasPositions) {\n              docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum, flags);\n              docsEnum = docsAndPositionsEnum;\n            } else {\n              docsEnum = termsEnum.docs(null, docsEnum, flags);\n              docsAndPositionsEnum = null;\n            }\n            assert docsEnum != null;\n\n            PostingsConsumer postingsConsumer = termsConsumer.startTerm(term);\n\n            // How many documents have this term:\n            int docFreq = 0;\n\n            // How many times this term occurs:\n            long totalTermFreq = 0;\n\n            while(true) { // for all docs in this field+term\n              int doc = docsEnum.nextDoc();\n              if (doc == DocsEnum.NO_MORE_DOCS) {\n                break;\n              }\n              docFreq++;\n              visitedDocs.set(doc);\n              if (hasFreq) {\n                int freq = docsEnum.freq();\n                postingsConsumer.startDoc(doc, freq);\n                totalTermFreq += freq;\n\n                if (hasPositions) {\n                  for(int i=0;i<freq;i++) { // for all positions in this field+term + doc\n                    int pos = docsAndPositionsEnum.nextPosition();\n                    BytesRef payload = docsAndPositionsEnum.getPayload();\n                    if (hasOffsets) {\n                      postingsConsumer.addPosition(pos, payload, docsAndPositionsEnum.startOffset(), docsAndPositionsEnum.endOffset());\n                    } else {\n                      postingsConsumer.addPosition(pos, payload, -1, -1);\n                    }\n                  }\n                }\n              } else {\n                postingsConsumer.startDoc(doc, -1);\n              }\n              postingsConsumer.finishDoc();\n            }\n\n            if (docFreq > 0) {\n              termsConsumer.finishTerm(term, new TermStats(docFreq, hasFreq ? totalTermFreq : -1));\n              sumTotalTermFreq += totalTermFreq;\n              sumDocFreq += docFreq;\n            }\n          }\n\n          termsConsumer.finish(hasFreq ? sumTotalTermFreq : -1, sumDocFreq, visitedDocs.cardinality());\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(this);\n      } else {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"519bac5f6a2dc1779d2fe8e51d9e1762ec94b4a5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"fa80a35d7c4b2b1e83082b275e3e8328ab93db52":["519bac5f6a2dc1779d2fe8e51d9e1762ec94b4a5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["fa80a35d7c4b2b1e83082b275e3e8328ab93db52"]},"commit2Childs":{"519bac5f6a2dc1779d2fe8e51d9e1762ec94b4a5":["fa80a35d7c4b2b1e83082b275e3e8328ab93db52"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["519bac5f6a2dc1779d2fe8e51d9e1762ec94b4a5"],"fa80a35d7c4b2b1e83082b275e3e8328ab93db52":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}