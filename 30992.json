{"path":"lucene/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","commits":[{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"/dev/null","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random, 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      w.addDocument(new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newField(\"id\", \"\"+finalDocCount, StringField.TYPE_STORED);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        });\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n        final boolean numeric = fieldID == 9;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else if (numeric) {\n            assertTrue(f instanceof NumericField);\n            final NumericField nf = (NumericField) f;\n            assertEquals(NumericField.DataType.INT, nf.numericDataType());\n            assertEquals(counter, nf.numericValue().intValue());\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          final TermFreqVector tfv = r.getTermFreqVector(docID, name);\n          if (tv) {\n            assertNotNull(tfv);\n            assertTrue(tfv instanceof TermPositionVector);\n            final TermPositionVector tpv = (TermPositionVector) tfv;\n            final BytesRef[] terms = tpv.getTerms();\n            assertEquals(2, terms.length);\n            assertEquals(new BytesRef(\"\"+counter), terms[0]);\n            assertEquals(new BytesRef(\"text\"), terms[1]);\n\n            final int[] freqs = tpv.getTermFrequencies();\n            assertEquals(2, freqs.length);\n            assertEquals(1, freqs[0]);\n            assertEquals(1, freqs[1]);\n\n            int[] positions = tpv.getTermPositions(0);\n            assertEquals(1, positions.length);\n            assertEquals(1, positions[0]);\n\n            positions = tpv.getTermPositions(1);\n            assertEquals(1, positions.length);\n            assertEquals(0, positions[0]);\n\n            // TODO: offsets\n            \n          } else {\n            assertNull(tfv);\n          }\n\n          if (numeric) {\n            NumericRangeQuery nrq = NumericRangeQuery.newIntRange(name, counter, counter, true, true);\n            final TopDocs hits2 = s.search(nrq, 1);\n            assertEquals(1, hits2.totalHits);\n            assertEquals(docID, hits2.scoreDocs[0].doc);\n          } else {\n            BooleanQuery bq = new BooleanQuery();\n            bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n            bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n            final TopDocs hits2 = s.search(bq, 1);\n            assertEquals(1, hits2.totalHits);\n            assertEquals(docID, hits2.scoreDocs[0].doc);\n\n            bq = new BooleanQuery();\n            bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n            bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n            final TopDocs hits3 = s.search(bq, 1);\n            assertEquals(1, hits3.totalHits);\n            assertEquals(docID, hits3.scoreDocs[0].doc);\n          }\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["fa0f44f887719e97183771e977cfc4bfb485b766","04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3cc749c053615f5871f3b95715fe292f34e70a53","date":1321470575,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random, 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      w.addDocument(new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newField(\"id\", \"\"+finalDocCount, StringField.TYPE_STORED);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        });\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n        final boolean numeric = fieldID == 9;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else if (numeric) {\n            assertTrue(f instanceof NumericField);\n            final NumericField nf = (NumericField) f;\n            assertEquals(NumericField.DataType.INT, nf.numericDataType());\n            assertEquals(counter, nf.numericValue().intValue());\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null);\n            assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n            assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          if (numeric) {\n            NumericRangeQuery nrq = NumericRangeQuery.newIntRange(name, counter, counter, true, true);\n            final TopDocs hits2 = s.search(nrq, 1);\n            assertEquals(1, hits2.totalHits);\n            assertEquals(docID, hits2.scoreDocs[0].doc);\n          } else {\n            BooleanQuery bq = new BooleanQuery();\n            bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n            bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n            final TopDocs hits2 = s.search(bq, 1);\n            assertEquals(1, hits2.totalHits);\n            assertEquals(docID, hits2.scoreDocs[0].doc);\n\n            bq = new BooleanQuery();\n            bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n            bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n            final TopDocs hits3 = s.search(bq, 1);\n            assertEquals(1, hits3.totalHits);\n            assertEquals(docID, hits3.scoreDocs[0].doc);\n          }\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random, 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      w.addDocument(new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newField(\"id\", \"\"+finalDocCount, StringField.TYPE_STORED);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        });\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n        final boolean numeric = fieldID == 9;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else if (numeric) {\n            assertTrue(f instanceof NumericField);\n            final NumericField nf = (NumericField) f;\n            assertEquals(NumericField.DataType.INT, nf.numericDataType());\n            assertEquals(counter, nf.numericValue().intValue());\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          final TermFreqVector tfv = r.getTermFreqVector(docID, name);\n          if (tv) {\n            assertNotNull(tfv);\n            assertTrue(tfv instanceof TermPositionVector);\n            final TermPositionVector tpv = (TermPositionVector) tfv;\n            final BytesRef[] terms = tpv.getTerms();\n            assertEquals(2, terms.length);\n            assertEquals(new BytesRef(\"\"+counter), terms[0]);\n            assertEquals(new BytesRef(\"text\"), terms[1]);\n\n            final int[] freqs = tpv.getTermFrequencies();\n            assertEquals(2, freqs.length);\n            assertEquals(1, freqs[0]);\n            assertEquals(1, freqs[1]);\n\n            int[] positions = tpv.getTermPositions(0);\n            assertEquals(1, positions.length);\n            assertEquals(1, positions[0]);\n\n            positions = tpv.getTermPositions(1);\n            assertEquals(1, positions.length);\n            assertEquals(0, positions[0]);\n\n            // TODO: offsets\n            \n          } else {\n            assertNull(tfv);\n          }\n\n          if (numeric) {\n            NumericRangeQuery nrq = NumericRangeQuery.newIntRange(name, counter, counter, true, true);\n            final TopDocs hits2 = s.search(nrq, 1);\n            assertEquals(1, hits2.totalHits);\n            assertEquals(docID, hits2.scoreDocs[0].doc);\n          } else {\n            BooleanQuery bq = new BooleanQuery();\n            bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n            bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n            final TopDocs hits2 = s.search(bq, 1);\n            assertEquals(1, hits2.totalHits);\n            assertEquals(docID, hits2.scoreDocs[0].doc);\n\n            bq = new BooleanQuery();\n            bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n            bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n            final TopDocs hits3 = s.search(bq, 1);\n            assertEquals(1, hits3.totalHits);\n            assertEquals(docID, hits3.scoreDocs[0].doc);\n          }\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fa0f44f887719e97183771e977cfc4bfb485b766","date":1326668713,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random, 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      w.addDocument(new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newField(\"id\", \"\"+finalDocCount, StringField.TYPE_STORED);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        });\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null);\n            assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n            assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random, 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      w.addDocument(new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newField(\"id\", \"\"+finalDocCount, StringField.TYPE_STORED);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        });\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n        final boolean numeric = fieldID == 9;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else if (numeric) {\n            assertTrue(f instanceof NumericField);\n            final NumericField nf = (NumericField) f;\n            assertEquals(NumericField.DataType.INT, nf.numericDataType());\n            assertEquals(counter, nf.numericValue().intValue());\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null);\n            assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n            assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          if (numeric) {\n            NumericRangeQuery nrq = NumericRangeQuery.newIntRange(name, counter, counter, true, true);\n            final TopDocs hits2 = s.search(nrq, 1);\n            assertEquals(1, hits2.totalHits);\n            assertEquals(docID, hits2.scoreDocs[0].doc);\n          } else {\n            BooleanQuery bq = new BooleanQuery();\n            bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n            bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n            final TopDocs hits2 = s.search(bq, 1);\n            assertEquals(1, hits2.totalHits);\n            assertEquals(docID, hits2.scoreDocs[0].doc);\n\n            bq = new BooleanQuery();\n            bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n            bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n            final TopDocs hits3 = s.search(bq, 1);\n            assertEquals(1, hits3.totalHits);\n            assertEquals(docID, hits3.scoreDocs[0].doc);\n          }\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"31f025ae60076ae95274433f3fe8e6ace2857a87","date":1326669465,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random, 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      w.addDocument(new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newField(\"id\", \"\"+finalDocCount, StringField.TYPE_STORED);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        });\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null, false);\n            assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n            assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random, 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      w.addDocument(new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newField(\"id\", \"\"+finalDocCount, StringField.TYPE_STORED);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        });\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null);\n            assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n            assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexableField#testArbitraryFields().mjava","sourceNew":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random, 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      w.addDocument(new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newField(\"id\", \"\"+finalDocCount, StringField.TYPE_STORED);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        });\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null, false);\n            assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n            assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Silly test showing how to index documents w/o using Lucene's core\n  // Document nor Field class\n  public void testArbitraryFields() throws Exception {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n\n    final int NUM_DOCS = atLeast(27);\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_DOCS + \" docs\");\n    }\n    final int[] fieldsPerDoc = new int[NUM_DOCS];\n    int baseCount = 0;\n\n    for(int docCount=0;docCount<NUM_DOCS;docCount++) {\n      final int fieldCount = _TestUtil.nextInt(random, 1, 17);\n      fieldsPerDoc[docCount] = fieldCount-1;\n\n      final int finalDocCount = docCount;\n      if (VERBOSE) {\n        System.out.println(\"TEST: \" + fieldCount + \" fields in doc \" + docCount);\n      }\n\n      final int finalBaseCount = baseCount;\n      baseCount += fieldCount-1;\n\n      w.addDocument(new Iterable<IndexableField>() {\n        @Override\n        public Iterator<IndexableField> iterator() {\n          return new Iterator<IndexableField>() {\n            int fieldUpto;\n\n            @Override\n            public boolean hasNext() {\n              return fieldUpto < fieldCount;\n            }\n\n            @Override\n            public IndexableField next() {\n              assert fieldUpto < fieldCount;\n              if (fieldUpto == 0) {\n                fieldUpto = 1;\n                return newField(\"id\", \"\"+finalDocCount, StringField.TYPE_STORED);\n              } else {\n                return new MyField(finalBaseCount + (fieldUpto++-1));\n              }\n            }\n\n            @Override\n            public void remove() {\n              throw new UnsupportedOperationException();\n            }\n          };\n        }\n        });\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final IndexSearcher s = new IndexSearcher(r);\n    int counter = 0;\n    for(int id=0;id<NUM_DOCS;id++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: verify doc id=\" + id + \" (\" + fieldsPerDoc[id] + \" fields) counter=\" + counter);\n      }\n      final TopDocs hits = s.search(new TermQuery(new Term(\"id\", \"\"+id)), 1);\n      assertEquals(1, hits.totalHits);\n      final int docID = hits.scoreDocs[0].doc;\n      final Document doc = s.doc(docID);\n      final int endCounter = counter + fieldsPerDoc[id];\n      while(counter < endCounter) {\n        final String name = \"f\" + counter;\n        final int fieldID = counter % 10;\n\n        final boolean stored = (counter&1) == 0 || fieldID == 3;\n        final boolean binary = fieldID == 3;\n        final boolean indexed = fieldID != 3;\n\n        final String stringValue;\n        if (fieldID != 3 && fieldID != 9) {\n          stringValue = \"text \" + counter;\n        } else {\n          stringValue = null;\n        }\n\n        // stored:\n        if (stored) {\n          IndexableField f = doc.getField(name);\n          assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n          if (binary) {\n            assertNotNull(\"doc \" + id + \" doesn't have field f\" + counter, f);\n            final BytesRef b = f.binaryValue();\n            assertNotNull(b);\n            assertEquals(10, b.length);\n            for(int idx=0;idx<10;idx++) {\n              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);\n            }\n          } else {\n            assert stringValue != null;\n            assertEquals(stringValue, f.stringValue());\n          }\n        }\n        \n        if (indexed) {\n          final boolean tv = counter % 2 == 1 && fieldID != 9;\n          if (tv) {\n            final Terms tfv = r.getTermVectors(docID).terms(name);\n            assertNotNull(tfv);\n            TermsEnum termsEnum = tfv.iterator(null);\n            assertEquals(new BytesRef(\"\"+counter), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null, false);\n            assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(1, dpEnum.nextPosition());\n\n            assertEquals(new BytesRef(\"text\"), termsEnum.next());\n            assertEquals(1, termsEnum.totalTermFreq());\n            dpEnum = termsEnum.docsAndPositions(null, dpEnum, false);\n            assertTrue(dpEnum.nextDoc() != DocsEnum.NO_MORE_DOCS);\n            assertEquals(1, dpEnum.freq());\n            assertEquals(0, dpEnum.nextPosition());\n\n            assertNull(termsEnum.next());\n\n            // TODO: offsets\n            \n          } else {\n            Fields vectors = r.getTermVectors(docID);\n            assertTrue(vectors == null || vectors.terms(name) == null);\n          }\n\n          BooleanQuery bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"text\")), BooleanClause.Occur.MUST);\n          final TopDocs hits2 = s.search(bq, 1);\n          assertEquals(1, hits2.totalHits);\n          assertEquals(docID, hits2.scoreDocs[0].doc);\n\n          bq = new BooleanQuery();\n          bq.add(new TermQuery(new Term(\"id\", \"\"+id)), BooleanClause.Occur.MUST);\n          bq.add(new TermQuery(new Term(name, \"\"+counter)), BooleanClause.Occur.MUST);\n          final TopDocs hits3 = s.search(bq, 1);\n          assertEquals(1, hits3.totalHits);\n          assertEquals(docID, hits3.scoreDocs[0].doc);\n        }\n\n        counter++;\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["31f025ae60076ae95274433f3fe8e6ace2857a87"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"fa0f44f887719e97183771e977cfc4bfb485b766":["3cc749c053615f5871f3b95715fe292f34e70a53"],"3cc749c053615f5871f3b95715fe292f34e70a53":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"31f025ae60076ae95274433f3fe8e6ace2857a87":["fa0f44f887719e97183771e977cfc4bfb485b766"]},"commit2Childs":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"fa0f44f887719e97183771e977cfc4bfb485b766":["31f025ae60076ae95274433f3fe8e6ace2857a87"],"3cc749c053615f5871f3b95715fe292f34e70a53":["fa0f44f887719e97183771e977cfc4bfb485b766"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["3cc749c053615f5871f3b95715fe292f34e70a53"],"31f025ae60076ae95274433f3fe8e6ace2857a87":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}