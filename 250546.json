{"path":"lucene/classification/src/java/org/apache/lucene/classification/BooleanPerceptronClassifier#BooleanPerceptronClassifier(LeafReader,String,String,Analyzer,Query,Integer,Double).mjava","commits":[{"id":"360ff513ddb24a30ffa2111a3ef0f91038803100","date":1430403123,"type":1,"author":"Tommaso Teofili","isMerge":false,"pathNew":"lucene/classification/src/java/org/apache/lucene/classification/BooleanPerceptronClassifier#BooleanPerceptronClassifier(LeafReader,String,String,Analyzer,Query,Integer,Double).mjava","pathOld":"lucene/classification/src/java/org/apache/lucene/classification/BooleanPerceptronClassifier#train(LeafReader,String,String,Analyzer,Query).mjava","sourceNew":"  public BooleanPerceptronClassifier(LeafReader leafReader, String textFieldName, String classFieldName, Analyzer analyzer,\n                                     Query query, Integer batchSize, Double threshold) throws IOException {\n    this.textTerms = MultiFields.getTerms(leafReader, textFieldName);\n\n    if (textTerms == null) {\n      throw new IOException(\"term vectors need to be available for field \" + textFieldName);\n    }\n\n    this.analyzer = analyzer;\n    this.textFieldName = textFieldName;\n\n    if (threshold == null || threshold == 0d) {\n      // automatic assign a threshold\n      long sumDocFreq = leafReader.getSumDocFreq(textFieldName);\n      if (sumDocFreq != -1) {\n        this.threshold = (double) sumDocFreq / 2d;\n      } else {\n        throw new IOException(\n                \"threshold cannot be assigned since term vectors for field \"\n                        + textFieldName + \" do not exist\");\n      }\n    } else {\n      this.threshold = threshold;\n    }\n\n    // TODO : remove this map as soon as we have a writable FST\n    SortedMap<String, Double> weights = new ConcurrentSkipListMap<>();\n\n    TermsEnum termsEnum = textTerms.iterator();\n    BytesRef textTerm;\n    while ((textTerm = termsEnum.next()) != null) {\n      weights.put(textTerm.utf8ToString(), (double) termsEnum.totalTermFreq());\n    }\n    updateFST(weights);\n\n    IndexSearcher indexSearcher = new IndexSearcher(leafReader);\n\n    int batchCount = 0;\n\n    BooleanQuery q = new BooleanQuery();\n    q.add(new BooleanClause(new WildcardQuery(new Term(classFieldName, \"*\")), BooleanClause.Occur.MUST));\n    if (query != null) {\n      q.add(new BooleanClause(query, BooleanClause.Occur.MUST));\n    }\n    // run the search and use stored field values\n    for (ScoreDoc scoreDoc : indexSearcher.search(q,\n            Integer.MAX_VALUE).scoreDocs) {\n      StoredDocument doc = indexSearcher.doc(scoreDoc.doc);\n\n      StorableField textField = doc.getField(textFieldName);\n\n      // get the expected result\n      StorableField classField = doc.getField(classFieldName);\n\n      if (textField != null && classField != null) {\n        // assign class to the doc\n        ClassificationResult<Boolean> classificationResult = assignClass(textField.stringValue());\n        Boolean assignedClass = classificationResult.getAssignedClass();\n\n        Boolean correctClass = Boolean.valueOf(classField.stringValue());\n        long modifier = correctClass.compareTo(assignedClass);\n        if (modifier != 0) {\n          updateWeights(leafReader, scoreDoc.doc, assignedClass,\n                  weights, modifier, batchCount % batchSize == 0);\n        }\n        batchCount++;\n      }\n    }\n    weights.clear(); // free memory while waiting for GC\n  }\n\n","sourceOld":"  /**\n   * {@inheritDoc}\n   */\n  @Override\n  public void train(LeafReader leafReader, String textFieldName,\n                    String classFieldName, Analyzer analyzer, Query query) throws IOException {\n    this.textTerms = MultiFields.getTerms(leafReader, textFieldName);\n\n    if (textTerms == null) {\n      throw new IOException(\"term vectors need to be available for field \" + textFieldName);\n    }\n\n    this.analyzer = analyzer;\n    this.textFieldName = textFieldName;\n\n    if (threshold == null || threshold == 0d) {\n      // automatic assign a threshold\n      long sumDocFreq = leafReader.getSumDocFreq(textFieldName);\n      if (sumDocFreq != -1) {\n        this.threshold = (double) sumDocFreq / 2d;\n      } else {\n        throw new IOException(\n            \"threshold cannot be assigned since term vectors for field \"\n                + textFieldName + \" do not exist\");\n      }\n    }\n\n    // TODO : remove this map as soon as we have a writable FST\n    SortedMap<String, Double> weights = new ConcurrentSkipListMap<>();\n\n    TermsEnum termsEnum = textTerms.iterator();\n    BytesRef textTerm;\n    while ((textTerm = termsEnum.next()) != null) {\n      weights.put(textTerm.utf8ToString(), (double) termsEnum.totalTermFreq());\n    }\n    updateFST(weights);\n\n    IndexSearcher indexSearcher = new IndexSearcher(leafReader);\n\n    int batchCount = 0;\n\n    BooleanQuery q = new BooleanQuery();\n    q.add(new BooleanClause(new WildcardQuery(new Term(classFieldName, \"*\")), BooleanClause.Occur.MUST));\n    if (query != null) {\n      q.add(new BooleanClause(query, BooleanClause.Occur.MUST));\n    }\n    // run the search and use stored field values\n    for (ScoreDoc scoreDoc : indexSearcher.search(q,\n        Integer.MAX_VALUE).scoreDocs) {\n      StoredDocument doc = indexSearcher.doc(scoreDoc.doc);\n\n      StorableField textField = doc.getField(textFieldName);\n\n      // get the expected result\n      StorableField classField = doc.getField(classFieldName);\n\n      if (textField != null && classField != null) {\n        // assign class to the doc\n        ClassificationResult<Boolean> classificationResult = assignClass(textField.stringValue());\n        Boolean assignedClass = classificationResult.getAssignedClass();\n\n        Boolean correctClass = Boolean.valueOf(classField.stringValue());\n        long modifier = correctClass.compareTo(assignedClass);\n        if (modifier != 0) {\n          updateWeights(leafReader, scoreDoc.doc, assignedClass,\n                weights, modifier, batchCount % batchSize == 0);\n        }\n        batchCount++;\n      }\n    }\n    weights.clear(); // free memory while waiting for GC\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5dcf11f5c46a9fb8465d812ea1a1a34c9305dac8","date":1430636069,"type":3,"author":"Tommaso Teofili","isMerge":false,"pathNew":"lucene/classification/src/java/org/apache/lucene/classification/BooleanPerceptronClassifier#BooleanPerceptronClassifier(LeafReader,String,String,Analyzer,Query,Integer,Double).mjava","pathOld":"lucene/classification/src/java/org/apache/lucene/classification/BooleanPerceptronClassifier#BooleanPerceptronClassifier(LeafReader,String,String,Analyzer,Query,Integer,Double).mjava","sourceNew":"  /**\n   * Creates a {@link BooleanPerceptronClassifier}\n   *\n   * @param leafReader     the reader on the index to be used for classification\n   * @param textFieldName  the name of the field used as input for the classifier\n   * @param classFieldName the name of the field used as the output for the classifier\n   * @param analyzer       an {@link Analyzer} used to analyze unseen text\n   * @param query          a {@link Query} to eventually filter the docs used for training the classifier, or {@code null}\n   *                       if all the indexed docs should be used\n   * @param batchSize      the size of the batch of docs to use for updating the perceptron weights\n   * @param threshold      the threshold used for class separation\n   * @throws IOException if the building of the underlying {@link FST} fails and / or {@link TermsEnum} for the text field\n   *                     cannot be found\n   */\n  public BooleanPerceptronClassifier(LeafReader leafReader, String textFieldName, String classFieldName, Analyzer analyzer,\n                                     Query query, Integer batchSize, Double threshold) throws IOException {\n    this.textTerms = MultiFields.getTerms(leafReader, textFieldName);\n\n    if (textTerms == null) {\n      throw new IOException(\"term vectors need to be available for field \" + textFieldName);\n    }\n\n    this.analyzer = analyzer;\n    this.textFieldName = textFieldName;\n\n    if (threshold == null || threshold == 0d) {\n      // automatic assign a threshold\n      long sumDocFreq = leafReader.getSumDocFreq(textFieldName);\n      if (sumDocFreq != -1) {\n        this.threshold = (double) sumDocFreq / 2d;\n      } else {\n        throw new IOException(\n                \"threshold cannot be assigned since term vectors for field \"\n                        + textFieldName + \" do not exist\");\n      }\n    } else {\n      this.threshold = threshold;\n    }\n\n    // TODO : remove this map as soon as we have a writable FST\n    SortedMap<String, Double> weights = new ConcurrentSkipListMap<>();\n\n    TermsEnum termsEnum = textTerms.iterator();\n    BytesRef textTerm;\n    while ((textTerm = termsEnum.next()) != null) {\n      weights.put(textTerm.utf8ToString(), (double) termsEnum.totalTermFreq());\n    }\n    updateFST(weights);\n\n    IndexSearcher indexSearcher = new IndexSearcher(leafReader);\n\n    int batchCount = 0;\n\n    BooleanQuery q = new BooleanQuery();\n    q.add(new BooleanClause(new WildcardQuery(new Term(classFieldName, \"*\")), BooleanClause.Occur.MUST));\n    if (query != null) {\n      q.add(new BooleanClause(query, BooleanClause.Occur.MUST));\n    }\n    // run the search and use stored field values\n    for (ScoreDoc scoreDoc : indexSearcher.search(q,\n            Integer.MAX_VALUE).scoreDocs) {\n      StoredDocument doc = indexSearcher.doc(scoreDoc.doc);\n\n      StorableField textField = doc.getField(textFieldName);\n\n      // get the expected result\n      StorableField classField = doc.getField(classFieldName);\n\n      if (textField != null && classField != null) {\n        // assign class to the doc\n        ClassificationResult<Boolean> classificationResult = assignClass(textField.stringValue());\n        Boolean assignedClass = classificationResult.getAssignedClass();\n\n        Boolean correctClass = Boolean.valueOf(classField.stringValue());\n        long modifier = correctClass.compareTo(assignedClass);\n        if (modifier != 0) {\n          updateWeights(leafReader, scoreDoc.doc, assignedClass,\n                  weights, modifier, batchCount % batchSize == 0);\n        }\n        batchCount++;\n      }\n    }\n    weights.clear(); // free memory while waiting for GC\n  }\n\n","sourceOld":"  public BooleanPerceptronClassifier(LeafReader leafReader, String textFieldName, String classFieldName, Analyzer analyzer,\n                                     Query query, Integer batchSize, Double threshold) throws IOException {\n    this.textTerms = MultiFields.getTerms(leafReader, textFieldName);\n\n    if (textTerms == null) {\n      throw new IOException(\"term vectors need to be available for field \" + textFieldName);\n    }\n\n    this.analyzer = analyzer;\n    this.textFieldName = textFieldName;\n\n    if (threshold == null || threshold == 0d) {\n      // automatic assign a threshold\n      long sumDocFreq = leafReader.getSumDocFreq(textFieldName);\n      if (sumDocFreq != -1) {\n        this.threshold = (double) sumDocFreq / 2d;\n      } else {\n        throw new IOException(\n                \"threshold cannot be assigned since term vectors for field \"\n                        + textFieldName + \" do not exist\");\n      }\n    } else {\n      this.threshold = threshold;\n    }\n\n    // TODO : remove this map as soon as we have a writable FST\n    SortedMap<String, Double> weights = new ConcurrentSkipListMap<>();\n\n    TermsEnum termsEnum = textTerms.iterator();\n    BytesRef textTerm;\n    while ((textTerm = termsEnum.next()) != null) {\n      weights.put(textTerm.utf8ToString(), (double) termsEnum.totalTermFreq());\n    }\n    updateFST(weights);\n\n    IndexSearcher indexSearcher = new IndexSearcher(leafReader);\n\n    int batchCount = 0;\n\n    BooleanQuery q = new BooleanQuery();\n    q.add(new BooleanClause(new WildcardQuery(new Term(classFieldName, \"*\")), BooleanClause.Occur.MUST));\n    if (query != null) {\n      q.add(new BooleanClause(query, BooleanClause.Occur.MUST));\n    }\n    // run the search and use stored field values\n    for (ScoreDoc scoreDoc : indexSearcher.search(q,\n            Integer.MAX_VALUE).scoreDocs) {\n      StoredDocument doc = indexSearcher.doc(scoreDoc.doc);\n\n      StorableField textField = doc.getField(textFieldName);\n\n      // get the expected result\n      StorableField classField = doc.getField(classFieldName);\n\n      if (textField != null && classField != null) {\n        // assign class to the doc\n        ClassificationResult<Boolean> classificationResult = assignClass(textField.stringValue());\n        Boolean assignedClass = classificationResult.getAssignedClass();\n\n        Boolean correctClass = Boolean.valueOf(classField.stringValue());\n        long modifier = correctClass.compareTo(assignedClass);\n        if (modifier != 0) {\n          updateWeights(leafReader, scoreDoc.doc, assignedClass,\n                  weights, modifier, batchCount % batchSize == 0);\n        }\n        batchCount++;\n      }\n    }\n    weights.clear(); // free memory while waiting for GC\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fdf5b5fada99884e038af8394cd1d14078f3d852","date":1431450289,"type":5,"author":"Tommaso Teofili","isMerge":false,"pathNew":"lucene/classification/src/java/org/apache/lucene/classification/BooleanPerceptronClassifier#BooleanPerceptronClassifier(LeafReader,Analyzer,Query,Integer,Double,String,String).mjava","pathOld":"lucene/classification/src/java/org/apache/lucene/classification/BooleanPerceptronClassifier#BooleanPerceptronClassifier(LeafReader,String,String,Analyzer,Query,Integer,Double).mjava","sourceNew":"  /**\n   * Creates a {@link BooleanPerceptronClassifier}\n   *\n   * @param leafReader     the reader on the index to be used for classification\n   * @param analyzer       an {@link Analyzer} used to analyze unseen text\n   * @param query          a {@link Query} to eventually filter the docs used for training the classifier, or {@code null}\n   *                       if all the indexed docs should be used\n   * @param batchSize      the size of the batch of docs to use for updating the perceptron weights\n   * @param threshold      the threshold used for class separation\n   * @param classFieldName the name of the field used as the output for the classifier\n   * @param textFieldName  the name of the field used as input for the classifier\n   * @throws IOException if the building of the underlying {@link FST} fails and / or {@link TermsEnum} for the text field\n   *                     cannot be found\n   */\n  public BooleanPerceptronClassifier(LeafReader leafReader, Analyzer analyzer, Query query, Integer batchSize,\n                                     Double threshold, String classFieldName, String textFieldName) throws IOException {\n    this.textTerms = MultiFields.getTerms(leafReader, textFieldName);\n\n    if (textTerms == null) {\n      throw new IOException(\"term vectors need to be available for field \" + textFieldName);\n    }\n\n    this.analyzer = analyzer;\n    this.textFieldName = textFieldName;\n\n    if (threshold == null || threshold == 0d) {\n      // automatic assign a threshold\n      long sumDocFreq = leafReader.getSumDocFreq(textFieldName);\n      if (sumDocFreq != -1) {\n        this.threshold = (double) sumDocFreq / 2d;\n      } else {\n        throw new IOException(\n                \"threshold cannot be assigned since term vectors for field \"\n                        + textFieldName + \" do not exist\");\n      }\n    } else {\n      this.threshold = threshold;\n    }\n\n    // TODO : remove this map as soon as we have a writable FST\n    SortedMap<String, Double> weights = new ConcurrentSkipListMap<>();\n\n    TermsEnum termsEnum = textTerms.iterator();\n    BytesRef textTerm;\n    while ((textTerm = termsEnum.next()) != null) {\n      weights.put(textTerm.utf8ToString(), (double) termsEnum.totalTermFreq());\n    }\n    updateFST(weights);\n\n    IndexSearcher indexSearcher = new IndexSearcher(leafReader);\n\n    int batchCount = 0;\n\n    BooleanQuery q = new BooleanQuery();\n    q.add(new BooleanClause(new WildcardQuery(new Term(classFieldName, \"*\")), BooleanClause.Occur.MUST));\n    if (query != null) {\n      q.add(new BooleanClause(query, BooleanClause.Occur.MUST));\n    }\n    // run the search and use stored field values\n    for (ScoreDoc scoreDoc : indexSearcher.search(q,\n            Integer.MAX_VALUE).scoreDocs) {\n      StoredDocument doc = indexSearcher.doc(scoreDoc.doc);\n\n      StorableField textField = doc.getField(textFieldName);\n\n      // get the expected result\n      StorableField classField = doc.getField(classFieldName);\n\n      if (textField != null && classField != null) {\n        // assign class to the doc\n        ClassificationResult<Boolean> classificationResult = assignClass(textField.stringValue());\n        Boolean assignedClass = classificationResult.getAssignedClass();\n\n        Boolean correctClass = Boolean.valueOf(classField.stringValue());\n        long modifier = correctClass.compareTo(assignedClass);\n        if (modifier != 0) {\n          updateWeights(leafReader, scoreDoc.doc, assignedClass,\n                  weights, modifier, batchCount % batchSize == 0);\n        }\n        batchCount++;\n      }\n    }\n    weights.clear(); // free memory while waiting for GC\n  }\n\n","sourceOld":"  /**\n   * Creates a {@link BooleanPerceptronClassifier}\n   *\n   * @param leafReader     the reader on the index to be used for classification\n   * @param textFieldName  the name of the field used as input for the classifier\n   * @param classFieldName the name of the field used as the output for the classifier\n   * @param analyzer       an {@link Analyzer} used to analyze unseen text\n   * @param query          a {@link Query} to eventually filter the docs used for training the classifier, or {@code null}\n   *                       if all the indexed docs should be used\n   * @param batchSize      the size of the batch of docs to use for updating the perceptron weights\n   * @param threshold      the threshold used for class separation\n   * @throws IOException if the building of the underlying {@link FST} fails and / or {@link TermsEnum} for the text field\n   *                     cannot be found\n   */\n  public BooleanPerceptronClassifier(LeafReader leafReader, String textFieldName, String classFieldName, Analyzer analyzer,\n                                     Query query, Integer batchSize, Double threshold) throws IOException {\n    this.textTerms = MultiFields.getTerms(leafReader, textFieldName);\n\n    if (textTerms == null) {\n      throw new IOException(\"term vectors need to be available for field \" + textFieldName);\n    }\n\n    this.analyzer = analyzer;\n    this.textFieldName = textFieldName;\n\n    if (threshold == null || threshold == 0d) {\n      // automatic assign a threshold\n      long sumDocFreq = leafReader.getSumDocFreq(textFieldName);\n      if (sumDocFreq != -1) {\n        this.threshold = (double) sumDocFreq / 2d;\n      } else {\n        throw new IOException(\n                \"threshold cannot be assigned since term vectors for field \"\n                        + textFieldName + \" do not exist\");\n      }\n    } else {\n      this.threshold = threshold;\n    }\n\n    // TODO : remove this map as soon as we have a writable FST\n    SortedMap<String, Double> weights = new ConcurrentSkipListMap<>();\n\n    TermsEnum termsEnum = textTerms.iterator();\n    BytesRef textTerm;\n    while ((textTerm = termsEnum.next()) != null) {\n      weights.put(textTerm.utf8ToString(), (double) termsEnum.totalTermFreq());\n    }\n    updateFST(weights);\n\n    IndexSearcher indexSearcher = new IndexSearcher(leafReader);\n\n    int batchCount = 0;\n\n    BooleanQuery q = new BooleanQuery();\n    q.add(new BooleanClause(new WildcardQuery(new Term(classFieldName, \"*\")), BooleanClause.Occur.MUST));\n    if (query != null) {\n      q.add(new BooleanClause(query, BooleanClause.Occur.MUST));\n    }\n    // run the search and use stored field values\n    for (ScoreDoc scoreDoc : indexSearcher.search(q,\n            Integer.MAX_VALUE).scoreDocs) {\n      StoredDocument doc = indexSearcher.doc(scoreDoc.doc);\n\n      StorableField textField = doc.getField(textFieldName);\n\n      // get the expected result\n      StorableField classField = doc.getField(classFieldName);\n\n      if (textField != null && classField != null) {\n        // assign class to the doc\n        ClassificationResult<Boolean> classificationResult = assignClass(textField.stringValue());\n        Boolean assignedClass = classificationResult.getAssignedClass();\n\n        Boolean correctClass = Boolean.valueOf(classField.stringValue());\n        long modifier = correctClass.compareTo(assignedClass);\n        if (modifier != 0) {\n          updateWeights(leafReader, scoreDoc.doc, assignedClass,\n                  weights, modifier, batchCount % batchSize == 0);\n        }\n        batchCount++;\n      }\n    }\n    weights.clear(); // free memory while waiting for GC\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"5dcf11f5c46a9fb8465d812ea1a1a34c9305dac8":["360ff513ddb24a30ffa2111a3ef0f91038803100"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"fdf5b5fada99884e038af8394cd1d14078f3d852":["5dcf11f5c46a9fb8465d812ea1a1a34c9305dac8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["fdf5b5fada99884e038af8394cd1d14078f3d852"],"360ff513ddb24a30ffa2111a3ef0f91038803100":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"5dcf11f5c46a9fb8465d812ea1a1a34c9305dac8":["fdf5b5fada99884e038af8394cd1d14078f3d852"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["360ff513ddb24a30ffa2111a3ef0f91038803100"],"fdf5b5fada99884e038af8394cd1d14078f3d852":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"360ff513ddb24a30ffa2111a3ef0f91038803100":["5dcf11f5c46a9fb8465d812ea1a1a34c9305dac8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}