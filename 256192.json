{"path":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toLookupAutomaton(CharSequence).mjava","commits":[{"id":"cc41b743423981e7ec17a024ce7e107096e472fe","date":1349975327,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toLookupAutomaton(CharSequence).mjava","pathOld":"/dev/null","sourceNew":"  final Automaton toLookupAutomaton(final CharSequence key) throws IOException {\n    // TODO: is there a Reader from a CharSequence?\n    // Turn tokenstream into automaton:\n    TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()));\n    Automaton automaton = (getTokenStreamToAutomaton()).toAutomaton(ts);\n    ts.end();\n    ts.close();\n\n    // TODO: we could use the end offset to \"guess\"\n    // whether the final token was a partial token; this\n    // would only be a heuristic ... but maybe an OK one.\n    // This way we could eg differentiate \"net\" from \"net \",\n    // which we can't today...\n\n    replaceSep(automaton);\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    BasicOperations.determinize(automaton);\n    return automaton;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["c83d6c4335f31cae14f625a222bc842f20073dcd","782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4f3db1dca4ec6d06e771211e9f7c4ae5d8e5758b","date":1351615637,"type":0,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toLookupAutomaton(CharSequence).mjava","pathOld":"/dev/null","sourceNew":"  final Automaton toLookupAutomaton(final CharSequence key) throws IOException {\n    // TODO: is there a Reader from a CharSequence?\n    // Turn tokenstream into automaton:\n    TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()));\n    Automaton automaton = (getTokenStreamToAutomaton()).toAutomaton(ts);\n    ts.end();\n    ts.close();\n\n    // TODO: we could use the end offset to \"guess\"\n    // whether the final token was a partial token; this\n    // would only be a heuristic ... but maybe an OK one.\n    // This way we could eg differentiate \"net\" from \"net \",\n    // which we can't today...\n\n    replaceSep(automaton);\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    BasicOperations.determinize(automaton);\n    return automaton;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"70728fc5d87dc51506cd3f763d68d2c16948e127","date":1363037076,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toLookupAutomaton(CharSequence).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toLookupAutomaton(CharSequence).mjava","sourceNew":"  final Automaton toLookupAutomaton(final CharSequence key) throws IOException {\n    // TODO: is there a Reader from a CharSequence?\n    // Turn tokenstream into automaton:\n    TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()));\n    Automaton automaton = (getTokenStreamToAutomaton()).toAutomaton(ts);\n    ts.close();\n\n    // TODO: we could use the end offset to \"guess\"\n    // whether the final token was a partial token; this\n    // would only be a heuristic ... but maybe an OK one.\n    // This way we could eg differentiate \"net\" from \"net \",\n    // which we can't today...\n\n    replaceSep(automaton);\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    BasicOperations.determinize(automaton);\n    return automaton;\n  }\n\n","sourceOld":"  final Automaton toLookupAutomaton(final CharSequence key) throws IOException {\n    // TODO: is there a Reader from a CharSequence?\n    // Turn tokenstream into automaton:\n    TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()));\n    Automaton automaton = (getTokenStreamToAutomaton()).toAutomaton(ts);\n    ts.end();\n    ts.close();\n\n    // TODO: we could use the end offset to \"guess\"\n    // whether the final token was a partial token; this\n    // would only be a heuristic ... but maybe an OK one.\n    // This way we could eg differentiate \"net\" from \"net \",\n    // which we can't today...\n\n    replaceSep(automaton);\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    BasicOperations.determinize(automaton);\n    return automaton;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c83d6c4335f31cae14f625a222bc842f20073dcd","date":1373306148,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toLookupAutomaton(CharSequence).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toLookupAutomaton(CharSequence).mjava","sourceNew":"  final Automaton toLookupAutomaton(final CharSequence key) throws IOException {\n    // TODO: is there a Reader from a CharSequence?\n    // Turn tokenstream into automaton:\n    TokenStream ts = queryAnalyzer.tokenStream(\"\", key.toString());\n    Automaton automaton = (getTokenStreamToAutomaton()).toAutomaton(ts);\n    ts.close();\n\n    // TODO: we could use the end offset to \"guess\"\n    // whether the final token was a partial token; this\n    // would only be a heuristic ... but maybe an OK one.\n    // This way we could eg differentiate \"net\" from \"net \",\n    // which we can't today...\n\n    replaceSep(automaton);\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    BasicOperations.determinize(automaton);\n    return automaton;\n  }\n\n","sourceOld":"  final Automaton toLookupAutomaton(final CharSequence key) throws IOException {\n    // TODO: is there a Reader from a CharSequence?\n    // Turn tokenstream into automaton:\n    TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()));\n    Automaton automaton = (getTokenStreamToAutomaton()).toAutomaton(ts);\n    ts.close();\n\n    // TODO: we could use the end offset to \"guess\"\n    // whether the final token was a partial token; this\n    // would only be a heuristic ... but maybe an OK one.\n    // This way we could eg differentiate \"net\" from \"net \",\n    // which we can't today...\n\n    replaceSep(automaton);\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    BasicOperations.determinize(automaton);\n    return automaton;\n  }\n\n","bugFix":["cc41b743423981e7ec17a024ce7e107096e472fe"],"bugIntro":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toLookupAutomaton(CharSequence).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toLookupAutomaton(CharSequence).mjava","sourceNew":"  final Automaton toLookupAutomaton(final CharSequence key) throws IOException {\n    // TODO: is there a Reader from a CharSequence?\n    // Turn tokenstream into automaton:\n    TokenStream ts = queryAnalyzer.tokenStream(\"\", key.toString());\n    Automaton automaton = (getTokenStreamToAutomaton()).toAutomaton(ts);\n    ts.close();\n\n    // TODO: we could use the end offset to \"guess\"\n    // whether the final token was a partial token; this\n    // would only be a heuristic ... but maybe an OK one.\n    // This way we could eg differentiate \"net\" from \"net \",\n    // which we can't today...\n\n    replaceSep(automaton);\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    BasicOperations.determinize(automaton);\n    return automaton;\n  }\n\n","sourceOld":"  final Automaton toLookupAutomaton(final CharSequence key) throws IOException {\n    // TODO: is there a Reader from a CharSequence?\n    // Turn tokenstream into automaton:\n    TokenStream ts = queryAnalyzer.tokenStream(\"\", new StringReader(key.toString()));\n    Automaton automaton = (getTokenStreamToAutomaton()).toAutomaton(ts);\n    ts.close();\n\n    // TODO: we could use the end offset to \"guess\"\n    // whether the final token was a partial token; this\n    // would only be a heuristic ... but maybe an OK one.\n    // This way we could eg differentiate \"net\" from \"net \",\n    // which we can't today...\n\n    replaceSep(automaton);\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    BasicOperations.determinize(automaton);\n    return automaton;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"782ed6a4b4ba50ec19734fc8db4e570ee193d627","date":1381127065,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toLookupAutomaton(CharSequence).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toLookupAutomaton(CharSequence).mjava","sourceNew":"  final Automaton toLookupAutomaton(final CharSequence key) throws IOException {\n    // TODO: is there a Reader from a CharSequence?\n    // Turn tokenstream into automaton:\n    Automaton automaton = null;\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", key.toString())) {\n      automaton = (getTokenStreamToAutomaton()).toAutomaton(ts);\n    }\n\n    // TODO: we could use the end offset to \"guess\"\n    // whether the final token was a partial token; this\n    // would only be a heuristic ... but maybe an OK one.\n    // This way we could eg differentiate \"net\" from \"net \",\n    // which we can't today...\n\n    replaceSep(automaton);\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    BasicOperations.determinize(automaton);\n    return automaton;\n  }\n\n","sourceOld":"  final Automaton toLookupAutomaton(final CharSequence key) throws IOException {\n    // TODO: is there a Reader from a CharSequence?\n    // Turn tokenstream into automaton:\n    TokenStream ts = queryAnalyzer.tokenStream(\"\", key.toString());\n    Automaton automaton = (getTokenStreamToAutomaton()).toAutomaton(ts);\n    ts.close();\n\n    // TODO: we could use the end offset to \"guess\"\n    // whether the final token was a partial token; this\n    // would only be a heuristic ... but maybe an OK one.\n    // This way we could eg differentiate \"net\" from \"net \",\n    // which we can't today...\n\n    replaceSep(automaton);\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    BasicOperations.determinize(automaton);\n    return automaton;\n  }\n\n","bugFix":["c83d6c4335f31cae14f625a222bc842f20073dcd","cc41b743423981e7ec17a024ce7e107096e472fe"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"75ac8571c2d82c574e446c3729251b994c69a55c","date":1402523781,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toLookupAutomaton(CharSequence).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toLookupAutomaton(CharSequence).mjava","sourceNew":"  final LightAutomaton toLookupAutomaton(final CharSequence key) throws IOException {\n    // TODO: is there a Reader from a CharSequence?\n    // Turn tokenstream into automaton:\n    LightAutomaton automaton = null;\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", key.toString())) {\n        automaton = getTokenStreamToAutomaton().toAutomaton(ts);\n    }\n\n    automaton = replaceSep(automaton);\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    automaton = BasicOperations.determinize(automaton);\n    return automaton;\n  }\n\n","sourceOld":"  final Automaton toLookupAutomaton(final CharSequence key) throws IOException {\n    // TODO: is there a Reader from a CharSequence?\n    // Turn tokenstream into automaton:\n    Automaton automaton = null;\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", key.toString())) {\n      automaton = (getTokenStreamToAutomaton()).toAutomaton(ts);\n    }\n\n    // TODO: we could use the end offset to \"guess\"\n    // whether the final token was a partial token; this\n    // would only be a heuristic ... but maybe an OK one.\n    // This way we could eg differentiate \"net\" from \"net \",\n    // which we can't today...\n\n    replaceSep(automaton);\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    BasicOperations.determinize(automaton);\n    return automaton;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4ca1c732df8923f5624f6c06b1dcca9e69d98c96","date":1402957391,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toLookupAutomaton(CharSequence).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toLookupAutomaton(CharSequence).mjava","sourceNew":"  final Automaton toLookupAutomaton(final CharSequence key) throws IOException {\n    // TODO: is there a Reader from a CharSequence?\n    // Turn tokenstream into automaton:\n    Automaton automaton = null;\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", key.toString())) {\n        automaton = getTokenStreamToAutomaton().toAutomaton(ts);\n    }\n\n    automaton = replaceSep(automaton);\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    automaton = Operations.determinize(automaton);\n    return automaton;\n  }\n\n","sourceOld":"  final LightAutomaton toLookupAutomaton(final CharSequence key) throws IOException {\n    // TODO: is there a Reader from a CharSequence?\n    // Turn tokenstream into automaton:\n    LightAutomaton automaton = null;\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", key.toString())) {\n        automaton = getTokenStreamToAutomaton().toAutomaton(ts);\n    }\n\n    automaton = replaceSep(automaton);\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    automaton = BasicOperations.determinize(automaton);\n    return automaton;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5c84485629d80d203608e8975a1139de9933cc38","date":1403166128,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toLookupAutomaton(CharSequence).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toLookupAutomaton(CharSequence).mjava","sourceNew":"  final Automaton toLookupAutomaton(final CharSequence key) throws IOException {\n    // TODO: is there a Reader from a CharSequence?\n    // Turn tokenstream into automaton:\n    Automaton automaton = null;\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", key.toString())) {\n        automaton = getTokenStreamToAutomaton().toAutomaton(ts);\n    }\n\n    automaton = replaceSep(automaton);\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    automaton = Operations.determinize(automaton);\n    return automaton;\n  }\n\n","sourceOld":"  final Automaton toLookupAutomaton(final CharSequence key) throws IOException {\n    // TODO: is there a Reader from a CharSequence?\n    // Turn tokenstream into automaton:\n    Automaton automaton = null;\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", key.toString())) {\n      automaton = (getTokenStreamToAutomaton()).toAutomaton(ts);\n    }\n\n    // TODO: we could use the end offset to \"guess\"\n    // whether the final token was a partial token; this\n    // would only be a heuristic ... but maybe an OK one.\n    // This way we could eg differentiate \"net\" from \"net \",\n    // which we can't today...\n\n    replaceSep(automaton);\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    BasicOperations.determinize(automaton);\n    return automaton;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8b316f82baae88f5e279893a9cb7eee51fd8902f","date":1415131390,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toLookupAutomaton(CharSequence).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toLookupAutomaton(CharSequence).mjava","sourceNew":"  final Automaton toLookupAutomaton(final CharSequence key) throws IOException {\n    // TODO: is there a Reader from a CharSequence?\n    // Turn tokenstream into automaton:\n    Automaton automaton = null;\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", key.toString())) {\n        automaton = getTokenStreamToAutomaton().toAutomaton(ts);\n    }\n\n    automaton = replaceSep(automaton);\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    automaton = Operations.determinize(automaton, DEFAULT_MAX_DETERMINIZED_STATES);\n    return automaton;\n  }\n\n","sourceOld":"  final Automaton toLookupAutomaton(final CharSequence key) throws IOException {\n    // TODO: is there a Reader from a CharSequence?\n    // Turn tokenstream into automaton:\n    Automaton automaton = null;\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", key.toString())) {\n        automaton = getTokenStreamToAutomaton().toAutomaton(ts);\n    }\n\n    automaton = replaceSep(automaton);\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    automaton = Operations.determinize(automaton);\n    return automaton;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"098528909bb70948871fd7ed865fafb87ed73964","date":1484667487,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toLookupAutomaton(CharSequence).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toLookupAutomaton(CharSequence).mjava","sourceNew":"  final Automaton toLookupAutomaton(final CharSequence key) throws IOException {\n    // TODO: is there a Reader from a CharSequence?\n    // Turn tokenstream into automaton:\n    Automaton automaton = null;\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", key.toString())) {\n      automaton = getTokenStreamToAutomaton().toAutomaton(ts);\n    }\n\n    automaton = replaceSep(automaton);\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    automaton = Operations.determinize(automaton, DEFAULT_MAX_DETERMINIZED_STATES);\n    return automaton;\n  }\n\n","sourceOld":"  final Automaton toLookupAutomaton(final CharSequence key) throws IOException {\n    // TODO: is there a Reader from a CharSequence?\n    // Turn tokenstream into automaton:\n    Automaton automaton = null;\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", key.toString())) {\n        automaton = getTokenStreamToAutomaton().toAutomaton(ts);\n    }\n\n    automaton = replaceSep(automaton);\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    automaton = Operations.determinize(automaton, DEFAULT_MAX_DETERMINIZED_STATES);\n    return automaton;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"302d34f2c66e8d489ee13078305c330cbf67b226","date":1484754357,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toLookupAutomaton(CharSequence).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggester#toLookupAutomaton(CharSequence).mjava","sourceNew":"  final Automaton toLookupAutomaton(final CharSequence key) throws IOException {\n    // TODO: is there a Reader from a CharSequence?\n    // Turn tokenstream into automaton:\n    Automaton automaton = null;\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", key.toString())) {\n      automaton = getTokenStreamToAutomaton().toAutomaton(ts);\n    }\n\n    automaton = replaceSep(automaton);\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    automaton = Operations.determinize(automaton, DEFAULT_MAX_DETERMINIZED_STATES);\n    return automaton;\n  }\n\n","sourceOld":"  final Automaton toLookupAutomaton(final CharSequence key) throws IOException {\n    // TODO: is there a Reader from a CharSequence?\n    // Turn tokenstream into automaton:\n    Automaton automaton = null;\n    try (TokenStream ts = queryAnalyzer.tokenStream(\"\", key.toString())) {\n        automaton = getTokenStreamToAutomaton().toAutomaton(ts);\n    }\n\n    automaton = replaceSep(automaton);\n\n    // TODO: we can optimize this somewhat by determinizing\n    // while we convert\n    automaton = Operations.determinize(automaton, DEFAULT_MAX_DETERMINIZED_STATES);\n    return automaton;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"75ac8571c2d82c574e446c3729251b994c69a55c":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["70728fc5d87dc51506cd3f763d68d2c16948e127","c83d6c4335f31cae14f625a222bc842f20073dcd"],"8b316f82baae88f5e279893a9cb7eee51fd8902f":["5c84485629d80d203608e8975a1139de9933cc38"],"782ed6a4b4ba50ec19734fc8db4e570ee193d627":["c83d6c4335f31cae14f625a222bc842f20073dcd"],"302d34f2c66e8d489ee13078305c330cbf67b226":["8b316f82baae88f5e279893a9cb7eee51fd8902f","098528909bb70948871fd7ed865fafb87ed73964"],"4f3db1dca4ec6d06e771211e9f7c4ae5d8e5758b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","cc41b743423981e7ec17a024ce7e107096e472fe"],"70728fc5d87dc51506cd3f763d68d2c16948e127":["4f3db1dca4ec6d06e771211e9f7c4ae5d8e5758b"],"c83d6c4335f31cae14f625a222bc842f20073dcd":["70728fc5d87dc51506cd3f763d68d2c16948e127"],"cc41b743423981e7ec17a024ce7e107096e472fe":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"098528909bb70948871fd7ed865fafb87ed73964":["8b316f82baae88f5e279893a9cb7eee51fd8902f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4ca1c732df8923f5624f6c06b1dcca9e69d98c96":["75ac8571c2d82c574e446c3729251b994c69a55c"],"5c84485629d80d203608e8975a1139de9933cc38":["782ed6a4b4ba50ec19734fc8db4e570ee193d627","4ca1c732df8923f5624f6c06b1dcca9e69d98c96"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["098528909bb70948871fd7ed865fafb87ed73964"]},"commit2Childs":{"75ac8571c2d82c574e446c3729251b994c69a55c":["4ca1c732df8923f5624f6c06b1dcca9e69d98c96"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":[],"782ed6a4b4ba50ec19734fc8db4e570ee193d627":["75ac8571c2d82c574e446c3729251b994c69a55c","5c84485629d80d203608e8975a1139de9933cc38"],"8b316f82baae88f5e279893a9cb7eee51fd8902f":["302d34f2c66e8d489ee13078305c330cbf67b226","098528909bb70948871fd7ed865fafb87ed73964"],"302d34f2c66e8d489ee13078305c330cbf67b226":[],"4f3db1dca4ec6d06e771211e9f7c4ae5d8e5758b":["70728fc5d87dc51506cd3f763d68d2c16948e127"],"70728fc5d87dc51506cd3f763d68d2c16948e127":["37a0f60745e53927c4c876cfe5b5a58170f0646c","c83d6c4335f31cae14f625a222bc842f20073dcd"],"c83d6c4335f31cae14f625a222bc842f20073dcd":["37a0f60745e53927c4c876cfe5b5a58170f0646c","782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"cc41b743423981e7ec17a024ce7e107096e472fe":["4f3db1dca4ec6d06e771211e9f7c4ae5d8e5758b"],"098528909bb70948871fd7ed865fafb87ed73964":["302d34f2c66e8d489ee13078305c330cbf67b226","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4f3db1dca4ec6d06e771211e9f7c4ae5d8e5758b","cc41b743423981e7ec17a024ce7e107096e472fe"],"4ca1c732df8923f5624f6c06b1dcca9e69d98c96":["5c84485629d80d203608e8975a1139de9933cc38"],"5c84485629d80d203608e8975a1139de9933cc38":["8b316f82baae88f5e279893a9cb7eee51fd8902f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["37a0f60745e53927c4c876cfe5b5a58170f0646c","302d34f2c66e8d489ee13078305c330cbf67b226","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}