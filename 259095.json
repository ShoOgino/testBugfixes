{"path":"lucene/src/java/org/apache/lucene/index/TieredMergePolicy#findMergesToExpungeDeletes(SegmentInfos).mjava","commits":[{"id":"01e5948db9a07144112d2f08f28ca2e3cd880348","date":1301759232,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TieredMergePolicy#findMergesToExpungeDeletes(SegmentInfos).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public MergeSpecification findMergesToExpungeDeletes(SegmentInfos infos)\n      throws CorruptIndexException, IOException {\n    if (verbose()) {\n      message(\"findMergesToExpungeDeletes infos=\" + writer.get().segString(infos) + \" expungeDeletesPctAllowed=\" + expungeDeletesPctAllowed);\n    }\n    final SegmentInfos eligible = new SegmentInfos();\n    final Collection<SegmentInfo> merging = writer.get().getMergingSegments();\n    for(SegmentInfo info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.docCount;\n      if (pctDeletes > expungeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, segmentByteSizeDescending);\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      long totAfterMergeBytes = 0;\n      int upto = start;\n      boolean done = false;\n      while(upto < start + maxMergeAtOnceExplicit) {\n        if (upto == eligible.size()) {\n          done = true;\n          break;\n        }\n        final SegmentInfo info = eligible.get(upto);\n        final long segBytes = size(info);\n        if (totAfterMergeBytes + segBytes > maxMergedSegmentBytes) {\n          // TODO: we could be smarter here, eg cherry\n          // picking smaller merges that'd sum up to just\n          // around the max size\n          break;\n        }\n        totAfterMergeBytes += segBytes;\n        upto++;\n      }\n\n      if (upto == start) {\n        // Single segment is too big; grace it\n        start++;\n        continue;\n      }\n      \n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.range(start, upto));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = upto;\n      if (done) {\n        break;\n      }\n    }\n\n    return spec;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["0791b41f65aecff2e75db0c1ebf95d745a5ab1b1","4d3e8520fd031bab31fd0e4d480e55958bc45efe","7358158aa96de7ba4e78d7fbee9f9fa41320173d"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"45669a651c970812a680841b97a77cce06af559f","date":1301922222,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/TieredMergePolicy#findMergesToExpungeDeletes(SegmentInfos).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public MergeSpecification findMergesToExpungeDeletes(SegmentInfos infos)\n      throws CorruptIndexException, IOException {\n    if (verbose()) {\n      message(\"findMergesToExpungeDeletes infos=\" + writer.get().segString(infos) + \" expungeDeletesPctAllowed=\" + expungeDeletesPctAllowed);\n    }\n    final SegmentInfos eligible = new SegmentInfos();\n    final Collection<SegmentInfo> merging = writer.get().getMergingSegments();\n    for(SegmentInfo info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.docCount;\n      if (pctDeletes > expungeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, segmentByteSizeDescending);\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      long totAfterMergeBytes = 0;\n      int upto = start;\n      boolean done = false;\n      while(upto < start + maxMergeAtOnceExplicit) {\n        if (upto == eligible.size()) {\n          done = true;\n          break;\n        }\n        final SegmentInfo info = eligible.get(upto);\n        final long segBytes = size(info);\n        if (totAfterMergeBytes + segBytes > maxMergedSegmentBytes) {\n          // TODO: we could be smarter here, eg cherry\n          // picking smaller merges that'd sum up to just\n          // around the max size\n          break;\n        }\n        totAfterMergeBytes += segBytes;\n        upto++;\n      }\n\n      if (upto == start) {\n        // Single segment is too big; grace it\n        start++;\n        continue;\n      }\n      \n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.range(start, upto));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = upto;\n      if (done) {\n        break;\n      }\n    }\n\n    return spec;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/TieredMergePolicy#findMergesToExpungeDeletes(SegmentInfos).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public MergeSpecification findMergesToExpungeDeletes(SegmentInfos infos)\n      throws CorruptIndexException, IOException {\n    if (verbose()) {\n      message(\"findMergesToExpungeDeletes infos=\" + writer.get().segString(infos) + \" expungeDeletesPctAllowed=\" + expungeDeletesPctAllowed);\n    }\n    final SegmentInfos eligible = new SegmentInfos();\n    final Collection<SegmentInfo> merging = writer.get().getMergingSegments();\n    for(SegmentInfo info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.docCount;\n      if (pctDeletes > expungeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, segmentByteSizeDescending);\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      long totAfterMergeBytes = 0;\n      int upto = start;\n      boolean done = false;\n      while(upto < start + maxMergeAtOnceExplicit) {\n        if (upto == eligible.size()) {\n          done = true;\n          break;\n        }\n        final SegmentInfo info = eligible.get(upto);\n        final long segBytes = size(info);\n        if (totAfterMergeBytes + segBytes > maxMergedSegmentBytes) {\n          // TODO: we could be smarter here, eg cherry\n          // picking smaller merges that'd sum up to just\n          // around the max size\n          break;\n        }\n        totAfterMergeBytes += segBytes;\n        upto++;\n      }\n\n      if (upto == start) {\n        // Single segment is too big; grace it\n        start++;\n        continue;\n      }\n      \n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.range(start, upto));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = upto;\n      if (done) {\n        break;\n      }\n    }\n\n    return spec;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5270fb4f55a1b77663dda53cb8090c083f0a23b3","date":1305050821,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TieredMergePolicy#findMergesToExpungeDeletes(SegmentInfos).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TieredMergePolicy#findMergesToExpungeDeletes(SegmentInfos).mjava","sourceNew":"  @Override\n  public MergeSpecification findMergesToExpungeDeletes(SegmentInfos infos)\n      throws CorruptIndexException, IOException {\n    if (verbose()) {\n      message(\"findMergesToExpungeDeletes infos=\" + writer.get().segString(infos) + \" expungeDeletesPctAllowed=\" + expungeDeletesPctAllowed);\n    }\n    final List<SegmentInfo> eligible = new ArrayList<SegmentInfo>();\n    final Collection<SegmentInfo> merging = writer.get().getMergingSegments();\n    for(SegmentInfo info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.docCount;\n      if (pctDeletes > expungeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, segmentByteSizeDescending);\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      long totAfterMergeBytes = 0;\n      int upto = start;\n      boolean done = false;\n      while(upto < start + maxMergeAtOnceExplicit) {\n        if (upto == eligible.size()) {\n          done = true;\n          break;\n        }\n        final SegmentInfo info = eligible.get(upto);\n        final long segBytes = size(info);\n        if (totAfterMergeBytes + segBytes > maxMergedSegmentBytes) {\n          // TODO: we could be smarter here, eg cherry\n          // picking smaller merges that'd sum up to just\n          // around the max size\n          break;\n        }\n        totAfterMergeBytes += segBytes;\n        upto++;\n      }\n\n      if (upto == start) {\n        // Single segment is too big; grace it\n        start++;\n        continue;\n      }\n      \n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, upto));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = upto;\n      if (done) {\n        break;\n      }\n    }\n\n    return spec;\n  }\n\n","sourceOld":"  @Override\n  public MergeSpecification findMergesToExpungeDeletes(SegmentInfos infos)\n      throws CorruptIndexException, IOException {\n    if (verbose()) {\n      message(\"findMergesToExpungeDeletes infos=\" + writer.get().segString(infos) + \" expungeDeletesPctAllowed=\" + expungeDeletesPctAllowed);\n    }\n    final SegmentInfos eligible = new SegmentInfos();\n    final Collection<SegmentInfo> merging = writer.get().getMergingSegments();\n    for(SegmentInfo info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.docCount;\n      if (pctDeletes > expungeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, segmentByteSizeDescending);\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      long totAfterMergeBytes = 0;\n      int upto = start;\n      boolean done = false;\n      while(upto < start + maxMergeAtOnceExplicit) {\n        if (upto == eligible.size()) {\n          done = true;\n          break;\n        }\n        final SegmentInfo info = eligible.get(upto);\n        final long segBytes = size(info);\n        if (totAfterMergeBytes + segBytes > maxMergedSegmentBytes) {\n          // TODO: we could be smarter here, eg cherry\n          // picking smaller merges that'd sum up to just\n          // around the max size\n          break;\n        }\n        totAfterMergeBytes += segBytes;\n        upto++;\n      }\n\n      if (upto == start) {\n        // Single segment is too big; grace it\n        start++;\n        continue;\n      }\n      \n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.range(start, upto));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = upto;\n      if (done) {\n        break;\n      }\n    }\n\n    return spec;\n  }\n\n","bugFix":null,"bugIntro":["7358158aa96de7ba4e78d7fbee9f9fa41320173d"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c700f8d0842d3e52bb2bdfbfdc046a137e836edb","date":1305285499,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/TieredMergePolicy#findMergesToExpungeDeletes(SegmentInfos).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TieredMergePolicy#findMergesToExpungeDeletes(SegmentInfos).mjava","sourceNew":"  @Override\n  public MergeSpecification findMergesToExpungeDeletes(SegmentInfos infos)\n      throws CorruptIndexException, IOException {\n    if (verbose()) {\n      message(\"findMergesToExpungeDeletes infos=\" + writer.get().segString(infos) + \" expungeDeletesPctAllowed=\" + expungeDeletesPctAllowed);\n    }\n    final List<SegmentInfo> eligible = new ArrayList<SegmentInfo>();\n    final Collection<SegmentInfo> merging = writer.get().getMergingSegments();\n    for(SegmentInfo info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.docCount;\n      if (pctDeletes > expungeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, segmentByteSizeDescending);\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      long totAfterMergeBytes = 0;\n      int upto = start;\n      boolean done = false;\n      while(upto < start + maxMergeAtOnceExplicit) {\n        if (upto == eligible.size()) {\n          done = true;\n          break;\n        }\n        final SegmentInfo info = eligible.get(upto);\n        final long segBytes = size(info);\n        if (totAfterMergeBytes + segBytes > maxMergedSegmentBytes) {\n          // TODO: we could be smarter here, eg cherry\n          // picking smaller merges that'd sum up to just\n          // around the max size\n          break;\n        }\n        totAfterMergeBytes += segBytes;\n        upto++;\n      }\n\n      if (upto == start) {\n        // Single segment is too big; grace it\n        start++;\n        continue;\n      }\n      \n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, upto));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = upto;\n      if (done) {\n        break;\n      }\n    }\n\n    return spec;\n  }\n\n","sourceOld":"  @Override\n  public MergeSpecification findMergesToExpungeDeletes(SegmentInfos infos)\n      throws CorruptIndexException, IOException {\n    if (verbose()) {\n      message(\"findMergesToExpungeDeletes infos=\" + writer.get().segString(infos) + \" expungeDeletesPctAllowed=\" + expungeDeletesPctAllowed);\n    }\n    final SegmentInfos eligible = new SegmentInfos();\n    final Collection<SegmentInfo> merging = writer.get().getMergingSegments();\n    for(SegmentInfo info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.docCount;\n      if (pctDeletes > expungeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, segmentByteSizeDescending);\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      long totAfterMergeBytes = 0;\n      int upto = start;\n      boolean done = false;\n      while(upto < start + maxMergeAtOnceExplicit) {\n        if (upto == eligible.size()) {\n          done = true;\n          break;\n        }\n        final SegmentInfo info = eligible.get(upto);\n        final long segBytes = size(info);\n        if (totAfterMergeBytes + segBytes > maxMergedSegmentBytes) {\n          // TODO: we could be smarter here, eg cherry\n          // picking smaller merges that'd sum up to just\n          // around the max size\n          break;\n        }\n        totAfterMergeBytes += segBytes;\n        upto++;\n      }\n\n      if (upto == start) {\n        // Single segment is too big; grace it\n        start++;\n        continue;\n      }\n      \n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.range(start, upto));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = upto;\n      if (done) {\n        break;\n      }\n    }\n\n    return spec;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":0,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/TieredMergePolicy#findMergesToExpungeDeletes(SegmentInfos).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public MergeSpecification findMergesToExpungeDeletes(SegmentInfos infos)\n      throws CorruptIndexException, IOException {\n    if (verbose()) {\n      message(\"findMergesToExpungeDeletes infos=\" + writer.get().segString(infos) + \" expungeDeletesPctAllowed=\" + expungeDeletesPctAllowed);\n    }\n    final List<SegmentInfo> eligible = new ArrayList<SegmentInfo>();\n    final Collection<SegmentInfo> merging = writer.get().getMergingSegments();\n    for(SegmentInfo info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.docCount;\n      if (pctDeletes > expungeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, segmentByteSizeDescending);\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      long totAfterMergeBytes = 0;\n      int upto = start;\n      boolean done = false;\n      while(upto < start + maxMergeAtOnceExplicit) {\n        if (upto == eligible.size()) {\n          done = true;\n          break;\n        }\n        final SegmentInfo info = eligible.get(upto);\n        final long segBytes = size(info);\n        if (totAfterMergeBytes + segBytes > maxMergedSegmentBytes) {\n          // TODO: we could be smarter here, eg cherry\n          // picking smaller merges that'd sum up to just\n          // around the max size\n          break;\n        }\n        totAfterMergeBytes += segBytes;\n        upto++;\n      }\n\n      if (upto == start) {\n        // Single segment is too big; grace it\n        start++;\n        continue;\n      }\n      \n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, upto));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = upto;\n      if (done) {\n        break;\n      }\n    }\n\n    return spec;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7358158aa96de7ba4e78d7fbee9f9fa41320173d","date":1315918473,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TieredMergePolicy#findMergesToExpungeDeletes(SegmentInfos).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TieredMergePolicy#findMergesToExpungeDeletes(SegmentInfos).mjava","sourceNew":"  @Override\n  public MergeSpecification findMergesToExpungeDeletes(SegmentInfos infos)\n      throws CorruptIndexException, IOException {\n    if (verbose()) {\n      message(\"findMergesToExpungeDeletes infos=\" + writer.get().segString(infos) + \" expungeDeletesPctAllowed=\" + expungeDeletesPctAllowed);\n    }\n    final List<SegmentInfo> eligible = new ArrayList<SegmentInfo>();\n    final Collection<SegmentInfo> merging = writer.get().getMergingSegments();\n    for(SegmentInfo info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.docCount;\n      if (pctDeletes > expungeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, segmentByteSizeDescending);\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      // Don't enforce max merged size here: app is explicitly\n      // calling expungeDeletes, and knows this may take a\n      // long time / produce big segments (like optimize):\n      final int end = Math.min(start + maxMergeAtOnceExplicit, eligible.size());\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, end));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = end;\n    }\n\n    return spec;\n  }\n\n","sourceOld":"  @Override\n  public MergeSpecification findMergesToExpungeDeletes(SegmentInfos infos)\n      throws CorruptIndexException, IOException {\n    if (verbose()) {\n      message(\"findMergesToExpungeDeletes infos=\" + writer.get().segString(infos) + \" expungeDeletesPctAllowed=\" + expungeDeletesPctAllowed);\n    }\n    final List<SegmentInfo> eligible = new ArrayList<SegmentInfo>();\n    final Collection<SegmentInfo> merging = writer.get().getMergingSegments();\n    for(SegmentInfo info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.docCount;\n      if (pctDeletes > expungeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, segmentByteSizeDescending);\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      long totAfterMergeBytes = 0;\n      int upto = start;\n      boolean done = false;\n      while(upto < start + maxMergeAtOnceExplicit) {\n        if (upto == eligible.size()) {\n          done = true;\n          break;\n        }\n        final SegmentInfo info = eligible.get(upto);\n        final long segBytes = size(info);\n        if (totAfterMergeBytes + segBytes > maxMergedSegmentBytes) {\n          // TODO: we could be smarter here, eg cherry\n          // picking smaller merges that'd sum up to just\n          // around the max size\n          break;\n        }\n        totAfterMergeBytes += segBytes;\n        upto++;\n      }\n\n      if (upto == start) {\n        // Single segment is too big; grace it\n        start++;\n        continue;\n      }\n      \n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, upto));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = upto;\n      if (done) {\n        break;\n      }\n    }\n\n    return spec;\n  }\n\n","bugFix":["01e5948db9a07144112d2f08f28ca2e3cd880348","5270fb4f55a1b77663dda53cb8090c083f0a23b3"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d14e8d18c0e3970c20354dbeeb49da11bd587fbd","date":1321041051,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TieredMergePolicy#findMergesToExpungeDeletes(SegmentInfos).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TieredMergePolicy#findMergesToExpungeDeletes(SegmentInfos).mjava","sourceNew":"  @Override\n  public MergeSpecification findMergesToExpungeDeletes(SegmentInfos infos)\n      throws CorruptIndexException, IOException {\n    if (verbose()) {\n      message(\"findMergesToExpungeDeletes infos=\" + writer.get().segString(infos) + \" expungeDeletesPctAllowed=\" + expungeDeletesPctAllowed);\n    }\n    final List<SegmentInfo> eligible = new ArrayList<SegmentInfo>();\n    final Collection<SegmentInfo> merging = writer.get().getMergingSegments();\n    for(SegmentInfo info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.docCount;\n      if (pctDeletes > expungeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, segmentByteSizeDescending);\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      // Don't enforce max merged size here: app is explicitly\n      // calling expungeDeletes, and knows this may take a\n      // long time / produce big segments (like forceMerge):\n      final int end = Math.min(start + maxMergeAtOnceExplicit, eligible.size());\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, end));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = end;\n    }\n\n    return spec;\n  }\n\n","sourceOld":"  @Override\n  public MergeSpecification findMergesToExpungeDeletes(SegmentInfos infos)\n      throws CorruptIndexException, IOException {\n    if (verbose()) {\n      message(\"findMergesToExpungeDeletes infos=\" + writer.get().segString(infos) + \" expungeDeletesPctAllowed=\" + expungeDeletesPctAllowed);\n    }\n    final List<SegmentInfo> eligible = new ArrayList<SegmentInfo>();\n    final Collection<SegmentInfo> merging = writer.get().getMergingSegments();\n    for(SegmentInfo info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.docCount;\n      if (pctDeletes > expungeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, segmentByteSizeDescending);\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      // Don't enforce max merged size here: app is explicitly\n      // calling expungeDeletes, and knows this may take a\n      // long time / produce big segments (like optimize):\n      final int end = Math.min(start + maxMergeAtOnceExplicit, eligible.size());\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, end));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = end;\n    }\n\n    return spec;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"34ce7c842452c79b12c45a8feb64e4597c7110e8","date":1321637224,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedDeletesMerges(SegmentInfos).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TieredMergePolicy#findMergesToExpungeDeletes(SegmentInfos).mjava","sourceNew":"  @Override\n  public MergeSpecification findForcedDeletesMerges(SegmentInfos infos)\n      throws CorruptIndexException, IOException {\n    if (verbose()) {\n      message(\"findForcedDeletesMerges infos=\" + writer.get().segString(infos) + \" forceMergeDeletesPctAllowed=\" + forceMergeDeletesPctAllowed);\n    }\n    final List<SegmentInfo> eligible = new ArrayList<SegmentInfo>();\n    final Collection<SegmentInfo> merging = writer.get().getMergingSegments();\n    for(SegmentInfo info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.docCount;\n      if (pctDeletes > forceMergeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, segmentByteSizeDescending);\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      // Don't enforce max merged size here: app is explicitly\n      // calling forceMergeDeletes, and knows this may take a\n      // long time / produce big segments (like forceMerge):\n      final int end = Math.min(start + maxMergeAtOnceExplicit, eligible.size());\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, end));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = end;\n    }\n\n    return spec;\n  }\n\n","sourceOld":"  @Override\n  public MergeSpecification findMergesToExpungeDeletes(SegmentInfos infos)\n      throws CorruptIndexException, IOException {\n    if (verbose()) {\n      message(\"findMergesToExpungeDeletes infos=\" + writer.get().segString(infos) + \" expungeDeletesPctAllowed=\" + expungeDeletesPctAllowed);\n    }\n    final List<SegmentInfo> eligible = new ArrayList<SegmentInfo>();\n    final Collection<SegmentInfo> merging = writer.get().getMergingSegments();\n    for(SegmentInfo info : infos) {\n      double pctDeletes = 100.*((double) writer.get().numDeletedDocs(info))/info.docCount;\n      if (pctDeletes > expungeDeletesPctAllowed && !merging.contains(info)) {\n        eligible.add(info);\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    Collections.sort(eligible, segmentByteSizeDescending);\n\n    if (verbose()) {\n      message(\"eligible=\" + eligible);\n    }\n\n    int start = 0;\n    MergeSpecification spec = null;\n\n    while(start < eligible.size()) {\n      // Don't enforce max merged size here: app is explicitly\n      // calling expungeDeletes, and knows this may take a\n      // long time / produce big segments (like forceMerge):\n      final int end = Math.min(start + maxMergeAtOnceExplicit, eligible.size());\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n\n      final OneMerge merge = new OneMerge(eligible.subList(start, end));\n      if (verbose()) {\n        message(\"add merge=\" + writer.get().segString(merge.segments));\n      }\n      spec.add(merge);\n      start = end;\n    }\n\n    return spec;\n  }\n\n","bugFix":null,"bugIntro":["4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"7358158aa96de7ba4e78d7fbee9f9fa41320173d":["5270fb4f55a1b77663dda53cb8090c083f0a23b3"],"01e5948db9a07144112d2f08f28ca2e3cd880348":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a3776dccca01c11e7046323cfad46a3b4a471233":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","5270fb4f55a1b77663dda53cb8090c083f0a23b3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","01e5948db9a07144112d2f08f28ca2e3cd880348"],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":["135621f3a0670a9394eb563224a3b76cc4dddc0f","5270fb4f55a1b77663dda53cb8090c083f0a23b3"],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["7358158aa96de7ba4e78d7fbee9f9fa41320173d"],"5270fb4f55a1b77663dda53cb8090c083f0a23b3":["01e5948db9a07144112d2f08f28ca2e3cd880348"],"45669a651c970812a680841b97a77cce06af559f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","01e5948db9a07144112d2f08f28ca2e3cd880348"],"34ce7c842452c79b12c45a8feb64e4597c7110e8":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["34ce7c842452c79b12c45a8feb64e4597c7110e8"]},"commit2Childs":{"7358158aa96de7ba4e78d7fbee9f9fa41320173d":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"],"01e5948db9a07144112d2f08f28ca2e3cd880348":["135621f3a0670a9394eb563224a3b76cc4dddc0f","5270fb4f55a1b77663dda53cb8090c083f0a23b3","45669a651c970812a680841b97a77cce06af559f"],"a3776dccca01c11e7046323cfad46a3b4a471233":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["01e5948db9a07144112d2f08f28ca2e3cd880348","a3776dccca01c11e7046323cfad46a3b4a471233","135621f3a0670a9394eb563224a3b76cc4dddc0f","45669a651c970812a680841b97a77cce06af559f"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["c700f8d0842d3e52bb2bdfbfdc046a137e836edb"],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":[],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["34ce7c842452c79b12c45a8feb64e4597c7110e8"],"5270fb4f55a1b77663dda53cb8090c083f0a23b3":["7358158aa96de7ba4e78d7fbee9f9fa41320173d","a3776dccca01c11e7046323cfad46a3b4a471233","c700f8d0842d3e52bb2bdfbfdc046a137e836edb"],"45669a651c970812a680841b97a77cce06af559f":[],"34ce7c842452c79b12c45a8feb64e4597c7110e8":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a3776dccca01c11e7046323cfad46a3b4a471233","c700f8d0842d3e52bb2bdfbfdc046a137e836edb","45669a651c970812a680841b97a77cce06af559f","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}