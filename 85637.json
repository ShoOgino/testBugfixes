{"path":"lucene/src/java/org/apache/lucene/search/ParallelMultiSearcher#createDocFrequencyMap(Set[Term]).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/ParallelMultiSearcher#createDocFrequencyMap(Set[Term]).mjava","pathOld":"src/java/org/apache/lucene/search/ParallelMultiSearcher#createDocFrequencyMap(Set[Term]).mjava","sourceNew":"  @Override\n  HashMap<Term, Integer> createDocFrequencyMap(Set<Term> terms) throws IOException {\n    final Term[] allTermsArray = terms.toArray(new Term[terms.size()]);\n    final int[] aggregatedDocFreqs = new int[terms.size()];\n    final ArrayList<Future<int[]>> searchThreads = new ArrayList<Future<int[]>>(searchables.length);\n    for (Searchable searchable : searchables) {\n      final Future<int[]> future = executor.submit(\n          new DocumentFrequencyCallable(searchable, allTermsArray));\n      searchThreads.add(future);\n    }\n    foreach(new AggregateDocFrequency(aggregatedDocFreqs), searchThreads);\n\n    final HashMap<Term,Integer> dfMap = new HashMap<Term,Integer>();\n    for(int i=0; i<allTermsArray.length; i++) {\n      dfMap.put(allTermsArray[i], Integer.valueOf(aggregatedDocFreqs[i]));\n    }\n    return dfMap;\n  }\n\n","sourceOld":"  @Override\n  HashMap<Term, Integer> createDocFrequencyMap(Set<Term> terms) throws IOException {\n    final Term[] allTermsArray = terms.toArray(new Term[terms.size()]);\n    final int[] aggregatedDocFreqs = new int[terms.size()];\n    final ArrayList<Future<int[]>> searchThreads = new ArrayList<Future<int[]>>(searchables.length);\n    for (Searchable searchable : searchables) {\n      final Future<int[]> future = executor.submit(\n          new DocumentFrequencyCallable(searchable, allTermsArray));\n      searchThreads.add(future);\n    }\n    foreach(new AggregateDocFrequency(aggregatedDocFreqs), searchThreads);\n\n    final HashMap<Term,Integer> dfMap = new HashMap<Term,Integer>();\n    for(int i=0; i<allTermsArray.length; i++) {\n      dfMap.put(allTermsArray[i], Integer.valueOf(aggregatedDocFreqs[i]));\n    }\n    return dfMap;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0d6aa47ee944540caf43af80e17bbd289b949ae4","date":1276190873,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/ParallelMultiSearcher#createDocFrequencyMap(Set[Term]).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/ParallelMultiSearcher#createDocFrequencyMap(Set[Term]).mjava","sourceNew":"  @Override\n  HashMap<Term, Integer> createDocFrequencyMap(Set<Term> terms) throws IOException {\n    final Term[] allTermsArray = terms.toArray(new Term[terms.size()]);\n    final int[] aggregatedDocFreqs = new int[terms.size()];\n    final ExecutionHelper<int[]> runner = new ExecutionHelper<int[]>(executor);\n    for (Searchable searchable : searchables) {\n      runner.submit(\n          new DocumentFrequencyCallable(searchable, allTermsArray));\n    }\n    final int docFreqLen = aggregatedDocFreqs.length;\n    for (final int[] docFreqs : runner) {\n      for(int i=0; i < docFreqLen; i++){\n        aggregatedDocFreqs[i] += docFreqs[i];\n      }\n    }\n\n    final HashMap<Term,Integer> dfMap = new HashMap<Term,Integer>();\n    for(int i=0; i<allTermsArray.length; i++) {\n      dfMap.put(allTermsArray[i], Integer.valueOf(aggregatedDocFreqs[i]));\n    }\n    return dfMap;\n  }\n\n","sourceOld":"  @Override\n  HashMap<Term, Integer> createDocFrequencyMap(Set<Term> terms) throws IOException {\n    final Term[] allTermsArray = terms.toArray(new Term[terms.size()]);\n    final int[] aggregatedDocFreqs = new int[terms.size()];\n    final ArrayList<Future<int[]>> searchThreads = new ArrayList<Future<int[]>>(searchables.length);\n    for (Searchable searchable : searchables) {\n      final Future<int[]> future = executor.submit(\n          new DocumentFrequencyCallable(searchable, allTermsArray));\n      searchThreads.add(future);\n    }\n    foreach(new AggregateDocFrequency(aggregatedDocFreqs), searchThreads);\n\n    final HashMap<Term,Integer> dfMap = new HashMap<Term,Integer>();\n    for(int i=0; i<allTermsArray.length; i++) {\n      dfMap.put(allTermsArray[i], Integer.valueOf(aggregatedDocFreqs[i]));\n    }\n    return dfMap;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8b241ea5e635d896cc0af83cd96ffd0322e0aba7","date":1294226200,"type":4,"author":"Michael McCandless","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/search/ParallelMultiSearcher#createDocFrequencyMap(Set[Term]).mjava","sourceNew":null,"sourceOld":"  @Override\n  HashMap<Term, Integer> createDocFrequencyMap(Set<Term> terms) throws IOException {\n    final Term[] allTermsArray = terms.toArray(new Term[terms.size()]);\n    final int[] aggregatedDocFreqs = new int[terms.size()];\n    final ExecutionHelper<int[]> runner = new ExecutionHelper<int[]>(executor);\n    for (Searchable searchable : searchables) {\n      runner.submit(\n          new DocumentFrequencyCallable(searchable, allTermsArray));\n    }\n    final int docFreqLen = aggregatedDocFreqs.length;\n    for (final int[] docFreqs : runner) {\n      for(int i=0; i < docFreqLen; i++){\n        aggregatedDocFreqs[i] += docFreqs[i];\n      }\n    }\n\n    final HashMap<Term,Integer> dfMap = new HashMap<Term,Integer>();\n    for(int i=0; i<allTermsArray.length; i++) {\n      dfMap.put(allTermsArray[i], Integer.valueOf(aggregatedDocFreqs[i]));\n    }\n    return dfMap;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70ad682703b8585f5d0a637efec044d57ec05efb","date":1294259117,"type":4,"author":"Simon Willnauer","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/search/ParallelMultiSearcher#createDocFrequencyMap(Set[Term]).mjava","sourceNew":null,"sourceOld":"  @Override\n  HashMap<Term, Integer> createDocFrequencyMap(Set<Term> terms) throws IOException {\n    final Term[] allTermsArray = terms.toArray(new Term[terms.size()]);\n    final int[] aggregatedDocFreqs = new int[terms.size()];\n    final ExecutionHelper<int[]> runner = new ExecutionHelper<int[]>(executor);\n    for (Searchable searchable : searchables) {\n      runner.submit(\n          new DocumentFrequencyCallable(searchable, allTermsArray));\n    }\n    final int docFreqLen = aggregatedDocFreqs.length;\n    for (final int[] docFreqs : runner) {\n      for(int i=0; i < docFreqLen; i++){\n        aggregatedDocFreqs[i] += docFreqs[i];\n      }\n    }\n\n    final HashMap<Term,Integer> dfMap = new HashMap<Term,Integer>();\n    for(int i=0; i<allTermsArray.length; i++) {\n      dfMap.put(allTermsArray[i], Integer.valueOf(aggregatedDocFreqs[i]));\n    }\n    return dfMap;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":4,"author":"Michael Busch","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/search/ParallelMultiSearcher#createDocFrequencyMap(Set[Term]).mjava","sourceNew":null,"sourceOld":"  @Override\n  HashMap<Term, Integer> createDocFrequencyMap(Set<Term> terms) throws IOException {\n    final Term[] allTermsArray = terms.toArray(new Term[terms.size()]);\n    final int[] aggregatedDocFreqs = new int[terms.size()];\n    final ExecutionHelper<int[]> runner = new ExecutionHelper<int[]>(executor);\n    for (Searchable searchable : searchables) {\n      runner.submit(\n          new DocumentFrequencyCallable(searchable, allTermsArray));\n    }\n    final int docFreqLen = aggregatedDocFreqs.length;\n    for (final int[] docFreqs : runner) {\n      for(int i=0; i < docFreqLen; i++){\n        aggregatedDocFreqs[i] += docFreqs[i];\n      }\n    }\n\n    final HashMap<Term,Integer> dfMap = new HashMap<Term,Integer>();\n    for(int i=0; i<allTermsArray.length; i++) {\n      dfMap.put(allTermsArray[i], Integer.valueOf(aggregatedDocFreqs[i]));\n    }\n    return dfMap;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"70ad682703b8585f5d0a637efec044d57ec05efb":["0d6aa47ee944540caf43af80e17bbd289b949ae4","8b241ea5e635d896cc0af83cd96ffd0322e0aba7"],"8b241ea5e635d896cc0af83cd96ffd0322e0aba7":["0d6aa47ee944540caf43af80e17bbd289b949ae4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0d6aa47ee944540caf43af80e17bbd289b949ae4":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["0d6aa47ee944540caf43af80e17bbd289b949ae4","8b241ea5e635d896cc0af83cd96ffd0322e0aba7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["8b241ea5e635d896cc0af83cd96ffd0322e0aba7"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"70ad682703b8585f5d0a637efec044d57ec05efb":[],"8b241ea5e635d896cc0af83cd96ffd0322e0aba7":["70ad682703b8585f5d0a637efec044d57ec05efb","868da859b43505d9d2a023bfeae6dd0c795f5295","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"0d6aa47ee944540caf43af80e17bbd289b949ae4":["70ad682703b8585f5d0a637efec044d57ec05efb","8b241ea5e635d896cc0af83cd96ffd0322e0aba7","868da859b43505d9d2a023bfeae6dd0c795f5295"],"868da859b43505d9d2a023bfeae6dd0c795f5295":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["0d6aa47ee944540caf43af80e17bbd289b949ae4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["70ad682703b8585f5d0a637efec044d57ec05efb","868da859b43505d9d2a023bfeae6dd0c795f5295","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}