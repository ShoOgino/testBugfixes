{"path":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","pathOld":"src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","sourceNew":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (int i = 0; i < core.fieldInfos.size(); i++) {\n      FieldInfo fi = core.fieldInfos.fieldInfo(i);\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normSeek = 0;\n          normInput = d.openInput(fileName);\n        }\n\n        norms.put(fi.name, new Norm(normInput, fi.number, normSeek));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","sourceOld":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (int i = 0; i < core.fieldInfos.size(); i++) {\n      FieldInfo fi = core.fieldInfos.fieldInfo(i);\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normSeek = 0;\n          normInput = d.openInput(fileName);\n        }\n\n        norms.put(fi.name, new Norm(normInput, fi.number, normSeek));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b0c7a8f7304b75b1528814c5820fa23a96816c27","date":1298314239,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","sourceNew":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normSeek = 0;\n          normInput = d.openInput(fileName);\n        }\n\n        norms.put(fi.name, new Norm(normInput, fi.number, normSeek));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","sourceOld":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (int i = 0; i < core.fieldInfos.size(); i++) {\n      FieldInfo fi = core.fieldInfos.fieldInfo(i);\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normSeek = 0;\n          normInput = d.openInput(fileName);\n        }\n\n        norms.put(fi.name, new Norm(normInput, fi.number, normSeek));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","sourceNew":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normSeek = 0;\n          normInput = d.openInput(fileName);\n        }\n\n        norms.put(fi.name, new Norm(normInput, fi.number, normSeek));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","sourceOld":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (int i = 0; i < core.fieldInfos.size(); i++) {\n      FieldInfo fi = core.fieldInfos.fieldInfo(i);\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normSeek = 0;\n          normInput = d.openInput(fileName);\n        }\n\n        norms.put(fi.name, new Norm(normInput, fi.number, normSeek));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"14ec33385f6fbb6ce172882d14605790418a5d31","date":1298910796,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","sourceNew":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (int i = 0; i < core.fieldInfos.size(); i++) {\n      FieldInfo fi = core.fieldInfos.fieldInfo(i);\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normSeek = 0;\n          normInput = d.openInput(fileName);\n        }\n\n        norms.put(fi.name, new Norm(normInput, fi.number, normSeek));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","sourceOld":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normSeek = 0;\n          normInput = d.openInput(fileName);\n        }\n\n        norms.put(fi.name, new Norm(normInput, fi.number, normSeek));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1224a4027481acce15495b03bce9b48b93b42722","date":1300792329,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","sourceNew":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normSeek = 0;\n          normInput = d.openInput(fileName);\n        }\n\n        norms.put(fi.name, new Norm(normInput, fi.number, normSeek));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","sourceOld":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (int i = 0; i < core.fieldInfos.size(); i++) {\n      FieldInfo fi = core.fieldInfos.fieldInfo(i);\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normSeek = 0;\n          normInput = d.openInput(fileName);\n        }\n\n        norms.put(fi.name, new Norm(normInput, fi.number, normSeek));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d619839baa8ce5503e496b94a9e42ad6f079293f","date":1301309428,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","sourceNew":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normSeek = 0;\n          normInput = d.openInput(fileName);\n        }\n\n        norms.put(fi.name, new Norm(normInput, fi.number, normSeek));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","sourceOld":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (int i = 0; i < core.fieldInfos.size(); i++) {\n      FieldInfo fi = core.fieldInfos.fieldInfo(i);\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normSeek = 0;\n          normInput = d.openInput(fileName);\n        }\n\n        norms.put(fi.name, new Norm(normInput, fi.number, normSeek));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c7843edbf325fe98ea91515ee3ff56ab40a9594d","date":1305742986,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","sourceNew":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normInput = d.openInput(fileName);\n          // if the segment was created in 3.2 or after, we wrote the header for sure,\n          // and don't need to do the sketchy file size check. otherwise, we check \n          // if the size is exactly equal to maxDoc to detect a headerless file.\n          // NOTE: remove this check in Lucene 5.0!\n          String version = si.getVersion();\n          final boolean isUnversioned = \n            (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n            && normInput.length() == maxDoc();\n          if (isUnversioned) {\n            normSeek = 0;\n          } else {\n            normSeek = SegmentMerger.NORMS_HEADER.length;\n          }\n        }\n\n        norms.put(fi.name, new Norm(normInput, fi.number, normSeek));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","sourceOld":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normSeek = 0;\n          normInput = d.openInput(fileName);\n        }\n\n        norms.put(fi.name, new Norm(normInput, fi.number, normSeek));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","bugFix":["111f5f9f92c974cb15ad5a47e0caec190ca207b7"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8b5e0eebe355b14693e24007d721da78a79d8170","date":1305898401,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","sourceNew":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normInput = d.openInput(fileName);\n          // if the segment was created in 3.2 or after, we wrote the header for sure,\n          // and don't need to do the sketchy file size check. otherwise, we check \n          // if the size is exactly equal to maxDoc to detect a headerless file.\n          // NOTE: remove this check in Lucene 5.0!\n          String version = si.getVersion();\n          final boolean isUnversioned = \n            (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n            && normInput.length() == maxDoc();\n          if (isUnversioned) {\n            normSeek = 0;\n          } else {\n            normSeek = SegmentMerger.NORMS_HEADER.length;\n          }\n        }\n\n        norms.put(fi.name, new SegmentNorms(normInput, fi.number, normSeek, this));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","sourceOld":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normInput = d.openInput(fileName);\n          // if the segment was created in 3.2 or after, we wrote the header for sure,\n          // and don't need to do the sketchy file size check. otherwise, we check \n          // if the size is exactly equal to maxDoc to detect a headerless file.\n          // NOTE: remove this check in Lucene 5.0!\n          String version = si.getVersion();\n          final boolean isUnversioned = \n            (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n            && normInput.length() == maxDoc();\n          if (isUnversioned) {\n            normSeek = 0;\n          } else {\n            normSeek = SegmentMerger.NORMS_HEADER.length;\n          }\n        }\n\n        norms.put(fi.name, new Norm(normInput, fi.number, normSeek));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","sourceNew":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normInput = d.openInput(fileName);\n          // if the segment was created in 3.2 or after, we wrote the header for sure,\n          // and don't need to do the sketchy file size check. otherwise, we check \n          // if the size is exactly equal to maxDoc to detect a headerless file.\n          // NOTE: remove this check in Lucene 5.0!\n          String version = si.getVersion();\n          final boolean isUnversioned = \n            (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n            && normInput.length() == maxDoc();\n          if (isUnversioned) {\n            normSeek = 0;\n          } else {\n            normSeek = SegmentMerger.NORMS_HEADER.length;\n          }\n        }\n\n        norms.put(fi.name, new SegmentNorms(normInput, fi.number, normSeek, this));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","sourceOld":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normSeek = 0;\n          normInput = d.openInput(fileName);\n        }\n\n        norms.put(fi.name, new Norm(normInput, fi.number, normSeek));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5c698c0cb88bac4bcd36a1b1001a0c6a2163ea2a","date":1306150983,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","sourceNew":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normInput = d.openInput(fileName);\n          // if the segment was created in 3.2 or after, we wrote the header for sure,\n          // and don't need to do the sketchy file size check. otherwise, we check \n          // if the size is exactly equal to maxDoc to detect a headerless file.\n          // NOTE: remove this check in Lucene 5.0!\n          String version = si.getVersion();\n          final boolean isUnversioned = \n            (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n            && normInput.length() == maxDoc();\n          if (isUnversioned) {\n            normSeek = 0;\n          } else {\n            normSeek = SegmentMerger.NORMS_HEADER.length;\n          }\n        }\n\n        norms.put(fi.name, new SegmentNorms(normInput, fi.number, normSeek, this));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","sourceOld":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normSeek = 0;\n          normInput = d.openInput(fileName);\n        }\n\n        norms.put(fi.name, new Norm(normInput, fi.number, normSeek));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8b76d8c77c9c069618078344054ff4c6a3374f80","date":1306168582,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","sourceNew":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentNorms.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normInput = d.openInput(fileName);\n          // if the segment was created in 3.2 or after, we wrote the header for sure,\n          // and don't need to do the sketchy file size check. otherwise, we check \n          // if the size is exactly equal to maxDoc to detect a headerless file.\n          // NOTE: remove this check in Lucene 5.0!\n          String version = si.getVersion();\n          final boolean isUnversioned = \n            (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n            && normInput.length() == maxDoc();\n          if (isUnversioned) {\n            normSeek = 0;\n          } else {\n            normSeek = SegmentNorms.NORMS_HEADER.length;\n          }\n        }\n\n        norms.put(fi.name, new SegmentNorms(normInput, fi.number, normSeek, this));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","sourceOld":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normInput = d.openInput(fileName);\n          // if the segment was created in 3.2 or after, we wrote the header for sure,\n          // and don't need to do the sketchy file size check. otherwise, we check \n          // if the size is exactly equal to maxDoc to detect a headerless file.\n          // NOTE: remove this check in Lucene 5.0!\n          String version = si.getVersion();\n          final boolean isUnversioned = \n            (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n            && normInput.length() == maxDoc();\n          if (isUnversioned) {\n            normSeek = 0;\n          } else {\n            normSeek = SegmentMerger.NORMS_HEADER.length;\n          }\n        }\n\n        norms.put(fi.name, new SegmentNorms(normInput, fi.number, normSeek, this));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","date":1306767085,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","sourceNew":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentNorms.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normInput = d.openInput(fileName);\n          // if the segment was created in 3.2 or after, we wrote the header for sure,\n          // and don't need to do the sketchy file size check. otherwise, we check \n          // if the size is exactly equal to maxDoc to detect a headerless file.\n          // NOTE: remove this check in Lucene 5.0!\n          String version = si.getVersion();\n          final boolean isUnversioned = \n            (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n            && normInput.length() == maxDoc();\n          if (isUnversioned) {\n            normSeek = 0;\n          } else {\n            normSeek = SegmentNorms.NORMS_HEADER.length;\n          }\n        }\n\n        norms.put(fi.name, new SegmentNorms(normInput, fi.number, normSeek, this));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","sourceOld":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normInput = d.openInput(fileName);\n          // if the segment was created in 3.2 or after, we wrote the header for sure,\n          // and don't need to do the sketchy file size check. otherwise, we check \n          // if the size is exactly equal to maxDoc to detect a headerless file.\n          // NOTE: remove this check in Lucene 5.0!\n          String version = si.getVersion();\n          final boolean isUnversioned = \n            (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n            && normInput.length() == maxDoc();\n          if (isUnversioned) {\n            normSeek = 0;\n          } else {\n            normSeek = SegmentMerger.NORMS_HEADER.length;\n          }\n        }\n\n        norms.put(fi.name, new SegmentNorms(normInput, fi.number, normSeek, this));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2e10cb22a8bdb44339e282925a29182bb2f3174d","date":1306841137,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","sourceNew":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentNorms.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normInput = d.openInput(fileName);\n          // if the segment was created in 3.2 or after, we wrote the header for sure,\n          // and don't need to do the sketchy file size check. otherwise, we check \n          // if the size is exactly equal to maxDoc to detect a headerless file.\n          // NOTE: remove this check in Lucene 5.0!\n          String version = si.getVersion();\n          final boolean isUnversioned = \n            (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n            && normInput.length() == maxDoc();\n          if (isUnversioned) {\n            normSeek = 0;\n          } else {\n            normSeek = SegmentNorms.NORMS_HEADER.length;\n          }\n        }\n\n        norms.put(fi.name, new SegmentNorms(normInput, fi.number, normSeek, this));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","sourceOld":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normInput = d.openInput(fileName);\n          // if the segment was created in 3.2 or after, we wrote the header for sure,\n          // and don't need to do the sketchy file size check. otherwise, we check \n          // if the size is exactly equal to maxDoc to detect a headerless file.\n          // NOTE: remove this check in Lucene 5.0!\n          String version = si.getVersion();\n          final boolean isUnversioned = \n            (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n            && normInput.length() == maxDoc();\n          if (isUnversioned) {\n            normSeek = 0;\n          } else {\n            normSeek = SegmentMerger.NORMS_HEADER.length;\n          }\n        }\n\n        norms.put(fi.name, new SegmentNorms(normInput, fi.number, normSeek, this));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"639c36565ce03aed5b0fce7c9e4448e53a1f7efd","date":1308580104,"type":5,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,IOContext).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","sourceNew":"  private void openNorms(Directory cfsDir, IOContext context) throws IOException {\n    long nextNormSeek = SegmentNorms.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, context);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normInput = d.openInput(fileName, context);\n          // if the segment was created in 3.2 or after, we wrote the header for sure,\n          // and don't need to do the sketchy file size check. otherwise, we check \n          // if the size is exactly equal to maxDoc to detect a headerless file.\n          // NOTE: remove this check in Lucene 5.0!\n          String version = si.getVersion();\n          final boolean isUnversioned = \n            (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n            && normInput.length() == maxDoc();\n          if (isUnversioned) {\n            normSeek = 0;\n          } else {\n            normSeek = SegmentNorms.NORMS_HEADER.length;\n          }\n        }\n\n        norms.put(fi.name, new SegmentNorms(normInput, fi.number, normSeek, this));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","sourceOld":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentNorms.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normInput = d.openInput(fileName);\n          // if the segment was created in 3.2 or after, we wrote the header for sure,\n          // and don't need to do the sketchy file size check. otherwise, we check \n          // if the size is exactly equal to maxDoc to detect a headerless file.\n          // NOTE: remove this check in Lucene 5.0!\n          String version = si.getVersion();\n          final boolean isUnversioned = \n            (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n            && normInput.length() == maxDoc();\n          if (isUnversioned) {\n            normSeek = 0;\n          } else {\n            normSeek = SegmentNorms.NORMS_HEADER.length;\n          }\n        }\n\n        norms.put(fi.name, new SegmentNorms(normInput, fi.number, normSeek, this));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ddc4c914be86e34b54f70023f45a60fa7f04e929","date":1310115160,"type":5,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,IOContext).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","sourceNew":"  private void openNorms(Directory cfsDir, IOContext context) throws IOException {\n    long nextNormSeek = SegmentNorms.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, context);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normInput = d.openInput(fileName, context);\n          // if the segment was created in 3.2 or after, we wrote the header for sure,\n          // and don't need to do the sketchy file size check. otherwise, we check \n          // if the size is exactly equal to maxDoc to detect a headerless file.\n          // NOTE: remove this check in Lucene 5.0!\n          String version = si.getVersion();\n          final boolean isUnversioned = \n            (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n            && normInput.length() == maxDoc();\n          if (isUnversioned) {\n            normSeek = 0;\n          } else {\n            normSeek = SegmentNorms.NORMS_HEADER.length;\n          }\n        }\n\n        norms.put(fi.name, new SegmentNorms(normInput, fi.number, normSeek, this));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","sourceOld":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentNorms.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normInput = d.openInput(fileName);\n          // if the segment was created in 3.2 or after, we wrote the header for sure,\n          // and don't need to do the sketchy file size check. otherwise, we check \n          // if the size is exactly equal to maxDoc to detect a headerless file.\n          // NOTE: remove this check in Lucene 5.0!\n          String version = si.getVersion();\n          final boolean isUnversioned = \n            (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n            && normInput.length() == maxDoc();\n          if (isUnversioned) {\n            normSeek = 0;\n          } else {\n            normSeek = SegmentNorms.NORMS_HEADER.length;\n          }\n        }\n\n        norms.put(fi.name, new SegmentNorms(normInput, fi.number, normSeek, this));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5d004d0e0b3f65bb40da76d476d659d7888270e8","date":1310158940,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,IOContext).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","sourceNew":"  private void openNorms(Directory cfsDir, IOContext context) throws IOException {\n    long nextNormSeek = SegmentNorms.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, context);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normInput = d.openInput(fileName, context);\n          // if the segment was created in 3.2 or after, we wrote the header for sure,\n          // and don't need to do the sketchy file size check. otherwise, we check \n          // if the size is exactly equal to maxDoc to detect a headerless file.\n          // NOTE: remove this check in Lucene 5.0!\n          String version = si.getVersion();\n          final boolean isUnversioned = \n            (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n            && normInput.length() == maxDoc();\n          if (isUnversioned) {\n            normSeek = 0;\n          } else {\n            normSeek = SegmentNorms.NORMS_HEADER.length;\n          }\n        }\n\n        norms.put(fi.name, new SegmentNorms(normInput, fi.number, normSeek, this));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","sourceOld":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentNorms.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normInput = d.openInput(fileName);\n          // if the segment was created in 3.2 or after, we wrote the header for sure,\n          // and don't need to do the sketchy file size check. otherwise, we check \n          // if the size is exactly equal to maxDoc to detect a headerless file.\n          // NOTE: remove this check in Lucene 5.0!\n          String version = si.getVersion();\n          final boolean isUnversioned = \n            (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n            && normInput.length() == maxDoc();\n          if (isUnversioned) {\n            normSeek = 0;\n          } else {\n            normSeek = SegmentNorms.NORMS_HEADER.length;\n          }\n        }\n\n        norms.put(fi.name, new SegmentNorms(normInput, fi.number, normSeek, this));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"8b76d8c77c9c069618078344054ff4c6a3374f80":["8b5e0eebe355b14693e24007d721da78a79d8170"],"5c698c0cb88bac4bcd36a1b1001a0c6a2163ea2a":["d619839baa8ce5503e496b94a9e42ad6f079293f","8b5e0eebe355b14693e24007d721da78a79d8170"],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["8b76d8c77c9c069618078344054ff4c6a3374f80"],"8b5e0eebe355b14693e24007d721da78a79d8170":["c7843edbf325fe98ea91515ee3ff56ab40a9594d"],"14ec33385f6fbb6ce172882d14605790418a5d31":["b0c7a8f7304b75b1528814c5820fa23a96816c27"],"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":["a3776dccca01c11e7046323cfad46a3b4a471233","8b76d8c77c9c069618078344054ff4c6a3374f80"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["9454a6510e2db155fb01faa5c049b06ece95fab9","1224a4027481acce15495b03bce9b48b93b42722"],"b0c7a8f7304b75b1528814c5820fa23a96816c27":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a3776dccca01c11e7046323cfad46a3b4a471233":["1224a4027481acce15495b03bce9b48b93b42722","8b5e0eebe355b14693e24007d721da78a79d8170"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"5d004d0e0b3f65bb40da76d476d659d7888270e8":["5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","ddc4c914be86e34b54f70023f45a60fa7f04e929"],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["8b76d8c77c9c069618078344054ff4c6a3374f80","639c36565ce03aed5b0fce7c9e4448e53a1f7efd"],"c7843edbf325fe98ea91515ee3ff56ab40a9594d":["1224a4027481acce15495b03bce9b48b93b42722"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["9454a6510e2db155fb01faa5c049b06ece95fab9","b0c7a8f7304b75b1528814c5820fa23a96816c27"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["ddc4c914be86e34b54f70023f45a60fa7f04e929"],"1224a4027481acce15495b03bce9b48b93b42722":["14ec33385f6fbb6ce172882d14605790418a5d31"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"2e10cb22a8bdb44339e282925a29182bb2f3174d":["5c698c0cb88bac4bcd36a1b1001a0c6a2163ea2a","8b76d8c77c9c069618078344054ff4c6a3374f80"]},"commit2Childs":{"8b76d8c77c9c069618078344054ff4c6a3374f80":["639c36565ce03aed5b0fce7c9e4448e53a1f7efd","5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","ddc4c914be86e34b54f70023f45a60fa7f04e929","2e10cb22a8bdb44339e282925a29182bb2f3174d"],"5c698c0cb88bac4bcd36a1b1001a0c6a2163ea2a":["2e10cb22a8bdb44339e282925a29182bb2f3174d"],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["ddc4c914be86e34b54f70023f45a60fa7f04e929"],"8b5e0eebe355b14693e24007d721da78a79d8170":["8b76d8c77c9c069618078344054ff4c6a3374f80","5c698c0cb88bac4bcd36a1b1001a0c6a2163ea2a","a3776dccca01c11e7046323cfad46a3b4a471233"],"14ec33385f6fbb6ce172882d14605790418a5d31":["1224a4027481acce15495b03bce9b48b93b42722"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["5c698c0cb88bac4bcd36a1b1001a0c6a2163ea2a"],"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":["5d004d0e0b3f65bb40da76d476d659d7888270e8"],"b0c7a8f7304b75b1528814c5820fa23a96816c27":["14ec33385f6fbb6ce172882d14605790418a5d31","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"a3776dccca01c11e7046323cfad46a3b4a471233":["5128b7b3b73fedff05fdc5ea2e6be53c1020bb91"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"5d004d0e0b3f65bb40da76d476d659d7888270e8":[],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["5d004d0e0b3f65bb40da76d476d659d7888270e8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c7843edbf325fe98ea91515ee3ff56ab40a9594d":["8b5e0eebe355b14693e24007d721da78a79d8170"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["d619839baa8ce5503e496b94a9e42ad6f079293f","b0c7a8f7304b75b1528814c5820fa23a96816c27","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"1224a4027481acce15495b03bce9b48b93b42722":["d619839baa8ce5503e496b94a9e42ad6f079293f","a3776dccca01c11e7046323cfad46a3b4a471233","c7843edbf325fe98ea91515ee3ff56ab40a9594d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"2e10cb22a8bdb44339e282925a29182bb2f3174d":[]},"heads":["5d004d0e0b3f65bb40da76d476d659d7888270e8","bde51b089eb7f86171eb3406e38a274743f9b7ac","cd5edd1f2b162a5cfa08efd17851a07373a96817","2e10cb22a8bdb44339e282925a29182bb2f3174d"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}