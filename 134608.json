{"path":"lucene/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","commits":[{"id":"d14e8d18c0e3970c20354dbeeb49da11bd587fbd","date":1321041051,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOptimize#testOptimizeTempSpaceUsage().mjava","sourceNew":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(10).setMergePolicy(newLogMergePolicy()));\n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    final int termIndexInterval = writer.getConfig().getTermIndexInterval();\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage\");\n    }\n    long startDiskUsage = 0;\n    String[] files = dir.listAll();\n    for(int i=0;i<files.length;i++) {\n      startDiskUsage += dir.fileLength(files[i]);\n      if (VERBOSE) {\n        System.out.println(files[i] + \": \" + dir.fileLength(files[i]));\n      }\n    }\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    // Import to use same term index interval else a\n    // smaller one here could increase the disk usage and\n    // cause a false failure:\n    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.APPEND).setTermIndexInterval(termIndexInterval).setMergePolicy(newLogMergePolicy()));\n    writer.forceMerge(1);\n    writer.close();\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \" + startDiskUsage + \" bytes; max temp usage was \" + maxDiskUsage + \" but should have been \" + (4*startDiskUsage) + \" (= 4X starting usage)\",\n               maxDiskUsage <= 4*startDiskUsage);\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure optimize doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testOptimizeTempSpaceUsage() throws IOException {\n\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(10).setMergePolicy(newLogMergePolicy()));\n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    final int termIndexInterval = writer.getConfig().getTermIndexInterval();\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage\");\n    }\n    long startDiskUsage = 0;\n    String[] files = dir.listAll();\n    for(int i=0;i<files.length;i++) {\n      startDiskUsage += dir.fileLength(files[i]);\n      if (VERBOSE) {\n        System.out.println(files[i] + \": \" + dir.fileLength(files[i]));\n      }\n    }\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    // Import to use same term index interval else a\n    // smaller one here could increase the disk usage and\n    // cause a false failure:\n    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.APPEND).setTermIndexInterval(termIndexInterval).setMergePolicy(newLogMergePolicy()));\n    writer.optimize();\n    writer.close();\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"optimize used too much temporary space: starting usage was \" + startDiskUsage + \" bytes; max temp usage was \" + maxDiskUsage + \" but should have been \" + (4*startDiskUsage) + \" (= 4X starting usage)\",\n               maxDiskUsage <= 4*startDiskUsage);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","sourceNew":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(10).setMergePolicy(newLogMergePolicy()));\n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    final int termIndexInterval = writer.getConfig().getTermIndexInterval();\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage\");\n    }\n    long startDiskUsage = 0;\n    String[] files = dir.listAll();\n    for(int i=0;i<files.length;i++) {\n      startDiskUsage += dir.fileLength(files[i]);\n      if (VERBOSE) {\n        System.out.println(files[i] + \": \" + dir.fileLength(files[i]));\n      }\n    }\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    // Import to use same term index interval else a\n    // smaller one here could increase the disk usage and\n    // cause a false failure:\n    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.APPEND).setTermIndexInterval(termIndexInterval).setMergePolicy(newLogMergePolicy()));\n    writer.forceMerge(1);\n    writer.close();\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \" + startDiskUsage + \" bytes; max temp usage was \" + maxDiskUsage + \" but should have been \" + (4*startDiskUsage) + \" (= 4X starting usage)\",\n               maxDiskUsage <= 4*startDiskUsage);\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(10).setMergePolicy(newLogMergePolicy()));\n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    final int termIndexInterval = writer.getConfig().getTermIndexInterval();\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage\");\n    }\n    long startDiskUsage = 0;\n    String[] files = dir.listAll();\n    for(int i=0;i<files.length;i++) {\n      startDiskUsage += dir.fileLength(files[i]);\n      if (VERBOSE) {\n        System.out.println(files[i] + \": \" + dir.fileLength(files[i]));\n      }\n    }\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    // Import to use same term index interval else a\n    // smaller one here could increase the disk usage and\n    // cause a false failure:\n    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.APPEND).setTermIndexInterval(termIndexInterval).setMergePolicy(newLogMergePolicy()));\n    writer.forceMerge(1);\n    writer.close();\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \" + startDiskUsage + \" bytes; max temp usage was \" + maxDiskUsage + \" but should have been \" + (4*startDiskUsage) + \" (= 4X starting usage)\",\n               maxDiskUsage <= 4*startDiskUsage);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}