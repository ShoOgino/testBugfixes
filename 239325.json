{"path":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#build().mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#build().mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#build().mjava","sourceNew":"    /**\n     * Builds an {@link SynonymMap} and returns it.\n     */\n    public SynonymMap build() throws IOException {\n      ByteSequenceOutputs outputs = ByteSequenceOutputs.getSingleton();\n      // TODO: are we using the best sharing options?\n      org.apache.lucene.util.fst.Builder<BytesRef> builder = \n        new org.apache.lucene.util.fst.Builder<BytesRef>(FST.INPUT_TYPE.BYTE4, outputs);\n      \n      BytesRef scratch = new BytesRef(64);\n      ByteArrayDataOutput scratchOutput = new ByteArrayDataOutput();\n\n      final Set<Integer> dedupSet;\n\n      if (dedup) {\n        dedupSet = new HashSet<Integer>();\n      } else {\n        dedupSet = null;\n      }\n\n      final byte[] spare = new byte[5];\n      \n      Set<CharsRef> keys = workingSet.keySet();\n      CharsRef sortedKeys[] = keys.toArray(new CharsRef[keys.size()]);\n      Arrays.sort(sortedKeys, CharsRef.getUTF16SortedAsUTF8Comparator());\n\n      final IntsRef scratchIntsRef = new IntsRef();\n      \n      //System.out.println(\"fmap.build\");\n      for (int keyIdx = 0; keyIdx < sortedKeys.length; keyIdx++) {\n        CharsRef input = sortedKeys[keyIdx];\n        MapEntry output = workingSet.get(input);\n\n        int numEntries = output.ords.size();\n        // output size, assume the worst case\n        int estimatedSize = 5 + numEntries * 5; // numEntries + one ord for each entry\n        \n        scratch.grow(estimatedSize);\n        scratchOutput.reset(scratch.bytes, scratch.offset, scratch.bytes.length);\n        assert scratch.offset == 0;\n\n        // now write our output data:\n        int count = 0;\n        for (int i = 0; i < numEntries; i++) {\n          if (dedupSet != null) {\n            // box once\n            final Integer ent = output.ords.get(i);\n            if (dedupSet.contains(ent)) {\n              continue;\n            }\n            dedupSet.add(ent);\n          }\n          scratchOutput.writeVInt(output.ords.get(i));   \n          count++;\n        }\n\n        final int pos = scratchOutput.getPosition();\n        scratchOutput.writeVInt(count << 1 | (output.includeOrig ? 0 : 1));\n        final int pos2 = scratchOutput.getPosition();\n        final int vIntLen = pos2-pos;\n\n        // Move the count + includeOrig to the front of the byte[]:\n        System.arraycopy(scratch.bytes, pos, spare, 0, vIntLen);\n        System.arraycopy(scratch.bytes, 0, scratch.bytes, vIntLen, pos);\n        System.arraycopy(spare, 0, scratch.bytes, 0, vIntLen);\n\n        if (dedupSet != null) {\n          dedupSet.clear();\n        }\n        \n        scratch.length = scratchOutput.getPosition() - scratch.offset;\n        //System.out.println(\"  add input=\" + input + \" output=\" + scratch + \" offset=\" + scratch.offset + \" length=\" + scratch.length + \" count=\" + count);\n        builder.add(Util.toUTF32(input, scratchIntsRef), BytesRef.deepCopyOf(scratch));\n      }\n      \n      FST<BytesRef> fst = builder.finish();\n      return new SynonymMap(fst, words, maxHorizontalContext);\n    }\n\n","sourceOld":"    /**\n     * Builds an {@link SynonymMap} and returns it.\n     */\n    public SynonymMap build() throws IOException {\n      ByteSequenceOutputs outputs = ByteSequenceOutputs.getSingleton();\n      // TODO: are we using the best sharing options?\n      org.apache.lucene.util.fst.Builder<BytesRef> builder = \n        new org.apache.lucene.util.fst.Builder<BytesRef>(FST.INPUT_TYPE.BYTE4, outputs);\n      \n      BytesRef scratch = new BytesRef(64);\n      ByteArrayDataOutput scratchOutput = new ByteArrayDataOutput();\n\n      final Set<Integer> dedupSet;\n\n      if (dedup) {\n        dedupSet = new HashSet<Integer>();\n      } else {\n        dedupSet = null;\n      }\n\n      final byte[] spare = new byte[5];\n      \n      Set<CharsRef> keys = workingSet.keySet();\n      CharsRef sortedKeys[] = keys.toArray(new CharsRef[keys.size()]);\n      Arrays.sort(sortedKeys, CharsRef.getUTF16SortedAsUTF8Comparator());\n\n      final IntsRef scratchIntsRef = new IntsRef();\n      \n      //System.out.println(\"fmap.build\");\n      for (int keyIdx = 0; keyIdx < sortedKeys.length; keyIdx++) {\n        CharsRef input = sortedKeys[keyIdx];\n        MapEntry output = workingSet.get(input);\n\n        int numEntries = output.ords.size();\n        // output size, assume the worst case\n        int estimatedSize = 5 + numEntries * 5; // numEntries + one ord for each entry\n        \n        scratch.grow(estimatedSize);\n        scratchOutput.reset(scratch.bytes, scratch.offset, scratch.bytes.length);\n        assert scratch.offset == 0;\n\n        // now write our output data:\n        int count = 0;\n        for (int i = 0; i < numEntries; i++) {\n          if (dedupSet != null) {\n            // box once\n            final Integer ent = output.ords.get(i);\n            if (dedupSet.contains(ent)) {\n              continue;\n            }\n            dedupSet.add(ent);\n          }\n          scratchOutput.writeVInt(output.ords.get(i));   \n          count++;\n        }\n\n        final int pos = scratchOutput.getPosition();\n        scratchOutput.writeVInt(count << 1 | (output.includeOrig ? 0 : 1));\n        final int pos2 = scratchOutput.getPosition();\n        final int vIntLen = pos2-pos;\n\n        // Move the count + includeOrig to the front of the byte[]:\n        System.arraycopy(scratch.bytes, pos, spare, 0, vIntLen);\n        System.arraycopy(scratch.bytes, 0, scratch.bytes, vIntLen, pos);\n        System.arraycopy(spare, 0, scratch.bytes, 0, vIntLen);\n\n        if (dedupSet != null) {\n          dedupSet.clear();\n        }\n        \n        scratch.length = scratchOutput.getPosition() - scratch.offset;\n        //System.out.println(\"  add input=\" + input + \" output=\" + scratch + \" offset=\" + scratch.offset + \" length=\" + scratch.length + \" count=\" + count);\n        builder.add(Util.toUTF32(input, scratchIntsRef), BytesRef.deepCopyOf(scratch));\n      }\n      \n      FST<BytesRef> fst = builder.finish();\n      return new SynonymMap(fst, words, maxHorizontalContext);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#build().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#build().mjava","sourceNew":"    /**\n     * Builds an {@link SynonymMap} and returns it.\n     */\n    public SynonymMap build() throws IOException {\n      ByteSequenceOutputs outputs = ByteSequenceOutputs.getSingleton();\n      // TODO: are we using the best sharing options?\n      org.apache.lucene.util.fst.Builder<BytesRef> builder = \n        new org.apache.lucene.util.fst.Builder<>(FST.INPUT_TYPE.BYTE4, outputs);\n      \n      BytesRef scratch = new BytesRef(64);\n      ByteArrayDataOutput scratchOutput = new ByteArrayDataOutput();\n\n      final Set<Integer> dedupSet;\n\n      if (dedup) {\n        dedupSet = new HashSet<>();\n      } else {\n        dedupSet = null;\n      }\n\n      final byte[] spare = new byte[5];\n      \n      Set<CharsRef> keys = workingSet.keySet();\n      CharsRef sortedKeys[] = keys.toArray(new CharsRef[keys.size()]);\n      Arrays.sort(sortedKeys, CharsRef.getUTF16SortedAsUTF8Comparator());\n\n      final IntsRef scratchIntsRef = new IntsRef();\n      \n      //System.out.println(\"fmap.build\");\n      for (int keyIdx = 0; keyIdx < sortedKeys.length; keyIdx++) {\n        CharsRef input = sortedKeys[keyIdx];\n        MapEntry output = workingSet.get(input);\n\n        int numEntries = output.ords.size();\n        // output size, assume the worst case\n        int estimatedSize = 5 + numEntries * 5; // numEntries + one ord for each entry\n        \n        scratch.grow(estimatedSize);\n        scratchOutput.reset(scratch.bytes, scratch.offset, scratch.bytes.length);\n        assert scratch.offset == 0;\n\n        // now write our output data:\n        int count = 0;\n        for (int i = 0; i < numEntries; i++) {\n          if (dedupSet != null) {\n            // box once\n            final Integer ent = output.ords.get(i);\n            if (dedupSet.contains(ent)) {\n              continue;\n            }\n            dedupSet.add(ent);\n          }\n          scratchOutput.writeVInt(output.ords.get(i));   \n          count++;\n        }\n\n        final int pos = scratchOutput.getPosition();\n        scratchOutput.writeVInt(count << 1 | (output.includeOrig ? 0 : 1));\n        final int pos2 = scratchOutput.getPosition();\n        final int vIntLen = pos2-pos;\n\n        // Move the count + includeOrig to the front of the byte[]:\n        System.arraycopy(scratch.bytes, pos, spare, 0, vIntLen);\n        System.arraycopy(scratch.bytes, 0, scratch.bytes, vIntLen, pos);\n        System.arraycopy(spare, 0, scratch.bytes, 0, vIntLen);\n\n        if (dedupSet != null) {\n          dedupSet.clear();\n        }\n        \n        scratch.length = scratchOutput.getPosition() - scratch.offset;\n        //System.out.println(\"  add input=\" + input + \" output=\" + scratch + \" offset=\" + scratch.offset + \" length=\" + scratch.length + \" count=\" + count);\n        builder.add(Util.toUTF32(input, scratchIntsRef), BytesRef.deepCopyOf(scratch));\n      }\n      \n      FST<BytesRef> fst = builder.finish();\n      return new SynonymMap(fst, words, maxHorizontalContext);\n    }\n\n","sourceOld":"    /**\n     * Builds an {@link SynonymMap} and returns it.\n     */\n    public SynonymMap build() throws IOException {\n      ByteSequenceOutputs outputs = ByteSequenceOutputs.getSingleton();\n      // TODO: are we using the best sharing options?\n      org.apache.lucene.util.fst.Builder<BytesRef> builder = \n        new org.apache.lucene.util.fst.Builder<BytesRef>(FST.INPUT_TYPE.BYTE4, outputs);\n      \n      BytesRef scratch = new BytesRef(64);\n      ByteArrayDataOutput scratchOutput = new ByteArrayDataOutput();\n\n      final Set<Integer> dedupSet;\n\n      if (dedup) {\n        dedupSet = new HashSet<Integer>();\n      } else {\n        dedupSet = null;\n      }\n\n      final byte[] spare = new byte[5];\n      \n      Set<CharsRef> keys = workingSet.keySet();\n      CharsRef sortedKeys[] = keys.toArray(new CharsRef[keys.size()]);\n      Arrays.sort(sortedKeys, CharsRef.getUTF16SortedAsUTF8Comparator());\n\n      final IntsRef scratchIntsRef = new IntsRef();\n      \n      //System.out.println(\"fmap.build\");\n      for (int keyIdx = 0; keyIdx < sortedKeys.length; keyIdx++) {\n        CharsRef input = sortedKeys[keyIdx];\n        MapEntry output = workingSet.get(input);\n\n        int numEntries = output.ords.size();\n        // output size, assume the worst case\n        int estimatedSize = 5 + numEntries * 5; // numEntries + one ord for each entry\n        \n        scratch.grow(estimatedSize);\n        scratchOutput.reset(scratch.bytes, scratch.offset, scratch.bytes.length);\n        assert scratch.offset == 0;\n\n        // now write our output data:\n        int count = 0;\n        for (int i = 0; i < numEntries; i++) {\n          if (dedupSet != null) {\n            // box once\n            final Integer ent = output.ords.get(i);\n            if (dedupSet.contains(ent)) {\n              continue;\n            }\n            dedupSet.add(ent);\n          }\n          scratchOutput.writeVInt(output.ords.get(i));   \n          count++;\n        }\n\n        final int pos = scratchOutput.getPosition();\n        scratchOutput.writeVInt(count << 1 | (output.includeOrig ? 0 : 1));\n        final int pos2 = scratchOutput.getPosition();\n        final int vIntLen = pos2-pos;\n\n        // Move the count + includeOrig to the front of the byte[]:\n        System.arraycopy(scratch.bytes, pos, spare, 0, vIntLen);\n        System.arraycopy(scratch.bytes, 0, scratch.bytes, vIntLen, pos);\n        System.arraycopy(spare, 0, scratch.bytes, 0, vIntLen);\n\n        if (dedupSet != null) {\n          dedupSet.clear();\n        }\n        \n        scratch.length = scratchOutput.getPosition() - scratch.offset;\n        //System.out.println(\"  add input=\" + input + \" output=\" + scratch + \" offset=\" + scratch.offset + \" length=\" + scratch.length + \" count=\" + count);\n        builder.add(Util.toUTF32(input, scratchIntsRef), BytesRef.deepCopyOf(scratch));\n      }\n      \n      FST<BytesRef> fst = builder.finish();\n      return new SynonymMap(fst, words, maxHorizontalContext);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","date":1407854805,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#build().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#build().mjava","sourceNew":"    /**\n     * Builds an {@link SynonymMap} and returns it.\n     */\n    public SynonymMap build() throws IOException {\n      ByteSequenceOutputs outputs = ByteSequenceOutputs.getSingleton();\n      // TODO: are we using the best sharing options?\n      org.apache.lucene.util.fst.Builder<BytesRef> builder = \n        new org.apache.lucene.util.fst.Builder<>(FST.INPUT_TYPE.BYTE4, outputs);\n      \n      BytesRefBuilder scratch = new BytesRefBuilder();\n      ByteArrayDataOutput scratchOutput = new ByteArrayDataOutput();\n\n      final Set<Integer> dedupSet;\n\n      if (dedup) {\n        dedupSet = new HashSet<>();\n      } else {\n        dedupSet = null;\n      }\n\n      final byte[] spare = new byte[5];\n      \n      Set<CharsRef> keys = workingSet.keySet();\n      CharsRef sortedKeys[] = keys.toArray(new CharsRef[keys.size()]);\n      Arrays.sort(sortedKeys, CharsRef.getUTF16SortedAsUTF8Comparator());\n\n      final IntsRefBuilder scratchIntsRef = new IntsRefBuilder();\n      \n      //System.out.println(\"fmap.build\");\n      for (int keyIdx = 0; keyIdx < sortedKeys.length; keyIdx++) {\n        CharsRef input = sortedKeys[keyIdx];\n        MapEntry output = workingSet.get(input);\n\n        int numEntries = output.ords.size();\n        // output size, assume the worst case\n        int estimatedSize = 5 + numEntries * 5; // numEntries + one ord for each entry\n        \n        scratch.grow(estimatedSize);\n        scratchOutput.reset(scratch.bytes());\n\n        // now write our output data:\n        int count = 0;\n        for (int i = 0; i < numEntries; i++) {\n          if (dedupSet != null) {\n            // box once\n            final Integer ent = output.ords.get(i);\n            if (dedupSet.contains(ent)) {\n              continue;\n            }\n            dedupSet.add(ent);\n          }\n          scratchOutput.writeVInt(output.ords.get(i));   \n          count++;\n        }\n\n        final int pos = scratchOutput.getPosition();\n        scratchOutput.writeVInt(count << 1 | (output.includeOrig ? 0 : 1));\n        final int pos2 = scratchOutput.getPosition();\n        final int vIntLen = pos2-pos;\n\n        // Move the count + includeOrig to the front of the byte[]:\n        System.arraycopy(scratch.bytes(), pos, spare, 0, vIntLen);\n        System.arraycopy(scratch.bytes(), 0, scratch.bytes(), vIntLen, pos);\n        System.arraycopy(spare, 0, scratch.bytes(), 0, vIntLen);\n\n        if (dedupSet != null) {\n          dedupSet.clear();\n        }\n        \n        scratch.setLength(scratchOutput.getPosition());\n        //System.out.println(\"  add input=\" + input + \" output=\" + scratch + \" offset=\" + scratch.offset + \" length=\" + scratch.length + \" count=\" + count);\n        builder.add(Util.toUTF32(input, scratchIntsRef), scratch.toBytesRef());\n      }\n      \n      FST<BytesRef> fst = builder.finish();\n      return new SynonymMap(fst, words, maxHorizontalContext);\n    }\n\n","sourceOld":"    /**\n     * Builds an {@link SynonymMap} and returns it.\n     */\n    public SynonymMap build() throws IOException {\n      ByteSequenceOutputs outputs = ByteSequenceOutputs.getSingleton();\n      // TODO: are we using the best sharing options?\n      org.apache.lucene.util.fst.Builder<BytesRef> builder = \n        new org.apache.lucene.util.fst.Builder<>(FST.INPUT_TYPE.BYTE4, outputs);\n      \n      BytesRef scratch = new BytesRef(64);\n      ByteArrayDataOutput scratchOutput = new ByteArrayDataOutput();\n\n      final Set<Integer> dedupSet;\n\n      if (dedup) {\n        dedupSet = new HashSet<>();\n      } else {\n        dedupSet = null;\n      }\n\n      final byte[] spare = new byte[5];\n      \n      Set<CharsRef> keys = workingSet.keySet();\n      CharsRef sortedKeys[] = keys.toArray(new CharsRef[keys.size()]);\n      Arrays.sort(sortedKeys, CharsRef.getUTF16SortedAsUTF8Comparator());\n\n      final IntsRef scratchIntsRef = new IntsRef();\n      \n      //System.out.println(\"fmap.build\");\n      for (int keyIdx = 0; keyIdx < sortedKeys.length; keyIdx++) {\n        CharsRef input = sortedKeys[keyIdx];\n        MapEntry output = workingSet.get(input);\n\n        int numEntries = output.ords.size();\n        // output size, assume the worst case\n        int estimatedSize = 5 + numEntries * 5; // numEntries + one ord for each entry\n        \n        scratch.grow(estimatedSize);\n        scratchOutput.reset(scratch.bytes, scratch.offset, scratch.bytes.length);\n        assert scratch.offset == 0;\n\n        // now write our output data:\n        int count = 0;\n        for (int i = 0; i < numEntries; i++) {\n          if (dedupSet != null) {\n            // box once\n            final Integer ent = output.ords.get(i);\n            if (dedupSet.contains(ent)) {\n              continue;\n            }\n            dedupSet.add(ent);\n          }\n          scratchOutput.writeVInt(output.ords.get(i));   \n          count++;\n        }\n\n        final int pos = scratchOutput.getPosition();\n        scratchOutput.writeVInt(count << 1 | (output.includeOrig ? 0 : 1));\n        final int pos2 = scratchOutput.getPosition();\n        final int vIntLen = pos2-pos;\n\n        // Move the count + includeOrig to the front of the byte[]:\n        System.arraycopy(scratch.bytes, pos, spare, 0, vIntLen);\n        System.arraycopy(scratch.bytes, 0, scratch.bytes, vIntLen, pos);\n        System.arraycopy(spare, 0, scratch.bytes, 0, vIntLen);\n\n        if (dedupSet != null) {\n          dedupSet.clear();\n        }\n        \n        scratch.length = scratchOutput.getPosition() - scratch.offset;\n        //System.out.println(\"  add input=\" + input + \" output=\" + scratch + \" offset=\" + scratch.offset + \" length=\" + scratch.length + \" count=\" + count);\n        builder.add(Util.toUTF32(input, scratchIntsRef), BytesRef.deepCopyOf(scratch));\n      }\n      \n      FST<BytesRef> fst = builder.finish();\n      return new SynonymMap(fst, words, maxHorizontalContext);\n    }\n\n","bugFix":["44d6f0ab53c1962856b9f48dedb7a2a6cc18905c","1ec890fad2ea96317f4429e0aa0085bb25673641"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9","date":1574619880,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#build().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#build().mjava","sourceNew":"    /**\n     * Builds an {@link SynonymMap} and returns it.\n     */\n    @SuppressWarnings(\"deprecation\")\n    public SynonymMap build() throws IOException {\n      ByteSequenceOutputs outputs = ByteSequenceOutputs.getSingleton();\n      // TODO: are we using the best sharing options?\n      org.apache.lucene.util.fst.Builder<BytesRef> builder = \n        new org.apache.lucene.util.fst.Builder<>(FST.INPUT_TYPE.BYTE4, outputs);\n      \n      BytesRefBuilder scratch = new BytesRefBuilder();\n      ByteArrayDataOutput scratchOutput = new ByteArrayDataOutput();\n\n      final Set<Integer> dedupSet;\n\n      if (dedup) {\n        dedupSet = new HashSet<>();\n      } else {\n        dedupSet = null;\n      }\n\n      final byte[] spare = new byte[5];\n      \n      Set<CharsRef> keys = workingSet.keySet();\n      CharsRef sortedKeys[] = keys.toArray(new CharsRef[keys.size()]);\n      Arrays.sort(sortedKeys, CharsRef.getUTF16SortedAsUTF8Comparator());\n\n      final IntsRefBuilder scratchIntsRef = new IntsRefBuilder();\n      \n      //System.out.println(\"fmap.build\");\n      for (int keyIdx = 0; keyIdx < sortedKeys.length; keyIdx++) {\n        CharsRef input = sortedKeys[keyIdx];\n        MapEntry output = workingSet.get(input);\n\n        int numEntries = output.ords.size();\n        // output size, assume the worst case\n        int estimatedSize = 5 + numEntries * 5; // numEntries + one ord for each entry\n        \n        scratch.grow(estimatedSize);\n        scratchOutput.reset(scratch.bytes());\n\n        // now write our output data:\n        int count = 0;\n        for (int i = 0; i < numEntries; i++) {\n          if (dedupSet != null) {\n            // box once\n            final Integer ent = output.ords.get(i);\n            if (dedupSet.contains(ent)) {\n              continue;\n            }\n            dedupSet.add(ent);\n          }\n          scratchOutput.writeVInt(output.ords.get(i));   \n          count++;\n        }\n\n        final int pos = scratchOutput.getPosition();\n        scratchOutput.writeVInt(count << 1 | (output.includeOrig ? 0 : 1));\n        final int pos2 = scratchOutput.getPosition();\n        final int vIntLen = pos2-pos;\n\n        // Move the count + includeOrig to the front of the byte[]:\n        System.arraycopy(scratch.bytes(), pos, spare, 0, vIntLen);\n        System.arraycopy(scratch.bytes(), 0, scratch.bytes(), vIntLen, pos);\n        System.arraycopy(spare, 0, scratch.bytes(), 0, vIntLen);\n\n        if (dedupSet != null) {\n          dedupSet.clear();\n        }\n        \n        scratch.setLength(scratchOutput.getPosition());\n        //System.out.println(\"  add input=\" + input + \" output=\" + scratch + \" offset=\" + scratch.offset + \" length=\" + scratch.length + \" count=\" + count);\n        builder.add(Util.toUTF32(input, scratchIntsRef), scratch.toBytesRef());\n      }\n      \n      FST<BytesRef> fst = builder.finish();\n      return new SynonymMap(fst, words, maxHorizontalContext);\n    }\n\n","sourceOld":"    /**\n     * Builds an {@link SynonymMap} and returns it.\n     */\n    public SynonymMap build() throws IOException {\n      ByteSequenceOutputs outputs = ByteSequenceOutputs.getSingleton();\n      // TODO: are we using the best sharing options?\n      org.apache.lucene.util.fst.Builder<BytesRef> builder = \n        new org.apache.lucene.util.fst.Builder<>(FST.INPUT_TYPE.BYTE4, outputs);\n      \n      BytesRefBuilder scratch = new BytesRefBuilder();\n      ByteArrayDataOutput scratchOutput = new ByteArrayDataOutput();\n\n      final Set<Integer> dedupSet;\n\n      if (dedup) {\n        dedupSet = new HashSet<>();\n      } else {\n        dedupSet = null;\n      }\n\n      final byte[] spare = new byte[5];\n      \n      Set<CharsRef> keys = workingSet.keySet();\n      CharsRef sortedKeys[] = keys.toArray(new CharsRef[keys.size()]);\n      Arrays.sort(sortedKeys, CharsRef.getUTF16SortedAsUTF8Comparator());\n\n      final IntsRefBuilder scratchIntsRef = new IntsRefBuilder();\n      \n      //System.out.println(\"fmap.build\");\n      for (int keyIdx = 0; keyIdx < sortedKeys.length; keyIdx++) {\n        CharsRef input = sortedKeys[keyIdx];\n        MapEntry output = workingSet.get(input);\n\n        int numEntries = output.ords.size();\n        // output size, assume the worst case\n        int estimatedSize = 5 + numEntries * 5; // numEntries + one ord for each entry\n        \n        scratch.grow(estimatedSize);\n        scratchOutput.reset(scratch.bytes());\n\n        // now write our output data:\n        int count = 0;\n        for (int i = 0; i < numEntries; i++) {\n          if (dedupSet != null) {\n            // box once\n            final Integer ent = output.ords.get(i);\n            if (dedupSet.contains(ent)) {\n              continue;\n            }\n            dedupSet.add(ent);\n          }\n          scratchOutput.writeVInt(output.ords.get(i));   \n          count++;\n        }\n\n        final int pos = scratchOutput.getPosition();\n        scratchOutput.writeVInt(count << 1 | (output.includeOrig ? 0 : 1));\n        final int pos2 = scratchOutput.getPosition();\n        final int vIntLen = pos2-pos;\n\n        // Move the count + includeOrig to the front of the byte[]:\n        System.arraycopy(scratch.bytes(), pos, spare, 0, vIntLen);\n        System.arraycopy(scratch.bytes(), 0, scratch.bytes(), vIntLen, pos);\n        System.arraycopy(spare, 0, scratch.bytes(), 0, vIntLen);\n\n        if (dedupSet != null) {\n          dedupSet.clear();\n        }\n        \n        scratch.setLength(scratchOutput.getPosition());\n        //System.out.println(\"  add input=\" + input + \" output=\" + scratch + \" offset=\" + scratch.offset + \" length=\" + scratch.length + \" count=\" + count);\n        builder.add(Util.toUTF32(input, scratchIntsRef), scratch.toBytesRef());\n      }\n      \n      FST<BytesRef> fst = builder.finish();\n      return new SynonymMap(fst, words, maxHorizontalContext);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bb9c3baacabd473e8ecd6c4948aabacead49b88e","date":1574700980,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#build().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#build().mjava","sourceNew":"    /**\n     * Builds an {@link SynonymMap} and returns it.\n     */\n    public SynonymMap build() throws IOException {\n      ByteSequenceOutputs outputs = ByteSequenceOutputs.getSingleton();\n      // TODO: are we using the best sharing options?\n      org.apache.lucene.util.fst.Builder<BytesRef> builder = \n        new org.apache.lucene.util.fst.Builder<>(FST.INPUT_TYPE.BYTE4, outputs);\n      \n      BytesRefBuilder scratch = new BytesRefBuilder();\n      ByteArrayDataOutput scratchOutput = new ByteArrayDataOutput();\n\n      final Set<Integer> dedupSet;\n\n      if (dedup) {\n        dedupSet = new HashSet<>();\n      } else {\n        dedupSet = null;\n      }\n\n      final byte[] spare = new byte[5];\n      \n      Set<CharsRef> keys = workingSet.keySet();\n      CharsRef sortedKeys[] = keys.toArray(new CharsRef[keys.size()]);\n      Arrays.sort(sortedKeys, CharsRef.getUTF16SortedAsUTF8Comparator());\n\n      final IntsRefBuilder scratchIntsRef = new IntsRefBuilder();\n      \n      //System.out.println(\"fmap.build\");\n      for (int keyIdx = 0; keyIdx < sortedKeys.length; keyIdx++) {\n        CharsRef input = sortedKeys[keyIdx];\n        MapEntry output = workingSet.get(input);\n\n        int numEntries = output.ords.size();\n        // output size, assume the worst case\n        int estimatedSize = 5 + numEntries * 5; // numEntries + one ord for each entry\n        \n        scratch.grow(estimatedSize);\n        scratchOutput.reset(scratch.bytes());\n\n        // now write our output data:\n        int count = 0;\n        for (int i = 0; i < numEntries; i++) {\n          if (dedupSet != null) {\n            // box once\n            final Integer ent = output.ords.get(i);\n            if (dedupSet.contains(ent)) {\n              continue;\n            }\n            dedupSet.add(ent);\n          }\n          scratchOutput.writeVInt(output.ords.get(i));   \n          count++;\n        }\n\n        final int pos = scratchOutput.getPosition();\n        scratchOutput.writeVInt(count << 1 | (output.includeOrig ? 0 : 1));\n        final int pos2 = scratchOutput.getPosition();\n        final int vIntLen = pos2-pos;\n\n        // Move the count + includeOrig to the front of the byte[]:\n        System.arraycopy(scratch.bytes(), pos, spare, 0, vIntLen);\n        System.arraycopy(scratch.bytes(), 0, scratch.bytes(), vIntLen, pos);\n        System.arraycopy(spare, 0, scratch.bytes(), 0, vIntLen);\n\n        if (dedupSet != null) {\n          dedupSet.clear();\n        }\n        \n        scratch.setLength(scratchOutput.getPosition());\n        //System.out.println(\"  add input=\" + input + \" output=\" + scratch + \" offset=\" + scratch.offset + \" length=\" + scratch.length + \" count=\" + count);\n        builder.add(Util.toUTF32(input, scratchIntsRef), scratch.toBytesRef());\n      }\n      \n      FST<BytesRef> fst = builder.finish();\n      return new SynonymMap(fst, words, maxHorizontalContext);\n    }\n\n","sourceOld":"    /**\n     * Builds an {@link SynonymMap} and returns it.\n     */\n    @SuppressWarnings(\"deprecation\")\n    public SynonymMap build() throws IOException {\n      ByteSequenceOutputs outputs = ByteSequenceOutputs.getSingleton();\n      // TODO: are we using the best sharing options?\n      org.apache.lucene.util.fst.Builder<BytesRef> builder = \n        new org.apache.lucene.util.fst.Builder<>(FST.INPUT_TYPE.BYTE4, outputs);\n      \n      BytesRefBuilder scratch = new BytesRefBuilder();\n      ByteArrayDataOutput scratchOutput = new ByteArrayDataOutput();\n\n      final Set<Integer> dedupSet;\n\n      if (dedup) {\n        dedupSet = new HashSet<>();\n      } else {\n        dedupSet = null;\n      }\n\n      final byte[] spare = new byte[5];\n      \n      Set<CharsRef> keys = workingSet.keySet();\n      CharsRef sortedKeys[] = keys.toArray(new CharsRef[keys.size()]);\n      Arrays.sort(sortedKeys, CharsRef.getUTF16SortedAsUTF8Comparator());\n\n      final IntsRefBuilder scratchIntsRef = new IntsRefBuilder();\n      \n      //System.out.println(\"fmap.build\");\n      for (int keyIdx = 0; keyIdx < sortedKeys.length; keyIdx++) {\n        CharsRef input = sortedKeys[keyIdx];\n        MapEntry output = workingSet.get(input);\n\n        int numEntries = output.ords.size();\n        // output size, assume the worst case\n        int estimatedSize = 5 + numEntries * 5; // numEntries + one ord for each entry\n        \n        scratch.grow(estimatedSize);\n        scratchOutput.reset(scratch.bytes());\n\n        // now write our output data:\n        int count = 0;\n        for (int i = 0; i < numEntries; i++) {\n          if (dedupSet != null) {\n            // box once\n            final Integer ent = output.ords.get(i);\n            if (dedupSet.contains(ent)) {\n              continue;\n            }\n            dedupSet.add(ent);\n          }\n          scratchOutput.writeVInt(output.ords.get(i));   \n          count++;\n        }\n\n        final int pos = scratchOutput.getPosition();\n        scratchOutput.writeVInt(count << 1 | (output.includeOrig ? 0 : 1));\n        final int pos2 = scratchOutput.getPosition();\n        final int vIntLen = pos2-pos;\n\n        // Move the count + includeOrig to the front of the byte[]:\n        System.arraycopy(scratch.bytes(), pos, spare, 0, vIntLen);\n        System.arraycopy(scratch.bytes(), 0, scratch.bytes(), vIntLen, pos);\n        System.arraycopy(spare, 0, scratch.bytes(), 0, vIntLen);\n\n        if (dedupSet != null) {\n          dedupSet.clear();\n        }\n        \n        scratch.setLength(scratchOutput.getPosition());\n        //System.out.println(\"  add input=\" + input + \" output=\" + scratch + \" offset=\" + scratch.offset + \" length=\" + scratch.length + \" count=\" + count);\n        builder.add(Util.toUTF32(input, scratchIntsRef), scratch.toBytesRef());\n      }\n      \n      FST<BytesRef> fst = builder.finish();\n      return new SynonymMap(fst, words, maxHorizontalContext);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f5661e6a04d3172e262ad741b717924f2f1b6a5","date":1576244274,"type":3,"author":"Bruno Roustant","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#build().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#build().mjava","sourceNew":"    /**\n     * Builds an {@link SynonymMap} and returns it.\n     */\n    public SynonymMap build() throws IOException {\n      ByteSequenceOutputs outputs = ByteSequenceOutputs.getSingleton();\n      // TODO: are we using the best sharing options?\n      FSTCompiler<BytesRef> fstCompiler =\n        new FSTCompiler<>(FST.INPUT_TYPE.BYTE4, outputs);\n      \n      BytesRefBuilder scratch = new BytesRefBuilder();\n      ByteArrayDataOutput scratchOutput = new ByteArrayDataOutput();\n\n      final Set<Integer> dedupSet;\n\n      if (dedup) {\n        dedupSet = new HashSet<>();\n      } else {\n        dedupSet = null;\n      }\n\n      final byte[] spare = new byte[5];\n      \n      Set<CharsRef> keys = workingSet.keySet();\n      CharsRef sortedKeys[] = keys.toArray(new CharsRef[keys.size()]);\n      Arrays.sort(sortedKeys, CharsRef.getUTF16SortedAsUTF8Comparator());\n\n      final IntsRefBuilder scratchIntsRef = new IntsRefBuilder();\n      \n      //System.out.println(\"fmap.build\");\n      for (int keyIdx = 0; keyIdx < sortedKeys.length; keyIdx++) {\n        CharsRef input = sortedKeys[keyIdx];\n        MapEntry output = workingSet.get(input);\n\n        int numEntries = output.ords.size();\n        // output size, assume the worst case\n        int estimatedSize = 5 + numEntries * 5; // numEntries + one ord for each entry\n        \n        scratch.grow(estimatedSize);\n        scratchOutput.reset(scratch.bytes());\n\n        // now write our output data:\n        int count = 0;\n        for (int i = 0; i < numEntries; i++) {\n          if (dedupSet != null) {\n            // box once\n            final Integer ent = output.ords.get(i);\n            if (dedupSet.contains(ent)) {\n              continue;\n            }\n            dedupSet.add(ent);\n          }\n          scratchOutput.writeVInt(output.ords.get(i));   \n          count++;\n        }\n\n        final int pos = scratchOutput.getPosition();\n        scratchOutput.writeVInt(count << 1 | (output.includeOrig ? 0 : 1));\n        final int pos2 = scratchOutput.getPosition();\n        final int vIntLen = pos2-pos;\n\n        // Move the count + includeOrig to the front of the byte[]:\n        System.arraycopy(scratch.bytes(), pos, spare, 0, vIntLen);\n        System.arraycopy(scratch.bytes(), 0, scratch.bytes(), vIntLen, pos);\n        System.arraycopy(spare, 0, scratch.bytes(), 0, vIntLen);\n\n        if (dedupSet != null) {\n          dedupSet.clear();\n        }\n        \n        scratch.setLength(scratchOutput.getPosition());\n        //System.out.println(\"  add input=\" + input + \" output=\" + scratch + \" offset=\" + scratch.offset + \" length=\" + scratch.length + \" count=\" + count);\n        fstCompiler.add(Util.toUTF32(input, scratchIntsRef), scratch.toBytesRef());\n      }\n      \n      FST<BytesRef> fst = fstCompiler.compile();\n      return new SynonymMap(fst, words, maxHorizontalContext);\n    }\n\n","sourceOld":"    /**\n     * Builds an {@link SynonymMap} and returns it.\n     */\n    public SynonymMap build() throws IOException {\n      ByteSequenceOutputs outputs = ByteSequenceOutputs.getSingleton();\n      // TODO: are we using the best sharing options?\n      org.apache.lucene.util.fst.Builder<BytesRef> builder = \n        new org.apache.lucene.util.fst.Builder<>(FST.INPUT_TYPE.BYTE4, outputs);\n      \n      BytesRefBuilder scratch = new BytesRefBuilder();\n      ByteArrayDataOutput scratchOutput = new ByteArrayDataOutput();\n\n      final Set<Integer> dedupSet;\n\n      if (dedup) {\n        dedupSet = new HashSet<>();\n      } else {\n        dedupSet = null;\n      }\n\n      final byte[] spare = new byte[5];\n      \n      Set<CharsRef> keys = workingSet.keySet();\n      CharsRef sortedKeys[] = keys.toArray(new CharsRef[keys.size()]);\n      Arrays.sort(sortedKeys, CharsRef.getUTF16SortedAsUTF8Comparator());\n\n      final IntsRefBuilder scratchIntsRef = new IntsRefBuilder();\n      \n      //System.out.println(\"fmap.build\");\n      for (int keyIdx = 0; keyIdx < sortedKeys.length; keyIdx++) {\n        CharsRef input = sortedKeys[keyIdx];\n        MapEntry output = workingSet.get(input);\n\n        int numEntries = output.ords.size();\n        // output size, assume the worst case\n        int estimatedSize = 5 + numEntries * 5; // numEntries + one ord for each entry\n        \n        scratch.grow(estimatedSize);\n        scratchOutput.reset(scratch.bytes());\n\n        // now write our output data:\n        int count = 0;\n        for (int i = 0; i < numEntries; i++) {\n          if (dedupSet != null) {\n            // box once\n            final Integer ent = output.ords.get(i);\n            if (dedupSet.contains(ent)) {\n              continue;\n            }\n            dedupSet.add(ent);\n          }\n          scratchOutput.writeVInt(output.ords.get(i));   \n          count++;\n        }\n\n        final int pos = scratchOutput.getPosition();\n        scratchOutput.writeVInt(count << 1 | (output.includeOrig ? 0 : 1));\n        final int pos2 = scratchOutput.getPosition();\n        final int vIntLen = pos2-pos;\n\n        // Move the count + includeOrig to the front of the byte[]:\n        System.arraycopy(scratch.bytes(), pos, spare, 0, vIntLen);\n        System.arraycopy(scratch.bytes(), 0, scratch.bytes(), vIntLen, pos);\n        System.arraycopy(spare, 0, scratch.bytes(), 0, vIntLen);\n\n        if (dedupSet != null) {\n          dedupSet.clear();\n        }\n        \n        scratch.setLength(scratchOutput.getPosition());\n        //System.out.println(\"  add input=\" + input + \" output=\" + scratch + \" offset=\" + scratch.offset + \" length=\" + scratch.length + \" count=\" + count);\n        builder.add(Util.toUTF32(input, scratchIntsRef), scratch.toBytesRef());\n      }\n      \n      FST<BytesRef> fst = builder.finish();\n      return new SynonymMap(fst, words, maxHorizontalContext);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c5db9bff3aeb942c848a2ab8fa4b8b0737377deb","date":1576247714,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#build().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#build().mjava","sourceNew":"    /**\n     * Builds an {@link SynonymMap} and returns it.\n     */\n    public SynonymMap build() throws IOException {\n      ByteSequenceOutputs outputs = ByteSequenceOutputs.getSingleton();\n      // TODO: are we using the best sharing options?\n      FSTCompiler<BytesRef> fstCompiler =\n        new FSTCompiler<>(FST.INPUT_TYPE.BYTE4, outputs);\n      \n      BytesRefBuilder scratch = new BytesRefBuilder();\n      ByteArrayDataOutput scratchOutput = new ByteArrayDataOutput();\n\n      final Set<Integer> dedupSet;\n\n      if (dedup) {\n        dedupSet = new HashSet<>();\n      } else {\n        dedupSet = null;\n      }\n\n      final byte[] spare = new byte[5];\n      \n      Set<CharsRef> keys = workingSet.keySet();\n      CharsRef sortedKeys[] = keys.toArray(new CharsRef[keys.size()]);\n      Arrays.sort(sortedKeys, CharsRef.getUTF16SortedAsUTF8Comparator());\n\n      final IntsRefBuilder scratchIntsRef = new IntsRefBuilder();\n      \n      //System.out.println(\"fmap.build\");\n      for (int keyIdx = 0; keyIdx < sortedKeys.length; keyIdx++) {\n        CharsRef input = sortedKeys[keyIdx];\n        MapEntry output = workingSet.get(input);\n\n        int numEntries = output.ords.size();\n        // output size, assume the worst case\n        int estimatedSize = 5 + numEntries * 5; // numEntries + one ord for each entry\n        \n        scratch.grow(estimatedSize);\n        scratchOutput.reset(scratch.bytes());\n\n        // now write our output data:\n        int count = 0;\n        for (int i = 0; i < numEntries; i++) {\n          if (dedupSet != null) {\n            // box once\n            final Integer ent = output.ords.get(i);\n            if (dedupSet.contains(ent)) {\n              continue;\n            }\n            dedupSet.add(ent);\n          }\n          scratchOutput.writeVInt(output.ords.get(i));   \n          count++;\n        }\n\n        final int pos = scratchOutput.getPosition();\n        scratchOutput.writeVInt(count << 1 | (output.includeOrig ? 0 : 1));\n        final int pos2 = scratchOutput.getPosition();\n        final int vIntLen = pos2-pos;\n\n        // Move the count + includeOrig to the front of the byte[]:\n        System.arraycopy(scratch.bytes(), pos, spare, 0, vIntLen);\n        System.arraycopy(scratch.bytes(), 0, scratch.bytes(), vIntLen, pos);\n        System.arraycopy(spare, 0, scratch.bytes(), 0, vIntLen);\n\n        if (dedupSet != null) {\n          dedupSet.clear();\n        }\n        \n        scratch.setLength(scratchOutput.getPosition());\n        //System.out.println(\"  add input=\" + input + \" output=\" + scratch + \" offset=\" + scratch.offset + \" length=\" + scratch.length + \" count=\" + count);\n        fstCompiler.add(Util.toUTF32(input, scratchIntsRef), scratch.toBytesRef());\n      }\n      \n      FST<BytesRef> fst = fstCompiler.compile();\n      return new SynonymMap(fst, words, maxHorizontalContext);\n    }\n\n","sourceOld":"    /**\n     * Builds an {@link SynonymMap} and returns it.\n     */\n    public SynonymMap build() throws IOException {\n      ByteSequenceOutputs outputs = ByteSequenceOutputs.getSingleton();\n      // TODO: are we using the best sharing options?\n      org.apache.lucene.util.fst.Builder<BytesRef> builder = \n        new org.apache.lucene.util.fst.Builder<>(FST.INPUT_TYPE.BYTE4, outputs);\n      \n      BytesRefBuilder scratch = new BytesRefBuilder();\n      ByteArrayDataOutput scratchOutput = new ByteArrayDataOutput();\n\n      final Set<Integer> dedupSet;\n\n      if (dedup) {\n        dedupSet = new HashSet<>();\n      } else {\n        dedupSet = null;\n      }\n\n      final byte[] spare = new byte[5];\n      \n      Set<CharsRef> keys = workingSet.keySet();\n      CharsRef sortedKeys[] = keys.toArray(new CharsRef[keys.size()]);\n      Arrays.sort(sortedKeys, CharsRef.getUTF16SortedAsUTF8Comparator());\n\n      final IntsRefBuilder scratchIntsRef = new IntsRefBuilder();\n      \n      //System.out.println(\"fmap.build\");\n      for (int keyIdx = 0; keyIdx < sortedKeys.length; keyIdx++) {\n        CharsRef input = sortedKeys[keyIdx];\n        MapEntry output = workingSet.get(input);\n\n        int numEntries = output.ords.size();\n        // output size, assume the worst case\n        int estimatedSize = 5 + numEntries * 5; // numEntries + one ord for each entry\n        \n        scratch.grow(estimatedSize);\n        scratchOutput.reset(scratch.bytes());\n\n        // now write our output data:\n        int count = 0;\n        for (int i = 0; i < numEntries; i++) {\n          if (dedupSet != null) {\n            // box once\n            final Integer ent = output.ords.get(i);\n            if (dedupSet.contains(ent)) {\n              continue;\n            }\n            dedupSet.add(ent);\n          }\n          scratchOutput.writeVInt(output.ords.get(i));   \n          count++;\n        }\n\n        final int pos = scratchOutput.getPosition();\n        scratchOutput.writeVInt(count << 1 | (output.includeOrig ? 0 : 1));\n        final int pos2 = scratchOutput.getPosition();\n        final int vIntLen = pos2-pos;\n\n        // Move the count + includeOrig to the front of the byte[]:\n        System.arraycopy(scratch.bytes(), pos, spare, 0, vIntLen);\n        System.arraycopy(scratch.bytes(), 0, scratch.bytes(), vIntLen, pos);\n        System.arraycopy(spare, 0, scratch.bytes(), 0, vIntLen);\n\n        if (dedupSet != null) {\n          dedupSet.clear();\n        }\n        \n        scratch.setLength(scratchOutput.getPosition());\n        //System.out.println(\"  add input=\" + input + \" output=\" + scratch + \" offset=\" + scratch.offset + \" length=\" + scratch.length + \" count=\" + count);\n        builder.add(Util.toUTF32(input, scratchIntsRef), scratch.toBytesRef());\n      }\n      \n      FST<BytesRef> fst = builder.finish();\n      return new SynonymMap(fst, words, maxHorizontalContext);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"bb9c3baacabd473e8ecd6c4948aabacead49b88e":["a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"c5db9bff3aeb942c848a2ab8fa4b8b0737377deb":["bb9c3baacabd473e8ecd6c4948aabacead49b88e","0f5661e6a04d3172e262ad741b717924f2f1b6a5"],"0f5661e6a04d3172e262ad741b717924f2f1b6a5":["bb9c3baacabd473e8ecd6c4948aabacead49b88e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["0f5661e6a04d3172e262ad741b717924f2f1b6a5"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9":["bb9c3baacabd473e8ecd6c4948aabacead49b88e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"bb9c3baacabd473e8ecd6c4948aabacead49b88e":["c5db9bff3aeb942c848a2ab8fa4b8b0737377deb","0f5661e6a04d3172e262ad741b717924f2f1b6a5"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9"],"c5db9bff3aeb942c848a2ab8fa4b8b0737377deb":[],"0f5661e6a04d3172e262ad741b717924f2f1b6a5":["c5db9bff3aeb942c848a2ab8fa4b8b0737377deb","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c5db9bff3aeb942c848a2ab8fa4b8b0737377deb","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}