{"path":"solr/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","commits":[{"id":"4e8cc373c801e54cec75daf9f52792cb4b17f536","date":1291116159,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","pathOld":"/dev/null","sourceNew":"  @SuppressWarnings(\"unchecked\")\n  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setMaxFieldLength(IndexWriterConfig.UNLIMITED_FIELD_LENGTH).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new Field(WORD_FIELD_NAME, s, Field.Store.NO, Field.Index.ANALYZED));\n          writer.addDocument(d);\n        }\n        writer.optimize();\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3bb13258feba31ab676502787ab2e1779f129b7a","date":1291596436,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","pathOld":"/dev/null","sourceNew":"  @SuppressWarnings(\"unchecked\")\n  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setMaxFieldLength(IndexWriterConfig.UNLIMITED_FIELD_LENGTH).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new Field(WORD_FIELD_NAME, s, Field.Store.NO, Field.Index.ANALYZED));\n          writer.addDocument(d);\n        }\n        writer.optimize();\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":0,"author":"Michael Busch","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","pathOld":"/dev/null","sourceNew":"  @SuppressWarnings(\"unchecked\")\n  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setMaxFieldLength(IndexWriterConfig.UNLIMITED_FIELD_LENGTH).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new Field(WORD_FIELD_NAME, s, Field.Store.NO, Field.Index.ANALYZED));\n          writer.addDocument(d);\n        }\n        writer.optimize();\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c2047784e704fe141e0ff36affac8a7cb6c7bbec","date":1295352100,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","pathOld":"solr/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","sourceNew":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new Field(WORD_FIELD_NAME, s, Field.Store.NO, Field.Index.ANALYZED));\n          writer.addDocument(d);\n        }\n        writer.optimize();\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","sourceOld":"  @SuppressWarnings(\"unchecked\")\n  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setMaxFieldLength(IndexWriterConfig.UNLIMITED_FIELD_LENGTH).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new Field(WORD_FIELD_NAME, s, Field.Store.NO, Field.Index.ANALYZED));\n          writer.addDocument(d);\n        }\n        writer.optimize();\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e79a6d080bdd5b2a8f56342cf571b5476de04180","date":1295638686,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","pathOld":"solr/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","sourceNew":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new Field(WORD_FIELD_NAME, s, Field.Store.NO, Field.Index.ANALYZED));\n          writer.addDocument(d);\n        }\n        writer.optimize();\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","sourceOld":"  @SuppressWarnings(\"unchecked\")\n  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setMaxFieldLength(IndexWriterConfig.UNLIMITED_FIELD_LENGTH).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new Field(WORD_FIELD_NAME, s, Field.Store.NO, Field.Index.ANALYZED));\n          writer.addDocument(d);\n        }\n        writer.optimize();\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","pathOld":"solr/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","sourceNew":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new Field(WORD_FIELD_NAME, s, Field.Store.NO, Field.Index.ANALYZED));\n          writer.addDocument(d);\n        }\n        writer.optimize();\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","sourceOld":"  @SuppressWarnings(\"unchecked\")\n  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setMaxFieldLength(IndexWriterConfig.UNLIMITED_FIELD_LENGTH).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new Field(WORD_FIELD_NAME, s, Field.Store.NO, Field.Index.ANALYZED));\n          writer.addDocument(d);\n        }\n        writer.optimize();\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","pathOld":"solr/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","sourceNew":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new Field(WORD_FIELD_NAME, s, Field.Store.NO, Field.Index.ANALYZED));\n          writer.addDocument(d);\n        }\n        writer.optimize();\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","sourceOld":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new Field(WORD_FIELD_NAME, s, Field.Store.NO, Field.Index.ANALYZED));\n          writer.addDocument(d);\n        }\n        writer.optimize();\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","pathOld":"solr/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","sourceNew":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new Field(WORD_FIELD_NAME, s, Field.Store.NO, Field.Index.ANALYZED));\n          writer.addDocument(d);\n        }\n        writer.optimize();\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","sourceOld":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new Field(WORD_FIELD_NAME, s, Field.Store.NO, Field.Index.ANALYZED));\n          writer.addDocument(d);\n        }\n        writer.optimize();\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","pathOld":"solr/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","sourceNew":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new Field(WORD_FIELD_NAME, s, Field.Store.NO, Field.Index.ANALYZED));\n          writer.addDocument(d);\n        }\n        writer.optimize();\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","sourceOld":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new Field(WORD_FIELD_NAME, s, Field.Store.NO, Field.Index.ANALYZED));\n          writer.addDocument(d);\n        }\n        writer.optimize();\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(IndexReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c2047784e704fe141e0ff36affac8a7cb6c7bbec":["4e8cc373c801e54cec75daf9f52792cb4b17f536"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c2047784e704fe141e0ff36affac8a7cb6c7bbec"],"c26f00b574427b55127e869b935845554afde1fa":["c2047784e704fe141e0ff36affac8a7cb6c7bbec","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["3bb13258feba31ab676502787ab2e1779f129b7a","c2047784e704fe141e0ff36affac8a7cb6c7bbec"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a258fbb26824fd104ed795e5d9033d2d040049ee":["c2047784e704fe141e0ff36affac8a7cb6c7bbec"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"e79a6d080bdd5b2a8f56342cf571b5476de04180":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","c2047784e704fe141e0ff36affac8a7cb6c7bbec"],"3bb13258feba31ab676502787ab2e1779f129b7a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c26f00b574427b55127e869b935845554afde1fa"],"4e8cc373c801e54cec75daf9f52792cb4b17f536":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"c2047784e704fe141e0ff36affac8a7cb6c7bbec":["c903c3d15906a3da96b8c0c2fb704491005fdbdb","c26f00b574427b55127e869b935845554afde1fa","29ef99d61cda9641b6250bf9567329a6e65f901d","a258fbb26824fd104ed795e5d9033d2d040049ee","e79a6d080bdd5b2a8f56342cf571b5476de04180"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"c26f00b574427b55127e869b935845554afde1fa":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"29ef99d61cda9641b6250bf9567329a6e65f901d":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","3bb13258feba31ab676502787ab2e1779f129b7a","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["e79a6d080bdd5b2a8f56342cf571b5476de04180"],"e79a6d080bdd5b2a8f56342cf571b5476de04180":[],"3bb13258feba31ab676502787ab2e1779f129b7a":["29ef99d61cda9641b6250bf9567329a6e65f901d"],"4e8cc373c801e54cec75daf9f52792cb4b17f536":["c2047784e704fe141e0ff36affac8a7cb6c7bbec","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","3bb13258feba31ab676502787ab2e1779f129b7a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["29ef99d61cda9641b6250bf9567329a6e65f901d","a258fbb26824fd104ed795e5d9033d2d040049ee","e79a6d080bdd5b2a8f56342cf571b5476de04180","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}