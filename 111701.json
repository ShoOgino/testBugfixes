{"path":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedMerges(SegmentInfos,int,Map[SegmentCommitInfo,Boolean],MergeContext).mjava","commits":[{"id":"1d28f215464f76024caf026606f8ea51a5319c53","date":1527226629,"type":1,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedMerges(SegmentInfos,int,Map[SegmentCommitInfo,Boolean],MergeContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedMerges(SegmentInfos,int,Map[SegmentCommitInfo,Boolean],IndexWriter).mjava","sourceNew":"  @Override\n  public MergeSpecification findForcedMerges(SegmentInfos infos, int maxSegmentCount, Map<SegmentCommitInfo,Boolean> segmentsToMerge, MergeContext mergeContext) throws IOException {\n    if (verbose(mergeContext)) {\n      message(\"findForcedMerges maxSegmentCount=\" + maxSegmentCount + \" infos=\" + segString(mergeContext, infos) + \" segmentsToMerge=\" + segmentsToMerge, mergeContext);\n    }\n\n    List<SegmentCommitInfo> eligible = new ArrayList<>();\n    boolean forceMergeRunning = false;\n    final Set<SegmentCommitInfo> merging = mergeContext.getMergingSegments();\n    boolean segmentIsOriginal = false;\n    for(SegmentCommitInfo info : infos) {\n      final Boolean isOriginal = segmentsToMerge.get(info);\n      if (isOriginal != null) {\n        segmentIsOriginal = isOriginal;\n        if (merging.contains(info) == false) {\n          eligible.add(info);\n        } else {\n          forceMergeRunning = true;\n        }\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    // The size can change concurrently while we are running here, because deletes\n    // are now applied concurrently, and this can piss off TimSort!  So we\n    // call size() once per segment and sort by that:\n    Map<SegmentCommitInfo,Long> sizeInBytes = getSegmentSizes(mergeContext, eligible);\n\n    if ((maxSegmentCount > 1 && eligible.size() <= maxSegmentCount) ||\n        (maxSegmentCount == 1 && eligible.size() == 1 && (!segmentIsOriginal || isMerged(infos, eligible.get(0), mergeContext)))) {\n      if (verbose(mergeContext)) {\n        message(\"already merged\", mergeContext);\n      }\n      return null;\n    }\n\n    eligible.sort(new SegmentByteSizeDescending(sizeInBytes));\n\n    if (verbose(mergeContext)) {\n      message(\"eligible=\" + eligible, mergeContext);\n      message(\"forceMergeRunning=\" + forceMergeRunning, mergeContext);\n    }\n\n    int end = eligible.size();\n    \n    MergeSpecification spec = null;\n\n    // Do full merges, first, backwards:\n    while(end >= maxMergeAtOnceExplicit + maxSegmentCount - 1) {\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n      final OneMerge merge = new OneMerge(eligible.subList(end-maxMergeAtOnceExplicit, end));\n      if (verbose(mergeContext)) {\n        message(\"add merge=\" + segString(mergeContext, merge.segments), mergeContext);\n      }\n      spec.add(merge);\n      end -= maxMergeAtOnceExplicit;\n    }\n\n    if (spec == null && !forceMergeRunning) {\n      // Do final merge\n      final int numToMerge = end - maxSegmentCount + 1;\n      final OneMerge merge = new OneMerge(eligible.subList(end-numToMerge, end));\n      if (verbose(mergeContext)) {\n        message(\"add final merge=\" + merge.segString(), mergeContext);\n      }\n      spec = new MergeSpecification();\n      spec.add(merge);\n    }\n\n    return spec;\n  }\n\n","sourceOld":"  @Override\n  public MergeSpecification findForcedMerges(SegmentInfos infos, int maxSegmentCount, Map<SegmentCommitInfo,Boolean> segmentsToMerge, IndexWriter writer) throws IOException {\n    if (verbose(writer)) {\n      message(\"findForcedMerges maxSegmentCount=\" + maxSegmentCount + \" infos=\" + writer.segString(infos) + \" segmentsToMerge=\" + segmentsToMerge, writer);\n    }\n\n    List<SegmentCommitInfo> eligible = new ArrayList<>();\n    boolean forceMergeRunning = false;\n    final Set<SegmentCommitInfo> merging = writer.getMergingSegments();\n    boolean segmentIsOriginal = false;\n    for(SegmentCommitInfo info : infos) {\n      final Boolean isOriginal = segmentsToMerge.get(info);\n      if (isOriginal != null) {\n        segmentIsOriginal = isOriginal;\n        if (merging.contains(info) == false) {\n          eligible.add(info);\n        } else {\n          forceMergeRunning = true;\n        }\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    // The size can change concurrently while we are running here, because deletes\n    // are now applied concurrently, and this can piss off TimSort!  So we\n    // call size() once per segment and sort by that:\n    Map<SegmentCommitInfo,Long> sizeInBytes = getSegmentSizes(writer, eligible);\n\n    if ((maxSegmentCount > 1 && eligible.size() <= maxSegmentCount) ||\n        (maxSegmentCount == 1 && eligible.size() == 1 && (!segmentIsOriginal || isMerged(infos, eligible.get(0), writer)))) {\n      if (verbose(writer)) {\n        message(\"already merged\", writer);\n      }\n      return null;\n    }\n\n    eligible.sort(new SegmentByteSizeDescending(sizeInBytes));\n\n    if (verbose(writer)) {\n      message(\"eligible=\" + eligible, writer);\n      message(\"forceMergeRunning=\" + forceMergeRunning, writer);\n    }\n\n    int end = eligible.size();\n    \n    MergeSpecification spec = null;\n\n    // Do full merges, first, backwards:\n    while(end >= maxMergeAtOnceExplicit + maxSegmentCount - 1) {\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n      final OneMerge merge = new OneMerge(eligible.subList(end-maxMergeAtOnceExplicit, end));\n      if (verbose(writer)) {\n        message(\"add merge=\" + writer.segString(merge.segments), writer);\n      }\n      spec.add(merge);\n      end -= maxMergeAtOnceExplicit;\n    }\n\n    if (spec == null && !forceMergeRunning) {\n      // Do final merge\n      final int numToMerge = end - maxSegmentCount + 1;\n      final OneMerge merge = new OneMerge(eligible.subList(end-numToMerge, end));\n      if (verbose(writer)) {\n        message(\"add final merge=\" + merge.segString(), writer);\n      }\n      spec = new MergeSpecification();\n      spec.add(merge);\n    }\n\n    return spec;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"56fb5e4e4b239474721e13b4cd9542ea2d215451","date":1529091182,"type":3,"author":"Erick","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedMerges(SegmentInfos,int,Map[SegmentCommitInfo,Boolean],MergeContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedMerges(SegmentInfos,int,Map[SegmentCommitInfo,Boolean],MergeContext).mjava","sourceNew":"  @Override\n  public MergeSpecification findForcedMerges(SegmentInfos infos, int maxSegmentCount, Map<SegmentCommitInfo,Boolean> segmentsToMerge, MergeContext mergeContext) throws IOException {\n    if (verbose(mergeContext)) {\n      message(\"findForcedMerges maxSegmentCount=\" + maxSegmentCount + \" infos=\" + segString(mergeContext, infos) +\n          \" segmentsToMerge=\" + segmentsToMerge, mergeContext);\n    }\n\n    List<SegmentSizeAndDocs> sortedSizeAndDocs = getSortedBySegmentSize(infos, mergeContext);\n\n    long totalMergeBytes = 0;\n    final Set<SegmentCommitInfo> merging = mergeContext.getMergingSegments();\n\n\n    // Trim the list down, remove if we're respecting max segment size and it's not original. Presumably it's been merged before and\n    //   is close enough to the max segment size we shouldn't add it in again.\n    Iterator<SegmentSizeAndDocs> iter = sortedSizeAndDocs.iterator();\n    while (iter.hasNext()) {\n      SegmentSizeAndDocs segSizeDocs = iter.next();\n      final Boolean isOriginal = segmentsToMerge.get(segSizeDocs.segInfo);\n      if (isOriginal == null) {\n        iter.remove();\n      } else {\n        if (merging.contains(segSizeDocs.segInfo)) {\n          iter.remove();\n        } else {\n          totalMergeBytes += segSizeDocs.sizeInBytes;\n        }\n      }\n    }\n\n    long maxMergeBytes = maxMergedSegmentBytes;\n\n    // Set the maximum segment size based on how many segments have been specified.\n    if (maxSegmentCount == 1) maxMergeBytes = Long.MAX_VALUE;\n    else if (maxSegmentCount != Integer.MAX_VALUE) {\n      // Fudge this up a bit so we have a better chance of not having to rewrite segments. If we use the exact size,\n      // it's almost guaranteed that the segments won't fit perfectly and we'll be left with more segments than\n      // we want and have to re-merge in the code at the bottom of this method.\n      maxMergeBytes = Math.max((long) (((double) totalMergeBytes / (double) maxSegmentCount)), maxMergedSegmentBytes);\n      maxMergeBytes = (long) ((double) maxMergeBytes * 1.25);\n    }\n\n    iter = sortedSizeAndDocs.iterator();\n    boolean foundDeletes = false;\n    while (iter.hasNext()) {\n      SegmentSizeAndDocs segSizeDocs = iter.next();\n      Boolean isOriginal = segmentsToMerge.get(segSizeDocs.segInfo);\n      if (segSizeDocs.delCount != 0) { // This is forceMerge, all segments with deleted docs should be merged.\n        if (isOriginal != null && isOriginal) {\n          foundDeletes = true;\n        }\n        continue;\n      }\n      // Let the scoring handle whether to merge large segments.\n      if (maxSegmentCount == Integer.MAX_VALUE && isOriginal != null && isOriginal == false) {\n        iter.remove();\n      }\n      // Don't try to merge a segment with no deleted docs that's over the max size.\n      if (maxSegmentCount != Integer.MAX_VALUE && segSizeDocs.sizeInBytes >= maxMergeBytes) {\n        iter.remove();\n      }\n    }\n\n    // Nothing to merge this round.\n    if (sortedSizeAndDocs.size() == 0) {\n      return null;\n    }\n\n    // We should never bail if there are segments that have deleted documents, all deleted docs should be purged.\n    if (foundDeletes == false) {\n      SegmentCommitInfo infoZero = sortedSizeAndDocs.get(0).segInfo;\n      if ((maxSegmentCount != Integer.MAX_VALUE && maxSegmentCount > 1 && sortedSizeAndDocs.size() <= maxSegmentCount) ||\n          (maxSegmentCount == 1 && sortedSizeAndDocs.size() == 1 && (segmentsToMerge.get(infoZero) != null || isMerged(infos, infoZero, mergeContext)))) {\n        if (verbose(mergeContext)) {\n          message(\"already merged\", mergeContext);\n        }\n        return null;\n      }\n    }\n\n    if (verbose(mergeContext)) {\n      message(\"eligible=\" + sortedSizeAndDocs, mergeContext);\n    }\n\n    // This is the special case of merging down to one segment\n    if (sortedSizeAndDocs.size() < maxMergeAtOnceExplicit && maxSegmentCount == 1 && totalMergeBytes < maxMergeBytes) {\n      MergeSpecification spec = new MergeSpecification();\n      List<SegmentCommitInfo> allOfThem = new ArrayList<>();\n      for (SegmentSizeAndDocs segSizeDocs : sortedSizeAndDocs) {\n        allOfThem.add(segSizeDocs.segInfo);\n      }\n      spec.add(new OneMerge(allOfThem));\n      return spec;\n    }\n\n    MergeSpecification spec = doFindMerges(sortedSizeAndDocs, maxMergeBytes, maxMergeAtOnceExplicit,\n        maxSegmentCount, MERGE_TYPE.FORCE_MERGE, mergeContext, false);\n\n    return spec;\n  }\n\n","sourceOld":"  @Override\n  public MergeSpecification findForcedMerges(SegmentInfos infos, int maxSegmentCount, Map<SegmentCommitInfo,Boolean> segmentsToMerge, MergeContext mergeContext) throws IOException {\n    if (verbose(mergeContext)) {\n      message(\"findForcedMerges maxSegmentCount=\" + maxSegmentCount + \" infos=\" + segString(mergeContext, infos) + \" segmentsToMerge=\" + segmentsToMerge, mergeContext);\n    }\n\n    List<SegmentCommitInfo> eligible = new ArrayList<>();\n    boolean forceMergeRunning = false;\n    final Set<SegmentCommitInfo> merging = mergeContext.getMergingSegments();\n    boolean segmentIsOriginal = false;\n    for(SegmentCommitInfo info : infos) {\n      final Boolean isOriginal = segmentsToMerge.get(info);\n      if (isOriginal != null) {\n        segmentIsOriginal = isOriginal;\n        if (merging.contains(info) == false) {\n          eligible.add(info);\n        } else {\n          forceMergeRunning = true;\n        }\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    // The size can change concurrently while we are running here, because deletes\n    // are now applied concurrently, and this can piss off TimSort!  So we\n    // call size() once per segment and sort by that:\n    Map<SegmentCommitInfo,Long> sizeInBytes = getSegmentSizes(mergeContext, eligible);\n\n    if ((maxSegmentCount > 1 && eligible.size() <= maxSegmentCount) ||\n        (maxSegmentCount == 1 && eligible.size() == 1 && (!segmentIsOriginal || isMerged(infos, eligible.get(0), mergeContext)))) {\n      if (verbose(mergeContext)) {\n        message(\"already merged\", mergeContext);\n      }\n      return null;\n    }\n\n    eligible.sort(new SegmentByteSizeDescending(sizeInBytes));\n\n    if (verbose(mergeContext)) {\n      message(\"eligible=\" + eligible, mergeContext);\n      message(\"forceMergeRunning=\" + forceMergeRunning, mergeContext);\n    }\n\n    int end = eligible.size();\n    \n    MergeSpecification spec = null;\n\n    // Do full merges, first, backwards:\n    while(end >= maxMergeAtOnceExplicit + maxSegmentCount - 1) {\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n      final OneMerge merge = new OneMerge(eligible.subList(end-maxMergeAtOnceExplicit, end));\n      if (verbose(mergeContext)) {\n        message(\"add merge=\" + segString(mergeContext, merge.segments), mergeContext);\n      }\n      spec.add(merge);\n      end -= maxMergeAtOnceExplicit;\n    }\n\n    if (spec == null && !forceMergeRunning) {\n      // Do final merge\n      final int numToMerge = end - maxSegmentCount + 1;\n      final OneMerge merge = new OneMerge(eligible.subList(end-numToMerge, end));\n      if (verbose(mergeContext)) {\n        message(\"add final merge=\" + merge.segString(), mergeContext);\n      }\n      spec = new MergeSpecification();\n      spec.add(merge);\n    }\n\n    return spec;\n  }\n\n","bugFix":null,"bugIntro":["79ba4baff197d5691f403962548d82fe855e4101"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedMerges(SegmentInfos,int,Map[SegmentCommitInfo,Boolean],MergeContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedMerges(SegmentInfos,int,Map[SegmentCommitInfo,Boolean],MergeContext).mjava","sourceNew":"  @Override\n  public MergeSpecification findForcedMerges(SegmentInfos infos, int maxSegmentCount, Map<SegmentCommitInfo,Boolean> segmentsToMerge, MergeContext mergeContext) throws IOException {\n    if (verbose(mergeContext)) {\n      message(\"findForcedMerges maxSegmentCount=\" + maxSegmentCount + \" infos=\" + segString(mergeContext, infos) +\n          \" segmentsToMerge=\" + segmentsToMerge, mergeContext);\n    }\n\n    List<SegmentSizeAndDocs> sortedSizeAndDocs = getSortedBySegmentSize(infos, mergeContext);\n\n    long totalMergeBytes = 0;\n    final Set<SegmentCommitInfo> merging = mergeContext.getMergingSegments();\n\n\n    // Trim the list down, remove if we're respecting max segment size and it's not original. Presumably it's been merged before and\n    //   is close enough to the max segment size we shouldn't add it in again.\n    Iterator<SegmentSizeAndDocs> iter = sortedSizeAndDocs.iterator();\n    while (iter.hasNext()) {\n      SegmentSizeAndDocs segSizeDocs = iter.next();\n      final Boolean isOriginal = segmentsToMerge.get(segSizeDocs.segInfo);\n      if (isOriginal == null) {\n        iter.remove();\n      } else {\n        if (merging.contains(segSizeDocs.segInfo)) {\n          iter.remove();\n        } else {\n          totalMergeBytes += segSizeDocs.sizeInBytes;\n        }\n      }\n    }\n\n    long maxMergeBytes = maxMergedSegmentBytes;\n\n    // Set the maximum segment size based on how many segments have been specified.\n    if (maxSegmentCount == 1) maxMergeBytes = Long.MAX_VALUE;\n    else if (maxSegmentCount != Integer.MAX_VALUE) {\n      // Fudge this up a bit so we have a better chance of not having to rewrite segments. If we use the exact size,\n      // it's almost guaranteed that the segments won't fit perfectly and we'll be left with more segments than\n      // we want and have to re-merge in the code at the bottom of this method.\n      maxMergeBytes = Math.max((long) (((double) totalMergeBytes / (double) maxSegmentCount)), maxMergedSegmentBytes);\n      maxMergeBytes = (long) ((double) maxMergeBytes * 1.25);\n    }\n\n    iter = sortedSizeAndDocs.iterator();\n    boolean foundDeletes = false;\n    while (iter.hasNext()) {\n      SegmentSizeAndDocs segSizeDocs = iter.next();\n      Boolean isOriginal = segmentsToMerge.get(segSizeDocs.segInfo);\n      if (segSizeDocs.delCount != 0) { // This is forceMerge, all segments with deleted docs should be merged.\n        if (isOriginal != null && isOriginal) {\n          foundDeletes = true;\n        }\n        continue;\n      }\n      // Let the scoring handle whether to merge large segments.\n      if (maxSegmentCount == Integer.MAX_VALUE && isOriginal != null && isOriginal == false) {\n        iter.remove();\n      }\n      // Don't try to merge a segment with no deleted docs that's over the max size.\n      if (maxSegmentCount != Integer.MAX_VALUE && segSizeDocs.sizeInBytes >= maxMergeBytes) {\n        iter.remove();\n      }\n    }\n\n    // Nothing to merge this round.\n    if (sortedSizeAndDocs.size() == 0) {\n      return null;\n    }\n\n    // We should never bail if there are segments that have deleted documents, all deleted docs should be purged.\n    if (foundDeletes == false) {\n      SegmentCommitInfo infoZero = sortedSizeAndDocs.get(0).segInfo;\n      if ((maxSegmentCount != Integer.MAX_VALUE && maxSegmentCount > 1 && sortedSizeAndDocs.size() <= maxSegmentCount) ||\n          (maxSegmentCount == 1 && sortedSizeAndDocs.size() == 1 && (segmentsToMerge.get(infoZero) != null || isMerged(infos, infoZero, mergeContext)))) {\n        if (verbose(mergeContext)) {\n          message(\"already merged\", mergeContext);\n        }\n        return null;\n      }\n    }\n\n    if (verbose(mergeContext)) {\n      message(\"eligible=\" + sortedSizeAndDocs, mergeContext);\n    }\n\n    // This is the special case of merging down to one segment\n    if (sortedSizeAndDocs.size() < maxMergeAtOnceExplicit && maxSegmentCount == 1 && totalMergeBytes < maxMergeBytes) {\n      MergeSpecification spec = new MergeSpecification();\n      List<SegmentCommitInfo> allOfThem = new ArrayList<>();\n      for (SegmentSizeAndDocs segSizeDocs : sortedSizeAndDocs) {\n        allOfThem.add(segSizeDocs.segInfo);\n      }\n      spec.add(new OneMerge(allOfThem));\n      return spec;\n    }\n\n    MergeSpecification spec = doFindMerges(sortedSizeAndDocs, maxMergeBytes, maxMergeAtOnceExplicit,\n        maxSegmentCount, MERGE_TYPE.FORCE_MERGE, mergeContext, false);\n\n    return spec;\n  }\n\n","sourceOld":"  @Override\n  public MergeSpecification findForcedMerges(SegmentInfos infos, int maxSegmentCount, Map<SegmentCommitInfo,Boolean> segmentsToMerge, MergeContext mergeContext) throws IOException {\n    if (verbose(mergeContext)) {\n      message(\"findForcedMerges maxSegmentCount=\" + maxSegmentCount + \" infos=\" + segString(mergeContext, infos) + \" segmentsToMerge=\" + segmentsToMerge, mergeContext);\n    }\n\n    List<SegmentCommitInfo> eligible = new ArrayList<>();\n    boolean forceMergeRunning = false;\n    final Set<SegmentCommitInfo> merging = mergeContext.getMergingSegments();\n    boolean segmentIsOriginal = false;\n    for(SegmentCommitInfo info : infos) {\n      final Boolean isOriginal = segmentsToMerge.get(info);\n      if (isOriginal != null) {\n        segmentIsOriginal = isOriginal;\n        if (merging.contains(info) == false) {\n          eligible.add(info);\n        } else {\n          forceMergeRunning = true;\n        }\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    // The size can change concurrently while we are running here, because deletes\n    // are now applied concurrently, and this can piss off TimSort!  So we\n    // call size() once per segment and sort by that:\n    Map<SegmentCommitInfo,Long> sizeInBytes = getSegmentSizes(mergeContext, eligible);\n\n    if ((maxSegmentCount > 1 && eligible.size() <= maxSegmentCount) ||\n        (maxSegmentCount == 1 && eligible.size() == 1 && (!segmentIsOriginal || isMerged(infos, eligible.get(0), mergeContext)))) {\n      if (verbose(mergeContext)) {\n        message(\"already merged\", mergeContext);\n      }\n      return null;\n    }\n\n    eligible.sort(new SegmentByteSizeDescending(sizeInBytes));\n\n    if (verbose(mergeContext)) {\n      message(\"eligible=\" + eligible, mergeContext);\n      message(\"forceMergeRunning=\" + forceMergeRunning, mergeContext);\n    }\n\n    int end = eligible.size();\n    \n    MergeSpecification spec = null;\n\n    // Do full merges, first, backwards:\n    while(end >= maxMergeAtOnceExplicit + maxSegmentCount - 1) {\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n      final OneMerge merge = new OneMerge(eligible.subList(end-maxMergeAtOnceExplicit, end));\n      if (verbose(mergeContext)) {\n        message(\"add merge=\" + segString(mergeContext, merge.segments), mergeContext);\n      }\n      spec.add(merge);\n      end -= maxMergeAtOnceExplicit;\n    }\n\n    if (spec == null && !forceMergeRunning) {\n      // Do final merge\n      final int numToMerge = end - maxSegmentCount + 1;\n      final OneMerge merge = new OneMerge(eligible.subList(end-numToMerge, end));\n      if (verbose(mergeContext)) {\n        message(\"add final merge=\" + merge.segString(), mergeContext);\n      }\n      spec = new MergeSpecification();\n      spec.add(merge);\n    }\n\n    return spec;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4a90cc8c90aa53ddf51fbd15019989ac269514a3","date":1531845066,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedMerges(SegmentInfos,int,Map[SegmentCommitInfo,Boolean],MergeContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedMerges(SegmentInfos,int,Map[SegmentCommitInfo,Boolean],MergeContext).mjava","sourceNew":"  @Override\n  public MergeSpecification findForcedMerges(SegmentInfos infos, int maxSegmentCount, Map<SegmentCommitInfo,Boolean> segmentsToMerge, MergeContext mergeContext) throws IOException {\n    if (verbose(mergeContext)) {\n      message(\"findForcedMerges maxSegmentCount=\" + maxSegmentCount + \" infos=\" + segString(mergeContext, infos) +\n          \" segmentsToMerge=\" + segmentsToMerge, mergeContext);\n    }\n\n    List<SegmentSizeAndDocs> sortedSizeAndDocs = getSortedBySegmentSize(infos, mergeContext);\n\n    long totalMergeBytes = 0;\n    final Set<SegmentCommitInfo> merging = mergeContext.getMergingSegments();\n\n\n    // Trim the list down, remove if we're respecting max segment size and it's not original. Presumably it's been merged before and\n    //   is close enough to the max segment size we shouldn't add it in again.\n    Iterator<SegmentSizeAndDocs> iter = sortedSizeAndDocs.iterator();\n    while (iter.hasNext()) {\n      SegmentSizeAndDocs segSizeDocs = iter.next();\n      final Boolean isOriginal = segmentsToMerge.get(segSizeDocs.segInfo);\n      if (isOriginal == null) {\n        iter.remove();\n      } else {\n        if (merging.contains(segSizeDocs.segInfo)) {\n          iter.remove();\n        } else {\n          totalMergeBytes += segSizeDocs.sizeInBytes;\n        }\n      }\n    }\n\n    long maxMergeBytes = maxMergedSegmentBytes;\n\n    // Set the maximum segment size based on how many segments have been specified.\n    if (maxSegmentCount == 1) maxMergeBytes = Long.MAX_VALUE;\n    else if (maxSegmentCount != Integer.MAX_VALUE) {\n      // Fudge this up a bit so we have a better chance of not having to rewrite segments. If we use the exact size,\n      // it's almost guaranteed that the segments won't fit perfectly and we'll be left with more segments than\n      // we want and have to re-merge in the code at the bottom of this method.\n      maxMergeBytes = Math.max((long) (((double) totalMergeBytes / (double) maxSegmentCount)), maxMergedSegmentBytes);\n      maxMergeBytes = (long) ((double) maxMergeBytes * 1.25);\n    }\n\n    iter = sortedSizeAndDocs.iterator();\n    boolean foundDeletes = false;\n    while (iter.hasNext()) {\n      SegmentSizeAndDocs segSizeDocs = iter.next();\n      Boolean isOriginal = segmentsToMerge.get(segSizeDocs.segInfo);\n      if (segSizeDocs.delCount != 0) { // This is forceMerge, all segments with deleted docs should be merged.\n        if (isOriginal != null && isOriginal) {\n          foundDeletes = true;\n        }\n        continue;\n      }\n      // Let the scoring handle whether to merge large segments.\n      if (maxSegmentCount == Integer.MAX_VALUE && isOriginal != null && isOriginal == false) {\n        iter.remove();\n      }\n      // Don't try to merge a segment with no deleted docs that's over the max size.\n      if (maxSegmentCount != Integer.MAX_VALUE && segSizeDocs.sizeInBytes >= maxMergeBytes) {\n        iter.remove();\n      }\n    }\n\n    // Nothing to merge this round.\n    if (sortedSizeAndDocs.size() == 0) {\n      return null;\n    }\n\n    // We should never bail if there are segments that have deleted documents, all deleted docs should be purged.\n    if (foundDeletes == false) {\n      SegmentCommitInfo infoZero = sortedSizeAndDocs.get(0).segInfo;\n      if ((maxSegmentCount != Integer.MAX_VALUE && maxSegmentCount > 1 && sortedSizeAndDocs.size() <= maxSegmentCount) ||\n          (maxSegmentCount == 1 && sortedSizeAndDocs.size() == 1 && (segmentsToMerge.get(infoZero) != null || isMerged(infos, infoZero, mergeContext)))) {\n        if (verbose(mergeContext)) {\n          message(\"already merged\", mergeContext);\n        }\n        return null;\n      }\n    }\n\n    if (verbose(mergeContext)) {\n      message(\"eligible=\" + sortedSizeAndDocs, mergeContext);\n    }\n\n    // This is the special case of merging down to one segment\n    if (sortedSizeAndDocs.size() < maxMergeAtOnceExplicit && maxSegmentCount == 1 && totalMergeBytes < maxMergeBytes) {\n      MergeSpecification spec = new MergeSpecification();\n      List<SegmentCommitInfo> allOfThem = new ArrayList<>();\n      for (SegmentSizeAndDocs segSizeDocs : sortedSizeAndDocs) {\n        allOfThem.add(segSizeDocs.segInfo);\n      }\n      spec.add(new OneMerge(allOfThem));\n      return spec;\n    }\n\n    MergeSpecification spec = doFindMerges(sortedSizeAndDocs, maxMergeBytes, maxMergeAtOnceExplicit,\n        maxSegmentCount, 0, MERGE_TYPE.FORCE_MERGE, mergeContext, false);\n\n    return spec;\n  }\n\n","sourceOld":"  @Override\n  public MergeSpecification findForcedMerges(SegmentInfos infos, int maxSegmentCount, Map<SegmentCommitInfo,Boolean> segmentsToMerge, MergeContext mergeContext) throws IOException {\n    if (verbose(mergeContext)) {\n      message(\"findForcedMerges maxSegmentCount=\" + maxSegmentCount + \" infos=\" + segString(mergeContext, infos) +\n          \" segmentsToMerge=\" + segmentsToMerge, mergeContext);\n    }\n\n    List<SegmentSizeAndDocs> sortedSizeAndDocs = getSortedBySegmentSize(infos, mergeContext);\n\n    long totalMergeBytes = 0;\n    final Set<SegmentCommitInfo> merging = mergeContext.getMergingSegments();\n\n\n    // Trim the list down, remove if we're respecting max segment size and it's not original. Presumably it's been merged before and\n    //   is close enough to the max segment size we shouldn't add it in again.\n    Iterator<SegmentSizeAndDocs> iter = sortedSizeAndDocs.iterator();\n    while (iter.hasNext()) {\n      SegmentSizeAndDocs segSizeDocs = iter.next();\n      final Boolean isOriginal = segmentsToMerge.get(segSizeDocs.segInfo);\n      if (isOriginal == null) {\n        iter.remove();\n      } else {\n        if (merging.contains(segSizeDocs.segInfo)) {\n          iter.remove();\n        } else {\n          totalMergeBytes += segSizeDocs.sizeInBytes;\n        }\n      }\n    }\n\n    long maxMergeBytes = maxMergedSegmentBytes;\n\n    // Set the maximum segment size based on how many segments have been specified.\n    if (maxSegmentCount == 1) maxMergeBytes = Long.MAX_VALUE;\n    else if (maxSegmentCount != Integer.MAX_VALUE) {\n      // Fudge this up a bit so we have a better chance of not having to rewrite segments. If we use the exact size,\n      // it's almost guaranteed that the segments won't fit perfectly and we'll be left with more segments than\n      // we want and have to re-merge in the code at the bottom of this method.\n      maxMergeBytes = Math.max((long) (((double) totalMergeBytes / (double) maxSegmentCount)), maxMergedSegmentBytes);\n      maxMergeBytes = (long) ((double) maxMergeBytes * 1.25);\n    }\n\n    iter = sortedSizeAndDocs.iterator();\n    boolean foundDeletes = false;\n    while (iter.hasNext()) {\n      SegmentSizeAndDocs segSizeDocs = iter.next();\n      Boolean isOriginal = segmentsToMerge.get(segSizeDocs.segInfo);\n      if (segSizeDocs.delCount != 0) { // This is forceMerge, all segments with deleted docs should be merged.\n        if (isOriginal != null && isOriginal) {\n          foundDeletes = true;\n        }\n        continue;\n      }\n      // Let the scoring handle whether to merge large segments.\n      if (maxSegmentCount == Integer.MAX_VALUE && isOriginal != null && isOriginal == false) {\n        iter.remove();\n      }\n      // Don't try to merge a segment with no deleted docs that's over the max size.\n      if (maxSegmentCount != Integer.MAX_VALUE && segSizeDocs.sizeInBytes >= maxMergeBytes) {\n        iter.remove();\n      }\n    }\n\n    // Nothing to merge this round.\n    if (sortedSizeAndDocs.size() == 0) {\n      return null;\n    }\n\n    // We should never bail if there are segments that have deleted documents, all deleted docs should be purged.\n    if (foundDeletes == false) {\n      SegmentCommitInfo infoZero = sortedSizeAndDocs.get(0).segInfo;\n      if ((maxSegmentCount != Integer.MAX_VALUE && maxSegmentCount > 1 && sortedSizeAndDocs.size() <= maxSegmentCount) ||\n          (maxSegmentCount == 1 && sortedSizeAndDocs.size() == 1 && (segmentsToMerge.get(infoZero) != null || isMerged(infos, infoZero, mergeContext)))) {\n        if (verbose(mergeContext)) {\n          message(\"already merged\", mergeContext);\n        }\n        return null;\n      }\n    }\n\n    if (verbose(mergeContext)) {\n      message(\"eligible=\" + sortedSizeAndDocs, mergeContext);\n    }\n\n    // This is the special case of merging down to one segment\n    if (sortedSizeAndDocs.size() < maxMergeAtOnceExplicit && maxSegmentCount == 1 && totalMergeBytes < maxMergeBytes) {\n      MergeSpecification spec = new MergeSpecification();\n      List<SegmentCommitInfo> allOfThem = new ArrayList<>();\n      for (SegmentSizeAndDocs segSizeDocs : sortedSizeAndDocs) {\n        allOfThem.add(segSizeDocs.segInfo);\n      }\n      spec.add(new OneMerge(allOfThem));\n      return spec;\n    }\n\n    MergeSpecification spec = doFindMerges(sortedSizeAndDocs, maxMergeBytes, maxMergeAtOnceExplicit,\n        maxSegmentCount, MERGE_TYPE.FORCE_MERGE, mergeContext, false);\n\n    return spec;\n  }\n\n","bugFix":null,"bugIntro":["79ba4baff197d5691f403962548d82fe855e4101"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedMerges(SegmentInfos,int,Map[SegmentCommitInfo,Boolean],MergeContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedMerges(SegmentInfos,int,Map[SegmentCommitInfo,Boolean],MergeContext).mjava","sourceNew":"  @Override\n  public MergeSpecification findForcedMerges(SegmentInfos infos, int maxSegmentCount, Map<SegmentCommitInfo,Boolean> segmentsToMerge, MergeContext mergeContext) throws IOException {\n    if (verbose(mergeContext)) {\n      message(\"findForcedMerges maxSegmentCount=\" + maxSegmentCount + \" infos=\" + segString(mergeContext, infos) +\n          \" segmentsToMerge=\" + segmentsToMerge, mergeContext);\n    }\n\n    List<SegmentSizeAndDocs> sortedSizeAndDocs = getSortedBySegmentSize(infos, mergeContext);\n\n    long totalMergeBytes = 0;\n    final Set<SegmentCommitInfo> merging = mergeContext.getMergingSegments();\n\n\n    // Trim the list down, remove if we're respecting max segment size and it's not original. Presumably it's been merged before and\n    //   is close enough to the max segment size we shouldn't add it in again.\n    Iterator<SegmentSizeAndDocs> iter = sortedSizeAndDocs.iterator();\n    while (iter.hasNext()) {\n      SegmentSizeAndDocs segSizeDocs = iter.next();\n      final Boolean isOriginal = segmentsToMerge.get(segSizeDocs.segInfo);\n      if (isOriginal == null) {\n        iter.remove();\n      } else {\n        if (merging.contains(segSizeDocs.segInfo)) {\n          iter.remove();\n        } else {\n          totalMergeBytes += segSizeDocs.sizeInBytes;\n        }\n      }\n    }\n\n    long maxMergeBytes = maxMergedSegmentBytes;\n\n    // Set the maximum segment size based on how many segments have been specified.\n    if (maxSegmentCount == 1) maxMergeBytes = Long.MAX_VALUE;\n    else if (maxSegmentCount != Integer.MAX_VALUE) {\n      // Fudge this up a bit so we have a better chance of not having to rewrite segments. If we use the exact size,\n      // it's almost guaranteed that the segments won't fit perfectly and we'll be left with more segments than\n      // we want and have to re-merge in the code at the bottom of this method.\n      maxMergeBytes = Math.max((long) (((double) totalMergeBytes / (double) maxSegmentCount)), maxMergedSegmentBytes);\n      maxMergeBytes = (long) ((double) maxMergeBytes * 1.25);\n    }\n\n    iter = sortedSizeAndDocs.iterator();\n    boolean foundDeletes = false;\n    while (iter.hasNext()) {\n      SegmentSizeAndDocs segSizeDocs = iter.next();\n      Boolean isOriginal = segmentsToMerge.get(segSizeDocs.segInfo);\n      if (segSizeDocs.delCount != 0) { // This is forceMerge, all segments with deleted docs should be merged.\n        if (isOriginal != null && isOriginal) {\n          foundDeletes = true;\n        }\n        continue;\n      }\n      // Let the scoring handle whether to merge large segments.\n      if (maxSegmentCount == Integer.MAX_VALUE && isOriginal != null && isOriginal == false) {\n        iter.remove();\n      }\n      // Don't try to merge a segment with no deleted docs that's over the max size.\n      if (maxSegmentCount != Integer.MAX_VALUE && segSizeDocs.sizeInBytes >= maxMergeBytes) {\n        iter.remove();\n      }\n    }\n\n    // Nothing to merge this round.\n    if (sortedSizeAndDocs.size() == 0) {\n      return null;\n    }\n\n    // We should never bail if there are segments that have deleted documents, all deleted docs should be purged.\n    if (foundDeletes == false) {\n      SegmentCommitInfo infoZero = sortedSizeAndDocs.get(0).segInfo;\n      if ((maxSegmentCount != Integer.MAX_VALUE && maxSegmentCount > 1 && sortedSizeAndDocs.size() <= maxSegmentCount) ||\n          (maxSegmentCount == 1 && sortedSizeAndDocs.size() == 1 && (segmentsToMerge.get(infoZero) != null || isMerged(infos, infoZero, mergeContext)))) {\n        if (verbose(mergeContext)) {\n          message(\"already merged\", mergeContext);\n        }\n        return null;\n      }\n    }\n\n    if (verbose(mergeContext)) {\n      message(\"eligible=\" + sortedSizeAndDocs, mergeContext);\n    }\n\n    // This is the special case of merging down to one segment\n    if (sortedSizeAndDocs.size() < maxMergeAtOnceExplicit && maxSegmentCount == 1 && totalMergeBytes < maxMergeBytes) {\n      MergeSpecification spec = new MergeSpecification();\n      List<SegmentCommitInfo> allOfThem = new ArrayList<>();\n      for (SegmentSizeAndDocs segSizeDocs : sortedSizeAndDocs) {\n        allOfThem.add(segSizeDocs.segInfo);\n      }\n      spec.add(new OneMerge(allOfThem));\n      return spec;\n    }\n\n    MergeSpecification spec = doFindMerges(sortedSizeAndDocs, maxMergeBytes, maxMergeAtOnceExplicit,\n        maxSegmentCount, 0, MERGE_TYPE.FORCE_MERGE, mergeContext, false);\n\n    return spec;\n  }\n\n","sourceOld":"  @Override\n  public MergeSpecification findForcedMerges(SegmentInfos infos, int maxSegmentCount, Map<SegmentCommitInfo,Boolean> segmentsToMerge, MergeContext mergeContext) throws IOException {\n    if (verbose(mergeContext)) {\n      message(\"findForcedMerges maxSegmentCount=\" + maxSegmentCount + \" infos=\" + segString(mergeContext, infos) + \" segmentsToMerge=\" + segmentsToMerge, mergeContext);\n    }\n\n    List<SegmentCommitInfo> eligible = new ArrayList<>();\n    boolean forceMergeRunning = false;\n    final Set<SegmentCommitInfo> merging = mergeContext.getMergingSegments();\n    boolean segmentIsOriginal = false;\n    for(SegmentCommitInfo info : infos) {\n      final Boolean isOriginal = segmentsToMerge.get(info);\n      if (isOriginal != null) {\n        segmentIsOriginal = isOriginal;\n        if (merging.contains(info) == false) {\n          eligible.add(info);\n        } else {\n          forceMergeRunning = true;\n        }\n      }\n    }\n\n    if (eligible.size() == 0) {\n      return null;\n    }\n\n    // The size can change concurrently while we are running here, because deletes\n    // are now applied concurrently, and this can piss off TimSort!  So we\n    // call size() once per segment and sort by that:\n    Map<SegmentCommitInfo,Long> sizeInBytes = getSegmentSizes(mergeContext, eligible);\n\n    if ((maxSegmentCount > 1 && eligible.size() <= maxSegmentCount) ||\n        (maxSegmentCount == 1 && eligible.size() == 1 && (!segmentIsOriginal || isMerged(infos, eligible.get(0), mergeContext)))) {\n      if (verbose(mergeContext)) {\n        message(\"already merged\", mergeContext);\n      }\n      return null;\n    }\n\n    eligible.sort(new SegmentByteSizeDescending(sizeInBytes));\n\n    if (verbose(mergeContext)) {\n      message(\"eligible=\" + eligible, mergeContext);\n      message(\"forceMergeRunning=\" + forceMergeRunning, mergeContext);\n    }\n\n    int end = eligible.size();\n    \n    MergeSpecification spec = null;\n\n    // Do full merges, first, backwards:\n    while(end >= maxMergeAtOnceExplicit + maxSegmentCount - 1) {\n      if (spec == null) {\n        spec = new MergeSpecification();\n      }\n      final OneMerge merge = new OneMerge(eligible.subList(end-maxMergeAtOnceExplicit, end));\n      if (verbose(mergeContext)) {\n        message(\"add merge=\" + segString(mergeContext, merge.segments), mergeContext);\n      }\n      spec.add(merge);\n      end -= maxMergeAtOnceExplicit;\n    }\n\n    if (spec == null && !forceMergeRunning) {\n      // Do final merge\n      final int numToMerge = end - maxSegmentCount + 1;\n      final OneMerge merge = new OneMerge(eligible.subList(end-numToMerge, end));\n      if (verbose(mergeContext)) {\n        message(\"add final merge=\" + merge.segString(), mergeContext);\n      }\n      spec = new MergeSpecification();\n      spec.add(merge);\n    }\n\n    return spec;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"79ba4baff197d5691f403962548d82fe855e4101","date":1552642047,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedMerges(SegmentInfos,int,Map[SegmentCommitInfo,Boolean],MergeContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy#findForcedMerges(SegmentInfos,int,Map[SegmentCommitInfo,Boolean],MergeContext).mjava","sourceNew":"  @Override\n  public MergeSpecification findForcedMerges(SegmentInfos infos, int maxSegmentCount, Map<SegmentCommitInfo, Boolean> segmentsToMerge, MergeContext mergeContext) throws IOException {\n    if (verbose(mergeContext)) {\n      message(\"findForcedMerges maxSegmentCount=\" + maxSegmentCount + \" infos=\" + segString(mergeContext, infos) +\n          \" segmentsToMerge=\" + segmentsToMerge, mergeContext);\n    }\n\n    List<SegmentSizeAndDocs> sortedSizeAndDocs = getSortedBySegmentSize(infos, mergeContext);\n\n    long totalMergeBytes = 0;\n    final Set<SegmentCommitInfo> merging = mergeContext.getMergingSegments();\n\n\n    // Trim the list down, remove if we're respecting max segment size and it's not original. Presumably it's been merged before and\n    //   is close enough to the max segment size we shouldn't add it in again.\n    Iterator<SegmentSizeAndDocs> iter = sortedSizeAndDocs.iterator();\n    boolean forceMergeRunning = false;\n    while (iter.hasNext()) {\n      SegmentSizeAndDocs segSizeDocs = iter.next();\n      final Boolean isOriginal = segmentsToMerge.get(segSizeDocs.segInfo);\n      if (isOriginal == null) {\n        iter.remove();\n      } else {\n        if (merging.contains(segSizeDocs.segInfo)) {\n          forceMergeRunning = true;\n          iter.remove();\n        } else {\n          totalMergeBytes += segSizeDocs.sizeInBytes;\n        }\n      }\n    }\n\n    long maxMergeBytes = maxMergedSegmentBytes;\n\n    // Set the maximum segment size based on how many segments have been specified.\n    if (maxSegmentCount == 1) maxMergeBytes = Long.MAX_VALUE;\n    else if (maxSegmentCount != Integer.MAX_VALUE) {\n      // Fudge this up a bit so we have a better chance of not having to rewrite segments. If we use the exact size,\n      // it's almost guaranteed that the segments won't fit perfectly and we'll be left with more segments than\n      // we want and have to re-merge in the code at the bottom of this method.\n      maxMergeBytes = Math.max((long) (((double) totalMergeBytes / (double) maxSegmentCount)), maxMergedSegmentBytes);\n      maxMergeBytes = (long) ((double) maxMergeBytes * 1.25);\n    }\n\n    iter = sortedSizeAndDocs.iterator();\n    boolean foundDeletes = false;\n    while (iter.hasNext()) {\n      SegmentSizeAndDocs segSizeDocs = iter.next();\n      Boolean isOriginal = segmentsToMerge.get(segSizeDocs.segInfo);\n      if (segSizeDocs.delCount != 0) { // This is forceMerge, all segments with deleted docs should be merged.\n        if (isOriginal != null && isOriginal) {\n          foundDeletes = true;\n        }\n        continue;\n      }\n      // Let the scoring handle whether to merge large segments.\n      if (maxSegmentCount == Integer.MAX_VALUE && isOriginal != null && isOriginal == false) {\n        iter.remove();\n      }\n      // Don't try to merge a segment with no deleted docs that's over the max size.\n      if (maxSegmentCount != Integer.MAX_VALUE && segSizeDocs.sizeInBytes >= maxMergeBytes) {\n        iter.remove();\n      }\n    }\n\n    // Nothing to merge this round.\n    if (sortedSizeAndDocs.size() == 0) {\n      return null;\n    }\n\n    // We should never bail if there are segments that have deleted documents, all deleted docs should be purged.\n    if (foundDeletes == false) {\n      SegmentCommitInfo infoZero = sortedSizeAndDocs.get(0).segInfo;\n      if ((maxSegmentCount != Integer.MAX_VALUE && maxSegmentCount > 1 && sortedSizeAndDocs.size() <= maxSegmentCount) ||\n          (maxSegmentCount == 1 && sortedSizeAndDocs.size() == 1 && (segmentsToMerge.get(infoZero) != null || isMerged(infos, infoZero, mergeContext)))) {\n        if (verbose(mergeContext)) {\n          message(\"already merged\", mergeContext);\n        }\n        return null;\n      }\n    }\n\n    if (verbose(mergeContext)) {\n      message(\"eligible=\" + sortedSizeAndDocs, mergeContext);\n    }\n\n    final int startingSegmentCount = sortedSizeAndDocs.size();\n    final boolean finalMerge = startingSegmentCount < maxSegmentCount + maxMergeAtOnceExplicit - 1;\n    if (finalMerge && forceMergeRunning) {\n      return null;\n    }\n\n    // This is the special case of merging down to one segment\n    if (sortedSizeAndDocs.size() < maxMergeAtOnceExplicit && maxSegmentCount == 1 && totalMergeBytes < maxMergeBytes) {\n      MergeSpecification spec = new MergeSpecification();\n      List<SegmentCommitInfo> allOfThem = new ArrayList<>();\n      for (SegmentSizeAndDocs segSizeDocs : sortedSizeAndDocs) {\n        allOfThem.add(segSizeDocs.segInfo);\n      }\n      spec.add(new OneMerge(allOfThem));\n      return spec;\n    }\n\n    MergeSpecification spec = null;\n\n    int index = startingSegmentCount - 1;\n    int resultingSegments = startingSegmentCount;\n    while (true) {\n      List<SegmentCommitInfo> candidate = new ArrayList<>();\n      long currentCandidateBytes = 0L;\n      int mergesAllowed = maxMergeAtOnceExplicit;\n      while (index >= 0 && resultingSegments > maxSegmentCount && mergesAllowed > 0) {\n        final SegmentCommitInfo current = sortedSizeAndDocs.get(index).segInfo;\n        final int initialCandidateSize = candidate.size();\n        final long currentSegmentSize = current.sizeInBytes();\n        // We either add to the bin because there's space or because the it is the smallest possible bin since\n        // decrementing the index will move us to even larger segments.\n        if (currentCandidateBytes + currentSegmentSize <= maxMergeBytes || initialCandidateSize < 2) {\n          candidate.add(current);\n          --index;\n          currentCandidateBytes += currentSegmentSize;\n          --mergesAllowed;\n          if (initialCandidateSize > 0) {\n            // Any merge that handles two or more segments reduces the resulting number of segments\n            // by the number of segments handled - 1\n            --resultingSegments;\n          }\n        } else {\n          break;\n        }\n      }\n      final int candidateSize = candidate.size();\n      // While a force merge is running, only merges that cover the maximum allowed number of segments or that create a segment close to the\n      // maximum allowed segment sized are permitted\n      if (candidateSize > 1 && (forceMergeRunning == false || candidateSize == maxMergeAtOnceExplicit || candidateSize > 0.7 * maxMergeBytes)) {\n        final OneMerge merge = new OneMerge(candidate);\n        if (verbose(mergeContext)) {\n          message(\"add merge=\" + segString(mergeContext, merge.segments), mergeContext);\n        }\n        if (spec == null) {\n          spec = new MergeSpecification();\n        }\n        spec.add(merge);\n      } else {\n        return spec;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public MergeSpecification findForcedMerges(SegmentInfos infos, int maxSegmentCount, Map<SegmentCommitInfo,Boolean> segmentsToMerge, MergeContext mergeContext) throws IOException {\n    if (verbose(mergeContext)) {\n      message(\"findForcedMerges maxSegmentCount=\" + maxSegmentCount + \" infos=\" + segString(mergeContext, infos) +\n          \" segmentsToMerge=\" + segmentsToMerge, mergeContext);\n    }\n\n    List<SegmentSizeAndDocs> sortedSizeAndDocs = getSortedBySegmentSize(infos, mergeContext);\n\n    long totalMergeBytes = 0;\n    final Set<SegmentCommitInfo> merging = mergeContext.getMergingSegments();\n\n\n    // Trim the list down, remove if we're respecting max segment size and it's not original. Presumably it's been merged before and\n    //   is close enough to the max segment size we shouldn't add it in again.\n    Iterator<SegmentSizeAndDocs> iter = sortedSizeAndDocs.iterator();\n    while (iter.hasNext()) {\n      SegmentSizeAndDocs segSizeDocs = iter.next();\n      final Boolean isOriginal = segmentsToMerge.get(segSizeDocs.segInfo);\n      if (isOriginal == null) {\n        iter.remove();\n      } else {\n        if (merging.contains(segSizeDocs.segInfo)) {\n          iter.remove();\n        } else {\n          totalMergeBytes += segSizeDocs.sizeInBytes;\n        }\n      }\n    }\n\n    long maxMergeBytes = maxMergedSegmentBytes;\n\n    // Set the maximum segment size based on how many segments have been specified.\n    if (maxSegmentCount == 1) maxMergeBytes = Long.MAX_VALUE;\n    else if (maxSegmentCount != Integer.MAX_VALUE) {\n      // Fudge this up a bit so we have a better chance of not having to rewrite segments. If we use the exact size,\n      // it's almost guaranteed that the segments won't fit perfectly and we'll be left with more segments than\n      // we want and have to re-merge in the code at the bottom of this method.\n      maxMergeBytes = Math.max((long) (((double) totalMergeBytes / (double) maxSegmentCount)), maxMergedSegmentBytes);\n      maxMergeBytes = (long) ((double) maxMergeBytes * 1.25);\n    }\n\n    iter = sortedSizeAndDocs.iterator();\n    boolean foundDeletes = false;\n    while (iter.hasNext()) {\n      SegmentSizeAndDocs segSizeDocs = iter.next();\n      Boolean isOriginal = segmentsToMerge.get(segSizeDocs.segInfo);\n      if (segSizeDocs.delCount != 0) { // This is forceMerge, all segments with deleted docs should be merged.\n        if (isOriginal != null && isOriginal) {\n          foundDeletes = true;\n        }\n        continue;\n      }\n      // Let the scoring handle whether to merge large segments.\n      if (maxSegmentCount == Integer.MAX_VALUE && isOriginal != null && isOriginal == false) {\n        iter.remove();\n      }\n      // Don't try to merge a segment with no deleted docs that's over the max size.\n      if (maxSegmentCount != Integer.MAX_VALUE && segSizeDocs.sizeInBytes >= maxMergeBytes) {\n        iter.remove();\n      }\n    }\n\n    // Nothing to merge this round.\n    if (sortedSizeAndDocs.size() == 0) {\n      return null;\n    }\n\n    // We should never bail if there are segments that have deleted documents, all deleted docs should be purged.\n    if (foundDeletes == false) {\n      SegmentCommitInfo infoZero = sortedSizeAndDocs.get(0).segInfo;\n      if ((maxSegmentCount != Integer.MAX_VALUE && maxSegmentCount > 1 && sortedSizeAndDocs.size() <= maxSegmentCount) ||\n          (maxSegmentCount == 1 && sortedSizeAndDocs.size() == 1 && (segmentsToMerge.get(infoZero) != null || isMerged(infos, infoZero, mergeContext)))) {\n        if (verbose(mergeContext)) {\n          message(\"already merged\", mergeContext);\n        }\n        return null;\n      }\n    }\n\n    if (verbose(mergeContext)) {\n      message(\"eligible=\" + sortedSizeAndDocs, mergeContext);\n    }\n\n    // This is the special case of merging down to one segment\n    if (sortedSizeAndDocs.size() < maxMergeAtOnceExplicit && maxSegmentCount == 1 && totalMergeBytes < maxMergeBytes) {\n      MergeSpecification spec = new MergeSpecification();\n      List<SegmentCommitInfo> allOfThem = new ArrayList<>();\n      for (SegmentSizeAndDocs segSizeDocs : sortedSizeAndDocs) {\n        allOfThem.add(segSizeDocs.segInfo);\n      }\n      spec.add(new OneMerge(allOfThem));\n      return spec;\n    }\n\n    MergeSpecification spec = doFindMerges(sortedSizeAndDocs, maxMergeBytes, maxMergeAtOnceExplicit,\n        maxSegmentCount, 0, MERGE_TYPE.FORCE_MERGE, mergeContext, false);\n\n    return spec;\n  }\n\n","bugFix":["01e5948db9a07144112d2f08f28ca2e3cd880348","56fb5e4e4b239474721e13b4cd9542ea2d215451","4a90cc8c90aa53ddf51fbd15019989ac269514a3","1d28f215464f76024caf026606f8ea51a5319c53"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["1d28f215464f76024caf026606f8ea51a5319c53","4a90cc8c90aa53ddf51fbd15019989ac269514a3"],"56fb5e4e4b239474721e13b4cd9542ea2d215451":["1d28f215464f76024caf026606f8ea51a5319c53"],"79ba4baff197d5691f403962548d82fe855e4101":["4a90cc8c90aa53ddf51fbd15019989ac269514a3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1d28f215464f76024caf026606f8ea51a5319c53":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4a90cc8c90aa53ddf51fbd15019989ac269514a3":["56fb5e4e4b239474721e13b4cd9542ea2d215451"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["79ba4baff197d5691f403962548d82fe855e4101"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["1d28f215464f76024caf026606f8ea51a5319c53","56fb5e4e4b239474721e13b4cd9542ea2d215451"]},"commit2Childs":{"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"56fb5e4e4b239474721e13b4cd9542ea2d215451":["4a90cc8c90aa53ddf51fbd15019989ac269514a3","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"79ba4baff197d5691f403962548d82fe855e4101":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1d28f215464f76024caf026606f8ea51a5319c53"],"1d28f215464f76024caf026606f8ea51a5319c53":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","56fb5e4e4b239474721e13b4cd9542ea2d215451","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"4a90cc8c90aa53ddf51fbd15019989ac269514a3":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","79ba4baff197d5691f403962548d82fe855e4101"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[]},"heads":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}