{"path":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50DocValuesConsumer#addReverseTermIndex(FieldInfo,Iterable[BytesRef],int).mjava","commits":[{"id":"d6a3823714ed5de938fb4f3fc814824fe0f95e1a","date":1413422458,"type":2,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50DocValuesConsumer#addReverseTermIndex(FieldInfo,Iterable[BytesRef],int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene410/Lucene410DocValuesConsumer#addReverseTermIndex(FieldInfo,Iterable[BytesRef],int).mjava","sourceNew":"  // writes reverse term index: used for binary searching a term into a range of 64 blocks\n  // for every 64 blocks (1024 terms) we store a term, trimming any suffix unnecessary for comparison\n  // terms are written as a contiguous byte[], but never spanning 2^15 byte boundaries.\n  private void addReverseTermIndex(FieldInfo field, final Iterable<BytesRef> values, int maxLength) throws IOException {\n    long count = 0;\n    BytesRefBuilder priorTerm = new BytesRefBuilder();\n    priorTerm.grow(maxLength);\n    BytesRef indexTerm = new BytesRef();\n    long startFP = data.getFilePointer();\n    PagedBytes pagedBytes = new PagedBytes(15);\n    MonotonicBlockPackedWriter addresses = new MonotonicBlockPackedWriter(data, BLOCK_SIZE);\n    \n    for (BytesRef b : values) {\n      int termPosition = (int) (count & REVERSE_INTERVAL_MASK);\n      if (termPosition == 0) {\n        int len = StringHelper.sortKeyLength(priorTerm.get(), b);\n        indexTerm.bytes = b.bytes;\n        indexTerm.offset = b.offset;\n        indexTerm.length = len;\n        addresses.add(pagedBytes.copyUsingLengthPrefix(indexTerm));\n      } else if (termPosition == REVERSE_INTERVAL_MASK) {\n        priorTerm.copyBytes(b);\n      }\n      count++;\n    }\n    addresses.finish();\n    long numBytes = pagedBytes.getPointer();\n    pagedBytes.freeze(true);\n    PagedBytesDataInput in = pagedBytes.getDataInput();\n    meta.writeLong(startFP);\n    data.writeVLong(numBytes);\n    data.copyBytes(in, numBytes);\n  }\n\n","sourceOld":"  // writes reverse term index: used for binary searching a term into a range of 64 blocks\n  // for every 64 blocks (1024 terms) we store a term, trimming any suffix unnecessary for comparison\n  // terms are written as a contiguous byte[], but never spanning 2^15 byte boundaries.\n  private void addReverseTermIndex(FieldInfo field, final Iterable<BytesRef> values, int maxLength) throws IOException {\n    long count = 0;\n    BytesRefBuilder priorTerm = new BytesRefBuilder();\n    priorTerm.grow(maxLength);\n    BytesRef indexTerm = new BytesRef();\n    long startFP = data.getFilePointer();\n    PagedBytes pagedBytes = new PagedBytes(15);\n    MonotonicBlockPackedWriter addresses = new MonotonicBlockPackedWriter(data, BLOCK_SIZE);\n    \n    for (BytesRef b : values) {\n      int termPosition = (int) (count & REVERSE_INTERVAL_MASK);\n      if (termPosition == 0) {\n        int len = StringHelper.sortKeyLength(priorTerm.get(), b);\n        indexTerm.bytes = b.bytes;\n        indexTerm.offset = b.offset;\n        indexTerm.length = len;\n        addresses.add(pagedBytes.copyUsingLengthPrefix(indexTerm));\n      } else if (termPosition == REVERSE_INTERVAL_MASK) {\n        priorTerm.copyBytes(b);\n      }\n      count++;\n    }\n    addresses.finish();\n    long numBytes = pagedBytes.getPointer();\n    pagedBytes.freeze(true);\n    PagedBytesDataInput in = pagedBytes.getDataInput();\n    meta.writeLong(startFP);\n    data.writeVLong(numBytes);\n    data.copyBytes(in, numBytes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db68c63cbfaa8698b9c4475f75ed2b9c9696d238","date":1414118621,"type":2,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50DocValuesConsumer#addReverseTermIndex(FieldInfo,Iterable[BytesRef],int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene410/Lucene410DocValuesConsumer#addReverseTermIndex(FieldInfo,Iterable[BytesRef],int).mjava","sourceNew":"  // writes reverse term index: used for binary searching a term into a range of 64 blocks\n  // for every 64 blocks (1024 terms) we store a term, trimming any suffix unnecessary for comparison\n  // terms are written as a contiguous byte[], but never spanning 2^15 byte boundaries.\n  private void addReverseTermIndex(FieldInfo field, final Iterable<BytesRef> values, int maxLength) throws IOException {\n    long count = 0;\n    BytesRefBuilder priorTerm = new BytesRefBuilder();\n    priorTerm.grow(maxLength);\n    BytesRef indexTerm = new BytesRef();\n    long startFP = data.getFilePointer();\n    PagedBytes pagedBytes = new PagedBytes(15);\n    MonotonicBlockPackedWriter addresses = new MonotonicBlockPackedWriter(data, BLOCK_SIZE);\n    \n    for (BytesRef b : values) {\n      int termPosition = (int) (count & REVERSE_INTERVAL_MASK);\n      if (termPosition == 0) {\n        int len = StringHelper.sortKeyLength(priorTerm.get(), b);\n        indexTerm.bytes = b.bytes;\n        indexTerm.offset = b.offset;\n        indexTerm.length = len;\n        addresses.add(pagedBytes.copyUsingLengthPrefix(indexTerm));\n      } else if (termPosition == REVERSE_INTERVAL_MASK) {\n        priorTerm.copyBytes(b);\n      }\n      count++;\n    }\n    addresses.finish();\n    long numBytes = pagedBytes.getPointer();\n    pagedBytes.freeze(true);\n    PagedBytesDataInput in = pagedBytes.getDataInput();\n    meta.writeLong(startFP);\n    data.writeVLong(numBytes);\n    data.copyBytes(in, numBytes);\n  }\n\n","sourceOld":"  // writes reverse term index: used for binary searching a term into a range of 64 blocks\n  // for every 64 blocks (1024 terms) we store a term, trimming any suffix unnecessary for comparison\n  // terms are written as a contiguous byte[], but never spanning 2^15 byte boundaries.\n  private void addReverseTermIndex(FieldInfo field, final Iterable<BytesRef> values, int maxLength) throws IOException {\n    long count = 0;\n    BytesRefBuilder priorTerm = new BytesRefBuilder();\n    priorTerm.grow(maxLength);\n    BytesRef indexTerm = new BytesRef();\n    long startFP = data.getFilePointer();\n    PagedBytes pagedBytes = new PagedBytes(15);\n    MonotonicBlockPackedWriter addresses = new MonotonicBlockPackedWriter(data, BLOCK_SIZE);\n    \n    for (BytesRef b : values) {\n      int termPosition = (int) (count & REVERSE_INTERVAL_MASK);\n      if (termPosition == 0) {\n        int len = StringHelper.sortKeyLength(priorTerm.get(), b);\n        indexTerm.bytes = b.bytes;\n        indexTerm.offset = b.offset;\n        indexTerm.length = len;\n        addresses.add(pagedBytes.copyUsingLengthPrefix(indexTerm));\n      } else if (termPosition == REVERSE_INTERVAL_MASK) {\n        priorTerm.copyBytes(b);\n      }\n      count++;\n    }\n    addresses.finish();\n    long numBytes = pagedBytes.getPointer();\n    pagedBytes.freeze(true);\n    PagedBytesDataInput in = pagedBytes.getDataInput();\n    meta.writeLong(startFP);\n    data.writeVLong(numBytes);\n    data.copyBytes(in, numBytes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"22895d92bc967fd16d7d69596268ad8254a7bd05","date":1435200722,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50DocValuesConsumer#addReverseTermIndex(FieldInfo,Iterable[BytesRef],int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50DocValuesConsumer#addReverseTermIndex(FieldInfo,Iterable[BytesRef],int).mjava","sourceNew":"  // writes reverse term index: used for binary searching a term into a range of 64 blocks\n  // for every 64 blocks (1024 terms) we store a term, trimming any suffix unnecessary for comparison\n  // terms are written as a contiguous byte[], but never spanning 2^15 byte boundaries.\n  private void addReverseTermIndex(FieldInfo field, final Iterable<BytesRef> values, int maxLength) throws IOException {\n    long count = 0;\n    BytesRefBuilder priorTerm = new BytesRefBuilder();\n    priorTerm.grow(maxLength);\n    BytesRef indexTerm = new BytesRef();\n    long startFP = data.getFilePointer();\n    PagedBytes pagedBytes = new PagedBytes(15);\n    MonotonicBlockPackedWriter addresses = new MonotonicBlockPackedWriter(data, MONOTONIC_BLOCK_SIZE);\n    \n    for (BytesRef b : values) {\n      int termPosition = (int) (count & REVERSE_INTERVAL_MASK);\n      if (termPosition == 0) {\n        int len = StringHelper.sortKeyLength(priorTerm.get(), b);\n        indexTerm.bytes = b.bytes;\n        indexTerm.offset = b.offset;\n        indexTerm.length = len;\n        addresses.add(pagedBytes.copyUsingLengthPrefix(indexTerm));\n      } else if (termPosition == REVERSE_INTERVAL_MASK) {\n        priorTerm.copyBytes(b);\n      }\n      count++;\n    }\n    addresses.finish();\n    long numBytes = pagedBytes.getPointer();\n    pagedBytes.freeze(true);\n    PagedBytesDataInput in = pagedBytes.getDataInput();\n    meta.writeLong(startFP);\n    data.writeVLong(numBytes);\n    data.copyBytes(in, numBytes);\n  }\n\n","sourceOld":"  // writes reverse term index: used for binary searching a term into a range of 64 blocks\n  // for every 64 blocks (1024 terms) we store a term, trimming any suffix unnecessary for comparison\n  // terms are written as a contiguous byte[], but never spanning 2^15 byte boundaries.\n  private void addReverseTermIndex(FieldInfo field, final Iterable<BytesRef> values, int maxLength) throws IOException {\n    long count = 0;\n    BytesRefBuilder priorTerm = new BytesRefBuilder();\n    priorTerm.grow(maxLength);\n    BytesRef indexTerm = new BytesRef();\n    long startFP = data.getFilePointer();\n    PagedBytes pagedBytes = new PagedBytes(15);\n    MonotonicBlockPackedWriter addresses = new MonotonicBlockPackedWriter(data, BLOCK_SIZE);\n    \n    for (BytesRef b : values) {\n      int termPosition = (int) (count & REVERSE_INTERVAL_MASK);\n      if (termPosition == 0) {\n        int len = StringHelper.sortKeyLength(priorTerm.get(), b);\n        indexTerm.bytes = b.bytes;\n        indexTerm.offset = b.offset;\n        indexTerm.length = len;\n        addresses.add(pagedBytes.copyUsingLengthPrefix(indexTerm));\n      } else if (termPosition == REVERSE_INTERVAL_MASK) {\n        priorTerm.copyBytes(b);\n      }\n      count++;\n    }\n    addresses.finish();\n    long numBytes = pagedBytes.getPointer();\n    pagedBytes.freeze(true);\n    PagedBytesDataInput in = pagedBytes.getDataInput();\n    meta.writeLong(startFP);\n    data.writeVLong(numBytes);\n    data.copyBytes(in, numBytes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a870f9917149dc600c4ad4417d615c1795de5864","date":1445975387,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene50/Lucene50DocValuesConsumer#addReverseTermIndex(FieldInfo,Iterable[BytesRef],int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50DocValuesConsumer#addReverseTermIndex(FieldInfo,Iterable[BytesRef],int).mjava","sourceNew":"  // writes reverse term index: used for binary searching a term into a range of 64 blocks\n  // for every 64 blocks (1024 terms) we store a term, trimming any suffix unnecessary for comparison\n  // terms are written as a contiguous byte[], but never spanning 2^15 byte boundaries.\n  private void addReverseTermIndex(FieldInfo field, final Iterable<BytesRef> values, int maxLength) throws IOException {\n    long count = 0;\n    BytesRefBuilder priorTerm = new BytesRefBuilder();\n    priorTerm.grow(maxLength);\n    BytesRef indexTerm = new BytesRef();\n    long startFP = data.getFilePointer();\n    PagedBytes pagedBytes = new PagedBytes(15);\n    MonotonicBlockPackedWriter addresses = new MonotonicBlockPackedWriter(data, MONOTONIC_BLOCK_SIZE);\n    \n    for (BytesRef b : values) {\n      int termPosition = (int) (count & REVERSE_INTERVAL_MASK);\n      if (termPosition == 0) {\n        int len = StringHelper.sortKeyLength(priorTerm.get(), b);\n        indexTerm.bytes = b.bytes;\n        indexTerm.offset = b.offset;\n        indexTerm.length = len;\n        addresses.add(pagedBytes.copyUsingLengthPrefix(indexTerm));\n      } else if (termPosition == REVERSE_INTERVAL_MASK) {\n        priorTerm.copyBytes(b);\n      }\n      count++;\n    }\n    addresses.finish();\n    long numBytes = pagedBytes.getPointer();\n    pagedBytes.freeze(true);\n    PagedBytesDataInput in = pagedBytes.getDataInput();\n    meta.writeLong(startFP);\n    data.writeVLong(numBytes);\n    data.copyBytes(in, numBytes);\n  }\n\n","sourceOld":"  // writes reverse term index: used for binary searching a term into a range of 64 blocks\n  // for every 64 blocks (1024 terms) we store a term, trimming any suffix unnecessary for comparison\n  // terms are written as a contiguous byte[], but never spanning 2^15 byte boundaries.\n  private void addReverseTermIndex(FieldInfo field, final Iterable<BytesRef> values, int maxLength) throws IOException {\n    long count = 0;\n    BytesRefBuilder priorTerm = new BytesRefBuilder();\n    priorTerm.grow(maxLength);\n    BytesRef indexTerm = new BytesRef();\n    long startFP = data.getFilePointer();\n    PagedBytes pagedBytes = new PagedBytes(15);\n    MonotonicBlockPackedWriter addresses = new MonotonicBlockPackedWriter(data, MONOTONIC_BLOCK_SIZE);\n    \n    for (BytesRef b : values) {\n      int termPosition = (int) (count & REVERSE_INTERVAL_MASK);\n      if (termPosition == 0) {\n        int len = StringHelper.sortKeyLength(priorTerm.get(), b);\n        indexTerm.bytes = b.bytes;\n        indexTerm.offset = b.offset;\n        indexTerm.length = len;\n        addresses.add(pagedBytes.copyUsingLengthPrefix(indexTerm));\n      } else if (termPosition == REVERSE_INTERVAL_MASK) {\n        priorTerm.copyBytes(b);\n      }\n      count++;\n    }\n    addresses.finish();\n    long numBytes = pagedBytes.getPointer();\n    pagedBytes.freeze(true);\n    PagedBytesDataInput in = pagedBytes.getDataInput();\n    meta.writeLong(startFP);\n    data.writeVLong(numBytes);\n    data.copyBytes(in, numBytes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a870f9917149dc600c4ad4417d615c1795de5864","date":1445975387,"type":6,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene54/Lucene54DocValuesConsumer#addReverseTermIndex(FieldInfo,Iterable[BytesRef],int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50DocValuesConsumer#addReverseTermIndex(FieldInfo,Iterable[BytesRef],int).mjava","sourceNew":"  // writes reverse term index: used for binary searching a term into a range of 64 blocks\n  // for every 64 blocks (1024 terms) we store a term, trimming any suffix unnecessary for comparison\n  // terms are written as a contiguous byte[], but never spanning 2^15 byte boundaries.\n  private void addReverseTermIndex(FieldInfo field, final Iterable<BytesRef> values, int maxLength) throws IOException {\n    long count = 0;\n    BytesRefBuilder priorTerm = new BytesRefBuilder();\n    priorTerm.grow(maxLength);\n    BytesRef indexTerm = new BytesRef();\n    long startFP = data.getFilePointer();\n    PagedBytes pagedBytes = new PagedBytes(15);\n    MonotonicBlockPackedWriter addresses = new MonotonicBlockPackedWriter(data, MONOTONIC_BLOCK_SIZE);\n    \n    for (BytesRef b : values) {\n      int termPosition = (int) (count & REVERSE_INTERVAL_MASK);\n      if (termPosition == 0) {\n        int len = StringHelper.sortKeyLength(priorTerm.get(), b);\n        indexTerm.bytes = b.bytes;\n        indexTerm.offset = b.offset;\n        indexTerm.length = len;\n        addresses.add(pagedBytes.copyUsingLengthPrefix(indexTerm));\n      } else if (termPosition == REVERSE_INTERVAL_MASK) {\n        priorTerm.copyBytes(b);\n      }\n      count++;\n    }\n    addresses.finish();\n    long numBytes = pagedBytes.getPointer();\n    pagedBytes.freeze(true);\n    PagedBytesDataInput in = pagedBytes.getDataInput();\n    meta.writeLong(startFP);\n    data.writeVLong(numBytes);\n    data.copyBytes(in, numBytes);\n  }\n\n","sourceOld":"  // writes reverse term index: used for binary searching a term into a range of 64 blocks\n  // for every 64 blocks (1024 terms) we store a term, trimming any suffix unnecessary for comparison\n  // terms are written as a contiguous byte[], but never spanning 2^15 byte boundaries.\n  private void addReverseTermIndex(FieldInfo field, final Iterable<BytesRef> values, int maxLength) throws IOException {\n    long count = 0;\n    BytesRefBuilder priorTerm = new BytesRefBuilder();\n    priorTerm.grow(maxLength);\n    BytesRef indexTerm = new BytesRef();\n    long startFP = data.getFilePointer();\n    PagedBytes pagedBytes = new PagedBytes(15);\n    MonotonicBlockPackedWriter addresses = new MonotonicBlockPackedWriter(data, MONOTONIC_BLOCK_SIZE);\n    \n    for (BytesRef b : values) {\n      int termPosition = (int) (count & REVERSE_INTERVAL_MASK);\n      if (termPosition == 0) {\n        int len = StringHelper.sortKeyLength(priorTerm.get(), b);\n        indexTerm.bytes = b.bytes;\n        indexTerm.offset = b.offset;\n        indexTerm.length = len;\n        addresses.add(pagedBytes.copyUsingLengthPrefix(indexTerm));\n      } else if (termPosition == REVERSE_INTERVAL_MASK) {\n        priorTerm.copyBytes(b);\n      }\n      count++;\n    }\n    addresses.finish();\n    long numBytes = pagedBytes.getPointer();\n    pagedBytes.freeze(true);\n    PagedBytesDataInput in = pagedBytes.getDataInput();\n    meta.writeLong(startFP);\n    data.writeVLong(numBytes);\n    data.copyBytes(in, numBytes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"22895d92bc967fd16d7d69596268ad8254a7bd05":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","d6a3823714ed5de938fb4f3fc814824fe0f95e1a"],"a870f9917149dc600c4ad4417d615c1795de5864":["22895d92bc967fd16d7d69596268ad8254a7bd05"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a870f9917149dc600c4ad4417d615c1795de5864"],"d6a3823714ed5de938fb4f3fc814824fe0f95e1a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"22895d92bc967fd16d7d69596268ad8254a7bd05":["a870f9917149dc600c4ad4417d615c1795de5864"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238","d6a3823714ed5de938fb4f3fc814824fe0f95e1a"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["22895d92bc967fd16d7d69596268ad8254a7bd05"],"a870f9917149dc600c4ad4417d615c1795de5864":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d6a3823714ed5de938fb4f3fc814824fe0f95e1a":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}