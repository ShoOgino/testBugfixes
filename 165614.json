{"path":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfoReader#readSegmentInfo(String,Directory,int,IndexInput).mjava","commits":[{"id":"ace9b78896617dcee984890f3300d45c539c1b15","date":1337655022,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfoReader#readSegmentInfo(String,Directory,int,IndexInput).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfosReader#readSegmentInfo(String,Directory,int,IndexInput).mjava","sourceNew":"  private SegmentInfo readSegmentInfo(String segmentName, Directory dir, int format, IndexInput input) throws IOException {\n    // check that it is a format we can understand\n    if (format > Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS) {\n      throw new IndexFormatTooOldException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE);\n    }\n    if (format < Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE) {\n      throw new IndexFormatTooNewException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE);\n    }\n    final String version;\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n\n    // NOTE: we ignore this and use the incoming arg\n    // instead, if it's non-null:\n    final String name = input.readString();\n    if (segmentName == null) {\n      segmentName = name;\n    }\n\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    final int docStoreOffset = input.readInt();\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    if (docStoreOffset != -1) {\n      docStoreSegment = input.readString();\n      docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n    } else {\n      docStoreSegment = name;\n      docStoreIsCompoundFile = false;\n    }\n\n    // pre-4.0 indexes write a byte if there is a single norms file\n    byte b = input.readByte();\n\n    //System.out.println(\"version=\" + version + \" name=\" + name + \" docCount=\" + docCount + \" delGen=\" + delGen + \" dso=\" + docStoreOffset + \" dss=\" + docStoreSegment + \" dssCFs=\" + docStoreIsCompoundFile + \" b=\" + b + \" format=\" + format);\n\n    assert 1 == b : \"expected 1 but was: \"+ b + \" format: \" + format;\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(j, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final boolean hasProx = input.readByte() == 1;\n\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_HAS_VECTORS) {\n      // NOTE: unused\n      final int hasVectors = input.readByte();\n    }\n\n    final Set<String> files;\n    if (format == Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE) {\n      files = input.readStringSet();\n    } else {\n      // Replicate logic from 3.x's SegmentInfo.files():\n      files = new HashSet<String>();\n      if (isCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      } else {\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xFieldInfosReader.FIELD_INFOS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.FREQ_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.PROX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.TERMS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.TERMS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xNormsProducer.NORMS_EXTENSION));\n      }\n\n      if (docStoreOffset != -1) {\n        if (docStoreIsCompoundFile) {\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION));\n        } else {\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n        }\n      } else if (!isCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n        files.add(IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n      }\n\n      if (normGen != null) {\n        for(Map.Entry<Integer,Long> ent : normGen.entrySet()) {\n          long gen = ent.getValue();\n          if (gen >= SegmentInfo.YES) {\n            // Definitely a separate norm file, with generation:\n            files.add(IndexFileNames.fileNameFromGeneration(segmentName, \"s\" + ent.getKey(), gen));\n          } else if (gen == SegmentInfo.NO) {\n            // No separate norm\n          } else {\n            // nocommit -- i thought _X_N.sY files were pre-3.0...????\n            assert false;\n          }\n        }\n      }\n    }\n\n    SegmentInfo info = new SegmentInfo(dir, version, segmentName, docCount, docStoreOffset,\n                                       docStoreSegment, docStoreIsCompoundFile, normGen, isCompoundFile,\n                                       delCount, null, diagnostics);\n    info.setDelGen(delGen);\n    info.setFiles(files);\n    return info;\n  }\n\n","sourceOld":"  private SegmentInfo readSegmentInfo(String segmentName, Directory dir, int format, IndexInput input) throws IOException {\n    // check that it is a format we can understand\n    if (format > Lucene3xSegmentInfosFormat.FORMAT_DIAGNOSTICS) {\n      throw new IndexFormatTooOldException(input, format,\n                                           Lucene3xSegmentInfosFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfosFormat.FORMAT_4X_UPGRADE);\n    }\n    if (format < Lucene3xSegmentInfosFormat.FORMAT_4X_UPGRADE) {\n      throw new IndexFormatTooNewException(input, format,\n                                           Lucene3xSegmentInfosFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfosFormat.FORMAT_4X_UPGRADE);\n    }\n    final String version;\n    if (format <= Lucene3xSegmentInfosFormat.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n\n    // NOTE: we ignore this and use the incoming arg\n    // instead, if it's non-null:\n    final String name = input.readString();\n    if (segmentName == null) {\n      segmentName = name;\n    }\n\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    final int docStoreOffset = input.readInt();\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    if (docStoreOffset != -1) {\n      docStoreSegment = input.readString();\n      docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n    } else {\n      docStoreSegment = name;\n      docStoreIsCompoundFile = false;\n    }\n\n    // pre-4.0 indexes write a byte if there is a single norms file\n    byte b = input.readByte();\n\n    //System.out.println(\"version=\" + version + \" name=\" + name + \" docCount=\" + docCount + \" delGen=\" + delGen + \" dso=\" + docStoreOffset + \" dss=\" + docStoreSegment + \" dssCFs=\" + docStoreIsCompoundFile + \" b=\" + b + \" format=\" + format);\n\n    assert 1 == b : \"expected 1 but was: \"+ b + \" format: \" + format;\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(j, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final boolean hasProx = input.readByte() == 1;\n\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    if (format <= Lucene3xSegmentInfosFormat.FORMAT_HAS_VECTORS) {\n      // NOTE: unused\n      final int hasVectors = input.readByte();\n    }\n\n    final Set<String> files;\n    if (format == Lucene3xSegmentInfosFormat.FORMAT_4X_UPGRADE) {\n      files = input.readStringSet();\n    } else {\n      // Replicate logic from 3.x's SegmentInfo.files():\n      files = new HashSet<String>();\n      if (isCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      } else {\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xFieldInfosReader.FIELD_INFOS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.FREQ_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.PROX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.TERMS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.TERMS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xNormsProducer.NORMS_EXTENSION));\n      }\n\n      if (docStoreOffset != -1) {\n        if (docStoreIsCompoundFile) {\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION));\n        } else {\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n        }\n      } else if (!isCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n        files.add(IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n      }\n\n      if (normGen != null) {\n        for(Map.Entry<Integer,Long> ent : normGen.entrySet()) {\n          long gen = ent.getValue();\n          if (gen >= SegmentInfo.YES) {\n            // Definitely a separate norm file, with generation:\n            files.add(IndexFileNames.fileNameFromGeneration(segmentName, \"s\" + ent.getKey(), gen));\n          } else if (gen == SegmentInfo.NO) {\n            // No seaprate norm\n          } else {\n            // nocommit -- i thought _X_N.sY files were pre-3.0...????\n            assert false;\n          }\n        }\n      }\n    }\n\n    SegmentInfo info = new SegmentInfo(dir, version, segmentName, docCount, docStoreOffset,\n                                       docStoreSegment, docStoreIsCompoundFile, normGen, isCompoundFile,\n                                       delCount, null, diagnostics);\n    info.setDelGen(delGen);\n    info.setFiles(files);\n    return info;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9d153abcf92dc5329d98571a8c3035df9bd80648","date":1337702630,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfoReader#readSegmentInfo(String,Directory,int,IndexInput).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfoReader#readSegmentInfo(String,Directory,int,IndexInput).mjava","sourceNew":"  private SegmentInfoPerCommit readSegmentInfo(String segmentName, Directory dir, int format, IndexInput input) throws IOException {\n    // check that it is a format we can understand\n    if (format > Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS) {\n      throw new IndexFormatTooOldException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE);\n    }\n    if (format < Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE) {\n      throw new IndexFormatTooNewException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE);\n    }\n    final String version;\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n\n    // NOTE: we ignore this and use the incoming arg\n    // instead, if it's non-null:\n    final String name = input.readString();\n    if (segmentName == null) {\n      segmentName = name;\n    }\n\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    final int docStoreOffset = input.readInt();\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    if (docStoreOffset != -1) {\n      docStoreSegment = input.readString();\n      docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n    } else {\n      docStoreSegment = name;\n      docStoreIsCompoundFile = false;\n    }\n\n    // pre-4.0 indexes write a byte if there is a single norms file\n    byte b = input.readByte();\n\n    //System.out.println(\"version=\" + version + \" name=\" + name + \" docCount=\" + docCount + \" delGen=\" + delGen + \" dso=\" + docStoreOffset + \" dss=\" + docStoreSegment + \" dssCFs=\" + docStoreIsCompoundFile + \" b=\" + b + \" format=\" + format);\n\n    assert 1 == b : \"expected 1 but was: \"+ b + \" format: \" + format;\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(j, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final boolean hasProx = input.readByte() == 1;\n\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_HAS_VECTORS) {\n      // NOTE: unused\n      final int hasVectors = input.readByte();\n    }\n\n    final Set<String> files;\n    if (format == Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE) {\n      files = input.readStringSet();\n    } else {\n      // Replicate logic from 3.x's SegmentInfo.files():\n      files = new HashSet<String>();\n      if (isCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      } else {\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xFieldInfosReader.FIELD_INFOS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.FREQ_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.PROX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.TERMS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.TERMS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xNormsProducer.NORMS_EXTENSION));\n      }\n\n      if (docStoreOffset != -1) {\n        if (docStoreIsCompoundFile) {\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION));\n        } else {\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n        }\n      } else if (!isCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n        files.add(IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n      }\n\n      if (normGen != null) {\n        for(Map.Entry<Integer,Long> ent : normGen.entrySet()) {\n          long gen = ent.getValue();\n          if (gen >= SegmentInfo.YES) {\n            // Definitely a separate norm file, with generation:\n            files.add(IndexFileNames.fileNameFromGeneration(segmentName, \"s\" + ent.getKey(), gen));\n          } else if (gen == SegmentInfo.NO) {\n            // No separate norm\n          } else {\n            // nocommit -- i thought _X_N.sY files were pre-3.0...????\n            assert false;\n          }\n        }\n      }\n    }\n\n    SegmentInfo info = new SegmentInfo(dir, version, segmentName, docCount, docStoreOffset,\n                                       docStoreSegment, docStoreIsCompoundFile, normGen, isCompoundFile,\n                                       null, diagnostics);\n    info.setFiles(files);\n\n    SegmentInfoPerCommit infoPerCommit = new SegmentInfoPerCommit(info, delCount, delGen);\n    return infoPerCommit;\n  }\n\n","sourceOld":"  private SegmentInfo readSegmentInfo(String segmentName, Directory dir, int format, IndexInput input) throws IOException {\n    // check that it is a format we can understand\n    if (format > Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS) {\n      throw new IndexFormatTooOldException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE);\n    }\n    if (format < Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE) {\n      throw new IndexFormatTooNewException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE);\n    }\n    final String version;\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n\n    // NOTE: we ignore this and use the incoming arg\n    // instead, if it's non-null:\n    final String name = input.readString();\n    if (segmentName == null) {\n      segmentName = name;\n    }\n\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    final int docStoreOffset = input.readInt();\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    if (docStoreOffset != -1) {\n      docStoreSegment = input.readString();\n      docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n    } else {\n      docStoreSegment = name;\n      docStoreIsCompoundFile = false;\n    }\n\n    // pre-4.0 indexes write a byte if there is a single norms file\n    byte b = input.readByte();\n\n    //System.out.println(\"version=\" + version + \" name=\" + name + \" docCount=\" + docCount + \" delGen=\" + delGen + \" dso=\" + docStoreOffset + \" dss=\" + docStoreSegment + \" dssCFs=\" + docStoreIsCompoundFile + \" b=\" + b + \" format=\" + format);\n\n    assert 1 == b : \"expected 1 but was: \"+ b + \" format: \" + format;\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(j, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final boolean hasProx = input.readByte() == 1;\n\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_HAS_VECTORS) {\n      // NOTE: unused\n      final int hasVectors = input.readByte();\n    }\n\n    final Set<String> files;\n    if (format == Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE) {\n      files = input.readStringSet();\n    } else {\n      // Replicate logic from 3.x's SegmentInfo.files():\n      files = new HashSet<String>();\n      if (isCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      } else {\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xFieldInfosReader.FIELD_INFOS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.FREQ_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.PROX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.TERMS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.TERMS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xNormsProducer.NORMS_EXTENSION));\n      }\n\n      if (docStoreOffset != -1) {\n        if (docStoreIsCompoundFile) {\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION));\n        } else {\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n        }\n      } else if (!isCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n        files.add(IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n      }\n\n      if (normGen != null) {\n        for(Map.Entry<Integer,Long> ent : normGen.entrySet()) {\n          long gen = ent.getValue();\n          if (gen >= SegmentInfo.YES) {\n            // Definitely a separate norm file, with generation:\n            files.add(IndexFileNames.fileNameFromGeneration(segmentName, \"s\" + ent.getKey(), gen));\n          } else if (gen == SegmentInfo.NO) {\n            // No separate norm\n          } else {\n            // nocommit -- i thought _X_N.sY files were pre-3.0...????\n            assert false;\n          }\n        }\n      }\n    }\n\n    SegmentInfo info = new SegmentInfo(dir, version, segmentName, docCount, docStoreOffset,\n                                       docStoreSegment, docStoreIsCompoundFile, normGen, isCompoundFile,\n                                       delCount, null, diagnostics);\n    info.setDelGen(delGen);\n    info.setFiles(files);\n    return info;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"63caed6eb28209e181e97822c4c8fdf808884c3b","date":1337712793,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfoReader#readSegmentInfo(String,Directory,int,IndexInput).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfoReader#readSegmentInfo(String,Directory,int,IndexInput).mjava","sourceNew":"  private SegmentInfoPerCommit readSegmentInfo(String segmentName, Directory dir, int format, IndexInput input) throws IOException {\n    // check that it is a format we can understand\n    if (format > Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS) {\n      throw new IndexFormatTooOldException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE);\n    }\n    if (format < Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE) {\n      throw new IndexFormatTooNewException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE);\n    }\n    final String version;\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n\n    // NOTE: we ignore this and use the incoming arg\n    // instead, if it's non-null:\n    final String name = input.readString();\n    if (segmentName == null) {\n      segmentName = name;\n    }\n\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    final int docStoreOffset = input.readInt();\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    if (docStoreOffset != -1) {\n      docStoreSegment = input.readString();\n      docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n    } else {\n      docStoreSegment = name;\n      docStoreIsCompoundFile = false;\n    }\n\n    // pre-4.0 indexes write a byte if there is a single norms file\n    byte b = input.readByte();\n\n    //System.out.println(\"version=\" + version + \" name=\" + name + \" docCount=\" + docCount + \" delGen=\" + delGen + \" dso=\" + docStoreOffset + \" dss=\" + docStoreSegment + \" dssCFs=\" + docStoreIsCompoundFile + \" b=\" + b + \" format=\" + format);\n\n    assert 1 == b : \"expected 1 but was: \"+ b + \" format: \" + format;\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(j, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final boolean hasProx = input.readByte() == 1;\n\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_HAS_VECTORS) {\n      // NOTE: unused\n      final int hasVectors = input.readByte();\n    }\n\n    final Set<String> files;\n    if (format == Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE) {\n      files = input.readStringSet();\n    } else {\n      // Replicate logic from 3.x's SegmentInfo.files():\n      files = new HashSet<String>();\n      if (isCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      } else {\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xFieldInfosReader.FIELD_INFOS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.FREQ_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.PROX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.TERMS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.TERMS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xNormsProducer.NORMS_EXTENSION));\n      }\n\n      if (docStoreOffset != -1) {\n        if (docStoreIsCompoundFile) {\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION));\n        } else {\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n        }\n      } else if (!isCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n        files.add(IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n      }\n\n      if (normGen != null) {\n        for(Map.Entry<Integer,Long> ent : normGen.entrySet()) {\n          long gen = ent.getValue();\n          if (gen >= SegmentInfo.YES) {\n            // Definitely a separate norm file, with generation:\n            files.add(IndexFileNames.fileNameFromGeneration(segmentName, \"s\" + ent.getKey(), gen));\n          } else if (gen == SegmentInfo.NO) {\n            // No separate norm\n          } else {\n            // nocommit -- i thought _X_N.sY files were pre-3.0...????\n            assert false;\n          }\n        }\n      }\n    }\n\n    // nocommit: convert 3.x specific stuff (shared docstores, normgen, etc) into attributes\n    SegmentInfo info = new SegmentInfo(dir, version, segmentName, docCount, docStoreOffset,\n                                       docStoreSegment, docStoreIsCompoundFile, normGen, isCompoundFile,\n                                       null, diagnostics, null);\n    info.setFiles(files);\n\n    SegmentInfoPerCommit infoPerCommit = new SegmentInfoPerCommit(info, delCount, delGen);\n    return infoPerCommit;\n  }\n\n","sourceOld":"  private SegmentInfoPerCommit readSegmentInfo(String segmentName, Directory dir, int format, IndexInput input) throws IOException {\n    // check that it is a format we can understand\n    if (format > Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS) {\n      throw new IndexFormatTooOldException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE);\n    }\n    if (format < Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE) {\n      throw new IndexFormatTooNewException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE);\n    }\n    final String version;\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n\n    // NOTE: we ignore this and use the incoming arg\n    // instead, if it's non-null:\n    final String name = input.readString();\n    if (segmentName == null) {\n      segmentName = name;\n    }\n\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    final int docStoreOffset = input.readInt();\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    if (docStoreOffset != -1) {\n      docStoreSegment = input.readString();\n      docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n    } else {\n      docStoreSegment = name;\n      docStoreIsCompoundFile = false;\n    }\n\n    // pre-4.0 indexes write a byte if there is a single norms file\n    byte b = input.readByte();\n\n    //System.out.println(\"version=\" + version + \" name=\" + name + \" docCount=\" + docCount + \" delGen=\" + delGen + \" dso=\" + docStoreOffset + \" dss=\" + docStoreSegment + \" dssCFs=\" + docStoreIsCompoundFile + \" b=\" + b + \" format=\" + format);\n\n    assert 1 == b : \"expected 1 but was: \"+ b + \" format: \" + format;\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(j, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final boolean hasProx = input.readByte() == 1;\n\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_HAS_VECTORS) {\n      // NOTE: unused\n      final int hasVectors = input.readByte();\n    }\n\n    final Set<String> files;\n    if (format == Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE) {\n      files = input.readStringSet();\n    } else {\n      // Replicate logic from 3.x's SegmentInfo.files():\n      files = new HashSet<String>();\n      if (isCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      } else {\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xFieldInfosReader.FIELD_INFOS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.FREQ_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.PROX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.TERMS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.TERMS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xNormsProducer.NORMS_EXTENSION));\n      }\n\n      if (docStoreOffset != -1) {\n        if (docStoreIsCompoundFile) {\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION));\n        } else {\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n        }\n      } else if (!isCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n        files.add(IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n      }\n\n      if (normGen != null) {\n        for(Map.Entry<Integer,Long> ent : normGen.entrySet()) {\n          long gen = ent.getValue();\n          if (gen >= SegmentInfo.YES) {\n            // Definitely a separate norm file, with generation:\n            files.add(IndexFileNames.fileNameFromGeneration(segmentName, \"s\" + ent.getKey(), gen));\n          } else if (gen == SegmentInfo.NO) {\n            // No separate norm\n          } else {\n            // nocommit -- i thought _X_N.sY files were pre-3.0...????\n            assert false;\n          }\n        }\n      }\n    }\n\n    SegmentInfo info = new SegmentInfo(dir, version, segmentName, docCount, docStoreOffset,\n                                       docStoreSegment, docStoreIsCompoundFile, normGen, isCompoundFile,\n                                       null, diagnostics);\n    info.setFiles(files);\n\n    SegmentInfoPerCommit infoPerCommit = new SegmentInfoPerCommit(info, delCount, delGen);\n    return infoPerCommit;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6a917aca07a305ab70118a83e84d931503441271","date":1337826487,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfoReader#readSegmentInfo(String,Directory,int,IndexInput).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfoReader#readSegmentInfo(String,Directory,int,IndexInput).mjava","sourceNew":"  private SegmentInfoPerCommit readSegmentInfo(String segmentName, Directory dir, int format, IndexInput input) throws IOException {\n    // check that it is a format we can understand\n    if (format > Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS) {\n      throw new IndexFormatTooOldException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE);\n    }\n    if (format < Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE) {\n      throw new IndexFormatTooNewException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE);\n    }\n    final String version;\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n\n    // NOTE: we ignore this and use the incoming arg\n    // instead, if it's non-null:\n    final String name = input.readString();\n    if (segmentName == null) {\n      segmentName = name;\n    }\n\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    \n    final int docStoreOffset;\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    final Map<String,String> attributes;\n    \n    if (format == Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE) {\n      // we already upgraded to 4.x si format: so shared docstore stuff is in the attributes map.\n      attributes = input.readStringStringMap();\n      String v = attributes.get(Lucene3xSegmentInfoFormat.DS_OFFSET_KEY);\n      docStoreOffset = v == null ? -1 : Integer.parseInt(v);\n      \n      v = attributes.get(Lucene3xSegmentInfoFormat.DS_NAME_KEY);\n      docStoreSegment = v == null ? segmentName : v;\n      \n      v = attributes.get(Lucene3xSegmentInfoFormat.DS_COMPOUND_KEY);\n      docStoreIsCompoundFile = v == null ? false : Boolean.parseBoolean(v);\n    } else {\n      // for older formats, parse the docstore stuff and shove it into attributes\n      attributes = new HashMap<String,String>();\n      docStoreOffset = input.readInt();\n      if (docStoreOffset != -1) {\n        docStoreSegment = input.readString();\n        docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n        attributes.put(Lucene3xSegmentInfoFormat.DS_OFFSET_KEY, Integer.toString(docStoreOffset));\n        attributes.put(Lucene3xSegmentInfoFormat.DS_NAME_KEY, docStoreSegment);\n        attributes.put(Lucene3xSegmentInfoFormat.DS_COMPOUND_KEY, Boolean.toString(docStoreIsCompoundFile));\n      } else {\n        docStoreSegment = name;\n        docStoreIsCompoundFile = false;\n      }\n    }\n\n    // pre-4.0 indexes write a byte if there is a single norms file\n    byte b = input.readByte();\n\n    //System.out.println(\"version=\" + version + \" name=\" + name + \" docCount=\" + docCount + \" delGen=\" + delGen + \" dso=\" + docStoreOffset + \" dss=\" + docStoreSegment + \" dssCFs=\" + docStoreIsCompoundFile + \" b=\" + b + \" format=\" + format);\n\n    assert 1 == b : \"expected 1 but was: \"+ b + \" format: \" + format;\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(j, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final boolean hasProx = input.readByte() == 1;\n\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_HAS_VECTORS) {\n      // NOTE: unused\n      final int hasVectors = input.readByte();\n    }\n\n    final Set<String> files;\n    if (format == Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE) {\n      files = input.readStringSet();\n    } else {\n      // Replicate logic from 3.x's SegmentInfo.files():\n      files = new HashSet<String>();\n      if (isCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      } else {\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xFieldInfosReader.FIELD_INFOS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.FREQ_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.PROX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.TERMS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.TERMS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xNormsProducer.NORMS_EXTENSION));\n      }\n\n      if (docStoreOffset != -1) {\n        if (docStoreIsCompoundFile) {\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION));\n        } else {\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n        }\n      } else if (!isCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n        files.add(IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n      }\n\n      if (normGen != null) {\n        for(Map.Entry<Integer,Long> ent : normGen.entrySet()) {\n          long gen = ent.getValue();\n          if (gen >= SegmentInfo.YES) {\n            // Definitely a separate norm file, with generation:\n            files.add(IndexFileNames.fileNameFromGeneration(segmentName, \"s\" + ent.getKey(), gen));\n          } else if (gen == SegmentInfo.NO) {\n            // No separate norm\n          } else {\n            // We should have already hit indexformat too old exception\n            assert false;\n          }\n        }\n      }\n    }\n\n    // nocommit: convert normgen into attributes?\n    SegmentInfo info = new SegmentInfo(dir, version, segmentName, docCount, normGen, isCompoundFile,\n                                       null, diagnostics, attributes);\n    info.setFiles(files);\n\n    SegmentInfoPerCommit infoPerCommit = new SegmentInfoPerCommit(info, delCount, delGen);\n    return infoPerCommit;\n  }\n\n","sourceOld":"  private SegmentInfoPerCommit readSegmentInfo(String segmentName, Directory dir, int format, IndexInput input) throws IOException {\n    // check that it is a format we can understand\n    if (format > Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS) {\n      throw new IndexFormatTooOldException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE);\n    }\n    if (format < Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE) {\n      throw new IndexFormatTooNewException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE);\n    }\n    final String version;\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n\n    // NOTE: we ignore this and use the incoming arg\n    // instead, if it's non-null:\n    final String name = input.readString();\n    if (segmentName == null) {\n      segmentName = name;\n    }\n\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    final int docStoreOffset = input.readInt();\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    if (docStoreOffset != -1) {\n      docStoreSegment = input.readString();\n      docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n    } else {\n      docStoreSegment = name;\n      docStoreIsCompoundFile = false;\n    }\n\n    // pre-4.0 indexes write a byte if there is a single norms file\n    byte b = input.readByte();\n\n    //System.out.println(\"version=\" + version + \" name=\" + name + \" docCount=\" + docCount + \" delGen=\" + delGen + \" dso=\" + docStoreOffset + \" dss=\" + docStoreSegment + \" dssCFs=\" + docStoreIsCompoundFile + \" b=\" + b + \" format=\" + format);\n\n    assert 1 == b : \"expected 1 but was: \"+ b + \" format: \" + format;\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(j, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final boolean hasProx = input.readByte() == 1;\n\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_HAS_VECTORS) {\n      // NOTE: unused\n      final int hasVectors = input.readByte();\n    }\n\n    final Set<String> files;\n    if (format == Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE) {\n      files = input.readStringSet();\n    } else {\n      // Replicate logic from 3.x's SegmentInfo.files():\n      files = new HashSet<String>();\n      if (isCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      } else {\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xFieldInfosReader.FIELD_INFOS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.FREQ_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.PROX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.TERMS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.TERMS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xNormsProducer.NORMS_EXTENSION));\n      }\n\n      if (docStoreOffset != -1) {\n        if (docStoreIsCompoundFile) {\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION));\n        } else {\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n        }\n      } else if (!isCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n        files.add(IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n      }\n\n      if (normGen != null) {\n        for(Map.Entry<Integer,Long> ent : normGen.entrySet()) {\n          long gen = ent.getValue();\n          if (gen >= SegmentInfo.YES) {\n            // Definitely a separate norm file, with generation:\n            files.add(IndexFileNames.fileNameFromGeneration(segmentName, \"s\" + ent.getKey(), gen));\n          } else if (gen == SegmentInfo.NO) {\n            // No separate norm\n          } else {\n            // nocommit -- i thought _X_N.sY files were pre-3.0...????\n            assert false;\n          }\n        }\n      }\n    }\n\n    // nocommit: convert 3.x specific stuff (shared docstores, normgen, etc) into attributes\n    SegmentInfo info = new SegmentInfo(dir, version, segmentName, docCount, docStoreOffset,\n                                       docStoreSegment, docStoreIsCompoundFile, normGen, isCompoundFile,\n                                       null, diagnostics, null);\n    info.setFiles(files);\n\n    SegmentInfoPerCommit infoPerCommit = new SegmentInfoPerCommit(info, delCount, delGen);\n    return infoPerCommit;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f00f0f8c602950d28e2cb62039b72f51f5d5c44c","date":1337861286,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfoReader#readSegmentInfo(String,Directory,int,IndexInput).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfoReader#readSegmentInfo(String,Directory,int,IndexInput).mjava","sourceNew":"  private SegmentInfoPerCommit readSegmentInfo(String segmentName, Directory dir, int format, IndexInput input) throws IOException {\n    // check that it is a format we can understand\n    if (format > Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS) {\n      throw new IndexFormatTooOldException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE);\n    }\n    if (format < Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE) {\n      throw new IndexFormatTooNewException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE);\n    }\n    final String version;\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n\n    // NOTE: we ignore this and use the incoming arg\n    // instead, if it's non-null:\n    final String name = input.readString();\n    if (segmentName == null) {\n      segmentName = name;\n    }\n\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    \n    final int docStoreOffset;\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    final Map<String,String> attributes;\n    \n    if (format == Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE) {\n      // we already upgraded to 4.x si format: so shared docstore stuff is in the attributes map.\n      attributes = input.readStringStringMap();\n      String v = attributes.get(Lucene3xSegmentInfoFormat.DS_OFFSET_KEY);\n      docStoreOffset = v == null ? -1 : Integer.parseInt(v);\n      \n      v = attributes.get(Lucene3xSegmentInfoFormat.DS_NAME_KEY);\n      docStoreSegment = v == null ? segmentName : v;\n      \n      v = attributes.get(Lucene3xSegmentInfoFormat.DS_COMPOUND_KEY);\n      docStoreIsCompoundFile = v == null ? false : Boolean.parseBoolean(v);\n    } else {\n      // for older formats, parse the docstore stuff and shove it into attributes\n      attributes = new HashMap<String,String>();\n      docStoreOffset = input.readInt();\n      if (docStoreOffset != -1) {\n        docStoreSegment = input.readString();\n        docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n        attributes.put(Lucene3xSegmentInfoFormat.DS_OFFSET_KEY, Integer.toString(docStoreOffset));\n        attributes.put(Lucene3xSegmentInfoFormat.DS_NAME_KEY, docStoreSegment);\n        attributes.put(Lucene3xSegmentInfoFormat.DS_COMPOUND_KEY, Boolean.toString(docStoreIsCompoundFile));\n      } else {\n        docStoreSegment = name;\n        docStoreIsCompoundFile = false;\n      }\n    }\n\n    // pre-4.0 indexes write a byte if there is a single norms file\n    byte b = input.readByte();\n\n    //System.out.println(\"version=\" + version + \" name=\" + name + \" docCount=\" + docCount + \" delGen=\" + delGen + \" dso=\" + docStoreOffset + \" dss=\" + docStoreSegment + \" dssCFs=\" + docStoreIsCompoundFile + \" b=\" + b + \" format=\" + format);\n\n    assert 1 == b : \"expected 1 but was: \"+ b + \" format: \" + format;\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(j, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final boolean hasProx = input.readByte() == 1;\n\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_HAS_VECTORS) {\n      // NOTE: unused\n      final int hasVectors = input.readByte();\n    }\n\n    final Set<String> files;\n    if (format == Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE) {\n      files = input.readStringSet();\n    } else {\n      // Replicate logic from 3.x's SegmentInfo.files():\n      files = new HashSet<String>();\n      if (isCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      } else {\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xFieldInfosReader.FIELD_INFOS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.FREQ_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.PROX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.TERMS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.TERMS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xNormsProducer.NORMS_EXTENSION));\n      }\n\n      if (docStoreOffset != -1) {\n        if (docStoreIsCompoundFile) {\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION));\n        } else {\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n        }\n      } else if (!isCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n        files.add(IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n      }\n\n      if (normGen != null) {\n        for(Map.Entry<Integer,Long> ent : normGen.entrySet()) {\n          long gen = ent.getValue();\n          if (gen >= SegmentInfo.YES) {\n            // Definitely a separate norm file, with generation:\n            files.add(IndexFileNames.fileNameFromGeneration(segmentName, \"s\" + ent.getKey(), gen));\n          } else if (gen == SegmentInfo.NO) {\n            // No separate norm\n          } else {\n            // We should have already hit indexformat too old exception\n            assert false;\n          }\n        }\n      }\n    }\n\n    // nocommit: convert normgen into attributes?\n    SegmentInfo info = new SegmentInfo(dir, version, segmentName, docCount, normGen, isCompoundFile,\n                                       null, diagnostics, Collections.unmodifiableMap(attributes));\n    info.setFiles(files);\n\n    SegmentInfoPerCommit infoPerCommit = new SegmentInfoPerCommit(info, delCount, delGen);\n    return infoPerCommit;\n  }\n\n","sourceOld":"  private SegmentInfoPerCommit readSegmentInfo(String segmentName, Directory dir, int format, IndexInput input) throws IOException {\n    // check that it is a format we can understand\n    if (format > Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS) {\n      throw new IndexFormatTooOldException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE);\n    }\n    if (format < Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE) {\n      throw new IndexFormatTooNewException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE);\n    }\n    final String version;\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n\n    // NOTE: we ignore this and use the incoming arg\n    // instead, if it's non-null:\n    final String name = input.readString();\n    if (segmentName == null) {\n      segmentName = name;\n    }\n\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    \n    final int docStoreOffset;\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    final Map<String,String> attributes;\n    \n    if (format == Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE) {\n      // we already upgraded to 4.x si format: so shared docstore stuff is in the attributes map.\n      attributes = input.readStringStringMap();\n      String v = attributes.get(Lucene3xSegmentInfoFormat.DS_OFFSET_KEY);\n      docStoreOffset = v == null ? -1 : Integer.parseInt(v);\n      \n      v = attributes.get(Lucene3xSegmentInfoFormat.DS_NAME_KEY);\n      docStoreSegment = v == null ? segmentName : v;\n      \n      v = attributes.get(Lucene3xSegmentInfoFormat.DS_COMPOUND_KEY);\n      docStoreIsCompoundFile = v == null ? false : Boolean.parseBoolean(v);\n    } else {\n      // for older formats, parse the docstore stuff and shove it into attributes\n      attributes = new HashMap<String,String>();\n      docStoreOffset = input.readInt();\n      if (docStoreOffset != -1) {\n        docStoreSegment = input.readString();\n        docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n        attributes.put(Lucene3xSegmentInfoFormat.DS_OFFSET_KEY, Integer.toString(docStoreOffset));\n        attributes.put(Lucene3xSegmentInfoFormat.DS_NAME_KEY, docStoreSegment);\n        attributes.put(Lucene3xSegmentInfoFormat.DS_COMPOUND_KEY, Boolean.toString(docStoreIsCompoundFile));\n      } else {\n        docStoreSegment = name;\n        docStoreIsCompoundFile = false;\n      }\n    }\n\n    // pre-4.0 indexes write a byte if there is a single norms file\n    byte b = input.readByte();\n\n    //System.out.println(\"version=\" + version + \" name=\" + name + \" docCount=\" + docCount + \" delGen=\" + delGen + \" dso=\" + docStoreOffset + \" dss=\" + docStoreSegment + \" dssCFs=\" + docStoreIsCompoundFile + \" b=\" + b + \" format=\" + format);\n\n    assert 1 == b : \"expected 1 but was: \"+ b + \" format: \" + format;\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(j, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final boolean hasProx = input.readByte() == 1;\n\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_HAS_VECTORS) {\n      // NOTE: unused\n      final int hasVectors = input.readByte();\n    }\n\n    final Set<String> files;\n    if (format == Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE) {\n      files = input.readStringSet();\n    } else {\n      // Replicate logic from 3.x's SegmentInfo.files():\n      files = new HashSet<String>();\n      if (isCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      } else {\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xFieldInfosReader.FIELD_INFOS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.FREQ_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.PROX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.TERMS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.TERMS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xNormsProducer.NORMS_EXTENSION));\n      }\n\n      if (docStoreOffset != -1) {\n        if (docStoreIsCompoundFile) {\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION));\n        } else {\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n        }\n      } else if (!isCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n        files.add(IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n      }\n\n      if (normGen != null) {\n        for(Map.Entry<Integer,Long> ent : normGen.entrySet()) {\n          long gen = ent.getValue();\n          if (gen >= SegmentInfo.YES) {\n            // Definitely a separate norm file, with generation:\n            files.add(IndexFileNames.fileNameFromGeneration(segmentName, \"s\" + ent.getKey(), gen));\n          } else if (gen == SegmentInfo.NO) {\n            // No separate norm\n          } else {\n            // We should have already hit indexformat too old exception\n            assert false;\n          }\n        }\n      }\n    }\n\n    // nocommit: convert normgen into attributes?\n    SegmentInfo info = new SegmentInfo(dir, version, segmentName, docCount, normGen, isCompoundFile,\n                                       null, diagnostics, attributes);\n    info.setFiles(files);\n\n    SegmentInfoPerCommit infoPerCommit = new SegmentInfoPerCommit(info, delCount, delGen);\n    return infoPerCommit;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6842f2837919389de395b2bb61824335f40e5431","date":1337865715,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfoReader#readLegacySegmentInfo(Directory,int,IndexInput).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfoReader#readSegmentInfo(String,Directory,int,IndexInput).mjava","sourceNew":"  /** reads from legacy 3.x segments_N */\n  private SegmentInfoPerCommit readLegacySegmentInfo(Directory dir, int format, IndexInput input) throws IOException {\n    // check that it is a format we can understand\n    assert format != Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE;\n    if (format > Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS) {\n      throw new IndexFormatTooOldException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE);\n    }\n    if (format < Lucene3xSegmentInfoFormat.FORMAT_3_1) {\n      throw new IndexFormatTooNewException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE);\n    }\n    final String version;\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n\n    final String name = input.readString();\n\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    \n    final int docStoreOffset = input.readInt();\n    final Map<String,String> attributes = new HashMap<String,String>();\n    \n    // parse the docstore stuff and shove it into attributes\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    if (docStoreOffset != -1) {\n      docStoreSegment = input.readString();\n      docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n      attributes.put(Lucene3xSegmentInfoFormat.DS_OFFSET_KEY, Integer.toString(docStoreOffset));\n      attributes.put(Lucene3xSegmentInfoFormat.DS_NAME_KEY, docStoreSegment);\n      attributes.put(Lucene3xSegmentInfoFormat.DS_COMPOUND_KEY, Boolean.toString(docStoreIsCompoundFile));\n    } else {\n      docStoreSegment = name;\n      docStoreIsCompoundFile = false;\n    }\n\n    // pre-4.0 indexes write a byte if there is a single norms file\n    byte b = input.readByte();\n\n    //System.out.println(\"version=\" + version + \" name=\" + name + \" docCount=\" + docCount + \" delGen=\" + delGen + \" dso=\" + docStoreOffset + \" dss=\" + docStoreSegment + \" dssCFs=\" + docStoreIsCompoundFile + \" b=\" + b + \" format=\" + format);\n\n    assert 1 == b : \"expected 1 but was: \"+ b + \" format: \" + format;\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(j, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final boolean hasProx = input.readByte() == 1;\n\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_HAS_VECTORS) {\n      // NOTE: unused\n      final int hasVectors = input.readByte();\n    }\n\n    // Replicate logic from 3.x's SegmentInfo.files():\n    final Set<String> files = new HashSet<String>();\n    if (isCompoundFile) {\n      files.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xFieldInfosReader.FIELD_INFOS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.FREQ_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.PROX_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.TERMS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.TERMS_INDEX_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xNormsProducer.NORMS_EXTENSION));\n    }\n    \n    if (docStoreOffset != -1) {\n      if (docStoreIsCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n        files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n      }\n    } else if (!isCompoundFile) {\n      files.add(IndexFileNames.segmentFileName(name, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n      files.add(IndexFileNames.segmentFileName(name, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n    }\n    \n    if (normGen != null) {\n      for(Map.Entry<Integer,Long> ent : normGen.entrySet()) {\n        long gen = ent.getValue();\n        if (gen >= SegmentInfo.YES) {\n          // Definitely a separate norm file, with generation:\n          files.add(IndexFileNames.fileNameFromGeneration(name, \"s\" + ent.getKey(), gen));\n        } else if (gen == SegmentInfo.NO) {\n          // No separate norm\n        } else {\n          // We should have already hit indexformat too old exception\n          assert false;\n        }\n      }\n    }\n\n    // nocommit: convert normgen into attributes?\n    SegmentInfo info = new SegmentInfo(dir, version, name, docCount, normGen, isCompoundFile,\n                                       null, diagnostics, Collections.unmodifiableMap(attributes));\n    info.setFiles(files);\n\n    SegmentInfoPerCommit infoPerCommit = new SegmentInfoPerCommit(info, delCount, delGen);\n    return infoPerCommit;\n  }\n\n","sourceOld":"  private SegmentInfoPerCommit readSegmentInfo(String segmentName, Directory dir, int format, IndexInput input) throws IOException {\n    // check that it is a format we can understand\n    if (format > Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS) {\n      throw new IndexFormatTooOldException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE);\n    }\n    if (format < Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE) {\n      throw new IndexFormatTooNewException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE);\n    }\n    final String version;\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n\n    // NOTE: we ignore this and use the incoming arg\n    // instead, if it's non-null:\n    final String name = input.readString();\n    if (segmentName == null) {\n      segmentName = name;\n    }\n\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    \n    final int docStoreOffset;\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    final Map<String,String> attributes;\n    \n    if (format == Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE) {\n      // we already upgraded to 4.x si format: so shared docstore stuff is in the attributes map.\n      attributes = input.readStringStringMap();\n      String v = attributes.get(Lucene3xSegmentInfoFormat.DS_OFFSET_KEY);\n      docStoreOffset = v == null ? -1 : Integer.parseInt(v);\n      \n      v = attributes.get(Lucene3xSegmentInfoFormat.DS_NAME_KEY);\n      docStoreSegment = v == null ? segmentName : v;\n      \n      v = attributes.get(Lucene3xSegmentInfoFormat.DS_COMPOUND_KEY);\n      docStoreIsCompoundFile = v == null ? false : Boolean.parseBoolean(v);\n    } else {\n      // for older formats, parse the docstore stuff and shove it into attributes\n      attributes = new HashMap<String,String>();\n      docStoreOffset = input.readInt();\n      if (docStoreOffset != -1) {\n        docStoreSegment = input.readString();\n        docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n        attributes.put(Lucene3xSegmentInfoFormat.DS_OFFSET_KEY, Integer.toString(docStoreOffset));\n        attributes.put(Lucene3xSegmentInfoFormat.DS_NAME_KEY, docStoreSegment);\n        attributes.put(Lucene3xSegmentInfoFormat.DS_COMPOUND_KEY, Boolean.toString(docStoreIsCompoundFile));\n      } else {\n        docStoreSegment = name;\n        docStoreIsCompoundFile = false;\n      }\n    }\n\n    // pre-4.0 indexes write a byte if there is a single norms file\n    byte b = input.readByte();\n\n    //System.out.println(\"version=\" + version + \" name=\" + name + \" docCount=\" + docCount + \" delGen=\" + delGen + \" dso=\" + docStoreOffset + \" dss=\" + docStoreSegment + \" dssCFs=\" + docStoreIsCompoundFile + \" b=\" + b + \" format=\" + format);\n\n    assert 1 == b : \"expected 1 but was: \"+ b + \" format: \" + format;\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(j, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final boolean hasProx = input.readByte() == 1;\n\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_HAS_VECTORS) {\n      // NOTE: unused\n      final int hasVectors = input.readByte();\n    }\n\n    final Set<String> files;\n    if (format == Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE) {\n      files = input.readStringSet();\n    } else {\n      // Replicate logic from 3.x's SegmentInfo.files():\n      files = new HashSet<String>();\n      if (isCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      } else {\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xFieldInfosReader.FIELD_INFOS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.FREQ_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.PROX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.TERMS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.TERMS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xNormsProducer.NORMS_EXTENSION));\n      }\n\n      if (docStoreOffset != -1) {\n        if (docStoreIsCompoundFile) {\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION));\n        } else {\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n        }\n      } else if (!isCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n        files.add(IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n      }\n\n      if (normGen != null) {\n        for(Map.Entry<Integer,Long> ent : normGen.entrySet()) {\n          long gen = ent.getValue();\n          if (gen >= SegmentInfo.YES) {\n            // Definitely a separate norm file, with generation:\n            files.add(IndexFileNames.fileNameFromGeneration(segmentName, \"s\" + ent.getKey(), gen));\n          } else if (gen == SegmentInfo.NO) {\n            // No separate norm\n          } else {\n            // We should have already hit indexformat too old exception\n            assert false;\n          }\n        }\n      }\n    }\n\n    // nocommit: convert normgen into attributes?\n    SegmentInfo info = new SegmentInfo(dir, version, segmentName, docCount, normGen, isCompoundFile,\n                                       null, diagnostics, Collections.unmodifiableMap(attributes));\n    info.setFiles(files);\n\n    SegmentInfoPerCommit infoPerCommit = new SegmentInfoPerCommit(info, delCount, delGen);\n    return infoPerCommit;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"f00f0f8c602950d28e2cb62039b72f51f5d5c44c":["6a917aca07a305ab70118a83e84d931503441271"],"6a917aca07a305ab70118a83e84d931503441271":["63caed6eb28209e181e97822c4c8fdf808884c3b"],"63caed6eb28209e181e97822c4c8fdf808884c3b":["9d153abcf92dc5329d98571a8c3035df9bd80648"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"9d153abcf92dc5329d98571a8c3035df9bd80648":["ace9b78896617dcee984890f3300d45c539c1b15"],"6842f2837919389de395b2bb61824335f40e5431":["f00f0f8c602950d28e2cb62039b72f51f5d5c44c"],"ace9b78896617dcee984890f3300d45c539c1b15":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"f00f0f8c602950d28e2cb62039b72f51f5d5c44c":["6842f2837919389de395b2bb61824335f40e5431"],"6a917aca07a305ab70118a83e84d931503441271":["f00f0f8c602950d28e2cb62039b72f51f5d5c44c"],"63caed6eb28209e181e97822c4c8fdf808884c3b":["6a917aca07a305ab70118a83e84d931503441271"],"9d153abcf92dc5329d98571a8c3035df9bd80648":["63caed6eb28209e181e97822c4c8fdf808884c3b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ace9b78896617dcee984890f3300d45c539c1b15","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ace9b78896617dcee984890f3300d45c539c1b15":["9d153abcf92dc5329d98571a8c3035df9bd80648"],"6842f2837919389de395b2bb61824335f40e5431":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["6842f2837919389de395b2bb61824335f40e5431","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}