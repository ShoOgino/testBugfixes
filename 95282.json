{"path":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge,MergeState).mjava","commits":[{"id":"8a16d06e7522604de20b2d758d9b9464bb30fe02","date":1327070101,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge).mjava","sourceNew":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfo> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfo info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.docCount;\n      final Bits prevLiveDocs = merge.readerLiveDocs.get(i);\n      final Bits currentLiveDocs;\n      ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We enrolled in mergeInit:\n      assert rld != null;\n      currentLiveDocs = rld.liveDocs;\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        if (currentLiveDocs != prevLiveDocs) {\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                }\n                mergedDeletes.delete(docUpto);\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          final int readerDocCount;\n          if (i == sourceSegments.size()-1) {\n            readerDocCount = mergeState.mergedDocCount - mergeState.docBase[i];\n          } else {\n            readerDocCount = mergeState.docBase[i+1] - mergeState.docBase[i];\n          }\n          docUpto += readerDocCount;\n        }\n      } else if (currentLiveDocs != null) {\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n            }\n            mergedDeletes.delete(docUpto);\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.docCount;\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.pendingDeleteCount + \" new deletes since merge started\");\n      }\n    }\n\n    // If new deletes were applied while we were merging\n    // (which happens if eg commit() or getReader() is\n    // called during our merge), then it better be the case\n    // that the delGen has increased for all our merged\n    // segments:\n    assert mergedDeletes == null || minGen > merge.info.getBufferedDeletesGen();\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","sourceOld":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfo> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfo info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.docCount;\n      final MutableBits prevLiveDocs = merge.readerLiveDocs.get(i);\n      final MutableBits currentLiveDocs;\n      ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We enrolled in mergeInit:\n      assert rld != null;\n      currentLiveDocs = rld.liveDocs;\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        if (currentLiveDocs.count() < prevLiveDocs.count()) {\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                }\n                mergedDeletes.delete(docUpto);\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          assert currentLiveDocs.count() == prevLiveDocs.count(): \"currentLiveDocs.count()==\" + currentLiveDocs.count() + \" vs prevLiveDocs.count()=\" + prevLiveDocs.count() + \" info=\" + info;\n          docUpto += currentLiveDocs.count();\n        }\n      } else if (currentLiveDocs != null) {\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n            }\n            mergedDeletes.delete(docUpto);\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.docCount;\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.pendingDeleteCount + \" new deletes since merge started\");\n      }\n    }\n\n    // If new deletes were applied while we were merging\n    // (which happens if eg commit() or getReader() is\n    // called during our merge), then it better be the case\n    // that the delGen has increased for all our merged\n    // segments:\n    assert mergedDeletes == null || minGen > merge.info.getBufferedDeletesGen();\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ccad4bab070f323ce610caa0040346d4a87213dc","date":1327747432,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfo> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfo info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.docCount;\n      final Bits prevLiveDocs = merge.readerLiveDocs.get(i);\n      final Bits currentLiveDocs;\n      ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We enrolled in mergeInit:\n      assert rld != null;\n      currentLiveDocs = rld.liveDocs;\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          final int startDocUpto = docUpto;\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                }\n                mergedDeletes.delete(docUpto);\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          assert mergeState.readers != null;\n          assert mergeState.segmentDocCounts != null;\n          docUpto += mergeState.segmentDocCounts.get(info);\n        }\n      } else if (currentLiveDocs != null) {\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n            }\n            mergedDeletes.delete(docUpto);\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.docCount;\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.pendingDeleteCount + \" new deletes since merge started\");\n      }\n    }\n\n    // If new deletes were applied while we were merging\n    // (which happens if eg commit() or getReader() is\n    // called during our merge), then it better be the case\n    // that the delGen has increased for all our merged\n    // segments:\n    assert mergedDeletes == null || minGen > merge.info.getBufferedDeletesGen();\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","sourceOld":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfo> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfo info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.docCount;\n      final Bits prevLiveDocs = merge.readerLiveDocs.get(i);\n      final Bits currentLiveDocs;\n      ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We enrolled in mergeInit:\n      assert rld != null;\n      currentLiveDocs = rld.liveDocs;\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        if (currentLiveDocs != prevLiveDocs) {\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                }\n                mergedDeletes.delete(docUpto);\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          final int readerDocCount;\n          if (i == sourceSegments.size()-1) {\n            readerDocCount = mergeState.mergedDocCount - mergeState.docBase[i];\n          } else {\n            readerDocCount = mergeState.docBase[i+1] - mergeState.docBase[i];\n          }\n          docUpto += readerDocCount;\n        }\n      } else if (currentLiveDocs != null) {\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n            }\n            mergedDeletes.delete(docUpto);\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.docCount;\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.pendingDeleteCount + \" new deletes since merge started\");\n      }\n    }\n\n    // If new deletes were applied while we were merging\n    // (which happens if eg commit() or getReader() is\n    // called during our merge), then it better be the case\n    // that the delGen has increased for all our merged\n    // segments:\n    assert mergedDeletes == null || minGen > merge.info.getBufferedDeletesGen();\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","bugFix":null,"bugIntro":["36d84416fc00253f9e834f8dba14fa89b298e64e"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d3d53ad7b9687e0dfaacaab099d3c7e98bfbe78e","date":1327757020,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfo> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfo info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.docCount;\n      final Bits prevLiveDocs = merge.readerLiveDocs.get(i);\n      final Bits currentLiveDocs;\n      ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We enrolled in mergeInit:\n      assert rld != null;\n      currentLiveDocs = rld.liveDocs;\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                }\n                mergedDeletes.delete(docUpto);\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += mergeState.segmentDocCounts.get(info);\n        }\n      } else if (currentLiveDocs != null) {\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n            }\n            mergedDeletes.delete(docUpto);\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.docCount;\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.pendingDeleteCount + \" new deletes since merge started\");\n      }\n    }\n\n    // If new deletes were applied while we were merging\n    // (which happens if eg commit() or getReader() is\n    // called during our merge), then it better be the case\n    // that the delGen has increased for all our merged\n    // segments:\n    assert mergedDeletes == null || minGen > merge.info.getBufferedDeletesGen();\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","sourceOld":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfo> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfo info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.docCount;\n      final Bits prevLiveDocs = merge.readerLiveDocs.get(i);\n      final Bits currentLiveDocs;\n      ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We enrolled in mergeInit:\n      assert rld != null;\n      currentLiveDocs = rld.liveDocs;\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          final int startDocUpto = docUpto;\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                }\n                mergedDeletes.delete(docUpto);\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          assert mergeState.readers != null;\n          assert mergeState.segmentDocCounts != null;\n          docUpto += mergeState.segmentDocCounts.get(info);\n        }\n      } else if (currentLiveDocs != null) {\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n            }\n            mergedDeletes.delete(docUpto);\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.docCount;\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.pendingDeleteCount + \" new deletes since merge started\");\n      }\n    }\n\n    // If new deletes were applied while we were merging\n    // (which happens if eg commit() or getReader() is\n    // called during our merge), then it better be the case\n    // that the delGen has increased for all our merged\n    // segments:\n    assert mergedDeletes == null || minGen > merge.info.getBufferedDeletesGen();\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"32feb7c2c571b402d2e231bd8e3b6add4af6d6eb","date":1327773585,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfo> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfo info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.docCount;\n      final Bits prevLiveDocs = merge.readerLiveDocs.get(i);\n      final Bits currentLiveDocs;\n      ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We enrolled in mergeInit:\n      assert rld != null;\n      currentLiveDocs = rld.liveDocs;\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                }\n                mergedDeletes.delete(docUpto);\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += info.docCount - info.getDelCount() - rld.pendingDeleteCount;\n        }\n      } else if (currentLiveDocs != null) {\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n            }\n            mergedDeletes.delete(docUpto);\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.docCount;\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.pendingDeleteCount + \" new deletes since merge started\");\n      }\n    }\n\n    // If new deletes were applied while we were merging\n    // (which happens if eg commit() or getReader() is\n    // called during our merge), then it better be the case\n    // that the delGen has increased for all our merged\n    // segments:\n    assert mergedDeletes == null || minGen > merge.info.getBufferedDeletesGen();\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","sourceOld":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfo> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfo info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.docCount;\n      final Bits prevLiveDocs = merge.readerLiveDocs.get(i);\n      final Bits currentLiveDocs;\n      ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We enrolled in mergeInit:\n      assert rld != null;\n      currentLiveDocs = rld.liveDocs;\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                }\n                mergedDeletes.delete(docUpto);\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += mergeState.segmentDocCounts.get(info);\n        }\n      } else if (currentLiveDocs != null) {\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n            }\n            mergedDeletes.delete(docUpto);\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.docCount;\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.pendingDeleteCount + \" new deletes since merge started\");\n      }\n    }\n\n    // If new deletes were applied while we were merging\n    // (which happens if eg commit() or getReader() is\n    // called during our merge), then it better be the case\n    // that the delGen has increased for all our merged\n    // segments:\n    assert mergedDeletes == null || minGen > merge.info.getBufferedDeletesGen();\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","bugFix":null,"bugIntro":["ae695f21c50b03702b5d0fa2543d5af844bb7cd3"],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d3d53ad7b9687e0dfaacaab099d3c7e98bfbe78e":["ccad4bab070f323ce610caa0040346d4a87213dc"],"32feb7c2c571b402d2e231bd8e3b6add4af6d6eb":["d3d53ad7b9687e0dfaacaab099d3c7e98bfbe78e"],"ccad4bab070f323ce610caa0040346d4a87213dc":["8a16d06e7522604de20b2d758d9b9464bb30fe02"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"8a16d06e7522604de20b2d758d9b9464bb30fe02":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817","8a16d06e7522604de20b2d758d9b9464bb30fe02"],"d3d53ad7b9687e0dfaacaab099d3c7e98bfbe78e":["32feb7c2c571b402d2e231bd8e3b6add4af6d6eb"],"32feb7c2c571b402d2e231bd8e3b6add4af6d6eb":[],"ccad4bab070f323ce610caa0040346d4a87213dc":["d3d53ad7b9687e0dfaacaab099d3c7e98bfbe78e"],"8a16d06e7522604de20b2d758d9b9464bb30fe02":["ccad4bab070f323ce610caa0040346d4a87213dc"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["32feb7c2c571b402d2e231bd8e3b6add4af6d6eb","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}