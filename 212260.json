{"path":"lucene/core/src/test/org/apache/lucene/codecs/compressing/AbstractTestLZ4CompressionMode#test(byte[]).mjava","commits":[{"id":"0c3c76aa202009a206735eb7501d52a87ccaba79","date":1354660681,"type":0,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/compressing/AbstractTestLZ4CompressionMode#test(byte[]).mjava","pathOld":"/dev/null","sourceNew":"  public byte[] test(byte[] decompressed) throws IOException {\n    final byte[] compressed = super.test(decompressed);\n    int off = 0;\n    int decompressedOff = 0;\n    for (;;) {\n      final int token = compressed[off++] & 0xFF;\n      int literalLen = token >>> 4;\n      if (literalLen == 0x0F) {\n        while (compressed[off] == (byte) 0xFF) {\n          literalLen += 0xFF;\n          ++off;\n        }\n        literalLen += compressed[off++] & 0xFF;\n      }\n      // skip literals\n      off += literalLen;\n      decompressedOff += literalLen;\n\n      // check that the stream ends with literals and that there are at least\n      // 5 of them\n      if (off == compressed.length) {\n        assertEquals(decompressed.length, decompressedOff);\n        assertTrue(\"lastLiterals=\" + literalLen + \", bytes=\" + decompressed.length,\n            literalLen >= LZ4.LAST_LITERALS || literalLen == decompressed.length);\n        break;\n      }\n\n      final int matchDec = (compressed[off++] & 0xFF) | ((compressed[off++] & 0xFF) << 8);\n      // check that match dec is not 0\n      assertTrue(matchDec + \" \" + decompressedOff, matchDec > 0 && matchDec <= decompressedOff);\n\n      int matchLen = token & 0x0F;\n      if (matchLen == 0x0F) {\n        while (compressed[off] == (byte) 0xFF) {\n          matchLen += 0xFF;\n          ++off;\n        }\n        matchLen += compressed[off++] & 0xFF;\n      }\n      matchLen += LZ4.MIN_MATCH;\n\n      // if the match ends prematurely, the next sequence should not have\n      // literals or this means we are wasting space\n      if (decompressedOff + matchLen < decompressed.length - LZ4.LAST_LITERALS) {\n        final boolean moreCommonBytes = decompressed[decompressedOff + matchLen] == decompressed[decompressedOff - matchDec + matchLen];\n        final boolean nextSequenceHasLiterals = ((compressed[off] & 0xFF) >>> 4) != 0;\n        assertTrue(!moreCommonBytes || !nextSequenceHasLiterals);\n      }      \n\n      decompressedOff += matchLen;\n    }\n    assertEquals(decompressed.length, decompressedOff);\n    return compressed;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"407687e67faf6e1f02a211ca078d8e3eed631027","date":1355157407,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/compressing/AbstractTestLZ4CompressionMode#test(byte[]).mjava","pathOld":"/dev/null","sourceNew":"  public byte[] test(byte[] decompressed) throws IOException {\n    final byte[] compressed = super.test(decompressed);\n    int off = 0;\n    int decompressedOff = 0;\n    for (;;) {\n      final int token = compressed[off++] & 0xFF;\n      int literalLen = token >>> 4;\n      if (literalLen == 0x0F) {\n        while (compressed[off] == (byte) 0xFF) {\n          literalLen += 0xFF;\n          ++off;\n        }\n        literalLen += compressed[off++] & 0xFF;\n      }\n      // skip literals\n      off += literalLen;\n      decompressedOff += literalLen;\n\n      // check that the stream ends with literals and that there are at least\n      // 5 of them\n      if (off == compressed.length) {\n        assertEquals(decompressed.length, decompressedOff);\n        assertTrue(\"lastLiterals=\" + literalLen + \", bytes=\" + decompressed.length,\n            literalLen >= LZ4.LAST_LITERALS || literalLen == decompressed.length);\n        break;\n      }\n\n      final int matchDec = (compressed[off++] & 0xFF) | ((compressed[off++] & 0xFF) << 8);\n      // check that match dec is not 0\n      assertTrue(matchDec + \" \" + decompressedOff, matchDec > 0 && matchDec <= decompressedOff);\n\n      int matchLen = token & 0x0F;\n      if (matchLen == 0x0F) {\n        while (compressed[off] == (byte) 0xFF) {\n          matchLen += 0xFF;\n          ++off;\n        }\n        matchLen += compressed[off++] & 0xFF;\n      }\n      matchLen += LZ4.MIN_MATCH;\n\n      // if the match ends prematurely, the next sequence should not have\n      // literals or this means we are wasting space\n      if (decompressedOff + matchLen < decompressed.length - LZ4.LAST_LITERALS) {\n        final boolean moreCommonBytes = decompressed[decompressedOff + matchLen] == decompressed[decompressedOff - matchDec + matchLen];\n        final boolean nextSequenceHasLiterals = ((compressed[off] & 0xFF) >>> 4) != 0;\n        assertTrue(!moreCommonBytes || !nextSequenceHasLiterals);\n      }      \n\n      decompressedOff += matchLen;\n    }\n    assertEquals(decompressed.length, decompressedOff);\n    return compressed;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7530de27b87b961b51f01bd1299b7004d46e8823","date":1355236261,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/compressing/AbstractTestLZ4CompressionMode#test(byte[]).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/compressing/AbstractTestLZ4CompressionMode#test(byte[]).mjava","sourceNew":"  @Override\n  public byte[] test(byte[] decompressed) throws IOException {\n    final byte[] compressed = super.test(decompressed);\n    int off = 0;\n    int decompressedOff = 0;\n    for (;;) {\n      final int token = compressed[off++] & 0xFF;\n      int literalLen = token >>> 4;\n      if (literalLen == 0x0F) {\n        while (compressed[off] == (byte) 0xFF) {\n          literalLen += 0xFF;\n          ++off;\n        }\n        literalLen += compressed[off++] & 0xFF;\n      }\n      // skip literals\n      off += literalLen;\n      decompressedOff += literalLen;\n\n      // check that the stream ends with literals and that there are at least\n      // 5 of them\n      if (off == compressed.length) {\n        assertEquals(decompressed.length, decompressedOff);\n        assertTrue(\"lastLiterals=\" + literalLen + \", bytes=\" + decompressed.length,\n            literalLen >= LZ4.LAST_LITERALS || literalLen == decompressed.length);\n        break;\n      }\n\n      final int matchDec = (compressed[off++] & 0xFF) | ((compressed[off++] & 0xFF) << 8);\n      // check that match dec is not 0\n      assertTrue(matchDec + \" \" + decompressedOff, matchDec > 0 && matchDec <= decompressedOff);\n\n      int matchLen = token & 0x0F;\n      if (matchLen == 0x0F) {\n        while (compressed[off] == (byte) 0xFF) {\n          matchLen += 0xFF;\n          ++off;\n        }\n        matchLen += compressed[off++] & 0xFF;\n      }\n      matchLen += LZ4.MIN_MATCH;\n\n      // if the match ends prematurely, the next sequence should not have\n      // literals or this means we are wasting space\n      if (decompressedOff + matchLen < decompressed.length - LZ4.LAST_LITERALS) {\n        final boolean moreCommonBytes = decompressed[decompressedOff + matchLen] == decompressed[decompressedOff - matchDec + matchLen];\n        final boolean nextSequenceHasLiterals = ((compressed[off] & 0xFF) >>> 4) != 0;\n        assertTrue(!moreCommonBytes || !nextSequenceHasLiterals);\n      }      \n\n      decompressedOff += matchLen;\n    }\n    assertEquals(decompressed.length, decompressedOff);\n    return compressed;\n  }\n\n","sourceOld":"  public byte[] test(byte[] decompressed) throws IOException {\n    final byte[] compressed = super.test(decompressed);\n    int off = 0;\n    int decompressedOff = 0;\n    for (;;) {\n      final int token = compressed[off++] & 0xFF;\n      int literalLen = token >>> 4;\n      if (literalLen == 0x0F) {\n        while (compressed[off] == (byte) 0xFF) {\n          literalLen += 0xFF;\n          ++off;\n        }\n        literalLen += compressed[off++] & 0xFF;\n      }\n      // skip literals\n      off += literalLen;\n      decompressedOff += literalLen;\n\n      // check that the stream ends with literals and that there are at least\n      // 5 of them\n      if (off == compressed.length) {\n        assertEquals(decompressed.length, decompressedOff);\n        assertTrue(\"lastLiterals=\" + literalLen + \", bytes=\" + decompressed.length,\n            literalLen >= LZ4.LAST_LITERALS || literalLen == decompressed.length);\n        break;\n      }\n\n      final int matchDec = (compressed[off++] & 0xFF) | ((compressed[off++] & 0xFF) << 8);\n      // check that match dec is not 0\n      assertTrue(matchDec + \" \" + decompressedOff, matchDec > 0 && matchDec <= decompressedOff);\n\n      int matchLen = token & 0x0F;\n      if (matchLen == 0x0F) {\n        while (compressed[off] == (byte) 0xFF) {\n          matchLen += 0xFF;\n          ++off;\n        }\n        matchLen += compressed[off++] & 0xFF;\n      }\n      matchLen += LZ4.MIN_MATCH;\n\n      // if the match ends prematurely, the next sequence should not have\n      // literals or this means we are wasting space\n      if (decompressedOff + matchLen < decompressed.length - LZ4.LAST_LITERALS) {\n        final boolean moreCommonBytes = decompressed[decompressedOff + matchLen] == decompressed[decompressedOff - matchDec + matchLen];\n        final boolean nextSequenceHasLiterals = ((compressed[off] & 0xFF) >>> 4) != 0;\n        assertTrue(!moreCommonBytes || !nextSequenceHasLiterals);\n      }      \n\n      decompressedOff += matchLen;\n    }\n    assertEquals(decompressed.length, decompressedOff);\n    return compressed;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/compressing/AbstractTestLZ4CompressionMode#test(byte[]).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/compressing/AbstractTestLZ4CompressionMode#test(byte[]).mjava","sourceNew":"  @Override\n  public byte[] test(byte[] decompressed) throws IOException {\n    final byte[] compressed = super.test(decompressed);\n    int off = 0;\n    int decompressedOff = 0;\n    for (;;) {\n      final int token = compressed[off++] & 0xFF;\n      int literalLen = token >>> 4;\n      if (literalLen == 0x0F) {\n        while (compressed[off] == (byte) 0xFF) {\n          literalLen += 0xFF;\n          ++off;\n        }\n        literalLen += compressed[off++] & 0xFF;\n      }\n      // skip literals\n      off += literalLen;\n      decompressedOff += literalLen;\n\n      // check that the stream ends with literals and that there are at least\n      // 5 of them\n      if (off == compressed.length) {\n        assertEquals(decompressed.length, decompressedOff);\n        assertTrue(\"lastLiterals=\" + literalLen + \", bytes=\" + decompressed.length,\n            literalLen >= LZ4.LAST_LITERALS || literalLen == decompressed.length);\n        break;\n      }\n\n      final int matchDec = (compressed[off++] & 0xFF) | ((compressed[off++] & 0xFF) << 8);\n      // check that match dec is not 0\n      assertTrue(matchDec + \" \" + decompressedOff, matchDec > 0 && matchDec <= decompressedOff);\n\n      int matchLen = token & 0x0F;\n      if (matchLen == 0x0F) {\n        while (compressed[off] == (byte) 0xFF) {\n          matchLen += 0xFF;\n          ++off;\n        }\n        matchLen += compressed[off++] & 0xFF;\n      }\n      matchLen += LZ4.MIN_MATCH;\n\n      // if the match ends prematurely, the next sequence should not have\n      // literals or this means we are wasting space\n      if (decompressedOff + matchLen < decompressed.length - LZ4.LAST_LITERALS) {\n        final boolean moreCommonBytes = decompressed[decompressedOff + matchLen] == decompressed[decompressedOff - matchDec + matchLen];\n        final boolean nextSequenceHasLiterals = ((compressed[off] & 0xFF) >>> 4) != 0;\n        assertTrue(!moreCommonBytes || !nextSequenceHasLiterals);\n      }      \n\n      decompressedOff += matchLen;\n    }\n    assertEquals(decompressed.length, decompressedOff);\n    return compressed;\n  }\n\n","sourceOld":"  public byte[] test(byte[] decompressed) throws IOException {\n    final byte[] compressed = super.test(decompressed);\n    int off = 0;\n    int decompressedOff = 0;\n    for (;;) {\n      final int token = compressed[off++] & 0xFF;\n      int literalLen = token >>> 4;\n      if (literalLen == 0x0F) {\n        while (compressed[off] == (byte) 0xFF) {\n          literalLen += 0xFF;\n          ++off;\n        }\n        literalLen += compressed[off++] & 0xFF;\n      }\n      // skip literals\n      off += literalLen;\n      decompressedOff += literalLen;\n\n      // check that the stream ends with literals and that there are at least\n      // 5 of them\n      if (off == compressed.length) {\n        assertEquals(decompressed.length, decompressedOff);\n        assertTrue(\"lastLiterals=\" + literalLen + \", bytes=\" + decompressed.length,\n            literalLen >= LZ4.LAST_LITERALS || literalLen == decompressed.length);\n        break;\n      }\n\n      final int matchDec = (compressed[off++] & 0xFF) | ((compressed[off++] & 0xFF) << 8);\n      // check that match dec is not 0\n      assertTrue(matchDec + \" \" + decompressedOff, matchDec > 0 && matchDec <= decompressedOff);\n\n      int matchLen = token & 0x0F;\n      if (matchLen == 0x0F) {\n        while (compressed[off] == (byte) 0xFF) {\n          matchLen += 0xFF;\n          ++off;\n        }\n        matchLen += compressed[off++] & 0xFF;\n      }\n      matchLen += LZ4.MIN_MATCH;\n\n      // if the match ends prematurely, the next sequence should not have\n      // literals or this means we are wasting space\n      if (decompressedOff + matchLen < decompressed.length - LZ4.LAST_LITERALS) {\n        final boolean moreCommonBytes = decompressed[decompressedOff + matchLen] == decompressed[decompressedOff - matchDec + matchLen];\n        final boolean nextSequenceHasLiterals = ((compressed[off] & 0xFF) >>> 4) != 0;\n        assertTrue(!moreCommonBytes || !nextSequenceHasLiterals);\n      }      \n\n      decompressedOff += matchLen;\n    }\n    assertEquals(decompressed.length, decompressedOff);\n    return compressed;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9407318969e8504257b4c5764c65755a043e5404","date":1579873617,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/util/compress/LZ4TestCase#doTest(byte[],int,int,LZ4.HashTable).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/compressing/AbstractTestLZ4CompressionMode#test(byte[]).mjava","sourceNew":"  private void doTest(byte[] data, int offset, int length, LZ4.HashTable hashTable) throws IOException {\n    ByteBuffersDataOutput out = new ByteBuffersDataOutput();\n    LZ4.compress(data, offset, length, out, hashTable);\n    byte[] compressed = out.toArrayCopy();\n\n    int off = 0;\n    int decompressedOff = 0;\n    for (;;) {\n      final int token = compressed[off++] & 0xFF;\n      int literalLen = token >>> 4;\n      if (literalLen == 0x0F) {\n        while (compressed[off] == (byte) 0xFF) {\n          literalLen += 0xFF;\n          ++off;\n        }\n        literalLen += compressed[off++] & 0xFF;\n      }\n      // skip literals\n      off += literalLen;\n      decompressedOff += literalLen;\n\n      // check that the stream ends with literals and that there are at least\n      // 5 of them\n      if (off == compressed.length) {\n        assertEquals(length, decompressedOff);\n        assertTrue(\"lastLiterals=\" + literalLen + \", bytes=\" + length,\n            literalLen >= LZ4.LAST_LITERALS || literalLen == length);\n        break;\n      }\n\n      final int matchDec = (compressed[off++] & 0xFF) | ((compressed[off++] & 0xFF) << 8);\n      // check that match dec is not 0\n      assertTrue(matchDec + \" \" + decompressedOff, matchDec > 0 && matchDec <= decompressedOff);\n\n      int matchLen = token & 0x0F;\n      if (matchLen == 0x0F) {\n        while (compressed[off] == (byte) 0xFF) {\n          matchLen += 0xFF;\n          ++off;\n        }\n        matchLen += compressed[off++] & 0xFF;\n      }\n      matchLen += LZ4.MIN_MATCH;\n\n      // if the match ends prematurely, the next sequence should not have\n      // literals or this means we are wasting space\n      if (decompressedOff + matchLen < length - LZ4.LAST_LITERALS) {\n        final boolean moreCommonBytes = data[offset + decompressedOff + matchLen] == data[offset + decompressedOff - matchDec + matchLen];\n        final boolean nextSequenceHasLiterals = ((compressed[off] & 0xFF) >>> 4) != 0;\n        assertTrue(moreCommonBytes == false || nextSequenceHasLiterals == false);\n      }      \n\n      decompressedOff += matchLen;\n    }\n    assertEquals(length, decompressedOff);\n\n    // Compress once again with the same hash table to test reuse\n    ByteBuffersDataOutput out2 = new ByteBuffersDataOutput();\n    LZ4.compress(data, offset, length, out2, hashTable);\n    assertArrayEquals(compressed, out2.toArrayCopy());\n  }\n\n","sourceOld":"  @Override\n  public byte[] test(byte[] decompressed) throws IOException {\n    final byte[] compressed = super.test(decompressed);\n    int off = 0;\n    int decompressedOff = 0;\n    for (;;) {\n      final int token = compressed[off++] & 0xFF;\n      int literalLen = token >>> 4;\n      if (literalLen == 0x0F) {\n        while (compressed[off] == (byte) 0xFF) {\n          literalLen += 0xFF;\n          ++off;\n        }\n        literalLen += compressed[off++] & 0xFF;\n      }\n      // skip literals\n      off += literalLen;\n      decompressedOff += literalLen;\n\n      // check that the stream ends with literals and that there are at least\n      // 5 of them\n      if (off == compressed.length) {\n        assertEquals(decompressed.length, decompressedOff);\n        assertTrue(\"lastLiterals=\" + literalLen + \", bytes=\" + decompressed.length,\n            literalLen >= LZ4.LAST_LITERALS || literalLen == decompressed.length);\n        break;\n      }\n\n      final int matchDec = (compressed[off++] & 0xFF) | ((compressed[off++] & 0xFF) << 8);\n      // check that match dec is not 0\n      assertTrue(matchDec + \" \" + decompressedOff, matchDec > 0 && matchDec <= decompressedOff);\n\n      int matchLen = token & 0x0F;\n      if (matchLen == 0x0F) {\n        while (compressed[off] == (byte) 0xFF) {\n          matchLen += 0xFF;\n          ++off;\n        }\n        matchLen += compressed[off++] & 0xFF;\n      }\n      matchLen += LZ4.MIN_MATCH;\n\n      // if the match ends prematurely, the next sequence should not have\n      // literals or this means we are wasting space\n      if (decompressedOff + matchLen < decompressed.length - LZ4.LAST_LITERALS) {\n        final boolean moreCommonBytes = decompressed[decompressedOff + matchLen] == decompressed[decompressedOff - matchDec + matchLen];\n        final boolean nextSequenceHasLiterals = ((compressed[off] & 0xFF) >>> 4) != 0;\n        assertTrue(!moreCommonBytes || !nextSequenceHasLiterals);\n      }      \n\n      decompressedOff += matchLen;\n    }\n    assertEquals(decompressed.length, decompressedOff);\n    return compressed;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["407687e67faf6e1f02a211ca078d8e3eed631027","7530de27b87b961b51f01bd1299b7004d46e8823"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"407687e67faf6e1f02a211ca078d8e3eed631027":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","0c3c76aa202009a206735eb7501d52a87ccaba79"],"9407318969e8504257b4c5764c65755a043e5404":["7530de27b87b961b51f01bd1299b7004d46e8823"],"0c3c76aa202009a206735eb7501d52a87ccaba79":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"7530de27b87b961b51f01bd1299b7004d46e8823":["0c3c76aa202009a206735eb7501d52a87ccaba79"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9407318969e8504257b4c5764c65755a043e5404"]},"commit2Childs":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"407687e67faf6e1f02a211ca078d8e3eed631027":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["407687e67faf6e1f02a211ca078d8e3eed631027","0c3c76aa202009a206735eb7501d52a87ccaba79"],"9407318969e8504257b4c5764c65755a043e5404":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"0c3c76aa202009a206735eb7501d52a87ccaba79":["407687e67faf6e1f02a211ca078d8e3eed631027","7530de27b87b961b51f01bd1299b7004d46e8823"],"7530de27b87b961b51f01bd1299b7004d46e8823":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","9407318969e8504257b4c5764c65755a043e5404"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}