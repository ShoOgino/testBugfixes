{"path":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean).mjava","commits":[{"id":"5b38e3f2849cb8d8626cd5368aa64de4fed9edde","date":1196183330,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean).mjava","pathOld":"/dev/null","sourceNew":"  /** Returns true if index is clean, else false.*/\n  public static boolean check(Directory dir, boolean doFix) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    \n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read any segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not open segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read segment file version in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else if (format < SegmentInfos.FORMAT_SHARED_DOC_STORE) {\n      sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n      skip = true;\n    } else {\n      sFormat = format + \" [Lucene 1.3 or prior]\";\n    }\n\n    out.println(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n\n    if (skip) {\n      out.println(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      return false;\n    }\n\n    SegmentInfos newSIS = (SegmentInfos) sis.clone();\n    newSIS.clear();\n    boolean changed = false;\n    int totLoseDocCount = 0;\n    int numBadSegments = 0;\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      out.println(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        out.println(\"    compound=\" + info.getUseCompoundFile());\n        out.println(\"    numFiles=\" + info.files().size());\n        out.println(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          out.println(\"    docStoreOffset=\" + docStoreOffset);\n          out.println(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          out.println(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null)\n          out.println(\"    no deletions\");\n        else\n          out.println(\"    has deletions [delFileName=\" + delFileName + \"]\");\n        out.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions())\n          out.println(\"OK [\" + (info.docCount - numDocs) + \" deleted docs]\");\n        else\n          out.println(\"OK\");\n\n        out.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          byte[] b = reader.norms(fieldName);\n          if (b.length != info.docCount)\n            throw new RuntimeException(\"norms for field \\\"\" + fieldName + \"\\\" is length \" + b.length + \" != maxDoc \" + info.docCount);\n\n        }\n        out.println(\"OK [\" + fieldNames.size() + \" fields]\");\n\n        out.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" < lastDoc \" + lastDoc);\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < 0)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos <= lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        out.println(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        out.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        out.println(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        out.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        out.println(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        out.println(\"\");\n\n      } catch (Throwable t) {\n        out.println(\"FAILED\");\n        String comment;\n        if (doFix)\n          comment = \"will remove reference to this segment (-fix is specified)\";\n        else\n          comment = \"would remove reference to this segment (-fix was not specified)\";\n        out.println(\"    WARNING: \" + comment + \"; full exception:\");\n        t.printStackTrace(out);\n        out.println(\"\");\n        totLoseDocCount += toLoseDocCount;\n        numBadSegments++;\n        changed = true;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      newSIS.add(info.clone());\n    }\n\n    if (!changed) {\n      out.println(\"No problems were detected with this index.\\n\");\n      return true;\n    } else {\n      out.println(\"WARNING: \" + numBadSegments + \" broken segments detected\");\n      if (doFix)\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents will be lost\");\n      else\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents would be lost if -fix were specified\");\n      out.println();\n    }\n\n    if (doFix) {\n      out.println(\"NOTE: will write new segments file in 5 seconds; this will remove \" + totLoseDocCount + \" docs from the index. THIS IS YOUR LAST CHANCE TO CTRL+C!\");\n      for(int i=0;i<5;i++) {\n        try {\n          Thread.sleep(1000);\n        } catch (InterruptedException ie) {\n          Thread.currentThread().interrupt();\n          i--;\n          continue;\n        }\n          \n        out.println(\"  \" + (5-i) + \"...\");\n      }\n      out.print(\"Writing...\");\n      try {\n        newSIS.write(dir);\n      } catch (Throwable t) {\n        out.println(\"FAILED; exiting\");\n        t.printStackTrace(out);\n        return false;\n      }\n      out.println(\"OK\");\n      out.println(\"Wrote new segments file \\\"\" + newSIS.getCurrentSegmentFileName() + \"\\\"\");\n    } else {\n      out.println(\"NOTE: would write new segments file [-fix was not specified]\");\n    }\n    out.println(\"\");\n\n    return false;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["7391c1f4ab1a6817de8a262f5c1b3de3cf190785"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"618f42b75ebb7827e10d9ce2b2df8b50ee73c27c","date":1198269108,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean).mjava","pathOld":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean).mjava","sourceNew":"  /** Returns true if index is clean, else false.*/\n  public static boolean check(Directory dir, boolean doFix) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    \n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read any segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not open segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read segment file version in directory\");\n      t.printStackTrace(out);\n      return false;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else if (format < SegmentInfos.FORMAT_SHARED_DOC_STORE) {\n      sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n      skip = true;\n    } else {\n      sFormat = format + \" [Lucene 1.3 or prior]\";\n    }\n\n    out.println(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n\n    if (skip) {\n      out.println(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      return false;\n    }\n\n    SegmentInfos newSIS = (SegmentInfos) sis.clone();\n    newSIS.clear();\n    boolean changed = false;\n    int totLoseDocCount = 0;\n    int numBadSegments = 0;\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      out.println(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        out.println(\"    compound=\" + info.getUseCompoundFile());\n        out.println(\"    numFiles=\" + info.files().size());\n        out.println(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          out.println(\"    docStoreOffset=\" + docStoreOffset);\n          out.println(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          out.println(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null)\n          out.println(\"    no deletions\");\n        else\n          out.println(\"    has deletions [delFileName=\" + delFileName + \"]\");\n        out.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions())\n          out.println(\"OK [\" + (info.docCount - numDocs) + \" deleted docs]\");\n        else\n          out.println(\"OK\");\n\n        out.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          byte[] b = reader.norms(fieldName);\n          if (b.length != info.docCount)\n            throw new RuntimeException(\"norms for field \\\"\" + fieldName + \"\\\" is length \" + b.length + \" != maxDoc \" + info.docCount);\n\n        }\n        out.println(\"OK [\" + fieldNames.size() + \" fields]\");\n\n        out.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" < lastDoc \" + lastDoc);\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < 0)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos <= lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        out.println(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        out.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        out.println(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        out.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        out.println(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        out.println(\"\");\n\n      } catch (Throwable t) {\n        out.println(\"FAILED\");\n        String comment;\n        if (doFix)\n          comment = \"will remove reference to this segment (-fix is specified)\";\n        else\n          comment = \"would remove reference to this segment (-fix was not specified)\";\n        out.println(\"    WARNING: \" + comment + \"; full exception:\");\n        t.printStackTrace(out);\n        out.println(\"\");\n        totLoseDocCount += toLoseDocCount;\n        numBadSegments++;\n        changed = true;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      newSIS.add(info.clone());\n    }\n\n    if (!changed) {\n      out.println(\"No problems were detected with this index.\\n\");\n      return true;\n    } else {\n      out.println(\"WARNING: \" + numBadSegments + \" broken segments detected\");\n      if (doFix)\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents will be lost\");\n      else\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents would be lost if -fix were specified\");\n      out.println();\n    }\n\n    if (doFix) {\n      out.println(\"NOTE: will write new segments file in 5 seconds; this will remove \" + totLoseDocCount + \" docs from the index. THIS IS YOUR LAST CHANCE TO CTRL+C!\");\n      for(int i=0;i<5;i++) {\n        try {\n          Thread.sleep(1000);\n        } catch (InterruptedException ie) {\n          Thread.currentThread().interrupt();\n          i--;\n          continue;\n        }\n          \n        out.println(\"  \" + (5-i) + \"...\");\n      }\n      out.print(\"Writing...\");\n      try {\n        newSIS.write(dir);\n      } catch (Throwable t) {\n        out.println(\"FAILED; exiting\");\n        t.printStackTrace(out);\n        return false;\n      }\n      out.println(\"OK\");\n      out.println(\"Wrote new segments file \\\"\" + newSIS.getCurrentSegmentFileName() + \"\\\"\");\n    } else {\n      out.println(\"NOTE: would write new segments file [-fix was not specified]\");\n    }\n    out.println(\"\");\n\n    return false;\n  }\n\n","sourceOld":"  /** Returns true if index is clean, else false.*/\n  public static boolean check(Directory dir, boolean doFix) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    \n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read any segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not open segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read segment file version in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else if (format < SegmentInfos.FORMAT_SHARED_DOC_STORE) {\n      sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n      skip = true;\n    } else {\n      sFormat = format + \" [Lucene 1.3 or prior]\";\n    }\n\n    out.println(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n\n    if (skip) {\n      out.println(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      return false;\n    }\n\n    SegmentInfos newSIS = (SegmentInfos) sis.clone();\n    newSIS.clear();\n    boolean changed = false;\n    int totLoseDocCount = 0;\n    int numBadSegments = 0;\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      out.println(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        out.println(\"    compound=\" + info.getUseCompoundFile());\n        out.println(\"    numFiles=\" + info.files().size());\n        out.println(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          out.println(\"    docStoreOffset=\" + docStoreOffset);\n          out.println(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          out.println(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null)\n          out.println(\"    no deletions\");\n        else\n          out.println(\"    has deletions [delFileName=\" + delFileName + \"]\");\n        out.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions())\n          out.println(\"OK [\" + (info.docCount - numDocs) + \" deleted docs]\");\n        else\n          out.println(\"OK\");\n\n        out.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          byte[] b = reader.norms(fieldName);\n          if (b.length != info.docCount)\n            throw new RuntimeException(\"norms for field \\\"\" + fieldName + \"\\\" is length \" + b.length + \" != maxDoc \" + info.docCount);\n\n        }\n        out.println(\"OK [\" + fieldNames.size() + \" fields]\");\n\n        out.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" < lastDoc \" + lastDoc);\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < 0)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos <= lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        out.println(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        out.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        out.println(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        out.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        out.println(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        out.println(\"\");\n\n      } catch (Throwable t) {\n        out.println(\"FAILED\");\n        String comment;\n        if (doFix)\n          comment = \"will remove reference to this segment (-fix is specified)\";\n        else\n          comment = \"would remove reference to this segment (-fix was not specified)\";\n        out.println(\"    WARNING: \" + comment + \"; full exception:\");\n        t.printStackTrace(out);\n        out.println(\"\");\n        totLoseDocCount += toLoseDocCount;\n        numBadSegments++;\n        changed = true;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      newSIS.add(info.clone());\n    }\n\n    if (!changed) {\n      out.println(\"No problems were detected with this index.\\n\");\n      return true;\n    } else {\n      out.println(\"WARNING: \" + numBadSegments + \" broken segments detected\");\n      if (doFix)\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents will be lost\");\n      else\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents would be lost if -fix were specified\");\n      out.println();\n    }\n\n    if (doFix) {\n      out.println(\"NOTE: will write new segments file in 5 seconds; this will remove \" + totLoseDocCount + \" docs from the index. THIS IS YOUR LAST CHANCE TO CTRL+C!\");\n      for(int i=0;i<5;i++) {\n        try {\n          Thread.sleep(1000);\n        } catch (InterruptedException ie) {\n          Thread.currentThread().interrupt();\n          i--;\n          continue;\n        }\n          \n        out.println(\"  \" + (5-i) + \"...\");\n      }\n      out.print(\"Writing...\");\n      try {\n        newSIS.write(dir);\n      } catch (Throwable t) {\n        out.println(\"FAILED; exiting\");\n        t.printStackTrace(out);\n        return false;\n      }\n      out.println(\"OK\");\n      out.println(\"Wrote new segments file \\\"\" + newSIS.getCurrentSegmentFileName() + \"\\\"\");\n    } else {\n      out.println(\"NOTE: would write new segments file [-fix was not specified]\");\n    }\n    out.println(\"\");\n\n    return false;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a64db7380e46c730a4ff0f00ebd7b29219312c14","date":1201253781,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean).mjava","pathOld":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean).mjava","sourceNew":"  /** Returns true if index is clean, else false.*/\n  public static boolean check(Directory dir, boolean doFix) throws IOException {\n    return check(dir, doFix, null);\n  }\n\n","sourceOld":"  /** Returns true if index is clean, else false.*/\n  public static boolean check(Directory dir, boolean doFix) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    \n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read any segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not open segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read segment file version in directory\");\n      t.printStackTrace(out);\n      return false;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else if (format < SegmentInfos.FORMAT_SHARED_DOC_STORE) {\n      sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n      skip = true;\n    } else {\n      sFormat = format + \" [Lucene 1.3 or prior]\";\n    }\n\n    out.println(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n\n    if (skip) {\n      out.println(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      return false;\n    }\n\n    SegmentInfos newSIS = (SegmentInfos) sis.clone();\n    newSIS.clear();\n    boolean changed = false;\n    int totLoseDocCount = 0;\n    int numBadSegments = 0;\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      out.println(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        out.println(\"    compound=\" + info.getUseCompoundFile());\n        out.println(\"    numFiles=\" + info.files().size());\n        out.println(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          out.println(\"    docStoreOffset=\" + docStoreOffset);\n          out.println(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          out.println(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null)\n          out.println(\"    no deletions\");\n        else\n          out.println(\"    has deletions [delFileName=\" + delFileName + \"]\");\n        out.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions())\n          out.println(\"OK [\" + (info.docCount - numDocs) + \" deleted docs]\");\n        else\n          out.println(\"OK\");\n\n        out.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          byte[] b = reader.norms(fieldName);\n          if (b.length != info.docCount)\n            throw new RuntimeException(\"norms for field \\\"\" + fieldName + \"\\\" is length \" + b.length + \" != maxDoc \" + info.docCount);\n\n        }\n        out.println(\"OK [\" + fieldNames.size() + \" fields]\");\n\n        out.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" < lastDoc \" + lastDoc);\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < 0)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos <= lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        out.println(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        out.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        out.println(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        out.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        out.println(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        out.println(\"\");\n\n      } catch (Throwable t) {\n        out.println(\"FAILED\");\n        String comment;\n        if (doFix)\n          comment = \"will remove reference to this segment (-fix is specified)\";\n        else\n          comment = \"would remove reference to this segment (-fix was not specified)\";\n        out.println(\"    WARNING: \" + comment + \"; full exception:\");\n        t.printStackTrace(out);\n        out.println(\"\");\n        totLoseDocCount += toLoseDocCount;\n        numBadSegments++;\n        changed = true;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      newSIS.add(info.clone());\n    }\n\n    if (!changed) {\n      out.println(\"No problems were detected with this index.\\n\");\n      return true;\n    } else {\n      out.println(\"WARNING: \" + numBadSegments + \" broken segments detected\");\n      if (doFix)\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents will be lost\");\n      else\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents would be lost if -fix were specified\");\n      out.println();\n    }\n\n    if (doFix) {\n      out.println(\"NOTE: will write new segments file in 5 seconds; this will remove \" + totLoseDocCount + \" docs from the index. THIS IS YOUR LAST CHANCE TO CTRL+C!\");\n      for(int i=0;i<5;i++) {\n        try {\n          Thread.sleep(1000);\n        } catch (InterruptedException ie) {\n          Thread.currentThread().interrupt();\n          i--;\n          continue;\n        }\n          \n        out.println(\"  \" + (5-i) + \"...\");\n      }\n      out.print(\"Writing...\");\n      try {\n        newSIS.write(dir);\n      } catch (Throwable t) {\n        out.println(\"FAILED; exiting\");\n        t.printStackTrace(out);\n        return false;\n      }\n      out.println(\"OK\");\n      out.println(\"Wrote new segments file \\\"\" + newSIS.getCurrentSegmentFileName() + \"\\\"\");\n    } else {\n      out.println(\"NOTE: would write new segments file [-fix was not specified]\");\n    }\n    out.println(\"\");\n\n    return false;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cba44a7c8f0e3eb449bcdbd53960b7705c0bf902","date":1220978058,"type":3,"author":"Grant Ingersoll","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean).mjava","pathOld":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean).mjava","sourceNew":"  /** Returns true if index is clean, else false.*/\n  public static CheckIndexStatus check(Directory dir, boolean doFix) throws IOException {\n    return check(dir, doFix, null);\n  }\n\n","sourceOld":"  /** Returns true if index is clean, else false.*/\n  public static boolean check(Directory dir, boolean doFix) throws IOException {\n    return check(dir, doFix, null);\n  }\n\n","bugFix":null,"bugIntro":["7391c1f4ab1a6817de8a262f5c1b3de3cf190785"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7391c1f4ab1a6817de8a262f5c1b3de3cf190785","date":1222335791,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean).mjava","pathOld":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean).mjava","sourceNew":"  /** Returns true if index is clean, else false. \n   *  @deprecated Please instantiate a CheckIndex and then use {@link #checkIndex()} instead */\n  public static boolean check(Directory dir, boolean doFix) throws IOException {\n    return check(dir, doFix, null);\n  }\n\n","sourceOld":"  /** Returns true if index is clean, else false.*/\n  public static CheckIndexStatus check(Directory dir, boolean doFix) throws IOException {\n    return check(dir, doFix, null);\n  }\n\n","bugFix":["5b38e3f2849cb8d8626cd5368aa64de4fed9edde","cba44a7c8f0e3eb449bcdbd53960b7705c0bf902"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"be2419774ad2eb3c65ca1cb035c3a2ccc6ae7da1","date":1255502337,"type":4,"author":"Michael Busch","isMerge":false,"pathNew":"/dev/null","pathOld":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean).mjava","sourceNew":null,"sourceOld":"  /** Returns true if index is clean, else false. \n   *  @deprecated Please instantiate a CheckIndex and then use {@link #checkIndex()} instead */\n  public static boolean check(Directory dir, boolean doFix) throws IOException {\n    return check(dir, doFix, null);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a64db7380e46c730a4ff0f00ebd7b29219312c14":["618f42b75ebb7827e10d9ce2b2df8b50ee73c27c"],"cba44a7c8f0e3eb449bcdbd53960b7705c0bf902":["a64db7380e46c730a4ff0f00ebd7b29219312c14"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"618f42b75ebb7827e10d9ce2b2df8b50ee73c27c":["5b38e3f2849cb8d8626cd5368aa64de4fed9edde"],"be2419774ad2eb3c65ca1cb035c3a2ccc6ae7da1":["7391c1f4ab1a6817de8a262f5c1b3de3cf190785"],"7391c1f4ab1a6817de8a262f5c1b3de3cf190785":["cba44a7c8f0e3eb449bcdbd53960b7705c0bf902"],"5b38e3f2849cb8d8626cd5368aa64de4fed9edde":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["be2419774ad2eb3c65ca1cb035c3a2ccc6ae7da1"]},"commit2Childs":{"a64db7380e46c730a4ff0f00ebd7b29219312c14":["cba44a7c8f0e3eb449bcdbd53960b7705c0bf902"],"cba44a7c8f0e3eb449bcdbd53960b7705c0bf902":["7391c1f4ab1a6817de8a262f5c1b3de3cf190785"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["5b38e3f2849cb8d8626cd5368aa64de4fed9edde"],"618f42b75ebb7827e10d9ce2b2df8b50ee73c27c":["a64db7380e46c730a4ff0f00ebd7b29219312c14"],"be2419774ad2eb3c65ca1cb035c3a2ccc6ae7da1":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"7391c1f4ab1a6817de8a262f5c1b3de3cf190785":["be2419774ad2eb3c65ca1cb035c3a2ccc6ae7da1"],"5b38e3f2849cb8d8626cd5368aa64de4fed9edde":["618f42b75ebb7827e10d9ce2b2df8b50ee73c27c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}