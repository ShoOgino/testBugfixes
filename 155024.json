{"path":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy#createOffsetsEnumsForAutomata(Terms,int,List[OffsetsEnum]).mjava","commits":[{"id":"eef54e3d232eae0e9fc18d75e9b0c3d9ce04b571","date":1515642580,"type":1,"author":"David Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy#createOffsetsEnumsForAutomata(Terms,int,List[OffsetsEnum]).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy#createAutomataOffsetsFromTerms(Terms,int).mjava","sourceNew":"  protected void createOffsetsEnumsForAutomata(Terms termsIndex, int doc, List<OffsetsEnum> results) throws IOException {\n    List<List<PostingsEnum>> automataPostings = new ArrayList<>(automata.length);\n    for (int i = 0; i < automata.length; i++) {\n      automataPostings.add(new ArrayList<>());\n    }\n\n    TermsEnum termsEnum = termsIndex.iterator();\n    BytesRef term;\n\n    CharsRefBuilder refBuilder = new CharsRefBuilder();\n    while ((term = termsEnum.next()) != null) {\n      for (int i = 0; i < automata.length; i++) {\n        CharacterRunAutomaton automaton = automata[i];\n        refBuilder.copyUTF8Bytes(term);\n        if (automaton.run(refBuilder.chars(), 0, refBuilder.length())) {\n          PostingsEnum postings = termsEnum.postings(null, PostingsEnum.OFFSETS);\n          if (doc == postings.advance(doc)) {\n            automataPostings.get(i).add(postings);\n          }\n        }\n      }\n    }\n\n    for (int i = 0; i < automata.length; i++) {\n      CharacterRunAutomaton automaton = automata[i];\n      List<PostingsEnum> postingsEnums = automataPostings.get(i);\n      int size = postingsEnums.size();\n      if (size > 0) { //only add if we have offsets\n        BytesRef wildcardTerm = new BytesRef(automaton.toString());\n        if (size == 1) { //don't wrap in a composite if there's only one OffsetsEnum\n          results.add(new OffsetsEnum.OfPostings(wildcardTerm, postingsEnums.get(0)));\n        } else {\n          results.add(new OffsetsEnum.OfPostings(wildcardTerm, new CompositeOffsetsPostingsEnum(postingsEnums)));\n        }\n      }\n    }\n\n  }\n\n","sourceOld":"  protected List<OffsetsEnum> createAutomataOffsetsFromTerms(Terms termsIndex, int doc) throws IOException {\n    List<List<PostingsEnum>> automataPostings = new ArrayList<>(automata.length);\n    for (int i = 0; i < automata.length; i++) {\n      automataPostings.add(new ArrayList<>());\n    }\n\n    TermsEnum termsEnum = termsIndex.iterator();\n    BytesRef term;\n    CharsRefBuilder refBuilder = new CharsRefBuilder();\n    while ((term = termsEnum.next()) != null) {\n      for (int i = 0; i < automata.length; i++) {\n        CharacterRunAutomaton automaton = automata[i];\n        refBuilder.copyUTF8Bytes(term);\n        if (automaton.run(refBuilder.chars(), 0, refBuilder.length())) {\n          PostingsEnum postings = termsEnum.postings(null, PostingsEnum.OFFSETS);\n          if (doc == postings.advance(doc)) {\n            automataPostings.get(i).add(postings);\n          }\n        }\n      }\n    }\n\n    List<OffsetsEnum> offsetsEnums = new ArrayList<>(automata.length); //will be at most this long\n    for (int i = 0; i < automata.length; i++) {\n      CharacterRunAutomaton automaton = automata[i];\n      List<PostingsEnum> postingsEnums = automataPostings.get(i);\n      int size = postingsEnums.size();\n      if (size > 0) { //only add if we have offsets\n        BytesRef wildcardTerm = new BytesRef(automaton.toString());\n        if (size == 1) { //don't wrap in a composite if there's only one OffsetsEnum\n          offsetsEnums.add(new OffsetsEnum(wildcardTerm, postingsEnums.get(0)));\n        } else {\n          offsetsEnums.add(new OffsetsEnum(wildcardTerm, new CompositeOffsetsPostingsEnum(postingsEnums)));\n        }\n      }\n    }\n\n    return offsetsEnums;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b94236357aaa22b76c10629851fe4e376e0cea82","date":1516710914,"type":0,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy#createOffsetsEnumsForAutomata(Terms,int,List[OffsetsEnum]).mjava","pathOld":"/dev/null","sourceNew":"  protected void createOffsetsEnumsForAutomata(Terms termsIndex, int doc, List<OffsetsEnum> results) throws IOException {\n    List<List<PostingsEnum>> automataPostings = new ArrayList<>(automata.length);\n    for (int i = 0; i < automata.length; i++) {\n      automataPostings.add(new ArrayList<>());\n    }\n\n    TermsEnum termsEnum = termsIndex.iterator();\n    BytesRef term;\n\n    CharsRefBuilder refBuilder = new CharsRefBuilder();\n    while ((term = termsEnum.next()) != null) {\n      for (int i = 0; i < automata.length; i++) {\n        CharacterRunAutomaton automaton = automata[i];\n        refBuilder.copyUTF8Bytes(term);\n        if (automaton.run(refBuilder.chars(), 0, refBuilder.length())) {\n          PostingsEnum postings = termsEnum.postings(null, PostingsEnum.OFFSETS);\n          if (doc == postings.advance(doc)) {\n            automataPostings.get(i).add(postings);\n          }\n        }\n      }\n    }\n\n    for (int i = 0; i < automata.length; i++) {\n      CharacterRunAutomaton automaton = automata[i];\n      List<PostingsEnum> postingsEnums = automataPostings.get(i);\n      int size = postingsEnums.size();\n      if (size > 0) { //only add if we have offsets\n        BytesRef wildcardTerm = new BytesRef(automaton.toString());\n        if (size == 1) { //don't wrap in a composite if there's only one OffsetsEnum\n          results.add(new OffsetsEnum.OfPostings(wildcardTerm, postingsEnums.get(0)));\n        } else {\n          results.add(new OffsetsEnum.OfPostings(wildcardTerm, new CompositeOffsetsPostingsEnum(postingsEnums)));\n        }\n      }\n    }\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8764ca7bb74ee716c839b9545a93ec4a578c2005","date":1517564468,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy#createOffsetsEnumsForAutomata(Terms,int,List[OffsetsEnum]).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy#createOffsetsEnumsForAutomata(Terms,int,List[OffsetsEnum]).mjava","sourceNew":"  protected void createOffsetsEnumsForAutomata(Terms termsIndex, int doc, List<OffsetsEnum> results) throws IOException {\n    List<List<PostingsEnum>> automataPostings = new ArrayList<>(automata.length);\n    for (int i = 0; i < automata.length; i++) {\n      automataPostings.add(new ArrayList<>());\n    }\n\n    TermsEnum termsEnum = termsIndex.iterator();\n    BytesRef term;\n\n    CharsRefBuilder refBuilder = new CharsRefBuilder();\n    while ((term = termsEnum.next()) != null) {\n      for (int i = 0; i < automata.length; i++) {\n        CharacterRunAutomaton automaton = automata[i];\n        refBuilder.copyUTF8Bytes(term);\n        if (automaton.run(refBuilder.chars(), 0, refBuilder.length())) {\n          PostingsEnum postings = termsEnum.postings(null, PostingsEnum.OFFSETS);\n          if (doc == postings.advance(doc)) {\n            automataPostings.get(i).add(postings);\n          }\n        }\n      }\n    }\n\n    for (int i = 0; i < automata.length; i++) {\n      CharacterRunAutomaton automaton = automata[i];\n      List<PostingsEnum> postingsEnums = automataPostings.get(i);\n      if (postingsEnums.isEmpty()) {\n        continue;\n      }\n      // Build one OffsetsEnum exposing the automata.toString as the term, and the sum of freq\n      BytesRef wildcardTerm = new BytesRef(automaton.toString());\n      int sumFreq = 0;\n      for (PostingsEnum postingsEnum : postingsEnums) {\n        sumFreq += postingsEnum.freq();\n      }\n      for (PostingsEnum postingsEnum : postingsEnums) {\n        results.add(new OffsetsEnum.OfPostings(wildcardTerm, sumFreq, postingsEnum));\n      }\n    }\n\n  }\n\n","sourceOld":"  protected void createOffsetsEnumsForAutomata(Terms termsIndex, int doc, List<OffsetsEnum> results) throws IOException {\n    List<List<PostingsEnum>> automataPostings = new ArrayList<>(automata.length);\n    for (int i = 0; i < automata.length; i++) {\n      automataPostings.add(new ArrayList<>());\n    }\n\n    TermsEnum termsEnum = termsIndex.iterator();\n    BytesRef term;\n\n    CharsRefBuilder refBuilder = new CharsRefBuilder();\n    while ((term = termsEnum.next()) != null) {\n      for (int i = 0; i < automata.length; i++) {\n        CharacterRunAutomaton automaton = automata[i];\n        refBuilder.copyUTF8Bytes(term);\n        if (automaton.run(refBuilder.chars(), 0, refBuilder.length())) {\n          PostingsEnum postings = termsEnum.postings(null, PostingsEnum.OFFSETS);\n          if (doc == postings.advance(doc)) {\n            automataPostings.get(i).add(postings);\n          }\n        }\n      }\n    }\n\n    for (int i = 0; i < automata.length; i++) {\n      CharacterRunAutomaton automaton = automata[i];\n      List<PostingsEnum> postingsEnums = automataPostings.get(i);\n      int size = postingsEnums.size();\n      if (size > 0) { //only add if we have offsets\n        BytesRef wildcardTerm = new BytesRef(automaton.toString());\n        if (size == 1) { //don't wrap in a composite if there's only one OffsetsEnum\n          results.add(new OffsetsEnum.OfPostings(wildcardTerm, postingsEnums.get(0)));\n        } else {\n          results.add(new OffsetsEnum.OfPostings(wildcardTerm, new CompositeOffsetsPostingsEnum(postingsEnums)));\n        }\n      }\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"795822cce6616d4035b5a4bdbb6c113ea2f715ba","date":1535599765,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy#createOffsetsEnumsForAutomata(Terms,int,List[OffsetsEnum]).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy#createOffsetsEnumsForAutomata(Terms,int,List[OffsetsEnum]).mjava","sourceNew":"  protected void createOffsetsEnumsForAutomata(Terms termsIndex, int doc, List<OffsetsEnum> results) throws IOException {\n    final CharacterRunAutomaton[] automata = components.getAutomata();\n    List<List<PostingsEnum>> automataPostings = new ArrayList<>(automata.length);\n    for (int i = 0; i < automata.length; i++) {\n      automataPostings.add(new ArrayList<>());\n    }\n\n    TermsEnum termsEnum = termsIndex.iterator();\n    BytesRef term;\n\n    CharsRefBuilder refBuilder = new CharsRefBuilder();\n    while ((term = termsEnum.next()) != null) {\n      for (int i = 0; i < automata.length; i++) {\n        CharacterRunAutomaton automaton = automata[i];\n        refBuilder.copyUTF8Bytes(term);\n        if (automaton.run(refBuilder.chars(), 0, refBuilder.length())) {\n          PostingsEnum postings = termsEnum.postings(null, PostingsEnum.OFFSETS);\n          if (doc == postings.advance(doc)) {\n            automataPostings.get(i).add(postings);\n          }\n        }\n      }\n    }\n\n    for (int i = 0; i < automata.length; i++) {\n      CharacterRunAutomaton automaton = automata[i];\n      List<PostingsEnum> postingsEnums = automataPostings.get(i);\n      if (postingsEnums.isEmpty()) {\n        continue;\n      }\n      // Build one OffsetsEnum exposing the automata.toString as the term, and the sum of freq\n      BytesRef wildcardTerm = new BytesRef(automaton.toString());\n      int sumFreq = 0;\n      for (PostingsEnum postingsEnum : postingsEnums) {\n        sumFreq += postingsEnum.freq();\n      }\n      for (PostingsEnum postingsEnum : postingsEnums) {\n        results.add(new OffsetsEnum.OfPostings(wildcardTerm, sumFreq, postingsEnum));\n      }\n    }\n\n  }\n\n","sourceOld":"  protected void createOffsetsEnumsForAutomata(Terms termsIndex, int doc, List<OffsetsEnum> results) throws IOException {\n    List<List<PostingsEnum>> automataPostings = new ArrayList<>(automata.length);\n    for (int i = 0; i < automata.length; i++) {\n      automataPostings.add(new ArrayList<>());\n    }\n\n    TermsEnum termsEnum = termsIndex.iterator();\n    BytesRef term;\n\n    CharsRefBuilder refBuilder = new CharsRefBuilder();\n    while ((term = termsEnum.next()) != null) {\n      for (int i = 0; i < automata.length; i++) {\n        CharacterRunAutomaton automaton = automata[i];\n        refBuilder.copyUTF8Bytes(term);\n        if (automaton.run(refBuilder.chars(), 0, refBuilder.length())) {\n          PostingsEnum postings = termsEnum.postings(null, PostingsEnum.OFFSETS);\n          if (doc == postings.advance(doc)) {\n            automataPostings.get(i).add(postings);\n          }\n        }\n      }\n    }\n\n    for (int i = 0; i < automata.length; i++) {\n      CharacterRunAutomaton automaton = automata[i];\n      List<PostingsEnum> postingsEnums = automataPostings.get(i);\n      if (postingsEnums.isEmpty()) {\n        continue;\n      }\n      // Build one OffsetsEnum exposing the automata.toString as the term, and the sum of freq\n      BytesRef wildcardTerm = new BytesRef(automaton.toString());\n      int sumFreq = 0;\n      for (PostingsEnum postingsEnum : postingsEnums) {\n        sumFreq += postingsEnum.freq();\n      }\n      for (PostingsEnum postingsEnum : postingsEnums) {\n        results.add(new OffsetsEnum.OfPostings(wildcardTerm, sumFreq, postingsEnum));\n      }\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d35c63123a7e255b58f8cf3948eb9a6128100a32","date":1574872099,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy#createOffsetsEnumsForAutomata(Terms,int,List[OffsetsEnum]).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy#createOffsetsEnumsForAutomata(Terms,int,List[OffsetsEnum]).mjava","sourceNew":"  protected void createOffsetsEnumsForAutomata(Terms termsIndex, int doc, List<OffsetsEnum> results) throws IOException {\n    final LabelledCharArrayMatcher[] automata = components.getAutomata();\n    List<List<PostingsEnum>> automataPostings = new ArrayList<>(automata.length);\n    for (int i = 0; i < automata.length; i++) {\n      automataPostings.add(new ArrayList<>());\n    }\n\n    TermsEnum termsEnum = termsIndex.iterator();\n    BytesRef term;\n\n    CharsRefBuilder refBuilder = new CharsRefBuilder();\n    while ((term = termsEnum.next()) != null) {\n      for (int i = 0; i < automata.length; i++) {\n        CharArrayMatcher automaton = automata[i];\n        refBuilder.copyUTF8Bytes(term);\n        if (automaton.match(refBuilder.get())) {\n          PostingsEnum postings = termsEnum.postings(null, PostingsEnum.OFFSETS);\n          if (doc == postings.advance(doc)) {\n            automataPostings.get(i).add(postings);\n          }\n        }\n      }\n    }\n\n    for (int i = 0; i < automata.length; i++) {\n      LabelledCharArrayMatcher automaton = automata[i];\n      List<PostingsEnum> postingsEnums = automataPostings.get(i);\n      if (postingsEnums.isEmpty()) {\n        continue;\n      }\n      // Build one OffsetsEnum exposing the automaton label as the term, and the sum of freq\n      BytesRef wildcardTerm = new BytesRef(automaton.getLabel());\n      int sumFreq = 0;\n      for (PostingsEnum postingsEnum : postingsEnums) {\n        sumFreq += postingsEnum.freq();\n      }\n      for (PostingsEnum postingsEnum : postingsEnums) {\n        results.add(new OffsetsEnum.OfPostings(wildcardTerm, sumFreq, postingsEnum));\n      }\n    }\n\n  }\n\n","sourceOld":"  protected void createOffsetsEnumsForAutomata(Terms termsIndex, int doc, List<OffsetsEnum> results) throws IOException {\n    final CharacterRunAutomaton[] automata = components.getAutomata();\n    List<List<PostingsEnum>> automataPostings = new ArrayList<>(automata.length);\n    for (int i = 0; i < automata.length; i++) {\n      automataPostings.add(new ArrayList<>());\n    }\n\n    TermsEnum termsEnum = termsIndex.iterator();\n    BytesRef term;\n\n    CharsRefBuilder refBuilder = new CharsRefBuilder();\n    while ((term = termsEnum.next()) != null) {\n      for (int i = 0; i < automata.length; i++) {\n        CharacterRunAutomaton automaton = automata[i];\n        refBuilder.copyUTF8Bytes(term);\n        if (automaton.run(refBuilder.chars(), 0, refBuilder.length())) {\n          PostingsEnum postings = termsEnum.postings(null, PostingsEnum.OFFSETS);\n          if (doc == postings.advance(doc)) {\n            automataPostings.get(i).add(postings);\n          }\n        }\n      }\n    }\n\n    for (int i = 0; i < automata.length; i++) {\n      CharacterRunAutomaton automaton = automata[i];\n      List<PostingsEnum> postingsEnums = automataPostings.get(i);\n      if (postingsEnums.isEmpty()) {\n        continue;\n      }\n      // Build one OffsetsEnum exposing the automata.toString as the term, and the sum of freq\n      BytesRef wildcardTerm = new BytesRef(automaton.toString());\n      int sumFreq = 0;\n      for (PostingsEnum postingsEnum : postingsEnums) {\n        sumFreq += postingsEnum.freq();\n      }\n      for (PostingsEnum postingsEnum : postingsEnums) {\n        results.add(new OffsetsEnum.OfPostings(wildcardTerm, sumFreq, postingsEnum));\n      }\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b94236357aaa22b76c10629851fe4e376e0cea82":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","eef54e3d232eae0e9fc18d75e9b0c3d9ce04b571"],"8764ca7bb74ee716c839b9545a93ec4a578c2005":["b94236357aaa22b76c10629851fe4e376e0cea82"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"eef54e3d232eae0e9fc18d75e9b0c3d9ce04b571":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"d35c63123a7e255b58f8cf3948eb9a6128100a32":["795822cce6616d4035b5a4bdbb6c113ea2f715ba"],"795822cce6616d4035b5a4bdbb6c113ea2f715ba":["8764ca7bb74ee716c839b9545a93ec4a578c2005"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d35c63123a7e255b58f8cf3948eb9a6128100a32"]},"commit2Childs":{"b94236357aaa22b76c10629851fe4e376e0cea82":["8764ca7bb74ee716c839b9545a93ec4a578c2005"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b94236357aaa22b76c10629851fe4e376e0cea82","eef54e3d232eae0e9fc18d75e9b0c3d9ce04b571"],"8764ca7bb74ee716c839b9545a93ec4a578c2005":["795822cce6616d4035b5a4bdbb6c113ea2f715ba"],"eef54e3d232eae0e9fc18d75e9b0c3d9ce04b571":["b94236357aaa22b76c10629851fe4e376e0cea82"],"d35c63123a7e255b58f8cf3948eb9a6128100a32":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"795822cce6616d4035b5a4bdbb6c113ea2f715ba":["d35c63123a7e255b58f8cf3948eb9a6128100a32"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}