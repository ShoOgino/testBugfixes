{"path":"lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates#apply(IndexWriter).mjava","commits":[{"id":"f4363cd33f6eff7fb4753574a441e2d18c1022a4","date":1498067235,"type":0,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates#apply(IndexWriter).mjava","pathOld":"/dev/null","sourceNew":"  /** Translates a frozen packet of delete term/query, or doc values\n   *  updates, into their actual docIDs in the index, and applies the change.  This is a heavy\n   *  operation and is done concurrently by incoming indexing threads. */\n\n  public synchronized void apply(IndexWriter writer) throws IOException {\n    if (applied.getCount() == 0) {\n      // already done\n      return;\n    }\n\n    long startNS = System.nanoTime();\n\n    assert any();\n\n    Set<SegmentCommitInfo> seenSegments = new HashSet<>();\n\n    int iter = 0;\n    int totalSegmentCount = 0;\n    long totalDelCount = 0;\n\n    // Optimistic concurrency: assume we are free to resolve the deletes against all current segments in the index, despite that\n    // concurrent merges are running.  Once we are done, we check to see if a merge completed while we were running.  If so, we must retry\n    // resolving against the newly merged segment(s).  Eventually no merge finishes while we were running and we are done.\n    while (true) {\n      String messagePrefix;\n      if (iter == 0) {\n        messagePrefix = \"\";\n      } else {\n        messagePrefix = \"iter \" + iter;\n      }\n\n      long iterStartNS = System.nanoTime();\n\n      long mergeGenStart = writer.mergeFinishedGen.get();\n\n      Set<String> delFiles = new HashSet<>();\n      BufferedUpdatesStream.SegmentState[] segStates;\n\n      synchronized (writer) {\n        List<SegmentCommitInfo> infos = getInfosToApply(writer);\n        if (infos == null) {\n          break;\n        }\n\n        for (SegmentCommitInfo info : infos) {\n          delFiles.addAll(info.files());\n        }\n\n        // Must open while holding IW lock so that e.g. segments are not merged\n        // away, dropped from 100% deletions, etc., before we can open the readers\n        segStates = writer.bufferedUpdatesStream.openSegmentStates(writer.readerPool, infos, seenSegments, delGen());\n\n        if (segStates.length == 0) {\n\n          if (infoStream.isEnabled(\"BD\")) {\n            infoStream.message(\"BD\", \"packet matches no segments\");\n          }\n          \n          break;\n        }\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                                 messagePrefix + \"now apply del packet (%s) to %d segments, mergeGen %d\",\n                                                 this, segStates.length, mergeGenStart));\n        }\n\n        totalSegmentCount += segStates.length;\n\n        // Important, else IFD may try to delete our files while we are still using them,\n        // if e.g. a merge finishes on some of the segments we are resolving on:\n        writer.deleter.incRef(delFiles);\n      }\n\n      boolean success = false;\n      long delCount;\n      try {\n        // don't hold IW monitor lock here so threads are free concurrently resolve deletes/updates:\n        delCount = apply(segStates);\n        success = true;\n      } finally {\n        finishApply(writer, segStates, success, delFiles);\n      }\n\n      // Since we jus resolved some more deletes/updates, now is a good time to write them:\n      writer.readerPool.writeSomeDocValuesUpdates();\n\n      // It's OK to add this here, even if the while loop retries, because delCount only includes newly\n      // deleted documents, on the segments we didn't already do in previous iterations:\n      totalDelCount += delCount;\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                               messagePrefix + \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                               this, segStates.length, delCount, (System.nanoTime() - iterStartNS) / 1000000000.));\n      }\n      \n      if (privateSegment != null) {\n        // No need to retry for a segment-private packet: the merge that folds in our private segment already waits for all deletes to\n        // be applied before it kicks off, so this private segment must already not be in the set of merging segments\n\n        break;\n      }\n\n      // Must sync on writer here so that IW.mergeCommit is not running concurrently, so that if we exit, we know mergeCommit will succeed\n      // in pulling all our delGens into a merge:\n      synchronized (writer) {\n        long mergeGenCur = writer.mergeFinishedGen.get();\n\n        if (mergeGenCur == mergeGenStart) {\n\n          // No merge finished while we were applying, so we are done!\n          break;\n        }\n      }\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", messagePrefix + \"concurrent merges finished; move to next iter\");\n      }\n        \n      // A merge completed while we were running.  In this case, that merge may have picked up some of the updates we did, but not\n      // necessarily all of them, so we cycle again, re-applying all our updates to the newly merged segment.\n\n      iter++;\n    }\n\n    // Record that this packet is finished:\n    writer.bufferedUpdatesStream.finished(this);\n\n    if (infoStream.isEnabled(\"BD\")) {\n      String message = String.format(Locale.ROOT,\n                                     \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                     this, totalSegmentCount, totalDelCount, (System.nanoTime() - startNS) / 1000000000.);\n      if (iter > 0) {\n        message += \"; \" + (iter+1) + \" iters due to concurrent merges\";\n      }\n      message += \"; \" + writer.bufferedUpdatesStream.getPendingUpdatesCount() + \" packets remain\";\n      infoStream.message(\"BD\", message);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["636c73dfa97dd282a3089d4239620475f2633519","15e716649e2bd79a98b5e68c464154ea4c44677a","b4a1e501646d5889b8128849329c2e6e52fc3615"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b7dfa64bc2074fb87d0ca70095a644c1ead107e1","date":1498356339,"type":0,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates#apply(IndexWriter).mjava","pathOld":"/dev/null","sourceNew":"  /** Translates a frozen packet of delete term/query, or doc values\n   *  updates, into their actual docIDs in the index, and applies the change.  This is a heavy\n   *  operation and is done concurrently by incoming indexing threads. */\n\n  public synchronized void apply(IndexWriter writer) throws IOException {\n    if (applied.getCount() == 0) {\n      // already done\n      return;\n    }\n\n    long startNS = System.nanoTime();\n\n    assert any();\n\n    Set<SegmentCommitInfo> seenSegments = new HashSet<>();\n\n    int iter = 0;\n    int totalSegmentCount = 0;\n    long totalDelCount = 0;\n\n    // Optimistic concurrency: assume we are free to resolve the deletes against all current segments in the index, despite that\n    // concurrent merges are running.  Once we are done, we check to see if a merge completed while we were running.  If so, we must retry\n    // resolving against the newly merged segment(s).  Eventually no merge finishes while we were running and we are done.\n    while (true) {\n      String messagePrefix;\n      if (iter == 0) {\n        messagePrefix = \"\";\n      } else {\n        messagePrefix = \"iter \" + iter;\n      }\n\n      long iterStartNS = System.nanoTime();\n\n      long mergeGenStart = writer.mergeFinishedGen.get();\n\n      Set<String> delFiles = new HashSet<>();\n      BufferedUpdatesStream.SegmentState[] segStates;\n\n      synchronized (writer) {\n        List<SegmentCommitInfo> infos = getInfosToApply(writer);\n        if (infos == null) {\n          break;\n        }\n\n        for (SegmentCommitInfo info : infos) {\n          delFiles.addAll(info.files());\n        }\n\n        // Must open while holding IW lock so that e.g. segments are not merged\n        // away, dropped from 100% deletions, etc., before we can open the readers\n        segStates = writer.bufferedUpdatesStream.openSegmentStates(writer.readerPool, infos, seenSegments, delGen());\n\n        if (segStates.length == 0) {\n\n          if (infoStream.isEnabled(\"BD\")) {\n            infoStream.message(\"BD\", \"packet matches no segments\");\n          }\n          \n          break;\n        }\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                                 messagePrefix + \"now apply del packet (%s) to %d segments, mergeGen %d\",\n                                                 this, segStates.length, mergeGenStart));\n        }\n\n        totalSegmentCount += segStates.length;\n\n        // Important, else IFD may try to delete our files while we are still using them,\n        // if e.g. a merge finishes on some of the segments we are resolving on:\n        writer.deleter.incRef(delFiles);\n      }\n\n      boolean success = false;\n      long delCount;\n      try {\n        // don't hold IW monitor lock here so threads are free concurrently resolve deletes/updates:\n        delCount = apply(segStates);\n        success = true;\n      } finally {\n        finishApply(writer, segStates, success, delFiles);\n      }\n\n      // Since we jus resolved some more deletes/updates, now is a good time to write them:\n      writer.readerPool.writeSomeDocValuesUpdates();\n\n      // It's OK to add this here, even if the while loop retries, because delCount only includes newly\n      // deleted documents, on the segments we didn't already do in previous iterations:\n      totalDelCount += delCount;\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                               messagePrefix + \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                               this, segStates.length, delCount, (System.nanoTime() - iterStartNS) / 1000000000.));\n      }\n      \n      if (privateSegment != null) {\n        // No need to retry for a segment-private packet: the merge that folds in our private segment already waits for all deletes to\n        // be applied before it kicks off, so this private segment must already not be in the set of merging segments\n\n        break;\n      }\n\n      // Must sync on writer here so that IW.mergeCommit is not running concurrently, so that if we exit, we know mergeCommit will succeed\n      // in pulling all our delGens into a merge:\n      synchronized (writer) {\n        long mergeGenCur = writer.mergeFinishedGen.get();\n\n        if (mergeGenCur == mergeGenStart) {\n\n          // No merge finished while we were applying, so we are done!\n          break;\n        }\n      }\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", messagePrefix + \"concurrent merges finished; move to next iter\");\n      }\n        \n      // A merge completed while we were running.  In this case, that merge may have picked up some of the updates we did, but not\n      // necessarily all of them, so we cycle again, re-applying all our updates to the newly merged segment.\n\n      iter++;\n    }\n\n    // Record that this packet is finished:\n    writer.bufferedUpdatesStream.finished(this);\n\n    if (infoStream.isEnabled(\"BD\")) {\n      String message = String.format(Locale.ROOT,\n                                     \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                     this, totalSegmentCount, totalDelCount, (System.nanoTime() - startNS) / 1000000000.);\n      if (iter > 0) {\n        message += \"; \" + (iter+1) + \" iters due to concurrent merges\";\n      }\n      message += \"; \" + writer.bufferedUpdatesStream.getPendingUpdatesCount() + \" packets remain\";\n      infoStream.message(\"BD\", message);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":0,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates#apply(IndexWriter).mjava","pathOld":"/dev/null","sourceNew":"  /** Translates a frozen packet of delete term/query, or doc values\n   *  updates, into their actual docIDs in the index, and applies the change.  This is a heavy\n   *  operation and is done concurrently by incoming indexing threads. */\n\n  public synchronized void apply(IndexWriter writer) throws IOException {\n    if (applied.getCount() == 0) {\n      // already done\n      return;\n    }\n\n    long startNS = System.nanoTime();\n\n    assert any();\n\n    Set<SegmentCommitInfo> seenSegments = new HashSet<>();\n\n    int iter = 0;\n    int totalSegmentCount = 0;\n    long totalDelCount = 0;\n\n    // Optimistic concurrency: assume we are free to resolve the deletes against all current segments in the index, despite that\n    // concurrent merges are running.  Once we are done, we check to see if a merge completed while we were running.  If so, we must retry\n    // resolving against the newly merged segment(s).  Eventually no merge finishes while we were running and we are done.\n    while (true) {\n      String messagePrefix;\n      if (iter == 0) {\n        messagePrefix = \"\";\n      } else {\n        messagePrefix = \"iter \" + iter;\n      }\n\n      long iterStartNS = System.nanoTime();\n\n      long mergeGenStart = writer.mergeFinishedGen.get();\n\n      Set<String> delFiles = new HashSet<>();\n      BufferedUpdatesStream.SegmentState[] segStates;\n\n      synchronized (writer) {\n        List<SegmentCommitInfo> infos = getInfosToApply(writer);\n        if (infos == null) {\n          break;\n        }\n\n        for (SegmentCommitInfo info : infos) {\n          delFiles.addAll(info.files());\n        }\n\n        // Must open while holding IW lock so that e.g. segments are not merged\n        // away, dropped from 100% deletions, etc., before we can open the readers\n        segStates = writer.bufferedUpdatesStream.openSegmentStates(writer.readerPool, infos, seenSegments, delGen());\n\n        if (segStates.length == 0) {\n\n          if (infoStream.isEnabled(\"BD\")) {\n            infoStream.message(\"BD\", \"packet matches no segments\");\n          }\n          \n          break;\n        }\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                                 messagePrefix + \"now apply del packet (%s) to %d segments, mergeGen %d\",\n                                                 this, segStates.length, mergeGenStart));\n        }\n\n        totalSegmentCount += segStates.length;\n\n        // Important, else IFD may try to delete our files while we are still using them,\n        // if e.g. a merge finishes on some of the segments we are resolving on:\n        writer.deleter.incRef(delFiles);\n      }\n\n      boolean success = false;\n      long delCount;\n      try {\n        // don't hold IW monitor lock here so threads are free concurrently resolve deletes/updates:\n        delCount = apply(segStates);\n        success = true;\n      } finally {\n        finishApply(writer, segStates, success, delFiles);\n      }\n\n      // Since we jus resolved some more deletes/updates, now is a good time to write them:\n      writer.readerPool.writeSomeDocValuesUpdates();\n\n      // It's OK to add this here, even if the while loop retries, because delCount only includes newly\n      // deleted documents, on the segments we didn't already do in previous iterations:\n      totalDelCount += delCount;\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                               messagePrefix + \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                               this, segStates.length, delCount, (System.nanoTime() - iterStartNS) / 1000000000.));\n      }\n      \n      if (privateSegment != null) {\n        // No need to retry for a segment-private packet: the merge that folds in our private segment already waits for all deletes to\n        // be applied before it kicks off, so this private segment must already not be in the set of merging segments\n\n        break;\n      }\n\n      // Must sync on writer here so that IW.mergeCommit is not running concurrently, so that if we exit, we know mergeCommit will succeed\n      // in pulling all our delGens into a merge:\n      synchronized (writer) {\n        long mergeGenCur = writer.mergeFinishedGen.get();\n\n        if (mergeGenCur == mergeGenStart) {\n\n          // No merge finished while we were applying, so we are done!\n          break;\n        }\n      }\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", messagePrefix + \"concurrent merges finished; move to next iter\");\n      }\n        \n      // A merge completed while we were running.  In this case, that merge may have picked up some of the updates we did, but not\n      // necessarily all of them, so we cycle again, re-applying all our updates to the newly merged segment.\n\n      iter++;\n    }\n\n    // Record that this packet is finished:\n    writer.bufferedUpdatesStream.finished(this);\n\n    if (infoStream.isEnabled(\"BD\")) {\n      String message = String.format(Locale.ROOT,\n                                     \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                     this, totalSegmentCount, totalDelCount, (System.nanoTime() - startNS) / 1000000000.);\n      if (iter > 0) {\n        message += \"; \" + (iter+1) + \" iters due to concurrent merges\";\n      }\n      message += \"; \" + writer.bufferedUpdatesStream.getPendingUpdatesCount() + \" packets remain\";\n      infoStream.message(\"BD\", message);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b4a1e501646d5889b8128849329c2e6e52fc3615","date":1498729990,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates#apply(IndexWriter).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates#apply(IndexWriter).mjava","sourceNew":"  /** Translates a frozen packet of delete term/query, or doc values\n   *  updates, into their actual docIDs in the index, and applies the change.  This is a heavy\n   *  operation and is done concurrently by incoming indexing threads. */\n\n  public synchronized void apply(IndexWriter writer) throws IOException {\n    if (applied.getCount() == 0) {\n      // already done\n      return;\n    }\n\n    long startNS = System.nanoTime();\n\n    assert any();\n\n    Set<SegmentCommitInfo> seenSegments = new HashSet<>();\n\n    int iter = 0;\n    int totalSegmentCount = 0;\n    long totalDelCount = 0;\n\n    // Optimistic concurrency: assume we are free to resolve the deletes against all current segments in the index, despite that\n    // concurrent merges are running.  Once we are done, we check to see if a merge completed while we were running.  If so, we must retry\n    // resolving against the newly merged segment(s).  Eventually no merge finishes while we were running and we are done.\n    while (true) {\n      String messagePrefix;\n      if (iter == 0) {\n        messagePrefix = \"\";\n      } else {\n        messagePrefix = \"iter \" + iter;\n      }\n\n      long iterStartNS = System.nanoTime();\n\n      long mergeGenStart = writer.mergeFinishedGen.get();\n\n      Set<String> delFiles = new HashSet<>();\n      BufferedUpdatesStream.SegmentState[] segStates;\n\n      synchronized (writer) {\n        List<SegmentCommitInfo> infos = getInfosToApply(writer);\n        if (infos == null) {\n          break;\n        }\n\n        for (SegmentCommitInfo info : infos) {\n          delFiles.addAll(info.files());\n        }\n\n        // Must open while holding IW lock so that e.g. segments are not merged\n        // away, dropped from 100% deletions, etc., before we can open the readers\n        segStates = writer.bufferedUpdatesStream.openSegmentStates(writer.readerPool, infos, seenSegments, delGen());\n\n        if (segStates.length == 0) {\n\n          if (infoStream.isEnabled(\"BD\")) {\n            infoStream.message(\"BD\", \"packet matches no segments\");\n          }\n          break;\n        }\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                                 messagePrefix + \"now apply del packet (%s) to %d segments, mergeGen %d\",\n                                                 this, segStates.length, mergeGenStart));\n        }\n\n        totalSegmentCount += segStates.length;\n\n        // Important, else IFD may try to delete our files while we are still using them,\n        // if e.g. a merge finishes on some of the segments we are resolving on:\n        writer.deleter.incRef(delFiles);\n      }\n\n      boolean success = false;\n      long delCount;\n      try {\n        // don't hold IW monitor lock here so threads are free concurrently resolve deletes/updates:\n        delCount = apply(segStates);\n        success = true;\n      } finally {\n        finishApply(writer, segStates, success, delFiles);\n      }\n\n      // Since we jus resolved some more deletes/updates, now is a good time to write them:\n      writer.readerPool.writeSomeDocValuesUpdates();\n\n      // It's OK to add this here, even if the while loop retries, because delCount only includes newly\n      // deleted documents, on the segments we didn't already do in previous iterations:\n      totalDelCount += delCount;\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                               messagePrefix + \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                               this, segStates.length, delCount, (System.nanoTime() - iterStartNS) / 1000000000.));\n      }\n      \n      if (privateSegment != null) {\n        // No need to retry for a segment-private packet: the merge that folds in our private segment already waits for all deletes to\n        // be applied before it kicks off, so this private segment must already not be in the set of merging segments\n\n        break;\n      }\n\n      // Must sync on writer here so that IW.mergeCommit is not running concurrently, so that if we exit, we know mergeCommit will succeed\n      // in pulling all our delGens into a merge:\n      synchronized (writer) {\n        long mergeGenCur = writer.mergeFinishedGen.get();\n\n        if (mergeGenCur == mergeGenStart) {\n\n          // No merge finished while we were applying, so we are done!\n          break;\n        }\n      }\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", messagePrefix + \"concurrent merges finished; move to next iter\");\n      }\n        \n      // A merge completed while we were running.  In this case, that merge may have picked up some of the updates we did, but not\n      // necessarily all of them, so we cycle again, re-applying all our updates to the newly merged segment.\n\n      iter++;\n    }\n\n    // Record that this packet is finished:\n    writer.bufferedUpdatesStream.finished(this);\n\n    if (infoStream.isEnabled(\"BD\")) {\n      String message = String.format(Locale.ROOT,\n                                     \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                     this, totalSegmentCount, totalDelCount, (System.nanoTime() - startNS) / 1000000000.);\n      if (iter > 0) {\n        message += \"; \" + (iter+1) + \" iters due to concurrent merges\";\n      }\n      message += \"; \" + writer.bufferedUpdatesStream.getPendingUpdatesCount() + \" packets remain\";\n      infoStream.message(\"BD\", message);\n    }\n  }\n\n","sourceOld":"  /** Translates a frozen packet of delete term/query, or doc values\n   *  updates, into their actual docIDs in the index, and applies the change.  This is a heavy\n   *  operation and is done concurrently by incoming indexing threads. */\n\n  public synchronized void apply(IndexWriter writer) throws IOException {\n    if (applied.getCount() == 0) {\n      // already done\n      return;\n    }\n\n    long startNS = System.nanoTime();\n\n    assert any();\n\n    Set<SegmentCommitInfo> seenSegments = new HashSet<>();\n\n    int iter = 0;\n    int totalSegmentCount = 0;\n    long totalDelCount = 0;\n\n    // Optimistic concurrency: assume we are free to resolve the deletes against all current segments in the index, despite that\n    // concurrent merges are running.  Once we are done, we check to see if a merge completed while we were running.  If so, we must retry\n    // resolving against the newly merged segment(s).  Eventually no merge finishes while we were running and we are done.\n    while (true) {\n      String messagePrefix;\n      if (iter == 0) {\n        messagePrefix = \"\";\n      } else {\n        messagePrefix = \"iter \" + iter;\n      }\n\n      long iterStartNS = System.nanoTime();\n\n      long mergeGenStart = writer.mergeFinishedGen.get();\n\n      Set<String> delFiles = new HashSet<>();\n      BufferedUpdatesStream.SegmentState[] segStates;\n\n      synchronized (writer) {\n        List<SegmentCommitInfo> infos = getInfosToApply(writer);\n        if (infos == null) {\n          break;\n        }\n\n        for (SegmentCommitInfo info : infos) {\n          delFiles.addAll(info.files());\n        }\n\n        // Must open while holding IW lock so that e.g. segments are not merged\n        // away, dropped from 100% deletions, etc., before we can open the readers\n        segStates = writer.bufferedUpdatesStream.openSegmentStates(writer.readerPool, infos, seenSegments, delGen());\n\n        if (segStates.length == 0) {\n\n          if (infoStream.isEnabled(\"BD\")) {\n            infoStream.message(\"BD\", \"packet matches no segments\");\n          }\n          \n          break;\n        }\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                                 messagePrefix + \"now apply del packet (%s) to %d segments, mergeGen %d\",\n                                                 this, segStates.length, mergeGenStart));\n        }\n\n        totalSegmentCount += segStates.length;\n\n        // Important, else IFD may try to delete our files while we are still using them,\n        // if e.g. a merge finishes on some of the segments we are resolving on:\n        writer.deleter.incRef(delFiles);\n      }\n\n      boolean success = false;\n      long delCount;\n      try {\n        // don't hold IW monitor lock here so threads are free concurrently resolve deletes/updates:\n        delCount = apply(segStates);\n        success = true;\n      } finally {\n        finishApply(writer, segStates, success, delFiles);\n      }\n\n      // Since we jus resolved some more deletes/updates, now is a good time to write them:\n      writer.readerPool.writeSomeDocValuesUpdates();\n\n      // It's OK to add this here, even if the while loop retries, because delCount only includes newly\n      // deleted documents, on the segments we didn't already do in previous iterations:\n      totalDelCount += delCount;\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                               messagePrefix + \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                               this, segStates.length, delCount, (System.nanoTime() - iterStartNS) / 1000000000.));\n      }\n      \n      if (privateSegment != null) {\n        // No need to retry for a segment-private packet: the merge that folds in our private segment already waits for all deletes to\n        // be applied before it kicks off, so this private segment must already not be in the set of merging segments\n\n        break;\n      }\n\n      // Must sync on writer here so that IW.mergeCommit is not running concurrently, so that if we exit, we know mergeCommit will succeed\n      // in pulling all our delGens into a merge:\n      synchronized (writer) {\n        long mergeGenCur = writer.mergeFinishedGen.get();\n\n        if (mergeGenCur == mergeGenStart) {\n\n          // No merge finished while we were applying, so we are done!\n          break;\n        }\n      }\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", messagePrefix + \"concurrent merges finished; move to next iter\");\n      }\n        \n      // A merge completed while we were running.  In this case, that merge may have picked up some of the updates we did, but not\n      // necessarily all of them, so we cycle again, re-applying all our updates to the newly merged segment.\n\n      iter++;\n    }\n\n    // Record that this packet is finished:\n    writer.bufferedUpdatesStream.finished(this);\n\n    if (infoStream.isEnabled(\"BD\")) {\n      String message = String.format(Locale.ROOT,\n                                     \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                     this, totalSegmentCount, totalDelCount, (System.nanoTime() - startNS) / 1000000000.);\n      if (iter > 0) {\n        message += \"; \" + (iter+1) + \" iters due to concurrent merges\";\n      }\n      message += \"; \" + writer.bufferedUpdatesStream.getPendingUpdatesCount() + \" packets remain\";\n      infoStream.message(\"BD\", message);\n    }\n  }\n\n","bugFix":["f4363cd33f6eff7fb4753574a441e2d18c1022a4"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"636c73dfa97dd282a3089d4239620475f2633519","date":1499025533,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates#apply(IndexWriter).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates#apply(IndexWriter).mjava","sourceNew":"  /** Translates a frozen packet of delete term/query, or doc values\n   *  updates, into their actual docIDs in the index, and applies the change.  This is a heavy\n   *  operation and is done concurrently by incoming indexing threads. */\n\n  public synchronized void apply(IndexWriter writer) throws IOException {\n    if (applied.getCount() == 0) {\n      // already done\n      return;\n    }\n\n    long startNS = System.nanoTime();\n\n    assert any();\n\n    Set<SegmentCommitInfo> seenSegments = new HashSet<>();\n\n    int iter = 0;\n    int totalSegmentCount = 0;\n    long totalDelCount = 0;\n\n    boolean finished = false;\n\n    // Optimistic concurrency: assume we are free to resolve the deletes against all current segments in the index, despite that\n    // concurrent merges are running.  Once we are done, we check to see if a merge completed while we were running.  If so, we must retry\n    // resolving against the newly merged segment(s).  Eventually no merge finishes while we were running and we are done.\n    while (true) {\n      String messagePrefix;\n      if (iter == 0) {\n        messagePrefix = \"\";\n      } else {\n        messagePrefix = \"iter \" + iter;\n      }\n\n      long iterStartNS = System.nanoTime();\n\n      long mergeGenStart = writer.mergeFinishedGen.get();\n\n      Set<String> delFiles = new HashSet<>();\n      BufferedUpdatesStream.SegmentState[] segStates;\n\n      synchronized (writer) {\n        List<SegmentCommitInfo> infos = getInfosToApply(writer);\n        if (infos == null) {\n          break;\n        }\n\n        for (SegmentCommitInfo info : infos) {\n          delFiles.addAll(info.files());\n        }\n\n        // Must open while holding IW lock so that e.g. segments are not merged\n        // away, dropped from 100% deletions, etc., before we can open the readers\n        segStates = writer.bufferedUpdatesStream.openSegmentStates(writer.readerPool, infos, seenSegments, delGen());\n\n        if (segStates.length == 0) {\n\n          if (infoStream.isEnabled(\"BD\")) {\n            infoStream.message(\"BD\", \"packet matches no segments\");\n          }\n          break;\n        }\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                                 messagePrefix + \"now apply del packet (%s) to %d segments, mergeGen %d\",\n                                                 this, segStates.length, mergeGenStart));\n        }\n\n        totalSegmentCount += segStates.length;\n\n        // Important, else IFD may try to delete our files while we are still using them,\n        // if e.g. a merge finishes on some of the segments we are resolving on:\n        writer.deleter.incRef(delFiles);\n      }\n\n      boolean success = false;\n      long delCount;\n      try {\n        // don't hold IW monitor lock here so threads are free concurrently resolve deletes/updates:\n        delCount = apply(segStates);\n        success = true;\n      } finally {\n        finishApply(writer, segStates, success, delFiles);\n      }\n\n      // Since we jus resolved some more deletes/updates, now is a good time to write them:\n      writer.readerPool.writeSomeDocValuesUpdates();\n\n      // It's OK to add this here, even if the while loop retries, because delCount only includes newly\n      // deleted documents, on the segments we didn't already do in previous iterations:\n      totalDelCount += delCount;\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                               messagePrefix + \"done inner apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                               this, segStates.length, delCount, (System.nanoTime() - iterStartNS) / 1000000000.));\n      }\n      \n      if (privateSegment != null) {\n        // No need to retry for a segment-private packet: the merge that folds in our private segment already waits for all deletes to\n        // be applied before it kicks off, so this private segment must already not be in the set of merging segments\n\n        break;\n      }\n\n      // Must sync on writer here so that IW.mergeCommit is not running concurrently, so that if we exit, we know mergeCommit will succeed\n      // in pulling all our delGens into a merge:\n      synchronized (writer) {\n        long mergeGenCur = writer.mergeFinishedGen.get();\n\n        if (mergeGenCur == mergeGenStart) {\n\n          // Must do this while still holding IW lock else a merge could finish and skip carrying over our updates:\n          \n          // Record that this packet is finished:\n          writer.bufferedUpdatesStream.finished(this);\n\n          finished = true;\n\n          // No merge finished while we were applying, so we are done!\n          break;\n        }\n      }\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", messagePrefix + \"concurrent merges finished; move to next iter\");\n      }\n        \n      // A merge completed while we were running.  In this case, that merge may have picked up some of the updates we did, but not\n      // necessarily all of them, so we cycle again, re-applying all our updates to the newly merged segment.\n\n      iter++;\n    }\n\n    if (finished == false) {\n      // Record that this packet is finished:\n      writer.bufferedUpdatesStream.finished(this);\n    }\n        \n    if (infoStream.isEnabled(\"BD\")) {\n      String message = String.format(Locale.ROOT,\n                                     \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                     this, totalSegmentCount, totalDelCount, (System.nanoTime() - startNS) / 1000000000.);\n      if (iter > 0) {\n        message += \"; \" + (iter+1) + \" iters due to concurrent merges\";\n      }\n      message += \"; \" + writer.bufferedUpdatesStream.getPendingUpdatesCount() + \" packets remain\";\n      infoStream.message(\"BD\", message);\n    }\n  }\n\n","sourceOld":"  /** Translates a frozen packet of delete term/query, or doc values\n   *  updates, into their actual docIDs in the index, and applies the change.  This is a heavy\n   *  operation and is done concurrently by incoming indexing threads. */\n\n  public synchronized void apply(IndexWriter writer) throws IOException {\n    if (applied.getCount() == 0) {\n      // already done\n      return;\n    }\n\n    long startNS = System.nanoTime();\n\n    assert any();\n\n    Set<SegmentCommitInfo> seenSegments = new HashSet<>();\n\n    int iter = 0;\n    int totalSegmentCount = 0;\n    long totalDelCount = 0;\n\n    // Optimistic concurrency: assume we are free to resolve the deletes against all current segments in the index, despite that\n    // concurrent merges are running.  Once we are done, we check to see if a merge completed while we were running.  If so, we must retry\n    // resolving against the newly merged segment(s).  Eventually no merge finishes while we were running and we are done.\n    while (true) {\n      String messagePrefix;\n      if (iter == 0) {\n        messagePrefix = \"\";\n      } else {\n        messagePrefix = \"iter \" + iter;\n      }\n\n      long iterStartNS = System.nanoTime();\n\n      long mergeGenStart = writer.mergeFinishedGen.get();\n\n      Set<String> delFiles = new HashSet<>();\n      BufferedUpdatesStream.SegmentState[] segStates;\n\n      synchronized (writer) {\n        List<SegmentCommitInfo> infos = getInfosToApply(writer);\n        if (infos == null) {\n          break;\n        }\n\n        for (SegmentCommitInfo info : infos) {\n          delFiles.addAll(info.files());\n        }\n\n        // Must open while holding IW lock so that e.g. segments are not merged\n        // away, dropped from 100% deletions, etc., before we can open the readers\n        segStates = writer.bufferedUpdatesStream.openSegmentStates(writer.readerPool, infos, seenSegments, delGen());\n\n        if (segStates.length == 0) {\n\n          if (infoStream.isEnabled(\"BD\")) {\n            infoStream.message(\"BD\", \"packet matches no segments\");\n          }\n          break;\n        }\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                                 messagePrefix + \"now apply del packet (%s) to %d segments, mergeGen %d\",\n                                                 this, segStates.length, mergeGenStart));\n        }\n\n        totalSegmentCount += segStates.length;\n\n        // Important, else IFD may try to delete our files while we are still using them,\n        // if e.g. a merge finishes on some of the segments we are resolving on:\n        writer.deleter.incRef(delFiles);\n      }\n\n      boolean success = false;\n      long delCount;\n      try {\n        // don't hold IW monitor lock here so threads are free concurrently resolve deletes/updates:\n        delCount = apply(segStates);\n        success = true;\n      } finally {\n        finishApply(writer, segStates, success, delFiles);\n      }\n\n      // Since we jus resolved some more deletes/updates, now is a good time to write them:\n      writer.readerPool.writeSomeDocValuesUpdates();\n\n      // It's OK to add this here, even if the while loop retries, because delCount only includes newly\n      // deleted documents, on the segments we didn't already do in previous iterations:\n      totalDelCount += delCount;\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                               messagePrefix + \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                               this, segStates.length, delCount, (System.nanoTime() - iterStartNS) / 1000000000.));\n      }\n      \n      if (privateSegment != null) {\n        // No need to retry for a segment-private packet: the merge that folds in our private segment already waits for all deletes to\n        // be applied before it kicks off, so this private segment must already not be in the set of merging segments\n\n        break;\n      }\n\n      // Must sync on writer here so that IW.mergeCommit is not running concurrently, so that if we exit, we know mergeCommit will succeed\n      // in pulling all our delGens into a merge:\n      synchronized (writer) {\n        long mergeGenCur = writer.mergeFinishedGen.get();\n\n        if (mergeGenCur == mergeGenStart) {\n\n          // No merge finished while we were applying, so we are done!\n          break;\n        }\n      }\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", messagePrefix + \"concurrent merges finished; move to next iter\");\n      }\n        \n      // A merge completed while we were running.  In this case, that merge may have picked up some of the updates we did, but not\n      // necessarily all of them, so we cycle again, re-applying all our updates to the newly merged segment.\n\n      iter++;\n    }\n\n    // Record that this packet is finished:\n    writer.bufferedUpdatesStream.finished(this);\n\n    if (infoStream.isEnabled(\"BD\")) {\n      String message = String.format(Locale.ROOT,\n                                     \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                     this, totalSegmentCount, totalDelCount, (System.nanoTime() - startNS) / 1000000000.);\n      if (iter > 0) {\n        message += \"; \" + (iter+1) + \" iters due to concurrent merges\";\n      }\n      message += \"; \" + writer.bufferedUpdatesStream.getPendingUpdatesCount() + \" packets remain\";\n      infoStream.message(\"BD\", message);\n    }\n  }\n\n","bugFix":["f4363cd33f6eff7fb4753574a441e2d18c1022a4"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6324f236dd5a5430f2ff91ebd6cb3f0ae8d34a35","date":1499066739,"type":3,"author":"Adrien Grand","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates#apply(IndexWriter).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates#apply(IndexWriter).mjava","sourceNew":"  /** Translates a frozen packet of delete term/query, or doc values\n   *  updates, into their actual docIDs in the index, and applies the change.  This is a heavy\n   *  operation and is done concurrently by incoming indexing threads. */\n\n  public synchronized void apply(IndexWriter writer) throws IOException {\n    if (applied.getCount() == 0) {\n      // already done\n      return;\n    }\n\n    long startNS = System.nanoTime();\n\n    assert any();\n\n    Set<SegmentCommitInfo> seenSegments = new HashSet<>();\n\n    int iter = 0;\n    int totalSegmentCount = 0;\n    long totalDelCount = 0;\n\n    boolean finished = false;\n\n    // Optimistic concurrency: assume we are free to resolve the deletes against all current segments in the index, despite that\n    // concurrent merges are running.  Once we are done, we check to see if a merge completed while we were running.  If so, we must retry\n    // resolving against the newly merged segment(s).  Eventually no merge finishes while we were running and we are done.\n    while (true) {\n      String messagePrefix;\n      if (iter == 0) {\n        messagePrefix = \"\";\n      } else {\n        messagePrefix = \"iter \" + iter;\n      }\n\n      long iterStartNS = System.nanoTime();\n\n      long mergeGenStart = writer.mergeFinishedGen.get();\n\n      Set<String> delFiles = new HashSet<>();\n      BufferedUpdatesStream.SegmentState[] segStates;\n\n      synchronized (writer) {\n        List<SegmentCommitInfo> infos = getInfosToApply(writer);\n        if (infos == null) {\n          break;\n        }\n\n        for (SegmentCommitInfo info : infos) {\n          delFiles.addAll(info.files());\n        }\n\n        // Must open while holding IW lock so that e.g. segments are not merged\n        // away, dropped from 100% deletions, etc., before we can open the readers\n        segStates = writer.bufferedUpdatesStream.openSegmentStates(writer.readerPool, infos, seenSegments, delGen());\n\n        if (segStates.length == 0) {\n\n          if (infoStream.isEnabled(\"BD\")) {\n            infoStream.message(\"BD\", \"packet matches no segments\");\n          }\n          break;\n        }\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                                 messagePrefix + \"now apply del packet (%s) to %d segments, mergeGen %d\",\n                                                 this, segStates.length, mergeGenStart));\n        }\n\n        totalSegmentCount += segStates.length;\n\n        // Important, else IFD may try to delete our files while we are still using them,\n        // if e.g. a merge finishes on some of the segments we are resolving on:\n        writer.deleter.incRef(delFiles);\n      }\n\n      boolean success = false;\n      long delCount;\n      try {\n        // don't hold IW monitor lock here so threads are free concurrently resolve deletes/updates:\n        delCount = apply(segStates);\n        success = true;\n      } finally {\n        finishApply(writer, segStates, success, delFiles);\n      }\n\n      // Since we jus resolved some more deletes/updates, now is a good time to write them:\n      writer.readerPool.writeSomeDocValuesUpdates();\n\n      // It's OK to add this here, even if the while loop retries, because delCount only includes newly\n      // deleted documents, on the segments we didn't already do in previous iterations:\n      totalDelCount += delCount;\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                               messagePrefix + \"done inner apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                               this, segStates.length, delCount, (System.nanoTime() - iterStartNS) / 1000000000.));\n      }\n      \n      if (privateSegment != null) {\n        // No need to retry for a segment-private packet: the merge that folds in our private segment already waits for all deletes to\n        // be applied before it kicks off, so this private segment must already not be in the set of merging segments\n\n        break;\n      }\n\n      // Must sync on writer here so that IW.mergeCommit is not running concurrently, so that if we exit, we know mergeCommit will succeed\n      // in pulling all our delGens into a merge:\n      synchronized (writer) {\n        long mergeGenCur = writer.mergeFinishedGen.get();\n\n        if (mergeGenCur == mergeGenStart) {\n\n          // Must do this while still holding IW lock else a merge could finish and skip carrying over our updates:\n          \n          // Record that this packet is finished:\n          writer.bufferedUpdatesStream.finished(this);\n\n          finished = true;\n\n          // No merge finished while we were applying, so we are done!\n          break;\n        }\n      }\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", messagePrefix + \"concurrent merges finished; move to next iter\");\n      }\n        \n      // A merge completed while we were running.  In this case, that merge may have picked up some of the updates we did, but not\n      // necessarily all of them, so we cycle again, re-applying all our updates to the newly merged segment.\n\n      iter++;\n    }\n\n    if (finished == false) {\n      // Record that this packet is finished:\n      writer.bufferedUpdatesStream.finished(this);\n    }\n        \n    if (infoStream.isEnabled(\"BD\")) {\n      String message = String.format(Locale.ROOT,\n                                     \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                     this, totalSegmentCount, totalDelCount, (System.nanoTime() - startNS) / 1000000000.);\n      if (iter > 0) {\n        message += \"; \" + (iter+1) + \" iters due to concurrent merges\";\n      }\n      message += \"; \" + writer.bufferedUpdatesStream.getPendingUpdatesCount() + \" packets remain\";\n      infoStream.message(\"BD\", message);\n    }\n  }\n\n","sourceOld":"  /** Translates a frozen packet of delete term/query, or doc values\n   *  updates, into their actual docIDs in the index, and applies the change.  This is a heavy\n   *  operation and is done concurrently by incoming indexing threads. */\n\n  public synchronized void apply(IndexWriter writer) throws IOException {\n    if (applied.getCount() == 0) {\n      // already done\n      return;\n    }\n\n    long startNS = System.nanoTime();\n\n    assert any();\n\n    Set<SegmentCommitInfo> seenSegments = new HashSet<>();\n\n    int iter = 0;\n    int totalSegmentCount = 0;\n    long totalDelCount = 0;\n\n    // Optimistic concurrency: assume we are free to resolve the deletes against all current segments in the index, despite that\n    // concurrent merges are running.  Once we are done, we check to see if a merge completed while we were running.  If so, we must retry\n    // resolving against the newly merged segment(s).  Eventually no merge finishes while we were running and we are done.\n    while (true) {\n      String messagePrefix;\n      if (iter == 0) {\n        messagePrefix = \"\";\n      } else {\n        messagePrefix = \"iter \" + iter;\n      }\n\n      long iterStartNS = System.nanoTime();\n\n      long mergeGenStart = writer.mergeFinishedGen.get();\n\n      Set<String> delFiles = new HashSet<>();\n      BufferedUpdatesStream.SegmentState[] segStates;\n\n      synchronized (writer) {\n        List<SegmentCommitInfo> infos = getInfosToApply(writer);\n        if (infos == null) {\n          break;\n        }\n\n        for (SegmentCommitInfo info : infos) {\n          delFiles.addAll(info.files());\n        }\n\n        // Must open while holding IW lock so that e.g. segments are not merged\n        // away, dropped from 100% deletions, etc., before we can open the readers\n        segStates = writer.bufferedUpdatesStream.openSegmentStates(writer.readerPool, infos, seenSegments, delGen());\n\n        if (segStates.length == 0) {\n\n          if (infoStream.isEnabled(\"BD\")) {\n            infoStream.message(\"BD\", \"packet matches no segments\");\n          }\n          break;\n        }\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                                 messagePrefix + \"now apply del packet (%s) to %d segments, mergeGen %d\",\n                                                 this, segStates.length, mergeGenStart));\n        }\n\n        totalSegmentCount += segStates.length;\n\n        // Important, else IFD may try to delete our files while we are still using them,\n        // if e.g. a merge finishes on some of the segments we are resolving on:\n        writer.deleter.incRef(delFiles);\n      }\n\n      boolean success = false;\n      long delCount;\n      try {\n        // don't hold IW monitor lock here so threads are free concurrently resolve deletes/updates:\n        delCount = apply(segStates);\n        success = true;\n      } finally {\n        finishApply(writer, segStates, success, delFiles);\n      }\n\n      // Since we jus resolved some more deletes/updates, now is a good time to write them:\n      writer.readerPool.writeSomeDocValuesUpdates();\n\n      // It's OK to add this here, even if the while loop retries, because delCount only includes newly\n      // deleted documents, on the segments we didn't already do in previous iterations:\n      totalDelCount += delCount;\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                               messagePrefix + \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                               this, segStates.length, delCount, (System.nanoTime() - iterStartNS) / 1000000000.));\n      }\n      \n      if (privateSegment != null) {\n        // No need to retry for a segment-private packet: the merge that folds in our private segment already waits for all deletes to\n        // be applied before it kicks off, so this private segment must already not be in the set of merging segments\n\n        break;\n      }\n\n      // Must sync on writer here so that IW.mergeCommit is not running concurrently, so that if we exit, we know mergeCommit will succeed\n      // in pulling all our delGens into a merge:\n      synchronized (writer) {\n        long mergeGenCur = writer.mergeFinishedGen.get();\n\n        if (mergeGenCur == mergeGenStart) {\n\n          // No merge finished while we were applying, so we are done!\n          break;\n        }\n      }\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", messagePrefix + \"concurrent merges finished; move to next iter\");\n      }\n        \n      // A merge completed while we were running.  In this case, that merge may have picked up some of the updates we did, but not\n      // necessarily all of them, so we cycle again, re-applying all our updates to the newly merged segment.\n\n      iter++;\n    }\n\n    // Record that this packet is finished:\n    writer.bufferedUpdatesStream.finished(this);\n\n    if (infoStream.isEnabled(\"BD\")) {\n      String message = String.format(Locale.ROOT,\n                                     \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                     this, totalSegmentCount, totalDelCount, (System.nanoTime() - startNS) / 1000000000.);\n      if (iter > 0) {\n        message += \"; \" + (iter+1) + \" iters due to concurrent merges\";\n      }\n      message += \"; \" + writer.bufferedUpdatesStream.getPendingUpdatesCount() + \" packets remain\";\n      infoStream.message(\"BD\", message);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"30c8e5574b55d57947e989443dfde611646530ee","date":1499131153,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates#apply(IndexWriter).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates#apply(IndexWriter).mjava","sourceNew":"  /** Translates a frozen packet of delete term/query, or doc values\n   *  updates, into their actual docIDs in the index, and applies the change.  This is a heavy\n   *  operation and is done concurrently by incoming indexing threads. */\n\n  public synchronized void apply(IndexWriter writer) throws IOException {\n    if (applied.getCount() == 0) {\n      // already done\n      return;\n    }\n\n    long startNS = System.nanoTime();\n\n    assert any();\n\n    Set<SegmentCommitInfo> seenSegments = new HashSet<>();\n\n    int iter = 0;\n    int totalSegmentCount = 0;\n    long totalDelCount = 0;\n\n    boolean finished = false;\n\n    // Optimistic concurrency: assume we are free to resolve the deletes against all current segments in the index, despite that\n    // concurrent merges are running.  Once we are done, we check to see if a merge completed while we were running.  If so, we must retry\n    // resolving against the newly merged segment(s).  Eventually no merge finishes while we were running and we are done.\n    while (true) {\n      String messagePrefix;\n      if (iter == 0) {\n        messagePrefix = \"\";\n      } else {\n        messagePrefix = \"iter \" + iter;\n      }\n\n      long iterStartNS = System.nanoTime();\n\n      long mergeGenStart = writer.mergeFinishedGen.get();\n\n      Set<String> delFiles = new HashSet<>();\n      BufferedUpdatesStream.SegmentState[] segStates;\n\n      synchronized (writer) {\n        List<SegmentCommitInfo> infos = getInfosToApply(writer);\n        if (infos == null) {\n          break;\n        }\n\n        for (SegmentCommitInfo info : infos) {\n          delFiles.addAll(info.files());\n        }\n\n        // Must open while holding IW lock so that e.g. segments are not merged\n        // away, dropped from 100% deletions, etc., before we can open the readers\n        segStates = writer.bufferedUpdatesStream.openSegmentStates(writer.readerPool, infos, seenSegments, delGen());\n\n        if (segStates.length == 0) {\n\n          if (infoStream.isEnabled(\"BD\")) {\n            infoStream.message(\"BD\", \"packet matches no segments\");\n          }\n          break;\n        }\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                                 messagePrefix + \"now apply del packet (%s) to %d segments, mergeGen %d\",\n                                                 this, segStates.length, mergeGenStart));\n        }\n\n        totalSegmentCount += segStates.length;\n\n        // Important, else IFD may try to delete our files while we are still using them,\n        // if e.g. a merge finishes on some of the segments we are resolving on:\n        writer.deleter.incRef(delFiles);\n      }\n\n      boolean success = false;\n      long delCount;\n      try {\n        // don't hold IW monitor lock here so threads are free concurrently resolve deletes/updates:\n        delCount = apply(segStates);\n        success = true;\n      } finally {\n        finishApply(writer, segStates, success, delFiles);\n      }\n\n      // Since we jus resolved some more deletes/updates, now is a good time to write them:\n      writer.readerPool.writeSomeDocValuesUpdates();\n\n      // It's OK to add this here, even if the while loop retries, because delCount only includes newly\n      // deleted documents, on the segments we didn't already do in previous iterations:\n      totalDelCount += delCount;\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                               messagePrefix + \"done inner apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                               this, segStates.length, delCount, (System.nanoTime() - iterStartNS) / 1000000000.));\n      }\n      \n      if (privateSegment != null) {\n        // No need to retry for a segment-private packet: the merge that folds in our private segment already waits for all deletes to\n        // be applied before it kicks off, so this private segment must already not be in the set of merging segments\n\n        break;\n      }\n\n      // Must sync on writer here so that IW.mergeCommit is not running concurrently, so that if we exit, we know mergeCommit will succeed\n      // in pulling all our delGens into a merge:\n      synchronized (writer) {\n        long mergeGenCur = writer.mergeFinishedGen.get();\n\n        if (mergeGenCur == mergeGenStart) {\n\n          // Must do this while still holding IW lock else a merge could finish and skip carrying over our updates:\n          \n          // Record that this packet is finished:\n          writer.bufferedUpdatesStream.finished(this);\n\n          finished = true;\n\n          // No merge finished while we were applying, so we are done!\n          break;\n        }\n      }\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", messagePrefix + \"concurrent merges finished; move to next iter\");\n      }\n        \n      // A merge completed while we were running.  In this case, that merge may have picked up some of the updates we did, but not\n      // necessarily all of them, so we cycle again, re-applying all our updates to the newly merged segment.\n\n      iter++;\n    }\n\n    if (finished == false) {\n      // Record that this packet is finished:\n      writer.bufferedUpdatesStream.finished(this);\n    }\n        \n    if (infoStream.isEnabled(\"BD\")) {\n      String message = String.format(Locale.ROOT,\n                                     \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                     this, totalSegmentCount, totalDelCount, (System.nanoTime() - startNS) / 1000000000.);\n      if (iter > 0) {\n        message += \"; \" + (iter+1) + \" iters due to concurrent merges\";\n      }\n      message += \"; \" + writer.bufferedUpdatesStream.getPendingUpdatesCount() + \" packets remain\";\n      infoStream.message(\"BD\", message);\n    }\n  }\n\n","sourceOld":"  /** Translates a frozen packet of delete term/query, or doc values\n   *  updates, into their actual docIDs in the index, and applies the change.  This is a heavy\n   *  operation and is done concurrently by incoming indexing threads. */\n\n  public synchronized void apply(IndexWriter writer) throws IOException {\n    if (applied.getCount() == 0) {\n      // already done\n      return;\n    }\n\n    long startNS = System.nanoTime();\n\n    assert any();\n\n    Set<SegmentCommitInfo> seenSegments = new HashSet<>();\n\n    int iter = 0;\n    int totalSegmentCount = 0;\n    long totalDelCount = 0;\n\n    // Optimistic concurrency: assume we are free to resolve the deletes against all current segments in the index, despite that\n    // concurrent merges are running.  Once we are done, we check to see if a merge completed while we were running.  If so, we must retry\n    // resolving against the newly merged segment(s).  Eventually no merge finishes while we were running and we are done.\n    while (true) {\n      String messagePrefix;\n      if (iter == 0) {\n        messagePrefix = \"\";\n      } else {\n        messagePrefix = \"iter \" + iter;\n      }\n\n      long iterStartNS = System.nanoTime();\n\n      long mergeGenStart = writer.mergeFinishedGen.get();\n\n      Set<String> delFiles = new HashSet<>();\n      BufferedUpdatesStream.SegmentState[] segStates;\n\n      synchronized (writer) {\n        List<SegmentCommitInfo> infos = getInfosToApply(writer);\n        if (infos == null) {\n          break;\n        }\n\n        for (SegmentCommitInfo info : infos) {\n          delFiles.addAll(info.files());\n        }\n\n        // Must open while holding IW lock so that e.g. segments are not merged\n        // away, dropped from 100% deletions, etc., before we can open the readers\n        segStates = writer.bufferedUpdatesStream.openSegmentStates(writer.readerPool, infos, seenSegments, delGen());\n\n        if (segStates.length == 0) {\n\n          if (infoStream.isEnabled(\"BD\")) {\n            infoStream.message(\"BD\", \"packet matches no segments\");\n          }\n          \n          break;\n        }\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                                 messagePrefix + \"now apply del packet (%s) to %d segments, mergeGen %d\",\n                                                 this, segStates.length, mergeGenStart));\n        }\n\n        totalSegmentCount += segStates.length;\n\n        // Important, else IFD may try to delete our files while we are still using them,\n        // if e.g. a merge finishes on some of the segments we are resolving on:\n        writer.deleter.incRef(delFiles);\n      }\n\n      boolean success = false;\n      long delCount;\n      try {\n        // don't hold IW monitor lock here so threads are free concurrently resolve deletes/updates:\n        delCount = apply(segStates);\n        success = true;\n      } finally {\n        finishApply(writer, segStates, success, delFiles);\n      }\n\n      // Since we jus resolved some more deletes/updates, now is a good time to write them:\n      writer.readerPool.writeSomeDocValuesUpdates();\n\n      // It's OK to add this here, even if the while loop retries, because delCount only includes newly\n      // deleted documents, on the segments we didn't already do in previous iterations:\n      totalDelCount += delCount;\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                               messagePrefix + \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                               this, segStates.length, delCount, (System.nanoTime() - iterStartNS) / 1000000000.));\n      }\n      \n      if (privateSegment != null) {\n        // No need to retry for a segment-private packet: the merge that folds in our private segment already waits for all deletes to\n        // be applied before it kicks off, so this private segment must already not be in the set of merging segments\n\n        break;\n      }\n\n      // Must sync on writer here so that IW.mergeCommit is not running concurrently, so that if we exit, we know mergeCommit will succeed\n      // in pulling all our delGens into a merge:\n      synchronized (writer) {\n        long mergeGenCur = writer.mergeFinishedGen.get();\n\n        if (mergeGenCur == mergeGenStart) {\n\n          // No merge finished while we were applying, so we are done!\n          break;\n        }\n      }\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", messagePrefix + \"concurrent merges finished; move to next iter\");\n      }\n        \n      // A merge completed while we were running.  In this case, that merge may have picked up some of the updates we did, but not\n      // necessarily all of them, so we cycle again, re-applying all our updates to the newly merged segment.\n\n      iter++;\n    }\n\n    // Record that this packet is finished:\n    writer.bufferedUpdatesStream.finished(this);\n\n    if (infoStream.isEnabled(\"BD\")) {\n      String message = String.format(Locale.ROOT,\n                                     \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                     this, totalSegmentCount, totalDelCount, (System.nanoTime() - startNS) / 1000000000.);\n      if (iter > 0) {\n        message += \"; \" + (iter+1) + \" iters due to concurrent merges\";\n      }\n      message += \"; \" + writer.bufferedUpdatesStream.getPendingUpdatesCount() + \" packets remain\";\n      infoStream.message(\"BD\", message);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"14d66d86a8b184a86bcaebcf6e15fcef486e0876","date":1521539412,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates#apply(IndexWriter).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates#apply(IndexWriter).mjava","sourceNew":"  /** Translates a frozen packet of delete term/query, or doc values\n   *  updates, into their actual docIDs in the index, and applies the change.  This is a heavy\n   *  operation and is done concurrently by incoming indexing threads. */\n  @SuppressWarnings(\"try\")\n  public synchronized void apply(IndexWriter writer) throws IOException {\n    if (applied.getCount() == 0) {\n      // already done\n      return;\n    }\n\n    long startNS = System.nanoTime();\n\n    assert any();\n\n    Set<SegmentCommitInfo> seenSegments = new HashSet<>();\n\n    int iter = 0;\n    int totalSegmentCount = 0;\n    long totalDelCount = 0;\n\n    boolean finished = false;\n\n    // Optimistic concurrency: assume we are free to resolve the deletes against all current segments in the index, despite that\n    // concurrent merges are running.  Once we are done, we check to see if a merge completed while we were running.  If so, we must retry\n    // resolving against the newly merged segment(s).  Eventually no merge finishes while we were running and we are done.\n    while (true) {\n      String messagePrefix;\n      if (iter == 0) {\n        messagePrefix = \"\";\n      } else {\n        messagePrefix = \"iter \" + iter;\n      }\n\n      long iterStartNS = System.nanoTime();\n\n      long mergeGenStart = writer.mergeFinishedGen.get();\n\n      Set<String> delFiles = new HashSet<>();\n      BufferedUpdatesStream.SegmentState[] segStates;\n\n      synchronized (writer) {\n        List<SegmentCommitInfo> infos = getInfosToApply(writer);\n        if (infos == null) {\n          break;\n        }\n\n        for (SegmentCommitInfo info : infos) {\n          delFiles.addAll(info.files());\n        }\n\n        // Must open while holding IW lock so that e.g. segments are not merged\n        // away, dropped from 100% deletions, etc., before we can open the readers\n        segStates = writer.bufferedUpdatesStream.openSegmentStates(writer.readerPool, infos, seenSegments, delGen());\n\n        if (segStates.length == 0) {\n\n          if (infoStream.isEnabled(\"BD\")) {\n            infoStream.message(\"BD\", \"packet matches no segments\");\n          }\n          break;\n        }\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                                 messagePrefix + \"now apply del packet (%s) to %d segments, mergeGen %d\",\n                                                 this, segStates.length, mergeGenStart));\n        }\n\n        totalSegmentCount += segStates.length;\n\n        // Important, else IFD may try to delete our files while we are still using them,\n        // if e.g. a merge finishes on some of the segments we are resolving on:\n        writer.deleter.incRef(delFiles);\n      }\n\n      AtomicBoolean success = new AtomicBoolean();\n      long delCount;\n      try (Closeable finalizer = () -> finishApply(writer, segStates, success.get(), delFiles)) {\n        // don't hold IW monitor lock here so threads are free concurrently resolve deletes/updates:\n        delCount = apply(segStates);\n        success.set(true);\n      }\n\n      // Since we jus resolved some more deletes/updates, now is a good time to write them:\n      writer.readerPool.writeSomeDocValuesUpdates();\n\n      // It's OK to add this here, even if the while loop retries, because delCount only includes newly\n      // deleted documents, on the segments we didn't already do in previous iterations:\n      totalDelCount += delCount;\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                               messagePrefix + \"done inner apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                               this, segStates.length, delCount, (System.nanoTime() - iterStartNS) / 1000000000.));\n      }\n      \n      if (privateSegment != null) {\n        // No need to retry for a segment-private packet: the merge that folds in our private segment already waits for all deletes to\n        // be applied before it kicks off, so this private segment must already not be in the set of merging segments\n\n        break;\n      }\n\n      // Must sync on writer here so that IW.mergeCommit is not running concurrently, so that if we exit, we know mergeCommit will succeed\n      // in pulling all our delGens into a merge:\n      synchronized (writer) {\n        long mergeGenCur = writer.mergeFinishedGen.get();\n\n        if (mergeGenCur == mergeGenStart) {\n\n          // Must do this while still holding IW lock else a merge could finish and skip carrying over our updates:\n          \n          // Record that this packet is finished:\n          writer.bufferedUpdatesStream.finished(this);\n\n          finished = true;\n\n          // No merge finished while we were applying, so we are done!\n          break;\n        }\n      }\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", messagePrefix + \"concurrent merges finished; move to next iter\");\n      }\n        \n      // A merge completed while we were running.  In this case, that merge may have picked up some of the updates we did, but not\n      // necessarily all of them, so we cycle again, re-applying all our updates to the newly merged segment.\n\n      iter++;\n    }\n\n    if (finished == false) {\n      // Record that this packet is finished:\n      writer.bufferedUpdatesStream.finished(this);\n    }\n        \n    if (infoStream.isEnabled(\"BD\")) {\n      String message = String.format(Locale.ROOT,\n                                     \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                     this, totalSegmentCount, totalDelCount, (System.nanoTime() - startNS) / 1000000000.);\n      if (iter > 0) {\n        message += \"; \" + (iter+1) + \" iters due to concurrent merges\";\n      }\n      message += \"; \" + writer.bufferedUpdatesStream.getPendingUpdatesCount() + \" packets remain\";\n      infoStream.message(\"BD\", message);\n    }\n  }\n\n","sourceOld":"  /** Translates a frozen packet of delete term/query, or doc values\n   *  updates, into their actual docIDs in the index, and applies the change.  This is a heavy\n   *  operation and is done concurrently by incoming indexing threads. */\n\n  public synchronized void apply(IndexWriter writer) throws IOException {\n    if (applied.getCount() == 0) {\n      // already done\n      return;\n    }\n\n    long startNS = System.nanoTime();\n\n    assert any();\n\n    Set<SegmentCommitInfo> seenSegments = new HashSet<>();\n\n    int iter = 0;\n    int totalSegmentCount = 0;\n    long totalDelCount = 0;\n\n    boolean finished = false;\n\n    // Optimistic concurrency: assume we are free to resolve the deletes against all current segments in the index, despite that\n    // concurrent merges are running.  Once we are done, we check to see if a merge completed while we were running.  If so, we must retry\n    // resolving against the newly merged segment(s).  Eventually no merge finishes while we were running and we are done.\n    while (true) {\n      String messagePrefix;\n      if (iter == 0) {\n        messagePrefix = \"\";\n      } else {\n        messagePrefix = \"iter \" + iter;\n      }\n\n      long iterStartNS = System.nanoTime();\n\n      long mergeGenStart = writer.mergeFinishedGen.get();\n\n      Set<String> delFiles = new HashSet<>();\n      BufferedUpdatesStream.SegmentState[] segStates;\n\n      synchronized (writer) {\n        List<SegmentCommitInfo> infos = getInfosToApply(writer);\n        if (infos == null) {\n          break;\n        }\n\n        for (SegmentCommitInfo info : infos) {\n          delFiles.addAll(info.files());\n        }\n\n        // Must open while holding IW lock so that e.g. segments are not merged\n        // away, dropped from 100% deletions, etc., before we can open the readers\n        segStates = writer.bufferedUpdatesStream.openSegmentStates(writer.readerPool, infos, seenSegments, delGen());\n\n        if (segStates.length == 0) {\n\n          if (infoStream.isEnabled(\"BD\")) {\n            infoStream.message(\"BD\", \"packet matches no segments\");\n          }\n          break;\n        }\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                                 messagePrefix + \"now apply del packet (%s) to %d segments, mergeGen %d\",\n                                                 this, segStates.length, mergeGenStart));\n        }\n\n        totalSegmentCount += segStates.length;\n\n        // Important, else IFD may try to delete our files while we are still using them,\n        // if e.g. a merge finishes on some of the segments we are resolving on:\n        writer.deleter.incRef(delFiles);\n      }\n\n      boolean success = false;\n      long delCount;\n      try {\n        // don't hold IW monitor lock here so threads are free concurrently resolve deletes/updates:\n        delCount = apply(segStates);\n        success = true;\n      } finally {\n        finishApply(writer, segStates, success, delFiles);\n      }\n\n      // Since we jus resolved some more deletes/updates, now is a good time to write them:\n      writer.readerPool.writeSomeDocValuesUpdates();\n\n      // It's OK to add this here, even if the while loop retries, because delCount only includes newly\n      // deleted documents, on the segments we didn't already do in previous iterations:\n      totalDelCount += delCount;\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                               messagePrefix + \"done inner apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                               this, segStates.length, delCount, (System.nanoTime() - iterStartNS) / 1000000000.));\n      }\n      \n      if (privateSegment != null) {\n        // No need to retry for a segment-private packet: the merge that folds in our private segment already waits for all deletes to\n        // be applied before it kicks off, so this private segment must already not be in the set of merging segments\n\n        break;\n      }\n\n      // Must sync on writer here so that IW.mergeCommit is not running concurrently, so that if we exit, we know mergeCommit will succeed\n      // in pulling all our delGens into a merge:\n      synchronized (writer) {\n        long mergeGenCur = writer.mergeFinishedGen.get();\n\n        if (mergeGenCur == mergeGenStart) {\n\n          // Must do this while still holding IW lock else a merge could finish and skip carrying over our updates:\n          \n          // Record that this packet is finished:\n          writer.bufferedUpdatesStream.finished(this);\n\n          finished = true;\n\n          // No merge finished while we were applying, so we are done!\n          break;\n        }\n      }\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", messagePrefix + \"concurrent merges finished; move to next iter\");\n      }\n        \n      // A merge completed while we were running.  In this case, that merge may have picked up some of the updates we did, but not\n      // necessarily all of them, so we cycle again, re-applying all our updates to the newly merged segment.\n\n      iter++;\n    }\n\n    if (finished == false) {\n      // Record that this packet is finished:\n      writer.bufferedUpdatesStream.finished(this);\n    }\n        \n    if (infoStream.isEnabled(\"BD\")) {\n      String message = String.format(Locale.ROOT,\n                                     \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                     this, totalSegmentCount, totalDelCount, (System.nanoTime() - startNS) / 1000000000.);\n      if (iter > 0) {\n        message += \"; \" + (iter+1) + \" iters due to concurrent merges\";\n      }\n      message += \"; \" + writer.bufferedUpdatesStream.getPendingUpdatesCount() + \" packets remain\";\n      infoStream.message(\"BD\", message);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6815b5b5d6334b2245dd7be2f8b6cca949bf7f43","date":1521731438,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates#apply(IndexWriter).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates#apply(IndexWriter).mjava","sourceNew":"  /** Translates a frozen packet of delete term/query, or doc values\n   *  updates, into their actual docIDs in the index, and applies the change.  This is a heavy\n   *  operation and is done concurrently by incoming indexing threads. */\n  @SuppressWarnings(\"try\")\n  public synchronized void apply(IndexWriter writer) throws IOException {\n    if (applied.getCount() == 0) {\n      // already done\n      return;\n    }\n\n    long startNS = System.nanoTime();\n\n    assert any();\n\n    Set<SegmentCommitInfo> seenSegments = new HashSet<>();\n\n    int iter = 0;\n    int totalSegmentCount = 0;\n    long totalDelCount = 0;\n\n    boolean finished = false;\n\n    // Optimistic concurrency: assume we are free to resolve the deletes against all current segments in the index, despite that\n    // concurrent merges are running.  Once we are done, we check to see if a merge completed while we were running.  If so, we must retry\n    // resolving against the newly merged segment(s).  Eventually no merge finishes while we were running and we are done.\n    while (true) {\n      String messagePrefix;\n      if (iter == 0) {\n        messagePrefix = \"\";\n      } else {\n        messagePrefix = \"iter \" + iter;\n      }\n\n      long iterStartNS = System.nanoTime();\n\n      long mergeGenStart = writer.mergeFinishedGen.get();\n\n      Set<String> delFiles = new HashSet<>();\n      BufferedUpdatesStream.SegmentState[] segStates;\n\n      synchronized (writer) {\n        List<SegmentCommitInfo> infos = getInfosToApply(writer);\n        if (infos == null) {\n          break;\n        }\n\n        for (SegmentCommitInfo info : infos) {\n          delFiles.addAll(info.files());\n        }\n\n        // Must open while holding IW lock so that e.g. segments are not merged\n        // away, dropped from 100% deletions, etc., before we can open the readers\n        segStates = writer.bufferedUpdatesStream.openSegmentStates(writer.readerPool, infos, seenSegments, delGen());\n\n        if (segStates.length == 0) {\n\n          if (infoStream.isEnabled(\"BD\")) {\n            infoStream.message(\"BD\", \"packet matches no segments\");\n          }\n          break;\n        }\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                                 messagePrefix + \"now apply del packet (%s) to %d segments, mergeGen %d\",\n                                                 this, segStates.length, mergeGenStart));\n        }\n\n        totalSegmentCount += segStates.length;\n\n        // Important, else IFD may try to delete our files while we are still using them,\n        // if e.g. a merge finishes on some of the segments we are resolving on:\n        writer.deleter.incRef(delFiles);\n      }\n\n      AtomicBoolean success = new AtomicBoolean();\n      long delCount;\n      try (Closeable finalizer = () -> finishApply(writer, segStates, success.get(), delFiles)) {\n        // don't hold IW monitor lock here so threads are free concurrently resolve deletes/updates:\n        delCount = apply(segStates);\n        success.set(true);\n      }\n\n      // Since we jus resolved some more deletes/updates, now is a good time to write them:\n      writer.readerPool.writeSomeDocValuesUpdates();\n\n      // It's OK to add this here, even if the while loop retries, because delCount only includes newly\n      // deleted documents, on the segments we didn't already do in previous iterations:\n      totalDelCount += delCount;\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                               messagePrefix + \"done inner apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                               this, segStates.length, delCount, (System.nanoTime() - iterStartNS) / 1000000000.));\n      }\n      \n      if (privateSegment != null) {\n        // No need to retry for a segment-private packet: the merge that folds in our private segment already waits for all deletes to\n        // be applied before it kicks off, so this private segment must already not be in the set of merging segments\n\n        break;\n      }\n\n      // Must sync on writer here so that IW.mergeCommit is not running concurrently, so that if we exit, we know mergeCommit will succeed\n      // in pulling all our delGens into a merge:\n      synchronized (writer) {\n        long mergeGenCur = writer.mergeFinishedGen.get();\n\n        if (mergeGenCur == mergeGenStart) {\n\n          // Must do this while still holding IW lock else a merge could finish and skip carrying over our updates:\n          \n          // Record that this packet is finished:\n          writer.bufferedUpdatesStream.finished(this);\n\n          finished = true;\n\n          // No merge finished while we were applying, so we are done!\n          break;\n        }\n      }\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", messagePrefix + \"concurrent merges finished; move to next iter\");\n      }\n        \n      // A merge completed while we were running.  In this case, that merge may have picked up some of the updates we did, but not\n      // necessarily all of them, so we cycle again, re-applying all our updates to the newly merged segment.\n\n      iter++;\n    }\n\n    if (finished == false) {\n      // Record that this packet is finished:\n      writer.bufferedUpdatesStream.finished(this);\n    }\n        \n    if (infoStream.isEnabled(\"BD\")) {\n      String message = String.format(Locale.ROOT,\n                                     \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                     this, totalSegmentCount, totalDelCount, (System.nanoTime() - startNS) / 1000000000.);\n      if (iter > 0) {\n        message += \"; \" + (iter+1) + \" iters due to concurrent merges\";\n      }\n      message += \"; \" + writer.bufferedUpdatesStream.getPendingUpdatesCount() + \" packets remain\";\n      infoStream.message(\"BD\", message);\n    }\n  }\n\n","sourceOld":"  /** Translates a frozen packet of delete term/query, or doc values\n   *  updates, into their actual docIDs in the index, and applies the change.  This is a heavy\n   *  operation and is done concurrently by incoming indexing threads. */\n\n  public synchronized void apply(IndexWriter writer) throws IOException {\n    if (applied.getCount() == 0) {\n      // already done\n      return;\n    }\n\n    long startNS = System.nanoTime();\n\n    assert any();\n\n    Set<SegmentCommitInfo> seenSegments = new HashSet<>();\n\n    int iter = 0;\n    int totalSegmentCount = 0;\n    long totalDelCount = 0;\n\n    boolean finished = false;\n\n    // Optimistic concurrency: assume we are free to resolve the deletes against all current segments in the index, despite that\n    // concurrent merges are running.  Once we are done, we check to see if a merge completed while we were running.  If so, we must retry\n    // resolving against the newly merged segment(s).  Eventually no merge finishes while we were running and we are done.\n    while (true) {\n      String messagePrefix;\n      if (iter == 0) {\n        messagePrefix = \"\";\n      } else {\n        messagePrefix = \"iter \" + iter;\n      }\n\n      long iterStartNS = System.nanoTime();\n\n      long mergeGenStart = writer.mergeFinishedGen.get();\n\n      Set<String> delFiles = new HashSet<>();\n      BufferedUpdatesStream.SegmentState[] segStates;\n\n      synchronized (writer) {\n        List<SegmentCommitInfo> infos = getInfosToApply(writer);\n        if (infos == null) {\n          break;\n        }\n\n        for (SegmentCommitInfo info : infos) {\n          delFiles.addAll(info.files());\n        }\n\n        // Must open while holding IW lock so that e.g. segments are not merged\n        // away, dropped from 100% deletions, etc., before we can open the readers\n        segStates = writer.bufferedUpdatesStream.openSegmentStates(writer.readerPool, infos, seenSegments, delGen());\n\n        if (segStates.length == 0) {\n\n          if (infoStream.isEnabled(\"BD\")) {\n            infoStream.message(\"BD\", \"packet matches no segments\");\n          }\n          break;\n        }\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                                 messagePrefix + \"now apply del packet (%s) to %d segments, mergeGen %d\",\n                                                 this, segStates.length, mergeGenStart));\n        }\n\n        totalSegmentCount += segStates.length;\n\n        // Important, else IFD may try to delete our files while we are still using them,\n        // if e.g. a merge finishes on some of the segments we are resolving on:\n        writer.deleter.incRef(delFiles);\n      }\n\n      boolean success = false;\n      long delCount;\n      try {\n        // don't hold IW monitor lock here so threads are free concurrently resolve deletes/updates:\n        delCount = apply(segStates);\n        success = true;\n      } finally {\n        finishApply(writer, segStates, success, delFiles);\n      }\n\n      // Since we jus resolved some more deletes/updates, now is a good time to write them:\n      writer.readerPool.writeSomeDocValuesUpdates();\n\n      // It's OK to add this here, even if the while loop retries, because delCount only includes newly\n      // deleted documents, on the segments we didn't already do in previous iterations:\n      totalDelCount += delCount;\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                               messagePrefix + \"done inner apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                               this, segStates.length, delCount, (System.nanoTime() - iterStartNS) / 1000000000.));\n      }\n      \n      if (privateSegment != null) {\n        // No need to retry for a segment-private packet: the merge that folds in our private segment already waits for all deletes to\n        // be applied before it kicks off, so this private segment must already not be in the set of merging segments\n\n        break;\n      }\n\n      // Must sync on writer here so that IW.mergeCommit is not running concurrently, so that if we exit, we know mergeCommit will succeed\n      // in pulling all our delGens into a merge:\n      synchronized (writer) {\n        long mergeGenCur = writer.mergeFinishedGen.get();\n\n        if (mergeGenCur == mergeGenStart) {\n\n          // Must do this while still holding IW lock else a merge could finish and skip carrying over our updates:\n          \n          // Record that this packet is finished:\n          writer.bufferedUpdatesStream.finished(this);\n\n          finished = true;\n\n          // No merge finished while we were applying, so we are done!\n          break;\n        }\n      }\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", messagePrefix + \"concurrent merges finished; move to next iter\");\n      }\n        \n      // A merge completed while we were running.  In this case, that merge may have picked up some of the updates we did, but not\n      // necessarily all of them, so we cycle again, re-applying all our updates to the newly merged segment.\n\n      iter++;\n    }\n\n    if (finished == false) {\n      // Record that this packet is finished:\n      writer.bufferedUpdatesStream.finished(this);\n    }\n        \n    if (infoStream.isEnabled(\"BD\")) {\n      String message = String.format(Locale.ROOT,\n                                     \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                     this, totalSegmentCount, totalDelCount, (System.nanoTime() - startNS) / 1000000000.);\n      if (iter > 0) {\n        message += \"; \" + (iter+1) + \" iters due to concurrent merges\";\n      }\n      message += \"; \" + writer.bufferedUpdatesStream.getPendingUpdatesCount() + \" packets remain\";\n      infoStream.message(\"BD\", message);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"15e716649e2bd79a98b5e68c464154ea4c44677a","date":1523975212,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates#apply(IndexWriter).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates#apply(IndexWriter).mjava","sourceNew":"  /** Translates a frozen packet of delete term/query, or doc values\n   *  updates, into their actual docIDs in the index, and applies the change.  This is a heavy\n   *  operation and is done concurrently by incoming indexing threads. */\n  @SuppressWarnings(\"try\")\n  public synchronized void apply(IndexWriter writer) throws IOException {\n    if (applied.getCount() == 0) {\n      // already done\n      return;\n    }\n\n    long startNS = System.nanoTime();\n\n    assert any();\n\n    Set<SegmentCommitInfo> seenSegments = new HashSet<>();\n\n    int iter = 0;\n    int totalSegmentCount = 0;\n    long totalDelCount = 0;\n\n    boolean finished = false;\n\n    // Optimistic concurrency: assume we are free to resolve the deletes against all current segments in the index, despite that\n    // concurrent merges are running.  Once we are done, we check to see if a merge completed while we were running.  If so, we must retry\n    // resolving against the newly merged segment(s).  Eventually no merge finishes while we were running and we are done.\n    while (true) {\n      String messagePrefix;\n      if (iter == 0) {\n        messagePrefix = \"\";\n      } else {\n        messagePrefix = \"iter \" + iter;\n      }\n\n      long iterStartNS = System.nanoTime();\n\n      long mergeGenStart = writer.mergeFinishedGen.get();\n\n      Set<String> delFiles = new HashSet<>();\n      BufferedUpdatesStream.SegmentState[] segStates;\n\n      synchronized (writer) {\n        List<SegmentCommitInfo> infos = getInfosToApply(writer);\n        if (infos == null) {\n          break;\n        }\n\n        for (SegmentCommitInfo info : infos) {\n          delFiles.addAll(info.files());\n        }\n\n        // Must open while holding IW lock so that e.g. segments are not merged\n        // away, dropped from 100% deletions, etc., before we can open the readers\n        segStates = writer.bufferedUpdatesStream.openSegmentStates(writer.readerPool, infos, seenSegments, delGen());\n\n        if (segStates.length == 0) {\n\n          if (infoStream.isEnabled(\"BD\")) {\n            infoStream.message(\"BD\", \"packet matches no segments\");\n          }\n          break;\n        }\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                                 messagePrefix + \"now apply del packet (%s) to %d segments, mergeGen %d\",\n                                                 this, segStates.length, mergeGenStart));\n        }\n\n        totalSegmentCount += segStates.length;\n\n        // Important, else IFD may try to delete our files while we are still using them,\n        // if e.g. a merge finishes on some of the segments we are resolving on:\n        writer.deleter.incRef(delFiles);\n      }\n\n      AtomicBoolean success = new AtomicBoolean();\n      long delCount;\n      try (Closeable finalizer = () -> finishApply(writer, segStates, success.get(), delFiles)) {\n        // don't hold IW monitor lock here so threads are free concurrently resolve deletes/updates:\n        delCount = apply(segStates);\n        success.set(true);\n      }\n\n      // Since we jus resolved some more deletes/updates, now is a good time to write them:\n      writer.readerPool.writeSomeDocValuesUpdates();\n\n      // It's OK to add this here, even if the while loop retries, because delCount only includes newly\n      // deleted documents, on the segments we didn't already do in previous iterations:\n      totalDelCount += delCount;\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                               messagePrefix + \"done inner apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                               this, segStates.length, delCount, (System.nanoTime() - iterStartNS) / 1000000000.));\n      }\n      if (privateSegment != null) {\n        // No need to retry for a segment-private packet: the merge that folds in our private segment already waits for all deletes to\n        // be applied before it kicks off, so this private segment must already not be in the set of merging segments\n\n        break;\n      }\n\n      // Must sync on writer here so that IW.mergeCommit is not running concurrently, so that if we exit, we know mergeCommit will succeed\n      // in pulling all our delGens into a merge:\n      synchronized (writer) {\n        long mergeGenCur = writer.mergeFinishedGen.get();\n\n        if (mergeGenCur == mergeGenStart) {\n\n          // Must do this while still holding IW lock else a merge could finish and skip carrying over our updates:\n          \n          // Record that this packet is finished:\n          writer.bufferedUpdatesStream.finished(this);\n\n          finished = true;\n\n          // No merge finished while we were applying, so we are done!\n          break;\n        }\n      }\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", messagePrefix + \"concurrent merges finished; move to next iter\");\n      }\n        \n      // A merge completed while we were running.  In this case, that merge may have picked up some of the updates we did, but not\n      // necessarily all of them, so we cycle again, re-applying all our updates to the newly merged segment.\n\n      iter++;\n    }\n\n    if (finished == false) {\n      // Record that this packet is finished:\n      writer.bufferedUpdatesStream.finished(this);\n    }\n        \n    if (infoStream.isEnabled(\"BD\")) {\n      String message = String.format(Locale.ROOT,\n                                     \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                     this, totalSegmentCount, totalDelCount, (System.nanoTime() - startNS) / 1000000000.);\n      if (iter > 0) {\n        message += \"; \" + (iter+1) + \" iters due to concurrent merges\";\n      }\n      message += \"; \" + writer.bufferedUpdatesStream.getPendingUpdatesCount() + \" packets remain\";\n      infoStream.message(\"BD\", message);\n    }\n  }\n\n","sourceOld":"  /** Translates a frozen packet of delete term/query, or doc values\n   *  updates, into their actual docIDs in the index, and applies the change.  This is a heavy\n   *  operation and is done concurrently by incoming indexing threads. */\n  @SuppressWarnings(\"try\")\n  public synchronized void apply(IndexWriter writer) throws IOException {\n    if (applied.getCount() == 0) {\n      // already done\n      return;\n    }\n\n    long startNS = System.nanoTime();\n\n    assert any();\n\n    Set<SegmentCommitInfo> seenSegments = new HashSet<>();\n\n    int iter = 0;\n    int totalSegmentCount = 0;\n    long totalDelCount = 0;\n\n    boolean finished = false;\n\n    // Optimistic concurrency: assume we are free to resolve the deletes against all current segments in the index, despite that\n    // concurrent merges are running.  Once we are done, we check to see if a merge completed while we were running.  If so, we must retry\n    // resolving against the newly merged segment(s).  Eventually no merge finishes while we were running and we are done.\n    while (true) {\n      String messagePrefix;\n      if (iter == 0) {\n        messagePrefix = \"\";\n      } else {\n        messagePrefix = \"iter \" + iter;\n      }\n\n      long iterStartNS = System.nanoTime();\n\n      long mergeGenStart = writer.mergeFinishedGen.get();\n\n      Set<String> delFiles = new HashSet<>();\n      BufferedUpdatesStream.SegmentState[] segStates;\n\n      synchronized (writer) {\n        List<SegmentCommitInfo> infos = getInfosToApply(writer);\n        if (infos == null) {\n          break;\n        }\n\n        for (SegmentCommitInfo info : infos) {\n          delFiles.addAll(info.files());\n        }\n\n        // Must open while holding IW lock so that e.g. segments are not merged\n        // away, dropped from 100% deletions, etc., before we can open the readers\n        segStates = writer.bufferedUpdatesStream.openSegmentStates(writer.readerPool, infos, seenSegments, delGen());\n\n        if (segStates.length == 0) {\n\n          if (infoStream.isEnabled(\"BD\")) {\n            infoStream.message(\"BD\", \"packet matches no segments\");\n          }\n          break;\n        }\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                                 messagePrefix + \"now apply del packet (%s) to %d segments, mergeGen %d\",\n                                                 this, segStates.length, mergeGenStart));\n        }\n\n        totalSegmentCount += segStates.length;\n\n        // Important, else IFD may try to delete our files while we are still using them,\n        // if e.g. a merge finishes on some of the segments we are resolving on:\n        writer.deleter.incRef(delFiles);\n      }\n\n      AtomicBoolean success = new AtomicBoolean();\n      long delCount;\n      try (Closeable finalizer = () -> finishApply(writer, segStates, success.get(), delFiles)) {\n        // don't hold IW monitor lock here so threads are free concurrently resolve deletes/updates:\n        delCount = apply(segStates);\n        success.set(true);\n      }\n\n      // Since we jus resolved some more deletes/updates, now is a good time to write them:\n      writer.readerPool.writeSomeDocValuesUpdates();\n\n      // It's OK to add this here, even if the while loop retries, because delCount only includes newly\n      // deleted documents, on the segments we didn't already do in previous iterations:\n      totalDelCount += delCount;\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                               messagePrefix + \"done inner apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                               this, segStates.length, delCount, (System.nanoTime() - iterStartNS) / 1000000000.));\n      }\n      \n      if (privateSegment != null) {\n        // No need to retry for a segment-private packet: the merge that folds in our private segment already waits for all deletes to\n        // be applied before it kicks off, so this private segment must already not be in the set of merging segments\n\n        break;\n      }\n\n      // Must sync on writer here so that IW.mergeCommit is not running concurrently, so that if we exit, we know mergeCommit will succeed\n      // in pulling all our delGens into a merge:\n      synchronized (writer) {\n        long mergeGenCur = writer.mergeFinishedGen.get();\n\n        if (mergeGenCur == mergeGenStart) {\n\n          // Must do this while still holding IW lock else a merge could finish and skip carrying over our updates:\n          \n          // Record that this packet is finished:\n          writer.bufferedUpdatesStream.finished(this);\n\n          finished = true;\n\n          // No merge finished while we were applying, so we are done!\n          break;\n        }\n      }\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", messagePrefix + \"concurrent merges finished; move to next iter\");\n      }\n        \n      // A merge completed while we were running.  In this case, that merge may have picked up some of the updates we did, but not\n      // necessarily all of them, so we cycle again, re-applying all our updates to the newly merged segment.\n\n      iter++;\n    }\n\n    if (finished == false) {\n      // Record that this packet is finished:\n      writer.bufferedUpdatesStream.finished(this);\n    }\n        \n    if (infoStream.isEnabled(\"BD\")) {\n      String message = String.format(Locale.ROOT,\n                                     \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                     this, totalSegmentCount, totalDelCount, (System.nanoTime() - startNS) / 1000000000.);\n      if (iter > 0) {\n        message += \"; \" + (iter+1) + \" iters due to concurrent merges\";\n      }\n      message += \"; \" + writer.bufferedUpdatesStream.getPendingUpdatesCount() + \" packets remain\";\n      infoStream.message(\"BD\", message);\n    }\n  }\n\n","bugFix":["f4363cd33f6eff7fb4753574a441e2d18c1022a4"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1926100d9b67becc9701c54266fee3ba7878a5f0","date":1524472150,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates#apply(IndexWriter).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates#apply(IndexWriter).mjava","sourceNew":"  /** Translates a frozen packet of delete term/query, or doc values\n   *  updates, into their actual docIDs in the index, and applies the change.  This is a heavy\n   *  operation and is done concurrently by incoming indexing threads. */\n  @SuppressWarnings(\"try\")\n  public synchronized void apply(IndexWriter writer) throws IOException {\n    if (applied.getCount() == 0) {\n      // already done\n      return;\n    }\n\n    long startNS = System.nanoTime();\n\n    assert any();\n\n    Set<SegmentCommitInfo> seenSegments = new HashSet<>();\n\n    int iter = 0;\n    int totalSegmentCount = 0;\n    long totalDelCount = 0;\n\n    boolean finished = false;\n\n    // Optimistic concurrency: assume we are free to resolve the deletes against all current segments in the index, despite that\n    // concurrent merges are running.  Once we are done, we check to see if a merge completed while we were running.  If so, we must retry\n    // resolving against the newly merged segment(s).  Eventually no merge finishes while we were running and we are done.\n    while (true) {\n      String messagePrefix;\n      if (iter == 0) {\n        messagePrefix = \"\";\n      } else {\n        messagePrefix = \"iter \" + iter;\n      }\n\n      long iterStartNS = System.nanoTime();\n\n      long mergeGenStart = writer.mergeFinishedGen.get();\n\n      Set<String> delFiles = new HashSet<>();\n      BufferedUpdatesStream.SegmentState[] segStates;\n\n      synchronized (writer) {\n        List<SegmentCommitInfo> infos = getInfosToApply(writer);\n        if (infos == null) {\n          break;\n        }\n\n        for (SegmentCommitInfo info : infos) {\n          delFiles.addAll(info.files());\n        }\n\n        // Must open while holding IW lock so that e.g. segments are not merged\n        // away, dropped from 100% deletions, etc., before we can open the readers\n        segStates = writer.bufferedUpdatesStream.openSegmentStates(infos, seenSegments, delGen());\n\n        if (segStates.length == 0) {\n\n          if (infoStream.isEnabled(\"BD\")) {\n            infoStream.message(\"BD\", \"packet matches no segments\");\n          }\n          break;\n        }\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                                 messagePrefix + \"now apply del packet (%s) to %d segments, mergeGen %d\",\n                                                 this, segStates.length, mergeGenStart));\n        }\n\n        totalSegmentCount += segStates.length;\n\n        // Important, else IFD may try to delete our files while we are still using them,\n        // if e.g. a merge finishes on some of the segments we are resolving on:\n        writer.deleter.incRef(delFiles);\n      }\n\n      AtomicBoolean success = new AtomicBoolean();\n      long delCount;\n      try (Closeable finalizer = () -> finishApply(writer, segStates, success.get(), delFiles)) {\n        // don't hold IW monitor lock here so threads are free concurrently resolve deletes/updates:\n        delCount = apply(segStates);\n        success.set(true);\n      }\n\n      // Since we just resolved some more deletes/updates, now is a good time to write them:\n      writer.writeSomeDocValuesUpdates();\n\n      // It's OK to add this here, even if the while loop retries, because delCount only includes newly\n      // deleted documents, on the segments we didn't already do in previous iterations:\n      totalDelCount += delCount;\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                               messagePrefix + \"done inner apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                               this, segStates.length, delCount, (System.nanoTime() - iterStartNS) / 1000000000.));\n      }\n      if (privateSegment != null) {\n        // No need to retry for a segment-private packet: the merge that folds in our private segment already waits for all deletes to\n        // be applied before it kicks off, so this private segment must already not be in the set of merging segments\n\n        break;\n      }\n\n      // Must sync on writer here so that IW.mergeCommit is not running concurrently, so that if we exit, we know mergeCommit will succeed\n      // in pulling all our delGens into a merge:\n      synchronized (writer) {\n        long mergeGenCur = writer.mergeFinishedGen.get();\n\n        if (mergeGenCur == mergeGenStart) {\n\n          // Must do this while still holding IW lock else a merge could finish and skip carrying over our updates:\n          \n          // Record that this packet is finished:\n          writer.bufferedUpdatesStream.finished(this);\n\n          finished = true;\n\n          // No merge finished while we were applying, so we are done!\n          break;\n        }\n      }\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", messagePrefix + \"concurrent merges finished; move to next iter\");\n      }\n        \n      // A merge completed while we were running.  In this case, that merge may have picked up some of the updates we did, but not\n      // necessarily all of them, so we cycle again, re-applying all our updates to the newly merged segment.\n\n      iter++;\n    }\n\n    if (finished == false) {\n      // Record that this packet is finished:\n      writer.bufferedUpdatesStream.finished(this);\n    }\n        \n    if (infoStream.isEnabled(\"BD\")) {\n      String message = String.format(Locale.ROOT,\n                                     \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                     this, totalSegmentCount, totalDelCount, (System.nanoTime() - startNS) / 1000000000.);\n      if (iter > 0) {\n        message += \"; \" + (iter+1) + \" iters due to concurrent merges\";\n      }\n      message += \"; \" + writer.bufferedUpdatesStream.getPendingUpdatesCount() + \" packets remain\";\n      infoStream.message(\"BD\", message);\n    }\n  }\n\n","sourceOld":"  /** Translates a frozen packet of delete term/query, or doc values\n   *  updates, into their actual docIDs in the index, and applies the change.  This is a heavy\n   *  operation and is done concurrently by incoming indexing threads. */\n  @SuppressWarnings(\"try\")\n  public synchronized void apply(IndexWriter writer) throws IOException {\n    if (applied.getCount() == 0) {\n      // already done\n      return;\n    }\n\n    long startNS = System.nanoTime();\n\n    assert any();\n\n    Set<SegmentCommitInfo> seenSegments = new HashSet<>();\n\n    int iter = 0;\n    int totalSegmentCount = 0;\n    long totalDelCount = 0;\n\n    boolean finished = false;\n\n    // Optimistic concurrency: assume we are free to resolve the deletes against all current segments in the index, despite that\n    // concurrent merges are running.  Once we are done, we check to see if a merge completed while we were running.  If so, we must retry\n    // resolving against the newly merged segment(s).  Eventually no merge finishes while we were running and we are done.\n    while (true) {\n      String messagePrefix;\n      if (iter == 0) {\n        messagePrefix = \"\";\n      } else {\n        messagePrefix = \"iter \" + iter;\n      }\n\n      long iterStartNS = System.nanoTime();\n\n      long mergeGenStart = writer.mergeFinishedGen.get();\n\n      Set<String> delFiles = new HashSet<>();\n      BufferedUpdatesStream.SegmentState[] segStates;\n\n      synchronized (writer) {\n        List<SegmentCommitInfo> infos = getInfosToApply(writer);\n        if (infos == null) {\n          break;\n        }\n\n        for (SegmentCommitInfo info : infos) {\n          delFiles.addAll(info.files());\n        }\n\n        // Must open while holding IW lock so that e.g. segments are not merged\n        // away, dropped from 100% deletions, etc., before we can open the readers\n        segStates = writer.bufferedUpdatesStream.openSegmentStates(writer.readerPool, infos, seenSegments, delGen());\n\n        if (segStates.length == 0) {\n\n          if (infoStream.isEnabled(\"BD\")) {\n            infoStream.message(\"BD\", \"packet matches no segments\");\n          }\n          break;\n        }\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                                 messagePrefix + \"now apply del packet (%s) to %d segments, mergeGen %d\",\n                                                 this, segStates.length, mergeGenStart));\n        }\n\n        totalSegmentCount += segStates.length;\n\n        // Important, else IFD may try to delete our files while we are still using them,\n        // if e.g. a merge finishes on some of the segments we are resolving on:\n        writer.deleter.incRef(delFiles);\n      }\n\n      AtomicBoolean success = new AtomicBoolean();\n      long delCount;\n      try (Closeable finalizer = () -> finishApply(writer, segStates, success.get(), delFiles)) {\n        // don't hold IW monitor lock here so threads are free concurrently resolve deletes/updates:\n        delCount = apply(segStates);\n        success.set(true);\n      }\n\n      // Since we jus resolved some more deletes/updates, now is a good time to write them:\n      writer.readerPool.writeSomeDocValuesUpdates();\n\n      // It's OK to add this here, even if the while loop retries, because delCount only includes newly\n      // deleted documents, on the segments we didn't already do in previous iterations:\n      totalDelCount += delCount;\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                               messagePrefix + \"done inner apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                               this, segStates.length, delCount, (System.nanoTime() - iterStartNS) / 1000000000.));\n      }\n      if (privateSegment != null) {\n        // No need to retry for a segment-private packet: the merge that folds in our private segment already waits for all deletes to\n        // be applied before it kicks off, so this private segment must already not be in the set of merging segments\n\n        break;\n      }\n\n      // Must sync on writer here so that IW.mergeCommit is not running concurrently, so that if we exit, we know mergeCommit will succeed\n      // in pulling all our delGens into a merge:\n      synchronized (writer) {\n        long mergeGenCur = writer.mergeFinishedGen.get();\n\n        if (mergeGenCur == mergeGenStart) {\n\n          // Must do this while still holding IW lock else a merge could finish and skip carrying over our updates:\n          \n          // Record that this packet is finished:\n          writer.bufferedUpdatesStream.finished(this);\n\n          finished = true;\n\n          // No merge finished while we were applying, so we are done!\n          break;\n        }\n      }\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", messagePrefix + \"concurrent merges finished; move to next iter\");\n      }\n        \n      // A merge completed while we were running.  In this case, that merge may have picked up some of the updates we did, but not\n      // necessarily all of them, so we cycle again, re-applying all our updates to the newly merged segment.\n\n      iter++;\n    }\n\n    if (finished == false) {\n      // Record that this packet is finished:\n      writer.bufferedUpdatesStream.finished(this);\n    }\n        \n    if (infoStream.isEnabled(\"BD\")) {\n      String message = String.format(Locale.ROOT,\n                                     \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                     this, totalSegmentCount, totalDelCount, (System.nanoTime() - startNS) / 1000000000.);\n      if (iter > 0) {\n        message += \"; \" + (iter+1) + \" iters due to concurrent merges\";\n      }\n      message += \"; \" + writer.bufferedUpdatesStream.getPendingUpdatesCount() + \" packets remain\";\n      infoStream.message(\"BD\", message);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"86a2e8a56b368d37ef3ba7180541fa317d6fd6c7","date":1524496660,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates#apply(IndexWriter).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates#apply(IndexWriter).mjava","sourceNew":"  /** Translates a frozen packet of delete term/query, or doc values\n   *  updates, into their actual docIDs in the index, and applies the change.  This is a heavy\n   *  operation and is done concurrently by incoming indexing threads. */\n  @SuppressWarnings(\"try\")\n  public synchronized void apply(IndexWriter writer) throws IOException {\n    if (applied.getCount() == 0) {\n      // already done\n      return;\n    }\n\n    long startNS = System.nanoTime();\n\n    assert any();\n\n    Set<SegmentCommitInfo> seenSegments = new HashSet<>();\n\n    int iter = 0;\n    int totalSegmentCount = 0;\n    long totalDelCount = 0;\n\n    boolean finished = false;\n\n    // Optimistic concurrency: assume we are free to resolve the deletes against all current segments in the index, despite that\n    // concurrent merges are running.  Once we are done, we check to see if a merge completed while we were running.  If so, we must retry\n    // resolving against the newly merged segment(s).  Eventually no merge finishes while we were running and we are done.\n    while (true) {\n      String messagePrefix;\n      if (iter == 0) {\n        messagePrefix = \"\";\n      } else {\n        messagePrefix = \"iter \" + iter;\n      }\n\n      long iterStartNS = System.nanoTime();\n\n      long mergeGenStart = writer.mergeFinishedGen.get();\n\n      Set<String> delFiles = new HashSet<>();\n      BufferedUpdatesStream.SegmentState[] segStates;\n\n      synchronized (writer) {\n        List<SegmentCommitInfo> infos = getInfosToApply(writer);\n        if (infos == null) {\n          break;\n        }\n\n        for (SegmentCommitInfo info : infos) {\n          delFiles.addAll(info.files());\n        }\n\n        // Must open while holding IW lock so that e.g. segments are not merged\n        // away, dropped from 100% deletions, etc., before we can open the readers\n        segStates = openSegmentStates(writer, infos, seenSegments, delGen());\n\n        if (segStates.length == 0) {\n\n          if (infoStream.isEnabled(\"BD\")) {\n            infoStream.message(\"BD\", \"packet matches no segments\");\n          }\n          break;\n        }\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                                 messagePrefix + \"now apply del packet (%s) to %d segments, mergeGen %d\",\n                                                 this, segStates.length, mergeGenStart));\n        }\n\n        totalSegmentCount += segStates.length;\n\n        // Important, else IFD may try to delete our files while we are still using them,\n        // if e.g. a merge finishes on some of the segments we are resolving on:\n        writer.deleter.incRef(delFiles);\n      }\n\n      AtomicBoolean success = new AtomicBoolean();\n      long delCount;\n      try (Closeable finalizer = () -> finishApply(writer, segStates, success.get(), delFiles)) {\n        // don't hold IW monitor lock here so threads are free concurrently resolve deletes/updates:\n        delCount = apply(segStates);\n        success.set(true);\n      }\n\n      // Since we just resolved some more deletes/updates, now is a good time to write them:\n      writer.writeSomeDocValuesUpdates();\n\n      // It's OK to add this here, even if the while loop retries, because delCount only includes newly\n      // deleted documents, on the segments we didn't already do in previous iterations:\n      totalDelCount += delCount;\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                               messagePrefix + \"done inner apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                               this, segStates.length, delCount, (System.nanoTime() - iterStartNS) / 1000000000.));\n      }\n      if (privateSegment != null) {\n        // No need to retry for a segment-private packet: the merge that folds in our private segment already waits for all deletes to\n        // be applied before it kicks off, so this private segment must already not be in the set of merging segments\n\n        break;\n      }\n\n      // Must sync on writer here so that IW.mergeCommit is not running concurrently, so that if we exit, we know mergeCommit will succeed\n      // in pulling all our delGens into a merge:\n      synchronized (writer) {\n        long mergeGenCur = writer.mergeFinishedGen.get();\n\n        if (mergeGenCur == mergeGenStart) {\n\n          // Must do this while still holding IW lock else a merge could finish and skip carrying over our updates:\n          \n          // Record that this packet is finished:\n          writer.finished(this);\n\n          finished = true;\n\n          // No merge finished while we were applying, so we are done!\n          break;\n        }\n      }\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", messagePrefix + \"concurrent merges finished; move to next iter\");\n      }\n        \n      // A merge completed while we were running.  In this case, that merge may have picked up some of the updates we did, but not\n      // necessarily all of them, so we cycle again, re-applying all our updates to the newly merged segment.\n\n      iter++;\n    }\n\n    if (finished == false) {\n      // Record that this packet is finished:\n      writer.finished(this);\n    }\n        \n    if (infoStream.isEnabled(\"BD\")) {\n      String message = String.format(Locale.ROOT,\n                                     \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                     this, totalSegmentCount, totalDelCount, (System.nanoTime() - startNS) / 1000000000.);\n      if (iter > 0) {\n        message += \"; \" + (iter+1) + \" iters due to concurrent merges\";\n      }\n      message += \"; \" + writer.getPendingUpdatesCount() + \" packets remain\";\n      infoStream.message(\"BD\", message);\n    }\n  }\n\n","sourceOld":"  /** Translates a frozen packet of delete term/query, or doc values\n   *  updates, into their actual docIDs in the index, and applies the change.  This is a heavy\n   *  operation and is done concurrently by incoming indexing threads. */\n  @SuppressWarnings(\"try\")\n  public synchronized void apply(IndexWriter writer) throws IOException {\n    if (applied.getCount() == 0) {\n      // already done\n      return;\n    }\n\n    long startNS = System.nanoTime();\n\n    assert any();\n\n    Set<SegmentCommitInfo> seenSegments = new HashSet<>();\n\n    int iter = 0;\n    int totalSegmentCount = 0;\n    long totalDelCount = 0;\n\n    boolean finished = false;\n\n    // Optimistic concurrency: assume we are free to resolve the deletes against all current segments in the index, despite that\n    // concurrent merges are running.  Once we are done, we check to see if a merge completed while we were running.  If so, we must retry\n    // resolving against the newly merged segment(s).  Eventually no merge finishes while we were running and we are done.\n    while (true) {\n      String messagePrefix;\n      if (iter == 0) {\n        messagePrefix = \"\";\n      } else {\n        messagePrefix = \"iter \" + iter;\n      }\n\n      long iterStartNS = System.nanoTime();\n\n      long mergeGenStart = writer.mergeFinishedGen.get();\n\n      Set<String> delFiles = new HashSet<>();\n      BufferedUpdatesStream.SegmentState[] segStates;\n\n      synchronized (writer) {\n        List<SegmentCommitInfo> infos = getInfosToApply(writer);\n        if (infos == null) {\n          break;\n        }\n\n        for (SegmentCommitInfo info : infos) {\n          delFiles.addAll(info.files());\n        }\n\n        // Must open while holding IW lock so that e.g. segments are not merged\n        // away, dropped from 100% deletions, etc., before we can open the readers\n        segStates = writer.bufferedUpdatesStream.openSegmentStates(infos, seenSegments, delGen());\n\n        if (segStates.length == 0) {\n\n          if (infoStream.isEnabled(\"BD\")) {\n            infoStream.message(\"BD\", \"packet matches no segments\");\n          }\n          break;\n        }\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                                 messagePrefix + \"now apply del packet (%s) to %d segments, mergeGen %d\",\n                                                 this, segStates.length, mergeGenStart));\n        }\n\n        totalSegmentCount += segStates.length;\n\n        // Important, else IFD may try to delete our files while we are still using them,\n        // if e.g. a merge finishes on some of the segments we are resolving on:\n        writer.deleter.incRef(delFiles);\n      }\n\n      AtomicBoolean success = new AtomicBoolean();\n      long delCount;\n      try (Closeable finalizer = () -> finishApply(writer, segStates, success.get(), delFiles)) {\n        // don't hold IW monitor lock here so threads are free concurrently resolve deletes/updates:\n        delCount = apply(segStates);\n        success.set(true);\n      }\n\n      // Since we just resolved some more deletes/updates, now is a good time to write them:\n      writer.writeSomeDocValuesUpdates();\n\n      // It's OK to add this here, even if the while loop retries, because delCount only includes newly\n      // deleted documents, on the segments we didn't already do in previous iterations:\n      totalDelCount += delCount;\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                               messagePrefix + \"done inner apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                               this, segStates.length, delCount, (System.nanoTime() - iterStartNS) / 1000000000.));\n      }\n      if (privateSegment != null) {\n        // No need to retry for a segment-private packet: the merge that folds in our private segment already waits for all deletes to\n        // be applied before it kicks off, so this private segment must already not be in the set of merging segments\n\n        break;\n      }\n\n      // Must sync on writer here so that IW.mergeCommit is not running concurrently, so that if we exit, we know mergeCommit will succeed\n      // in pulling all our delGens into a merge:\n      synchronized (writer) {\n        long mergeGenCur = writer.mergeFinishedGen.get();\n\n        if (mergeGenCur == mergeGenStart) {\n\n          // Must do this while still holding IW lock else a merge could finish and skip carrying over our updates:\n          \n          // Record that this packet is finished:\n          writer.bufferedUpdatesStream.finished(this);\n\n          finished = true;\n\n          // No merge finished while we were applying, so we are done!\n          break;\n        }\n      }\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", messagePrefix + \"concurrent merges finished; move to next iter\");\n      }\n        \n      // A merge completed while we were running.  In this case, that merge may have picked up some of the updates we did, but not\n      // necessarily all of them, so we cycle again, re-applying all our updates to the newly merged segment.\n\n      iter++;\n    }\n\n    if (finished == false) {\n      // Record that this packet is finished:\n      writer.bufferedUpdatesStream.finished(this);\n    }\n        \n    if (infoStream.isEnabled(\"BD\")) {\n      String message = String.format(Locale.ROOT,\n                                     \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                     this, totalSegmentCount, totalDelCount, (System.nanoTime() - startNS) / 1000000000.);\n      if (iter > 0) {\n        message += \"; \" + (iter+1) + \" iters due to concurrent merges\";\n      }\n      message += \"; \" + writer.bufferedUpdatesStream.getPendingUpdatesCount() + \" packets remain\";\n      infoStream.message(\"BD\", message);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"72332a99ce230f8edf8404d6043ac18a0e26dfeb","date":1542806419,"type":4,"author":"Simon Willnauer","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/index/FrozenBufferedUpdates#apply(IndexWriter).mjava","sourceNew":null,"sourceOld":"  /** Translates a frozen packet of delete term/query, or doc values\n   *  updates, into their actual docIDs in the index, and applies the change.  This is a heavy\n   *  operation and is done concurrently by incoming indexing threads. */\n  @SuppressWarnings(\"try\")\n  public synchronized void apply(IndexWriter writer) throws IOException {\n    if (applied.getCount() == 0) {\n      // already done\n      return;\n    }\n\n    long startNS = System.nanoTime();\n\n    assert any();\n\n    Set<SegmentCommitInfo> seenSegments = new HashSet<>();\n\n    int iter = 0;\n    int totalSegmentCount = 0;\n    long totalDelCount = 0;\n\n    boolean finished = false;\n\n    // Optimistic concurrency: assume we are free to resolve the deletes against all current segments in the index, despite that\n    // concurrent merges are running.  Once we are done, we check to see if a merge completed while we were running.  If so, we must retry\n    // resolving against the newly merged segment(s).  Eventually no merge finishes while we were running and we are done.\n    while (true) {\n      String messagePrefix;\n      if (iter == 0) {\n        messagePrefix = \"\";\n      } else {\n        messagePrefix = \"iter \" + iter;\n      }\n\n      long iterStartNS = System.nanoTime();\n\n      long mergeGenStart = writer.mergeFinishedGen.get();\n\n      Set<String> delFiles = new HashSet<>();\n      BufferedUpdatesStream.SegmentState[] segStates;\n\n      synchronized (writer) {\n        List<SegmentCommitInfo> infos = getInfosToApply(writer);\n        if (infos == null) {\n          break;\n        }\n\n        for (SegmentCommitInfo info : infos) {\n          delFiles.addAll(info.files());\n        }\n\n        // Must open while holding IW lock so that e.g. segments are not merged\n        // away, dropped from 100% deletions, etc., before we can open the readers\n        segStates = openSegmentStates(writer, infos, seenSegments, delGen());\n\n        if (segStates.length == 0) {\n\n          if (infoStream.isEnabled(\"BD\")) {\n            infoStream.message(\"BD\", \"packet matches no segments\");\n          }\n          break;\n        }\n\n        if (infoStream.isEnabled(\"BD\")) {\n          infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                                 messagePrefix + \"now apply del packet (%s) to %d segments, mergeGen %d\",\n                                                 this, segStates.length, mergeGenStart));\n        }\n\n        totalSegmentCount += segStates.length;\n\n        // Important, else IFD may try to delete our files while we are still using them,\n        // if e.g. a merge finishes on some of the segments we are resolving on:\n        writer.deleter.incRef(delFiles);\n      }\n\n      AtomicBoolean success = new AtomicBoolean();\n      long delCount;\n      try (Closeable finalizer = () -> finishApply(writer, segStates, success.get(), delFiles)) {\n        // don't hold IW monitor lock here so threads are free concurrently resolve deletes/updates:\n        delCount = apply(segStates);\n        success.set(true);\n      }\n\n      // Since we just resolved some more deletes/updates, now is a good time to write them:\n      writer.writeSomeDocValuesUpdates();\n\n      // It's OK to add this here, even if the while loop retries, because delCount only includes newly\n      // deleted documents, on the segments we didn't already do in previous iterations:\n      totalDelCount += delCount;\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", String.format(Locale.ROOT,\n                                               messagePrefix + \"done inner apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                               this, segStates.length, delCount, (System.nanoTime() - iterStartNS) / 1000000000.));\n      }\n      if (privateSegment != null) {\n        // No need to retry for a segment-private packet: the merge that folds in our private segment already waits for all deletes to\n        // be applied before it kicks off, so this private segment must already not be in the set of merging segments\n\n        break;\n      }\n\n      // Must sync on writer here so that IW.mergeCommit is not running concurrently, so that if we exit, we know mergeCommit will succeed\n      // in pulling all our delGens into a merge:\n      synchronized (writer) {\n        long mergeGenCur = writer.mergeFinishedGen.get();\n\n        if (mergeGenCur == mergeGenStart) {\n\n          // Must do this while still holding IW lock else a merge could finish and skip carrying over our updates:\n          \n          // Record that this packet is finished:\n          writer.finished(this);\n\n          finished = true;\n\n          // No merge finished while we were applying, so we are done!\n          break;\n        }\n      }\n\n      if (infoStream.isEnabled(\"BD\")) {\n        infoStream.message(\"BD\", messagePrefix + \"concurrent merges finished; move to next iter\");\n      }\n        \n      // A merge completed while we were running.  In this case, that merge may have picked up some of the updates we did, but not\n      // necessarily all of them, so we cycle again, re-applying all our updates to the newly merged segment.\n\n      iter++;\n    }\n\n    if (finished == false) {\n      // Record that this packet is finished:\n      writer.finished(this);\n    }\n        \n    if (infoStream.isEnabled(\"BD\")) {\n      String message = String.format(Locale.ROOT,\n                                     \"done apply del packet (%s) to %d segments; %d new deletes/updates; took %.3f sec\",\n                                     this, totalSegmentCount, totalDelCount, (System.nanoTime() - startNS) / 1000000000.);\n      if (iter > 0) {\n        message += \"; \" + (iter+1) + \" iters due to concurrent merges\";\n      }\n      message += \"; \" + writer.getPendingUpdatesCount() + \" packets remain\";\n      infoStream.message(\"BD\", message);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"6815b5b5d6334b2245dd7be2f8b6cca949bf7f43":["636c73dfa97dd282a3089d4239620475f2633519","14d66d86a8b184a86bcaebcf6e15fcef486e0876"],"86a2e8a56b368d37ef3ba7180541fa317d6fd6c7":["1926100d9b67becc9701c54266fee3ba7878a5f0"],"f4363cd33f6eff7fb4753574a441e2d18c1022a4":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"30c8e5574b55d57947e989443dfde611646530ee":["b7dfa64bc2074fb87d0ca70095a644c1ead107e1","636c73dfa97dd282a3089d4239620475f2633519"],"1926100d9b67becc9701c54266fee3ba7878a5f0":["15e716649e2bd79a98b5e68c464154ea4c44677a"],"72332a99ce230f8edf8404d6043ac18a0e26dfeb":["86a2e8a56b368d37ef3ba7180541fa317d6fd6c7"],"b4a1e501646d5889b8128849329c2e6e52fc3615":["28288370235ed02234a64753cdbf0c6ec096304a"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","f4363cd33f6eff7fb4753574a441e2d18c1022a4"],"28288370235ed02234a64753cdbf0c6ec096304a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","f4363cd33f6eff7fb4753574a441e2d18c1022a4"],"636c73dfa97dd282a3089d4239620475f2633519":["b4a1e501646d5889b8128849329c2e6e52fc3615"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"15e716649e2bd79a98b5e68c464154ea4c44677a":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43"],"6324f236dd5a5430f2ff91ebd6cb3f0ae8d34a35":["b4a1e501646d5889b8128849329c2e6e52fc3615","636c73dfa97dd282a3089d4239620475f2633519"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["72332a99ce230f8edf8404d6043ac18a0e26dfeb"],"14d66d86a8b184a86bcaebcf6e15fcef486e0876":["636c73dfa97dd282a3089d4239620475f2633519"]},"commit2Childs":{"6815b5b5d6334b2245dd7be2f8b6cca949bf7f43":["15e716649e2bd79a98b5e68c464154ea4c44677a"],"86a2e8a56b368d37ef3ba7180541fa317d6fd6c7":["72332a99ce230f8edf8404d6043ac18a0e26dfeb"],"f4363cd33f6eff7fb4753574a441e2d18c1022a4":["b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a"],"30c8e5574b55d57947e989443dfde611646530ee":[],"1926100d9b67becc9701c54266fee3ba7878a5f0":["86a2e8a56b368d37ef3ba7180541fa317d6fd6c7"],"72332a99ce230f8edf8404d6043ac18a0e26dfeb":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"b4a1e501646d5889b8128849329c2e6e52fc3615":["636c73dfa97dd282a3089d4239620475f2633519","6324f236dd5a5430f2ff91ebd6cb3f0ae8d34a35"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":["30c8e5574b55d57947e989443dfde611646530ee"],"28288370235ed02234a64753cdbf0c6ec096304a":["b4a1e501646d5889b8128849329c2e6e52fc3615"],"636c73dfa97dd282a3089d4239620475f2633519":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43","30c8e5574b55d57947e989443dfde611646530ee","6324f236dd5a5430f2ff91ebd6cb3f0ae8d34a35","14d66d86a8b184a86bcaebcf6e15fcef486e0876"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["f4363cd33f6eff7fb4753574a441e2d18c1022a4","b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a"],"15e716649e2bd79a98b5e68c464154ea4c44677a":["1926100d9b67becc9701c54266fee3ba7878a5f0"],"6324f236dd5a5430f2ff91ebd6cb3f0ae8d34a35":[],"14d66d86a8b184a86bcaebcf6e15fcef486e0876":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["30c8e5574b55d57947e989443dfde611646530ee","6324f236dd5a5430f2ff91ebd6cb3f0ae8d34a35","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}