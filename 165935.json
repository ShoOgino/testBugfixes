{"path":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#slowGrouping(GroupDoc[],String,boolean,boolean,Sort,Sort,int,int,int,int).mjava","commits":[{"id":"1d3f7ab1a502671bbdb03bcced21e764d2483221","date":1532329609,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#slowGrouping(GroupDoc[],String,boolean,boolean,Sort,Sort,int,int,int,int).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#slowGrouping(GroupDoc[],String,boolean,boolean,boolean,Sort,Sort,int,int,int,int).mjava","sourceNew":"  private TopGroups<BytesRef> slowGrouping(GroupDoc[] groupDocs,\n                                           String searchTerm,\n                                           boolean getMaxScores,\n                                           boolean doAllGroups,\n                                           Sort groupSort,\n                                           Sort docSort,\n                                           int topNGroups,\n                                           int docsPerGroup,\n                                           int groupOffset,\n                                           int docOffset) {\n\n    final Comparator<GroupDoc> groupSortComp = getComparator(groupSort);\n\n    Arrays.sort(groupDocs, groupSortComp);\n    final HashMap<BytesRef,List<GroupDoc>> groups = new HashMap<>();\n    final List<BytesRef> sortedGroups = new ArrayList<>();\n    final List<Comparable<?>[]> sortedGroupFields = new ArrayList<>();\n\n    int totalHitCount = 0;\n    Set<BytesRef> knownGroups = new HashSet<>();\n\n    //System.out.println(\"TEST: slowGrouping\");\n    for(GroupDoc d : groupDocs) {\n      // TODO: would be better to filter by searchTerm before sorting!\n      if (!d.content.startsWith(searchTerm)) {\n        continue;\n      }\n      totalHitCount++;\n      //System.out.println(\"  match id=\" + d.id + \" score=\" + d.score);\n\n      if (doAllGroups) {\n        if (!knownGroups.contains(d.group)) {\n          knownGroups.add(d.group);\n          //System.out.println(\"    add group=\" + groupToString(d.group));\n        }\n      }\n\n      List<GroupDoc> l = groups.get(d.group);\n      if (l == null) {\n        //System.out.println(\"    add sortedGroup=\" + groupToString(d.group));\n        sortedGroups.add(d.group);\n        sortedGroupFields.add(fillFields(d, groupSort));\n        l = new ArrayList<>();\n        groups.put(d.group, l);\n      }\n      l.add(d);\n    }\n\n    if (groupOffset >= sortedGroups.size()) {\n      // slice is out of bounds\n      return null;\n    }\n\n    final int limit = Math.min(groupOffset + topNGroups, groups.size());\n\n    final Comparator<GroupDoc> docSortComp = getComparator(docSort);\n    @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n    final GroupDocs<BytesRef>[] result = new GroupDocs[limit-groupOffset];\n    int totalGroupedHitCount = 0;\n    for(int idx=groupOffset;idx < limit;idx++) {\n      final BytesRef group = sortedGroups.get(idx);\n      final List<GroupDoc> docs = groups.get(group);\n      totalGroupedHitCount += docs.size();\n      Collections.sort(docs, docSortComp);\n      final ScoreDoc[] hits;\n      if (docs.size() > docOffset) {\n        final int docIDXLimit = Math.min(docOffset + docsPerGroup, docs.size());\n        hits = new ScoreDoc[docIDXLimit - docOffset];\n        for(int docIDX=docOffset; docIDX < docIDXLimit; docIDX++) {\n          final GroupDoc d = docs.get(docIDX);\n          final FieldDoc fd;\n          fd = new FieldDoc(d.id, Float.NaN, fillFields(d, docSort));\n          hits[docIDX-docOffset] = fd;\n        }\n      } else  {\n        hits = new ScoreDoc[0];\n      }\n\n      result[idx-groupOffset] = new GroupDocs<>(Float.NaN,\n                                                        0.0f,\n                                                        docs.size(),\n                                                        hits,\n                                                        group,\n                                                        sortedGroupFields.get(idx));\n    }\n\n    if (doAllGroups) {\n      return new TopGroups<>(\n        new TopGroups<>(groupSort.getSort(), docSort.getSort(), totalHitCount, totalGroupedHitCount, result, Float.NaN),\n          knownGroups.size()\n      );\n    } else {\n      return new TopGroups<>(groupSort.getSort(), docSort.getSort(), totalHitCount, totalGroupedHitCount, result, Float.NaN);\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> slowGrouping(GroupDoc[] groupDocs,\n                                           String searchTerm,\n                                           boolean getScores,\n                                           boolean getMaxScores,\n                                           boolean doAllGroups,\n                                           Sort groupSort,\n                                           Sort docSort,\n                                           int topNGroups,\n                                           int docsPerGroup,\n                                           int groupOffset,\n                                           int docOffset) {\n\n    final Comparator<GroupDoc> groupSortComp = getComparator(groupSort);\n\n    Arrays.sort(groupDocs, groupSortComp);\n    final HashMap<BytesRef,List<GroupDoc>> groups = new HashMap<>();\n    final List<BytesRef> sortedGroups = new ArrayList<>();\n    final List<Comparable<?>[]> sortedGroupFields = new ArrayList<>();\n\n    int totalHitCount = 0;\n    Set<BytesRef> knownGroups = new HashSet<>();\n\n    //System.out.println(\"TEST: slowGrouping\");\n    for(GroupDoc d : groupDocs) {\n      // TODO: would be better to filter by searchTerm before sorting!\n      if (!d.content.startsWith(searchTerm)) {\n        continue;\n      }\n      totalHitCount++;\n      //System.out.println(\"  match id=\" + d.id + \" score=\" + d.score);\n\n      if (doAllGroups) {\n        if (!knownGroups.contains(d.group)) {\n          knownGroups.add(d.group);\n          //System.out.println(\"    add group=\" + groupToString(d.group));\n        }\n      }\n\n      List<GroupDoc> l = groups.get(d.group);\n      if (l == null) {\n        //System.out.println(\"    add sortedGroup=\" + groupToString(d.group));\n        sortedGroups.add(d.group);\n        sortedGroupFields.add(fillFields(d, groupSort));\n        l = new ArrayList<>();\n        groups.put(d.group, l);\n      }\n      l.add(d);\n    }\n\n    if (groupOffset >= sortedGroups.size()) {\n      // slice is out of bounds\n      return null;\n    }\n\n    final int limit = Math.min(groupOffset + topNGroups, groups.size());\n\n    final Comparator<GroupDoc> docSortComp = getComparator(docSort);\n    @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n    final GroupDocs<BytesRef>[] result = new GroupDocs[limit-groupOffset];\n    int totalGroupedHitCount = 0;\n    for(int idx=groupOffset;idx < limit;idx++) {\n      final BytesRef group = sortedGroups.get(idx);\n      final List<GroupDoc> docs = groups.get(group);\n      totalGroupedHitCount += docs.size();\n      Collections.sort(docs, docSortComp);\n      final ScoreDoc[] hits;\n      if (docs.size() > docOffset) {\n        final int docIDXLimit = Math.min(docOffset + docsPerGroup, docs.size());\n        hits = new ScoreDoc[docIDXLimit - docOffset];\n        for(int docIDX=docOffset; docIDX < docIDXLimit; docIDX++) {\n          final GroupDoc d = docs.get(docIDX);\n          final FieldDoc fd;\n          fd = new FieldDoc(d.id, getScores ? d.score : Float.NaN, fillFields(d, docSort));\n          hits[docIDX-docOffset] = fd;\n        }\n      } else  {\n        hits = new ScoreDoc[0];\n      }\n\n      result[idx-groupOffset] = new GroupDocs<>(Float.NaN,\n                                                        0.0f,\n                                                        docs.size(),\n                                                        hits,\n                                                        group,\n                                                        sortedGroupFields.get(idx));\n    }\n\n    if (doAllGroups) {\n      return new TopGroups<>(\n        new TopGroups<>(groupSort.getSort(), docSort.getSort(), totalHitCount, totalGroupedHitCount, result, Float.NaN),\n          knownGroups.size()\n      );\n    } else {\n      return new TopGroups<>(groupSort.getSort(), docSort.getSort(), totalHitCount, totalGroupedHitCount, result, Float.NaN);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"83788ad129a5154d5c6562c4e8ce3db48793aada","date":1532961485,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#slowGrouping(GroupDoc[],String,boolean,boolean,Sort,Sort,int,int,int,int).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#slowGrouping(GroupDoc[],String,boolean,boolean,Sort,Sort,int,int,int,int).mjava","sourceNew":"  private TopGroups<BytesRef> slowGrouping(GroupDoc[] groupDocs,\n                                           String searchTerm,\n                                           boolean getMaxScores,\n                                           boolean doAllGroups,\n                                           Sort groupSort,\n                                           Sort docSort,\n                                           int topNGroups,\n                                           int docsPerGroup,\n                                           int groupOffset,\n                                           int docOffset) {\n\n    final Comparator<GroupDoc> groupSortComp = getComparator(groupSort);\n\n    Arrays.sort(groupDocs, groupSortComp);\n    final HashMap<BytesRef,List<GroupDoc>> groups = new HashMap<>();\n    final List<BytesRef> sortedGroups = new ArrayList<>();\n    final List<Comparable<?>[]> sortedGroupFields = new ArrayList<>();\n\n    int totalHitCount = 0;\n    Set<BytesRef> knownGroups = new HashSet<>();\n\n    //System.out.println(\"TEST: slowGrouping\");\n    for(GroupDoc d : groupDocs) {\n      // TODO: would be better to filter by searchTerm before sorting!\n      if (!d.content.startsWith(searchTerm)) {\n        continue;\n      }\n      totalHitCount++;\n      //System.out.println(\"  match id=\" + d.id + \" score=\" + d.score);\n\n      if (doAllGroups) {\n        if (!knownGroups.contains(d.group)) {\n          knownGroups.add(d.group);\n          //System.out.println(\"    add group=\" + groupToString(d.group));\n        }\n      }\n\n      List<GroupDoc> l = groups.get(d.group);\n      if (l == null) {\n        //System.out.println(\"    add sortedGroup=\" + groupToString(d.group));\n        sortedGroups.add(d.group);\n        sortedGroupFields.add(fillFields(d, groupSort));\n        l = new ArrayList<>();\n        groups.put(d.group, l);\n      }\n      l.add(d);\n    }\n\n    if (groupOffset >= sortedGroups.size()) {\n      // slice is out of bounds\n      return null;\n    }\n\n    final int limit = Math.min(groupOffset + topNGroups, groups.size());\n\n    final Comparator<GroupDoc> docSortComp = getComparator(docSort);\n    @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n    final GroupDocs<BytesRef>[] result = new GroupDocs[limit-groupOffset];\n    int totalGroupedHitCount = 0;\n    for(int idx=groupOffset;idx < limit;idx++) {\n      final BytesRef group = sortedGroups.get(idx);\n      final List<GroupDoc> docs = groups.get(group);\n      totalGroupedHitCount += docs.size();\n      Collections.sort(docs, docSortComp);\n      final ScoreDoc[] hits;\n      if (docs.size() > docOffset) {\n        final int docIDXLimit = Math.min(docOffset + docsPerGroup, docs.size());\n        hits = new ScoreDoc[docIDXLimit - docOffset];\n        for(int docIDX=docOffset; docIDX < docIDXLimit; docIDX++) {\n          final GroupDoc d = docs.get(docIDX);\n          final FieldDoc fd;\n          fd = new FieldDoc(d.id, Float.NaN, fillFields(d, docSort));\n          hits[docIDX-docOffset] = fd;\n        }\n      } else  {\n        hits = new ScoreDoc[0];\n      }\n\n      result[idx-groupOffset] = new GroupDocs<>(Float.NaN,\n                                                        0.0f,\n                                                        new TotalHits(docs.size(), TotalHits.Relation.EQUAL_TO),\n                                                        hits,\n                                                        group,\n                                                        sortedGroupFields.get(idx));\n    }\n\n    if (doAllGroups) {\n      return new TopGroups<>(\n        new TopGroups<>(groupSort.getSort(), docSort.getSort(), totalHitCount, totalGroupedHitCount, result, Float.NaN),\n          knownGroups.size()\n      );\n    } else {\n      return new TopGroups<>(groupSort.getSort(), docSort.getSort(), totalHitCount, totalGroupedHitCount, result, Float.NaN);\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> slowGrouping(GroupDoc[] groupDocs,\n                                           String searchTerm,\n                                           boolean getMaxScores,\n                                           boolean doAllGroups,\n                                           Sort groupSort,\n                                           Sort docSort,\n                                           int topNGroups,\n                                           int docsPerGroup,\n                                           int groupOffset,\n                                           int docOffset) {\n\n    final Comparator<GroupDoc> groupSortComp = getComparator(groupSort);\n\n    Arrays.sort(groupDocs, groupSortComp);\n    final HashMap<BytesRef,List<GroupDoc>> groups = new HashMap<>();\n    final List<BytesRef> sortedGroups = new ArrayList<>();\n    final List<Comparable<?>[]> sortedGroupFields = new ArrayList<>();\n\n    int totalHitCount = 0;\n    Set<BytesRef> knownGroups = new HashSet<>();\n\n    //System.out.println(\"TEST: slowGrouping\");\n    for(GroupDoc d : groupDocs) {\n      // TODO: would be better to filter by searchTerm before sorting!\n      if (!d.content.startsWith(searchTerm)) {\n        continue;\n      }\n      totalHitCount++;\n      //System.out.println(\"  match id=\" + d.id + \" score=\" + d.score);\n\n      if (doAllGroups) {\n        if (!knownGroups.contains(d.group)) {\n          knownGroups.add(d.group);\n          //System.out.println(\"    add group=\" + groupToString(d.group));\n        }\n      }\n\n      List<GroupDoc> l = groups.get(d.group);\n      if (l == null) {\n        //System.out.println(\"    add sortedGroup=\" + groupToString(d.group));\n        sortedGroups.add(d.group);\n        sortedGroupFields.add(fillFields(d, groupSort));\n        l = new ArrayList<>();\n        groups.put(d.group, l);\n      }\n      l.add(d);\n    }\n\n    if (groupOffset >= sortedGroups.size()) {\n      // slice is out of bounds\n      return null;\n    }\n\n    final int limit = Math.min(groupOffset + topNGroups, groups.size());\n\n    final Comparator<GroupDoc> docSortComp = getComparator(docSort);\n    @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n    final GroupDocs<BytesRef>[] result = new GroupDocs[limit-groupOffset];\n    int totalGroupedHitCount = 0;\n    for(int idx=groupOffset;idx < limit;idx++) {\n      final BytesRef group = sortedGroups.get(idx);\n      final List<GroupDoc> docs = groups.get(group);\n      totalGroupedHitCount += docs.size();\n      Collections.sort(docs, docSortComp);\n      final ScoreDoc[] hits;\n      if (docs.size() > docOffset) {\n        final int docIDXLimit = Math.min(docOffset + docsPerGroup, docs.size());\n        hits = new ScoreDoc[docIDXLimit - docOffset];\n        for(int docIDX=docOffset; docIDX < docIDXLimit; docIDX++) {\n          final GroupDoc d = docs.get(docIDX);\n          final FieldDoc fd;\n          fd = new FieldDoc(d.id, Float.NaN, fillFields(d, docSort));\n          hits[docIDX-docOffset] = fd;\n        }\n      } else  {\n        hits = new ScoreDoc[0];\n      }\n\n      result[idx-groupOffset] = new GroupDocs<>(Float.NaN,\n                                                        0.0f,\n                                                        docs.size(),\n                                                        hits,\n                                                        group,\n                                                        sortedGroupFields.get(idx));\n    }\n\n    if (doAllGroups) {\n      return new TopGroups<>(\n        new TopGroups<>(groupSort.getSort(), docSort.getSort(), totalHitCount, totalGroupedHitCount, result, Float.NaN),\n          knownGroups.size()\n      );\n    } else {\n      return new TopGroups<>(groupSort.getSort(), docSort.getSort(), totalHitCount, totalGroupedHitCount, result, Float.NaN);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9","date":1574619880,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#slowGrouping(GroupDoc[],String,boolean,boolean,Sort,Sort,int,int,int,int).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#slowGrouping(GroupDoc[],String,boolean,boolean,Sort,Sort,int,int,int,int).mjava","sourceNew":"  private TopGroups<BytesRef> slowGrouping(GroupDoc[] groupDocs,\n                                           String searchTerm,\n                                           boolean getMaxScores,\n                                           boolean doAllGroups,\n                                           Sort groupSort,\n                                           Sort docSort,\n                                           int topNGroups,\n                                           int docsPerGroup,\n                                           int groupOffset,\n                                           int docOffset) {\n\n    final Comparator<GroupDoc> groupSortComp = getComparator(groupSort);\n\n    Arrays.sort(groupDocs, groupSortComp);\n    final HashMap<BytesRef,List<GroupDoc>> groups = new HashMap<>();\n    final List<BytesRef> sortedGroups = new ArrayList<>();\n    final List<Comparable<?>[]> sortedGroupFields = new ArrayList<>();\n\n    int totalHitCount = 0;\n    Set<BytesRef> knownGroups = new HashSet<>();\n\n    //System.out.println(\"TEST: slowGrouping\");\n    for(GroupDoc d : groupDocs) {\n      // TODO: would be better to filter by searchTerm before sorting!\n      if (!d.content.startsWith(searchTerm)) {\n        continue;\n      }\n      totalHitCount++;\n      //System.out.println(\"  match id=\" + d.id + \" score=\" + d.score);\n\n      if (doAllGroups) {\n        if (!knownGroups.contains(d.group)) {\n          knownGroups.add(d.group);\n          //System.out.println(\"    add group=\" + groupToString(d.group));\n        }\n      }\n\n      List<GroupDoc> l = groups.get(d.group);\n      if (l == null) {\n        //System.out.println(\"    add sortedGroup=\" + groupToString(d.group));\n        sortedGroups.add(d.group);\n        sortedGroupFields.add(fillFields(d, groupSort));\n        l = new ArrayList<>();\n        groups.put(d.group, l);\n      }\n      l.add(d);\n    }\n\n    if (groupOffset >= sortedGroups.size()) {\n      // slice is out of bounds\n      return null;\n    }\n\n    final int limit = Math.min(groupOffset + topNGroups, groups.size());\n\n    final Comparator<GroupDoc> docSortComp = getComparator(docSort);\n    @SuppressWarnings({\"unchecked\"})\n    final GroupDocs<BytesRef>[] result = new GroupDocs[limit-groupOffset];\n    int totalGroupedHitCount = 0;\n    for(int idx=groupOffset;idx < limit;idx++) {\n      final BytesRef group = sortedGroups.get(idx);\n      final List<GroupDoc> docs = groups.get(group);\n      totalGroupedHitCount += docs.size();\n      Collections.sort(docs, docSortComp);\n      final ScoreDoc[] hits;\n      if (docs.size() > docOffset) {\n        final int docIDXLimit = Math.min(docOffset + docsPerGroup, docs.size());\n        hits = new ScoreDoc[docIDXLimit - docOffset];\n        for(int docIDX=docOffset; docIDX < docIDXLimit; docIDX++) {\n          final GroupDoc d = docs.get(docIDX);\n          final FieldDoc fd;\n          fd = new FieldDoc(d.id, Float.NaN, fillFields(d, docSort));\n          hits[docIDX-docOffset] = fd;\n        }\n      } else  {\n        hits = new ScoreDoc[0];\n      }\n\n      result[idx-groupOffset] = new GroupDocs<>(Float.NaN,\n                                                        0.0f,\n                                                        new TotalHits(docs.size(), TotalHits.Relation.EQUAL_TO),\n                                                        hits,\n                                                        group,\n                                                        sortedGroupFields.get(idx));\n    }\n\n    if (doAllGroups) {\n      return new TopGroups<>(\n        new TopGroups<>(groupSort.getSort(), docSort.getSort(), totalHitCount, totalGroupedHitCount, result, Float.NaN),\n          knownGroups.size()\n      );\n    } else {\n      return new TopGroups<>(groupSort.getSort(), docSort.getSort(), totalHitCount, totalGroupedHitCount, result, Float.NaN);\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> slowGrouping(GroupDoc[] groupDocs,\n                                           String searchTerm,\n                                           boolean getMaxScores,\n                                           boolean doAllGroups,\n                                           Sort groupSort,\n                                           Sort docSort,\n                                           int topNGroups,\n                                           int docsPerGroup,\n                                           int groupOffset,\n                                           int docOffset) {\n\n    final Comparator<GroupDoc> groupSortComp = getComparator(groupSort);\n\n    Arrays.sort(groupDocs, groupSortComp);\n    final HashMap<BytesRef,List<GroupDoc>> groups = new HashMap<>();\n    final List<BytesRef> sortedGroups = new ArrayList<>();\n    final List<Comparable<?>[]> sortedGroupFields = new ArrayList<>();\n\n    int totalHitCount = 0;\n    Set<BytesRef> knownGroups = new HashSet<>();\n\n    //System.out.println(\"TEST: slowGrouping\");\n    for(GroupDoc d : groupDocs) {\n      // TODO: would be better to filter by searchTerm before sorting!\n      if (!d.content.startsWith(searchTerm)) {\n        continue;\n      }\n      totalHitCount++;\n      //System.out.println(\"  match id=\" + d.id + \" score=\" + d.score);\n\n      if (doAllGroups) {\n        if (!knownGroups.contains(d.group)) {\n          knownGroups.add(d.group);\n          //System.out.println(\"    add group=\" + groupToString(d.group));\n        }\n      }\n\n      List<GroupDoc> l = groups.get(d.group);\n      if (l == null) {\n        //System.out.println(\"    add sortedGroup=\" + groupToString(d.group));\n        sortedGroups.add(d.group);\n        sortedGroupFields.add(fillFields(d, groupSort));\n        l = new ArrayList<>();\n        groups.put(d.group, l);\n      }\n      l.add(d);\n    }\n\n    if (groupOffset >= sortedGroups.size()) {\n      // slice is out of bounds\n      return null;\n    }\n\n    final int limit = Math.min(groupOffset + topNGroups, groups.size());\n\n    final Comparator<GroupDoc> docSortComp = getComparator(docSort);\n    @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n    final GroupDocs<BytesRef>[] result = new GroupDocs[limit-groupOffset];\n    int totalGroupedHitCount = 0;\n    for(int idx=groupOffset;idx < limit;idx++) {\n      final BytesRef group = sortedGroups.get(idx);\n      final List<GroupDoc> docs = groups.get(group);\n      totalGroupedHitCount += docs.size();\n      Collections.sort(docs, docSortComp);\n      final ScoreDoc[] hits;\n      if (docs.size() > docOffset) {\n        final int docIDXLimit = Math.min(docOffset + docsPerGroup, docs.size());\n        hits = new ScoreDoc[docIDXLimit - docOffset];\n        for(int docIDX=docOffset; docIDX < docIDXLimit; docIDX++) {\n          final GroupDoc d = docs.get(docIDX);\n          final FieldDoc fd;\n          fd = new FieldDoc(d.id, Float.NaN, fillFields(d, docSort));\n          hits[docIDX-docOffset] = fd;\n        }\n      } else  {\n        hits = new ScoreDoc[0];\n      }\n\n      result[idx-groupOffset] = new GroupDocs<>(Float.NaN,\n                                                        0.0f,\n                                                        new TotalHits(docs.size(), TotalHits.Relation.EQUAL_TO),\n                                                        hits,\n                                                        group,\n                                                        sortedGroupFields.get(idx));\n    }\n\n    if (doAllGroups) {\n      return new TopGroups<>(\n        new TopGroups<>(groupSort.getSort(), docSort.getSort(), totalHitCount, totalGroupedHitCount, result, Float.NaN),\n          knownGroups.size()\n      );\n    } else {\n      return new TopGroups<>(groupSort.getSort(), docSort.getSort(), totalHitCount, totalGroupedHitCount, result, Float.NaN);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bb9c3baacabd473e8ecd6c4948aabacead49b88e","date":1574700980,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#slowGrouping(GroupDoc[],String,boolean,boolean,Sort,Sort,int,int,int,int).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#slowGrouping(GroupDoc[],String,boolean,boolean,Sort,Sort,int,int,int,int).mjava","sourceNew":"  private TopGroups<BytesRef> slowGrouping(GroupDoc[] groupDocs,\n                                           String searchTerm,\n                                           boolean getMaxScores,\n                                           boolean doAllGroups,\n                                           Sort groupSort,\n                                           Sort docSort,\n                                           int topNGroups,\n                                           int docsPerGroup,\n                                           int groupOffset,\n                                           int docOffset) {\n\n    final Comparator<GroupDoc> groupSortComp = getComparator(groupSort);\n\n    Arrays.sort(groupDocs, groupSortComp);\n    final HashMap<BytesRef,List<GroupDoc>> groups = new HashMap<>();\n    final List<BytesRef> sortedGroups = new ArrayList<>();\n    final List<Comparable<?>[]> sortedGroupFields = new ArrayList<>();\n\n    int totalHitCount = 0;\n    Set<BytesRef> knownGroups = new HashSet<>();\n\n    //System.out.println(\"TEST: slowGrouping\");\n    for(GroupDoc d : groupDocs) {\n      // TODO: would be better to filter by searchTerm before sorting!\n      if (!d.content.startsWith(searchTerm)) {\n        continue;\n      }\n      totalHitCount++;\n      //System.out.println(\"  match id=\" + d.id + \" score=\" + d.score);\n\n      if (doAllGroups) {\n        if (!knownGroups.contains(d.group)) {\n          knownGroups.add(d.group);\n          //System.out.println(\"    add group=\" + groupToString(d.group));\n        }\n      }\n\n      List<GroupDoc> l = groups.get(d.group);\n      if (l == null) {\n        //System.out.println(\"    add sortedGroup=\" + groupToString(d.group));\n        sortedGroups.add(d.group);\n        sortedGroupFields.add(fillFields(d, groupSort));\n        l = new ArrayList<>();\n        groups.put(d.group, l);\n      }\n      l.add(d);\n    }\n\n    if (groupOffset >= sortedGroups.size()) {\n      // slice is out of bounds\n      return null;\n    }\n\n    final int limit = Math.min(groupOffset + topNGroups, groups.size());\n\n    final Comparator<GroupDoc> docSortComp = getComparator(docSort);\n    @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n    final GroupDocs<BytesRef>[] result = new GroupDocs[limit-groupOffset];\n    int totalGroupedHitCount = 0;\n    for(int idx=groupOffset;idx < limit;idx++) {\n      final BytesRef group = sortedGroups.get(idx);\n      final List<GroupDoc> docs = groups.get(group);\n      totalGroupedHitCount += docs.size();\n      Collections.sort(docs, docSortComp);\n      final ScoreDoc[] hits;\n      if (docs.size() > docOffset) {\n        final int docIDXLimit = Math.min(docOffset + docsPerGroup, docs.size());\n        hits = new ScoreDoc[docIDXLimit - docOffset];\n        for(int docIDX=docOffset; docIDX < docIDXLimit; docIDX++) {\n          final GroupDoc d = docs.get(docIDX);\n          final FieldDoc fd;\n          fd = new FieldDoc(d.id, Float.NaN, fillFields(d, docSort));\n          hits[docIDX-docOffset] = fd;\n        }\n      } else  {\n        hits = new ScoreDoc[0];\n      }\n\n      result[idx-groupOffset] = new GroupDocs<>(Float.NaN,\n                                                        0.0f,\n                                                        new TotalHits(docs.size(), TotalHits.Relation.EQUAL_TO),\n                                                        hits,\n                                                        group,\n                                                        sortedGroupFields.get(idx));\n    }\n\n    if (doAllGroups) {\n      return new TopGroups<>(\n        new TopGroups<>(groupSort.getSort(), docSort.getSort(), totalHitCount, totalGroupedHitCount, result, Float.NaN),\n          knownGroups.size()\n      );\n    } else {\n      return new TopGroups<>(groupSort.getSort(), docSort.getSort(), totalHitCount, totalGroupedHitCount, result, Float.NaN);\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> slowGrouping(GroupDoc[] groupDocs,\n                                           String searchTerm,\n                                           boolean getMaxScores,\n                                           boolean doAllGroups,\n                                           Sort groupSort,\n                                           Sort docSort,\n                                           int topNGroups,\n                                           int docsPerGroup,\n                                           int groupOffset,\n                                           int docOffset) {\n\n    final Comparator<GroupDoc> groupSortComp = getComparator(groupSort);\n\n    Arrays.sort(groupDocs, groupSortComp);\n    final HashMap<BytesRef,List<GroupDoc>> groups = new HashMap<>();\n    final List<BytesRef> sortedGroups = new ArrayList<>();\n    final List<Comparable<?>[]> sortedGroupFields = new ArrayList<>();\n\n    int totalHitCount = 0;\n    Set<BytesRef> knownGroups = new HashSet<>();\n\n    //System.out.println(\"TEST: slowGrouping\");\n    for(GroupDoc d : groupDocs) {\n      // TODO: would be better to filter by searchTerm before sorting!\n      if (!d.content.startsWith(searchTerm)) {\n        continue;\n      }\n      totalHitCount++;\n      //System.out.println(\"  match id=\" + d.id + \" score=\" + d.score);\n\n      if (doAllGroups) {\n        if (!knownGroups.contains(d.group)) {\n          knownGroups.add(d.group);\n          //System.out.println(\"    add group=\" + groupToString(d.group));\n        }\n      }\n\n      List<GroupDoc> l = groups.get(d.group);\n      if (l == null) {\n        //System.out.println(\"    add sortedGroup=\" + groupToString(d.group));\n        sortedGroups.add(d.group);\n        sortedGroupFields.add(fillFields(d, groupSort));\n        l = new ArrayList<>();\n        groups.put(d.group, l);\n      }\n      l.add(d);\n    }\n\n    if (groupOffset >= sortedGroups.size()) {\n      // slice is out of bounds\n      return null;\n    }\n\n    final int limit = Math.min(groupOffset + topNGroups, groups.size());\n\n    final Comparator<GroupDoc> docSortComp = getComparator(docSort);\n    @SuppressWarnings({\"unchecked\"})\n    final GroupDocs<BytesRef>[] result = new GroupDocs[limit-groupOffset];\n    int totalGroupedHitCount = 0;\n    for(int idx=groupOffset;idx < limit;idx++) {\n      final BytesRef group = sortedGroups.get(idx);\n      final List<GroupDoc> docs = groups.get(group);\n      totalGroupedHitCount += docs.size();\n      Collections.sort(docs, docSortComp);\n      final ScoreDoc[] hits;\n      if (docs.size() > docOffset) {\n        final int docIDXLimit = Math.min(docOffset + docsPerGroup, docs.size());\n        hits = new ScoreDoc[docIDXLimit - docOffset];\n        for(int docIDX=docOffset; docIDX < docIDXLimit; docIDX++) {\n          final GroupDoc d = docs.get(docIDX);\n          final FieldDoc fd;\n          fd = new FieldDoc(d.id, Float.NaN, fillFields(d, docSort));\n          hits[docIDX-docOffset] = fd;\n        }\n      } else  {\n        hits = new ScoreDoc[0];\n      }\n\n      result[idx-groupOffset] = new GroupDocs<>(Float.NaN,\n                                                        0.0f,\n                                                        new TotalHits(docs.size(), TotalHits.Relation.EQUAL_TO),\n                                                        hits,\n                                                        group,\n                                                        sortedGroupFields.get(idx));\n    }\n\n    if (doAllGroups) {\n      return new TopGroups<>(\n        new TopGroups<>(groupSort.getSort(), docSort.getSort(), totalHitCount, totalGroupedHitCount, result, Float.NaN),\n          knownGroups.size()\n      );\n    } else {\n      return new TopGroups<>(groupSort.getSort(), docSort.getSort(), totalHitCount, totalGroupedHitCount, result, Float.NaN);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9":["83788ad129a5154d5c6562c4e8ce3db48793aada"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"bb9c3baacabd473e8ecd6c4948aabacead49b88e":["a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["1d3f7ab1a502671bbdb03bcced21e764d2483221"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["bb9c3baacabd473e8ecd6c4948aabacead49b88e"],"1d3f7ab1a502671bbdb03bcced21e764d2483221":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9":["bb9c3baacabd473e8ecd6c4948aabacead49b88e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1d3f7ab1a502671bbdb03bcced21e764d2483221"],"bb9c3baacabd473e8ecd6c4948aabacead49b88e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9"],"1d3f7ab1a502671bbdb03bcced21e764d2483221":["83788ad129a5154d5c6562c4e8ce3db48793aada"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}