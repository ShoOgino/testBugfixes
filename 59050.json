{"path":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","pathOld":"lucene/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","sourceNew":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int)},\n   *  and {@link #finish(int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (MergeState.IndexReaderAndLiveDocs reader : mergeState.readers) {\n      final int maxDoc = reader.reader.maxDoc();\n      final Bits liveDocs = reader.liveDocs;\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState.fieldInfos);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(docCount);\n    return docCount;\n  }\n\n","sourceOld":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int)},\n   *  and {@link #finish(int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (MergeState.IndexReaderAndLiveDocs reader : mergeState.readers) {\n      final int maxDoc = reader.reader.maxDoc();\n      final Bits liveDocs = reader.liveDocs;\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState.fieldInfos);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(docCount);\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d08eba3d52b63561ebf936481ce73e6b6a14aa03","date":1333879759,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","sourceNew":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int)},\n   *  and {@link #finish(int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (MergeState.IndexReaderAndLiveDocs reader : mergeState.readers) {\n      final int maxDoc = reader.reader.maxDoc();\n      final Bits liveDocs = reader.liveDocs;\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        InvertedFields vectors = reader.reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState.fieldInfos);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(docCount);\n    return docCount;\n  }\n\n","sourceOld":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int)},\n   *  and {@link #finish(int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (MergeState.IndexReaderAndLiveDocs reader : mergeState.readers) {\n      final int maxDoc = reader.reader.maxDoc();\n      final Bits liveDocs = reader.liveDocs;\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState.fieldInfos);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(docCount);\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf","date":1333892281,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","sourceNew":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int)},\n   *  and {@link #finish(int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (MergeState.IndexReaderAndLiveDocs reader : mergeState.readers) {\n      final int maxDoc = reader.reader.maxDoc();\n      final Bits liveDocs = reader.liveDocs;\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState.fieldInfos);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(docCount);\n    return docCount;\n  }\n\n","sourceOld":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int)},\n   *  and {@link #finish(int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (MergeState.IndexReaderAndLiveDocs reader : mergeState.readers) {\n      final int maxDoc = reader.reader.maxDoc();\n      final Bits liveDocs = reader.liveDocs;\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        InvertedFields vectors = reader.reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState.fieldInfos);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(docCount);\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":["c95a819869502635864dac0a788f874787e3395b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8febb56d1ed9f3314d35d075599fd9aff857be3c","date":1337729003,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","sourceNew":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int)},\n   *  and {@link #finish(int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (MergeState.IndexReaderAndLiveDocs reader : mergeState.readers) {\n      final int maxDoc = reader.reader.maxDoc();\n      final Bits liveDocs = reader.liveDocs;\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState.fieldInfos);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(mergeState.fieldInfos, docCount);\n    return docCount;\n  }\n\n","sourceOld":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int)},\n   *  and {@link #finish(int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (MergeState.IndexReaderAndLiveDocs reader : mergeState.readers) {\n      final int maxDoc = reader.reader.maxDoc();\n      final Bits liveDocs = reader.liveDocs;\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState.fieldInfos);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(docCount);\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1a2a5e98a45dd6ebebdb91a9ebf1718dbbc065de","date":1337876330,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","sourceNew":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (MergeState.IndexReaderAndLiveDocs reader : mergeState.readers) {\n      final int maxDoc = reader.reader.maxDoc();\n      final Bits liveDocs = reader.liveDocs;\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState.fieldInfos);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(mergeState.fieldInfos, docCount);\n    return docCount;\n  }\n\n","sourceOld":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int)},\n   *  and {@link #finish(int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (MergeState.IndexReaderAndLiveDocs reader : mergeState.readers) {\n      final int maxDoc = reader.reader.maxDoc();\n      final Bits liveDocs = reader.liveDocs;\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState.fieldInfos);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(mergeState.fieldInfos, docCount);\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"615ddbd81799980d0fdd95e0238e1c498b6f47b0","date":1338233290,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","sourceNew":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (MergeState.IndexReaderAndLiveDocs reader : mergeState.readers) {\n      final int maxDoc = reader.reader.maxDoc();\n      final Bits liveDocs = reader.liveDocs;\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState.fieldInfos);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(mergeState.fieldInfos, docCount);\n    return docCount;\n  }\n\n","sourceOld":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int)},\n   *  and {@link #finish(int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (MergeState.IndexReaderAndLiveDocs reader : mergeState.readers) {\n      final int maxDoc = reader.reader.maxDoc();\n      final Bits liveDocs = reader.liveDocs;\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState.fieldInfos);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(docCount);\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c95a819869502635864dac0a788f874787e3395b","date":1341394787,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","sourceNew":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (AtomicReader reader : mergeState.readers) {\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState.fieldInfos);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(mergeState.fieldInfos, docCount);\n    return docCount;\n  }\n\n","sourceOld":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (MergeState.IndexReaderAndLiveDocs reader : mergeState.readers) {\n      final int maxDoc = reader.reader.maxDoc();\n      final Bits liveDocs = reader.liveDocs;\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState.fieldInfos);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(mergeState.fieldInfos, docCount);\n    return docCount;\n  }\n\n","bugFix":["3cc749c053615f5871f3b95715fe292f34e70a53","e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","sourceNew":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (AtomicReader reader : mergeState.readers) {\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState.fieldInfos);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(mergeState.fieldInfos, docCount);\n    return docCount;\n  }\n\n","sourceOld":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (MergeState.IndexReaderAndLiveDocs reader : mergeState.readers) {\n      final int maxDoc = reader.reader.maxDoc();\n      final Bits liveDocs = reader.liveDocs;\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState.fieldInfos);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(mergeState.fieldInfos, docCount);\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0935c850ea562932997b72c69d93e345f21d7f45","date":1344711506,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","sourceNew":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (int i = 0; i < mergeState.readers.size(); i++) {\n      final AtomicReader reader = mergeState.readers.get(i);\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n      // set PayloadProcessor\n      if (mergeState.payloadProcessorProvider != null) {\n        mergeState.currentReaderPayloadProcessor = mergeState.readerPayloadProcessor[i];\n      } else {\n        mergeState.currentReaderPayloadProcessor = null;\n      }\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(mergeState.fieldInfos, docCount);\n    return docCount;\n  }\n\n","sourceOld":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (AtomicReader reader : mergeState.readers) {\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState.fieldInfos);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(mergeState.fieldInfos, docCount);\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7869f64c874ebf7f317d22c00baf2b6857797a6","date":1344856617,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","sourceNew":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (int i = 0; i < mergeState.readers.size(); i++) {\n      final AtomicReader reader = mergeState.readers.get(i);\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n      // set PayloadProcessor\n      if (mergeState.payloadProcessorProvider != null) {\n        mergeState.currentReaderPayloadProcessor = mergeState.readerPayloadProcessor[i];\n      } else {\n        mergeState.currentReaderPayloadProcessor = null;\n      }\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(mergeState.fieldInfos, docCount);\n    return docCount;\n  }\n\n","sourceOld":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (AtomicReader reader : mergeState.readers) {\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState.fieldInfos);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(mergeState.fieldInfos, docCount);\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9","date":1344867506,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","sourceNew":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (int i = 0; i < mergeState.readers.size(); i++) {\n      final AtomicReader reader = mergeState.readers.get(i);\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n      // set PayloadProcessor\n      if (mergeState.payloadProcessorProvider != null) {\n        mergeState.currentReaderPayloadProcessor = mergeState.readerPayloadProcessor[i];\n      } else {\n        mergeState.currentReaderPayloadProcessor = null;\n      }\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(mergeState.fieldInfos, docCount);\n    return docCount;\n  }\n\n","sourceOld":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (AtomicReader reader : mergeState.readers) {\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState.fieldInfos);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(mergeState.fieldInfos, docCount);\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bc124b3b129ef11a255212f3af482b771c5b3a6c","date":1344947616,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","sourceNew":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (int i = 0; i < mergeState.readers.size(); i++) {\n      final AtomicReader reader = mergeState.readers.get(i);\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(mergeState.fieldInfos, docCount);\n    return docCount;\n  }\n\n","sourceOld":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (int i = 0; i < mergeState.readers.size(); i++) {\n      final AtomicReader reader = mergeState.readers.get(i);\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n      // set PayloadProcessor\n      if (mergeState.payloadProcessorProvider != null) {\n        mergeState.currentReaderPayloadProcessor = mergeState.readerPayloadProcessor[i];\n      } else {\n        mergeState.currentReaderPayloadProcessor = null;\n      }\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(mergeState.fieldInfos, docCount);\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","date":1345029782,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","sourceNew":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (int i = 0; i < mergeState.readers.size(); i++) {\n      final AtomicReader reader = mergeState.readers.get(i);\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(mergeState.fieldInfos, docCount);\n    return docCount;\n  }\n\n","sourceOld":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (int i = 0; i < mergeState.readers.size(); i++) {\n      final AtomicReader reader = mergeState.readers.get(i);\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n      // set PayloadProcessor\n      if (mergeState.payloadProcessorProvider != null) {\n        mergeState.currentReaderPayloadProcessor = mergeState.readerPayloadProcessor[i];\n      } else {\n        mergeState.currentReaderPayloadProcessor = null;\n      }\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(mergeState.fieldInfos, docCount);\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3c188105a9aae04f56c24996f98f8333fc825d2e","date":1345031914,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","sourceNew":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (int i = 0; i < mergeState.readers.size(); i++) {\n      final AtomicReader reader = mergeState.readers.get(i);\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(mergeState.fieldInfos, docCount);\n    return docCount;\n  }\n\n","sourceOld":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (int i = 0; i < mergeState.readers.size(); i++) {\n      final AtomicReader reader = mergeState.readers.get(i);\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n      // set PayloadProcessor\n      if (mergeState.payloadProcessorProvider != null) {\n        mergeState.currentReaderPayloadProcessor = mergeState.readerPayloadProcessor[i];\n      } else {\n        mergeState.currentReaderPayloadProcessor = null;\n      }\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(mergeState.fieldInfos, docCount);\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1c93396a1df03720cb20e2c2f513a6fa59b21e4c","date":1345032673,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","sourceNew":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (int i = 0; i < mergeState.readers.size(); i++) {\n      final AtomicReader reader = mergeState.readers.get(i);\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n      // set PayloadProcessor\n      if (mergeState.payloadProcessorProvider != null) {\n        mergeState.currentReaderPayloadProcessor = mergeState.readerPayloadProcessor[i];\n      } else {\n        mergeState.currentReaderPayloadProcessor = null;\n      }\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(mergeState.fieldInfos, docCount);\n    return docCount;\n  }\n\n","sourceOld":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (int i = 0; i < mergeState.readers.size(); i++) {\n      final AtomicReader reader = mergeState.readers.get(i);\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(mergeState.fieldInfos, docCount);\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b05c56a41b733e02a189c48895922b5bd8c7f3d1","date":1345033322,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","sourceNew":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (int i = 0; i < mergeState.readers.size(); i++) {\n      final AtomicReader reader = mergeState.readers.get(i);\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(mergeState.fieldInfos, docCount);\n    return docCount;\n  }\n\n","sourceOld":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (int i = 0; i < mergeState.readers.size(); i++) {\n      final AtomicReader reader = mergeState.readers.get(i);\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n      // set PayloadProcessor\n      if (mergeState.payloadProcessorProvider != null) {\n        mergeState.currentReaderPayloadProcessor = mergeState.readerPayloadProcessor[i];\n      } else {\n        mergeState.currentReaderPayloadProcessor = null;\n      }\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(mergeState.fieldInfos, docCount);\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","sourceNew":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (int i = 0; i < mergeState.readers.size(); i++) {\n      final LeafReader reader = mergeState.readers.get(i);\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(mergeState.fieldInfos, docCount);\n    return docCount;\n  }\n\n","sourceOld":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (int i = 0; i < mergeState.readers.size(); i++) {\n      final AtomicReader reader = mergeState.readers.get(i);\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(mergeState.fieldInfos, docCount);\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2131047ecceac64b54ba70feec3d26bbd7e483d7","date":1411862069,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","sourceNew":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    int numReaders = mergeState.maxDocs.length;\n    for (int i = 0; i < numReaders; i++) {\n      int maxDoc = mergeState.maxDocs[i];\n      Bits liveDocs = mergeState.liveDocs[i];\n      TermVectorsReader termVectorsReader = mergeState.termVectorsReaders[i];\n      if (termVectorsReader != null) {\n        termVectorsReader.checkIntegrity();\n      }\n\n      for (int docID=0;docID<maxDoc;docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors;\n        if (termVectorsReader == null) {\n          vectors = null;\n        } else {\n          vectors = termVectorsReader.get(docID);\n        }\n        addAllDocVectors(vectors, mergeState);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(mergeState.mergeFieldInfos, docCount);\n    return docCount;\n  }\n\n","sourceOld":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (int i = 0; i < mergeState.readers.size(); i++) {\n      final LeafReader reader = mergeState.readers.get(i);\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(mergeState.fieldInfos, docCount);\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9bb9a29a5e71a90295f175df8919802993142c9a","date":1412517673,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","sourceNew":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    int numReaders = mergeState.maxDocs.length;\n    for (int i = 0; i < numReaders; i++) {\n      int maxDoc = mergeState.maxDocs[i];\n      Bits liveDocs = mergeState.liveDocs[i];\n      TermVectorsReader termVectorsReader = mergeState.termVectorsReaders[i];\n      if (termVectorsReader != null) {\n        termVectorsReader.checkIntegrity();\n      }\n\n      for (int docID=0;docID<maxDoc;docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors;\n        if (termVectorsReader == null) {\n          vectors = null;\n        } else {\n          vectors = termVectorsReader.get(docID);\n        }\n        addAllDocVectors(vectors, mergeState);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(mergeState.mergeFieldInfos, docCount);\n    return docCount;\n  }\n\n","sourceOld":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    for (int i = 0; i < mergeState.readers.size(); i++) {\n      final LeafReader reader = mergeState.readers.get(i);\n      final int maxDoc = reader.maxDoc();\n      final Bits liveDocs = reader.getLiveDocs();\n\n      for (int docID = 0; docID < maxDoc; docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors = reader.getTermVectors(docID);\n        addAllDocVectors(vectors, mergeState);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(mergeState.fieldInfos, docCount);\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5faf65b6692f15cca0f87bf8666c87899afc619f","date":1420468108,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","sourceNew":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    int numReaders = mergeState.maxDocs.length;\n    for (int i = 0; i < numReaders; i++) {\n      int maxDoc = mergeState.maxDocs[i];\n      Bits liveDocs = mergeState.liveDocs[i];\n      TermVectorsReader termVectorsReader = mergeState.termVectorsReaders[i];\n      if (termVectorsReader != null) {\n        termVectorsReader.checkIntegrity();\n      }\n\n      for (int docID=0;docID<maxDoc;docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors;\n        if (termVectorsReader == null) {\n          vectors = null;\n        } else {\n          vectors = termVectorsReader.get(docID);\n        }\n        addAllDocVectors(vectors, mergeState);\n        docCount++;\n      }\n    }\n    finish(mergeState.mergeFieldInfos, docCount);\n    return docCount;\n  }\n\n","sourceOld":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    int numReaders = mergeState.maxDocs.length;\n    for (int i = 0; i < numReaders; i++) {\n      int maxDoc = mergeState.maxDocs[i];\n      Bits liveDocs = mergeState.liveDocs[i];\n      TermVectorsReader termVectorsReader = mergeState.termVectorsReaders[i];\n      if (termVectorsReader != null) {\n        termVectorsReader.checkIntegrity();\n      }\n\n      for (int docID=0;docID<maxDoc;docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors;\n        if (termVectorsReader == null) {\n          vectors = null;\n        } else {\n          vectors = termVectorsReader.get(docID);\n        }\n        addAllDocVectors(vectors, mergeState);\n        docCount++;\n        mergeState.checkAbort.work(300);\n      }\n    }\n    finish(mergeState.mergeFieldInfos, docCount);\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ceaef6cfc68c8ab22a684192e469a8280f9e6e70","date":1462354657,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","sourceNew":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n\n    List<TermVectorsMergeSub> subs = new ArrayList<>();\n    for(int i=0;i<mergeState.termVectorsReaders.length;i++) {\n      TermVectorsReader reader = mergeState.termVectorsReaders[i];\n      if (reader != null) {\n        reader.checkIntegrity();\n      }\n      // nocommit make sure the else case tested here\n      subs.add(new TermVectorsMergeSub(mergeState.docMaps[i], mergeState.liveDocs[i], reader, mergeState.maxDocs[i]));\n    }\n\n    final DocIDMerger<TermVectorsMergeSub> docIDMerger = new DocIDMerger<>(subs, mergeState.segmentInfo.getIndexSort() != null);\n\n    int docCount = 0;\n    while (true) {\n      TermVectorsMergeSub sub = docIDMerger.next();\n      if (sub == null) {\n        break;\n      }\n\n      // NOTE: it's very important to first assign to vectors then pass it to\n      // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n      Fields vectors;\n      if (sub.reader == null) {\n        vectors = null;\n      } else {\n        vectors = sub.reader.get(sub.docID);\n      }\n      addAllDocVectors(vectors, mergeState);\n      docCount++;\n    }\n    finish(mergeState.mergeFieldInfos, docCount);\n    return docCount;\n  }\n\n","sourceOld":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    int numReaders = mergeState.maxDocs.length;\n    for (int i = 0; i < numReaders; i++) {\n      int maxDoc = mergeState.maxDocs[i];\n      Bits liveDocs = mergeState.liveDocs[i];\n      TermVectorsReader termVectorsReader = mergeState.termVectorsReaders[i];\n      if (termVectorsReader != null) {\n        termVectorsReader.checkIntegrity();\n      }\n\n      for (int docID=0;docID<maxDoc;docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors;\n        if (termVectorsReader == null) {\n          vectors = null;\n        } else {\n          vectors = termVectorsReader.get(docID);\n        }\n        addAllDocVectors(vectors, mergeState);\n        docCount++;\n      }\n    }\n    finish(mergeState.mergeFieldInfos, docCount);\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6d8200beeffd3fa5155855f4cb8a8a5e38aeff14","date":1462698019,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","sourceNew":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n\n    List<TermVectorsMergeSub> subs = new ArrayList<>();\n    for(int i=0;i<mergeState.termVectorsReaders.length;i++) {\n      TermVectorsReader reader = mergeState.termVectorsReaders[i];\n      if (reader != null) {\n        reader.checkIntegrity();\n      }\n      // nocommit make sure the else case tested here\n      subs.add(new TermVectorsMergeSub(mergeState.docMaps[i], reader, mergeState.maxDocs[i]));\n    }\n\n    final DocIDMerger<TermVectorsMergeSub> docIDMerger = new DocIDMerger<>(subs, mergeState.segmentInfo.getIndexSort() != null);\n\n    int docCount = 0;\n    while (true) {\n      TermVectorsMergeSub sub = docIDMerger.next();\n      if (sub == null) {\n        break;\n      }\n\n      // NOTE: it's very important to first assign to vectors then pass it to\n      // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n      Fields vectors;\n      if (sub.reader == null) {\n        vectors = null;\n      } else {\n        vectors = sub.reader.get(sub.docID);\n      }\n      addAllDocVectors(vectors, mergeState);\n      docCount++;\n    }\n    finish(mergeState.mergeFieldInfos, docCount);\n    return docCount;\n  }\n\n","sourceOld":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n\n    List<TermVectorsMergeSub> subs = new ArrayList<>();\n    for(int i=0;i<mergeState.termVectorsReaders.length;i++) {\n      TermVectorsReader reader = mergeState.termVectorsReaders[i];\n      if (reader != null) {\n        reader.checkIntegrity();\n      }\n      // nocommit make sure the else case tested here\n      subs.add(new TermVectorsMergeSub(mergeState.docMaps[i], mergeState.liveDocs[i], reader, mergeState.maxDocs[i]));\n    }\n\n    final DocIDMerger<TermVectorsMergeSub> docIDMerger = new DocIDMerger<>(subs, mergeState.segmentInfo.getIndexSort() != null);\n\n    int docCount = 0;\n    while (true) {\n      TermVectorsMergeSub sub = docIDMerger.next();\n      if (sub == null) {\n        break;\n      }\n\n      // NOTE: it's very important to first assign to vectors then pass it to\n      // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n      Fields vectors;\n      if (sub.reader == null) {\n        vectors = null;\n      } else {\n        vectors = sub.reader.get(sub.docID);\n      }\n      addAllDocVectors(vectors, mergeState);\n      docCount++;\n    }\n    finish(mergeState.mergeFieldInfos, docCount);\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5e03940e6e9044943de4b7ac08f8581da37a9534","date":1462870173,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","sourceNew":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n\n    List<TermVectorsMergeSub> subs = new ArrayList<>();\n    for(int i=0;i<mergeState.termVectorsReaders.length;i++) {\n      TermVectorsReader reader = mergeState.termVectorsReaders[i];\n      if (reader != null) {\n        reader.checkIntegrity();\n      }\n      subs.add(new TermVectorsMergeSub(mergeState.docMaps[i], reader, mergeState.maxDocs[i]));\n    }\n\n    final DocIDMerger<TermVectorsMergeSub> docIDMerger = new DocIDMerger<>(subs, mergeState.segmentInfo.getIndexSort() != null);\n\n    int docCount = 0;\n    while (true) {\n      TermVectorsMergeSub sub = docIDMerger.next();\n      if (sub == null) {\n        break;\n      }\n\n      // NOTE: it's very important to first assign to vectors then pass it to\n      // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n      Fields vectors;\n      if (sub.reader == null) {\n        vectors = null;\n      } else {\n        vectors = sub.reader.get(sub.docID);\n      }\n      addAllDocVectors(vectors, mergeState);\n      docCount++;\n    }\n    finish(mergeState.mergeFieldInfos, docCount);\n    return docCount;\n  }\n\n","sourceOld":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n\n    List<TermVectorsMergeSub> subs = new ArrayList<>();\n    for(int i=0;i<mergeState.termVectorsReaders.length;i++) {\n      TermVectorsReader reader = mergeState.termVectorsReaders[i];\n      if (reader != null) {\n        reader.checkIntegrity();\n      }\n      // nocommit make sure the else case tested here\n      subs.add(new TermVectorsMergeSub(mergeState.docMaps[i], reader, mergeState.maxDocs[i]));\n    }\n\n    final DocIDMerger<TermVectorsMergeSub> docIDMerger = new DocIDMerger<>(subs, mergeState.segmentInfo.getIndexSort() != null);\n\n    int docCount = 0;\n    while (true) {\n      TermVectorsMergeSub sub = docIDMerger.next();\n      if (sub == null) {\n        break;\n      }\n\n      // NOTE: it's very important to first assign to vectors then pass it to\n      // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n      Fields vectors;\n      if (sub.reader == null) {\n        vectors = null;\n      } else {\n        vectors = sub.reader.get(sub.docID);\n      }\n      addAllDocVectors(vectors, mergeState);\n      docCount++;\n    }\n    finish(mergeState.mergeFieldInfos, docCount);\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3d33e731a93d4b57e662ff094f64f94a745422d4","date":1463128289,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","sourceNew":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n\n    List<TermVectorsMergeSub> subs = new ArrayList<>();\n    for(int i=0;i<mergeState.termVectorsReaders.length;i++) {\n      TermVectorsReader reader = mergeState.termVectorsReaders[i];\n      if (reader != null) {\n        reader.checkIntegrity();\n      }\n      subs.add(new TermVectorsMergeSub(mergeState.docMaps[i], reader, mergeState.maxDocs[i]));\n    }\n\n    final DocIDMerger<TermVectorsMergeSub> docIDMerger = new DocIDMerger<>(subs, mergeState.segmentInfo.getIndexSort() != null);\n\n    int docCount = 0;\n    while (true) {\n      TermVectorsMergeSub sub = docIDMerger.next();\n      if (sub == null) {\n        break;\n      }\n\n      // NOTE: it's very important to first assign to vectors then pass it to\n      // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n      Fields vectors;\n      if (sub.reader == null) {\n        vectors = null;\n      } else {\n        vectors = sub.reader.get(sub.docID);\n      }\n      addAllDocVectors(vectors, mergeState);\n      docCount++;\n    }\n    finish(mergeState.mergeFieldInfos, docCount);\n    return docCount;\n  }\n\n","sourceOld":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    int numReaders = mergeState.maxDocs.length;\n    for (int i = 0; i < numReaders; i++) {\n      int maxDoc = mergeState.maxDocs[i];\n      Bits liveDocs = mergeState.liveDocs[i];\n      TermVectorsReader termVectorsReader = mergeState.termVectorsReaders[i];\n      if (termVectorsReader != null) {\n        termVectorsReader.checkIntegrity();\n      }\n\n      for (int docID=0;docID<maxDoc;docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors;\n        if (termVectorsReader == null) {\n          vectors = null;\n        } else {\n          vectors = termVectorsReader.get(docID);\n        }\n        addAllDocVectors(vectors, mergeState);\n        docCount++;\n      }\n    }\n    finish(mergeState.mergeFieldInfos, docCount);\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0ad30c6a479e764150a3316e57263319775f1df2","date":1463395403,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","sourceNew":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n\n    List<TermVectorsMergeSub> subs = new ArrayList<>();\n    for(int i=0;i<mergeState.termVectorsReaders.length;i++) {\n      TermVectorsReader reader = mergeState.termVectorsReaders[i];\n      if (reader != null) {\n        reader.checkIntegrity();\n      }\n      subs.add(new TermVectorsMergeSub(mergeState.docMaps[i], reader, mergeState.maxDocs[i]));\n    }\n\n    final DocIDMerger<TermVectorsMergeSub> docIDMerger = new DocIDMerger<>(subs, mergeState.segmentInfo.getIndexSort() != null);\n\n    int docCount = 0;\n    while (true) {\n      TermVectorsMergeSub sub = docIDMerger.next();\n      if (sub == null) {\n        break;\n      }\n\n      // NOTE: it's very important to first assign to vectors then pass it to\n      // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n      Fields vectors;\n      if (sub.reader == null) {\n        vectors = null;\n      } else {\n        vectors = sub.reader.get(sub.docID);\n      }\n      addAllDocVectors(vectors, mergeState);\n      docCount++;\n    }\n    finish(mergeState.mergeFieldInfos, docCount);\n    return docCount;\n  }\n\n","sourceOld":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    int numReaders = mergeState.maxDocs.length;\n    for (int i = 0; i < numReaders; i++) {\n      int maxDoc = mergeState.maxDocs[i];\n      Bits liveDocs = mergeState.liveDocs[i];\n      TermVectorsReader termVectorsReader = mergeState.termVectorsReaders[i];\n      if (termVectorsReader != null) {\n        termVectorsReader.checkIntegrity();\n      }\n\n      for (int docID=0;docID<maxDoc;docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors;\n        if (termVectorsReader == null) {\n          vectors = null;\n        } else {\n          vectors = termVectorsReader.get(docID);\n        }\n        addAllDocVectors(vectors, mergeState);\n        docCount++;\n      }\n    }\n    finish(mergeState.mergeFieldInfos, docCount);\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d470c8182e92b264680e34081b75e70a9f2b3c89","date":1463985353,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","sourceNew":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n\n    List<TermVectorsMergeSub> subs = new ArrayList<>();\n    for(int i=0;i<mergeState.termVectorsReaders.length;i++) {\n      TermVectorsReader reader = mergeState.termVectorsReaders[i];\n      if (reader != null) {\n        reader.checkIntegrity();\n      }\n      subs.add(new TermVectorsMergeSub(mergeState.docMaps[i], reader, mergeState.maxDocs[i]));\n    }\n\n    final DocIDMerger<TermVectorsMergeSub> docIDMerger = new DocIDMerger<>(subs, mergeState.segmentInfo.getIndexSort() != null);\n\n    int docCount = 0;\n    while (true) {\n      TermVectorsMergeSub sub = docIDMerger.next();\n      if (sub == null) {\n        break;\n      }\n\n      // NOTE: it's very important to first assign to vectors then pass it to\n      // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n      Fields vectors;\n      if (sub.reader == null) {\n        vectors = null;\n      } else {\n        vectors = sub.reader.get(sub.docID);\n      }\n      addAllDocVectors(vectors, mergeState);\n      docCount++;\n    }\n    finish(mergeState.mergeFieldInfos, docCount);\n    return docCount;\n  }\n\n","sourceOld":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    int numReaders = mergeState.maxDocs.length;\n    for (int i = 0; i < numReaders; i++) {\n      int maxDoc = mergeState.maxDocs[i];\n      Bits liveDocs = mergeState.liveDocs[i];\n      TermVectorsReader termVectorsReader = mergeState.termVectorsReaders[i];\n      if (termVectorsReader != null) {\n        termVectorsReader.checkIntegrity();\n      }\n\n      for (int docID=0;docID<maxDoc;docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors;\n        if (termVectorsReader == null) {\n          vectors = null;\n        } else {\n          vectors = termVectorsReader.get(docID);\n        }\n        addAllDocVectors(vectors, mergeState);\n        docCount++;\n      }\n    }\n    finish(mergeState.mergeFieldInfos, docCount);\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","sourceNew":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n\n    List<TermVectorsMergeSub> subs = new ArrayList<>();\n    for(int i=0;i<mergeState.termVectorsReaders.length;i++) {\n      TermVectorsReader reader = mergeState.termVectorsReaders[i];\n      if (reader != null) {\n        reader.checkIntegrity();\n      }\n      subs.add(new TermVectorsMergeSub(mergeState.docMaps[i], reader, mergeState.maxDocs[i]));\n    }\n\n    final DocIDMerger<TermVectorsMergeSub> docIDMerger = new DocIDMerger<>(subs, mergeState.segmentInfo.getIndexSort() != null);\n\n    int docCount = 0;\n    while (true) {\n      TermVectorsMergeSub sub = docIDMerger.next();\n      if (sub == null) {\n        break;\n      }\n\n      // NOTE: it's very important to first assign to vectors then pass it to\n      // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n      Fields vectors;\n      if (sub.reader == null) {\n        vectors = null;\n      } else {\n        vectors = sub.reader.get(sub.docID);\n      }\n      addAllDocVectors(vectors, mergeState);\n      docCount++;\n    }\n    finish(mergeState.mergeFieldInfos, docCount);\n    return docCount;\n  }\n\n","sourceOld":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n    int docCount = 0;\n    int numReaders = mergeState.maxDocs.length;\n    for (int i = 0; i < numReaders; i++) {\n      int maxDoc = mergeState.maxDocs[i];\n      Bits liveDocs = mergeState.liveDocs[i];\n      TermVectorsReader termVectorsReader = mergeState.termVectorsReaders[i];\n      if (termVectorsReader != null) {\n        termVectorsReader.checkIntegrity();\n      }\n\n      for (int docID=0;docID<maxDoc;docID++) {\n        if (liveDocs != null && !liveDocs.get(docID)) {\n          // skip deleted docs\n          continue;\n        }\n        // NOTE: it's very important to first assign to vectors then pass it to\n        // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n        Fields vectors;\n        if (termVectorsReader == null) {\n          vectors = null;\n        } else {\n          vectors = termVectorsReader.get(docID);\n        }\n        addAllDocVectors(vectors, mergeState);\n        docCount++;\n      }\n    }\n    finish(mergeState.mergeFieldInfos, docCount);\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"653128722fb3b4713ac331c621491a93f34a4a22","date":1479841816,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","sourceNew":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n\n    List<TermVectorsMergeSub> subs = new ArrayList<>();\n    for(int i=0;i<mergeState.termVectorsReaders.length;i++) {\n      TermVectorsReader reader = mergeState.termVectorsReaders[i];\n      if (reader != null) {\n        reader.checkIntegrity();\n      }\n      subs.add(new TermVectorsMergeSub(mergeState.docMaps[i], reader, mergeState.maxDocs[i]));\n    }\n\n    final DocIDMerger<TermVectorsMergeSub> docIDMerger = new DocIDMerger<>(subs, mergeState.needsIndexSort);\n\n    int docCount = 0;\n    while (true) {\n      TermVectorsMergeSub sub = docIDMerger.next();\n      if (sub == null) {\n        break;\n      }\n\n      // NOTE: it's very important to first assign to vectors then pass it to\n      // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n      Fields vectors;\n      if (sub.reader == null) {\n        vectors = null;\n      } else {\n        vectors = sub.reader.get(sub.docID);\n      }\n      addAllDocVectors(vectors, mergeState);\n      docCount++;\n    }\n    finish(mergeState.mergeFieldInfos, docCount);\n    return docCount;\n  }\n\n","sourceOld":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n\n    List<TermVectorsMergeSub> subs = new ArrayList<>();\n    for(int i=0;i<mergeState.termVectorsReaders.length;i++) {\n      TermVectorsReader reader = mergeState.termVectorsReaders[i];\n      if (reader != null) {\n        reader.checkIntegrity();\n      }\n      subs.add(new TermVectorsMergeSub(mergeState.docMaps[i], reader, mergeState.maxDocs[i]));\n    }\n\n    final DocIDMerger<TermVectorsMergeSub> docIDMerger = new DocIDMerger<>(subs, mergeState.segmentInfo.getIndexSort() != null);\n\n    int docCount = 0;\n    while (true) {\n      TermVectorsMergeSub sub = docIDMerger.next();\n      if (sub == null) {\n        break;\n      }\n\n      // NOTE: it's very important to first assign to vectors then pass it to\n      // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n      Fields vectors;\n      if (sub.reader == null) {\n        vectors = null;\n      } else {\n        vectors = sub.reader.get(sub.docID);\n      }\n      addAllDocVectors(vectors, mergeState);\n      docCount++;\n    }\n    finish(mergeState.mergeFieldInfos, docCount);\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"727bb765ff2542275f6d31f67be18d7104bae148","date":1480353976,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","sourceNew":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n\n    List<TermVectorsMergeSub> subs = new ArrayList<>();\n    for(int i=0;i<mergeState.termVectorsReaders.length;i++) {\n      TermVectorsReader reader = mergeState.termVectorsReaders[i];\n      if (reader != null) {\n        reader.checkIntegrity();\n      }\n      subs.add(new TermVectorsMergeSub(mergeState.docMaps[i], reader, mergeState.maxDocs[i]));\n    }\n\n    final DocIDMerger<TermVectorsMergeSub> docIDMerger = new DocIDMerger<>(subs, mergeState.needsIndexSort);\n\n    int docCount = 0;\n    while (true) {\n      TermVectorsMergeSub sub = docIDMerger.next();\n      if (sub == null) {\n        break;\n      }\n\n      // NOTE: it's very important to first assign to vectors then pass it to\n      // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n      Fields vectors;\n      if (sub.reader == null) {\n        vectors = null;\n      } else {\n        vectors = sub.reader.get(sub.docID);\n      }\n      addAllDocVectors(vectors, mergeState);\n      docCount++;\n    }\n    finish(mergeState.mergeFieldInfos, docCount);\n    return docCount;\n  }\n\n","sourceOld":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n\n    List<TermVectorsMergeSub> subs = new ArrayList<>();\n    for(int i=0;i<mergeState.termVectorsReaders.length;i++) {\n      TermVectorsReader reader = mergeState.termVectorsReaders[i];\n      if (reader != null) {\n        reader.checkIntegrity();\n      }\n      subs.add(new TermVectorsMergeSub(mergeState.docMaps[i], reader, mergeState.maxDocs[i]));\n    }\n\n    final DocIDMerger<TermVectorsMergeSub> docIDMerger = new DocIDMerger<>(subs, mergeState.segmentInfo.getIndexSort() != null);\n\n    int docCount = 0;\n    while (true) {\n      TermVectorsMergeSub sub = docIDMerger.next();\n      if (sub == null) {\n        break;\n      }\n\n      // NOTE: it's very important to first assign to vectors then pass it to\n      // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n      Fields vectors;\n      if (sub.reader == null) {\n        vectors = null;\n      } else {\n        vectors = sub.reader.get(sub.docID);\n      }\n      addAllDocVectors(vectors, mergeState);\n      docCount++;\n    }\n    finish(mergeState.mergeFieldInfos, docCount);\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d85b6e22926e7564c040d2a864f4887f6c59fa92","date":1482349496,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","sourceNew":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n\n    List<TermVectorsMergeSub> subs = new ArrayList<>();\n    for(int i=0;i<mergeState.termVectorsReaders.length;i++) {\n      TermVectorsReader reader = mergeState.termVectorsReaders[i];\n      if (reader != null) {\n        reader.checkIntegrity();\n      }\n      subs.add(new TermVectorsMergeSub(mergeState.docMaps[i], reader, mergeState.maxDocs[i]));\n    }\n\n    final DocIDMerger<TermVectorsMergeSub> docIDMerger = DocIDMerger.of(subs, mergeState.needsIndexSort);\n\n    int docCount = 0;\n    while (true) {\n      TermVectorsMergeSub sub = docIDMerger.next();\n      if (sub == null) {\n        break;\n      }\n\n      // NOTE: it's very important to first assign to vectors then pass it to\n      // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n      Fields vectors;\n      if (sub.reader == null) {\n        vectors = null;\n      } else {\n        vectors = sub.reader.get(sub.docID);\n      }\n      addAllDocVectors(vectors, mergeState);\n      docCount++;\n    }\n    finish(mergeState.mergeFieldInfos, docCount);\n    return docCount;\n  }\n\n","sourceOld":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n\n    List<TermVectorsMergeSub> subs = new ArrayList<>();\n    for(int i=0;i<mergeState.termVectorsReaders.length;i++) {\n      TermVectorsReader reader = mergeState.termVectorsReaders[i];\n      if (reader != null) {\n        reader.checkIntegrity();\n      }\n      subs.add(new TermVectorsMergeSub(mergeState.docMaps[i], reader, mergeState.maxDocs[i]));\n    }\n\n    final DocIDMerger<TermVectorsMergeSub> docIDMerger = new DocIDMerger<>(subs, mergeState.needsIndexSort);\n\n    int docCount = 0;\n    while (true) {\n      TermVectorsMergeSub sub = docIDMerger.next();\n      if (sub == null) {\n        break;\n      }\n\n      // NOTE: it's very important to first assign to vectors then pass it to\n      // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n      Fields vectors;\n      if (sub.reader == null) {\n        vectors = null;\n      } else {\n        vectors = sub.reader.get(sub.docID);\n      }\n      addAllDocVectors(vectors, mergeState);\n      docCount++;\n    }\n    finish(mergeState.mergeFieldInfos, docCount);\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f03e4bed5023ec3ef93a771b8888cae991cf448d","date":1483469262,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#merge(MergeState).mjava","sourceNew":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n\n    List<TermVectorsMergeSub> subs = new ArrayList<>();\n    for(int i=0;i<mergeState.termVectorsReaders.length;i++) {\n      TermVectorsReader reader = mergeState.termVectorsReaders[i];\n      if (reader != null) {\n        reader.checkIntegrity();\n      }\n      subs.add(new TermVectorsMergeSub(mergeState.docMaps[i], reader, mergeState.maxDocs[i]));\n    }\n\n    final DocIDMerger<TermVectorsMergeSub> docIDMerger = DocIDMerger.of(subs, mergeState.needsIndexSort);\n\n    int docCount = 0;\n    while (true) {\n      TermVectorsMergeSub sub = docIDMerger.next();\n      if (sub == null) {\n        break;\n      }\n\n      // NOTE: it's very important to first assign to vectors then pass it to\n      // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n      Fields vectors;\n      if (sub.reader == null) {\n        vectors = null;\n      } else {\n        vectors = sub.reader.get(sub.docID);\n      }\n      addAllDocVectors(vectors, mergeState);\n      docCount++;\n    }\n    finish(mergeState.mergeFieldInfos, docCount);\n    return docCount;\n  }\n\n","sourceOld":"  /** Merges in the term vectors from the readers in \n   *  <code>mergeState</code>. The default implementation skips\n   *  over deleted documents, and uses {@link #startDocument(int)},\n   *  {@link #startField(FieldInfo, int, boolean, boolean, boolean)}, \n   *  {@link #startTerm(BytesRef, int)}, {@link #addPosition(int, int, int, BytesRef)},\n   *  and {@link #finish(FieldInfos, int)},\n   *  returning the number of documents that were written.\n   *  Implementations can override this method for more sophisticated\n   *  merging (bulk-byte copying, etc). */\n  public int merge(MergeState mergeState) throws IOException {\n\n    List<TermVectorsMergeSub> subs = new ArrayList<>();\n    for(int i=0;i<mergeState.termVectorsReaders.length;i++) {\n      TermVectorsReader reader = mergeState.termVectorsReaders[i];\n      if (reader != null) {\n        reader.checkIntegrity();\n      }\n      subs.add(new TermVectorsMergeSub(mergeState.docMaps[i], reader, mergeState.maxDocs[i]));\n    }\n\n    final DocIDMerger<TermVectorsMergeSub> docIDMerger = new DocIDMerger<>(subs, mergeState.needsIndexSort);\n\n    int docCount = 0;\n    while (true) {\n      TermVectorsMergeSub sub = docIDMerger.next();\n      if (sub == null) {\n        break;\n      }\n\n      // NOTE: it's very important to first assign to vectors then pass it to\n      // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n      Fields vectors;\n      if (sub.reader == null) {\n        vectors = null;\n      } else {\n        vectors = sub.reader.get(sub.docID);\n      }\n      addAllDocVectors(vectors, mergeState);\n      docCount++;\n    }\n    finish(mergeState.mergeFieldInfos, docCount);\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c95a819869502635864dac0a788f874787e3395b":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"8febb56d1ed9f3314d35d075599fd9aff857be3c":["e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf"],"3c188105a9aae04f56c24996f98f8333fc825d2e":["c7869f64c874ebf7f317d22c00baf2b6857797a6"],"b05c56a41b733e02a189c48895922b5bd8c7f3d1":["1c93396a1df03720cb20e2c2f513a6fa59b21e4c","bc124b3b129ef11a255212f3af482b771c5b3a6c"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"d85b6e22926e7564c040d2a864f4887f6c59fa92":["653128722fb3b4713ac331c621491a93f34a4a22"],"0ad30c6a479e764150a3316e57263319775f1df2":["5faf65b6692f15cca0f87bf8666c87899afc619f","3d33e731a93d4b57e662ff094f64f94a745422d4"],"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198":["d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9","bc124b3b129ef11a255212f3af482b771c5b3a6c"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["bc124b3b129ef11a255212f3af482b771c5b3a6c"],"d470c8182e92b264680e34081b75e70a9f2b3c89":["5faf65b6692f15cca0f87bf8666c87899afc619f","0ad30c6a479e764150a3316e57263319775f1df2"],"c7869f64c874ebf7f317d22c00baf2b6857797a6":["fe33227f6805edab2036cbb80645cc4e2d1fa424","0935c850ea562932997b72c69d93e345f21d7f45"],"9bb9a29a5e71a90295f175df8919802993142c9a":["c9fb5f46e264daf5ba3860defe623a89d202dd87","2131047ecceac64b54ba70feec3d26bbd7e483d7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf":["d08eba3d52b63561ebf936481ce73e6b6a14aa03"],"bc124b3b129ef11a255212f3af482b771c5b3a6c":["0935c850ea562932997b72c69d93e345f21d7f45"],"d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9":["c95a819869502635864dac0a788f874787e3395b","0935c850ea562932997b72c69d93e345f21d7f45"],"1c93396a1df03720cb20e2c2f513a6fa59b21e4c":["3c188105a9aae04f56c24996f98f8333fc825d2e"],"d08eba3d52b63561ebf936481ce73e6b6a14aa03":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["5faf65b6692f15cca0f87bf8666c87899afc619f","d470c8182e92b264680e34081b75e70a9f2b3c89"],"f03e4bed5023ec3ef93a771b8888cae991cf448d":["727bb765ff2542275f6d31f67be18d7104bae148","d85b6e22926e7564c040d2a864f4887f6c59fa92"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf","1a2a5e98a45dd6ebebdb91a9ebf1718dbbc065de"],"727bb765ff2542275f6d31f67be18d7104bae148":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","653128722fb3b4713ac331c621491a93f34a4a22"],"ceaef6cfc68c8ab22a684192e469a8280f9e6e70":["5faf65b6692f15cca0f87bf8666c87899afc619f"],"1a2a5e98a45dd6ebebdb91a9ebf1718dbbc065de":["8febb56d1ed9f3314d35d075599fd9aff857be3c"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["615ddbd81799980d0fdd95e0238e1c498b6f47b0","c95a819869502635864dac0a788f874787e3395b"],"2131047ecceac64b54ba70feec3d26bbd7e483d7":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"6d8200beeffd3fa5155855f4cb8a8a5e38aeff14":["ceaef6cfc68c8ab22a684192e469a8280f9e6e70"],"5faf65b6692f15cca0f87bf8666c87899afc619f":["9bb9a29a5e71a90295f175df8919802993142c9a"],"5e03940e6e9044943de4b7ac08f8581da37a9534":["6d8200beeffd3fa5155855f4cb8a8a5e38aeff14"],"0935c850ea562932997b72c69d93e345f21d7f45":["c95a819869502635864dac0a788f874787e3395b"],"3d33e731a93d4b57e662ff094f64f94a745422d4":["5faf65b6692f15cca0f87bf8666c87899afc619f","5e03940e6e9044943de4b7ac08f8581da37a9534"],"653128722fb3b4713ac331c621491a93f34a4a22":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d85b6e22926e7564c040d2a864f4887f6c59fa92"]},"commit2Childs":{"c95a819869502635864dac0a788f874787e3395b":["d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9","fe33227f6805edab2036cbb80645cc4e2d1fa424","0935c850ea562932997b72c69d93e345f21d7f45"],"8febb56d1ed9f3314d35d075599fd9aff857be3c":["1a2a5e98a45dd6ebebdb91a9ebf1718dbbc065de"],"3c188105a9aae04f56c24996f98f8333fc825d2e":["1c93396a1df03720cb20e2c2f513a6fa59b21e4c"],"b05c56a41b733e02a189c48895922b5bd8c7f3d1":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["d08eba3d52b63561ebf936481ce73e6b6a14aa03"],"d85b6e22926e7564c040d2a864f4887f6c59fa92":["f03e4bed5023ec3ef93a771b8888cae991cf448d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"0ad30c6a479e764150a3316e57263319775f1df2":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198":[],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["9bb9a29a5e71a90295f175df8919802993142c9a","2131047ecceac64b54ba70feec3d26bbd7e483d7"],"d470c8182e92b264680e34081b75e70a9f2b3c89":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","653128722fb3b4713ac331c621491a93f34a4a22"],"c7869f64c874ebf7f317d22c00baf2b6857797a6":["3c188105a9aae04f56c24996f98f8333fc825d2e"],"9bb9a29a5e71a90295f175df8919802993142c9a":["5faf65b6692f15cca0f87bf8666c87899afc619f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf":["8febb56d1ed9f3314d35d075599fd9aff857be3c","615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"bc124b3b129ef11a255212f3af482b771c5b3a6c":["b05c56a41b733e02a189c48895922b5bd8c7f3d1","c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","c9fb5f46e264daf5ba3860defe623a89d202dd87"],"d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9":["c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198"],"1c93396a1df03720cb20e2c2f513a6fa59b21e4c":["b05c56a41b733e02a189c48895922b5bd8c7f3d1"],"d08eba3d52b63561ebf936481ce73e6b6a14aa03":["e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["727bb765ff2542275f6d31f67be18d7104bae148"],"f03e4bed5023ec3ef93a771b8888cae991cf448d":[],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["c95a819869502635864dac0a788f874787e3395b","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"727bb765ff2542275f6d31f67be18d7104bae148":["f03e4bed5023ec3ef93a771b8888cae991cf448d"],"ceaef6cfc68c8ab22a684192e469a8280f9e6e70":["6d8200beeffd3fa5155855f4cb8a8a5e38aeff14"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["c7869f64c874ebf7f317d22c00baf2b6857797a6"],"1a2a5e98a45dd6ebebdb91a9ebf1718dbbc065de":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"2131047ecceac64b54ba70feec3d26bbd7e483d7":["9bb9a29a5e71a90295f175df8919802993142c9a"],"6d8200beeffd3fa5155855f4cb8a8a5e38aeff14":["5e03940e6e9044943de4b7ac08f8581da37a9534"],"5faf65b6692f15cca0f87bf8666c87899afc619f":["0ad30c6a479e764150a3316e57263319775f1df2","d470c8182e92b264680e34081b75e70a9f2b3c89","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","ceaef6cfc68c8ab22a684192e469a8280f9e6e70","3d33e731a93d4b57e662ff094f64f94a745422d4"],"5e03940e6e9044943de4b7ac08f8581da37a9534":["3d33e731a93d4b57e662ff094f64f94a745422d4"],"3d33e731a93d4b57e662ff094f64f94a745422d4":["0ad30c6a479e764150a3316e57263319775f1df2"],"0935c850ea562932997b72c69d93e345f21d7f45":["c7869f64c874ebf7f317d22c00baf2b6857797a6","bc124b3b129ef11a255212f3af482b771c5b3a6c","d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9"],"653128722fb3b4713ac331c621491a93f34a4a22":["d85b6e22926e7564c040d2a864f4887f6c59fa92","727bb765ff2542275f6d31f67be18d7104bae148"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b05c56a41b733e02a189c48895922b5bd8c7f3d1","c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","f03e4bed5023ec3ef93a771b8888cae991cf448d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}