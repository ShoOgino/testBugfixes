{"path":"solr/core/src/java/org/apache/solr/util/hll/HLL#fromBytes(byte[]).mjava","commits":[{"id":"6d8714f9ceaaff94f0968d1c2d037978c3fde569","date":1437042727,"type":0,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/util/hll/HLL#fromBytes(byte[]).mjava","pathOld":"/dev/null","sourceNew":"    /**\n     * Deserializes the HLL (in {@link #toBytes(ISchemaVersion)} format) serialized\n     * into <code>bytes</code>.<p/>\n     *\n     * @param  bytes the serialized bytes of new HLL\n     * @return the deserialized HLL. This will never be <code>null</code>.\n     *\n     * @see #toBytes(ISchemaVersion)\n     */\n    public static HLL fromBytes(final byte[] bytes) {\n        final ISchemaVersion schemaVersion = SerializationUtil.getSchemaVersion(bytes);\n        final IHLLMetadata metadata = schemaVersion.readMetadata(bytes);\n\n        final HLLType type = metadata.HLLType();\n        final int regwidth = metadata.registerWidth();\n        final int log2m = metadata.registerCountLog2();\n        final boolean sparseon = metadata.sparseEnabled();\n\n        final int expthresh;\n        if(metadata.explicitAuto()) {\n            expthresh = -1;\n        } else if(metadata.explicitOff()) {\n            expthresh = 0;\n        } else {\n            // NOTE: take into account that the postgres-compatible constructor\n            //       subtracts one before taking a power of two.\n            expthresh = metadata.log2ExplicitCutoff() + 1;\n        }\n\n        final HLL hll = new HLL(log2m, regwidth, expthresh, sparseon, type);\n\n        // Short-circuit on empty, which needs no other deserialization.\n        if(HLLType.EMPTY.equals(type)) {\n            return hll;\n        }\n\n        final int wordLength;\n        switch(type) {\n            case EXPLICIT:\n                wordLength = Long.SIZE;\n                break;\n            case SPARSE:\n                wordLength = hll.shortWordLength;\n                break;\n            case FULL:\n                wordLength = hll.regwidth;\n                break;\n            default:\n                throw new RuntimeException(\"Unsupported HLL type \" + type);\n        }\n\n        final IWordDeserializer deserializer =\n                schemaVersion.getDeserializer(type, wordLength, bytes);\n        switch(type) {\n            case EXPLICIT:\n                // NOTE:  This should not exceed expthresh and this will always\n                //        be exactly the number of words that were encoded,\n                //        because the word length is at least a byte wide.\n                // SEE:   IWordDeserializer#totalWordCount()\n                for(int i=0; i<deserializer.totalWordCount(); i++) {\n                    hll.explicitStorage.add(deserializer.readWord());\n                }\n                break;\n            case SPARSE:\n                // NOTE:  If the shortWordLength were smaller than 8 bits\n                //        (1 byte) there would be a possibility (because of\n                //        padding arithmetic) of having one or more extra\n                //        registers read. However, this is not relevant as the\n                //        extra registers will be all zeroes, which are ignored\n                //        in the sparse representation.\n                for(int i=0; i<deserializer.totalWordCount(); i++) {\n                    final long shortWord = deserializer.readWord();\n                    final byte registerValue = (byte)(shortWord & hll.valueMask);\n                    // Only set non-zero registers.\n                    if (registerValue != 0) {\n                        hll.sparseProbabilisticStorage.put((int)(shortWord >>> hll.regwidth), registerValue);\n                    }\n                }\n                break;\n            case FULL:\n                // NOTE:  Iteration is done using m (register count) and NOT\n                //        deserializer#totalWordCount() because regwidth may be\n                //        less than 8 and as such the padding on the 'last' byte\n                //        may be larger than regwidth, causing an extra register\n                //        to be read.\n                // SEE: IWordDeserializer#totalWordCount()\n                for(long i=0; i<hll.m; i++) {\n                    hll.probabilisticStorage.setRegister(i, deserializer.readWord());\n                }\n                break;\n            default:\n                throw new RuntimeException(\"Unsupported HLL type \" + type);\n        }\n\n        return hll;\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3cee04f63da2b1e4185495f96d22b98fa63a4fa8","date":1437045299,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/util/hll/HLL#fromBytes(byte[]).mjava","pathOld":"solr/core/src/java/org/apache/solr/util/hll/HLL#fromBytes(byte[]).mjava","sourceNew":"    /**\n     * Deserializes the HLL (in {@link #toBytes(ISchemaVersion)} format) serialized\n     * into <code>bytes</code>.\n     *\n     * @param  bytes the serialized bytes of new HLL\n     * @return the deserialized HLL. This will never be <code>null</code>.\n     *\n     * @see #toBytes(ISchemaVersion)\n     */\n    public static HLL fromBytes(final byte[] bytes) {\n        final ISchemaVersion schemaVersion = SerializationUtil.getSchemaVersion(bytes);\n        final IHLLMetadata metadata = schemaVersion.readMetadata(bytes);\n\n        final HLLType type = metadata.HLLType();\n        final int regwidth = metadata.registerWidth();\n        final int log2m = metadata.registerCountLog2();\n        final boolean sparseon = metadata.sparseEnabled();\n\n        final int expthresh;\n        if(metadata.explicitAuto()) {\n            expthresh = -1;\n        } else if(metadata.explicitOff()) {\n            expthresh = 0;\n        } else {\n            // NOTE: take into account that the postgres-compatible constructor\n            //       subtracts one before taking a power of two.\n            expthresh = metadata.log2ExplicitCutoff() + 1;\n        }\n\n        final HLL hll = new HLL(log2m, regwidth, expthresh, sparseon, type);\n\n        // Short-circuit on empty, which needs no other deserialization.\n        if(HLLType.EMPTY.equals(type)) {\n            return hll;\n        }\n\n        final int wordLength;\n        switch(type) {\n            case EXPLICIT:\n                wordLength = Long.SIZE;\n                break;\n            case SPARSE:\n                wordLength = hll.shortWordLength;\n                break;\n            case FULL:\n                wordLength = hll.regwidth;\n                break;\n            default:\n                throw new RuntimeException(\"Unsupported HLL type \" + type);\n        }\n\n        final IWordDeserializer deserializer =\n                schemaVersion.getDeserializer(type, wordLength, bytes);\n        switch(type) {\n            case EXPLICIT:\n                // NOTE:  This should not exceed expthresh and this will always\n                //        be exactly the number of words that were encoded,\n                //        because the word length is at least a byte wide.\n                // SEE:   IWordDeserializer#totalWordCount()\n                for(int i=0; i<deserializer.totalWordCount(); i++) {\n                    hll.explicitStorage.add(deserializer.readWord());\n                }\n                break;\n            case SPARSE:\n                // NOTE:  If the shortWordLength were smaller than 8 bits\n                //        (1 byte) there would be a possibility (because of\n                //        padding arithmetic) of having one or more extra\n                //        registers read. However, this is not relevant as the\n                //        extra registers will be all zeroes, which are ignored\n                //        in the sparse representation.\n                for(int i=0; i<deserializer.totalWordCount(); i++) {\n                    final long shortWord = deserializer.readWord();\n                    final byte registerValue = (byte)(shortWord & hll.valueMask);\n                    // Only set non-zero registers.\n                    if (registerValue != 0) {\n                        hll.sparseProbabilisticStorage.put((int)(shortWord >>> hll.regwidth), registerValue);\n                    }\n                }\n                break;\n            case FULL:\n                // NOTE:  Iteration is done using m (register count) and NOT\n                //        deserializer#totalWordCount() because regwidth may be\n                //        less than 8 and as such the padding on the 'last' byte\n                //        may be larger than regwidth, causing an extra register\n                //        to be read.\n                // SEE: IWordDeserializer#totalWordCount()\n                for(long i=0; i<hll.m; i++) {\n                    hll.probabilisticStorage.setRegister(i, deserializer.readWord());\n                }\n                break;\n            default:\n                throw new RuntimeException(\"Unsupported HLL type \" + type);\n        }\n\n        return hll;\n    }\n\n","sourceOld":"    /**\n     * Deserializes the HLL (in {@link #toBytes(ISchemaVersion)} format) serialized\n     * into <code>bytes</code>.<p/>\n     *\n     * @param  bytes the serialized bytes of new HLL\n     * @return the deserialized HLL. This will never be <code>null</code>.\n     *\n     * @see #toBytes(ISchemaVersion)\n     */\n    public static HLL fromBytes(final byte[] bytes) {\n        final ISchemaVersion schemaVersion = SerializationUtil.getSchemaVersion(bytes);\n        final IHLLMetadata metadata = schemaVersion.readMetadata(bytes);\n\n        final HLLType type = metadata.HLLType();\n        final int regwidth = metadata.registerWidth();\n        final int log2m = metadata.registerCountLog2();\n        final boolean sparseon = metadata.sparseEnabled();\n\n        final int expthresh;\n        if(metadata.explicitAuto()) {\n            expthresh = -1;\n        } else if(metadata.explicitOff()) {\n            expthresh = 0;\n        } else {\n            // NOTE: take into account that the postgres-compatible constructor\n            //       subtracts one before taking a power of two.\n            expthresh = metadata.log2ExplicitCutoff() + 1;\n        }\n\n        final HLL hll = new HLL(log2m, regwidth, expthresh, sparseon, type);\n\n        // Short-circuit on empty, which needs no other deserialization.\n        if(HLLType.EMPTY.equals(type)) {\n            return hll;\n        }\n\n        final int wordLength;\n        switch(type) {\n            case EXPLICIT:\n                wordLength = Long.SIZE;\n                break;\n            case SPARSE:\n                wordLength = hll.shortWordLength;\n                break;\n            case FULL:\n                wordLength = hll.regwidth;\n                break;\n            default:\n                throw new RuntimeException(\"Unsupported HLL type \" + type);\n        }\n\n        final IWordDeserializer deserializer =\n                schemaVersion.getDeserializer(type, wordLength, bytes);\n        switch(type) {\n            case EXPLICIT:\n                // NOTE:  This should not exceed expthresh and this will always\n                //        be exactly the number of words that were encoded,\n                //        because the word length is at least a byte wide.\n                // SEE:   IWordDeserializer#totalWordCount()\n                for(int i=0; i<deserializer.totalWordCount(); i++) {\n                    hll.explicitStorage.add(deserializer.readWord());\n                }\n                break;\n            case SPARSE:\n                // NOTE:  If the shortWordLength were smaller than 8 bits\n                //        (1 byte) there would be a possibility (because of\n                //        padding arithmetic) of having one or more extra\n                //        registers read. However, this is not relevant as the\n                //        extra registers will be all zeroes, which are ignored\n                //        in the sparse representation.\n                for(int i=0; i<deserializer.totalWordCount(); i++) {\n                    final long shortWord = deserializer.readWord();\n                    final byte registerValue = (byte)(shortWord & hll.valueMask);\n                    // Only set non-zero registers.\n                    if (registerValue != 0) {\n                        hll.sparseProbabilisticStorage.put((int)(shortWord >>> hll.regwidth), registerValue);\n                    }\n                }\n                break;\n            case FULL:\n                // NOTE:  Iteration is done using m (register count) and NOT\n                //        deserializer#totalWordCount() because regwidth may be\n                //        less than 8 and as such the padding on the 'last' byte\n                //        may be larger than regwidth, causing an extra register\n                //        to be read.\n                // SEE: IWordDeserializer#totalWordCount()\n                for(long i=0; i<hll.m; i++) {\n                    hll.probabilisticStorage.setRegister(i, deserializer.readWord());\n                }\n                break;\n            default:\n                throw new RuntimeException(\"Unsupported HLL type \" + type);\n        }\n\n        return hll;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3b5ee4c66244bdfcc4796a114519d47701b2c026","date":1437132013,"type":0,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/util/hll/HLL#fromBytes(byte[]).mjava","pathOld":"/dev/null","sourceNew":"    /**\n     * Deserializes the HLL (in {@link #toBytes(ISchemaVersion)} format) serialized\n     * into <code>bytes</code>.\n     *\n     * @param  bytes the serialized bytes of new HLL\n     * @return the deserialized HLL. This will never be <code>null</code>.\n     *\n     * @see #toBytes(ISchemaVersion)\n     */\n    public static HLL fromBytes(final byte[] bytes) {\n        final ISchemaVersion schemaVersion = SerializationUtil.getSchemaVersion(bytes);\n        final IHLLMetadata metadata = schemaVersion.readMetadata(bytes);\n\n        final HLLType type = metadata.HLLType();\n        final int regwidth = metadata.registerWidth();\n        final int log2m = metadata.registerCountLog2();\n        final boolean sparseon = metadata.sparseEnabled();\n\n        final int expthresh;\n        if(metadata.explicitAuto()) {\n            expthresh = -1;\n        } else if(metadata.explicitOff()) {\n            expthresh = 0;\n        } else {\n            // NOTE: take into account that the postgres-compatible constructor\n            //       subtracts one before taking a power of two.\n            expthresh = metadata.log2ExplicitCutoff() + 1;\n        }\n\n        final HLL hll = new HLL(log2m, regwidth, expthresh, sparseon, type);\n\n        // Short-circuit on empty, which needs no other deserialization.\n        if(HLLType.EMPTY.equals(type)) {\n            return hll;\n        }\n\n        final int wordLength;\n        switch(type) {\n            case EXPLICIT:\n                wordLength = Long.SIZE;\n                break;\n            case SPARSE:\n                wordLength = hll.shortWordLength;\n                break;\n            case FULL:\n                wordLength = hll.regwidth;\n                break;\n            default:\n                throw new RuntimeException(\"Unsupported HLL type \" + type);\n        }\n\n        final IWordDeserializer deserializer =\n                schemaVersion.getDeserializer(type, wordLength, bytes);\n        switch(type) {\n            case EXPLICIT:\n                // NOTE:  This should not exceed expthresh and this will always\n                //        be exactly the number of words that were encoded,\n                //        because the word length is at least a byte wide.\n                // SEE:   IWordDeserializer#totalWordCount()\n                for(int i=0; i<deserializer.totalWordCount(); i++) {\n                    hll.explicitStorage.add(deserializer.readWord());\n                }\n                break;\n            case SPARSE:\n                // NOTE:  If the shortWordLength were smaller than 8 bits\n                //        (1 byte) there would be a possibility (because of\n                //        padding arithmetic) of having one or more extra\n                //        registers read. However, this is not relevant as the\n                //        extra registers will be all zeroes, which are ignored\n                //        in the sparse representation.\n                for(int i=0; i<deserializer.totalWordCount(); i++) {\n                    final long shortWord = deserializer.readWord();\n                    final byte registerValue = (byte)(shortWord & hll.valueMask);\n                    // Only set non-zero registers.\n                    if (registerValue != 0) {\n                        hll.sparseProbabilisticStorage.put((int)(shortWord >>> hll.regwidth), registerValue);\n                    }\n                }\n                break;\n            case FULL:\n                // NOTE:  Iteration is done using m (register count) and NOT\n                //        deserializer#totalWordCount() because regwidth may be\n                //        less than 8 and as such the padding on the 'last' byte\n                //        may be larger than regwidth, causing an extra register\n                //        to be read.\n                // SEE: IWordDeserializer#totalWordCount()\n                for(long i=0; i<hll.m; i++) {\n                    hll.probabilisticStorage.setRegister(i, deserializer.readWord());\n                }\n                break;\n            default:\n                throw new RuntimeException(\"Unsupported HLL type \" + type);\n        }\n\n        return hll;\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3b5ee4c66244bdfcc4796a114519d47701b2c026":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3cee04f63da2b1e4185495f96d22b98fa63a4fa8"],"3cee04f63da2b1e4185495f96d22b98fa63a4fa8":["6d8714f9ceaaff94f0968d1c2d037978c3fde569"],"6d8714f9ceaaff94f0968d1c2d037978c3fde569":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3b5ee4c66244bdfcc4796a114519d47701b2c026"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3b5ee4c66244bdfcc4796a114519d47701b2c026","6d8714f9ceaaff94f0968d1c2d037978c3fde569"],"3b5ee4c66244bdfcc4796a114519d47701b2c026":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cee04f63da2b1e4185495f96d22b98fa63a4fa8":["3b5ee4c66244bdfcc4796a114519d47701b2c026"],"6d8714f9ceaaff94f0968d1c2d037978c3fde569":["3cee04f63da2b1e4185495f96d22b98fa63a4fa8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}