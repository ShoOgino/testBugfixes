{"path":"solr/core/src/test/org/apache/solr/cloud/CdcrReplicationDistributedZkTest#doTestResilienceWithDeleteByQueryOnTarget().mjava","commits":[{"id":"86290366cefc1b9d4eced13b430858c4a4c0421d","date":1432321109,"type":0,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/CdcrReplicationDistributedZkTest#doTestResilienceWithDeleteByQueryOnTarget().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Check resilience of replication with delete by query executed on targets\n   */\n  public void doTestResilienceWithDeleteByQueryOnTarget() throws Exception {\n    this.clearSourceCollection();\n    this.clearTargetCollection();\n\n    // Index 50 documents\n    int start = 0;\n    List<SolrInputDocument> docs = new ArrayList<>();\n    for (; start < 50; start++) {\n      docs.add(getDoc(id, Integer.toString(start)));\n    }\n    index(SOURCE_COLLECTION, docs);\n\n    // Start CDCR\n    this.invokeCdcrAction(shardToLeaderJetty.get(SOURCE_COLLECTION).get(SHARD1), CdcrParams.CdcrAction.START);\n\n    // wait a bit for the replication to complete\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD1);\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD2);\n\n    commit(TARGET_COLLECTION);\n\n    // If the non-leader node were buffering updates, then the replication must be complete\n    assertEquals(50, getNumDocs(SOURCE_COLLECTION));\n    assertEquals(50, getNumDocs(TARGET_COLLECTION));\n\n    deleteByQuery(SOURCE_COLLECTION, \"*:*\");\n    deleteByQuery(TARGET_COLLECTION, \"*:*\");\n\n    assertEquals(0, getNumDocs(SOURCE_COLLECTION));\n    assertEquals(0, getNumDocs(TARGET_COLLECTION));\n\n    docs.clear();\n    for (; start < 100; start++) {\n      docs.add(getDoc(id, Integer.toString(start)));\n    }\n    index(SOURCE_COLLECTION, docs);\n\n    // wait a bit for the replication to complete\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD1);\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD2);\n\n    commit(TARGET_COLLECTION);\n\n    assertEquals(50, getNumDocs(SOURCE_COLLECTION));\n    assertEquals(50, getNumDocs(TARGET_COLLECTION));\n\n    deleteByQuery(TARGET_COLLECTION, \"*:*\");\n\n    assertEquals(50, getNumDocs(SOURCE_COLLECTION));\n    assertEquals(0, getNumDocs(TARGET_COLLECTION));\n\n    // Restart CDCR\n    this.invokeCdcrAction(shardToLeaderJetty.get(SOURCE_COLLECTION).get(SHARD1), CdcrParams.CdcrAction.STOP);\n    Thread.sleep(500); // wait a bit for the state to synch\n    this.invokeCdcrAction(shardToLeaderJetty.get(SOURCE_COLLECTION).get(SHARD1), CdcrParams.CdcrAction.START);\n\n    docs.clear();\n    for (; start < 150; start++) {\n      docs.add(getDoc(id, Integer.toString(start)));\n    }\n    index(SOURCE_COLLECTION, docs);\n\n    // wait a bit for the replication to complete\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD1);\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD2);\n\n    commit(TARGET_COLLECTION);\n\n    assertEquals(100, getNumDocs(SOURCE_COLLECTION));\n    assertEquals(50, getNumDocs(TARGET_COLLECTION));\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4dcd1fe49b76116e7d358993339fe8adbb030638","date":1437151093,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/CdcrReplicationDistributedZkTest#doTestResilienceWithDeleteByQueryOnTarget().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/CdcrReplicationDistributedZkTest#doTestResilienceWithDeleteByQueryOnTarget().mjava","sourceNew":"  /**\n   * Check resilience of replication with delete by query executed on targets\n   */\n  public void doTestResilienceWithDeleteByQueryOnTarget() throws Exception {\n    this.clearSourceCollection();\n    this.clearTargetCollection();\n\n    // Index 50 documents\n    int start = 0;\n    List<SolrInputDocument> docs = new ArrayList<>();\n    for (; start < 50; start++) {\n      docs.add(getDoc(id, Integer.toString(start)));\n    }\n    index(SOURCE_COLLECTION, docs);\n\n    // Start CDCR\n    this.invokeCdcrAction(shardToLeaderJetty.get(SOURCE_COLLECTION).get(SHARD1), CdcrParams.CdcrAction.START);\n    this.waitForCdcrStateReplication(SOURCE_COLLECTION);\n\n    // wait a bit for the replication to complete\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD1);\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD2);\n\n    commit(TARGET_COLLECTION);\n\n    // If the non-leader node were buffering updates, then the replication must be complete\n    assertEquals(50, getNumDocs(SOURCE_COLLECTION));\n    assertEquals(50, getNumDocs(TARGET_COLLECTION));\n\n    deleteByQuery(SOURCE_COLLECTION, \"*:*\");\n    deleteByQuery(TARGET_COLLECTION, \"*:*\");\n\n    assertEquals(0, getNumDocs(SOURCE_COLLECTION));\n    assertEquals(0, getNumDocs(TARGET_COLLECTION));\n\n    docs.clear();\n    for (; start < 100; start++) {\n      docs.add(getDoc(id, Integer.toString(start)));\n    }\n    index(SOURCE_COLLECTION, docs);\n\n    // wait a bit for the replication to complete\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD1);\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD2);\n\n    commit(TARGET_COLLECTION);\n\n    assertEquals(50, getNumDocs(SOURCE_COLLECTION));\n    assertEquals(50, getNumDocs(TARGET_COLLECTION));\n\n    deleteByQuery(TARGET_COLLECTION, \"*:*\");\n\n    assertEquals(50, getNumDocs(SOURCE_COLLECTION));\n    assertEquals(0, getNumDocs(TARGET_COLLECTION));\n\n    // Restart CDCR\n    this.invokeCdcrAction(shardToLeaderJetty.get(SOURCE_COLLECTION).get(SHARD1), CdcrParams.CdcrAction.STOP);\n    this.waitForCdcrStateReplication(SOURCE_COLLECTION);\n    this.invokeCdcrAction(shardToLeaderJetty.get(SOURCE_COLLECTION).get(SHARD1), CdcrParams.CdcrAction.START);\n    this.waitForCdcrStateReplication(SOURCE_COLLECTION);\n\n    docs.clear();\n    for (; start < 150; start++) {\n      docs.add(getDoc(id, Integer.toString(start)));\n    }\n    index(SOURCE_COLLECTION, docs);\n\n    // wait a bit for the replication to complete\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD1);\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD2);\n\n    commit(TARGET_COLLECTION);\n\n    assertEquals(100, getNumDocs(SOURCE_COLLECTION));\n    assertEquals(50, getNumDocs(TARGET_COLLECTION));\n  }\n\n","sourceOld":"  /**\n   * Check resilience of replication with delete by query executed on targets\n   */\n  public void doTestResilienceWithDeleteByQueryOnTarget() throws Exception {\n    this.clearSourceCollection();\n    this.clearTargetCollection();\n\n    // Index 50 documents\n    int start = 0;\n    List<SolrInputDocument> docs = new ArrayList<>();\n    for (; start < 50; start++) {\n      docs.add(getDoc(id, Integer.toString(start)));\n    }\n    index(SOURCE_COLLECTION, docs);\n\n    // Start CDCR\n    this.invokeCdcrAction(shardToLeaderJetty.get(SOURCE_COLLECTION).get(SHARD1), CdcrParams.CdcrAction.START);\n\n    // wait a bit for the replication to complete\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD1);\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD2);\n\n    commit(TARGET_COLLECTION);\n\n    // If the non-leader node were buffering updates, then the replication must be complete\n    assertEquals(50, getNumDocs(SOURCE_COLLECTION));\n    assertEquals(50, getNumDocs(TARGET_COLLECTION));\n\n    deleteByQuery(SOURCE_COLLECTION, \"*:*\");\n    deleteByQuery(TARGET_COLLECTION, \"*:*\");\n\n    assertEquals(0, getNumDocs(SOURCE_COLLECTION));\n    assertEquals(0, getNumDocs(TARGET_COLLECTION));\n\n    docs.clear();\n    for (; start < 100; start++) {\n      docs.add(getDoc(id, Integer.toString(start)));\n    }\n    index(SOURCE_COLLECTION, docs);\n\n    // wait a bit for the replication to complete\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD1);\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD2);\n\n    commit(TARGET_COLLECTION);\n\n    assertEquals(50, getNumDocs(SOURCE_COLLECTION));\n    assertEquals(50, getNumDocs(TARGET_COLLECTION));\n\n    deleteByQuery(TARGET_COLLECTION, \"*:*\");\n\n    assertEquals(50, getNumDocs(SOURCE_COLLECTION));\n    assertEquals(0, getNumDocs(TARGET_COLLECTION));\n\n    // Restart CDCR\n    this.invokeCdcrAction(shardToLeaderJetty.get(SOURCE_COLLECTION).get(SHARD1), CdcrParams.CdcrAction.STOP);\n    Thread.sleep(500); // wait a bit for the state to synch\n    this.invokeCdcrAction(shardToLeaderJetty.get(SOURCE_COLLECTION).get(SHARD1), CdcrParams.CdcrAction.START);\n\n    docs.clear();\n    for (; start < 150; start++) {\n      docs.add(getDoc(id, Integer.toString(start)));\n    }\n    index(SOURCE_COLLECTION, docs);\n\n    // wait a bit for the replication to complete\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD1);\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD2);\n\n    commit(TARGET_COLLECTION);\n\n    assertEquals(100, getNumDocs(SOURCE_COLLECTION));\n    assertEquals(50, getNumDocs(TARGET_COLLECTION));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e586ff50ac71d5ef3a27ced78f69deb41ab35ad5","date":1446841099,"type":5,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/CdcrReplicationDistributedZkTest#testResilienceWithDeleteByQueryOnTarget().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/CdcrReplicationDistributedZkTest#doTestResilienceWithDeleteByQueryOnTarget().mjava","sourceNew":"  /**\n   * Check resilience of replication with delete by query executed on targets\n   */\n  @Test\n  @ShardsFixed(num = 4)\n  public void testResilienceWithDeleteByQueryOnTarget() throws Exception {\n    // Index 50 documents\n    int start = 0;\n    List<SolrInputDocument> docs = new ArrayList<>();\n    for (; start < 50; start++) {\n      docs.add(getDoc(id, Integer.toString(start)));\n    }\n    index(SOURCE_COLLECTION, docs);\n\n    // Start CDCR\n    this.invokeCdcrAction(shardToLeaderJetty.get(SOURCE_COLLECTION).get(SHARD1), CdcrParams.CdcrAction.START);\n    this.waitForCdcrStateReplication(SOURCE_COLLECTION);\n\n    // wait a bit for the replication to complete\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD1);\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD2);\n\n    commit(TARGET_COLLECTION);\n\n    // If the non-leader node were buffering updates, then the replication must be complete\n    assertNumDocs(50, SOURCE_COLLECTION);\n    assertNumDocs(50, TARGET_COLLECTION);\n\n    deleteByQuery(SOURCE_COLLECTION, \"*:*\");\n    deleteByQuery(TARGET_COLLECTION, \"*:*\");\n\n    assertNumDocs(0, SOURCE_COLLECTION);\n    assertNumDocs(0, TARGET_COLLECTION);\n\n    docs.clear();\n    for (; start < 100; start++) {\n      docs.add(getDoc(id, Integer.toString(start)));\n    }\n    index(SOURCE_COLLECTION, docs);\n\n    // wait a bit for the replication to complete\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD1);\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD2);\n\n    commit(TARGET_COLLECTION);\n\n    assertNumDocs(50, SOURCE_COLLECTION);\n    assertNumDocs(50, TARGET_COLLECTION);\n\n    deleteByQuery(TARGET_COLLECTION, \"*:*\");\n\n    assertNumDocs(50, SOURCE_COLLECTION);\n    assertNumDocs(0, TARGET_COLLECTION);\n\n    // Restart CDCR\n    this.invokeCdcrAction(shardToLeaderJetty.get(SOURCE_COLLECTION).get(SHARD1), CdcrParams.CdcrAction.STOP);\n    this.waitForCdcrStateReplication(SOURCE_COLLECTION);\n    this.invokeCdcrAction(shardToLeaderJetty.get(SOURCE_COLLECTION).get(SHARD1), CdcrParams.CdcrAction.START);\n    this.waitForCdcrStateReplication(SOURCE_COLLECTION);\n\n    docs.clear();\n    for (; start < 150; start++) {\n      docs.add(getDoc(id, Integer.toString(start)));\n    }\n    index(SOURCE_COLLECTION, docs);\n\n    // wait a bit for the replication to complete\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD1);\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD2);\n\n    commit(TARGET_COLLECTION);\n\n    assertNumDocs(100, SOURCE_COLLECTION);\n    assertNumDocs(50, TARGET_COLLECTION);\n  }\n\n","sourceOld":"  /**\n   * Check resilience of replication with delete by query executed on targets\n   */\n  public void doTestResilienceWithDeleteByQueryOnTarget() throws Exception {\n    this.clearSourceCollection();\n    this.clearTargetCollection();\n\n    // Index 50 documents\n    int start = 0;\n    List<SolrInputDocument> docs = new ArrayList<>();\n    for (; start < 50; start++) {\n      docs.add(getDoc(id, Integer.toString(start)));\n    }\n    index(SOURCE_COLLECTION, docs);\n\n    // Start CDCR\n    this.invokeCdcrAction(shardToLeaderJetty.get(SOURCE_COLLECTION).get(SHARD1), CdcrParams.CdcrAction.START);\n    this.waitForCdcrStateReplication(SOURCE_COLLECTION);\n\n    // wait a bit for the replication to complete\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD1);\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD2);\n\n    commit(TARGET_COLLECTION);\n\n    // If the non-leader node were buffering updates, then the replication must be complete\n    assertEquals(50, getNumDocs(SOURCE_COLLECTION));\n    assertEquals(50, getNumDocs(TARGET_COLLECTION));\n\n    deleteByQuery(SOURCE_COLLECTION, \"*:*\");\n    deleteByQuery(TARGET_COLLECTION, \"*:*\");\n\n    assertEquals(0, getNumDocs(SOURCE_COLLECTION));\n    assertEquals(0, getNumDocs(TARGET_COLLECTION));\n\n    docs.clear();\n    for (; start < 100; start++) {\n      docs.add(getDoc(id, Integer.toString(start)));\n    }\n    index(SOURCE_COLLECTION, docs);\n\n    // wait a bit for the replication to complete\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD1);\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD2);\n\n    commit(TARGET_COLLECTION);\n\n    assertEquals(50, getNumDocs(SOURCE_COLLECTION));\n    assertEquals(50, getNumDocs(TARGET_COLLECTION));\n\n    deleteByQuery(TARGET_COLLECTION, \"*:*\");\n\n    assertEquals(50, getNumDocs(SOURCE_COLLECTION));\n    assertEquals(0, getNumDocs(TARGET_COLLECTION));\n\n    // Restart CDCR\n    this.invokeCdcrAction(shardToLeaderJetty.get(SOURCE_COLLECTION).get(SHARD1), CdcrParams.CdcrAction.STOP);\n    this.waitForCdcrStateReplication(SOURCE_COLLECTION);\n    this.invokeCdcrAction(shardToLeaderJetty.get(SOURCE_COLLECTION).get(SHARD1), CdcrParams.CdcrAction.START);\n    this.waitForCdcrStateReplication(SOURCE_COLLECTION);\n\n    docs.clear();\n    for (; start < 150; start++) {\n      docs.add(getDoc(id, Integer.toString(start)));\n    }\n    index(SOURCE_COLLECTION, docs);\n\n    // wait a bit for the replication to complete\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD1);\n    this.waitForReplicationToComplete(SOURCE_COLLECTION, SHARD2);\n\n    commit(TARGET_COLLECTION);\n\n    assertEquals(100, getNumDocs(SOURCE_COLLECTION));\n    assertEquals(50, getNumDocs(TARGET_COLLECTION));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"86290366cefc1b9d4eced13b430858c4a4c0421d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"e586ff50ac71d5ef3a27ced78f69deb41ab35ad5":["4dcd1fe49b76116e7d358993339fe8adbb030638"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4dcd1fe49b76116e7d358993339fe8adbb030638":["86290366cefc1b9d4eced13b430858c4a4c0421d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e586ff50ac71d5ef3a27ced78f69deb41ab35ad5"]},"commit2Childs":{"86290366cefc1b9d4eced13b430858c4a4c0421d":["4dcd1fe49b76116e7d358993339fe8adbb030638"],"e586ff50ac71d5ef3a27ced78f69deb41ab35ad5":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["86290366cefc1b9d4eced13b430858c4a4c0421d"],"4dcd1fe49b76116e7d358993339fe8adbb030638":["e586ff50ac71d5ef3a27ced78f69deb41ab35ad5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}