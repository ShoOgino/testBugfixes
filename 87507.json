{"path":"lucene/src/java/org/apache/lucene/index/values/VarStraightBytesImpl.Writer#merge(SingleSubMergeState).mjava","commits":[{"id":"32aca6bb0a6aa0a1813e7d035ac0e039f54269f4","date":1318260487,"type":1,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/values/VarStraightBytesImpl.Writer#merge(SingleSubMergeState).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/values/VarStraightBytesImpl.Writer#merge(MergeState).mjava","sourceNew":"    @Override\n    protected void merge(SingleSubMergeState state) throws IOException {\n      merge = true;\n      datOut = getOrCreateDataOut();\n      boolean success = false;\n      try {\n        if (state.liveDocs == null && state.reader instanceof VarStraightReader) {\n          // bulk merge since we don't have any deletes\n          VarStraightReader reader = (VarStraightReader) state.reader;\n          final int maxDocs = reader.maxDoc;\n          if (maxDocs == 0) {\n            return;\n          }\n          if (lastDocID+1 < state.docBase) {\n            fill(state.docBase, address);\n            lastDocID = state.docBase-1;\n          }\n          final long numDataBytes;\n          final IndexInput cloneIdx = reader.cloneIndex();\n          try {\n            numDataBytes = cloneIdx.readVLong();\n            final ReaderIterator iter = PackedInts.getReaderIterator(cloneIdx);\n            for (int i = 0; i < maxDocs; i++) {\n              long offset = iter.next();\n              ++lastDocID;\n              if (lastDocID >= docToAddress.length) {\n                int oldSize = docToAddress.length;\n                docToAddress = ArrayUtil.grow(docToAddress, 1 + lastDocID);\n                bytesUsed.addAndGet((docToAddress.length - oldSize)\n                    * RamUsageEstimator.NUM_BYTES_INT);\n              }\n              docToAddress[lastDocID] = address + offset;\n            }\n            address += numDataBytes; // this is the address after all addr pointers are updated\n            iter.close();\n          } finally {\n            IOUtils.close(cloneIdx);\n          }\n          final IndexInput cloneData = reader.cloneData();\n          try {\n            datOut.copyBytes(cloneData, numDataBytes);\n          } finally {\n            IOUtils.close(cloneData);  \n          }\n        } else {\n          super.merge(state);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          IOUtils.closeWhileHandlingException(datOut);\n        }\n      }\n    }\n\n","sourceOld":"    @Override\n    protected void merge(MergeState state) throws IOException {\n      merge = true;\n      datOut = getOrCreateDataOut();\n      boolean success = false;\n      try {\n        if (state.liveDocs == null && state.reader instanceof VarStraightReader) {\n          // bulk merge since we don't have any deletes\n          VarStraightReader reader = (VarStraightReader) state.reader;\n          final int maxDocs = reader.maxDoc;\n          if (maxDocs == 0) {\n            return;\n          }\n          if (lastDocID+1 < state.docBase) {\n            fill(state.docBase, address);\n            lastDocID = state.docBase-1;\n          }\n          final long numDataBytes;\n          final IndexInput cloneIdx = reader.cloneIndex();\n          try {\n            numDataBytes = cloneIdx.readVLong();\n            final ReaderIterator iter = PackedInts.getReaderIterator(cloneIdx);\n            for (int i = 0; i < maxDocs; i++) {\n              long offset = iter.next();\n              ++lastDocID;\n              if (lastDocID >= docToAddress.length) {\n                int oldSize = docToAddress.length;\n                docToAddress = ArrayUtil.grow(docToAddress, 1 + lastDocID);\n                bytesUsed.addAndGet((docToAddress.length - oldSize)\n                    * RamUsageEstimator.NUM_BYTES_INT);\n              }\n              docToAddress[lastDocID] = address + offset;\n            }\n            address += numDataBytes; // this is the address after all addr pointers are updated\n            iter.close();\n          } finally {\n            IOUtils.close(cloneIdx);\n          }\n          final IndexInput cloneData = reader.cloneData();\n          try {\n            datOut.copyBytes(cloneData, numDataBytes);\n          } finally {\n            IOUtils.close(cloneData);  \n          }\n        } else {\n          super.merge(state);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          IOUtils.closeWhileHandlingException(datOut);\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f9efc72acdea22f5285be0a808f8bba51bb8e367","date":1323217280,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/values/VarStraightBytesImpl.Writer#merge(SingleSubMergeState).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/values/VarStraightBytesImpl.Writer#merge(SingleSubMergeState).mjava","sourceNew":"    @Override\n    protected void merge(SingleSubMergeState state) throws IOException {\n      merge = true;\n      datOut = getOrCreateDataOut();\n      boolean success = false;\n      try {\n        if (state.liveDocs == null && state.reader instanceof VarStraightReader) {\n          // bulk merge since we don't have any deletes\n          VarStraightReader reader = (VarStraightReader) state.reader;\n          final int maxDocs = reader.maxDoc;\n          if (maxDocs == 0) {\n            return;\n          }\n          if (lastDocID+1 < state.docBase) {\n            fill(state.docBase, address);\n            lastDocID = state.docBase-1;\n          }\n          final long numDataBytes;\n          final IndexInput cloneIdx = reader.cloneIndex();\n          try {\n            numDataBytes = cloneIdx.readVLong();\n            final ReaderIterator iter = PackedInts.getReaderIterator(cloneIdx);\n            for (int i = 0; i < maxDocs; i++) {\n              long offset = iter.next();\n              ++lastDocID;\n              if (lastDocID >= docToAddress.length) {\n                int oldSize = docToAddress.length;\n                docToAddress = ArrayUtil.grow(docToAddress, 1 + lastDocID);\n                bytesUsed.addAndGet((docToAddress.length - oldSize)\n                    * RamUsageEstimator.NUM_BYTES_INT);\n              }\n              docToAddress[lastDocID] = address + offset;\n            }\n            address += numDataBytes; // this is the address after all addr pointers are updated\n            iter.close();\n          } finally {\n            IOUtils.close(cloneIdx);\n          }\n          final IndexInput cloneData = reader.cloneData();\n          try {\n            datOut.copyBytes(cloneData, numDataBytes);\n          } finally {\n            IOUtils.close(cloneData);  \n          }\n        } else {\n          super.merge(state);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          IOUtils.closeWhileHandlingException(datOut);\n        }\n      }\n    }\n\n","sourceOld":"    @Override\n    protected void merge(SingleSubMergeState state) throws IOException {\n      merge = true;\n      datOut = getOrCreateDataOut();\n      boolean success = false;\n      try {\n        if (state.liveDocs == null && state.reader instanceof VarStraightReader) {\n          // bulk merge since we don't have any deletes\n          VarStraightReader reader = (VarStraightReader) state.reader;\n          final int maxDocs = reader.maxDoc;\n          if (maxDocs == 0) {\n            return;\n          }\n          if (lastDocID+1 < state.docBase) {\n            fill(state.docBase, address);\n            lastDocID = state.docBase-1;\n          }\n          final long numDataBytes;\n          final IndexInput cloneIdx = reader.cloneIndex();\n          try {\n            numDataBytes = cloneIdx.readVLong();\n            final ReaderIterator iter = PackedInts.getReaderIterator(cloneIdx);\n            for (int i = 0; i < maxDocs; i++) {\n              long offset = iter.next();\n              ++lastDocID;\n              if (lastDocID >= docToAddress.length) {\n                int oldSize = docToAddress.length;\n                docToAddress = ArrayUtil.grow(docToAddress, 1 + lastDocID);\n                bytesUsed.addAndGet((docToAddress.length - oldSize)\n                    * RamUsageEstimator.NUM_BYTES_INT);\n              }\n              docToAddress[lastDocID] = address + offset;\n            }\n            address += numDataBytes; // this is the address after all addr pointers are updated\n            iter.close();\n          } finally {\n            IOUtils.close(cloneIdx);\n          }\n          final IndexInput cloneData = reader.cloneData();\n          try {\n            datOut.copyBytes(cloneData, numDataBytes);\n          } finally {\n            IOUtils.close(cloneData);  \n          }\n        } else {\n          super.merge(state);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          IOUtils.closeWhileHandlingException(datOut);\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d638301ad1cfcae567b681b893bc8781f0ee48a5","date":1323801546,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/values/VarStraightBytesImpl.Writer#merge(SingleSubMergeState).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/values/VarStraightBytesImpl.Writer#merge(SingleSubMergeState).mjava","sourceNew":"    @Override\n    protected void merge(SingleSubMergeState state) throws IOException {\n      merge = true;\n      datOut = getOrCreateDataOut();\n      boolean success = false;\n      try {\n        if (state.liveDocs == null && state.reader instanceof VarStraightReader) {\n          // bulk merge since we don't have any deletes\n          VarStraightReader reader = (VarStraightReader) state.reader;\n          final int maxDocs = reader.maxDoc;\n          if (maxDocs == 0) {\n            return;\n          }\n          if (lastDocID+1 < state.docBase) {\n            fill(state.docBase, address);\n            lastDocID = state.docBase-1;\n          }\n          final long numDataBytes;\n          final IndexInput cloneIdx = reader.cloneIndex();\n          try {\n            numDataBytes = cloneIdx.readVLong();\n            final ReaderIterator iter = PackedInts.getReaderIterator(cloneIdx);\n            for (int i = 0; i < maxDocs; i++) {\n              long offset = iter.next();\n              ++lastDocID;\n              if (lastDocID >= docToAddress.length) {\n                int oldSize = docToAddress.length;\n                docToAddress = ArrayUtil.grow(docToAddress, 1 + lastDocID);\n                bytesUsed.addAndGet((docToAddress.length - oldSize)\n                    * RamUsageEstimator.NUM_BYTES_INT);\n              }\n              docToAddress[lastDocID] = address + offset;\n            }\n            address += numDataBytes; // this is the address after all addr pointers are updated\n            iter.close();\n          } finally {\n            IOUtils.close(cloneIdx);\n          }\n          final IndexInput cloneData = reader.cloneData();\n          try {\n            datOut.copyBytes(cloneData, numDataBytes);\n          } finally {\n            IOUtils.close(cloneData);  \n          }\n        } else {\n          super.merge(state);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          IOUtils.closeWhileHandlingException(datOut);\n        }\n      }\n    }\n\n","sourceOld":"    @Override\n    protected void merge(SingleSubMergeState state) throws IOException {\n      merge = true;\n      datOut = getOrCreateDataOut();\n      boolean success = false;\n      try {\n        if (state.liveDocs == null && state.reader instanceof VarStraightReader) {\n          // bulk merge since we don't have any deletes\n          VarStraightReader reader = (VarStraightReader) state.reader;\n          final int maxDocs = reader.maxDoc;\n          if (maxDocs == 0) {\n            return;\n          }\n          if (lastDocID+1 < state.docBase) {\n            fill(state.docBase, address);\n            lastDocID = state.docBase-1;\n          }\n          final long numDataBytes;\n          final IndexInput cloneIdx = reader.cloneIndex();\n          try {\n            numDataBytes = cloneIdx.readVLong();\n            final ReaderIterator iter = PackedInts.getReaderIterator(cloneIdx);\n            for (int i = 0; i < maxDocs; i++) {\n              long offset = iter.next();\n              ++lastDocID;\n              if (lastDocID >= docToAddress.length) {\n                int oldSize = docToAddress.length;\n                docToAddress = ArrayUtil.grow(docToAddress, 1 + lastDocID);\n                bytesUsed.addAndGet((docToAddress.length - oldSize)\n                    * RamUsageEstimator.NUM_BYTES_INT);\n              }\n              docToAddress[lastDocID] = address + offset;\n            }\n            address += numDataBytes; // this is the address after all addr pointers are updated\n            iter.close();\n          } finally {\n            IOUtils.close(cloneIdx);\n          }\n          final IndexInput cloneData = reader.cloneData();\n          try {\n            datOut.copyBytes(cloneData, numDataBytes);\n          } finally {\n            IOUtils.close(cloneData);  \n          }\n        } else {\n          super.merge(state);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          IOUtils.closeWhileHandlingException(datOut);\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"f9efc72acdea22f5285be0a808f8bba51bb8e367":["32aca6bb0a6aa0a1813e7d035ac0e039f54269f4"],"32aca6bb0a6aa0a1813e7d035ac0e039f54269f4":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d638301ad1cfcae567b681b893bc8781f0ee48a5"],"d638301ad1cfcae567b681b893bc8781f0ee48a5":["32aca6bb0a6aa0a1813e7d035ac0e039f54269f4","f9efc72acdea22f5285be0a808f8bba51bb8e367"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["32aca6bb0a6aa0a1813e7d035ac0e039f54269f4"],"f9efc72acdea22f5285be0a808f8bba51bb8e367":["d638301ad1cfcae567b681b893bc8781f0ee48a5"],"32aca6bb0a6aa0a1813e7d035ac0e039f54269f4":["f9efc72acdea22f5285be0a808f8bba51bb8e367","d638301ad1cfcae567b681b893bc8781f0ee48a5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"d638301ad1cfcae567b681b893bc8781f0ee48a5":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}