{"path":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","sourceNew":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n      Document d1 = new Document();\n      d1.add(new Field(\"f1\", \"first field\", StringField.TYPE_STORED));\n      d1.add(new Field(\"f2\", \"second field\", StringField.TYPE_STORED));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.close();\n        writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\"));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\"));\n      d2.add(new TextField(\"f4\", \"fourth field\"));\n      writer.addDocument(d2);\n\n      writer.close();\n\n      SegmentInfos sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = sis.info(0).getFieldInfos();\n      FieldInfos fis2 = sis.info(1).getFieldInfos();\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      writer.forceMerge(1);\n      writer.close();\n\n      sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = sis.info(0).getFieldInfos();\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n      Document d1 = new Document();\n      d1.add(new Field(\"f1\", \"first field\", StringField.TYPE_STORED));\n      d1.add(new Field(\"f2\", \"second field\", StringField.TYPE_STORED));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.close();\n        writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\"));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\"));\n      d2.add(new TextField(\"f4\", \"fourth field\"));\n      writer.addDocument(d2);\n\n      writer.close();\n\n      SegmentInfos sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = sis.info(0).getFieldInfos();\n      FieldInfos fis2 = sis.info(1).getFieldInfos();\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      writer.forceMerge(1);\n      writer.close();\n\n      sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = sis.info(0).getFieldInfos();\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","sourceNew":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n      Document d1 = new Document();\n      d1.add(new Field(\"f1\", \"first field\", StringField.TYPE_STORED));\n      d1.add(new Field(\"f2\", \"second field\", StringField.TYPE_STORED));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.close();\n        writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\"));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\"));\n      d2.add(new TextField(\"f4\", \"fourth field\"));\n      writer.addDocument(d2);\n\n      writer.close();\n\n      SegmentInfos sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = sis.info(0).getFieldInfos();\n      FieldInfos fis2 = sis.info(1).getFieldInfos();\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      writer.forceMerge(1);\n      writer.close();\n\n      sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = sis.info(0).getFieldInfos();\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n      Document d1 = new Document();\n      d1.add(new Field(\"f1\", \"first field\", StringField.TYPE_STORED));\n      d1.add(new Field(\"f2\", \"second field\", StringField.TYPE_STORED));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.close();\n        writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\"));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\"));\n      d2.add(new TextField(\"f4\", \"fourth field\"));\n      writer.addDocument(d2);\n\n      writer.close();\n\n      SegmentInfos sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = sis.info(0).getFieldInfos();\n      FieldInfos fis2 = sis.info(1).getFieldInfos();\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      writer.forceMerge(1);\n      writer.close();\n\n      sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = sis.info(0).getFieldInfos();\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d2dee33619431ada2a7a07f5fe2dbd94bac6a460","date":1337274029,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","sourceNew":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n      Document d1 = new Document();\n      d1.add(new Field(\"f1\", \"first field\", StringField.TYPE_STORED));\n      d1.add(new Field(\"f2\", \"second field\", StringField.TYPE_STORED));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.close();\n        writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\"));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\"));\n      d2.add(new TextField(\"f4\", \"fourth field\"));\n      writer.addDocument(d2);\n\n      writer.close();\n\n      SegmentInfos sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = _TestUtil.getFieldInfos(sis.info(0));\n      FieldInfos fis2 = _TestUtil.getFieldInfos(sis.info(1));\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      writer.forceMerge(1);\n      writer.close();\n\n      sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = _TestUtil.getFieldInfos(sis.info(0));\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n      Document d1 = new Document();\n      d1.add(new Field(\"f1\", \"first field\", StringField.TYPE_STORED));\n      d1.add(new Field(\"f2\", \"second field\", StringField.TYPE_STORED));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.close();\n        writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\"));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\"));\n      d2.add(new TextField(\"f4\", \"fourth field\"));\n      writer.addDocument(d2);\n\n      writer.close();\n\n      SegmentInfos sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = sis.info(0).getFieldInfos();\n      FieldInfos fis2 = sis.info(1).getFieldInfos();\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      writer.forceMerge(1);\n      writer.close();\n\n      sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = sis.info(0).getFieldInfos();\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9d153abcf92dc5329d98571a8c3035df9bd80648","date":1337702630,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","sourceNew":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n      Document d1 = new Document();\n      d1.add(new Field(\"f1\", \"first field\", StringField.TYPE_STORED));\n      d1.add(new Field(\"f2\", \"second field\", StringField.TYPE_STORED));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.close();\n        writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\"));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\"));\n      d2.add(new TextField(\"f4\", \"fourth field\"));\n      writer.addDocument(d2);\n\n      writer.close();\n\n      SegmentInfos sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = _TestUtil.getFieldInfos(sis.info(0).info);\n      FieldInfos fis2 = _TestUtil.getFieldInfos(sis.info(1).info);\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      writer.forceMerge(1);\n      writer.close();\n\n      sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = _TestUtil.getFieldInfos(sis.info(0).info);\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n      Document d1 = new Document();\n      d1.add(new Field(\"f1\", \"first field\", StringField.TYPE_STORED));\n      d1.add(new Field(\"f2\", \"second field\", StringField.TYPE_STORED));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.close();\n        writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\"));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\"));\n      d2.add(new TextField(\"f4\", \"fourth field\"));\n      writer.addDocument(d2);\n\n      writer.close();\n\n      SegmentInfos sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = _TestUtil.getFieldInfos(sis.info(0));\n      FieldInfos fis2 = _TestUtil.getFieldInfos(sis.info(1));\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      writer.forceMerge(1);\n      writer.close();\n\n      sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = _TestUtil.getFieldInfos(sis.info(0));\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"615ddbd81799980d0fdd95e0238e1c498b6f47b0","date":1338233290,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","sourceNew":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n      Document d1 = new Document();\n      d1.add(new Field(\"f1\", \"first field\", StringField.TYPE_STORED));\n      d1.add(new Field(\"f2\", \"second field\", StringField.TYPE_STORED));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.close();\n        writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\"));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\"));\n      d2.add(new TextField(\"f4\", \"fourth field\"));\n      writer.addDocument(d2);\n\n      writer.close();\n\n      SegmentInfos sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = _TestUtil.getFieldInfos(sis.info(0).info);\n      FieldInfos fis2 = _TestUtil.getFieldInfos(sis.info(1).info);\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      writer.forceMerge(1);\n      writer.close();\n\n      sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = _TestUtil.getFieldInfos(sis.info(0).info);\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n      Document d1 = new Document();\n      d1.add(new Field(\"f1\", \"first field\", StringField.TYPE_STORED));\n      d1.add(new Field(\"f2\", \"second field\", StringField.TYPE_STORED));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.close();\n        writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\"));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\"));\n      d2.add(new TextField(\"f4\", \"fourth field\"));\n      writer.addDocument(d2);\n\n      writer.close();\n\n      SegmentInfos sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = sis.info(0).getFieldInfos();\n      FieldInfos fis2 = sis.info(1).getFieldInfos();\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      writer.forceMerge(1);\n      writer.close();\n\n      sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = sis.info(0).getFieldInfos();\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"04f07771a2a7dd3a395700665ed839c3dae2def2","date":1339350139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","sourceNew":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n      Document d1 = new Document();\n      d1.add(new StringField(\"f1\", \"first field\", Field.Store.YES));\n      d1.add(new StringField(\"f2\", \"second field\", Field.Store.YES));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.close();\n        writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\", Field.Store.NO));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\", Field.Store.NO));\n      d2.add(new TextField(\"f4\", \"fourth field\", Field.Store.NO));\n      writer.addDocument(d2);\n\n      writer.close();\n\n      SegmentInfos sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = _TestUtil.getFieldInfos(sis.info(0).info);\n      FieldInfos fis2 = _TestUtil.getFieldInfos(sis.info(1).info);\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      writer.forceMerge(1);\n      writer.close();\n\n      sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = _TestUtil.getFieldInfos(sis.info(0).info);\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n      Document d1 = new Document();\n      d1.add(new Field(\"f1\", \"first field\", StringField.TYPE_STORED));\n      d1.add(new Field(\"f2\", \"second field\", StringField.TYPE_STORED));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.close();\n        writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\"));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\"));\n      d2.add(new TextField(\"f4\", \"fourth field\"));\n      writer.addDocument(d2);\n\n      writer.close();\n\n      SegmentInfos sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = _TestUtil.getFieldInfos(sis.info(0).info);\n      FieldInfos fis2 = _TestUtil.getFieldInfos(sis.info(1).info);\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      writer.forceMerge(1);\n      writer.close();\n\n      sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = _TestUtil.getFieldInfos(sis.info(0).info);\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","bugFix":["1509f151d7692d84fae414b2b799ac06ba60fcb4","7e4db59c6b6c10e25322cfb41c4c19d78b4298bd"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8435160e9702b19398118ddf76b61c846612b6a4","date":1380349140,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","sourceNew":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n      Document d1 = new Document();\n      d1.add(new StringField(\"f1\", \"first field\", Field.Store.YES));\n      d1.add(new StringField(\"f2\", \"second field\", Field.Store.YES));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.close();\n        writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\", Field.Store.NO));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\", Field.Store.NO));\n      d2.add(new TextField(\"f4\", \"fourth field\", Field.Store.NO));\n      writer.addDocument(d2);\n\n      writer.close();\n\n      SegmentInfos sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = SegmentReader.readFieldInfos(sis.info(0));\n      FieldInfos fis2 = SegmentReader.readFieldInfos(sis.info(1));\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      writer.forceMerge(1);\n      writer.close();\n\n      sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = SegmentReader.readFieldInfos(sis.info(0));\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n      Document d1 = new Document();\n      d1.add(new StringField(\"f1\", \"first field\", Field.Store.YES));\n      d1.add(new StringField(\"f2\", \"second field\", Field.Store.YES));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.close();\n        writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\", Field.Store.NO));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\", Field.Store.NO));\n      d2.add(new TextField(\"f4\", \"fourth field\", Field.Store.NO));\n      writer.addDocument(d2);\n\n      writer.close();\n\n      SegmentInfos sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = _TestUtil.getFieldInfos(sis.info(0).info);\n      FieldInfos fis2 = _TestUtil.getFieldInfos(sis.info(1).info);\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      writer.forceMerge(1);\n      writer.close();\n\n      sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = _TestUtil.getFieldInfos(sis.info(0).info);\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","sourceNew":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n      Document d1 = new Document();\n      d1.add(new StringField(\"f1\", \"first field\", Field.Store.YES));\n      d1.add(new StringField(\"f2\", \"second field\", Field.Store.YES));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.shutdown();\n        writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\", Field.Store.NO));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\", Field.Store.NO));\n      d2.add(new TextField(\"f4\", \"fourth field\", Field.Store.NO));\n      writer.addDocument(d2);\n\n      writer.shutdown();\n\n      SegmentInfos sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = SegmentReader.readFieldInfos(sis.info(0));\n      FieldInfos fis2 = SegmentReader.readFieldInfos(sis.info(1));\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      writer.forceMerge(1);\n      writer.shutdown();\n\n      sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = SegmentReader.readFieldInfos(sis.info(0));\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n      Document d1 = new Document();\n      d1.add(new StringField(\"f1\", \"first field\", Field.Store.YES));\n      d1.add(new StringField(\"f2\", \"second field\", Field.Store.YES));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.close();\n        writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\", Field.Store.NO));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\", Field.Store.NO));\n      d2.add(new TextField(\"f4\", \"fourth field\", Field.Store.NO));\n      writer.addDocument(d2);\n\n      writer.close();\n\n      SegmentInfos sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = SegmentReader.readFieldInfos(sis.info(0));\n      FieldInfos fis2 = SegmentReader.readFieldInfos(sis.info(1));\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      writer.forceMerge(1);\n      writer.close();\n\n      sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = SegmentReader.readFieldInfos(sis.info(0));\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e2fb55c0777755badd3b46d8140f3d4301febed","date":1398881584,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","sourceNew":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.INSTANCE));\n\n      Document d1 = new Document();\n      d1.add(new StringField(\"f1\", \"first field\", Field.Store.YES));\n      d1.add(new StringField(\"f2\", \"second field\", Field.Store.YES));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.shutdown();\n        writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.INSTANCE));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\", Field.Store.NO));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\", Field.Store.NO));\n      d2.add(new TextField(\"f4\", \"fourth field\", Field.Store.NO));\n      writer.addDocument(d2);\n\n      writer.shutdown();\n\n      SegmentInfos sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = SegmentReader.readFieldInfos(sis.info(0));\n      FieldInfos fis2 = SegmentReader.readFieldInfos(sis.info(1));\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      writer.forceMerge(1);\n      writer.shutdown();\n\n      sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = SegmentReader.readFieldInfos(sis.info(0));\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n      Document d1 = new Document();\n      d1.add(new StringField(\"f1\", \"first field\", Field.Store.YES));\n      d1.add(new StringField(\"f2\", \"second field\", Field.Store.YES));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.shutdown();\n        writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\", Field.Store.NO));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\", Field.Store.NO));\n      d2.add(new TextField(\"f4\", \"fourth field\", Field.Store.NO));\n      writer.addDocument(d2);\n\n      writer.shutdown();\n\n      SegmentInfos sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = SegmentReader.readFieldInfos(sis.info(0));\n      FieldInfos fis2 = SegmentReader.readFieldInfos(sis.info(1));\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      writer.forceMerge(1);\n      writer.shutdown();\n\n      sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = SegmentReader.readFieldInfos(sis.info(0));\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","sourceNew":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                   .setMergePolicy(NoMergePolicy.INSTANCE));\n\n      Document d1 = new Document();\n      d1.add(new StringField(\"f1\", \"first field\", Field.Store.YES));\n      d1.add(new StringField(\"f2\", \"second field\", Field.Store.YES));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.shutdown();\n        writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                         .setMergePolicy(NoMergePolicy.INSTANCE));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\", Field.Store.NO));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\", Field.Store.NO));\n      d2.add(new TextField(\"f4\", \"fourth field\", Field.Store.NO));\n      writer.addDocument(d2);\n\n      writer.shutdown();\n\n      SegmentInfos sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = SegmentReader.readFieldInfos(sis.info(0));\n      FieldInfos fis2 = SegmentReader.readFieldInfos(sis.info(1));\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n      writer.forceMerge(1);\n      writer.shutdown();\n\n      sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = SegmentReader.readFieldInfos(sis.info(0));\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.INSTANCE));\n\n      Document d1 = new Document();\n      d1.add(new StringField(\"f1\", \"first field\", Field.Store.YES));\n      d1.add(new StringField(\"f2\", \"second field\", Field.Store.YES));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.shutdown();\n        writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(NoMergePolicy.INSTANCE));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\", Field.Store.NO));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\", Field.Store.NO));\n      d2.add(new TextField(\"f4\", \"fourth field\", Field.Store.NO));\n      writer.addDocument(d2);\n\n      writer.shutdown();\n\n      SegmentInfos sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = SegmentReader.readFieldInfos(sis.info(0));\n      FieldInfos fis2 = SegmentReader.readFieldInfos(sis.info(1));\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      writer.forceMerge(1);\n      writer.shutdown();\n\n      sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = SegmentReader.readFieldInfos(sis.info(0));\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","sourceNew":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                   .setMergePolicy(NoMergePolicy.INSTANCE));\n\n      Document d1 = new Document();\n      d1.add(new StringField(\"f1\", \"first field\", Field.Store.YES));\n      d1.add(new StringField(\"f2\", \"second field\", Field.Store.YES));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.close();\n        writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                         .setMergePolicy(NoMergePolicy.INSTANCE));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\", Field.Store.NO));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\", Field.Store.NO));\n      d2.add(new TextField(\"f4\", \"fourth field\", Field.Store.NO));\n      writer.addDocument(d2);\n\n      writer.close();\n\n      SegmentInfos sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = SegmentReader.readFieldInfos(sis.info(0));\n      FieldInfos fis2 = SegmentReader.readFieldInfos(sis.info(1));\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n      writer.forceMerge(1);\n      writer.close();\n\n      sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = SegmentReader.readFieldInfos(sis.info(0));\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                   .setMergePolicy(NoMergePolicy.INSTANCE));\n\n      Document d1 = new Document();\n      d1.add(new StringField(\"f1\", \"first field\", Field.Store.YES));\n      d1.add(new StringField(\"f2\", \"second field\", Field.Store.YES));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.shutdown();\n        writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                         .setMergePolicy(NoMergePolicy.INSTANCE));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\", Field.Store.NO));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\", Field.Store.NO));\n      d2.add(new TextField(\"f4\", \"fourth field\", Field.Store.NO));\n      writer.addDocument(d2);\n\n      writer.shutdown();\n\n      SegmentInfos sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = SegmentReader.readFieldInfos(sis.info(0));\n      FieldInfos fis2 = SegmentReader.readFieldInfos(sis.info(1));\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n      writer.forceMerge(1);\n      writer.shutdown();\n\n      sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = SegmentReader.readFieldInfos(sis.info(0));\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"256a0e54e76f18e115a43e7fe793b54d4e9a3005","date":1412426514,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","sourceNew":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                   .setMergePolicy(NoMergePolicy.INSTANCE));\n\n      Document d1 = new Document();\n      d1.add(new StringField(\"f1\", \"first field\", Field.Store.YES));\n      d1.add(new StringField(\"f2\", \"second field\", Field.Store.YES));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.close();\n        writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                         .setMergePolicy(NoMergePolicy.INSTANCE));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\", Field.Store.NO));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\", Field.Store.NO));\n      d2.add(new TextField(\"f4\", \"fourth field\", Field.Store.NO));\n      writer.addDocument(d2);\n\n      writer.close();\n\n      SegmentInfos sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = IndexWriter.readFieldInfos(sis.info(0));\n      FieldInfos fis2 = IndexWriter.readFieldInfos(sis.info(1));\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n      writer.forceMerge(1);\n      writer.close();\n\n      sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = IndexWriter.readFieldInfos(sis.info(0));\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                   .setMergePolicy(NoMergePolicy.INSTANCE));\n\n      Document d1 = new Document();\n      d1.add(new StringField(\"f1\", \"first field\", Field.Store.YES));\n      d1.add(new StringField(\"f2\", \"second field\", Field.Store.YES));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.close();\n        writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                         .setMergePolicy(NoMergePolicy.INSTANCE));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\", Field.Store.NO));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\", Field.Store.NO));\n      d2.add(new TextField(\"f4\", \"fourth field\", Field.Store.NO));\n      writer.addDocument(d2);\n\n      writer.close();\n\n      SegmentInfos sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = SegmentReader.readFieldInfos(sis.info(0));\n      FieldInfos fis2 = SegmentReader.readFieldInfos(sis.info(1));\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n      writer.forceMerge(1);\n      writer.close();\n\n      sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = SegmentReader.readFieldInfos(sis.info(0));\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9bb9a29a5e71a90295f175df8919802993142c9a","date":1412517673,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","sourceNew":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                   .setMergePolicy(NoMergePolicy.INSTANCE));\n\n      Document d1 = new Document();\n      d1.add(new StringField(\"f1\", \"first field\", Field.Store.YES));\n      d1.add(new StringField(\"f2\", \"second field\", Field.Store.YES));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.close();\n        writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                         .setMergePolicy(NoMergePolicy.INSTANCE));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\", Field.Store.NO));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\", Field.Store.NO));\n      d2.add(new TextField(\"f4\", \"fourth field\", Field.Store.NO));\n      writer.addDocument(d2);\n\n      writer.close();\n\n      SegmentInfos sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = IndexWriter.readFieldInfos(sis.info(0));\n      FieldInfos fis2 = IndexWriter.readFieldInfos(sis.info(1));\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n      writer.forceMerge(1);\n      writer.close();\n\n      sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = IndexWriter.readFieldInfos(sis.info(0));\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                   .setMergePolicy(NoMergePolicy.INSTANCE));\n\n      Document d1 = new Document();\n      d1.add(new StringField(\"f1\", \"first field\", Field.Store.YES));\n      d1.add(new StringField(\"f2\", \"second field\", Field.Store.YES));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.close();\n        writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                         .setMergePolicy(NoMergePolicy.INSTANCE));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\", Field.Store.NO));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\", Field.Store.NO));\n      d2.add(new TextField(\"f4\", \"fourth field\", Field.Store.NO));\n      writer.addDocument(d2);\n\n      writer.close();\n\n      SegmentInfos sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = SegmentReader.readFieldInfos(sis.info(0));\n      FieldInfos fis2 = SegmentReader.readFieldInfos(sis.info(1));\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n      writer.forceMerge(1);\n      writer.close();\n\n      sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = SegmentReader.readFieldInfos(sis.info(0));\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3384e6013a93e4d11b7d75388693f8d0388602bf","date":1413951663,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","sourceNew":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                   .setMergePolicy(NoMergePolicy.INSTANCE));\n\n      Document d1 = new Document();\n      d1.add(new StringField(\"f1\", \"first field\", Field.Store.YES));\n      d1.add(new StringField(\"f2\", \"second field\", Field.Store.YES));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.close();\n        writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                         .setMergePolicy(NoMergePolicy.INSTANCE));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\", Field.Store.NO));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\", Field.Store.NO));\n      d2.add(new TextField(\"f4\", \"fourth field\", Field.Store.NO));\n      writer.addDocument(d2);\n\n      writer.close();\n\n      SegmentInfos sis = SegmentInfos.readLatestCommit(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = IndexWriter.readFieldInfos(sis.info(0));\n      FieldInfos fis2 = IndexWriter.readFieldInfos(sis.info(1));\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n      writer.forceMerge(1);\n      writer.close();\n\n      sis = SegmentInfos.readLatestCommit(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = IndexWriter.readFieldInfos(sis.info(0));\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                   .setMergePolicy(NoMergePolicy.INSTANCE));\n\n      Document d1 = new Document();\n      d1.add(new StringField(\"f1\", \"first field\", Field.Store.YES));\n      d1.add(new StringField(\"f2\", \"second field\", Field.Store.YES));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.close();\n        writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                         .setMergePolicy(NoMergePolicy.INSTANCE));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\", Field.Store.NO));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\", Field.Store.NO));\n      d2.add(new TextField(\"f4\", \"fourth field\", Field.Store.NO));\n      writer.addDocument(d2);\n\n      writer.close();\n\n      SegmentInfos sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = IndexWriter.readFieldInfos(sis.info(0));\n      FieldInfos fis2 = IndexWriter.readFieldInfos(sis.info(1));\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n      writer.forceMerge(1);\n      writer.close();\n\n      sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = IndexWriter.readFieldInfos(sis.info(0));\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db68c63cbfaa8698b9c4475f75ed2b9c9696d238","date":1414118621,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","sourceNew":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                   .setMergePolicy(NoMergePolicy.INSTANCE));\n\n      Document d1 = new Document();\n      d1.add(new StringField(\"f1\", \"first field\", Field.Store.YES));\n      d1.add(new StringField(\"f2\", \"second field\", Field.Store.YES));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.close();\n        writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                         .setMergePolicy(NoMergePolicy.INSTANCE));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\", Field.Store.NO));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\", Field.Store.NO));\n      d2.add(new TextField(\"f4\", \"fourth field\", Field.Store.NO));\n      writer.addDocument(d2);\n\n      writer.close();\n\n      SegmentInfos sis = SegmentInfos.readLatestCommit(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = IndexWriter.readFieldInfos(sis.info(0));\n      FieldInfos fis2 = IndexWriter.readFieldInfos(sis.info(1));\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n      writer.forceMerge(1);\n      writer.close();\n\n      sis = SegmentInfos.readLatestCommit(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = IndexWriter.readFieldInfos(sis.info(0));\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                   .setMergePolicy(NoMergePolicy.INSTANCE));\n\n      Document d1 = new Document();\n      d1.add(new StringField(\"f1\", \"first field\", Field.Store.YES));\n      d1.add(new StringField(\"f2\", \"second field\", Field.Store.YES));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.close();\n        writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                         .setMergePolicy(NoMergePolicy.INSTANCE));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\", Field.Store.NO));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\", Field.Store.NO));\n      d2.add(new TextField(\"f4\", \"fourth field\", Field.Store.NO));\n      writer.addDocument(d2);\n\n      writer.close();\n\n      SegmentInfos sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = IndexWriter.readFieldInfos(sis.info(0));\n      FieldInfos fis2 = IndexWriter.readFieldInfos(sis.info(1));\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n      writer.forceMerge(1);\n      writer.close();\n\n      sis = new SegmentInfos();\n      sis.read(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = IndexWriter.readFieldInfos(sis.info(0));\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"165c905a42bedc7c7d1acb37b177498306b7e866","date":1518704038,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testSameFieldNumbersAcrossSegments().mjava","sourceNew":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                   .setMergePolicy(NoMergePolicy.INSTANCE));\n\n      Document d1 = new Document();\n      d1.add(new TextField(\"f1\", \"first field\", Field.Store.YES));\n      d1.add(new TextField(\"f2\", \"second field\", Field.Store.YES));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.close();\n        writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                         .setMergePolicy(NoMergePolicy.INSTANCE));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\", Field.Store.NO));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\", Field.Store.NO));\n      d2.add(new TextField(\"f4\", \"fourth field\", Field.Store.NO));\n      writer.addDocument(d2);\n\n      writer.close();\n\n      SegmentInfos sis = SegmentInfos.readLatestCommit(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = IndexWriter.readFieldInfos(sis.info(0));\n      FieldInfos fis2 = IndexWriter.readFieldInfos(sis.info(1));\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n      writer.forceMerge(1);\n      writer.close();\n\n      sis = SegmentInfos.readLatestCommit(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = IndexWriter.readFieldInfos(sis.info(0));\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testSameFieldNumbersAcrossSegments() throws Exception {\n    for (int i = 0; i < 2; i++) {\n      Directory dir = newDirectory();\n      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                   .setMergePolicy(NoMergePolicy.INSTANCE));\n\n      Document d1 = new Document();\n      d1.add(new StringField(\"f1\", \"first field\", Field.Store.YES));\n      d1.add(new StringField(\"f2\", \"second field\", Field.Store.YES));\n      writer.addDocument(d1);\n\n      if (i == 1) {\n        writer.close();\n        writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                         .setMergePolicy(NoMergePolicy.INSTANCE));\n      } else {\n        writer.commit();\n      }\n\n      Document d2 = new Document();\n      FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n      customType2.setStoreTermVectors(true);\n      d2.add(new TextField(\"f2\", \"second field\", Field.Store.NO));\n      d2.add(new Field(\"f1\", \"first field\", customType2));\n      d2.add(new TextField(\"f3\", \"third field\", Field.Store.NO));\n      d2.add(new TextField(\"f4\", \"fourth field\", Field.Store.NO));\n      writer.addDocument(d2);\n\n      writer.close();\n\n      SegmentInfos sis = SegmentInfos.readLatestCommit(dir);\n      assertEquals(2, sis.size());\n\n      FieldInfos fis1 = IndexWriter.readFieldInfos(sis.info(0));\n      FieldInfos fis2 = IndexWriter.readFieldInfos(sis.info(1));\n\n      assertEquals(\"f1\", fis1.fieldInfo(0).name);\n      assertEquals(\"f2\", fis1.fieldInfo(1).name);\n      assertEquals(\"f1\", fis2.fieldInfo(0).name);\n      assertEquals(\"f2\", fis2.fieldInfo(1).name);\n      assertEquals(\"f3\", fis2.fieldInfo(2).name);\n      assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n      writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n      writer.forceMerge(1);\n      writer.close();\n\n      sis = SegmentInfos.readLatestCommit(dir);\n      assertEquals(1, sis.size());\n\n      FieldInfos fis3 = IndexWriter.readFieldInfos(sis.info(0));\n\n      assertEquals(\"f1\", fis3.fieldInfo(0).name);\n      assertEquals(\"f2\", fis3.fieldInfo(1).name);\n      assertEquals(\"f3\", fis3.fieldInfo(2).name);\n      assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7e2fb55c0777755badd3b46d8140f3d4301febed":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["7e2fb55c0777755badd3b46d8140f3d4301febed"],"256a0e54e76f18e115a43e7fe793b54d4e9a3005":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"9d153abcf92dc5329d98571a8c3035df9bd80648":["d2dee33619431ada2a7a07f5fe2dbd94bac6a460"],"8435160e9702b19398118ddf76b61c846612b6a4":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"3384e6013a93e4d11b7d75388693f8d0388602bf":["256a0e54e76f18e115a43e7fe793b54d4e9a3005"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"d2dee33619431ada2a7a07f5fe2dbd94bac6a460":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"165c905a42bedc7c7d1acb37b177498306b7e866":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["629c38c4ae4e303d0617e05fbfe508140b32f0a3","9d153abcf92dc5329d98571a8c3035df9bd80648"],"9bb9a29a5e71a90295f175df8919802993142c9a":["d0ef034a4f10871667ae75181537775ddcf8ade4","256a0e54e76f18e115a43e7fe793b54d4e9a3005"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["8435160e9702b19398118ddf76b61c846612b6a4"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["9bb9a29a5e71a90295f175df8919802993142c9a","3384e6013a93e4d11b7d75388693f8d0388602bf"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["165c905a42bedc7c7d1acb37b177498306b7e866"]},"commit2Childs":{"7e2fb55c0777755badd3b46d8140f3d4301febed":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"256a0e54e76f18e115a43e7fe793b54d4e9a3005":["3384e6013a93e4d11b7d75388693f8d0388602bf","9bb9a29a5e71a90295f175df8919802993142c9a"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"9d153abcf92dc5329d98571a8c3035df9bd80648":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"8435160e9702b19398118ddf76b61c846612b6a4":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"3384e6013a93e4d11b7d75388693f8d0388602bf":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"d2dee33619431ada2a7a07f5fe2dbd94bac6a460":["9d153abcf92dc5329d98571a8c3035df9bd80648"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["8435160e9702b19398118ddf76b61c846612b6a4"],"165c905a42bedc7c7d1acb37b177498306b7e866":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"9bb9a29a5e71a90295f175df8919802993142c9a":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["256a0e54e76f18e115a43e7fe793b54d4e9a3005","9bb9a29a5e71a90295f175df8919802993142c9a"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["7e2fb55c0777755badd3b46d8140f3d4301febed"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["165c905a42bedc7c7d1acb37b177498306b7e866"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["d2dee33619431ada2a7a07f5fe2dbd94bac6a460","615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}