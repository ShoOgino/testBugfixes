{"path":"solr/core/src/test/org/apache/solr/cloud/api/collections/HdfsCollectionsAPIDistributedZkTest#moveReplicaTest().mjava","commits":[{"id":"6146c07c0dee1ae1e42926167acd127fed5ef59d","date":1516129420,"type":1,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/HdfsCollectionsAPIDistributedZkTest#moveReplicaTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/hdfs/HdfsCollectionsAPIDistributedZkTest#moveReplicaTest().mjava","sourceNew":"  @Test\n  public void moveReplicaTest() throws Exception {\n    cluster.waitForAllNodes(5000);\n    String coll = \"movereplicatest_coll\";\n\n    CloudSolrClient cloudClient = cluster.getSolrClient();\n\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(coll, \"conf\", 2, 2);\n    create.setMaxShardsPerNode(2);\n    cloudClient.request(create);\n\n    for (int i = 0; i < 10; i++) {\n      cloudClient.add(coll, sdoc(\"id\",String.valueOf(i)));\n      cloudClient.commit(coll);\n    }\n\n    List<Slice> slices = new ArrayList<>(cloudClient.getZkStateReader().getClusterState().getCollection(coll).getSlices());\n    Collections.shuffle(slices, random());\n    Slice slice = null;\n    Replica replica = null;\n    for (Slice s : slices) {\n      slice = s;\n      for (Replica r : s.getReplicas()) {\n        if (s.getLeader() != r) {\n          replica = r;\n        }\n      }\n    }\n    String dataDir = getDataDir(replica);\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    ArrayList<String> l = new ArrayList<>(liveNodes);\n    Collections.shuffle(l, random());\n    String targetNode = null;\n    for (String node : liveNodes) {\n      if (!replica.getNodeName().equals(node)) {\n        targetNode = node;\n        break;\n      }\n    }\n    assertNotNull(targetNode);\n\n    CollectionAdminRequest.MoveReplica moveReplica = new CollectionAdminRequest.MoveReplica(coll, replica.getName(), targetNode);\n    moveReplica.process(cloudClient);\n\n    checkNumOfCores(cloudClient, replica.getNodeName(), 0);\n    checkNumOfCores(cloudClient, targetNode, 2);\n\n    waitForState(\"Wait for recovery finish failed\",coll, clusterShape(2,2));\n    slice = cloudClient.getZkStateReader().getClusterState().getCollection(coll).getSlice(slice.getName());\n    boolean found = false;\n    for (Replica newReplica : slice.getReplicas()) {\n      if (getDataDir(newReplica).equals(dataDir)) {\n        found = true;\n      }\n    }\n    assertTrue(found);\n\n\n    // data dir is reused so replication will be skipped\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrMetricManager manager = jetty.getCoreContainer().getMetricManager();\n      List<String> registryNames = manager.registryNames().stream()\n          .filter(s -> s.startsWith(\"solr.core.\")).collect(Collectors.toList());\n      for (String registry : registryNames) {\n        Map<String, Metric> metrics = manager.registry(registry).getMetrics();\n        Counter counter = (Counter) metrics.get(\"REPLICATION./replication.requests\");\n        if (counter != null) {\n          assertEquals(0, counter.getCount());\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void moveReplicaTest() throws Exception {\n    cluster.waitForAllNodes(5000);\n    String coll = \"movereplicatest_coll\";\n\n    CloudSolrClient cloudClient = cluster.getSolrClient();\n\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(coll, \"conf\", 2, 2);\n    create.setMaxShardsPerNode(2);\n    cloudClient.request(create);\n\n    for (int i = 0; i < 10; i++) {\n      cloudClient.add(coll, sdoc(\"id\",String.valueOf(i)));\n      cloudClient.commit(coll);\n    }\n\n    List<Slice> slices = new ArrayList<>(cloudClient.getZkStateReader().getClusterState().getCollection(coll).getSlices());\n    Collections.shuffle(slices, random());\n    Slice slice = null;\n    Replica replica = null;\n    for (Slice s : slices) {\n      slice = s;\n      for (Replica r : s.getReplicas()) {\n        if (s.getLeader() != r) {\n          replica = r;\n        }\n      }\n    }\n    String dataDir = getDataDir(replica);\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    ArrayList<String> l = new ArrayList<>(liveNodes);\n    Collections.shuffle(l, random());\n    String targetNode = null;\n    for (String node : liveNodes) {\n      if (!replica.getNodeName().equals(node)) {\n        targetNode = node;\n        break;\n      }\n    }\n    assertNotNull(targetNode);\n\n    CollectionAdminRequest.MoveReplica moveReplica = new CollectionAdminRequest.MoveReplica(coll, replica.getName(), targetNode);\n    moveReplica.process(cloudClient);\n\n    checkNumOfCores(cloudClient, replica.getNodeName(), 0);\n    checkNumOfCores(cloudClient, targetNode, 2);\n\n    waitForState(\"Wait for recovery finish failed\",coll, clusterShape(2,2));\n    slice = cloudClient.getZkStateReader().getClusterState().getCollection(coll).getSlice(slice.getName());\n    boolean found = false;\n    for (Replica newReplica : slice.getReplicas()) {\n      if (getDataDir(newReplica).equals(dataDir)) {\n        found = true;\n      }\n    }\n    assertTrue(found);\n\n\n    // data dir is reused so replication will be skipped\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrMetricManager manager = jetty.getCoreContainer().getMetricManager();\n      List<String> registryNames = manager.registryNames().stream()\n          .filter(s -> s.startsWith(\"solr.core.\")).collect(Collectors.toList());\n      for (String registry : registryNames) {\n        Map<String, Metric> metrics = manager.registry(registry).getMetrics();\n        Counter counter = (Counter) metrics.get(\"REPLICATION./replication.requests\");\n        if (counter != null) {\n          assertEquals(0, counter.getCount());\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b94236357aaa22b76c10629851fe4e376e0cea82","date":1516710914,"type":1,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/HdfsCollectionsAPIDistributedZkTest#moveReplicaTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/hdfs/HdfsCollectionsAPIDistributedZkTest#moveReplicaTest().mjava","sourceNew":"  @Test\n  public void moveReplicaTest() throws Exception {\n    cluster.waitForAllNodes(5000);\n    String coll = \"movereplicatest_coll\";\n\n    CloudSolrClient cloudClient = cluster.getSolrClient();\n\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(coll, \"conf\", 2, 2);\n    create.setMaxShardsPerNode(2);\n    cloudClient.request(create);\n\n    for (int i = 0; i < 10; i++) {\n      cloudClient.add(coll, sdoc(\"id\",String.valueOf(i)));\n      cloudClient.commit(coll);\n    }\n\n    List<Slice> slices = new ArrayList<>(cloudClient.getZkStateReader().getClusterState().getCollection(coll).getSlices());\n    Collections.shuffle(slices, random());\n    Slice slice = null;\n    Replica replica = null;\n    for (Slice s : slices) {\n      slice = s;\n      for (Replica r : s.getReplicas()) {\n        if (s.getLeader() != r) {\n          replica = r;\n        }\n      }\n    }\n    String dataDir = getDataDir(replica);\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    ArrayList<String> l = new ArrayList<>(liveNodes);\n    Collections.shuffle(l, random());\n    String targetNode = null;\n    for (String node : liveNodes) {\n      if (!replica.getNodeName().equals(node)) {\n        targetNode = node;\n        break;\n      }\n    }\n    assertNotNull(targetNode);\n\n    CollectionAdminRequest.MoveReplica moveReplica = new CollectionAdminRequest.MoveReplica(coll, replica.getName(), targetNode);\n    moveReplica.process(cloudClient);\n\n    checkNumOfCores(cloudClient, replica.getNodeName(), 0);\n    checkNumOfCores(cloudClient, targetNode, 2);\n\n    waitForState(\"Wait for recovery finish failed\",coll, clusterShape(2,2));\n    slice = cloudClient.getZkStateReader().getClusterState().getCollection(coll).getSlice(slice.getName());\n    boolean found = false;\n    for (Replica newReplica : slice.getReplicas()) {\n      if (getDataDir(newReplica).equals(dataDir)) {\n        found = true;\n      }\n    }\n    assertTrue(found);\n\n\n    // data dir is reused so replication will be skipped\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrMetricManager manager = jetty.getCoreContainer().getMetricManager();\n      List<String> registryNames = manager.registryNames().stream()\n          .filter(s -> s.startsWith(\"solr.core.\")).collect(Collectors.toList());\n      for (String registry : registryNames) {\n        Map<String, Metric> metrics = manager.registry(registry).getMetrics();\n        Counter counter = (Counter) metrics.get(\"REPLICATION./replication.requests\");\n        if (counter != null) {\n          assertEquals(0, counter.getCount());\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void moveReplicaTest() throws Exception {\n    cluster.waitForAllNodes(5000);\n    String coll = \"movereplicatest_coll\";\n\n    CloudSolrClient cloudClient = cluster.getSolrClient();\n\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(coll, \"conf\", 2, 2);\n    create.setMaxShardsPerNode(2);\n    cloudClient.request(create);\n\n    for (int i = 0; i < 10; i++) {\n      cloudClient.add(coll, sdoc(\"id\",String.valueOf(i)));\n      cloudClient.commit(coll);\n    }\n\n    List<Slice> slices = new ArrayList<>(cloudClient.getZkStateReader().getClusterState().getCollection(coll).getSlices());\n    Collections.shuffle(slices, random());\n    Slice slice = null;\n    Replica replica = null;\n    for (Slice s : slices) {\n      slice = s;\n      for (Replica r : s.getReplicas()) {\n        if (s.getLeader() != r) {\n          replica = r;\n        }\n      }\n    }\n    String dataDir = getDataDir(replica);\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    ArrayList<String> l = new ArrayList<>(liveNodes);\n    Collections.shuffle(l, random());\n    String targetNode = null;\n    for (String node : liveNodes) {\n      if (!replica.getNodeName().equals(node)) {\n        targetNode = node;\n        break;\n      }\n    }\n    assertNotNull(targetNode);\n\n    CollectionAdminRequest.MoveReplica moveReplica = new CollectionAdminRequest.MoveReplica(coll, replica.getName(), targetNode);\n    moveReplica.process(cloudClient);\n\n    checkNumOfCores(cloudClient, replica.getNodeName(), 0);\n    checkNumOfCores(cloudClient, targetNode, 2);\n\n    waitForState(\"Wait for recovery finish failed\",coll, clusterShape(2,2));\n    slice = cloudClient.getZkStateReader().getClusterState().getCollection(coll).getSlice(slice.getName());\n    boolean found = false;\n    for (Replica newReplica : slice.getReplicas()) {\n      if (getDataDir(newReplica).equals(dataDir)) {\n        found = true;\n      }\n    }\n    assertTrue(found);\n\n\n    // data dir is reused so replication will be skipped\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrMetricManager manager = jetty.getCoreContainer().getMetricManager();\n      List<String> registryNames = manager.registryNames().stream()\n          .filter(s -> s.startsWith(\"solr.core.\")).collect(Collectors.toList());\n      for (String registry : registryNames) {\n        Map<String, Metric> metrics = manager.registry(registry).getMetrics();\n        Counter counter = (Counter) metrics.get(\"REPLICATION./replication.requests\");\n        if (counter != null) {\n          assertEquals(0, counter.getCount());\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/HdfsCollectionsAPIDistributedZkTest#moveReplicaTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/api/collections/HdfsCollectionsAPIDistributedZkTest#moveReplicaTest().mjava","sourceNew":"  @Test\n  public void moveReplicaTest() throws Exception {\n    String coll = \"movereplicatest_coll\";\n\n    CloudSolrClient cloudClient = cluster.getSolrClient();\n\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(coll, \"conf\", 2, 2);\n    create.setMaxShardsPerNode(2);\n    cloudClient.request(create);\n\n    for (int i = 0; i < 10; i++) {\n      cloudClient.add(coll, sdoc(\"id\",String.valueOf(i)));\n      cloudClient.commit(coll);\n    }\n\n    List<Slice> slices = new ArrayList<>(cloudClient.getZkStateReader().getClusterState().getCollection(coll).getSlices());\n    Collections.shuffle(slices, random());\n    Slice slice = null;\n    Replica replica = null;\n    for (Slice s : slices) {\n      slice = s;\n      for (Replica r : s.getReplicas()) {\n        if (s.getLeader() != r) {\n          replica = r;\n        }\n      }\n    }\n    String dataDir = getDataDir(replica);\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    ArrayList<String> l = new ArrayList<>(liveNodes);\n    Collections.shuffle(l, random());\n    String targetNode = null;\n    for (String node : liveNodes) {\n      if (!replica.getNodeName().equals(node)) {\n        targetNode = node;\n        break;\n      }\n    }\n    assertNotNull(targetNode);\n\n    CollectionAdminRequest.MoveReplica moveReplica = new CollectionAdminRequest.MoveReplica(coll, replica.getName(), targetNode);\n    moveReplica.process(cloudClient);\n\n    checkNumOfCores(cloudClient, replica.getNodeName(), 0);\n    checkNumOfCores(cloudClient, targetNode, 2);\n\n    waitForState(\"Wait for recovery finish failed\",coll, clusterShape(2,4));\n    slice = cloudClient.getZkStateReader().getClusterState().getCollection(coll).getSlice(slice.getName());\n    boolean found = false;\n    for (Replica newReplica : slice.getReplicas()) {\n      if (getDataDir(newReplica).equals(dataDir)) {\n        found = true;\n      }\n    }\n    assertTrue(found);\n\n\n    // data dir is reused so replication will be skipped\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrMetricManager manager = jetty.getCoreContainer().getMetricManager();\n      List<String> registryNames = manager.registryNames().stream()\n          .filter(s -> s.startsWith(\"solr.core.\")).collect(Collectors.toList());\n      for (String registry : registryNames) {\n        Map<String, Metric> metrics = manager.registry(registry).getMetrics();\n        Counter counter = (Counter) metrics.get(\"REPLICATION./replication.requests\");\n        if (counter != null) {\n          assertEquals(0, counter.getCount());\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void moveReplicaTest() throws Exception {\n    cluster.waitForAllNodes(5000);\n    String coll = \"movereplicatest_coll\";\n\n    CloudSolrClient cloudClient = cluster.getSolrClient();\n\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(coll, \"conf\", 2, 2);\n    create.setMaxShardsPerNode(2);\n    cloudClient.request(create);\n\n    for (int i = 0; i < 10; i++) {\n      cloudClient.add(coll, sdoc(\"id\",String.valueOf(i)));\n      cloudClient.commit(coll);\n    }\n\n    List<Slice> slices = new ArrayList<>(cloudClient.getZkStateReader().getClusterState().getCollection(coll).getSlices());\n    Collections.shuffle(slices, random());\n    Slice slice = null;\n    Replica replica = null;\n    for (Slice s : slices) {\n      slice = s;\n      for (Replica r : s.getReplicas()) {\n        if (s.getLeader() != r) {\n          replica = r;\n        }\n      }\n    }\n    String dataDir = getDataDir(replica);\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    ArrayList<String> l = new ArrayList<>(liveNodes);\n    Collections.shuffle(l, random());\n    String targetNode = null;\n    for (String node : liveNodes) {\n      if (!replica.getNodeName().equals(node)) {\n        targetNode = node;\n        break;\n      }\n    }\n    assertNotNull(targetNode);\n\n    CollectionAdminRequest.MoveReplica moveReplica = new CollectionAdminRequest.MoveReplica(coll, replica.getName(), targetNode);\n    moveReplica.process(cloudClient);\n\n    checkNumOfCores(cloudClient, replica.getNodeName(), 0);\n    checkNumOfCores(cloudClient, targetNode, 2);\n\n    waitForState(\"Wait for recovery finish failed\",coll, clusterShape(2,2));\n    slice = cloudClient.getZkStateReader().getClusterState().getCollection(coll).getSlice(slice.getName());\n    boolean found = false;\n    for (Replica newReplica : slice.getReplicas()) {\n      if (getDataDir(newReplica).equals(dataDir)) {\n        found = true;\n      }\n    }\n    assertTrue(found);\n\n\n    // data dir is reused so replication will be skipped\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrMetricManager manager = jetty.getCoreContainer().getMetricManager();\n      List<String> registryNames = manager.registryNames().stream()\n          .filter(s -> s.startsWith(\"solr.core.\")).collect(Collectors.toList());\n      for (String registry : registryNames) {\n        Map<String, Metric> metrics = manager.registry(registry).getMetrics();\n        Counter counter = (Counter) metrics.get(\"REPLICATION./replication.requests\");\n        if (counter != null) {\n          assertEquals(0, counter.getCount());\n        }\n      }\n    }\n  }\n\n","bugFix":["b54504c5305a6cc48f59c627c9c8dd727e2a8f0b"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"273ff2f5b0b365591fcbe91ea23b5e97027ca60d","date":1551111277,"type":4,"author":"Kevin Risden","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/test/org/apache/solr/cloud/api/collections/HdfsCollectionsAPIDistributedZkTest#moveReplicaTest().mjava","sourceNew":null,"sourceOld":"  @Test\n  public void moveReplicaTest() throws Exception {\n    String coll = \"movereplicatest_coll\";\n\n    CloudSolrClient cloudClient = cluster.getSolrClient();\n\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(coll, \"conf\", 2, 2);\n    create.setMaxShardsPerNode(2);\n    cloudClient.request(create);\n\n    for (int i = 0; i < 10; i++) {\n      cloudClient.add(coll, sdoc(\"id\",String.valueOf(i)));\n      cloudClient.commit(coll);\n    }\n\n    List<Slice> slices = new ArrayList<>(cloudClient.getZkStateReader().getClusterState().getCollection(coll).getSlices());\n    Collections.shuffle(slices, random());\n    Slice slice = null;\n    Replica replica = null;\n    for (Slice s : slices) {\n      slice = s;\n      for (Replica r : s.getReplicas()) {\n        if (s.getLeader() != r) {\n          replica = r;\n        }\n      }\n    }\n    String dataDir = getDataDir(replica);\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    ArrayList<String> l = new ArrayList<>(liveNodes);\n    Collections.shuffle(l, random());\n    String targetNode = null;\n    for (String node : liveNodes) {\n      if (!replica.getNodeName().equals(node)) {\n        targetNode = node;\n        break;\n      }\n    }\n    assertNotNull(targetNode);\n\n    CollectionAdminRequest.MoveReplica moveReplica = new CollectionAdminRequest.MoveReplica(coll, replica.getName(), targetNode);\n    moveReplica.process(cloudClient);\n\n    checkNumOfCores(cloudClient, replica.getNodeName(), 0);\n    checkNumOfCores(cloudClient, targetNode, 2);\n\n    waitForState(\"Wait for recovery finish failed\",coll, clusterShape(2,4));\n    slice = cloudClient.getZkStateReader().getClusterState().getCollection(coll).getSlice(slice.getName());\n    boolean found = false;\n    for (Replica newReplica : slice.getReplicas()) {\n      if (getDataDir(newReplica).equals(dataDir)) {\n        found = true;\n      }\n    }\n    assertTrue(found);\n\n\n    // data dir is reused so replication will be skipped\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrMetricManager manager = jetty.getCoreContainer().getMetricManager();\n      List<String> registryNames = manager.registryNames().stream()\n          .filter(s -> s.startsWith(\"solr.core.\")).collect(Collectors.toList());\n      for (String registry : registryNames) {\n        Map<String, Metric> metrics = manager.registry(registry).getMetrics();\n        Counter counter = (Counter) metrics.get(\"REPLICATION./replication.requests\");\n        if (counter != null) {\n          assertEquals(0, counter.getCount());\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"91f7dccce9b0ec051304926da532b96944956895","date":1551188806,"type":4,"author":"Karl Wright","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/core/src/test/org/apache/solr/cloud/api/collections/HdfsCollectionsAPIDistributedZkTest#moveReplicaTest().mjava","sourceNew":null,"sourceOld":"  @Test\n  public void moveReplicaTest() throws Exception {\n    String coll = \"movereplicatest_coll\";\n\n    CloudSolrClient cloudClient = cluster.getSolrClient();\n\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(coll, \"conf\", 2, 2);\n    create.setMaxShardsPerNode(2);\n    cloudClient.request(create);\n\n    for (int i = 0; i < 10; i++) {\n      cloudClient.add(coll, sdoc(\"id\",String.valueOf(i)));\n      cloudClient.commit(coll);\n    }\n\n    List<Slice> slices = new ArrayList<>(cloudClient.getZkStateReader().getClusterState().getCollection(coll).getSlices());\n    Collections.shuffle(slices, random());\n    Slice slice = null;\n    Replica replica = null;\n    for (Slice s : slices) {\n      slice = s;\n      for (Replica r : s.getReplicas()) {\n        if (s.getLeader() != r) {\n          replica = r;\n        }\n      }\n    }\n    String dataDir = getDataDir(replica);\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    ArrayList<String> l = new ArrayList<>(liveNodes);\n    Collections.shuffle(l, random());\n    String targetNode = null;\n    for (String node : liveNodes) {\n      if (!replica.getNodeName().equals(node)) {\n        targetNode = node;\n        break;\n      }\n    }\n    assertNotNull(targetNode);\n\n    CollectionAdminRequest.MoveReplica moveReplica = new CollectionAdminRequest.MoveReplica(coll, replica.getName(), targetNode);\n    moveReplica.process(cloudClient);\n\n    checkNumOfCores(cloudClient, replica.getNodeName(), 0);\n    checkNumOfCores(cloudClient, targetNode, 2);\n\n    waitForState(\"Wait for recovery finish failed\",coll, clusterShape(2,4));\n    slice = cloudClient.getZkStateReader().getClusterState().getCollection(coll).getSlice(slice.getName());\n    boolean found = false;\n    for (Replica newReplica : slice.getReplicas()) {\n      if (getDataDir(newReplica).equals(dataDir)) {\n        found = true;\n      }\n    }\n    assertTrue(found);\n\n\n    // data dir is reused so replication will be skipped\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrMetricManager manager = jetty.getCoreContainer().getMetricManager();\n      List<String> registryNames = manager.registryNames().stream()\n          .filter(s -> s.startsWith(\"solr.core.\")).collect(Collectors.toList());\n      for (String registry : registryNames) {\n        Map<String, Metric> metrics = manager.registry(registry).getMetrics();\n        Counter counter = (Counter) metrics.get(\"REPLICATION./replication.requests\");\n        if (counter != null) {\n          assertEquals(0, counter.getCount());\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b94236357aaa22b76c10629851fe4e376e0cea82":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","6146c07c0dee1ae1e42926167acd127fed5ef59d"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["b94236357aaa22b76c10629851fe4e376e0cea82"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"6146c07c0dee1ae1e42926167acd127fed5ef59d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"91f7dccce9b0ec051304926da532b96944956895":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f","273ff2f5b0b365591fcbe91ea23b5e97027ca60d"],"273ff2f5b0b365591fcbe91ea23b5e97027ca60d":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["91f7dccce9b0ec051304926da532b96944956895"]},"commit2Childs":{"b94236357aaa22b76c10629851fe4e376e0cea82":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["91f7dccce9b0ec051304926da532b96944956895","273ff2f5b0b365591fcbe91ea23b5e97027ca60d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b94236357aaa22b76c10629851fe4e376e0cea82","6146c07c0dee1ae1e42926167acd127fed5ef59d"],"6146c07c0dee1ae1e42926167acd127fed5ef59d":["b94236357aaa22b76c10629851fe4e376e0cea82"],"91f7dccce9b0ec051304926da532b96944956895":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"273ff2f5b0b365591fcbe91ea23b5e97027ca60d":["91f7dccce9b0ec051304926da532b96944956895"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}