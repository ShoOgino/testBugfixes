{"path":"lucene/test-framework/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBasic().mjava","commits":[{"id":"b52491e71f0d5d0f0160d6ed0d39e0dd661be68a","date":1429550638,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBasic().mjava","sourceNew":"  public void testMockGraphTokenFilterBasic() throws Exception {\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName) {\n            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n            final TokenStream t2 = new MockGraphTokenFilter(random(), t);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      checkAnalysisConsistency(random(), a, false, \"a b c d e f g h i j k\");\n    }\n  }\n\n","sourceOld":"  public void testMockGraphTokenFilterBasic() throws Exception {\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName) {\n            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n            final TokenStream t2 = new MockGraphTokenFilter(random(), t);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      checkAnalysisConsistency(random(), a, false, \"a b c d e f g h i j k\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"085e5eccb1e06e3bfb487813880adc54c888dd02","date":1483875517,"type":5,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBasic().mjava","pathOld":"lucene/test-framework/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBasic().mjava","sourceNew":"  public void testMockGraphTokenFilterBasic() throws Exception {\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName) {\n            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n            final TokenStream t2 = new MockGraphTokenFilter(random(), t);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      checkAnalysisConsistency(random(), a, false, \"a b c d e f g h i j k\");\n    }\n  }\n\n","sourceOld":"  public void testMockGraphTokenFilterBasic() throws Exception {\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName) {\n            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n            final TokenStream t2 = new MockGraphTokenFilter(random(), t);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      checkAnalysisConsistency(random(), a, false, \"a b c d e f g h i j k\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","date":1484239864,"type":5,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBasic().mjava","pathOld":"lucene/test-framework/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBasic().mjava","sourceNew":"  public void testMockGraphTokenFilterBasic() throws Exception {\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName) {\n            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n            final TokenStream t2 = new MockGraphTokenFilter(random(), t);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      checkAnalysisConsistency(random(), a, false, \"a b c d e f g h i j k\");\n    }\n  }\n\n","sourceOld":"  public void testMockGraphTokenFilterBasic() throws Exception {\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName) {\n            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n            final TokenStream t2 = new MockGraphTokenFilter(random(), t);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      checkAnalysisConsistency(random(), a, false, \"a b c d e f g h i j k\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7":["b52491e71f0d5d0f0160d6ed0d39e0dd661be68a","085e5eccb1e06e3bfb487813880adc54c888dd02"],"b52491e71f0d5d0f0160d6ed0d39e0dd661be68a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"085e5eccb1e06e3bfb487813880adc54c888dd02":["b52491e71f0d5d0f0160d6ed0d39e0dd661be68a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["085e5eccb1e06e3bfb487813880adc54c888dd02"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b52491e71f0d5d0f0160d6ed0d39e0dd661be68a"],"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7":[],"b52491e71f0d5d0f0160d6ed0d39e0dd661be68a":["09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","085e5eccb1e06e3bfb487813880adc54c888dd02"],"085e5eccb1e06e3bfb487813880adc54c888dd02":["09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}