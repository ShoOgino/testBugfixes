{"path":"lucene/queries/src/java/org/apache/lucene/queries/mlt/MoreLikeThis#createQueue(Map[String,Int]).mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/queries/src/java/org/apache/lucene/queries/mlt/MoreLikeThis#createQueue(Map[String,Int]).mjava","pathOld":"modules/queries/src/java/org/apache/lucene/queries/mlt/MoreLikeThis#createQueue(Map[String,Int]).mjava","sourceNew":"  /**\n   * Create a PriorityQueue from a word->tf map.\n   *\n   * @param words a map of words keyed on the word(String) with Int objects as the values.\n   */\n  private PriorityQueue<Object[]> createQueue(Map<String, Int> words) throws IOException {\n    // have collected all words in doc and their freqs\n    int numDocs = ir.numDocs();\n    FreqQ res = new FreqQ(words.size()); // will order words by score\n\n    for (String word : words.keySet()) { // for every word\n      int tf = words.get(word).x; // term freq in the source doc\n      if (minTermFreq > 0 && tf < minTermFreq) {\n        continue; // filter out words that don't occur enough times in the source\n      }\n\n      // go through all the fields and find the largest document frequency\n      String topField = fieldNames[0];\n      int docFreq = 0;\n      for (String fieldName : fieldNames) {\n        int freq = ir.docFreq(new Term(fieldName, word));\n        topField = (freq > docFreq) ? fieldName : topField;\n        docFreq = (freq > docFreq) ? freq : docFreq;\n      }\n\n      if (minDocFreq > 0 && docFreq < minDocFreq) {\n        continue; // filter out words that don't occur in enough docs\n      }\n\n      if (docFreq > maxDocFreq) {\n        continue; // filter out words that occur in too many docs\n      }\n\n      if (docFreq == 0) {\n        continue; // index update problem?\n      }\n\n      float idf = similarity.idf(docFreq, numDocs);\n      float score = tf * idf;\n\n      // only really need 1st 3 entries, other ones are for troubleshooting\n      res.insertWithOverflow(new Object[]{word,                   // the word\n          topField,               // the top field\n          score,       // overall score\n          idf,         // idf\n          docFreq,   // freq in all docs\n          tf\n      });\n    }\n    return res;\n  }\n\n","sourceOld":"  /**\n   * Create a PriorityQueue from a word->tf map.\n   *\n   * @param words a map of words keyed on the word(String) with Int objects as the values.\n   */\n  private PriorityQueue<Object[]> createQueue(Map<String, Int> words) throws IOException {\n    // have collected all words in doc and their freqs\n    int numDocs = ir.numDocs();\n    FreqQ res = new FreqQ(words.size()); // will order words by score\n\n    for (String word : words.keySet()) { // for every word\n      int tf = words.get(word).x; // term freq in the source doc\n      if (minTermFreq > 0 && tf < minTermFreq) {\n        continue; // filter out words that don't occur enough times in the source\n      }\n\n      // go through all the fields and find the largest document frequency\n      String topField = fieldNames[0];\n      int docFreq = 0;\n      for (String fieldName : fieldNames) {\n        int freq = ir.docFreq(new Term(fieldName, word));\n        topField = (freq > docFreq) ? fieldName : topField;\n        docFreq = (freq > docFreq) ? freq : docFreq;\n      }\n\n      if (minDocFreq > 0 && docFreq < minDocFreq) {\n        continue; // filter out words that don't occur in enough docs\n      }\n\n      if (docFreq > maxDocFreq) {\n        continue; // filter out words that occur in too many docs\n      }\n\n      if (docFreq == 0) {\n        continue; // index update problem?\n      }\n\n      float idf = similarity.idf(docFreq, numDocs);\n      float score = tf * idf;\n\n      // only really need 1st 3 entries, other ones are for troubleshooting\n      res.insertWithOverflow(new Object[]{word,                   // the word\n          topField,               // the top field\n          score,       // overall score\n          idf,         // idf\n          docFreq,   // freq in all docs\n          tf\n      });\n    }\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2f73cfcb38e83bad8ad6dce5dd4f021d44efe73d","date":1405005344,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/queries/src/java/org/apache/lucene/queries/mlt/MoreLikeThis#createQueue(Map[String,Int]).mjava","pathOld":"lucene/queries/src/java/org/apache/lucene/queries/mlt/MoreLikeThis#createQueue(Map[String,Int]).mjava","sourceNew":"  /**\n   * Create a PriorityQueue from a word->tf map.\n   *\n   * @param words a map of words keyed on the word(String) with Int objects as the values.\n   */\n  private PriorityQueue<ScoreTerm> createQueue(Map<String, Int> words) throws IOException {\n    // have collected all words in doc and their freqs\n    int numDocs = ir.numDocs();\n    final int limit = Math.min(maxQueryTerms, words.size());\n    FreqQ queue = new FreqQ(limit); // will order words by score\n\n    for (String word : words.keySet()) { // for every word\n      int tf = words.get(word).x; // term freq in the source doc\n      if (minTermFreq > 0 && tf < minTermFreq) {\n        continue; // filter out words that don't occur enough times in the source\n      }\n\n      // go through all the fields and find the largest document frequency\n      String topField = fieldNames[0];\n      int docFreq = 0;\n      for (String fieldName : fieldNames) {\n        int freq = ir.docFreq(new Term(fieldName, word));\n        topField = (freq > docFreq) ? fieldName : topField;\n        docFreq = (freq > docFreq) ? freq : docFreq;\n      }\n\n      if (minDocFreq > 0 && docFreq < minDocFreq) {\n        continue; // filter out words that don't occur in enough docs\n      }\n\n      if (docFreq > maxDocFreq) {\n        continue; // filter out words that occur in too many docs\n      }\n\n      if (docFreq == 0) {\n        continue; // index update problem?\n      }\n\n      float idf = similarity.idf(docFreq, numDocs);\n      float score = tf * idf;\n\n      if (queue.size() < limit) {\n        // there is still space in the queue\n        queue.add(new ScoreTerm(word, topField, score, idf, docFreq, tf));\n      } else {\n        ScoreTerm term = queue.top();\n        if (term.score < score) { // update the smallest in the queue in place and update the queue.\n          term.update(word, topField, score, idf, docFreq, tf);\n          queue.updateTop();\n        }\n      }\n    }\n    return queue;\n  }\n\n","sourceOld":"  /**\n   * Create a PriorityQueue from a word->tf map.\n   *\n   * @param words a map of words keyed on the word(String) with Int objects as the values.\n   */\n  private PriorityQueue<Object[]> createQueue(Map<String, Int> words) throws IOException {\n    // have collected all words in doc and their freqs\n    int numDocs = ir.numDocs();\n    FreqQ res = new FreqQ(words.size()); // will order words by score\n\n    for (String word : words.keySet()) { // for every word\n      int tf = words.get(word).x; // term freq in the source doc\n      if (minTermFreq > 0 && tf < minTermFreq) {\n        continue; // filter out words that don't occur enough times in the source\n      }\n\n      // go through all the fields and find the largest document frequency\n      String topField = fieldNames[0];\n      int docFreq = 0;\n      for (String fieldName : fieldNames) {\n        int freq = ir.docFreq(new Term(fieldName, word));\n        topField = (freq > docFreq) ? fieldName : topField;\n        docFreq = (freq > docFreq) ? freq : docFreq;\n      }\n\n      if (minDocFreq > 0 && docFreq < minDocFreq) {\n        continue; // filter out words that don't occur in enough docs\n      }\n\n      if (docFreq > maxDocFreq) {\n        continue; // filter out words that occur in too many docs\n      }\n\n      if (docFreq == 0) {\n        continue; // index update problem?\n      }\n\n      float idf = similarity.idf(docFreq, numDocs);\n      float score = tf * idf;\n\n      // only really need 1st 3 entries, other ones are for troubleshooting\n      res.insertWithOverflow(new Object[]{word,                   // the word\n          topField,               // the top field\n          score,       // overall score\n          idf,         // idf\n          docFreq,   // freq in all docs\n          tf\n      });\n    }\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6992bd44f38ea79b60af675e2148c25fb638b765","date":1417146793,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/queries/src/java/org/apache/lucene/queries/mlt/MoreLikeThis#createQueue(Map[String,Int]).mjava","pathOld":"lucene/queries/src/java/org/apache/lucene/queries/mlt/MoreLikeThis#createQueue(Map[String,Int]).mjava","sourceNew":"  /**\n   * Create a PriorityQueue from a word-&gt;tf map.\n   *\n   * @param words a map of words keyed on the word(String) with Int objects as the values.\n   */\n  private PriorityQueue<ScoreTerm> createQueue(Map<String, Int> words) throws IOException {\n    // have collected all words in doc and their freqs\n    int numDocs = ir.numDocs();\n    final int limit = Math.min(maxQueryTerms, words.size());\n    FreqQ queue = new FreqQ(limit); // will order words by score\n\n    for (String word : words.keySet()) { // for every word\n      int tf = words.get(word).x; // term freq in the source doc\n      if (minTermFreq > 0 && tf < minTermFreq) {\n        continue; // filter out words that don't occur enough times in the source\n      }\n\n      // go through all the fields and find the largest document frequency\n      String topField = fieldNames[0];\n      int docFreq = 0;\n      for (String fieldName : fieldNames) {\n        int freq = ir.docFreq(new Term(fieldName, word));\n        topField = (freq > docFreq) ? fieldName : topField;\n        docFreq = (freq > docFreq) ? freq : docFreq;\n      }\n\n      if (minDocFreq > 0 && docFreq < minDocFreq) {\n        continue; // filter out words that don't occur in enough docs\n      }\n\n      if (docFreq > maxDocFreq) {\n        continue; // filter out words that occur in too many docs\n      }\n\n      if (docFreq == 0) {\n        continue; // index update problem?\n      }\n\n      float idf = similarity.idf(docFreq, numDocs);\n      float score = tf * idf;\n\n      if (queue.size() < limit) {\n        // there is still space in the queue\n        queue.add(new ScoreTerm(word, topField, score, idf, docFreq, tf));\n      } else {\n        ScoreTerm term = queue.top();\n        if (term.score < score) { // update the smallest in the queue in place and update the queue.\n          term.update(word, topField, score, idf, docFreq, tf);\n          queue.updateTop();\n        }\n      }\n    }\n    return queue;\n  }\n\n","sourceOld":"  /**\n   * Create a PriorityQueue from a word->tf map.\n   *\n   * @param words a map of words keyed on the word(String) with Int objects as the values.\n   */\n  private PriorityQueue<ScoreTerm> createQueue(Map<String, Int> words) throws IOException {\n    // have collected all words in doc and their freqs\n    int numDocs = ir.numDocs();\n    final int limit = Math.min(maxQueryTerms, words.size());\n    FreqQ queue = new FreqQ(limit); // will order words by score\n\n    for (String word : words.keySet()) { // for every word\n      int tf = words.get(word).x; // term freq in the source doc\n      if (minTermFreq > 0 && tf < minTermFreq) {\n        continue; // filter out words that don't occur enough times in the source\n      }\n\n      // go through all the fields and find the largest document frequency\n      String topField = fieldNames[0];\n      int docFreq = 0;\n      for (String fieldName : fieldNames) {\n        int freq = ir.docFreq(new Term(fieldName, word));\n        topField = (freq > docFreq) ? fieldName : topField;\n        docFreq = (freq > docFreq) ? freq : docFreq;\n      }\n\n      if (minDocFreq > 0 && docFreq < minDocFreq) {\n        continue; // filter out words that don't occur in enough docs\n      }\n\n      if (docFreq > maxDocFreq) {\n        continue; // filter out words that occur in too many docs\n      }\n\n      if (docFreq == 0) {\n        continue; // index update problem?\n      }\n\n      float idf = similarity.idf(docFreq, numDocs);\n      float score = tf * idf;\n\n      if (queue.size() < limit) {\n        // there is still space in the queue\n        queue.add(new ScoreTerm(word, topField, score, idf, docFreq, tf));\n      } else {\n        ScoreTerm term = queue.top();\n        if (term.score < score) { // update the smallest in the queue in place and update the queue.\n          term.update(word, topField, score, idf, docFreq, tf);\n          queue.updateTop();\n        }\n      }\n    }\n    return queue;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e562682007e295029696e354ac6947531b083c79","date":1459152450,"type":4,"author":"Tommaso Teofili","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/queries/src/java/org/apache/lucene/queries/mlt/MoreLikeThis#createQueue(Map[String,Int]).mjava","sourceNew":null,"sourceOld":"  /**\n   * Create a PriorityQueue from a word-&gt;tf map.\n   *\n   * @param words a map of words keyed on the word(String) with Int objects as the values.\n   */\n  private PriorityQueue<ScoreTerm> createQueue(Map<String, Int> words) throws IOException {\n    // have collected all words in doc and their freqs\n    int numDocs = ir.numDocs();\n    final int limit = Math.min(maxQueryTerms, words.size());\n    FreqQ queue = new FreqQ(limit); // will order words by score\n\n    for (String word : words.keySet()) { // for every word\n      int tf = words.get(word).x; // term freq in the source doc\n      if (minTermFreq > 0 && tf < minTermFreq) {\n        continue; // filter out words that don't occur enough times in the source\n      }\n\n      // go through all the fields and find the largest document frequency\n      String topField = fieldNames[0];\n      int docFreq = 0;\n      for (String fieldName : fieldNames) {\n        int freq = ir.docFreq(new Term(fieldName, word));\n        topField = (freq > docFreq) ? fieldName : topField;\n        docFreq = (freq > docFreq) ? freq : docFreq;\n      }\n\n      if (minDocFreq > 0 && docFreq < minDocFreq) {\n        continue; // filter out words that don't occur in enough docs\n      }\n\n      if (docFreq > maxDocFreq) {\n        continue; // filter out words that occur in too many docs\n      }\n\n      if (docFreq == 0) {\n        continue; // index update problem?\n      }\n\n      float idf = similarity.idf(docFreq, numDocs);\n      float score = tf * idf;\n\n      if (queue.size() < limit) {\n        // there is still space in the queue\n        queue.add(new ScoreTerm(word, topField, score, idf, docFreq, tf));\n      } else {\n        ScoreTerm term = queue.top();\n        if (term.score < score) { // update the smallest in the queue in place and update the queue.\n          term.update(word, topField, score, idf, docFreq, tf);\n          queue.updateTop();\n        }\n      }\n    }\n    return queue;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"6992bd44f38ea79b60af675e2148c25fb638b765":["2f73cfcb38e83bad8ad6dce5dd4f021d44efe73d"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"2f73cfcb38e83bad8ad6dce5dd4f021d44efe73d":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"e562682007e295029696e354ac6947531b083c79":["6992bd44f38ea79b60af675e2148c25fb638b765"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e562682007e295029696e354ac6947531b083c79"]},"commit2Childs":{"6992bd44f38ea79b60af675e2148c25fb638b765":["e562682007e295029696e354ac6947531b083c79"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["2f73cfcb38e83bad8ad6dce5dd4f021d44efe73d"],"2f73cfcb38e83bad8ad6dce5dd4f021d44efe73d":["6992bd44f38ea79b60af675e2148c25fb638b765"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"e562682007e295029696e354ac6947531b083c79":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}